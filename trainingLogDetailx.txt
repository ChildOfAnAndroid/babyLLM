2025-04-01 12:08:22 | 10 | LR0.0003 | loss44.4838 | gradNorm0.9999 | logitMin-34.5793 | logitMax-3.2770 | memoryGate0.3333 | scheduledSampling0.0 | tokenCount3.0 | Training
2025-04-01 12:08:50 | 20 | LR0.0003 | loss48.7268 | gradNorm1.0000 | tokenCount3.0 | logitMin-18.0944 | logitMax11.3677 | memoryGate0.3333 | Training
2025-04-01 12:09:18 | 30 | LR0.0003 | loss39.1048 | gradNorm1.0000 | tokenCount3.0 | logitMin-30.0748 | logitMax-5.0849 | memoryGate0.3333 | Training
2025-04-01 12:09:47 | 40 | LR0.0003 | loss34.2275 | gradNorm0.9999 | tokenCount3.0 | logitMin-48.6296 | logitMax-18.3814 | memoryGate0.3333 | Training
2025-04-01 12:10:16 | 50 | LR0.0003 | loss41.0097 | gradNorm0.9999 | tokenCount3.0 | logitMin-29.5186 | logitMax-5.0730 | memoryGate0.3333 | Training
2025-04-01 12:10:44 | 60 | LR0.0003 | loss41.4989 | gradNorm0.9999 | tokenCount3.0 | logitMin-41.5367 | logitMax-13.5112 | memoryGate0.3333 | Training
2025-04-01 12:11:48 | 70 | LR0.0003 | loss44.2336 | gradNorm0.9999 | tokenCount3.0 | logitMin-40.7140 | logitMax-13.2904 | memoryGate0.3333 | Training
2025-04-01 12:13:16 | 80 | LR0.0003 | loss25.9143 | gradNorm0.9999 | tokenCount3.0 | logitMin-40.2713 | logitMax-12.6245 | memoryGate0.3333 | Training
2025-04-01 12:14:19 | 90 | LR0.0003 | loss44.7216 | gradNorm0.9999 | tokenCount3.0 | logitMin-34.8892 | logitMax-10.8788 | memoryGate0.3333 | Training
2025-04-01 12:17:38 | 100 | LR0.0003 | loss32.2352 | gradNorm0.9999 | tokenCount3.0 | logitMin-33.3302 | logitMax-9.5988 | memoryGate0.3333 | Training
2025-04-01 12:27:47 | 100 | LR0.0003 | loss27.6367 | gradNorm0.9999 | logitMin-55.5624 | logitMax-23.1680 | memoryGate0.3333 | scheduledSampling0.0 | tokenCount3.0 | Training
2025-04-01 12:32:39 | 200 | LR0.0003 | loss39.2712 | gradNorm1.0000 | tokenCount3.0 | logitMin-37.9259 | logitMax-8.0787 | memoryGate0.3333 | Training
2025-04-01 12:37:45 | 300 | LR0.0003 | loss44.9736 | gradNorm1.0000 | tokenCount3.0 | logitMin-40.2325 | logitMax-10.1579 | memoryGate0.3333 | Training
2025-04-01 12:43:04 | 400 | LR0.0003 | loss39.0474 | gradNorm0.9999 | tokenCount3.0 | logitMin-34.7129 | logitMax-8.9797 | memoryGate0.3333 | Training
2025-04-01 12:48:50 | 500 | LR0.0003 | loss32.4658 | gradNorm0.9999 | tokenCount3.0 | logitMin-36.6271 | logitMax-13.3079 | memoryGate0.3327 | Training
2025-04-01 12:53:46 | 600 | LR0.0003 | loss48.3788 | gradNorm0.9999 | tokenCount3.0 | logitMin-40.6201 | logitMax-6.0953 | memoryGate0.3333 | Training
2025-04-01 12:58:43 | 700 | LR0.0003 | loss37.4778 | gradNorm0.9999 | tokenCount3.0 | logitMin-33.9535 | logitMax-11.6043 | memoryGate0.3333 | Training
2025-04-01 13:03:51 | 800 | LR0.0003 | loss42.7151 | gradNorm1.0000 | tokenCount3.0 | logitMin-33.6290 | logitMax-6.7306 | memoryGate0.3333 | Training
2025-04-01 13:09:24 | 900 | LR0.0003 | loss44.9255 | gradNorm1.0000 | tokenCount3.0 | logitMin-32.1243 | logitMax-4.2861 | memoryGate0.3333 | Training
2025-04-01 13:21:36 | 100 | LR0.0003 | loss27.6367 | gradNorm0.9999 | logitMin-55.5624 | logitMax-23.1680 | memoryGate0.3333 | scheduledSampling0.0 | tokenCount3.0 | Training
2025-04-01 13:27:42 | 200 | LR0.0003 | loss39.2712 | gradNorm1.0000 | tokenCount3.0 | logitMin-37.9259 | logitMax-8.0787 | memoryGate0.3333 | Training
2025-04-01 13:33:30 | 300 | LR0.0003 | loss44.9736 | gradNorm1.0000 | tokenCount3.0 | logitMin-40.2325 | logitMax-10.1579 | memoryGate0.3333 | Training
2025-04-01 13:39:29 | 400 | LR0.0003 | loss39.0474 | gradNorm0.9999 | tokenCount3.0 | logitMin-34.7129 | logitMax-8.9797 | memoryGate0.3333 | Training
2025-04-01 13:45:27 | 500 | LR0.0003 | loss32.4658 | gradNorm0.9999 | tokenCount3.0 | logitMin-36.6271 | logitMax-13.3079 | memoryGate0.3327 | Training
2025-04-01 13:51:25 | 600 | LR0.0003 | loss48.3788 | gradNorm0.9999 | tokenCount3.0 | logitMin-40.6201 | logitMax-6.0953 | memoryGate0.3333 | Training
2025-04-01 13:57:18 | 700 | LR0.0003 | loss37.4778 | gradNorm0.9999 | tokenCount3.0 | logitMin-33.9535 | logitMax-11.6043 | memoryGate0.3333 | Training
2025-04-01 14:03:12 | 800 | LR0.0003 | loss42.7151 | gradNorm1.0000 | tokenCount3.0 | logitMin-33.6290 | logitMax-6.7306 | memoryGate0.3333 | Training
2025-04-01 14:09:07 | 900 | LR0.0003 | loss44.9255 | gradNorm1.0000 | tokenCount3.0 | logitMin-32.1243 | logitMax-4.2861 | memoryGate0.3333 | Training
2025-04-01 14:15:02 | 1000 | LR0.0003 | loss45.0679 | gradNorm1.0000 | tokenCount3.0 | logitMin-31.5090 | logitMax-2.9547 | memoryGate0.3253 | Training
2025-04-01 14:20:53 | 1100 | LR0.0003 | loss36.1677 | gradNorm0.9999 | tokenCount3.0 | logitMin-28.0126 | logitMax-4.6739 | memoryGate0.3333 | Training
2025-04-01 14:26:43 | 1200 | LR0.0003 | loss32.3844 | gradNorm0.9999 | tokenCount3.0 | logitMin-26.8898 | logitMax-6.2795 | memoryGate0.3333 | Training
2025-04-01 14:32:32 | 1300 | LR0.0003 | loss46.2341 | gradNorm0.9999 | tokenCount3.0 | logitMin-31.4247 | logitMax-4.9264 | memoryGate0.3333 | Training
2025-04-01 14:38:23 | 1400 | LR0.0003 | loss33.1467 | gradNorm1.0000 | tokenCount3.0 | logitMin-25.8626 | logitMax-6.9060 | memoryGate0.3333 | Training
2025-04-01 14:44:13 | 1500 | LR0.0003 | loss38.9934 | gradNorm1.0000 | tokenCount3.0 | logitMin-29.7623 | logitMax-2.8891 | memoryGate0.3333 | Training
2025-04-01 14:49:55 | 1600 | LR0.0003 | loss44.7431 | gradNorm1.0000 | tokenCount3.0 | logitMin-25.4898 | logitMax0.9192 | memoryGate0.3333 | Training
2025-04-01 14:55:00 | 1700 | LR0.0003 | loss45.3742 | gradNorm0.9999 | tokenCount3.0 | logitMin-27.3460 | logitMax1.3998 | memoryGate0.3333 | Training
2025-04-01 15:00:25 | 1800 | LR0.0003 | loss42.2640 | gradNorm1.0000 | tokenCount3.0 | logitMin-27.9354 | logitMax-0.2310 | memoryGate0.3333 | Training
2025-04-01 15:05:46 | 1900 | LR0.0003 | loss38.6438 | gradNorm0.9999 | tokenCount3.0 | logitMin-26.2693 | logitMax-3.8574 | memoryGate0.3333 | Training
2025-04-01 15:11:11 | 2000 | LR0.0003 | loss41.0704 | gradNorm1.0000 | tokenCount3.0 | logitMin-26.3746 | logitMax-1.1257 | memoryGate0.3333 | Training
2025-04-01 15:16:39 | 2100 | LR0.0003 | loss33.0445 | gradNorm1.0000 | tokenCount3.0 | logitMin-27.3442 | logitMax-7.5067 | memoryGate0.3333 | Training
2025-04-01 15:22:03 | 2200 | LR0.0003 | loss38.4150 | gradNorm0.9999 | tokenCount3.0 | logitMin-24.8421 | logitMax-0.9137 | memoryGate0.3333 | Training
2025-04-01 15:27:27 | 2300 | LR0.0003 | loss30.1481 | gradNorm0.9999 | tokenCount3.0 | logitMin-25.2006 | logitMax-4.5216 | memoryGate0.3331 | Training
2025-04-01 15:32:54 | 2400 | LR0.0003 | loss29.0975 | gradNorm0.9999 | tokenCount3.0 | logitMin-24.4517 | logitMax-3.7444 | memoryGate0.3331 | Training
2025-04-01 15:38:18 | 2500 | LR0.0003 | loss26.7603 | gradNorm1.0000 | tokenCount3.0 | logitMin-22.2992 | logitMax-4.9027 | memoryGate0.3333 | Training
2025-04-01 15:43:42 | 2600 | LR0.0003 | loss38.4760 | gradNorm1.0000 | tokenCount3.0 | logitMin-25.6170 | logitMax-1.7159 | memoryGate0.3333 | Training
2025-04-01 15:49:05 | 2700 | LR0.0003 | loss45.8750 | gradNorm0.9999 | tokenCount3.0 | logitMin-20.8686 | logitMax4.5590 | memoryGate0.3333 | Training
2025-04-01 15:54:03 | 2800 | LR0.0003 | loss36.1289 | gradNorm1.0000 | tokenCount3.0 | logitMin-17.4715 | logitMax3.7929 | memoryGate0.3333 | Training
2025-04-01 15:58:59 | 2900 | LR0.0003 | loss36.7100 | gradNorm1.0000 | tokenCount3.0 | logitMin-16.5386 | logitMax6.8862 | memoryGate0.3333 | Training
2025-04-01 16:03:59 | 3000 | LR0.0003 | loss26.8064 | gradNorm0.9999 | tokenCount3.0 | logitMin-13.4760 | logitMax5.8913 | memoryGate0.3333 | Training
2025-04-01 16:08:58 | 3100 | LR0.0003 | loss36.7121 | gradNorm0.9999 | tokenCount3.0 | logitMin-19.2003 | logitMax7.0835 | memoryGate0.3333 | Training
2025-04-01 16:13:57 | 3200 | LR0.0003 | loss36.8042 | gradNorm1.0000 | tokenCount3.0 | logitMin-17.1303 | logitMax7.0723 | memoryGate0.3333 | Training
2025-04-01 16:19:00 | 3300 | LR0.0003 | loss36.6905 | gradNorm1.0000 | tokenCount3.0 | logitMin-17.7781 | logitMax3.0847 | memoryGate0.3333 | Training
2025-04-01 16:24:04 | 3400 | LR0.0003 | loss31.7493 | gradNorm1.0000 | tokenCount3.0 | logitMin-13.1427 | logitMax6.2538 | memoryGate0.3333 | Training
2025-04-01 16:29:09 | 3500 | LR0.0003 | loss40.8907 | gradNorm1.0000 | tokenCount3.0 | logitMin-11.6432 | logitMax14.6336 | memoryGate0.3333 | Training
2025-04-01 16:34:13 | 3600 | LR0.0003 | loss35.9489 | gradNorm1.0000 | tokenCount3.0 | logitMin-8.3863 | logitMax15.0758 | memoryGate0.3333 | Training
2025-04-01 16:39:12 | 3700 | LR0.0003 | loss30.9469 | gradNorm0.9999 | tokenCount3.0 | logitMin-11.1956 | logitMax6.5063 | memoryGate0.3333 | Training
2025-04-01 17:08:57 | 3800 | LR0.0003 | loss29.4825 | gradNorm0.9999 | tokenCount3.0 | logitMin-12.6867 | logitMax7.0956 | memoryGate0.3333 | Training
2025-04-01 17:13:50 | 3900 | LR0.0003 | loss30.1868 | gradNorm0.9999 | tokenCount3.0 | logitMin-12.6547 | logitMax4.2771 | memoryGate0.3333 | Training
2025-04-01 17:18:50 | 4000 | LR0.0003 | loss37.9876 | gradNorm0.9999 | tokenCount3.0 | logitMin-18.2672 | logitMax5.8626 | memoryGate0.3333 | Training
2025-04-01 17:23:49 | 4100 | LR0.0003 | loss44.6722 | gradNorm0.9999 | tokenCount3.0 | logitMin-22.0024 | logitMax5.7897 | memoryGate0.3333 | Training
2025-04-01 17:28:50 | 4200 | LR0.0003 | loss45.6749 | gradNorm1.0000 | tokenCount3.0 | logitMin-21.1147 | logitMax3.3347 | memoryGate0.3332 | Training
2025-04-01 17:33:58 | 4300 | LR0.0003 | loss44.1110 | gradNorm0.9999 | tokenCount3.0 | logitMin-19.6800 | logitMax3.2612 | memoryGate0.3333 | Training
2025-04-01 17:39:04 | 4400 | LR0.0003 | loss52.3818 | gradNorm1.0000 | tokenCount3.0 | logitMin-22.1505 | logitMax6.7489 | memoryGate0.3333 | Training
2025-04-01 17:44:28 | 100 | LR0.0003 | loss27.6367 | gradNorm0.9999 | logitMin-55.5624 | logitMax-23.1680 | memoryGate0.3333 | scheduledSampling0.0 | tokenCount3.0 | Training
2025-04-01 17:49:21 | 200 | LR0.0003 | loss39.2712 | gradNorm1.0000 | tokenCount3.0 | logitMin-37.9259 | logitMax-8.0787 | memoryGate0.3333 | Training
2025-04-01 17:54:38 | 300 | LR0.0003 | loss44.9736 | gradNorm1.0000 | tokenCount3.0 | logitMin-40.2325 | logitMax-10.1579 | memoryGate0.3333 | Training
2025-04-01 17:59:43 | 400 | LR0.0003 | loss39.0474 | gradNorm0.9999 | tokenCount3.0 | logitMin-34.7129 | logitMax-8.9797 | memoryGate0.3333 | Training
2025-04-01 18:08:45 | 100 | LR0.0003 | loss37.5087 | gradNorm0.9900 | logitMin-40.0827 | logitMax6.1246 | memoryGate0.3333 | scheduledSampling0.0 | tokenCount3.0 | Training
2025-04-01 18:13:56 | 200 | LR0.0003 | loss46.5570 | gradNorm0.9999 | tokenCount3.0 | logitMin-25.1021 | logitMax9.7591 | memoryGate0.3333 | Training
2025-04-01 18:19:18 | 300 | LR0.0003 | loss29.9430 | gradNorm0.9999 | tokenCount3.0 | logitMin-18.3980 | logitMax2.8866 | memoryGate0.3333 | Training
2025-04-01 18:24:44 | 400 | LR0.0003 | loss25.5459 | gradNorm0.9999 | tokenCount3.0 | logitMin-24.3172 | logitMax-5.7599 | memoryGate0.3333 | Training
2025-04-01 18:32:36 | 100 | LR0.0003 | loss35.6938 | gradNorm0.9900 | logitMin-41.0307 | logitMax5.7077 | memoryGate0.3333 | scheduledSampling0.0 | tokenCount3.0 | Training
2025-04-01 18:37:45 | 200 | LR0.0003 | loss42.7105 | gradNorm1.0000 | tokenCount3.0 | logitMin-27.5390 | logitMax7.7023 | memoryGate0.3333 | Training
2025-04-01 18:42:49 | 300 | LR0.0003 | loss33.4387 | gradNorm0.9999 | tokenCount3.0 | logitMin-22.1242 | logitMax3.7515 | memoryGate0.3333 | Training
2025-04-01 18:47:57 | 400 | LR0.0003 | loss27.8834 | gradNorm0.9999 | tokenCount3.0 | logitMin-25.8529 | logitMax-5.3943 | memoryGate0.3333 | Training
2025-04-01 18:53:12 | 500 | LR0.0003 | loss27.7121 | gradNorm1.0000 | tokenCount3.0 | logitMin-23.8507 | logitMax-3.9150 | memoryGate0.3333 | Training
2025-04-01 18:58:14 | 600 | LR0.0003 | loss24.2895 | gradNorm1.0000 | tokenCount3.0 | logitMin-23.9462 | logitMax-4.5691 | memoryGate0.3333 | Training
2025-04-01 19:03:19 | 700 | LR0.0003 | loss26.2293 | gradNorm1.0000 | tokenCount3.0 | logitMin-20.4087 | logitMax-3.6603 | memoryGate0.3333 | Training
2025-04-01 19:08:22 | 800 | LR0.0003 | loss25.9656 | gradNorm0.9999 | tokenCount3.0 | logitMin-18.2206 | logitMax-0.0846 | memoryGate0.3333 | Training
2025-04-01 19:13:27 | 900 | LR0.0003 | loss27.3691 | gradNorm1.0000 | tokenCount3.0 | logitMin-17.4012 | logitMax-0.0790 | memoryGate0.3333 | Training
2025-04-01 19:18:32 | 1000 | LR0.0003 | loss24.1723 | gradNorm0.9999 | tokenCount3.0 | logitMin-19.2032 | logitMax-2.1985 | memoryGate0.3333 | Training
2025-04-01 19:23:34 | 1100 | LR0.0003 | loss30.3460 | gradNorm1.0000 | tokenCount3.0 | logitMin-20.8373 | logitMax1.9195 | memoryGate0.3333 | Training
2025-04-01 19:28:44 | 1200 | LR0.0003 | loss28.5961 | gradNorm1.0000 | tokenCount3.0 | logitMin-19.8951 | logitMax3.8860 | memoryGate0.3333 | Training
2025-04-01 19:34:13 | 1300 | LR0.0003 | loss32.2821 | gradNorm1.0000 | tokenCount3.0 | logitMin-19.3933 | logitMax2.3823 | memoryGate0.3333 | Training
2025-04-01 19:39:15 | 1400 | LR0.0003 | loss33.0538 | gradNorm0.9999 | tokenCount3.0 | logitMin-22.2607 | logitMax-0.2244 | memoryGate0.3333 | Training
2025-04-01 19:44:16 | 1500 | LR0.0003 | loss28.9576 | gradNorm0.9999 | tokenCount3.0 | logitMin-22.6218 | logitMax-2.6689 | memoryGate0.3333 | Training
2025-04-01 19:49:18 | 1600 | LR0.0003 | loss26.6218 | gradNorm1.0000 | tokenCount3.0 | logitMin-21.1539 | logitMax-0.7930 | memoryGate0.3333 | Training
2025-04-01 19:54:22 | 1700 | LR0.0003 | loss28.0978 | gradNorm1.0000 | tokenCount3.0 | logitMin-23.3998 | logitMax-5.5864 | memoryGate0.3333 | Training
2025-04-01 19:59:25 | 1800 | LR0.0003 | loss26.6205 | gradNorm1.0000 | tokenCount3.0 | logitMin-21.6166 | logitMax-1.4836 | memoryGate0.3333 | Training
2025-04-01 20:04:25 | 1900 | LR0.0003 | loss24.9773 | gradNorm0.9999 | tokenCount3.0 | logitMin-18.9415 | logitMax-0.0932 | memoryGate0.3333 | Training
2025-04-01 20:09:28 | 2000 | LR0.0003 | loss29.7596 | gradNorm0.9999 | tokenCount3.0 | logitMin-22.3863 | logitMax0.0956 | memoryGate0.3333 | Training
2025-04-01 20:14:51 | 2100 | LR0.0003 | loss32.5226 | gradNorm1.0000 | tokenCount3.0 | logitMin-23.1460 | logitMax-2.1832 | memoryGate0.3332 | Training
2025-04-01 20:20:06 | 2200 | LR0.0003 | loss24.4373 | gradNorm1.0000 | tokenCount3.0 | logitMin-21.9835 | logitMax-2.8372 | memoryGate0.3333 | Training
2025-04-01 20:25:09 | 2300 | LR0.0003 | loss24.9945 | gradNorm0.9999 | tokenCount3.0 | logitMin-25.1943 | logitMax-3.0558 | memoryGate0.3333 | Training
2025-04-01 20:30:16 | 2400 | LR0.0003 | loss20.2155 | gradNorm0.9999 | tokenCount3.0 | logitMin-22.2242 | logitMax-3.7165 | memoryGate0.3333 | Training
2025-04-01 20:35:23 | 2500 | LR0.0003 | loss27.2108 | gradNorm0.9999 | tokenCount3.0 | logitMin-23.9809 | logitMax-1.4615 | memoryGate0.3333 | Training
2025-04-01 20:40:26 | 2600 | LR0.0003 | loss26.9940 | gradNorm0.9999 | tokenCount3.0 | logitMin-20.0604 | logitMax-1.9417 | memoryGate0.3333 | Training
2025-04-01 20:45:29 | 2700 | LR0.0003 | loss29.1266 | gradNorm0.9999 | tokenCount3.0 | logitMin-16.0422 | logitMax2.2092 | memoryGate0.3333 | Training
2025-04-01 20:50:28 | 2800 | LR0.0003 | loss28.6907 | gradNorm1.0000 | tokenCount3.0 | logitMin-13.4413 | logitMax4.4387 | memoryGate0.3333 | Training
2025-04-01 20:55:28 | 2900 | LR0.0003 | loss24.7875 | gradNorm1.0000 | tokenCount3.0 | logitMin-13.7510 | logitMax0.9572 | memoryGate0.3333 | Training
2025-04-01 21:00:28 | 3000 | LR0.0003 | loss26.1847 | gradNorm0.9999 | tokenCount3.0 | logitMin-12.6249 | logitMax8.3062 | memoryGate0.3333 | Training
2025-04-01 21:07:45 | 100 | LR0.0003 | loss14.7036 | gradNorm0.9061 | logitMin-42.4305 | logitMax17.3397 | memoryGate0.3333 | scheduledSampling0.0 | tokenCount3.0 | Training
2025-04-01 21:14:59 | 100 | LR0.0003 | loss16.9396 | gradNorm0.7678 | logitMin-56.2336 | logitMax18.6931 | memoryGate0.3333 | scheduledSampling0.0 | tokenCount3.0 | Training
2025-04-01 21:20:00 | 200 | LR0.0003 | loss36.8145 | gradNorm1.0000 | tokenCount3.0 | logitMin-24.9412 | logitMax19.1514 | memoryGate0.3333 | Training
2025-04-01 21:25:01 | 300 | LR0.0003 | loss23.0219 | gradNorm1.0000 | tokenCount3.0 | logitMin-14.3042 | logitMax6.8406 | memoryGate0.3333 | Training
2025-04-01 21:30:18 | 400 | LR0.0003 | loss29.3314 | gradNorm0.9999 | tokenCount3.0 | logitMin-8.8192 | logitMax14.9666 | memoryGate0.3333 | Training
2025-04-01 21:35:24 | 500 | LR0.0003 | loss20.4540 | gradNorm1.0000 | tokenCount3.0 | logitMin-11.9824 | logitMax7.4463 | memoryGate0.3333 | Training
2025-04-01 21:40:26 | 600 | LR0.0003 | loss25.2823 | gradNorm1.0000 | tokenCount3.0 | logitMin-12.3428 | logitMax16.5294 | memoryGate0.3333 | Training
2025-04-01 21:45:24 | 700 | LR0.0003 | loss31.4508 | gradNorm0.9999 | tokenCount3.0 | logitMin-19.1426 | logitMax2.6938 | memoryGate0.3333 | Training
2025-04-01 21:50:30 | 800 | LR0.0003 | loss36.8405 | gradNorm0.9999 | tokenCount3.0 | logitMin-19.3549 | logitMax9.1268 | memoryGate0.3333 | Training
2025-04-01 21:55:36 | 900 | LR0.0003 | loss26.9790 | gradNorm1.0000 | tokenCount3.0 | logitMin-18.9057 | logitMax2.1537 | memoryGate0.3333 | Training
2025-04-01 22:00:41 | 1000 | LR0.0003 | loss27.6177 | gradNorm0.9999 | tokenCount3.0 | logitMin-20.3433 | logitMax-0.3409 | memoryGate0.3333 | Training
2025-04-01 22:05:45 | 1100 | LR0.0003 | loss30.4468 | gradNorm0.9999 | tokenCount3.0 | logitMin-16.6368 | logitMax3.6719 | memoryGate0.3333 | Training
2025-04-01 22:10:52 | 1200 | LR0.0003 | loss29.1419 | gradNorm0.9999 | tokenCount3.0 | logitMin-17.3139 | logitMax3.9663 | memoryGate0.3333 | Training
2025-04-01 22:15:59 | 1300 | LR0.0003 | loss31.9550 | gradNorm1.0000 | tokenCount3.0 | logitMin-17.1736 | logitMax2.7218 | memoryGate0.3333 | Training
2025-04-01 22:21:03 | 1400 | LR0.0003 | loss25.8868 | gradNorm1.0000 | tokenCount3.0 | logitMin-19.7630 | logitMax-2.4917 | memoryGate0.3333 | Training
2025-04-01 22:26:05 | 1500 | LR0.0003 | loss29.5466 | gradNorm0.9999 | tokenCount3.0 | logitMin-14.5098 | logitMax3.4289 | memoryGate0.3333 | Training
2025-04-01 22:31:10 | 1600 | LR0.0003 | loss30.4051 | gradNorm0.9999 | tokenCount3.0 | logitMin-21.5041 | logitMax3.7333 | memoryGate0.3333 | Training
2025-04-01 22:36:15 | 1700 | LR0.0003 | loss23.1768 | gradNorm0.9999 | tokenCount3.0 | logitMin-15.5939 | logitMax-0.6964 | memoryGate0.3333 | Training
2025-04-01 22:41:19 | 1800 | LR0.0003 | loss27.3495 | gradNorm0.9999 | tokenCount3.0 | logitMin-14.9084 | logitMax2.8444 | memoryGate0.3333 | Training
2025-04-01 22:46:29 | 1900 | LR0.0003 | loss30.0088 | gradNorm1.0000 | tokenCount3.0 | logitMin-13.2441 | logitMax5.4359 | memoryGate0.3333 | Training
2025-04-01 22:51:34 | 2000 | LR0.0003 | loss23.6316 | gradNorm1.0000 | tokenCount3.0 | logitMin-14.4948 | logitMax0.4381 | memoryGate0.3333 | Training
2025-04-01 22:56:39 | 2100 | LR0.0003 | loss27.2806 | gradNorm1.0000 | tokenCount3.0 | logitMin-19.5204 | logitMax-2.2543 | memoryGate0.3333 | Training
2025-04-01 23:01:43 | 2200 | LR0.0003 | loss26.3956 | gradNorm1.0000 | tokenCount3.0 | logitMin-21.4683 | logitMax-3.8360 | memoryGate0.3333 | Training
2025-04-01 23:06:46 | 2300 | LR0.0003 | loss33.3138 | gradNorm0.9999 | tokenCount3.0 | logitMin-15.6333 | logitMax5.2463 | memoryGate0.3333 | Training
2025-04-01 23:11:50 | 2400 | LR0.0003 | loss33.3394 | gradNorm1.0000 | tokenCount3.0 | logitMin-16.4075 | logitMax3.8364 | memoryGate0.3333 | Training
2025-04-01 23:16:53 | 2500 | LR0.0003 | loss33.3330 | gradNorm1.0000 | tokenCount3.0 | logitMin-15.6599 | logitMax4.7845 | memoryGate0.3333 | Training
2025-04-01 23:21:57 | 2600 | LR0.0003 | loss24.2506 | gradNorm1.0000 | tokenCount3.0 | logitMin-12.3718 | logitMax6.7045 | memoryGate0.3333 | Training
2025-04-01 23:27:02 | 2700 | LR0.0003 | loss26.0060 | gradNorm0.9999 | tokenCount3.0 | logitMin-16.7034 | logitMax1.5468 | memoryGate0.3333 | Training
2025-04-01 23:32:09 | 2800 | LR0.0003 | loss26.8718 | gradNorm0.9999 | tokenCount3.0 | logitMin-17.3913 | logitMax0.4701 | memoryGate0.3333 | Training
2025-04-01 23:37:16 | 2900 | LR0.0003 | loss22.2631 | gradNorm1.0000 | tokenCount3.0 | logitMin-12.6677 | logitMax4.5477 | memoryGate0.3333 | Training
2025-04-01 23:42:23 | 3000 | LR0.0003 | loss23.4110 | gradNorm1.0000 | tokenCount3.0 | logitMin-14.7730 | logitMax0.3550 | memoryGate0.3333 | Training
2025-04-01 23:47:30 | 3100 | LR0.0003 | loss25.3585 | gradNorm1.0000 | tokenCount3.0 | logitMin-14.9065 | logitMax3.0423 | memoryGate0.3333 | Training
2025-04-01 23:52:49 | 3200 | LR0.0003 | loss22.0596 | gradNorm1.0000 | tokenCount3.0 | logitMin-19.4981 | logitMax-5.0116 | memoryGate0.3333 | Training
2025-04-01 23:57:55 | 3300 | LR0.0003 | loss26.9559 | gradNorm1.0000 | tokenCount3.0 | logitMin-16.5293 | logitMax0.8592 | memoryGate0.3333 | Training
2025-04-02 00:02:57 | 3400 | LR0.0003 | loss35.0140 | gradNorm0.9999 | tokenCount3.0 | logitMin-20.4413 | logitMax3.4038 | memoryGate0.3333 | Training
2025-04-02 00:12:44 | 100 | LR0.0003 | loss8.3942 | gradNorm0.8610 | logitMin-45.1363 | logitMax13.7440 | memoryGate0.3333 | scheduledSampling0.0 | tokenCount3.0 | Training
2025-04-02 00:17:38 | 200 | LR0.0003 | loss22.2925 | gradNorm1.0000 | tokenCount3.0 | logitMin-18.4357 | logitMax13.0838 | memoryGate0.3332 | Training
2025-04-02 00:22:31 | 300 | LR0.0003 | loss25.7636 | gradNorm1.0000 | tokenCount3.0 | logitMin-13.9388 | logitMax5.0539 | memoryGate0.3333 | Training
2025-04-02 00:27:28 | 400 | LR0.0003 | loss22.4632 | gradNorm1.0000 | tokenCount3.0 | logitMin-12.4408 | logitMax6.7920 | memoryGate0.3333 | Training
2025-04-02 00:32:24 | 500 | LR0.0003 | loss32.1460 | gradNorm1.0000 | tokenCount3.0 | logitMin-18.1606 | logitMax3.8530 | memoryGate0.3333 | Training
2025-04-02 00:37:21 | 600 | LR0.0003 | loss25.3075 | gradNorm0.9999 | tokenCount3.0 | logitMin-15.7292 | logitMax2.5132 | memoryGate0.3333 | Training
2025-04-02 00:42:20 | 700 | LR0.0003 | loss31.5421 | gradNorm0.9999 | tokenCount3.0 | logitMin-17.6094 | logitMax2.5439 | memoryGate0.3333 | Training
2025-04-02 00:47:18 | 800 | LR0.0003 | loss24.7005 | gradNorm0.9999 | tokenCount3.0 | logitMin-15.8456 | logitMax0.9597 | memoryGate0.3333 | Training
2025-04-02 00:52:16 | 900 | LR0.0003 | loss26.9339 | gradNorm0.9999 | tokenCount3.0 | logitMin-17.1458 | logitMax2.9692 | memoryGate0.3333 | Training
2025-04-02 00:57:14 | 1000 | LR0.0003 | loss30.3401 | gradNorm0.9999 | tokenCount3.0 | logitMin-17.6995 | logitMax2.2568 | memoryGate0.3333 | Training
2025-04-02 01:02:12 | 1100 | LR0.0003 | loss31.4028 | gradNorm0.9999 | tokenCount3.0 | logitMin-17.7769 | logitMax1.8191 | memoryGate0.3333 | Training
2025-04-02 01:07:12 | 1200 | LR0.0003 | loss25.7291 | gradNorm0.9999 | tokenCount3.0 | logitMin-19.9712 | logitMax-5.3496 | memoryGate0.3333 | Training
2025-04-02 01:12:13 | 1300 | LR0.0003 | loss31.0665 | gradNorm0.9999 | tokenCount3.0 | logitMin-23.5206 | logitMax-3.7154 | memoryGate0.3333 | Training
2025-04-02 04:41:28 | 100 | LR0.0003 | loss9.0451 | gradNorm0.7675 | logitMin-44.5281 | logitMax17.1989 | memoryGate0.3333 | scheduledSampling0.0 | tokenCount3.0 | Training
2025-04-02 04:46:10 | 200 | LR0.0003 | loss30.1311 | gradNorm0.9999 | tokenCount3.0 | logitMin-25.3766 | logitMax19.8246 | memoryGate0.3333 | Training
2025-04-02 04:51:04 | 300 | LR0.0003 | loss28.7628 | gradNorm1.0000 | tokenCount3.0 | logitMin-20.4426 | logitMax3.8532 | memoryGate0.3333 | Training
2025-04-02 04:56:08 | 400 | LR0.0003 | loss24.3401 | gradNorm1.0000 | tokenCount3.0 | logitMin-19.3135 | logitMax3.4134 | memoryGate0.3333 | Training
2025-04-02 05:01:09 | 500 | LR0.0003 | loss23.8668 | gradNorm1.0000 | tokenCount3.0 | logitMin-15.3514 | logitMax2.9035 | memoryGate0.3333 | Training
2025-04-02 05:06:09 | 600 | LR0.0003 | loss25.9110 | gradNorm0.9999 | tokenCount3.0 | logitMin-16.7868 | logitMax2.0901 | memoryGate0.3333 | Training
2025-04-02 05:11:08 | 700 | LR0.0003 | loss26.0816 | gradNorm0.9999 | tokenCount3.0 | logitMin-14.5229 | logitMax3.3887 | memoryGate0.3333 | Training
2025-04-02 05:16:07 | 800 | LR0.0003 | loss32.7030 | gradNorm0.9999 | tokenCount3.0 | logitMin-20.1031 | logitMax2.7051 | memoryGate0.3333 | Training
2025-04-02 05:20:58 | 900 | LR0.0003 | loss24.0259 | gradNorm1.0000 | tokenCount3.0 | logitMin-20.3644 | logitMax-0.4079 | memoryGate0.3333 | Training
2025-04-02 05:25:47 | 1000 | LR0.0003 | loss22.7222 | gradNorm0.9999 | tokenCount3.0 | logitMin-18.3749 | logitMax-0.7091 | memoryGate0.3333 | Training
2025-04-02 05:30:37 | 1100 | LR0.0003 | loss25.8630 | gradNorm1.0000 | tokenCount3.0 | logitMin-19.9554 | logitMax-0.0717 | memoryGate0.3333 | Training
2025-04-02 05:35:26 | 1200 | LR0.0003 | loss26.7364 | gradNorm0.9999 | tokenCount3.0 | logitMin-17.2441 | logitMax-0.9850 | memoryGate0.3333 | Training
2025-04-02 05:40:21 | 1300 | LR0.0003 | loss25.6425 | gradNorm1.0000 | tokenCount3.0 | logitMin-21.9513 | logitMax-5.6702 | memoryGate0.3333 | Training
2025-04-02 05:45:10 | 1400 | LR0.0003 | loss31.2678 | gradNorm1.0000 | tokenCount3.0 | logitMin-22.7938 | logitMax-6.8314 | memoryGate0.3333 | Training
2025-04-02 05:50:01 | 1500 | LR0.0003 | loss28.0358 | gradNorm1.0000 | tokenCount3.0 | logitMin-23.2443 | logitMax-9.0951 | memoryGate0.3333 | Training
2025-04-02 05:54:53 | 1600 | LR0.0003 | loss27.9256 | gradNorm1.0000 | tokenCount3.0 | logitMin-22.8002 | logitMax-8.3755 | memoryGate0.3333 | Training
2025-04-02 05:59:44 | 1700 | LR0.0003 | loss32.1273 | gradNorm1.0000 | tokenCount3.0 | logitMin-28.2994 | logitMax-8.8922 | memoryGate0.3333 | Training
2025-04-02 06:04:34 | 1800 | LR0.0003 | loss24.1349 | gradNorm1.0000 | tokenCount3.0 | logitMin-23.4431 | logitMax-7.7722 | memoryGate0.3333 | Training
2025-04-02 06:09:28 | 1900 | LR0.0003 | loss26.2814 | gradNorm1.0000 | tokenCount3.0 | logitMin-25.0654 | logitMax-10.2525 | memoryGate0.3333 | Training
2025-04-02 06:14:21 | 2000 | LR0.0003 | loss24.8611 | gradNorm0.9999 | tokenCount3.0 | logitMin-20.6699 | logitMax-7.3159 | memoryGate0.3333 | Training
2025-04-02 06:19:20 | 2100 | LR0.0003 | loss25.2550 | gradNorm0.9999 | tokenCount3.0 | logitMin-20.4832 | logitMax-5.8103 | memoryGate0.3333 | Training
2025-04-02 06:24:14 | 2200 | LR0.0003 | loss26.9659 | gradNorm1.0000 | tokenCount3.0 | logitMin-19.2803 | logitMax-3.9159 | memoryGate0.3333 | Training
2025-04-02 06:29:07 | 2300 | LR0.0003 | loss26.1085 | gradNorm1.0000 | tokenCount3.0 | logitMin-18.7649 | logitMax-4.5853 | memoryGate0.3333 | Training
2025-04-02 06:33:58 | 2400 | LR0.0003 | loss24.5023 | gradNorm1.0000 | tokenCount3.0 | logitMin-21.0527 | logitMax-7.2450 | memoryGate0.3333 | Training
2025-04-02 06:38:51 | 2500 | LR0.0003 | loss28.5959 | gradNorm0.9999 | tokenCount3.0 | logitMin-24.5955 | logitMax-8.8068 | memoryGate0.3333 | Training
2025-04-02 06:43:42 | 2600 | LR0.0003 | loss30.5000 | gradNorm0.9999 | tokenCount3.0 | logitMin-19.9259 | logitMax-0.6457 | memoryGate0.3333 | Training
2025-04-02 06:48:35 | 2700 | LR0.0003 | loss27.7630 | gradNorm0.9999 | tokenCount3.0 | logitMin-18.1472 | logitMax-2.1517 | memoryGate0.3333 | Training
2025-04-02 06:53:32 | 2800 | LR0.0003 | loss30.8653 | gradNorm1.0000 | tokenCount3.0 | logitMin-17.2203 | logitMax3.4812 | memoryGate0.3333 | Training
2025-04-02 06:58:24 | 2900 | LR0.0003 | loss28.4056 | gradNorm1.0000 | tokenCount3.0 | logitMin-19.2494 | logitMax0.0298 | memoryGate0.3333 | Training
2025-04-02 07:03:17 | 3000 | LR0.0003 | loss25.1860 | gradNorm0.9999 | tokenCount3.0 | logitMin-19.9504 | logitMax-4.9941 | memoryGate0.3333 | Training
2025-04-02 07:08:09 | 3100 | LR0.0003 | loss33.0946 | gradNorm1.0000 | tokenCount3.0 | logitMin-24.7353 | logitMax-4.4880 | memoryGate0.3333 | Training
2025-04-02 07:13:02 | 3200 | LR0.0003 | loss26.9275 | gradNorm1.0000 | tokenCount3.0 | logitMin-27.3397 | logitMax-9.1241 | memoryGate0.3333 | Training
2025-04-02 07:17:59 | 3300 | LR0.0003 | loss49.2677 | gradNorm0.9999 | tokenCount3.0 | logitMin-21.2850 | logitMax4.0981 | memoryGate0.3333 | Training
2025-04-02 07:22:55 | 3400 | LR0.0003 | loss52.9276 | gradNorm1.0000 | tokenCount3.0 | logitMin-24.9580 | logitMax4.2953 | memoryGate0.3333 | Training
2025-04-02 07:27:47 | 3500 | LR0.0003 | loss40.0136 | gradNorm1.0000 | tokenCount3.0 | logitMin-19.0284 | logitMax0.8158 | memoryGate0.3333 | Training
2025-04-02 07:32:38 | 3600 | LR0.0003 | loss41.2186 | gradNorm0.9999 | tokenCount3.0 | logitMin-20.2861 | logitMax-0.3321 | memoryGate0.3333 | Training
2025-04-02 07:37:30 | 3700 | LR0.0003 | loss37.6515 | gradNorm1.0000 | tokenCount3.0 | logitMin-21.7418 | logitMax-2.4607 | memoryGate0.3333 | Training
2025-04-02 07:42:20 | 3800 | LR0.0003 | loss32.0663 | gradNorm1.0000 | tokenCount3.0 | logitMin-15.8720 | logitMax2.2557 | memoryGate0.3333 | Training
2025-04-02 07:47:10 | 3900 | LR0.0003 | loss31.0856 | gradNorm1.0000 | tokenCount3.0 | logitMin-16.4971 | logitMax4.3161 | memoryGate0.3333 | Training
2025-04-02 07:52:02 | 4000 | LR0.0003 | loss28.8359 | gradNorm1.0000 | tokenCount3.0 | logitMin-14.2454 | logitMax6.2164 | memoryGate0.3333 | Training
2025-04-02 07:56:56 | 4100 | LR0.0003 | loss18.7677 | gradNorm1.0000 | tokenCount3.0 | logitMin-12.2116 | logitMax10.6381 | memoryGate0.3333 | Training
2025-04-02 08:01:48 | 4200 | LR0.0003 | loss34.5527 | gradNorm0.9999 | tokenCount3.0 | logitMin-19.1912 | logitMax3.6711 | memoryGate0.3333 | Training
2025-04-02 08:06:39 | 4300 | LR0.0003 | loss30.2725 | gradNorm0.9999 | tokenCount3.0 | logitMin-22.5454 | logitMax-3.1799 | memoryGate0.3333 | Training
2025-04-02 08:11:32 | 4400 | LR0.0003 | loss28.4477 | gradNorm0.9999 | tokenCount3.0 | logitMin-24.9563 | logitMax-7.4761 | memoryGate0.3333 | Training
2025-04-02 08:16:29 | 4500 | LR0.0003 | loss30.1698 | gradNorm0.9999 | tokenCount3.0 | logitMin-22.5627 | logitMax-4.1820 | memoryGate0.3333 | Training
2025-04-02 08:21:22 | 4600 | LR0.0003 | loss32.8699 | gradNorm1.0000 | tokenCount3.0 | logitMin-18.2071 | logitMax1.4194 | memoryGate0.3333 | Training
2025-04-02 08:26:17 | 4700 | LR0.0003 | loss28.9808 | gradNorm0.9999 | tokenCount3.0 | logitMin-25.7856 | logitMax-11.2774 | memoryGate0.3333 | Training
2025-04-02 08:31:10 | 4800 | LR0.0003 | loss36.1228 | gradNorm1.0000 | tokenCount3.0 | logitMin-23.8461 | logitMax-3.5215 | memoryGate0.3333 | Training
2025-04-02 08:36:02 | 4900 | LR0.0003 | loss26.5568 | gradNorm0.9999 | tokenCount3.0 | logitMin-20.8709 | logitMax-5.7741 | memoryGate0.3333 | Training
2025-04-02 08:40:52 | 5000 | LR0.0003 | loss23.8312 | gradNorm0.9999 | tokenCount3.0 | logitMin-19.4318 | logitMax-5.1191 | memoryGate0.3333 | Training
2025-04-02 08:45:42 | 5100 | LR0.0003 | loss26.2476 | gradNorm1.0000 | tokenCount3.0 | logitMin-23.4676 | logitMax-6.3193 | memoryGate0.3333 | Training
2025-04-02 08:50:34 | 5200 | LR0.0003 | loss26.1892 | gradNorm0.9999 | tokenCount3.0 | logitMin-22.2842 | logitMax-8.6182 | memoryGate0.3334 | Training
2025-04-02 08:55:53 | 5300 | LR0.0003 | loss27.8197 | gradNorm1.0000 | tokenCount3.0 | logitMin-22.2379 | logitMax-6.2958 | memoryGate0.3333 | Training
2025-04-02 09:00:42 | 5400 | LR0.0003 | loss31.1808 | gradNorm1.0000 | tokenCount3.0 | logitMin-20.9656 | logitMax-1.9329 | memoryGate0.3333 | Training
2025-04-02 09:05:32 | 5500 | LR0.0003 | loss33.4572 | gradNorm0.9999 | tokenCount3.0 | logitMin-26.9066 | logitMax-5.5311 | memoryGate0.3333 | Training
2025-04-02 09:10:23 | 5600 | LR0.0003 | loss28.5768 | gradNorm1.0000 | tokenCount3.0 | logitMin-24.5477 | logitMax-4.5222 | memoryGate0.3333 | Training
2025-04-02 09:15:16 | 5700 | LR0.0003 | loss20.2162 | gradNorm0.9999 | tokenCount3.0 | logitMin-29.4665 | logitMax-6.2941 | memoryGate0.3333 | Training
2025-04-02 09:20:11 | 5800 | LR0.0003 | loss38.2777 | gradNorm0.9999 | tokenCount3.0 | logitMin-34.6836 | logitMax-6.0883 | memoryGate0.3333 | Training
2025-04-02 09:25:07 | 5900 | LR0.0003 | loss54.9682 | gradNorm1.0000 | tokenCount3.0 | logitMin-36.0156 | logitMax-0.9154 | memoryGate0.3333 | Training
2025-04-02 09:30:01 | 6000 | LR0.0003 | loss39.4177 | gradNorm0.9999 | tokenCount3.0 | logitMin-34.4828 | logitMax-9.5998 | memoryGate0.3333 | Training
2025-04-02 09:34:54 | 6100 | LR0.0003 | loss24.9767 | gradNorm1.0000 | tokenCount3.0 | logitMin-29.1852 | logitMax-14.9682 | memoryGate0.3333 | Training
2025-04-02 09:39:46 | 6200 | LR0.0003 | loss32.3394 | gradNorm0.9999 | tokenCount3.0 | logitMin-28.4000 | logitMax-9.2669 | memoryGate0.3333 | Training
2025-04-02 09:44:40 | 6300 | LR0.0003 | loss38.2537 | gradNorm1.0000 | tokenCount3.0 | logitMin-32.5262 | logitMax-7.9790 | memoryGate0.3333 | Training
2025-04-02 09:49:31 | 6400 | LR0.0003 | loss48.3011 | gradNorm1.0000 | tokenCount3.0 | logitMin-32.2160 | logitMax-3.3383 | memoryGate0.3333 | Training
2025-04-02 09:54:25 | 6500 | LR0.0003 | loss31.5808 | gradNorm1.0000 | tokenCount3.0 | logitMin-24.9159 | logitMax-6.1544 | memoryGate0.3333 | Training
2025-04-02 09:59:22 | 6600 | LR0.0003 | loss37.3110 | gradNorm1.0000 | tokenCount3.0 | logitMin-28.0953 | logitMax-6.9504 | memoryGate0.3333 | Training
2025-04-02 10:04:14 | 6700 | LR0.0003 | loss30.2128 | gradNorm1.0000 | tokenCount3.0 | logitMin-24.9094 | logitMax-5.6717 | memoryGate0.3333 | Training
2025-04-02 10:09:08 | 6800 | LR0.0003 | loss30.1280 | gradNorm1.0000 | tokenCount3.0 | logitMin-29.7744 | logitMax-9.8569 | memoryGate0.3333 | Training
2025-04-02 10:14:02 | 6900 | LR0.0003 | loss32.1657 | gradNorm1.0000 | tokenCount3.0 | logitMin-32.8173 | logitMax-12.1003 | memoryGate0.3333 | Training
2025-04-02 10:19:00 | 7000 | LR0.0003 | loss27.8345 | gradNorm0.9999 | tokenCount3.0 | logitMin-26.2252 | logitMax-10.7721 | memoryGate0.3333 | Training
2025-04-02 10:23:53 | 7100 | LR0.0003 | loss31.0847 | gradNorm0.9999 | tokenCount3.0 | logitMin-35.2084 | logitMax-13.4749 | memoryGate0.3333 | Training
2025-04-02 10:28:54 | 7200 | LR0.0003 | loss26.6307 | gradNorm0.9999 | tokenCount3.0 | logitMin-28.1768 | logitMax-10.5836 | memoryGate0.3332 | Training
2025-04-02 10:33:48 | 7300 | LR0.0003 | loss31.2557 | gradNorm1.0000 | tokenCount3.0 | logitMin-37.7805 | logitMax-14.1681 | memoryGate0.3333 | Training
2025-04-02 10:38:40 | 7400 | LR0.0003 | loss27.0717 | gradNorm1.0000 | tokenCount3.0 | logitMin-34.6209 | logitMax-13.2031 | memoryGate0.3333 | Training
2025-04-02 10:43:31 | 7500 | LR0.0003 | loss30.3904 | gradNorm0.9999 | tokenCount3.0 | logitMin-30.3739 | logitMax-10.1978 | memoryGate0.3333 | Training
2025-04-02 10:48:24 | 7600 | LR0.0003 | loss41.4674 | gradNorm0.9999 | tokenCount3.0 | logitMin-30.6303 | logitMax-3.8189 | memoryGate0.3333 | Training
2025-04-02 10:53:30 | 7700 | LR0.0003 | loss30.2063 | gradNorm0.9999 | tokenCount3.0 | logitMin-27.0524 | logitMax-9.4946 | memoryGate0.3333 | Training
2025-04-02 10:58:44 | 7800 | LR0.0003 | loss31.9361 | gradNorm1.0000 | tokenCount3.0 | logitMin-29.7563 | logitMax-6.1553 | memoryGate0.3333 | Training
2025-04-02 11:04:54 | 7900 | LR0.0003 | loss28.6506 | gradNorm0.9999 | tokenCount3.0 | logitMin-26.3989 | logitMax-6.0112 | memoryGate0.3333 | Training
2025-04-02 11:10:21 | 8000 | LR0.0003 | loss25.2841 | gradNorm0.9999 | tokenCount3.0 | logitMin-29.9872 | logitMax-12.2330 | memoryGate0.3333 | Training
2025-04-02 11:15:56 | 8100 | LR0.0003 | loss29.6044 | gradNorm1.0000 | tokenCount3.0 | logitMin-27.7855 | logitMax-7.5577 | memoryGate0.3333 | Training
2025-04-02 11:21:32 | 8200 | LR0.0003 | loss28.8768 | gradNorm0.9999 | tokenCount3.0 | logitMin-30.6589 | logitMax-7.3215 | memoryGate0.3333 | Training
2025-04-02 11:27:31 | 8300 | LR0.0003 | loss42.2687 | gradNorm0.9999 | tokenCount3.0 | logitMin-36.1676 | logitMax-9.2567 | memoryGate0.3334 | Training
2025-04-02 11:33:20 | 8400 | LR0.0003 | loss21.4004 | gradNorm0.9999 | tokenCount3.0 | logitMin-27.4128 | logitMax-8.0796 | memoryGate0.3333 | Training
2025-04-02 11:39:07 | 8500 | LR0.0003 | loss26.5102 | gradNorm0.9999 | tokenCount3.0 | logitMin-28.4151 | logitMax-11.4730 | memoryGate0.3332 | Training
2025-04-02 11:44:35 | 8600 | LR0.0003 | loss21.4747 | gradNorm0.9109 | tokenCount3.0 | logitMin-55.8618 | logitMax3.8275 | memoryGate0.3333 | Training
2025-04-02 11:50:13 | 8700 | LR0.0003 | loss31.9349 | gradNorm0.9999 | tokenCount3.0 | logitMin-39.0793 | logitMax1.5850 | memoryGate0.3333 | Training
2025-04-02 11:56:44 | 8800 | LR0.0003 | loss30.2052 | gradNorm1.0000 | tokenCount3.0 | logitMin-31.0824 | logitMax-9.9713 | memoryGate0.3333 | Training
2025-04-02 12:03:58 | 8900 | LR0.0003 | loss28.3305 | gradNorm1.0000 | tokenCount3.0 | logitMin-30.5172 | logitMax-12.1844 | memoryGate0.3333 | Training
2025-04-02 12:09:48 | 9000 | LR0.0003 | loss33.6822 | gradNorm1.0000 | tokenCount3.0 | logitMin-37.0779 | logitMax-14.1064 | memoryGate0.3333 | Training
2025-04-02 12:15:20 | 9100 | LR0.0003 | loss28.4825 | gradNorm0.9999 | tokenCount3.0 | logitMin-27.2189 | logitMax-10.7074 | memoryGate0.3333 | Training
2025-04-02 12:20:50 | 9200 | LR0.0003 | loss27.3044 | gradNorm0.9999 | tokenCount3.0 | logitMin-31.3636 | logitMax-11.2309 | memoryGate0.3333 | Training
2025-04-02 12:26:35 | 9300 | LR0.0003 | loss25.1722 | gradNorm0.9999 | tokenCount3.0 | logitMin-33.3253 | logitMax-14.4612 | memoryGate0.3333 | Training
2025-04-02 12:32:09 | 9400 | LR0.0003 | loss29.9556 | gradNorm0.9999 | tokenCount3.0 | logitMin-36.3245 | logitMax-15.5950 | memoryGate0.3333 | Training
2025-04-02 12:37:42 | 9500 | LR0.0003 | loss32.7386 | gradNorm1.0000 | tokenCount3.0 | logitMin-31.9551 | logitMax-8.6290 | memoryGate0.3333 | Training
2025-04-02 12:43:09 | 9600 | LR0.0003 | loss30.1130 | gradNorm1.0000 | tokenCount3.0 | logitMin-31.0111 | logitMax-7.8808 | memoryGate0.3333 | Training
2025-04-02 12:48:39 | 9700 | LR0.0003 | loss31.6204 | gradNorm0.9999 | tokenCount3.0 | logitMin-28.7942 | logitMax-8.7499 | memoryGate0.3333 | Training
2025-04-02 12:54:09 | 9800 | LR0.0003 | loss28.4266 | gradNorm1.0000 | tokenCount3.0 | logitMin-25.1157 | logitMax-8.0799 | memoryGate0.3333 | Training
2025-04-02 13:00:17 | 9900 | LR0.0003 | loss27.4797 | gradNorm0.9999 | tokenCount3.0 | logitMin-27.8735 | logitMax-10.2587 | memoryGate0.3333 | Training
2025-04-02 13:06:30 | 10000 | LR0.0003 | loss30.7693 | gradNorm0.9999 | tokenCount3.0 | logitMin-31.3133 | logitMax-10.2030 | memoryGate0.3333 | Training
