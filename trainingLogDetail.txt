--- 2025-03-15 02:24:28 ---
2025-03-15 02:29:39 | Context: [[3, 5, 7, 9, 11]] | LR: 0.00005 | Step 100 | Avg Loss: 25.2998
2025-03-15 02:35:00 | Context: [[3, 5, 7, 9, 11]] | LR: 0.00005 | Step 200 | Avg Loss: 25.5011
2025-03-15 02:40:19 | Context: [[3, 5, 7, 9, 11]] | LR: 0.00005 | Step 300 | Avg Loss: 23.9552
2025-03-15 02:45:43 | Context: [[3, 5, 7, 9, 11]] | LR: 0.00005 | Step 400 | Avg Loss: 29.1021

--- 2025-03-15 02:47:10 ---
2025-03-15 02:52:42 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 100 | Avg Loss: 26.0054
2025-03-15 02:58:26 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 200 | Avg Loss: 24.4129
2025-03-15 03:04:05 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 300 | Avg Loss: 28.1631
2025-03-15 03:09:47 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 400 | Avg Loss: 31.1546
2025-03-15 03:15:33 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 500 | Avg Loss: 28.4702
2025-03-15 03:21:17 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 600 | Avg Loss: 28.0436
2025-03-15 03:26:59 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 700 | Avg Loss: 26.2134
2025-03-15 03:32:37 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 800 | Avg Loss: 31.1412
2025-03-15 03:38:19 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 900 | Avg Loss: 27.8323
2025-03-15 03:44:00 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1000 | Avg Loss: 24.9488
2025-03-15 03:49:48 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1100 | Avg Loss: 28.5189
2025-03-15 03:55:38 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1200 | Avg Loss: 28.9171
2025-03-15 04:01:23 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1300 | Avg Loss: 29.6624
2025-03-15 04:07:04 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1400 | Avg Loss: 31.8279
2025-03-15 04:12:50 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1500 | Avg Loss: 31.0177
2025-03-15 04:18:43 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1600 | Avg Loss: 26.1206
2025-03-15 04:24:32 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1700 | Avg Loss: 27.8529
2025-03-15 04:30:22 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1800 | Avg Loss: 30.6420
2025-03-15 04:36:08 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1900 | Avg Loss: 29.5534
2025-03-15 04:41:51 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 2000 | Avg Loss: 27.6393

--- 2025-03-15 04:49:48 ---
2025-03-15 04:55:25 | Context: [[2, 4, 7, 7, 12]] | LR: 0.00030 | Step 100 | Avg Loss: 77.4762

--- 2025-03-15 04:56:28 ---
2025-03-15 05:02:03 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00030 | Step 100 | Avg Loss: 66.8302
2025-03-15 05:07:41 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00030 | Step 200 | Avg Loss: 148.5852

--- 2025-03-15 05:11:05 ---
2025-03-15 05:16:40 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00030 | Step 100 | Avg Loss: 115.5158

--- 2025-03-15 05:17:03 ---
2025-03-15 05:22:43 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00010 | Step 100 | Avg Loss: 77.8784
2025-03-15 05:28:31 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00010 | Step 200 | Avg Loss: 50.7676

--- 2025-03-15 05:29:17 ---

--- 2025-03-15 05:30:10 ---
2025-03-15 05:35:46 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00010 | Step 100 | Avg Loss: 39.5901
2025-03-15 05:41:28 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00010 | Step 200 | Avg Loss: 47.8724

--- 2025-03-15 05:42:34 ---
2025-03-15 05:48:10 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00010 | Step 100 | Avg Loss: 29.2407

--- 2025-03-15 05:51:51 ---
2025-03-15 05:57:26 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00010 | Step 100 | Avg Loss: 104.4668

--- 2025-03-15 05:57:55 ---

--- 2025-03-15 06:01:10 ---
2025-03-15 06:06:45 | Context: [[3, 5, 7, 10, 12]] | LR: 0.00010 | Step 100 | Avg Loss: 29.7282

--- 2025-03-15 06:07:14 ---
2025-03-15 06:12:55 | Context: [[3, 5, 7, 10, 12]] | LR: 0.00010 | Step 100 | Avg Loss: 46.7204

--- 2025-03-15 06:13:45 ---

--- 2025-03-15 06:57:36 ---
2025-03-15 07:05:07 | Context: [[7, 3, 10, 13, 15]] | LR: 0.00010 | Step 100 | Avg Loss: 86.4620

--- 2025-03-15 07:06:54 ---

--- 2025-03-15 07:10:56 ---
2025-03-15 07:17:46 | Context: [[7, 3, 7, 10, 13]] | LR: 0.00010 | Step 100 | Avg Loss: 140.1534

--- 2025-03-15 07:18:18 ---

--- 2025-03-15 07:18:42 ---
2025-03-15 07:25:09 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00010 | Step 100 | Avg Loss: 48.6443

--- 2025-03-15 07:25:58 ---

--- 2025-03-15 07:26:55 ---

--- 2025-03-15 07:31:55 ---
2025-03-15 07:38:23 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 109.2312
2025-03-15 07:45:16 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 200 | Avg Loss: 69.8390
2025-03-15 07:52:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 300 | Avg Loss: 84.9747
2025-03-15 07:59:04 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 400 | Avg Loss: 112.7125

--- 2025-03-15 08:24:14 ---

--- 2025-03-15 08:27:40 ---

--- 2025-03-15 08:28:41 ---
2025-03-15 08:34:52 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 246.5380
2025-03-15 08:41:40 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 200 | Avg Loss: 128.0534
2025-03-15 08:48:15 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 300 | Avg Loss: 122.6352
2025-03-15 08:54:14 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 400 | Avg Loss: 100.5878
2025-03-15 09:00:16 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 500 | Avg Loss: 220.3655
2025-03-15 09:06:20 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 600 | Avg Loss: 200.4332
2025-03-15 09:12:22 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 700 | Avg Loss: 187.5774
2025-03-15 09:18:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 800 | Avg Loss: 176.3647
2025-03-15 09:24:31 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 900 | Avg Loss: 173.5481
2025-03-15 09:30:33 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1000 | Avg Loss: 196.0468
2025-03-15 09:36:36 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1100 | Avg Loss: 187.1669
2025-03-15 09:42:44 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1200 | Avg Loss: 178.8575
2025-03-15 09:48:49 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1300 | Avg Loss: 177.5162
2025-03-15 09:54:55 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1400 | Avg Loss: 167.8484
2025-03-15 10:01:01 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1500 | Avg Loss: 218.6308
2025-03-15 10:07:05 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1600 | Avg Loss: 154.3260
2025-03-15 10:13:12 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1700 | Avg Loss: 147.1482
2025-03-15 10:19:19 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1800 | Avg Loss: 134.2065
2025-03-15 10:25:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1900 | Avg Loss: 134.6512
2025-03-15 10:31:31 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2000 | Avg Loss: 162.2315
2025-03-15 10:37:37 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2100 | Avg Loss: 131.4008
2025-03-15 10:43:46 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2200 | Avg Loss: 148.0430
2025-03-15 10:49:46 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2300 | Avg Loss: 126.7081
2025-03-15 10:55:48 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2400 | Avg Loss: 133.0843
2025-03-15 11:01:51 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2500 | Avg Loss: 140.3406
2025-03-15 11:07:55 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2600 | Avg Loss: 131.1765
2025-03-15 11:14:05 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2700 | Avg Loss: 129.3430
2025-03-15 11:20:14 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2800 | Avg Loss: 97.8129
2025-03-15 11:26:20 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2900 | Avg Loss: 135.7963
2025-03-15 11:32:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3000 | Avg Loss: 88.9440
2025-03-15 11:38:31 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3100 | Avg Loss: 111.3219
2025-03-15 11:44:37 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3200 | Avg Loss: 110.6982
2025-03-15 11:50:44 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3300 | Avg Loss: 117.2204
2025-03-15 11:56:48 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3400 | Avg Loss: 123.5096
2025-03-15 12:02:54 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3500 | Avg Loss: 99.7319
2025-03-15 12:08:58 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3600 | Avg Loss: 114.9261
2025-03-15 12:15:01 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3700 | Avg Loss: 111.0956
2025-03-15 12:21:11 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3800 | Avg Loss: 91.0441
2025-03-15 12:27:16 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3900 | Avg Loss: 118.3144
2025-03-15 12:33:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4000 | Avg Loss: 122.6783
2025-03-15 12:39:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4100 | Avg Loss: 93.2427
2025-03-15 12:45:31 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4200 | Avg Loss: 107.3375
2025-03-15 12:51:36 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4300 | Avg Loss: 114.5238
2025-03-15 12:57:42 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4400 | Avg Loss: 95.8251
2025-03-15 13:03:50 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4500 | Avg Loss: 108.2282
2025-03-15 13:09:55 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4600 | Avg Loss: 82.6846
2025-03-15 13:15:57 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4700 | Avg Loss: 114.3864
2025-03-15 13:22:05 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4800 | Avg Loss: 86.5105
2025-03-15 13:28:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4900 | Avg Loss: 121.5874
2025-03-15 13:34:20 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5000 | Avg Loss: 87.5749
2025-03-15 13:40:27 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5100 | Avg Loss: 175.1104
2025-03-15 13:46:32 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5200 | Avg Loss: 136.4255
2025-03-15 13:52:37 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5300 | Avg Loss: 75.8046
2025-03-15 13:58:45 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5400 | Avg Loss: 88.9204
2025-03-15 14:04:49 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5500 | Avg Loss: 95.2836
2025-03-15 14:10:57 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5600 | Avg Loss: 72.8710
2025-03-15 14:17:03 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5700 | Avg Loss: 78.1028
2025-03-15 14:23:07 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5800 | Avg Loss: 86.8291
2025-03-15 14:29:12 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5900 | Avg Loss: 85.3887
2025-03-15 14:35:17 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6000 | Avg Loss: 73.9537
2025-03-15 14:41:24 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6100 | Avg Loss: 81.1418
2025-03-15 14:47:29 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6200 | Avg Loss: 89.0133
2025-03-15 14:53:37 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6300 | Avg Loss: 79.6786
2025-03-15 14:59:44 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6400 | Avg Loss: 72.8702
2025-03-15 15:05:53 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6500 | Avg Loss: 76.2956
2025-03-15 15:11:57 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6600 | Avg Loss: 97.9542
2025-03-15 15:17:59 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6700 | Avg Loss: 69.9055
2025-03-15 15:24:06 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6800 | Avg Loss: 80.3380
2025-03-15 15:30:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6900 | Avg Loss: 88.7021
2025-03-15 15:36:24 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7000 | Avg Loss: 61.6491
2025-03-15 15:42:47 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7100 | Avg Loss: 97.2115
2025-03-15 15:49:11 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7200 | Avg Loss: 63.4097

--- 2025-03-15 15:50:45 ---
2025-03-15 15:56:40 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 115.8527
2025-03-15 16:02:46 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 200 | Avg Loss: 118.1715
2025-03-15 16:08:48 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 300 | Avg Loss: 111.5543
2025-03-15 16:14:43 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 400 | Avg Loss: 85.2576
2025-03-15 16:20:41 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 500 | Avg Loss: 112.3581
2025-03-15 16:26:40 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 600 | Avg Loss: 115.6110
2025-03-15 16:32:40 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 700 | Avg Loss: 101.3372
2025-03-15 16:38:53 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 800 | Avg Loss: 95.9238
2025-03-15 16:45:09 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 900 | Avg Loss: 97.1094
2025-03-15 16:51:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1000 | Avg Loss: 101.4199
2025-03-15 16:57:25 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1100 | Avg Loss: 91.5585
2025-03-15 17:03:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1200 | Avg Loss: 72.4589
2025-03-15 17:09:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1300 | Avg Loss: 69.8153
2025-03-15 17:15:28 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1400 | Avg Loss: 67.4341
2025-03-15 17:21:37 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1500 | Avg Loss: 84.8699

--- 2025-03-15 17:22:40 ---

--- 2025-03-15 17:26:13 ---
2025-03-15 17:32:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 31.3383
2025-03-15 17:38:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 200 | Avg Loss: 39.3956
2025-03-15 17:44:23 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 300 | Avg Loss: 67.3998
2025-03-15 17:50:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 400 | Avg Loss: 56.0565
2025-03-15 17:56:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 500 | Avg Loss: 99.9979
2025-03-15 18:02:38 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 600 | Avg Loss: 75.8656
2025-03-15 18:08:45 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 700 | Avg Loss: 129.0989
2025-03-15 18:14:44 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 800 | Avg Loss: 83.9430
2025-03-15 18:20:44 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 900 | Avg Loss: 73.0983
2025-03-15 18:26:50 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1000 | Avg Loss: 98.4316
2025-03-15 18:33:07 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1100 | Avg Loss: 64.4048
2025-03-15 18:39:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1200 | Avg Loss: 73.3789
2025-03-15 18:45:41 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1300 | Avg Loss: 102.1722
2025-03-15 18:52:00 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1400 | Avg Loss: 79.0767
2025-03-15 18:58:07 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1500 | Avg Loss: 56.8205
2025-03-15 19:04:09 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1600 | Avg Loss: 55.9097
2025-03-15 19:10:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1700 | Avg Loss: 78.8310
2025-03-15 19:16:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1800 | Avg Loss: 69.5042
2025-03-15 19:22:15 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1900 | Avg Loss: 55.1442
2025-03-15 19:28:18 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2000 | Avg Loss: 85.9705
2025-03-15 19:34:17 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2100 | Avg Loss: 72.7598
2025-03-15 19:40:17 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2200 | Avg Loss: 94.6816
2025-03-15 19:46:25 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2300 | Avg Loss: 64.2222
2025-03-15 19:52:33 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2400 | Avg Loss: 60.1549
2025-03-15 19:58:42 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2500 | Avg Loss: 62.4248
2025-03-15 20:04:53 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2600 | Avg Loss: 103.6482

--- 2025-03-15 20:07:41 ---
2025-03-15 20:13:31 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 36.0646
2025-03-15 20:19:33 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 200 | Avg Loss: 26.3742
2025-03-15 20:25:49 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 300 | Avg Loss: 65.9463
2025-03-15 20:31:56 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 400 | Avg Loss: 65.7200
2025-03-15 20:37:56 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 500 | Avg Loss: 196.0454
2025-03-15 20:43:59 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 600 | Avg Loss: 180.6565
2025-03-15 20:50:00 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 700 | Avg Loss: 166.2669
2025-03-15 20:56:04 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 800 | Avg Loss: 143.7420
2025-03-15 21:02:06 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 900 | Avg Loss: 142.5713
2025-03-15 21:08:10 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1000 | Avg Loss: 154.4563
2025-03-15 21:14:14 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1100 | Avg Loss: 114.4567
2025-03-15 21:20:14 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1200 | Avg Loss: 154.0373
2025-03-15 21:26:19 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1300 | Avg Loss: 123.1501
2025-03-15 21:32:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1400 | Avg Loss: 98.3505
2025-03-15 21:38:23 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1500 | Avg Loss: 104.9495
2025-03-15 21:44:24 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1600 | Avg Loss: 91.2051
2025-03-15 21:50:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1700 | Avg Loss: 108.8672
2025-03-15 21:56:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1800 | Avg Loss: 96.3650
2025-03-15 22:02:27 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1900 | Avg Loss: 163.4714
2025-03-15 22:08:32 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2000 | Avg Loss: 114.7532
2025-03-15 22:14:34 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2100 | Avg Loss: 100.2960
2025-03-15 22:20:40 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2200 | Avg Loss: 121.1595
2025-03-15 22:26:46 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2300 | Avg Loss: 100.0968
2025-03-15 22:32:48 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2400 | Avg Loss: 118.5921
2025-03-15 22:38:52 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2500 | Avg Loss: 97.3297
2025-03-15 22:44:56 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2600 | Avg Loss: 121.1797
2025-03-15 22:50:59 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2700 | Avg Loss: 84.0974
2025-03-15 22:57:01 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2800 | Avg Loss: 123.8064
2025-03-15 23:03:02 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2900 | Avg Loss: 111.8447
2025-03-15 23:09:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3000 | Avg Loss: 60.9404
2025-03-15 23:15:28 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3100 | Avg Loss: 69.8506

--- 2025-03-15 23:19:20 ---

--- 2025-03-15 23:26:46 ---
2025-03-15 23:33:07 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 22.2306

--- 2025-03-15 23:35:03 ---
2025-03-15 23:41:20 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 24.0999
2025-03-15 23:47:55 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 200 | Avg Loss: 30.6750
2025-03-15 23:54:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 300 | Avg Loss: 40.6864
2025-03-16 00:00:54 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 400 | Avg Loss: 61.6676
2025-03-16 00:07:30 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 500 | Avg Loss: 69.6424
2025-03-16 00:14:01 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 600 | Avg Loss: 54.7204
2025-03-16 00:20:22 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 700 | Avg Loss: 75.5601
2025-03-16 00:26:47 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 800 | Avg Loss: 55.6356
2025-03-16 00:33:14 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 900 | Avg Loss: 73.8038
2025-03-16 00:39:45 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1000 | Avg Loss: 46.3641
2025-03-16 00:46:17 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1100 | Avg Loss: 44.0149
2025-03-16 00:52:50 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1200 | Avg Loss: 45.9646
2025-03-16 00:59:27 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1300 | Avg Loss: 58.1323
2025-03-16 01:06:05 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1400 | Avg Loss: 45.5975
2025-03-16 01:12:39 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1500 | Avg Loss: 43.9294
2025-03-16 01:19:18 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1600 | Avg Loss: 42.9883
2025-03-16 01:25:55 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1700 | Avg Loss: 58.1261

--- 2025-03-16 01:28:02 ---
2025-03-16 01:34:24 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 33.5350
2025-03-16 01:40:55 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 200 | Avg Loss: 20.6602
2025-03-16 01:47:28 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 300 | Avg Loss: 35.1610
2025-03-16 01:53:56 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 400 | Avg Loss: 50.1460
2025-03-16 02:00:39 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 500 | Avg Loss: 106.6196
2025-03-16 02:07:12 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 600 | Avg Loss: 112.4661
2025-03-16 02:13:49 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 700 | Avg Loss: 111.3483
2025-03-16 02:20:30 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 800 | Avg Loss: 58.1489
2025-03-16 02:27:01 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 900 | Avg Loss: 84.3945
2025-03-16 02:33:34 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1000 | Avg Loss: 102.5407
2025-03-16 02:40:02 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1100 | Avg Loss: 80.7920
2025-03-16 02:46:41 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1200 | Avg Loss: 86.4024
2025-03-16 02:53:16 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1300 | Avg Loss: 69.4069
2025-03-16 02:59:48 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1400 | Avg Loss: 44.7647
2025-03-16 03:06:20 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1500 | Avg Loss: 68.3722
2025-03-16 03:12:58 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1600 | Avg Loss: 38.1073
2025-03-16 03:19:31 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1700 | Avg Loss: 73.8641
2025-03-16 03:26:09 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1800 | Avg Loss: 60.1812
2025-03-16 03:32:44 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1900 | Avg Loss: 105.1594
2025-03-16 03:39:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2000 | Avg Loss: 84.5493
2025-03-16 03:45:43 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2100 | Avg Loss: 59.3795
2025-03-16 03:52:16 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2200 | Avg Loss: 56.3045
2025-03-16 03:58:50 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2300 | Avg Loss: 55.7493
2025-03-16 04:05:25 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2400 | Avg Loss: 79.6449
2025-03-16 04:11:57 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2500 | Avg Loss: 51.0424
2025-03-16 04:18:25 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2600 | Avg Loss: 70.4421
2025-03-16 04:24:57 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2700 | Avg Loss: 78.3477
2025-03-16 04:31:29 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2800 | Avg Loss: 79.4457
2025-03-16 04:38:00 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2900 | Avg Loss: 93.8174
2025-03-16 04:44:33 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3000 | Avg Loss: 65.5502
2025-03-16 04:51:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3100 | Avg Loss: 64.9889
2025-03-16 04:57:45 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3200 | Avg Loss: 62.5843
2025-03-16 05:04:19 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3300 | Avg Loss: 66.1711
2025-03-16 05:10:51 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3400 | Avg Loss: 82.5766
2025-03-16 05:17:22 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3500 | Avg Loss: 56.9210
2025-03-16 05:23:53 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3600 | Avg Loss: 64.7987
2025-03-16 05:30:23 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3700 | Avg Loss: 52.5492
2025-03-16 05:36:51 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3800 | Avg Loss: 112.4007
2025-03-16 05:43:22 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3900 | Avg Loss: 70.1260
2025-03-16 05:49:56 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4000 | Avg Loss: 59.5052
2025-03-16 05:56:27 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4100 | Avg Loss: 52.7346
2025-03-16 06:03:00 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4200 | Avg Loss: 62.7025
2025-03-16 06:09:33 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4300 | Avg Loss: 97.5762
2025-03-16 06:16:06 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4400 | Avg Loss: 53.8367
2025-03-16 06:22:43 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4500 | Avg Loss: 53.4515
2025-03-16 06:29:16 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4600 | Avg Loss: 55.7380
2025-03-16 06:35:48 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4700 | Avg Loss: 65.0798
2025-03-16 06:42:23 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4800 | Avg Loss: 60.1677
2025-03-16 06:48:56 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4900 | Avg Loss: 90.4631
2025-03-16 06:55:31 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5000 | Avg Loss: 39.8402
2025-03-16 07:02:02 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5100 | Avg Loss: 55.3272
2025-03-16 07:08:33 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5200 | Avg Loss: 199.3606
2025-03-16 07:15:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5300 | Avg Loss: 91.2177
2025-03-16 07:21:46 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5400 | Avg Loss: 54.1649
2025-03-16 07:28:20 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5500 | Avg Loss: 48.1239
2025-03-16 07:34:48 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5600 | Avg Loss: 46.2544
2025-03-16 07:41:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5700 | Avg Loss: 40.6059
2025-03-16 07:47:54 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5800 | Avg Loss: 69.2682
2025-03-16 07:54:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5900 | Avg Loss: 75.3200
2025-03-16 08:01:00 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6000 | Avg Loss: 57.5763
2025-03-16 08:07:29 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6100 | Avg Loss: 96.8410
2025-03-16 08:14:04 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6200 | Avg Loss: 66.3142
2025-03-16 08:20:38 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6300 | Avg Loss: 68.2777
2025-03-16 08:27:15 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6400 | Avg Loss: 58.9544
2025-03-16 08:33:49 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6500 | Avg Loss: 81.5270
2025-03-16 08:40:19 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6600 | Avg Loss: 58.2103
2025-03-16 08:46:54 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6700 | Avg Loss: 50.8214
2025-03-16 08:53:23 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6800 | Avg Loss: 72.0570
2025-03-16 08:59:54 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6900 | Avg Loss: 69.7009
2025-03-16 09:06:27 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7000 | Avg Loss: 42.5143
2025-03-16 09:13:00 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7100 | Avg Loss: 70.5079
2025-03-16 09:19:38 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7200 | Avg Loss: 52.3134
2025-03-16 09:26:22 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7300 | Avg Loss: 58.7032
2025-03-16 09:33:02 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7400 | Avg Loss: 67.8549
2025-03-16 09:39:45 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7500 | Avg Loss: 73.4838
2025-03-16 09:46:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7600 | Avg Loss: 71.7162
2025-03-16 09:53:11 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7700 | Avg Loss: 56.5845
2025-03-16 09:59:52 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7800 | Avg Loss: 52.9866
2025-03-16 10:06:31 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7900 | Avg Loss: 82.8979
2025-03-16 10:13:09 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8000 | Avg Loss: 53.3453
2025-03-16 10:19:39 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8100 | Avg Loss: 45.3820
2025-03-16 10:26:06 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8200 | Avg Loss: 69.7555
2025-03-16 10:32:36 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8300 | Avg Loss: 82.8876
2025-03-16 10:39:12 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8400 | Avg Loss: 149.0091
2025-03-16 10:45:42 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8500 | Avg Loss: 70.2144
2025-03-16 10:52:14 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8600 | Avg Loss: 48.0424
2025-03-16 10:58:40 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8700 | Avg Loss: 48.4944
2025-03-16 11:05:17 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8800 | Avg Loss: 49.6207
2025-03-16 11:11:49 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8900 | Avg Loss: 43.4027
2025-03-16 11:18:33 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9000 | Avg Loss: 61.7206
2025-03-16 11:25:11 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9100 | Avg Loss: 63.1167
2025-03-16 11:31:35 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9200 | Avg Loss: 89.8418
2025-03-16 11:38:05 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9300 | Avg Loss: 58.4709
2025-03-16 11:44:35 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9400 | Avg Loss: 55.3873
2025-03-16 11:51:09 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9500 | Avg Loss: 46.9050
2025-03-16 11:57:46 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9600 | Avg Loss: 41.0728
2025-03-16 12:04:19 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9700 | Avg Loss: 59.3705
2025-03-16 12:10:52 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9800 | Avg Loss: 71.8097
2025-03-16 12:17:22 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9900 | Avg Loss: 46.7708
2025-03-16 12:23:58 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10000 | Avg Loss: 46.2166
2025-03-16 12:30:32 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10100 | Avg Loss: 58.2757
2025-03-16 12:37:06 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10200 | Avg Loss: 54.9861
2025-03-16 12:43:35 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10300 | Avg Loss: 66.2874
2025-03-16 12:50:07 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10400 | Avg Loss: 54.9689
2025-03-16 12:56:45 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10500 | Avg Loss: 54.2804
2025-03-16 13:03:23 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10600 | Avg Loss: 55.6618
2025-03-16 13:09:58 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10700 | Avg Loss: 47.6317
2025-03-16 13:16:25 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10800 | Avg Loss: 62.6010
2025-03-16 13:22:55 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10900 | Avg Loss: 72.9611
2025-03-16 13:29:33 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 11000 | Avg Loss: 57.6824
2025-03-16 13:36:08 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 11100 | Avg Loss: 52.6862
2025-03-16 13:42:40 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 11200 | Avg Loss: 70.6405
2025-03-16 13:49:08 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 11300 | Avg Loss: 42.4853
2025-03-16 13:55:50 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 11400 | Avg Loss: 67.0321
2025-03-16 14:02:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 11500 | Avg Loss: 55.9532
2025-03-16 14:08:49 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 11600 | Avg Loss: 57.3515
2025-03-16 14:15:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 11700 | Avg Loss: 47.1907
2025-03-16 14:21:52 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 11800 | Avg Loss: 72.0933

--- 2025-03-16 14:23:55 ---
2025-03-16 14:30:19 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 22.1896
2025-03-16 14:36:57 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 200 | Avg Loss: 15.5898
2025-03-16 14:43:32 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 300 | Avg Loss: 37.8824
2025-03-16 14:50:04 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 400 | Avg Loss: 47.7168
2025-03-16 14:56:32 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 500 | Avg Loss: 60.4211
2025-03-16 15:02:47 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 600 | Avg Loss: 105.2108
2025-03-16 15:09:15 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 700 | Avg Loss: 89.0301
2025-03-16 15:15:40 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 800 | Avg Loss: 59.9047
2025-03-16 15:22:03 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 900 | Avg Loss: 84.2073
2025-03-16 15:28:23 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1000 | Avg Loss: 86.5089
2025-03-16 15:34:55 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1100 | Avg Loss: 50.9784
2025-03-16 15:41:25 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1200 | Avg Loss: 88.1969
2025-03-16 15:48:03 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1300 | Avg Loss: 65.3012
2025-03-16 15:54:46 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1400 | Avg Loss: 57.0884
2025-03-16 16:01:24 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1500 | Avg Loss: 71.2024

--- 2025-03-16 16:12:02 ---

--- 2025-03-16 16:17:21 ---

--- 2025-03-16 16:19:29 ---

--- 2025-03-16 16:25:54 ---

--- 2025-03-16 16:34:11 ---

--- 2025-03-16 16:35:32 ---

--- 2025-03-16 16:36:50 ---

--- 2025-03-16 16:39:02 ---

--- 2025-03-16 16:40:04 ---

--- 2025-03-16 16:41:28 ---

--- 2025-03-16 16:45:08 ---

--- 2025-03-16 16:45:53 ---

--- 2025-03-16 17:02:28 ---

--- 2025-03-16 17:04:25 ---

--- 2025-03-16 17:06:37 ---
2025-03-16 17:13:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 20.0309
2025-03-16 17:20:17 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 200 | Avg Loss: 18.4499

--- 2025-03-17 00:49:52 ---

--- 2025-03-17 00:54:42 ---

--- 2025-03-17 01:01:08 ---

--- 2025-03-17 01:08:02 ---

--- 2025-03-17 01:13:13 ---

--- 2025-03-17 01:24:42 ---
2025-03-17 01:31:22 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 26715.9554

--- 2025-03-17 01:32:35 ---
2025-03-17 01:39:35 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 19879.6459

--- 2025-03-17 01:56:10 ---

--- 2025-03-17 01:56:55 ---

--- 2025-03-17 02:00:40 ---
2025-03-17 02:10:46 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00020 | Step 100 | Avg Loss: 39498.0762
2025-03-17 02:20:45 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00020 | Step 200 | Avg Loss: 28009.5755
2025-03-17 02:31:02 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00020 | Step 300 | Avg Loss: 25642.2160

--- 2025-03-17 02:37:49 ---
2025-03-17 02:48:05 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00100 | Step 100 | Avg Loss: 28843.6099

--- 2025-03-17 02:48:28 ---
2025-03-17 02:59:04 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00100 | Step 100 | Avg Loss: 25152.5686

--- 2025-03-17 03:00:01 ---
2025-03-17 03:10:07 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 4659.3183
2025-03-17 03:20:01 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 2600.4185
2025-03-17 03:30:11 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 3388.7038
2025-03-17 03:40:42 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 400 | Avg Loss: 4714.7594
2025-03-17 03:51:07 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 500 | Avg Loss: 3797.0653
2025-03-17 04:01:33 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 600 | Avg Loss: 4070.9521
2025-03-17 04:11:55 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 700 | Avg Loss: 3560.0172
2025-03-17 04:22:10 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 800 | Avg Loss: 3523.1642
2025-03-17 04:32:19 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 900 | Avg Loss: 3237.5456
2025-03-17 04:42:26 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1000 | Avg Loss: 2700.2383
2025-03-17 04:52:36 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1100 | Avg Loss: 2131.8759
2025-03-17 05:02:47 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1200 | Avg Loss: 2426.8967
2025-03-17 05:12:52 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1300 | Avg Loss: 2026.6394
2025-03-17 05:23:18 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1400 | Avg Loss: 2753.8994
2025-03-17 05:33:39 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1500 | Avg Loss: 1957.3865
2025-03-17 05:43:33 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1600 | Avg Loss: 2092.1095
2025-03-17 05:53:54 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1700 | Avg Loss: 2320.5258
2025-03-17 06:04:04 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1800 | Avg Loss: 2405.1164
2025-03-17 06:14:17 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1900 | Avg Loss: 2336.4856
2025-03-17 06:24:46 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2000 | Avg Loss: 1925.1590
2025-03-17 06:34:39 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2100 | Avg Loss: 1795.4731
2025-03-17 06:44:40 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2200 | Avg Loss: 1448.7990
2025-03-17 06:55:02 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2300 | Avg Loss: 1934.9342
2025-03-17 07:05:20 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2400 | Avg Loss: 1440.1762
2025-03-17 07:15:46 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2500 | Avg Loss: 1945.8349
2025-03-17 07:25:48 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2600 | Avg Loss: 1362.9692
2025-03-17 07:35:58 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2700 | Avg Loss: 1374.4692
2025-03-17 07:46:14 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2800 | Avg Loss: 1268.6737
2025-03-17 07:56:11 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2900 | Avg Loss: 1408.0841
2025-03-17 08:06:29 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3000 | Avg Loss: 2359.5954
2025-03-17 08:16:37 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3100 | Avg Loss: 1302.0832
2025-03-17 08:26:35 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3200 | Avg Loss: 1378.5651
2025-03-17 08:37:08 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3300 | Avg Loss: 1228.0489
2025-03-17 08:47:22 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3400 | Avg Loss: 1046.3980
2025-03-17 08:57:35 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3500 | Avg Loss: 738.8850
2025-03-17 09:07:36 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3600 | Avg Loss: 754.8634

--- 2025-03-17 21:11:37 ---
2025-03-17 21:21:25 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 901.1271
2025-03-17 21:31:08 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 565.6618
2025-03-17 21:40:48 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 640.2143
2025-03-17 21:51:07 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 400 | Avg Loss: 634.0207
2025-03-17 22:01:02 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 500 | Avg Loss: 716.5188
2025-03-17 22:11:02 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 600 | Avg Loss: 600.3293
2025-03-17 22:21:18 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 700 | Avg Loss: 462.7544
2025-03-17 22:31:20 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 800 | Avg Loss: 618.2580
2025-03-17 22:41:15 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 900 | Avg Loss: 469.7889
2025-03-17 22:51:28 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1000 | Avg Loss: 284.0975
2025-03-17 23:01:23 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1100 | Avg Loss: 357.9351
2025-03-17 23:11:16 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1200 | Avg Loss: 236.3479
2025-03-17 23:21:11 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1300 | Avg Loss: 101.6921
2025-03-17 23:31:15 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1400 | Avg Loss: 115.2247
2025-03-17 23:41:06 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1500 | Avg Loss: 150.5834
2025-03-17 23:51:16 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1600 | Avg Loss: 105.9382
2025-03-18 00:01:37 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1700 | Avg Loss: 85.4690
2025-03-18 00:11:29 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1800 | Avg Loss: 112.1785
2025-03-18 00:21:28 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1900 | Avg Loss: 131.2421
2025-03-18 00:31:41 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2000 | Avg Loss: 129.4005
2025-03-18 00:41:44 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2100 | Avg Loss: 70.1770
2025-03-18 00:51:40 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2200 | Avg Loss: 55.0736
2025-03-18 01:01:44 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2300 | Avg Loss: 61.0497
2025-03-18 01:11:56 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2400 | Avg Loss: 67.3330
2025-03-18 01:21:52 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2500 | Avg Loss: 108.1637
2025-03-18 01:31:55 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2600 | Avg Loss: 38.7703
2025-03-18 01:41:59 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2700 | Avg Loss: 140.6988
2025-03-18 01:51:46 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2800 | Avg Loss: 93.4041
2025-03-18 02:01:34 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2900 | Avg Loss: 113.1885
2025-03-18 02:11:34 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3000 | Avg Loss: 133.0571

--- 2025-03-18 02:12:19 ---
2025-03-18 02:21:48 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 149.6652

--- 2025-03-18 02:30:10 ---
2025-03-18 02:39:36 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 154.4235
2025-03-18 02:49:43 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 120.7164
2025-03-18 02:59:32 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 126.3523
2025-03-18 03:09:18 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 400 | Avg Loss: 74.9091
2025-03-18 03:19:17 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 500 | Avg Loss: 103.2713
2025-03-18 03:28:56 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 600 | Avg Loss: 104.9203
2025-03-18 03:38:32 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 700 | Avg Loss: 83.9783
2025-03-18 03:48:03 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 800 | Avg Loss: 97.7172
2025-03-18 03:57:44 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 900 | Avg Loss: 82.8607
2025-03-18 04:07:30 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1000 | Avg Loss: 58.2282
2025-03-18 04:17:03 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1100 | Avg Loss: 95.5480
2025-03-18 04:26:57 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1200 | Avg Loss: 43.9700
2025-03-18 04:36:33 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1300 | Avg Loss: 86.6372
2025-03-18 04:46:14 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1400 | Avg Loss: 54.8085
2025-03-18 04:56:10 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1500 | Avg Loss: 54.2438
2025-03-18 05:05:50 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1600 | Avg Loss: 56.8252
2025-03-18 05:15:31 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1700 | Avg Loss: 41.0499
2025-03-18 05:25:12 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1800 | Avg Loss: 62.0740
2025-03-18 05:35:06 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1900 | Avg Loss: 43.9846
2025-03-18 05:44:35 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2000 | Avg Loss: 109.8787
2025-03-18 05:54:11 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2100 | Avg Loss: 67.5122
2025-03-18 06:04:06 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2200 | Avg Loss: 65.1549
2025-03-18 06:13:42 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2300 | Avg Loss: 62.6281
2025-03-18 06:23:17 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2400 | Avg Loss: 55.0863
2025-03-18 06:32:55 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2500 | Avg Loss: 77.5686
2025-03-18 06:42:53 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2600 | Avg Loss: 33.7380
2025-03-18 06:52:33 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2700 | Avg Loss: 47.3602
2025-03-18 07:02:14 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2800 | Avg Loss: 49.4234
2025-03-18 07:12:02 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2900 | Avg Loss: 52.8042
2025-03-18 07:21:41 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3000 | Avg Loss: 38.4878
2025-03-18 07:31:18 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3100 | Avg Loss: 40.2493
2025-03-18 07:41:13 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3200 | Avg Loss: 56.8362
2025-03-18 07:50:55 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3300 | Avg Loss: 66.8023
2025-03-18 08:00:30 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3400 | Avg Loss: 92.0449
2025-03-18 08:10:12 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3500 | Avg Loss: 58.0209
2025-03-18 08:20:09 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3600 | Avg Loss: 65.9567
2025-03-18 08:29:48 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3700 | Avg Loss: 36.9712
2025-03-18 08:39:31 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3800 | Avg Loss: 51.2571
2025-03-18 08:49:28 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3900 | Avg Loss: 64.0146
2025-03-18 08:59:04 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4000 | Avg Loss: 57.3879
2025-03-18 09:08:41 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4100 | Avg Loss: 55.2836
2025-03-18 09:18:20 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4200 | Avg Loss: 54.1619
2025-03-18 09:28:15 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4300 | Avg Loss: 38.7133
2025-03-18 09:38:01 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4400 | Avg Loss: 33.4324
2025-03-18 09:47:43 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4500 | Avg Loss: 33.0967
2025-03-18 09:57:40 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4600 | Avg Loss: 71.9773
2025-03-18 10:07:21 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4700 | Avg Loss: 51.4032
2025-03-18 10:17:10 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4800 | Avg Loss: 51.1463
2025-03-18 10:27:07 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4900 | Avg Loss: 66.1633
2025-03-18 10:36:44 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5000 | Avg Loss: 48.8394
2025-03-18 10:46:28 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5100 | Avg Loss: 57.7208
2025-03-18 10:56:07 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5200 | Avg Loss: 62.0558

--- 2025-03-19 02:03:07 ---
2025-03-19 02:13:19 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 74.5730
2025-03-19 02:25:02 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 83.8378
2025-03-19 02:35:03 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 81.5079
2025-03-19 02:45:07 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 400 | Avg Loss: 57.4726
2025-03-19 02:55:52 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 500 | Avg Loss: 77.2571
2025-03-19 03:06:15 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 600 | Avg Loss: 59.9685
2025-03-19 03:16:05 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 700 | Avg Loss: 55.0320
2025-03-19 03:26:00 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 800 | Avg Loss: 67.0601
2025-03-19 03:35:56 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 900 | Avg Loss: 38.5078
2025-03-19 03:45:43 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1000 | Avg Loss: 30.0756
2025-03-19 03:55:32 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1100 | Avg Loss: 31.6567
2025-03-19 04:05:30 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1200 | Avg Loss: 37.8531
2025-03-19 04:15:13 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1300 | Avg Loss: 69.1231
2025-03-19 04:24:53 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1400 | Avg Loss: 43.1881
2025-03-19 04:34:38 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1500 | Avg Loss: 38.1132
2025-03-19 04:44:35 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1600 | Avg Loss: 43.4695
2025-03-19 04:54:17 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1700 | Avg Loss: 27.0129
2025-03-19 05:03:57 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1800 | Avg Loss: 29.5796
2025-03-19 05:13:57 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1900 | Avg Loss: 28.1929
2025-03-19 05:23:43 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2000 | Avg Loss: 30.5807
2025-03-19 05:33:25 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2100 | Avg Loss: 33.3245
2025-03-19 05:43:18 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2200 | Avg Loss: 43.6292
2025-03-19 05:53:15 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2300 | Avg Loss: 37.8051
2025-03-19 06:03:01 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2400 | Avg Loss: 39.3094
2025-03-19 06:12:43 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2500 | Avg Loss: 34.3984
2025-03-19 06:22:45 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2600 | Avg Loss: 33.2379
2025-03-19 06:32:30 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2700 | Avg Loss: 38.8905
2025-03-19 06:42:13 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2800 | Avg Loss: 31.2069
2025-03-19 06:52:13 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2900 | Avg Loss: 32.0529
2025-03-19 07:01:54 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3000 | Avg Loss: 23.3435
2025-03-19 07:11:44 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3100 | Avg Loss: 28.1499
2025-03-19 07:21:24 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3200 | Avg Loss: 28.1517
2025-03-19 07:31:28 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3300 | Avg Loss: 25.8394
2025-03-19 07:41:11 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3400 | Avg Loss: 27.2244
2025-03-19 07:50:55 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3500 | Avg Loss: 31.7479
2025-03-19 08:01:06 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3600 | Avg Loss: 22.4900
2025-03-19 08:10:48 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3700 | Avg Loss: 44.1103
2025-03-19 08:20:37 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3800 | Avg Loss: 49.0557
2025-03-19 08:31:03 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3900 | Avg Loss: 49.7291
2025-03-19 08:40:57 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4000 | Avg Loss: 46.4622
2025-03-19 08:50:42 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4100 | Avg Loss: 28.0462
2025-03-19 09:05:14 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4200 | Avg Loss: 33.3911
2025-03-19 09:14:54 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4300 | Avg Loss: 55.1869
2025-03-19 09:24:45 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4400 | Avg Loss: 29.8771
2025-03-19 09:35:01 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4500 | Avg Loss: 36.6915
2025-03-19 09:44:45 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4600 | Avg Loss: 30.9141
2025-03-19 09:54:36 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4700 | Avg Loss: 32.3652
2025-03-19 10:04:22 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4800 | Avg Loss: 21.0885
2025-03-19 10:15:13 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4900 | Avg Loss: 23.3824
2025-03-19 10:26:09 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5000 | Avg Loss: 43.1567
2025-03-19 10:36:00 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5100 | Avg Loss: 32.7820
2025-03-19 10:46:04 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5200 | Avg Loss: 24.8372
2025-03-19 10:55:47 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5300 | Avg Loss: 46.7594
2025-03-19 11:05:40 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5400 | Avg Loss: 42.2772
2025-03-19 11:15:53 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5500 | Avg Loss: 33.6713
2025-03-19 11:25:44 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5600 | Avg Loss: 26.1423
2025-03-19 11:35:36 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5700 | Avg Loss: 35.1191
2025-03-19 11:45:19 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5800 | Avg Loss: 22.5238
2025-03-19 11:55:29 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5900 | Avg Loss: 31.9580
2025-03-19 12:05:21 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6000 | Avg Loss: 26.9007
2025-03-19 12:15:04 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6100 | Avg Loss: 20.4065
2025-03-19 12:25:07 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6200 | Avg Loss: 20.2842
2025-03-19 12:34:48 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6300 | Avg Loss: 39.1758
2025-03-19 12:44:34 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6400 | Avg Loss: 20.5317

--- 2025-03-19 18:20:41 ---
2025-03-19 18:31:30 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 25.0672
2025-03-19 18:41:54 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 28.1405
2025-03-19 18:52:36 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 21.7400
2025-03-19 19:03:30 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 400 | Avg Loss: 25.9293
2025-03-19 19:14:02 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 500 | Avg Loss: 26.5720
2025-03-19 19:24:27 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 600 | Avg Loss: 22.8456
2025-03-19 19:35:27 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 700 | Avg Loss: 21.2141
2025-03-19 19:45:30 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 800 | Avg Loss: 20.9408
2025-03-19 19:56:02 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 900 | Avg Loss: 15.4001
2025-03-19 20:06:32 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1000 | Avg Loss: 24.6943
2025-03-19 20:17:01 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1100 | Avg Loss: 36.8573
2025-03-19 20:27:05 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1200 | Avg Loss: 28.6266
2025-03-19 20:37:35 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1300 | Avg Loss: 26.8032
2025-03-19 20:48:08 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1400 | Avg Loss: 28.1143
2025-03-19 20:58:20 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1500 | Avg Loss: 30.7547
2025-03-19 21:08:53 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1600 | Avg Loss: 32.3800

--- 2025-03-19 21:16:24 ---
2025-03-19 21:26:53 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 34.4316
2025-03-19 21:37:08 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 63.9691
2025-03-19 21:47:12 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 45.6076
2025-03-19 21:57:10 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 400 | Avg Loss: 46.0532
2025-03-19 22:07:17 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 500 | Avg Loss: 66.5735
2025-03-19 22:17:19 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 600 | Avg Loss: 41.6630
2025-03-19 22:27:20 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 700 | Avg Loss: 40.9412
2025-03-19 22:37:20 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 800 | Avg Loss: 50.1892
2025-03-19 22:47:50 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 900 | Avg Loss: 138.7861
2025-03-19 22:57:58 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1000 | Avg Loss: 125.5280
2025-03-19 23:08:28 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1100 | Avg Loss: 96.5232
2025-03-19 23:19:07 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1200 | Avg Loss: 95.7480
2025-03-19 23:29:39 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1300 | Avg Loss: 38.6874
2025-03-19 23:40:09 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1400 | Avg Loss: 70.2842
2025-03-19 23:50:31 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1500 | Avg Loss: 42.5463
2025-03-20 00:00:32 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1600 | Avg Loss: 73.9961
2025-03-20 00:10:44 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1700 | Avg Loss: 71.5795
2025-03-20 00:20:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1800 | Avg Loss: 47.4253
2025-03-20 00:30:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1900 | Avg Loss: 42.0408
2025-03-20 00:41:01 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2000 | Avg Loss: 61.5672
2025-03-20 00:51:16 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2100 | Avg Loss: 35.5857
2025-03-20 01:01:16 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2200 | Avg Loss: 40.3563
2025-03-20 01:11:22 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2300 | Avg Loss: 52.6408
2025-03-20 01:21:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2400 | Avg Loss: 103.8111
2025-03-20 01:31:58 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2500 | Avg Loss: 64.3269
2025-03-20 01:42:06 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2600 | Avg Loss: 72.5676
2025-03-20 01:52:14 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2700 | Avg Loss: 50.3425
2025-03-20 02:02:16 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2800 | Avg Loss: 46.4722
2025-03-20 02:12:11 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2900 | Avg Loss: 43.6143
2025-03-20 02:22:11 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3000 | Avg Loss: 59.9505
2025-03-20 02:32:18 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3100 | Avg Loss: 69.9928
2025-03-20 02:42:28 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3200 | Avg Loss: 110.4778
2025-03-20 02:52:30 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3300 | Avg Loss: 59.9074
2025-03-20 03:02:36 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3400 | Avg Loss: 69.6411
2025-03-20 03:12:43 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3500 | Avg Loss: 47.4202
2025-03-20 03:22:42 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3600 | Avg Loss: 47.3478
2025-03-20 03:32:42 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3700 | Avg Loss: 69.3206
2025-03-20 03:42:55 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3800 | Avg Loss: 45.9319
2025-03-20 03:52:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3900 | Avg Loss: 52.5073
2025-03-20 04:02:53 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4000 | Avg Loss: 42.5424
2025-03-20 04:13:02 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4100 | Avg Loss: 52.9361
2025-03-20 04:23:02 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4200 | Avg Loss: 89.7111
2025-03-20 04:33:02 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4300 | Avg Loss: 61.8416
2025-03-20 04:43:07 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4400 | Avg Loss: 60.4145
2025-03-20 04:53:13 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4500 | Avg Loss: 62.6083
2025-03-20 05:03:12 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4600 | Avg Loss: 30.2933
2025-03-20 05:13:20 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4700 | Avg Loss: 53.6502
2025-03-20 05:23:30 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4800 | Avg Loss: 84.8726
2025-03-20 05:33:29 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4900 | Avg Loss: 57.6585
2025-03-20 05:43:25 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5000 | Avg Loss: 53.1780
2025-03-20 05:53:50 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5100 | Avg Loss: 63.3396
2025-03-20 06:03:49 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5200 | Avg Loss: 39.8110
2025-03-20 06:13:50 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5300 | Avg Loss: 72.8728
2025-03-20 06:23:58 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5400 | Avg Loss: 43.4957
2025-03-20 06:33:58 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5500 | Avg Loss: 27.1155
2025-03-20 06:44:05 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5600 | Avg Loss: 41.3919
2025-03-20 06:54:18 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5700 | Avg Loss: 32.0334
2025-03-20 07:04:30 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5800 | Avg Loss: 35.8307
2025-03-20 07:14:37 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5900 | Avg Loss: 24.1026
2025-03-20 07:24:46 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6000 | Avg Loss: 31.2008
2025-03-20 07:34:56 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6100 | Avg Loss: 30.7753
2025-03-20 07:44:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6200 | Avg Loss: 34.8577
2025-03-20 07:54:59 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6300 | Avg Loss: 37.4313
2025-03-20 08:05:08 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6400 | Avg Loss: 24.6944
2025-03-20 08:15:12 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6500 | Avg Loss: 22.7344
2025-03-20 08:25:11 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6600 | Avg Loss: 23.8727
2025-03-20 08:35:29 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6700 | Avg Loss: 27.8779
2025-03-20 08:45:37 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6800 | Avg Loss: 24.7429
2025-03-20 08:55:41 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6900 | Avg Loss: 38.8952
2025-03-20 09:05:56 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7000 | Avg Loss: 42.6019
2025-03-20 09:16:02 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7100 | Avg Loss: 27.2461
2025-03-20 09:26:01 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7200 | Avg Loss: 39.1873
2025-03-20 09:36:06 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7300 | Avg Loss: 34.5512
2025-03-20 09:46:12 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7400 | Avg Loss: 29.8121
2025-03-20 09:56:19 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7500 | Avg Loss: 30.1615
2025-03-20 10:06:23 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7600 | Avg Loss: 22.9941
2025-03-20 10:16:31 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7700 | Avg Loss: 30.8956
2025-03-20 10:26:31 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7800 | Avg Loss: 29.0036
2025-03-20 10:36:36 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7900 | Avg Loss: 32.1875
2025-03-20 10:46:47 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8000 | Avg Loss: 30.5606
2025-03-20 10:56:45 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8100 | Avg Loss: 43.1274
2025-03-20 11:07:28 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8200 | Avg Loss: 37.3616
2025-03-20 11:17:48 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8300 | Avg Loss: 26.8993
2025-03-20 11:27:50 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8400 | Avg Loss: 31.5578
2025-03-20 11:38:37 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8500 | Avg Loss: 25.1077
2025-03-20 11:49:01 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8600 | Avg Loss: 24.3554
2025-03-20 11:59:07 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8700 | Avg Loss: 24.5216
2025-03-20 12:09:09 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8800 | Avg Loss: 37.8477
2025-03-20 12:19:17 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8900 | Avg Loss: 25.0435
2025-03-20 12:29:15 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9000 | Avg Loss: 16.9889
2025-03-20 12:39:28 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9100 | Avg Loss: 17.6504
2025-03-20 12:49:46 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9200 | Avg Loss: 23.1947
2025-03-20 12:59:57 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9300 | Avg Loss: 21.9184
2025-03-20 13:10:15 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9400 | Avg Loss: 23.9878
2025-03-20 13:20:53 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9500 | Avg Loss: 17.8185
2025-03-20 13:31:06 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9600 | Avg Loss: 27.8706
2025-03-20 13:41:19 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9700 | Avg Loss: 50.9230
2025-03-20 13:51:32 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9800 | Avg Loss: 26.7889
2025-03-20 14:01:40 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9900 | Avg Loss: 31.3636
2025-03-20 14:12:25 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10000 | Avg Loss: 22.4836
2025-03-20 14:23:26 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10100 | Avg Loss: 32.9215
2025-03-20 14:33:28 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10200 | Avg Loss: 25.4975
2025-03-20 14:43:45 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10300 | Avg Loss: 43.5477
2025-03-20 14:53:40 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10400 | Avg Loss: 24.2899
2025-03-20 15:03:58 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10500 | Avg Loss: 53.5532
2025-03-20 15:14:09 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10600 | Avg Loss: 26.2210
2025-03-20 15:24:24 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10700 | Avg Loss: 21.6207
2025-03-20 15:36:50 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10800 | Avg Loss: 22.5226
2025-03-20 15:51:17 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10900 | Avg Loss: 34.3061
2025-03-20 16:01:30 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11000 | Avg Loss: 43.5743
2025-03-20 16:12:23 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11100 | Avg Loss: 17.5609
2025-03-20 16:22:18 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11200 | Avg Loss: 22.9376
2025-03-20 16:32:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11300 | Avg Loss: 19.6813
2025-03-20 16:42:39 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11400 | Avg Loss: 22.4909
2025-03-20 16:53:11 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11500 | Avg Loss: 28.1832
2025-03-20 17:03:11 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11600 | Avg Loss: 34.4208
2025-03-20 17:13:15 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11700 | Avg Loss: 24.4247
2025-03-20 17:23:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11800 | Avg Loss: 17.3533
2025-03-20 17:33:45 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11900 | Avg Loss: 40.7150
2025-03-20 17:43:48 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12000 | Avg Loss: 28.3397
2025-03-20 17:53:48 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12100 | Avg Loss: 20.5123
2025-03-20 18:05:27 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12200 | Avg Loss: 22.3222
2025-03-20 18:16:52 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12300 | Avg Loss: 30.7943
2025-03-20 18:26:55 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12400 | Avg Loss: 36.8427
2025-03-20 18:37:50 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12500 | Avg Loss: 31.2685
2025-03-20 18:48:23 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12600 | Avg Loss: 18.4582
2025-03-20 18:58:24 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12700 | Avg Loss: 12.8927
2025-03-20 19:08:25 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12800 | Avg Loss: 28.1975
2025-03-20 19:19:12 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12900 | Avg Loss: 20.3522
2025-03-20 19:29:39 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13000 | Avg Loss: 34.1980
2025-03-20 19:40:02 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13100 | Avg Loss: 40.5166
2025-03-20 19:50:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13200 | Avg Loss: 17.8355
2025-03-20 20:00:48 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13300 | Avg Loss: 31.3274
2025-03-20 20:10:57 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13400 | Avg Loss: 20.5631
2025-03-20 20:21:15 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13500 | Avg Loss: 22.9026
2025-03-20 20:31:21 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13600 | Avg Loss: 12.1932
2025-03-20 20:41:20 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13700 | Avg Loss: 15.7096
2025-03-20 20:51:18 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13800 | Avg Loss: 18.8938
2025-03-20 21:01:49 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13900 | Avg Loss: 18.4053
2025-03-20 21:11:56 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14000 | Avg Loss: 18.9796
2025-03-20 21:22:42 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14100 | Avg Loss: 14.3286
2025-03-20 21:33:22 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14200 | Avg Loss: 21.2563
2025-03-20 21:43:18 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14300 | Avg Loss: 23.5806
2025-03-20 21:53:17 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14400 | Avg Loss: 18.3090
2025-03-20 22:04:03 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14500 | Avg Loss: 12.2258
2025-03-20 22:14:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14600 | Avg Loss: 15.3066
2025-03-20 22:24:56 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14700 | Avg Loss: 28.0160
2025-03-20 22:35:19 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14800 | Avg Loss: 12.7965
2025-03-20 22:46:16 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14900 | Avg Loss: 15.9247
2025-03-20 22:56:24 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15000 | Avg Loss: 16.4883
2025-03-20 23:06:42 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15100 | Avg Loss: 23.5458
2025-03-20 23:16:47 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15200 | Avg Loss: 24.8593
2025-03-20 23:26:53 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15300 | Avg Loss: 19.4509
2025-03-20 23:37:21 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15400 | Avg Loss: 15.0845
2025-03-20 23:47:17 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15500 | Avg Loss: 17.2614
2025-03-20 23:57:15 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15600 | Avg Loss: 17.4067
2025-03-21 00:07:46 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15700 | Avg Loss: 17.0702
2025-03-21 00:17:56 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15800 | Avg Loss: 20.5585
2025-03-21 00:28:10 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15900 | Avg Loss: 11.0969
2025-03-21 00:38:52 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16000 | Avg Loss: 30.9558
2025-03-21 00:49:05 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16100 | Avg Loss: 31.3157
2025-03-21 00:59:16 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16200 | Avg Loss: 19.1202
2025-03-21 01:09:27 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16300 | Avg Loss: 26.5424
2025-03-21 01:19:52 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16400 | Avg Loss: 31.2308
2025-03-21 01:29:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16500 | Avg Loss: 25.6780
2025-03-21 01:40:00 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16600 | Avg Loss: 19.7135
2025-03-21 01:50:22 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16700 | Avg Loss: 9.5259
2025-03-21 02:00:33 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16800 | Avg Loss: 19.4574
2025-03-21 02:10:41 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16900 | Avg Loss: 19.0130
2025-03-21 02:21:11 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17000 | Avg Loss: 38.2173
2025-03-21 02:31:11 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17100 | Avg Loss: 19.5197
2025-03-21 02:41:14 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17200 | Avg Loss: 17.5993
2025-03-21 02:51:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17300 | Avg Loss: 28.7814
2025-03-21 03:01:37 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17400 | Avg Loss: 28.8105
2025-03-21 03:11:53 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17500 | Avg Loss: 34.3090
2025-03-21 03:22:07 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17600 | Avg Loss: 52.8057
2025-03-21 03:32:25 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17700 | Avg Loss: 27.9136
2025-03-21 03:42:16 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17800 | Avg Loss: 40.3137
2025-03-21 03:52:20 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17900 | Avg Loss: 32.1854
2025-03-21 04:02:29 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 18000 | Avg Loss: 26.7132
2025-03-21 04:12:32 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 18100 | Avg Loss: 66.7907
2025-03-21 04:22:33 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 18200 | Avg Loss: 23.7316
2025-03-21 04:33:03 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 18300 | Avg Loss: 26.8902
2025-03-21 04:43:33 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 18400 | Avg Loss: 39.9468
2025-03-21 04:53:46 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 18500 | Avg Loss: 17.4035
2025-03-21 05:03:55 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 18600 | Avg Loss: 30.3594

--- 2025-03-21 05:06:44 ---
2025-03-21 05:15:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 18700 | Avg Loss: 36.7542

--- 2025-03-21 05:26:11 ---

--- 2025-03-21 05:32:36 ---

--- 2025-03-21 05:36:05 ---

--- 2025-03-21 05:43:42 ---

--- 2025-03-21 05:47:55 ---

--- 2025-03-21 05:49:28 ---

--- 2025-03-21 05:50:47 ---

--- 2025-03-21 05:52:26 ---

--- 2025-03-21 05:53:35 ---

--- 2025-03-21 05:56:44 ---

--- 2025-03-21 05:58:03 ---

--- 2025-03-21 05:59:10 ---

--- 2025-03-21 05:59:37 ---

--- 2025-03-23 12:49:08 ---

--- 2025-03-23 13:00:33 ---
2025-03-23 13:19:33 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 16.5437
2025-03-23 13:38:01 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 21.9825
2025-03-23 13:56:38 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 25.7907
2025-03-23 14:15:15 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 400 | Avg Loss: 19.0949
2025-03-23 14:33:55 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 500 | Avg Loss: 23.3306
2025-03-23 14:52:28 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 600 | Avg Loss: 22.6316
2025-03-23 15:11:08 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 700 | Avg Loss: 19.2779
2025-03-23 15:29:45 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 800 | Avg Loss: 26.2002
2025-03-23 15:48:37 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 900 | Avg Loss: 14.4576

--- 2025-03-23 17:03:35 ---
2025-03-23 17:31:20 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 15.3141
2025-03-23 17:59:39 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 32.6344
2025-03-23 18:28:12 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 10.6133

--- 2025-03-23 18:44:45 ---
2025-03-23 19:13:12 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 17.5438

--- 2025-03-23 19:15:36 ---

--- 2025-03-23 19:35:41 ---
2025-03-23 20:02:47 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 28.3127
2025-03-23 20:30:33 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 20.0003

--- 2025-03-23 20:43:31 ---

--- 2025-03-23 21:17:03 ---
2025-03-23 21:45:14 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 10.9648
Logits: -163.18  -24.56
Final window weightings: [0.00587413 0.14887016 0.17523532 0.2198666  0.07272907 0.20799461
 0.1617088  0.15256743 0.11650197]
2025-03-23 22:13:33 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 23.0835
Logits: -15.62  19.50
Final window weightings: [0.00655421 0.1495658  0.17678    0.22076482 0.0722838  0.20723154
 0.16101162 0.15127319 0.11561571]
2025-03-23 22:42:17 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 12.3316
Logits: -34.31  0.96
Final window weightings: [0.00666942 0.14930415 0.17641148 0.22099352 0.0722403  0.20719309
 0.1611619  0.15139756 0.11562002]
2025-03-23 23:10:57 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 400 | Avg Loss: 18.2188
Logits: -42.68  2.17
Final window weightings: [0.00661527 0.14927009 0.17626318 0.22100404 0.07197295 0.20717058
 0.16127537 0.15143034 0.11580253]
2025-03-23 23:39:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 500 | Avg Loss: 10.6145
Logits: 4.82  46.12
Final window weightings: [0.006633   0.14915444 0.17620441 0.22090004 0.07207057 0.20718867
 0.16138071 0.15158318 0.11570615]
2025-03-24 00:09:43 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 600 | Avg Loss: 20.1885
Logits: -50.55  -12.71
Final window weightings: [0.00657379 0.14905062 0.17598234 0.22037457 0.07177985 0.20738687
 0.1616183  0.15165867 0.11617613]
2025-03-24 00:39:02 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 700 | Avg Loss: 11.0634
Logits: -15.91  3.39
Final window weightings: [0.00657205 0.14895661 0.17562053 0.2201791  0.07159465 0.20755899
 0.16171005 0.15180418 0.11645833]
2025-03-24 01:07:26 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 800 | Avg Loss: 10.2943
Logits: -50.11  31.40
Final window weightings: [0.0064173  0.14893477 0.17563896 0.22027327 0.07131657 0.20749064
 0.16176474 0.15180829 0.11662783]
2025-03-24 01:35:22 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 900 | Avg Loss: 15.7544
Logits: -21.06  3.12
Final window weightings: [0.00630573 0.14893726 0.17552228 0.22014157 0.07118671 0.20745444
 0.16184847 0.15185407 0.11687316]

--- 2025-03-24 05:07:52 ---
2025-03-24 05:35:40 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 12.9493
Logits: -106.07  -19.45
Final window weightings: [0.00494963 0.14900702 0.17699447 0.2223612  0.06927894 0.20980012
 0.16087162 0.1514838  0.11550581]
2025-03-24 06:03:29 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 13.0966
Logits: -5.68  58.43
Final window weightings: [0.00522512 0.14924592 0.1775434  0.22319347 0.06738267 0.20997916
 0.16094035 0.15118611 0.11511109]
2025-03-24 06:31:17 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 8.7511
Logits: 5.89  50.46
Final window weightings: [0.0052803  0.14927864 0.17747933 0.2228686  0.06709627 0.2096932
 0.16117363 0.15150845 0.11517749]
2025-03-24 06:59:10 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 400 | Avg Loss: 11.5747
Logits: -91.93  -17.81
Final window weightings: [0.00550215 0.14917432 0.1774434  0.2224288  0.06707455 0.20958178
 0.16122088 0.15156813 0.11536548]
2025-03-24 07:27:01 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 500 | Avg Loss: 10.8790
Logits: 28.91  74.19
Final window weightings: [0.00582176 0.14901234 0.17776902 0.22255467 0.06738392 0.20919782
 0.16106209 0.15144938 0.11516104]
2025-03-24 07:54:56 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 600 | Avg Loss: 10.7517
Logits: -47.05  -18.48
Final window weightings: [0.00558324 0.14885712 0.17759168 0.22249423 0.06732014 0.20918304
 0.16135924 0.15175034 0.11520683]
2025-03-24 08:23:26 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 700 | Avg Loss: 8.3344
Logits: -12.28  4.43
Final window weightings: [0.00540004 0.14848757 0.17760338 0.22235382 0.06712542 0.20950358
 0.16142665 0.15193397 0.11538067]
2025-03-24 08:53:03 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 800 | Avg Loss: 9.5944
Logits: -47.17  -18.71
Final window weightings: [0.00563629 0.14845547 0.17728794 0.222187   0.06708297 0.20926487
 0.16155359 0.15214092 0.11543243]
2025-03-24 09:20:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 900 | Avg Loss: 9.0983
Logits: -43.53  -2.05
Final window weightings: [0.00541956 0.14843175 0.17732553 0.22214897 0.06704576 0.20915796
 0.16153376 0.15223886 0.1156981 ]
2025-03-24 09:48:14 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1000 | Avg Loss: 9.5921
Logits: -5.18  30.39
Final window weightings: [0.00527667 0.14834726 0.17709954 0.22188371 0.06689363 0.20937636
 0.1616922  0.15246983 0.11578511]
2025-03-24 10:15:48 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1100 | Avg Loss: 12.6317
Logits: -26.76  -4.12
Final window weightings: [0.00573369 0.14698994 0.17659226 0.22158341 0.06648912 0.2095013
 0.16237715 0.1532057  0.11589809]
2025-03-24 10:43:24 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1200 | Avg Loss: 10.7711
Logits: -25.48  3.23
Final window weightings: [0.00595559 0.14671563 0.17637165 0.22164203 0.06633106 0.20960602
 0.16237931 0.15327735 0.11594409]
2025-03-24 11:10:58 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1300 | Avg Loss: 10.8326
Logits: -15.96  3.45
Final window weightings: [0.00595885 0.14640693 0.17631467 0.22140217 0.06602602 0.20964046
 0.16240148 0.15353352 0.11629452]
2025-03-24 11:38:40 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1400 | Avg Loss: 10.7330
Logits: -31.68  -10.76
Final window weightings: [0.00647327 0.14595598 0.17652941 0.22117326 0.06589054 0.20945443
 0.16220674 0.1536711  0.11636444]
2025-03-24 12:06:33 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1500 | Avg Loss: 10.4466
Logits: -5.37  27.82
Final window weightings: [0.00631188 0.14577918 0.17646037 0.22102553 0.06552102 0.20958206
 0.16238423 0.15388328 0.11655954]
2025-03-24 12:33:57 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1600 | Avg Loss: 14.8318
Logits: -30.89  -12.29
Final window weightings: [0.00589246 0.14532304 0.17634441 0.22086628 0.06486853 0.20987616
 0.16290836 0.1541532  0.11694197]
2025-03-24 13:01:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1700 | Avg Loss: 10.5461
Logits: -28.87  -9.57
Final window weightings: [0.00624915 0.14494626 0.17631853 0.22116205 0.06489747 0.20979246
 0.16279066 0.15408134 0.11684591]
2025-03-24 13:29:38 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1800 | Avg Loss: 12.9000
Logits: -6.07  38.80
Final window weightings: [0.00615174 0.14487687 0.17604277 0.2210085  0.06475566 0.20952621
 0.1628888  0.15451029 0.11709997]
2025-03-24 13:57:22 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1900 | Avg Loss: 12.1511
Logits: 14.81  40.78
Final window weightings: [0.00603081 0.14459541 0.17594288 0.22056697 0.06443141 0.20955077
 0.16319175 0.15482643 0.11737849]
2025-03-24 14:25:14 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2000 | Avg Loss: 9.2805
Logits: -19.82  20.65
Final window weightings: [0.00483644 0.14447205 0.17561541 0.22050051 0.06355041 0.20992297
 0.16369244 0.15577094 0.11785332]
2025-03-24 14:52:43 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2100 | Avg Loss: 11.0758
Logits: -30.08  -4.84
Final window weightings: [0.00578743 0.1439369  0.17599227 0.2205188  0.06412432 0.20922267
 0.1634599  0.15553181 0.1175718 ]
2025-03-24 15:19:48 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2200 | Avg Loss: 10.2527
Logits: 5.98  27.49
Final window weightings: [0.0064269  0.14359145 0.17605746 0.22024408 0.06367751 0.20894618
 0.1634887  0.15556192 0.11772013]
2025-03-24 15:47:12 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2300 | Avg Loss: 10.4990
Logits: -29.15  -6.31
Final window weightings: [0.00657891 0.14321126 0.1760207  0.21980882 0.0632432  0.20881484
 0.16363071 0.15597092 0.11802988]
2025-03-24 16:14:37 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2400 | Avg Loss: 9.4123
Logits: -3.14  28.44
Final window weightings: [0.00687988 0.14247261 0.17582177 0.21986932 0.06344847 0.20871913
 0.16372228 0.1559659  0.11828379]
2025-03-24 16:42:23 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2500 | Avg Loss: 11.0236
Logits: -33.40  -11.09
Final window weightings: [0.00648752 0.14048338 0.17574845 0.22011702 0.06111161 0.20986797
 0.16390795 0.15776387 0.11876359]
2025-03-24 17:09:59 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2600 | Avg Loss: 9.0649
Logits: -24.15  -2.05
Final window weightings: [0.00727702 0.14015983 0.17501895 0.21981537 0.06019729 0.20897599
 0.16473901 0.15824585 0.11914085]
2025-03-24 17:37:03 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2700 | Avg Loss: 13.2261
Logits: -62.22  -23.75
Final window weightings: [0.00660001 0.13985543 0.174954   0.21954142 0.05960995 0.20911239
 0.16522922 0.15879412 0.11952617]
2025-03-24 18:04:35 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2800 | Avg Loss: 10.5417
Logits: -20.56  164.36
Final window weightings: [0.00788399 0.1380275  0.17412846 0.21984062 0.05824669 0.21024707
 0.16540182 0.15989402 0.11867736]
2025-03-24 18:32:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2900 | Avg Loss: 20.6796
Logits: 3.92  63.57
Final window weightings: [0.00565739 0.13387935 0.17387754 0.22181302 0.05477094 0.21106842
 0.16675584 0.16321938 0.11991505]
2025-03-24 19:00:02 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3000 | Avg Loss: 8.8579
Logits: -15.87  14.35
Final window weightings: [0.00614127 0.13422105 0.17375761 0.22230951 0.05572227 0.2110369
 0.16639964 0.16248846 0.11906446]
2025-03-24 19:27:26 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3100 | Avg Loss: 7.6188
Logits: -11.21  18.78
Final window weightings: [0.00647465 0.13561225 0.17356066 0.2208422  0.05523247 0.21110287
 0.16651434 0.16222557 0.11908773]
2025-03-24 19:55:26 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3200 | Avg Loss: 13.1708
Logits: 3.45  27.16
Final window weightings: [0.00973931 0.13521175 0.17302614 0.2210411  0.05629706 0.21063419
 0.16549626 0.16061696 0.11819266]
2025-03-24 20:23:20 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3300 | Avg Loss: 15.5535
Logits: -25.42  2.34
Final window weightings: [0.01055973 0.13491802 0.17284933 0.22103226 0.05549216 0.21211572
 0.16509385 0.15971725 0.11798126]
2025-03-24 20:50:56 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3400 | Avg Loss: 11.0667
Logits: -16.65  -2.97
Final window weightings: [0.01234172 0.13429305 0.17208633 0.22117293 0.0558504  0.21245843
 0.1648248  0.15881507 0.11760382]
2025-03-24 21:18:57 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3500 | Avg Loss: 10.7364
Logits: -13.34  4.20
Final window weightings: [0.01147406 0.1341796  0.17350566 0.22120564 0.05605736 0.21255104
 0.16494106 0.15834893 0.11736597]
2025-03-24 21:48:24 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3600 | Avg Loss: 14.5428
Logits: -19.18  11.75
Final window weightings: [0.01206201 0.13408776 0.17383602 0.2215594  0.05513679 0.2116733
 0.16528313 0.15832597 0.11724098]
2025-03-24 22:16:16 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3700 | Avg Loss: 9.7337
Logits: -18.48  -3.42
Final window weightings: [0.01283602 0.13350657 0.1730774  0.22112791 0.05482052 0.21189146
 0.16534351 0.15848835 0.1176182 ]
2025-03-24 22:43:47 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3800 | Avg Loss: 9.1695
Logits: -14.85  1.31
Final window weightings: [0.01408791 0.13402651 0.17197017 0.21989384 0.05496934 0.21159202
 0.16535772 0.15871434 0.11760189]
2025-03-24 23:11:36 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3900 | Avg Loss: 10.7923
Logits: 6.84  44.70
Final window weightings: [0.01484532 0.13328801 0.17147411 0.22001706 0.05540409 0.21168838
 0.16543777 0.15847747 0.11741423]
2025-03-24 23:39:42 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4000 | Avg Loss: 10.1661
Logits: 0.68  40.75
Final window weightings: [0.01508978 0.13255174 0.17058079 0.21897869 0.05430212 0.21315287
 0.16579753 0.15877317 0.11805566]
2025-03-25 00:06:55 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4100 | Avg Loss: 10.0265
Logits: 51.89  104.18
Final window weightings: [0.01649912 0.13088648 0.16993725 0.2185896  0.05545798 0.21305266
 0.1659658  0.15858272 0.11814095]
2025-03-25 00:34:39 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4200 | Avg Loss: 7.3296
Logits: -3.32  26.57
Final window weightings: [0.01742988 0.13243783 0.16915467 0.21874651 0.0564451  0.2139072
 0.16488975 0.15742743 0.11693929]
2025-03-25 01:02:00 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4300 | Avg Loss: 12.6786
Logits: 19.03  51.12
Final window weightings: [0.01825218 0.13198866 0.16904639 0.21760303 0.05515643 0.21380398
 0.16529088 0.15782498 0.11751318]
2025-03-25 01:29:55 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4400 | Avg Loss: 9.2704
Logits: -11.68  3.09
Final window weightings: [0.01739395 0.13197447 0.17003392 0.21813735 0.05525665 0.21321528
 0.16531613 0.15764871 0.11755234]
2025-03-25 01:57:17 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4500 | Avg Loss: 14.6985
Logits: 19.13  69.78
Final window weightings: [0.01742866 0.13189049 0.16986886 0.21805626 0.05479066 0.21348523
 0.16540061 0.15770558 0.11752968]
2025-03-25 02:25:23 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4600 | Avg Loss: 12.4149
Logits: 48.47  117.60
Final window weightings: [0.01804278 0.13197976 0.16931728 0.21764223 0.05368863 0.21410592
 0.16528848 0.15784986 0.11752775]
2025-03-25 02:52:51 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4700 | Avg Loss: 12.7815
Logits: -124.41  -53.34
Final window weightings: [0.01989812 0.13331439 0.17124565 0.21873306 0.05407597 0.211849
 0.16360167 0.15693673 0.11581335]
2025-03-25 03:20:49 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4800 | Avg Loss: 13.6691
Logits: -44.35  -12.57
Final window weightings: [0.01867038 0.13427055 0.17143154 0.21786858 0.05246955 0.2134603
 0.16357103 0.15673277 0.116374  ]
2025-03-25 03:48:22 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4900 | Avg Loss: 7.5641
Logits: -33.72  -11.56
Final window weightings: [0.0178702  0.13547277 0.17129757 0.21797656 0.04999761 0.2147865
 0.16351123 0.15687089 0.11645892]
2025-03-25 04:16:09 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5000 | Avg Loss: 11.0078
Logits: -17.23  3.66
Final window weightings: [0.01798254 0.13487493 0.16934887 0.21599756 0.05031135 0.21415715
 0.1648607  0.15820913 0.11790013]
2025-03-25 04:43:49 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5100 | Avg Loss: 7.0591
Logits: -38.53  -7.71
Final window weightings: [0.01834144 0.13348097 0.17003231 0.21776186 0.05054204 0.2136667
 0.16526812 0.15761194 0.11698633]
2025-03-25 05:13:02 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5200 | Avg Loss: 12.3182
Logits: -27.80  -6.36
Final window weightings: [0.01920215 0.13324274 0.1689531  0.21745989 0.05124654 0.21493703
 0.16475339 0.15704387 0.11674781]
2025-03-25 05:41:23 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5300 | Avg Loss: 9.5470
Logits: -15.57  9.45
Final window weightings: [0.01862888 0.13150004 0.16681731 0.21748312 0.05182705 0.21453789
 0.16632277 0.15842327 0.11771989]
2025-03-25 06:09:06 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5400 | Avg Loss: 10.4183
Logits: 9.49  54.29
Final window weightings: [0.01850999 0.13135108 0.16682354 0.21735124 0.05237475 0.21410908
 0.16652629 0.15854092 0.11757613]
2025-03-25 06:36:45 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5500 | Avg Loss: 7.9966
Logits: -17.76  2.81
Final window weightings: [0.01856544 0.13052154 0.16693069 0.21691169 0.05081785 0.2137905
 0.1671234  0.15940802 0.11841439]
2025-03-25 07:04:39 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5600 | Avg Loss: 11.4106
Logits: -41.18  -17.65
Final window weightings: [0.01936679 0.13014454 0.16748522 0.21624328 0.05000663 0.21301012
 0.16738968 0.15972446 0.11855024]
2025-03-25 07:32:08 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5700 | Avg Loss: 14.9608
Logits: 27.05  67.51
Final window weightings: [0.01975158 0.13024306 0.16746184 0.21609116 0.05105998 0.21301721
 0.16712105 0.1591758  0.11801489]
2025-03-25 07:59:42 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5800 | Avg Loss: 11.0740
Logits: 17.04  55.81
Final window weightings: [0.01908126 0.13041325 0.16818753 0.21657848 0.0511294  0.21361265
 0.16667101 0.15867883 0.11756518]
2025-03-25 08:27:29 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5900 | Avg Loss: 10.2134
Logits: 9.20  29.25
Final window weightings: [0.02058807 0.12911141 0.16716862 0.21598609 0.05025114 0.21391265
 0.16747575 0.15895104 0.11773187]
2025-03-25 08:54:37 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6000 | Avg Loss: 9.5198
Logits: -22.63  -5.79
Final window weightings: [0.02083565 0.12947638 0.16537148 0.21453753 0.0486146  0.21529475
 0.16834056 0.16010961 0.11760522]
2025-03-25 09:22:03 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6100 | Avg Loss: 10.0877
Logits: 24.81  61.50
Final window weightings: [0.02049829 0.12766819 0.16673033 0.21661344 0.04829605 0.21566786
 0.16794465 0.1595724  0.11708583]
2025-03-25 09:49:35 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6200 | Avg Loss: 8.3640
Logits: 23.12  52.52
Final window weightings: [0.02004001 0.12738255 0.16635655 0.21696146 0.04861305 0.21592511
 0.16828062 0.15962784 0.11679341]
2025-03-25 10:17:08 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6300 | Avg Loss: 8.3524
Logits: 57.25  107.47
Final window weightings: [0.02078349 0.12636594 0.16612813 0.21621193 0.04901408 0.21486507
 0.16861328 0.16022755 0.1174235 ]
2025-03-25 10:44:49 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6400 | Avg Loss: 8.5259
Logits: 50.52  92.72
Final window weightings: [0.02128525 0.12673208 0.16647512 0.21776797 0.04892052 0.21563803
 0.16751255 0.1589395  0.1164773 ]
2025-03-25 11:12:28 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6500 | Avg Loss: 12.1188
Logits: 163.32  260.18
Final window weightings: [0.02083689 0.12640348 0.1672359  0.21915157 0.04865778 0.21748863
 0.1665597  0.15781866 0.11560674]
2025-03-25 11:39:55 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6600 | Avg Loss: 9.5570
Logits: 135.16  217.91
Final window weightings: [0.01956959 0.12511812 0.16745238 0.21940841 0.04860525 0.21911311
 0.1666991  0.15780522 0.1156883 ]
2025-03-25 12:07:57 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6700 | Avg Loss: 12.8199
Logits: 49.54  90.97
Final window weightings: [0.0179908  0.12429766 0.16948631 0.22158831 0.04607037 0.21978892
 0.16662918 0.15743734 0.11517122]
2025-03-25 12:41:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6800 | Avg Loss: 11.1529
Logits: -21.17  19.52
Final window weightings: [0.01943152 0.12450645 0.16975358 0.22164072 0.04649362 0.22106758
 0.16548216 0.15594672 0.11410721]
2025-03-25 13:09:42 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6900 | Avg Loss: 13.3489
Logits: -51.54  -22.28
Final window weightings: [0.01761474 0.12310176 0.17056349 0.22390544 0.04601138 0.22208625
 0.16498081 0.15598631 0.11424444]
2025-03-25 13:37:53 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7000 | Avg Loss: 9.6633
Logits: -0.50  48.82
Final window weightings: [0.01888239 0.12468173 0.16995761 0.22234687 0.04670163 0.22162628
 0.16436382 0.15572272 0.11393756]
2025-03-25 14:06:53 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7100 | Avg Loss: 10.2959
Logits: 66.86  125.42
Final window weightings: [0.01980533 0.12528601 0.16959167 0.22236738 0.04648554 0.22230397
 0.16390468 0.15518525 0.11313889]
2025-03-25 14:35:46 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7200 | Avg Loss: 11.2848
Logits: -48.57  -27.44
Final window weightings: [0.01936133 0.12497711 0.16951573 0.2221986  0.04664313 0.22220697
 0.16444688 0.15556617 0.11294936]
2025-03-25 15:05:28 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7300 | Avg Loss: 8.5841
Logits: 41.02  91.73
Final window weightings: [0.02007658 0.12587258 0.16851512 0.22169898 0.04421192 0.22447793
 0.16337936 0.1549985  0.11430217]
2025-03-25 15:34:41 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7400 | Avg Loss: 9.7185
Logits: 21.04  40.35
Final window weightings: [0.01935653 0.1264806  0.16748214 0.22180769 0.04310851 0.22412829
 0.16400601 0.15578595 0.11488612]
2025-03-25 16:04:06 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7500 | Avg Loss: 8.3792
Logits: -16.90  0.44
Final window weightings: [0.02031678 0.12492399 0.16655967 0.22175796 0.04338891 0.22371858
 0.16433941 0.1561791  0.11541856]
2025-03-25 16:31:43 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7600 | Avg Loss: 8.6044
Logits: 13.37  36.99
Final window weightings: [0.02018015 0.1238954  0.16531308 0.22116268 0.04373907 0.22397996
 0.16512433 0.15682298 0.11610188]
2025-03-25 16:59:42 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7700 | Avg Loss: 7.2500
Logits: -10.42  8.42
Final window weightings: [0.02101192 0.12364554 0.16510083 0.22089668 0.04416907 0.22408728
 0.16491581 0.15649603 0.11590965]
2025-03-25 17:27:57 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7800 | Avg Loss: 8.1762
Logits: 37.29  79.99
Final window weightings: [0.02174191 0.12563196 0.16411798 0.2190876  0.04560159 0.22302695
 0.16405639 0.15640385 0.11636906]
2025-03-25 17:59:04 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7900 | Avg Loss: 8.5606
Logits: -6.52  16.27
Final window weightings: [0.0230951  0.1291712  0.16158906 0.21985528 0.04426656 0.22688472
 0.16254891 0.15501268 0.11397584]
2025-03-25 18:26:53 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8000 | Avg Loss: 15.3556
Logits: -55.30  -27.24
Final window weightings: [0.02276116 0.12688075 0.16045992 0.2176553  0.04292718 0.22715071
 0.16441229 0.15785778 0.11537844]
2025-03-25 18:54:31 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8100 | Avg Loss: 8.7567
Logits: 20.63  50.40
Final window weightings: [0.02196141 0.12523639 0.1608018  0.21755643 0.04179292 0.22721902
 0.16565092 0.15885691 0.11604608]
2025-03-25 19:22:03 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8200 | Avg Loss: 7.5604
Logits: 6.60  48.29
Final window weightings: [0.02260135 0.12487897 0.16086988 0.21742453 0.04168187 0.2273715
 0.16537566 0.15868501 0.11616146]
2025-03-25 19:50:09 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8300 | Avg Loss: 20.3099
Logits: 14.65  56.85
Final window weightings: [0.02205881 0.12420697 0.16043447 0.21703053 0.04190263 0.22735971
 0.16568473 0.15946728 0.11650664]
2025-03-25 20:20:09 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8400 | Avg Loss: 9.9527
Logits: -22.54  -0.46
Final window weightings: [0.02245457 0.12337974 0.1594697  0.21545394 0.04191326 0.22801198
 0.16634415 0.16006318 0.11719061]
2025-03-25 20:47:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8500 | Avg Loss: 9.1087
Logits: 15.81  35.83
Final window weightings: [0.0220091  0.1225162  0.15913846 0.21564664 0.04251892 0.22820728
 0.16670601 0.16032784 0.11708808]
2025-03-25 21:17:45 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8600 | Avg Loss: 7.9355
Logits: 61.53  107.10
Final window weightings: [0.02166955 0.1231464  0.15837945 0.2156051  0.04249575 0.22785652
 0.16698878 0.16081011 0.11696795]
2025-03-25 21:47:43 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8700 | Avg Loss: 9.4357
Logits: 73.52  142.30
Final window weightings: [0.02075324 0.12310403 0.15858886 0.21469112 0.04203273 0.22849892
 0.16734931 0.16142428 0.11737416]
2025-03-25 22:17:03 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8800 | Avg Loss: 11.9385
Logits: 7.71  27.27
Final window weightings: [0.02051181 0.12166499 0.15815529 0.21364743 0.04271847 0.22861837
 0.16808887 0.16236101 0.11771425]
2025-03-25 22:45:24 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8900 | Avg Loss: 8.4566
Logits: 41.54  80.75
Final window weightings: [0.02255909 0.12084724 0.15629585 0.21292356 0.04302134 0.2295446
 0.16843474 0.16199537 0.11760169]
2025-03-25 23:13:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9000 | Avg Loss: 6.7024
Logits: 72.33  140.66
Final window weightings: [0.02037896 0.12237759 0.15663782 0.21379174 0.04064461 0.22990902
 0.16932495 0.16242652 0.117511  ]
2025-03-25 23:41:44 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9100 | Avg Loss: 15.6405
Logits: 90.38  183.10
Final window weightings: [0.0211249  0.12149818 0.15491492 0.21335608 0.04234368 0.23178098
 0.16973853 0.16183555 0.11653557]
2025-03-26 00:11:06 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9200 | Avg Loss: 6.5878
Logits: 46.33  77.97
Final window weightings: [0.02056613 0.12047966 0.15547562 0.21388333 0.04235339 0.23228206
 0.16946256 0.16178809 0.11678809]
2025-03-26 00:41:13 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9300 | Avg Loss: 9.6728
Logits: -28.09  8.81
Final window weightings: [0.02014415 0.12000974 0.15517087 0.21363427 0.04204731 0.23276113
 0.16969617 0.16216122 0.11722779]
2025-03-26 01:08:59 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9400 | Avg Loss: 15.9481
Logits: -25.94  2.55
Final window weightings: [0.02051856 0.12111211 0.15488547 0.2134819  0.04278392 0.23313892
 0.16877216 0.16137391 0.11689272]
2025-03-26 02:10:30 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9500 | Avg Loss: 9.2281
Logits: 1.26  19.01
Final window weightings: [0.02026496 0.12134769 0.15501764 0.21332584 0.04380129 0.2335693
 0.16866387 0.16089591 0.11625034]
2025-03-26 02:37:59 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9600 | Avg Loss: 9.1799
Logits: 8.48  42.06
Final window weightings: [0.02093812 0.12032385 0.15476215 0.2130473  0.04244785 0.2333913
 0.16887811 0.1614692  0.11722943]
2025-03-26 03:05:35 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9700 | Avg Loss: 11.2719
Logits: -34.70  8.69
Final window weightings: [0.02081035 0.12141047 0.1550233  0.21280618 0.04217781 0.23476347
 0.16818775 0.16079207 0.11660037]
2025-03-26 03:32:56 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9800 | Avg Loss: 10.6549
Logits: -15.69  10.48
Final window weightings: [0.02175313 0.12284254 0.15526247 0.21453944 0.04168855 0.23400865
 0.16715147 0.15953887 0.115761  ]
2025-03-26 04:00:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9900 | Avg Loss: 8.3309
Logits: -20.89  -0.62
Final window weightings: [0.02106403 0.12108846 0.1535614  0.2149163  0.04088674 0.23525114
 0.16853707 0.1603974  0.11632244]
2025-03-26 04:28:47 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10000 | Avg Loss: 10.8874
Logits: 114.30  201.49
Final window weightings: [0.01904754 0.12063803 0.15410027 0.21558584 0.04043563 0.23588851
 0.16867524 0.16084778 0.11668556]
2025-03-26 04:56:26 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10100 | Avg Loss: 8.4926
Logits: 6.04  20.90
Final window weightings: [0.01944394 0.12106415 0.15476604 0.21266249 0.03975808 0.23398386
 0.169203   0.16196874 0.11824637]
2025-03-26 05:24:03 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10200 | Avg Loss: 11.5810
Logits: 8.75  35.04
Final window weightings: [0.01972977 0.12136421 0.15489155 0.21331298 0.04016557 0.23470663
 0.1685736  0.16109762 0.11740027]
2025-03-26 05:51:41 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10300 | Avg Loss: 8.8507
Logits: -60.88  -26.39
Final window weightings: [0.0204074  0.12094049 0.15422854 0.21348    0.04078568 0.23560022
 0.16849121 0.16067575 0.11661433]
2025-03-26 06:20:00 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10400 | Avg Loss: 10.0438
Logits: 55.52  110.33
Final window weightings: [0.02022762 0.12095972 0.15418857 0.21354671 0.04116189 0.23545955
 0.16837256 0.16045083 0.11675984]
2025-03-26 06:48:21 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10500 | Avg Loss: 9.2879
Logits: -22.24  -0.03
Final window weightings: [0.02120101 0.11983514 0.15340853 0.21529903 0.04126958 0.23879652
 0.1676905  0.15875271 0.11513522]
2025-03-26 07:16:01 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10600 | Avg Loss: 12.9117
Logits: -14.36  10.00
Final window weightings: [0.02139034 0.11734685 0.1520612  0.21280316 0.04174947 0.24008553
 0.16883887 0.16004956 0.11644959]
2025-03-26 07:43:55 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10700 | Avg Loss: 8.2966
Logits: 35.91  70.02
Final window weightings: [0.02072732 0.11569271 0.15130414 0.21338563 0.0404265  0.24010882
 0.16992398 0.16101539 0.11751445]
2025-03-26 08:11:38 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10800 | Avg Loss: 17.1828
Logits: 20.17  71.98
Final window weightings: [0.01950016 0.11443239 0.15327205 0.2147931  0.03835889 0.24084416
 0.1700448  0.16092852 0.11750741]
2025-03-26 08:38:52 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10900 | Avg Loss: 13.3543
Logits: -13.30  7.48
Final window weightings: [0.02049246 0.11288711 0.15175453 0.21337052 0.03886846 0.24210775
 0.17101316 0.16132481 0.11730487]
2025-03-26 09:06:27 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11000 | Avg Loss: 20.4954
Logits: 85.01  159.10
Final window weightings: [0.02365566 0.11652993 0.15000135 0.2123697  0.04205632 0.24177188
 0.16906324 0.15952468 0.11585938]
2025-03-26 09:34:04 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11100 | Avg Loss: 16.4486
Logits: -29.20  9.84
Final window weightings: [0.02332599 0.11679117 0.150125   0.21265362 0.04175107 0.24191926
 0.16901688 0.15942684 0.11567265]
2025-03-26 10:01:29 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11200 | Avg Loss: 18.3105
Logits: -18.71  -2.50
Final window weightings: [0.02259662 0.11702024 0.15041701 0.21325986 0.04137743 0.24222131
 0.16895103 0.15930502 0.11539926]
2025-03-26 10:29:00 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11300 | Avg Loss: 18.7326
Logits: 25.14  79.07
Final window weightings: [0.02197311 0.11771759 0.15079139 0.21394442 0.04106788 0.24234986
 0.16871257 0.15901515 0.11493979]
2025-03-26 10:58:09 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11400 | Avg Loss: 15.2125
Logits: -111.82  -64.70
Final window weightings: [0.02055537 0.11877762 0.15138334 0.2150911  0.04014872 0.24308468
 0.16864921 0.1585153  0.11403875]
2025-03-26 11:29:15 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11500 | Avg Loss: 11.5475
Logits: -31.76  -11.67
Final window weightings: [0.02048994 0.11949384 0.15099262 0.21500085 0.04023829 0.24345621
 0.1684085  0.15841809 0.11376777]
2025-03-26 11:57:28 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11600 | Avg Loss: 14.4656
Logits: -18.98  15.72
Final window weightings: [0.01973701 0.12053443 0.15199447 0.21638772 0.03980969 0.24390465
 0.16763346 0.15762815 0.11287028]
2025-03-26 12:24:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11700 | Avg Loss: 12.3399
Logits: 130.46  211.47
Final window weightings: [0.0184149  0.12044443 0.1520831  0.2164439  0.0395849  0.24425086
 0.1678209  0.15811235 0.11311231]
2025-03-26 12:52:10 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11800 | Avg Loss: 12.1513
Logits: -10.36  3.17
Final window weightings: [0.01817788 0.12103242 0.15195003 0.21653037 0.03947277 0.2444115
 0.16775265 0.15808631 0.11275319]
2025-03-26 13:19:57 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11900 | Avg Loss: 9.8309
Logits: 42.74  74.22
Final window weightings: [0.01794266 0.12129614 0.15200529 0.21666487 0.03938338 0.24464622
 0.16773136 0.1578974  0.11257683]
2025-03-26 13:47:32 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12000 | Avg Loss: 7.5786
Logits: 27.04  56.06
Final window weightings: [0.01801527 0.12141614 0.15213706 0.21698931 0.03914692 0.2448139
 0.16757481 0.15769455 0.11226413]
2025-03-26 14:15:00 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12100 | Avg Loss: 7.1251
Logits: -117.80  -62.34
Final window weightings: [0.01764212 0.12166888 0.15229374 0.21730384 0.03882438 0.24462886
 0.16780367 0.15703112 0.11261447]
2025-03-26 14:42:36 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12200 | Avg Loss: 9.6281
Logits: 33.50  76.53
Final window weightings: [0.01766462 0.1215683  0.15230522 0.21771528 0.03891687 0.24481748
 0.1676669  0.15678516 0.11244831]
2025-03-26 15:10:29 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12300 | Avg Loss: 10.8975
Logits: -9.39  32.57
Final window weightings: [0.01721051 0.12183673 0.15253416 0.21854544 0.03893403 0.24551295
 0.16745941 0.15636574 0.11172005]
2025-03-26 15:43:46 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12400 | Avg Loss: 10.4617
Logits: 67.20  118.66
Final window weightings: [0.01738808 0.12119286 0.15231894 0.21852618 0.03904399 0.24583757
 0.1676819  0.15644303 0.11162882]
2025-03-26 16:13:53 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12500 | Avg Loss: 9.1461
Logits: -110.39  -60.93
Final window weightings: [0.01666521 0.1207692  0.15299517 0.21915205 0.03888588 0.24601793
 0.16776773 0.15626413 0.11154452]

--- 2025-03-27 07:42:08 ---

--- 2025-03-27 07:49:31 ---
2025-03-27 08:25:02 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 100 | Avg Loss: 3.7851
Logits: -43.18  -9.90
Final window weightings: [0.01703957 0.12157364 0.15360762 0.22110426 0.03869126 0.24619924
 0.16627839 0.15600613 0.11002252]
2025-03-27 08:56:41 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 200 | Avg Loss: 7.8457
Logits: -31.80  -5.48
Final window weightings: [0.01721016 0.12205879 0.15464917 0.22157586 0.03836494 0.24605542
 0.16560867 0.15514083 0.10991556]
2025-03-27 09:27:14 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 300 | Avg Loss: 7.5951
Logits: 71.84  125.46
Final window weightings: [0.01775662 0.12162658 0.1548303  0.22152168 0.03944374 0.24486136
 0.16532989 0.15523276 0.10983761]
2025-03-27 10:00:32 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 400 | Avg Loss: 11.7850
Logits: -110.21  -66.54
Final window weightings: [0.01738247 0.12188373 0.15475906 0.22065882 0.03914401 0.24464878
 0.16558959 0.15566988 0.11042231]

--- 2025-03-27 10:05:17 ---
2025-03-27 10:33:42 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 100 | Avg Loss: 1.9614
Logits: 3.93  100.07
Final window weightings: [0.01838856 0.12363973 0.15480222 0.2219391  0.0396826  0.24492231
 0.16453256 0.15471448 0.10818404]
2025-03-27 11:00:41 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 200 | Avg Loss: 10.5806
Logits: 171.20  265.62
Final window weightings: [0.01734864 0.12541656 0.15545973 0.22246175 0.04081814 0.24513632
 0.16408162 0.15395878 0.10634134]
2025-03-27 11:28:24 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 300 | Avg Loss: 7.5618
Logits: -61.28  -35.13
Final window weightings: [0.01672122 0.12581636 0.15631421 0.22308958 0.03978517 0.24451517
 0.16415168 0.15410171 0.10679127]
2025-03-27 11:56:58 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 400 | Avg Loss: 8.0699
Logits: 20.53  54.21
Final window weightings: [0.01680636 0.1257278  0.1563085  0.22285093 0.03912503 0.2444036
 0.16443548 0.15452357 0.10703298]
2025-03-27 12:24:37 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 500 | Avg Loss: 7.6976
Logits: 128.03  200.25
Final window weightings: [0.01702816 0.12586932 0.15629855 0.2226191  0.03876344 0.2439648
 0.16430582 0.15478267 0.10754492]
2025-03-27 12:53:04 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 600 | Avg Loss: 9.3670
Logits: -149.01  -107.17
Final window weightings: [0.01688531 0.12584482 0.15621574 0.22239344 0.03879936 0.24391706
 0.164506   0.15497497 0.10752306]
2025-03-27 13:20:15 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 700 | Avg Loss: 7.9712
Logits: 78.90  123.24
Final window weightings: [0.01733606 0.12581828 0.1563631  0.22229749 0.03815397 0.24383645
 0.16442136 0.15523684 0.10757069]
2025-03-27 13:48:07 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 800 | Avg Loss: 7.3299
Logits: 40.19  74.40
Final window weightings: [0.01724619 0.12576015 0.15614189 0.22207075 0.03823848 0.24397959
 0.16456474 0.15529269 0.10763105]
2025-03-27 14:16:16 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 900 | Avg Loss: 7.3954
Logits: 5.43  20.02
Final window weightings: [0.01735254 0.12573522 0.15550615 0.22210924 0.03787319 0.24421465
 0.16486573 0.15556742 0.10762317]
2025-03-27 14:43:35 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1000 | Avg Loss: 8.5864
Logits: -32.88  -14.87
Final window weightings: [0.01713004 0.12537362 0.1550852  0.22194645 0.0381391  0.2443801
 0.16505663 0.1558761  0.10762533]
2025-03-27 15:10:33 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1100 | Avg Loss: 7.3129
Logits: 14.80  34.71
Final window weightings: [0.01667595 0.12486175 0.15493652 0.22155936 0.03821493 0.24419865
 0.16563535 0.15626231 0.10801849]
2025-03-27 15:37:51 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1200 | Avg Loss: 9.0067
Logits: -1.11  11.04
Final window weightings: [0.01661159 0.12477809 0.15434016 0.22160245 0.03839499 0.24446872
 0.16585772 0.15618004 0.10797517]
2025-03-27 16:05:36 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1300 | Avg Loss: 7.2668
Logits: -1.98  11.97
Final window weightings: [0.01655856 0.12468781 0.15427458 0.22101662 0.03827026 0.24438778
 0.16585779 0.1566497  0.1083578 ]
2025-03-27 16:33:20 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1400 | Avg Loss: 10.4495
Logits: 65.71  107.73
Final window weightings: [0.01654989 0.12419973 0.15389797 0.2202386  0.03830874 0.24459244
 0.16575845 0.15742809 0.10876579]
2025-03-27 17:01:49 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1500 | Avg Loss: 8.9700
Logits: -75.16  -46.16
Final window weightings: [0.01663767 0.12389252 0.1540507  0.21957436 0.03810178 0.24476065
 0.16608651 0.15746291 0.10898494]
2025-03-27 17:30:34 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1600 | Avg Loss: 7.4794
Logits: -8.10  4.87
Final window weightings: [0.017749   0.12320154 0.15465435 0.22075318 0.036657   0.24414437
 0.16614382 0.15762448 0.10865296]
2025-03-27 17:58:54 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1700 | Avg Loss: 10.0687
Logits: -13.79  -1.75
Final window weightings: [0.0173782  0.12288608 0.15468244 0.22114748 0.03668107 0.24425744
 0.16630536 0.15751754 0.10862052]
2025-03-27 21:20:17 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1800 | Avg Loss: 9.6381
Logits: 59.51  99.43
Final window weightings: [0.01831913 0.12368919 0.15530334 0.22184171 0.03586224 0.2447023
 0.16546781 0.15673307 0.1078319 ]
2025-03-27 22:15:59 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1900 | Avg Loss: 8.6177
Logits: -35.36  -13.89
Final window weightings: [0.01741873 0.12368888 0.15540326 0.22157237 0.03614571 0.24427743
 0.16573745 0.15707241 0.1082757 ]
2025-03-27 22:45:19 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2000 | Avg Loss: 7.6943
Logits: 4.50  25.51
Final window weightings: [0.01710222 0.123751   0.15479906 0.221383   0.03622629 0.24429882
 0.16611889 0.15746701 0.10829013]
2025-03-27 23:16:14 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2100 | Avg Loss: 6.8635
Logits: 6.96  26.46
Final window weightings: [0.01698986 0.12361613 0.15468031 0.2219289  0.0360251  0.24436931
 0.16622324 0.15748075 0.10807949]
2025-03-27 23:44:13 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2200 | Avg Loss: 11.3781
Logits: 93.71  153.79
Final window weightings: [0.01667044 0.12370603 0.15407144 0.22234865 0.03641952 0.24475725
 0.16598138 0.15723763 0.10802796]
2025-03-28 00:12:42 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2300 | Avg Loss: 12.1372
Logits: 32.23  62.04
Final window weightings: [0.01641105 0.12452389 0.15327767 0.22056872 0.03596021 0.24569334
 0.16681126 0.15750678 0.1082724 ]
2025-03-28 00:41:02 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2400 | Avg Loss: 8.6103
Logits: 24.31  51.02
Final window weightings: [0.01617615 0.12456991 0.15284479 0.22075959 0.03591835 0.24547777
 0.16669975 0.15790689 0.10854993]
2025-03-28 01:09:34 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2500 | Avg Loss: 9.9191
Logits: 19.53  39.46
Final window weightings: [0.01656844 0.12391794 0.15233664 0.22089481 0.03575204 0.24573073
 0.16700646 0.1579053  0.10852009]
2025-03-28 01:38:12 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2600 | Avg Loss: 7.8281
Logits: -2.47  20.99
Final window weightings: [0.01650704 0.12404018 0.15251541 0.2205198  0.03579921 0.24561004
 0.16708227 0.15788488 0.10856371]
2025-03-28 02:06:42 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2700 | Avg Loss: 8.9279
Logits: 64.92  107.34
Final window weightings: [0.01597654 0.12408389 0.15317136 0.22081189 0.03555727 0.2454041
 0.16651629 0.1580619  0.1088804 ]
2025-03-28 02:35:12 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2800 | Avg Loss: 6.6188
Logits: 173.91  434.17
Final window weightings: [0.01441318 0.1262403  0.15131707 0.22150908 0.03611684 0.25130436
 0.16518298 0.15551573 0.10759293]
2025-03-28 03:03:16 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2900 | Avg Loss: 8.3415
Logits: -9.29  22.79
Final window weightings: [0.01415753 0.12531549 0.14861849 0.21981879 0.03940894 0.2527751
 0.16538511 0.1553577  0.10738289]
2025-03-28 03:32:35 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3000 | Avg Loss: 5.5691
Logits: -16.82  1.15
Final window weightings: [0.01422854 0.12495214 0.14851278 0.2198783  0.03952118 0.25336027
 0.16542543 0.15524125 0.10704996]
2025-03-28 04:00:48 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3100 | Avg Loss: 5.1710
Logits: 9.92  48.46
Final window weightings: [0.01441754 0.12577775 0.148762   0.22013831 0.03961266 0.25308388
 0.16514046 0.15465693 0.10658387]
2025-03-28 04:28:47 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3200 | Avg Loss: 9.3027
Logits: -29.39  -4.93
Final window weightings: [0.01377274 0.12478375 0.14844997 0.22039732 0.03915681 0.25436598
 0.16572459 0.15483245 0.10664781]
2025-03-28 04:57:02 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3300 | Avg Loss: 9.7766
Logits: -89.45  -51.12
Final window weightings: [0.01331156 0.12507808 0.14890072 0.22059375 0.03875939 0.25487068
 0.16578479 0.15432446 0.10656476]
2025-03-28 05:25:18 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3400 | Avg Loss: 7.7378
Logits: 50.08  78.42
Final window weightings: [0.01279525 0.12543282 0.14819203 0.21965894 0.03838679 0.25843987
 0.16559732 0.15399514 0.10594618]
2025-03-28 05:53:16 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3500 | Avg Loss: 9.9523
Logits: -82.10  -52.96
Final window weightings: [0.01377084 0.12577085 0.14883476 0.22153062 0.03822618 0.25828275
 0.16412233 0.15231624 0.1057371 ]
2025-03-28 06:20:30 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3600 | Avg Loss: 7.6255
Logits: 16.93  56.75
Final window weightings: [0.01373327 0.12517188 0.14909334 0.22312155 0.03795035 0.25950047
 0.16393791 0.15177025 0.10466573]
2025-03-28 06:48:31 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3700 | Avg Loss: 7.9477
Logits: -3.17  35.18
Final window weightings: [0.01362895 0.12436094 0.14933011 0.22337025 0.0373015  0.26020765
 0.16434155 0.15200564 0.10446302]
2025-03-28 07:17:02 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3800 | Avg Loss: 8.1104
Logits: 45.81  83.96
Final window weightings: [0.01354501 0.12441272 0.14825034 0.22445413 0.0369232  0.26068532
 0.16435239 0.1521891  0.10428157]
2025-03-28 07:45:00 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3900 | Avg Loss: 7.9417
Logits: 55.18  89.43
Final window weightings: [0.01367119 0.12537508 0.14751326 0.22511043 0.03639079 0.2591077
 0.1636656  0.15275374 0.10515615]
2025-03-28 08:12:56 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4000 | Avg Loss: 7.2426
Logits: 12.28  37.81
Final window weightings: [0.01431473 0.12525085 0.14813322 0.22595406 0.03552525 0.25967228
 0.16337202 0.1520411  0.10468622]
2025-03-28 08:41:13 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4100 | Avg Loss: 7.0464
Logits: 113.56  153.97
Final window weightings: [0.01460678 0.12484846 0.14794315 0.22585028 0.03513085 0.25945008
 0.16370004 0.15234849 0.10486867]
2025-03-28 09:10:19 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4200 | Avg Loss: 8.3996
Logits: 119.45  176.68
Final window weightings: [0.01576725 0.12405173 0.14712414 0.22666565 0.03324478 0.26113036
 0.16473626 0.15264055 0.10378277]
2025-03-28 09:38:00 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4300 | Avg Loss: 6.8816
Logits: 11.43  24.96
Final window weightings: [0.01551862 0.12364016 0.14656053 0.2250853  0.03427094 0.260913
 0.16502091 0.15309562 0.1045619 ]
2025-03-28 10:05:30 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4400 | Avg Loss: 8.2135
Logits: 26.67  52.53
Final window weightings: [0.0154594  0.1238473  0.14703608 0.22461383 0.03397049 0.2609375
 0.16497773 0.15311779 0.1046562 ]
2025-03-28 10:32:40 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4500 | Avg Loss: 7.4447
Logits: -3.14  27.16
Final window weightings: [0.01590561 0.12345352 0.14710797 0.2242531  0.03429858 0.26071185
 0.16484807 0.15311085 0.10469087]
2025-03-28 10:59:45 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4600 | Avg Loss: 12.5431
Logits: 64.92  128.55
Final window weightings: [0.01670258 0.12414172 0.14731139 0.22437699 0.03487337 0.26081917
 0.16391475 0.15237978 0.10391171]
2025-03-28 11:26:42 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4700 | Avg Loss: 5.7681
Logits: -6.11  13.85
Final window weightings: [0.0170874  0.12461257 0.14862129 0.2249594  0.03348991 0.2614303
 0.16354132 0.15157582 0.10347617]
2025-03-28 11:53:20 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4800 | Avg Loss: 14.6248
Logits: 92.29  137.55
Final window weightings: [0.0170518  0.12473956 0.14908716 0.22481173 0.03312164 0.26344594
 0.16376166 0.15065166 0.10257804]
2025-03-28 12:20:21 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4900 | Avg Loss: 5.7908
Logits: 14.12  42.46
Final window weightings: [0.01630195 0.12426443 0.14870197 0.22292314 0.03269534 0.26393804
 0.16492411 0.15138261 0.10382048]
2025-03-28 12:47:24 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5000 | Avg Loss: 8.9533
Logits: 45.91  79.85
Final window weightings: [0.01538715 0.12462419 0.149892   0.22397947 0.03189968 0.26447147
 0.16463389 0.15106182 0.1033374 ]
2025-03-28 13:14:29 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5100 | Avg Loss: 5.3818
Logits: -14.14  19.69
Final window weightings: [0.01432726 0.12473816 0.15114072 0.22510746 0.03298998 0.2628738
 0.16435933 0.15021817 0.10325654]
2025-03-28 13:41:49 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5200 | Avg Loss: 5.4944
Logits: 9.65  35.82
Final window weightings: [0.01242643 0.1244094  0.15222938 0.22658478 0.03216836 0.26322818
 0.16465402 0.15006945 0.10344917]
2025-03-28 14:08:57 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5300 | Avg Loss: 11.5865
Logits: 12.31  28.32
Final window weightings: [0.01128861 0.12439307 0.15157647 0.22684139 0.03000941 0.26307485
 0.16614121 0.15144679 0.10435073]
2025-03-28 14:36:12 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5400 | Avg Loss: 8.6129
Logits: 14.81  70.80
Final window weightings: [0.01125893 0.12471282 0.15133649 0.226831   0.02984467 0.26286674
 0.16622868 0.15158632 0.10439626]
2025-03-28 15:03:14 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5500 | Avg Loss: 7.0551
Logits: -26.79  -3.34
Final window weightings: [0.0114239  0.12551728 0.15156531 0.22718546 0.02960239 0.26229367
 0.16565144 0.1514107  0.1044028 ]
2025-03-28 15:30:31 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5600 | Avg Loss: 6.5528
Logits: 13.25  36.78
Final window weightings: [0.01154209 0.12571001 0.15112992 0.22713184 0.02912449 0.2623767
 0.16562827 0.15175784 0.1046338 ]
2025-03-28 15:57:40 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5700 | Avg Loss: 9.1733
Logits: -2.03  15.65
Final window weightings: [0.01090713 0.12570687 0.151142   0.22689812 0.02892451 0.2628289
 0.16610059 0.15189189 0.10459976]
2025-03-28 16:25:56 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5800 | Avg Loss: 6.9271
Logits: 71.15  115.52
Final window weightings: [0.01169449 0.12684381 0.14979826 0.22692968 0.02822015 0.26342642
 0.16623375 0.15201916 0.10404673]
2025-03-28 16:54:17 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5900 | Avg Loss: 7.7419
Logits: 144.29  203.75
Final window weightings: [0.01187681 0.127104   0.14919613 0.22661616 0.02789052 0.26382563
 0.16666028 0.152148   0.10388575]
2025-03-28 17:26:23 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 6000 | Avg Loss: 7.0186
Logits: 75.00  113.99
Final window weightings: [0.01175933 0.12641907 0.1481455  0.22600444 0.02760961 0.2637343
 0.16793516 0.15295996 0.10428084]
2025-03-28 17:58:05 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 6100 | Avg Loss: 6.0174
Logits: 20.38  39.98
Final window weightings: [0.01097663 0.12580736 0.1488471  0.22619866 0.02804334 0.2650631
 0.16747752 0.1524035  0.10412625]
2025-03-28 18:27:37 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 6200 | Avg Loss: 7.8320
Logits: 53.40  85.44
Final window weightings: [0.01045498 0.12601286 0.1482297  0.22602561 0.02789477 0.2646623
 0.16819544 0.15298393 0.10427865]

--- 2025-03-28 18:52:37 ---
2025-03-28 19:21:12 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 100 | Avg Loss: 11.6541
Logits: 30.65  44.64
Final window weightings: [0.0106069  0.12483592 0.14849278 0.22563545 0.02775624 0.2643423
 0.16790587 0.15368627 0.10473551]

--- 2025-03-28 20:10:45 ---
2025-03-28 20:37:57 | Step 100    | LR: 0.00015 | Loss: 12.9315 | Logits: 1.45  4.63 | Weights: W8:0.21044  W3:0.18026  W13:0.13294  W15:0.12246  W2:0.11878  W1:0.09862  W18:0.08298  W7:0.02181  W14:0.009032025-03-28 21:06:04 | Step 200    | LR: 0.00015 | Loss: 12.1584 | Logits: 5.04  10.85 | Weights: W8:0.21016  W3:0.17971  W13:0.13294  W15:0.12236  W2:0.11926  W1:0.09840  W18:0.08338  W7:0.02180  W14:0.00933
--- 2025-03-28 21:08:10 ---

--- 2025-03-28 21:24:52 ---
2025-03-28 21:54:10 | Step 100    | LR: 0.00015 | Loss: 8.9781 | Logits: 3.89  5.62 | Weights: W8:0.21015  W3:0.17889  W13:0.13335  W15:0.12289  W2:0.11848  W1:0.09752  W18:0.08444  W7:0.02265  W14:0.009072025-03-28 22:25:06 | Step 200    | LR: 0.00015 | Loss: 8.8890 | Logits: 6.28  9.67 | Weights: W8:0.21002  W3:0.17832  W13:0.13374  W15:0.12333  W2:0.11847  W1:0.09693  W18:0.08474  W7:0.02319  W14:0.008732025-03-28 22:51:49 | Step 300    | LR: 0.00015 | Loss: 8.0227 | Logits: 10.42  15.39 | Weights: W8:0.20987  W3:0.17813  W13:0.13393  W15:0.12329  W2:0.11844  W1:0.09684  W18:0.08467  W7:0.02391  W14:0.008432025-03-28 23:18:49 | Step 400    | LR: 0.00015 | Loss: 10.0940 | Logits: 14.35  21.22 | Weights: W8:0.20957  W3:0.17771  W13:0.13418  W15:0.12353  W2:0.11798  W1:0.09680  W18:0.08498  W7:0.02447  W14:0.008322025-03-28 23:50:39 | Step 500    | LR: 0.00015 | Loss: 7.7102 | Logits: 17.62  26.04 | Weights: W8:0.20916  W3:0.17759  W13:0.13386  W15:0.12385  W2:0.11757  W1:0.09666  W18:0.08567  W7:0.02454  W14:0.008662025-03-29 00:26:16 | Step 600    | LR: 0.00015 | Loss: 8.8799 | Logits: 21.25  31.21 | Weights: W8:0.20890  W3:0.17726  W13:0.13425  W15:0.12443  W2:0.11726  W1:0.09635  W18:0.08615  W7:0.02430  W14:0.008682025-03-29 00:58:46 | Step 700    | LR: 0.00015 | Loss: 7.7783 | Logits: 24.52  36.03 | Weights: W8:0.20868  W3:0.17704  W13:0.13424  W15:0.12422  W2:0.11741  W1:0.09623  W18:0.08628  W7:0.02476  W14:0.008752025-03-29 01:32:43 | Step 800    | LR: 0.00015 | Loss: 10.0374 | Logits: 27.84  41.08 | Weights: W8:0.20871  W3:0.17691  W13:0.13452  W15:0.12440  W2:0.11717  W1:0.09597  W18:0.08650  W7:0.02471  W14:0.008722025-03-29 02:05:31 | Step 900    | LR: 0.00015 | Loss: 9.3248 | Logits: 30.69  45.71 | Weights: W8:0.20894  W3:0.17629  W13:0.13507  W15:0.12491  W2:0.11649  W1:0.09585  W18:0.08663  W7:0.02443  W14:0.009032025-03-29 02:34:41 | Step 1000   | LR: 0.00015 | Loss: 8.6617 | Logits: 0.00  0.00 | Weights: W8:0.20928  W3:0.17625  W13:0.13500  W15:0.12496  W2:0.11644  W1:0.09540  W18:0.08662  W7:0.02453  W14:0.009172025-03-29 03:06:34 | Step 1100   | LR: 0.00015 | Loss: 8.5479 | Logits: 3.15  4.79 | Weights: W8:0.20928  W3:0.17660  W13:0.13486  W15:0.12471  W2:0.11619  W1:0.09532  W18:0.08659  W7:0.02481  W14:0.009322025-03-29 03:43:32 | Step 1200   | LR: 0.00015 | Loss: 8.1176 | Logits: 6.15  9.31 | Weights: W8:0.20963  W3:0.17729  W13:0.13500  W15:0.12491  W2:0.11539  W1:0.09496  W18:0.08654  W7:0.02500  W14:0.008922025-03-29 04:13:32 | Step 1300   | LR: 0.00015 | Loss: 8.7634 | Logits: 8.64  13.42 | Weights: W8:0.21062  W3:0.17675  W13:0.13541  W15:0.12525  W2:0.11437  W1:0.09444  W18:0.08677  W7:0.02467  W14:0.00938
--- 2025-03-29 04:59:04 ---
2025-03-29 05:26:28 | Step 100    | LR: 0.00015 | Loss: 10.8492 | Logits: 2.74  4.70 | Weights: W8:0.21005  W3:0.17591  W13:0.13611  W15:0.12611  W2:0.11398  W1:0.09426  W18:0.08725  W7:0.02464  W14:0.009392025-03-29 05:54:36 | Step 200    | LR: 0.00015 | Loss: 8.4265 | Logits: 6.16  9.71 | Weights: W8:0.20996  W3:0.17580  W13:0.13638  W15:0.12624  W2:0.11384  W1:0.09379  W18:0.08764  W7:0.02502  W14:0.009052025-03-29 06:22:46 | Step 300    | LR: 0.00015 | Loss: 7.7694 | Logits: 9.18  14.10 | Weights: W8:0.21009  W3:0.17573  W13:0.13654  W15:0.12626  W2:0.11344  W1:0.09370  W18:0.08780  W7:0.02457  W14:0.009592025-03-29 06:51:38 | Step 400    | LR: 0.00015 | Loss: 8.1550 | Logits: 11.67  18.14 | Weights: W8:0.20956  W3:0.17563  W13:0.13708  W15:0.12670  W2:0.11295  W1:0.09275  W18:0.08861  W7:0.02430  W14:0.010152025-03-29 07:21:27 | Step 500    | LR: 0.00015 | Loss: 8.1959 | Logits: 14.49  22.28 | Weights: W8:0.20947  W3:0.17567  W13:0.13724  W15:0.12677  W2:0.11293  W1:0.09275  W18:0.08878  W7:0.02432  W14:0.009802025-03-29 07:51:57 | Step 600    | LR: 0.00015 | Loss: 7.9797 | Logits: 16.76  25.91 | Weights: W8:0.20959  W3:0.17633  W13:0.13708  W15:0.12631  W2:0.11291  W1:0.09346  W18:0.08800  W7:0.02346  W14:0.010592025-03-29 08:22:53 | Step 700    | LR: 0.00015 | Loss: 9.0329 | Logits: 19.57  30.43 | Weights: W8:0.20963  W3:0.17632  W13:0.13752  W15:0.12683  W2:0.11211  W1:0.09330  W18:0.08840  W7:0.02348  W14:0.010132025-03-29 08:54:14 | Step 800    | LR: 0.00015 | Loss: 8.3931 | Logits: 22.00  34.34 | Weights: W8:0.20970  W3:0.17593  W13:0.13746  W15:0.12677  W2:0.11276  W1:0.09319  W18:0.08839  W7:0.02353  W14:0.010012025-03-29 09:24:59 | Step 900    | LR: 0.00015 | Loss: 8.7092 | Logits: 23.36  37.10 | Weights: W8:0.20968  W3:0.17571  W13:0.13751  W15:0.12687  W2:0.11269  W1:0.09305  W18:0.08853  W7:0.02344  W14:0.010262025-03-29 09:57:04 | Step 1000   | LR: 0.00015 | Loss: 7.3909 | Logits: 0.00  0.00 | Weights: W8:0.20938  W3:0.17518  W13:0.13793  W15:0.12747  W2:0.11183  W1:0.09285  W18:0.08913  W7:0.02338  W14:0.010582025-03-29 10:26:28 | Step 1100   | LR: 0.00015 | Loss: 7.8297 | Logits: 1.80  3.08 | Weights: W8:0.20913  W3:0.17504  W13:0.13804  W15:0.12772  W2:0.11157  W1:0.09310  W18:0.08939  W7:0.02316  W14:0.01061
--- 2025-03-29 10:50:47 --- im testing whether you can make better notes! ---
2025-03-29 10:59:40 | Step 1200   | LR: 0.00015 | Loss: 8.9879 | Logits: 3.65  6.43 | Weights: W8:0.20851  W3:0.17478  W13:0.13900  W15:0.12843  W2:0.11064  W1:0.09276  W18:0.08987  W7:0.02299  W14:0.01079
--- 2025-03-29 11:12:16 --- i am just testing if your tokenizer works! ---
2025-03-29 11:31:30 | Step 1300   | LR: 0.00015 | Loss: 7.1182 | Logits: 5.46  9.44 | Weights: W8:0.20894  W3:0.17405  W13:0.13936  W15:0.12856  W2:0.11009  W1:0.09297  W18:0.08992  W7:0.02259  W14:0.011292025-03-29 12:02:38 | Step 1400   | LR: 0.00015 | Loss: 7.4365 | Logits: 7.20  12.44 | Weights: W8:0.20810  W3:0.17371  W13:0.13987  W15:0.12903  W2:0.11020  W1:0.09305  W18:0.09028  W7:0.02224  W14:0.01130
--- 2025-03-29 12:06:45 --- how to be a real boy! ---
2025-03-29 12:32:43 | Step 1500   | LR: 0.00015 | Loss: 7.8731 | Logits: 8.95  15.50 | Weights: W8:0.20786  W3:0.17357  W13:0.13982  W15:0.12918  W2:0.11024  W1:0.09298  W18:0.09045  W7:0.02220  W14:0.011492025-03-29 13:10:10 | Step 1600   | LR: 0.00015 | Loss: 7.1665 | Logits: 10.38  18.16 | Weights: W8:0.20798  W3:0.17346  W13:0.13971  W15:0.12907  W2:0.11020  W1:0.09287  W18:0.09052  W7:0.02198  W14:0.012012025-03-29 13:40:11 | Step 1700   | LR: 0.00015 | Loss: 8.0436 | Logits: 12.45  21.67 | Weights: W8:0.20821  W3:0.17379  W13:0.13938  W15:0.12857  W2:0.11013  W1:0.09270  W18:0.09019  W7:0.02148  W14:0.013342025-03-29 14:11:05 | Step 1800   | LR: 0.00015 | Loss: 7.8832 | Logits: 13.82  24.46 | Weights: W8:0.20781  W3:0.17367  W13:0.13947  W15:0.12874  W2:0.11028  W1:0.09277  W18:0.09034  W7:0.02163  W14:0.013102025-03-29 14:43:24 | Step 1900   | LR: 0.00015 | Loss: 8.1356 | Logits: 15.14  27.18 | Weights: W8:0.20723  W3:0.17284  W13:0.13941  W15:0.12900  W2:0.11029  W1:0.09331  W18:0.09065  W7:0.02159  W14:0.013502025-03-29 15:20:08 | Step 2000   | LR: 0.00015 | Loss: 7.1411 | Logits: 0.00  0.00 | Weights: W8:0.20659  W3:0.17244  W13:0.13968  W15:0.12930  W2:0.11079  W1:0.09388  W18:0.09095  W7:0.02112  W14:0.01307

--- 2025-03-30 05:56:26 ---
babyLLM: what am i learning today?
You: ur mum
2025-03-30 06:27:44 | Step 100 | LR: 0.00030 | Avg Loss: 16.3344 | Logits: 35.12, 64.12 | Window Weights: W8:0.20341, W3:0.17512, W13:0.13903, W15:0.12915, W2:0.11307, W1:0.09395, W18:0.09187, W7:0.02242, W14:0.00997 | Grad Norm: 0.000 | Memory Gates: Short:-2.999, Long:1.218, Current:2.781

--- 2025-03-30 03:40:51 ---
babyLLM: what am i learning today?
You: how to keep me up at night! again!
2025-03-30 12:52:11 | Step 100 | LR: 0.00030 | Avg Loss: 48.1059 | Logits: 9.35, 47.21 | Window Weights: W8:0.20436, W3:0.17488, W13:0.13834, W15:0.12795, W2:0.11393, W1:0.09712, W18:0.09032, W7:0.02341, W14:0.00784 | Grad Norm: 0.000 | Memory Gates: Short:-0.717, Long:1.188, Current:0.529
2025-03-30 13:21:19 | Step 200 | LR: 0.00030 | Avg Loss: 16.5991 | Logits: 42.41, 94.00 | Window Weights: W8:0.20417, W3:0.17557, W13:0.13748, W15:0.12804, W2:0.11500, W1:0.09736, W18:0.08986, W7:0.02336, W14:0.00729 | Grad Norm: 0.000 | Memory Gates: Short:-1.257, Long:-0.479, Current:2.735
2025-03-30 13:50:39 | Step 300 | LR: 0.00030 | Avg Loss: 22.9733 | Logits: 25.69, 108.58 | Window Weights: W8:0.20436, W3:0.17275, W13:0.13906, W15:0.12985, W2:0.11359, W1:0.09706, W18:0.09081, W7:0.02266, W14:0.00799 | Grad Norm: 0.000 | Memory Gates: Short:-1.487, Long:1.594, Current:0.893
2025-03-30 14:20:01 | Step 400 | LR: 0.00030 | Avg Loss: 28.5616 | Logits: 31.56, 51.07 | Window Weights: W8:0.20430, W3:0.17232, W13:0.13939, W15:0.13006, W2:0.11334, W1:0.09710, W18:0.09105, W7:0.02265, W14:0.00792 | Grad Norm: 0.000 | Memory Gates: Short:-0.244, Long:1.180, Current:0.064
2025-03-30 14:49:27 | Step 500 | LR: 0.00030 | Avg Loss: 15.9755 | Logits: 17.46, 68.20 | Window Weights: W8:0.20407, W3:0.17279, W13:0.13922, W15:0.12968, W2:0.11414, W1:0.09688, W18:0.09084, W7:0.02266, W14:0.00785 | Grad Norm: 0.000 | Memory Gates: Short:-1.327, Long:-0.450, Current:2.777
2025-03-30 15:18:59 | Step 600 | LR: 0.00030 | Avg Loss: 29.9475 | Logits: 11.68, 67.58 | Window Weights: W8:0.20391, W3:0.17279, W13:0.13909, W15:0.12958, W2:0.11476, W1:0.09721, W18:0.09047, W7:0.02236, W14:0.00796 | Grad Norm: 0.000 | Memory Gates: Short:-1.607, Long:-0.429, Current:3.036
2025-03-30 15:47:04 | Step 700 | LR: 0.00030 | Avg Loss: 13.4374 | Logits: 23.85, 138.97 | Window Weights: W8:0.20415, W3:0.17143, W13:0.13886, W15:0.12958, W2:0.11326, W1:0.09984, W18:0.09060, W7:0.02215, W14:0.00824 | Grad Norm: 0.000 | Memory Gates: Short:-0.870, Long:-0.233, Current:2.102
2025-03-30 16:14:12 | Step 800 | LR: 0.00030 | Avg Loss: 26.3727 | Logits: 13.78, 48.69 | Window Weights: W8:0.20371, W3:0.17272, W13:0.13884, W15:0.12942, W2:0.11382, W1:0.09897, W18:0.09056, W7:0.02287, W14:0.00722 | Grad Norm: 0.000 | Memory Gates: Short:-13.128, Long:-5.784, Current:19.911
2025-03-30 16:41:23 | Step 900 | LR: 0.00030 | Avg Loss: 31.2302 | Logits: 1.36, 30.54 | Window Weights: W8:0.20362, W3:0.17287, W13:0.13919, W15:0.12952, W2:0.11352, W1:0.09866, W18:0.09051, W7:0.02297, W14:0.00729 | Grad Norm: 0.000 | Memory Gates: Short:0.083, Long:0.287, Current:0.630
2025-03-30 17:08:33 | Step 1000 | LR: 0.00030 | Avg Loss: 26.1067 | Logits: 18.48, 68.85 | Window Weights: W8:0.20343, W3:0.17257, W13:0.13945, W15:0.12974, W2:0.11343, W1:0.09845, W18:0.09063, W7:0.02305, W14:0.00741 | Grad Norm: 0.000 | Memory Gates: Short:-0.239, Long:0.785, Current:0.454
2025-03-30 17:08:33 | Step 1000 | LR: 0.00030 | Avg Loss: 27.8635 | Logits: 7.61, 33.67 | Window Weights: W8:0.20343, W3:0.17257, W13:0.13945, W15:0.12974, W2:0.11343, W1:0.09845, W18:0.09063, W7:0.02305, W14:0.00741 | Grad Norm: 0.000 | Memory Gates: Short:-0.239, Long:0.785, Current:0.454
2025-03-30 17:35:49 | Step 1100 | LR: 0.00030 | Avg Loss: 28.7396 | Logits: 10.60, 32.05 | Window Weights: W8:0.20339, W3:0.17264, W13:0.13947, W15:0.12970, W2:0.11344, W1:0.09831, W18:0.09069, W7:0.02314, W14:0.00738 | Grad Norm: 0.000 | Memory Gates: Short:-3.590, Long:3.143, Current:1.447
2025-03-30 18:03:11 | Step 1200 | LR: 0.00030 | Avg Loss: 28.9355 | Logits: 9.47, 32.20 | Window Weights: W8:0.20334, W3:0.17269, W13:0.13946, W15:0.12970, W2:0.11345, W1:0.09830, W18:0.09075, W7:0.02307, W14:0.00742 | Grad Norm: 0.000 | Memory Gates: Short:-0.451, Long:1.289, Current:0.162
2025-03-30 18:31:18 | Step 1300 | LR: 0.00030 | Avg Loss: 38.8803 | Logits: 7.01, 36.23 | Window Weights: W8:0.20332, W3:0.17252, W13:0.13956, W15:0.12990, W2:0.11333, W1:0.09814, W18:0.09089, W7:0.02299, W14:0.00752 | Grad Norm: 0.000 | Memory Gates: Short:-0.136, Long:1.404, Current:-0.268
2025-03-30 18:59:57 | Step 1400 | LR: 0.00030 | Avg Loss: 30.4740 | Logits: 5.68, 31.60 | Window Weights: W8:0.20344, W3:0.17221, W13:0.13976, W15:0.13008, W2:0.11308, W1:0.09812, W18:0.09092, W7:0.02275, W14:0.00780 | Grad Norm: 0.000 | Memory Gates: Short:-1.572, Long:0.924, Current:1.648
2025-03-30 19:31:23 | Step 1500 | LR: 0.00030 | Avg Loss: 24.7038 | Logits: 9.07, 28.06 | Window Weights: W8:0.20347, W3:0.17206, W13:0.13984, W15:0.13018, W2:0.11277, W1:0.09814, W18:0.09090, W7:0.02267, W14:0.00815 | Grad Norm: 0.000 | Memory Gates: Short:-0.674, Long:2.251, Current:-0.577
2025-03-30 20:01:28 | Step 1600 | LR: 0.00030 | Avg Loss: 30.1009 | Logits: 9.11, 32.65 | Window Weights: W8:0.20357, W3:0.17205, W13:0.13982, W15:0.13019, W2:0.11280, W1:0.09792, W18:0.09101, W7:0.02277, W14:0.00805 | Grad Norm: 0.000 | Memory Gates: Short:-3.253, Long:2.553, Current:1.700

--- 2025-03-30 21:44:43 ---
babyLLM: what am i learning today?
You: you're learning about mice!
2025-03-30 22:14:43 | Step 100 | LR: 0.00030 | Avg Loss: 20.7674 | Logits: 7.18, 60.19 | Window Weights: W8:0.20279, W3:0.17214, W13:0.13981, W15:0.12999, W2:0.11436, W1:0.09848, W18:0.09063, W7:0.02223, W14:0.00781 | Grad Norm: 0.000 | Memory Gates: Short:6.644, Long:-0.968, Current:-4.675
2025-03-30 22:42:09 | Step 200 | LR: 0.00030 | Avg Loss: 23.3332 | Logits: 11.07, 41.77 | Window Weights: W8:0.20306, W3:0.17225, W13:0.13974, W15:0.12982, W2:0.11438, W1:0.09874, W18:0.09052, W7:0.02231, W14:0.00743 | Grad Norm: 0.000 | Memory Gates: Short:-4.095, Long:0.883, Current:4.212
2025-03-30 23:09:08 | Step 300 | LR: 0.00030 | Avg Loss: 23.1870 | Logits: 18.44, 52.05 | Window Weights: W8:0.20274, W3:0.17265, W13:0.13903, W15:0.12932, W2:0.11487, W1:0.09922, W18:0.08991, W7:0.02261, W14:0.00792 | Grad Norm: 0.000 | Memory Gates: Short:34.739, Long:-26.961, Current:-6.778
2025-03-30 23:36:18 | Step 400 | LR: 0.00030 | Avg Loss: 27.3437 | Logits: 34.66, 77.40 | Window Weights: W8:0.20252, W3:0.17315, W13:0.13836, W15:0.12899, W2:0.11587, W1:0.09881, W18:0.08976, W7:0.02249, W14:0.00832 | Grad Norm: 0.000 | Memory Gates: Short:-2.085, Long:-0.092, Current:3.177
2025-03-31 00:03:47 | Step 500 | LR: 0.00030 | Avg Loss: 23.9488 | Logits: 17.76, 49.41 | Window Weights: W8:0.20280, W3:0.17380, W13:0.13816, W15:0.12890, W2:0.11694, W1:0.09902, W18:0.08942, W7:0.02204, W14:0.00718 | Grad Norm: 0.000 | Memory Gates: Short:-0.925, Long:-0.004, Current:1.929
2025-03-31 00:31:16 | Step 600 | LR: 0.00030 | Avg Loss: 21.0514 | Logits: 17.44, 43.56 | Window Weights: W8:0.20289, W3:0.17388, W13:0.13903, W15:0.12929, W2:0.11582, W1:0.09835, W18:0.08978, W7:0.02218, W14:0.00702 | Grad Norm: 0.000 | Memory Gates: Short:5.443, Long:-0.275, Current:-4.168
2025-03-31 00:58:32 | Step 700 | LR: 0.00030 | Avg Loss: 23.8713 | Logits: 15.25, 36.74 | Window Weights: W8:0.20293, W3:0.17403, W13:0.13923, W15:0.12926, W2:0.11564, W1:0.09782, W18:0.08986, W7:0.02247, W14:0.00702 | Grad Norm: 0.000 | Memory Gates: Short:-5.580, Long:1.576, Current:5.004
2025-03-31 01:27:11 | Step 800 | LR: 0.00030 | Avg Loss: 26.6425 | Logits: 10.50, 35.36 | Window Weights: W8:0.20280, W3:0.17397, W13:0.13925, W15:0.12921, W2:0.11559, W1:0.09716, W18:0.08972, W7:0.02261, W14:0.00797 | Grad Norm: 0.000 | Memory Gates: Short:-0.226, Long:0.512, Current:0.714
2025-03-31 01:55:55 | Step 900 | LR: 0.00030 | Avg Loss: 21.9215 | Logits: 4.50, 31.89 | Window Weights: W8:0.20321, W3:0.17516, W13:0.13958, W15:0.12938, W2:0.11547, W1:0.09604, W18:0.08958, W7:0.02240, W14:0.00746 | Grad Norm: 0.000 | Memory Gates: Short:-5.965, Long:-3.419, Current:10.384
2025-03-31 02:24:42 | Step 1000 | LR: 0.00030 | Avg Loss: 23.8996 | Logits: 15.14, 46.57 | Window Weights: W8:0.20377, W3:0.17524, W13:0.13983, W15:0.12921, W2:0.11471, W1:0.09576, W18:0.08948, W7:0.02262, W14:0.00767 | Grad Norm: 0.000 | Memory Gates: Short:-3.035, Long:2.436, Current:1.599
2025-03-31 02:24:42 | Step 1000 | LR: 0.00030 | Avg Loss: 26.9291 | Logits: 14.65, 37.31 | Window Weights: W8:0.20377, W3:0.17524, W13:0.13983, W15:0.12921, W2:0.11471, W1:0.09576, W18:0.08948, W7:0.02262, W14:0.00767 | Grad Norm: 0.000 | Memory Gates: Short:-3.035, Long:2.436, Current:1.599
2025-03-31 02:54:02 | Step 1100 | LR: 0.00030 | Avg Loss: 23.1185 | Logits: 16.11, 41.95 | Window Weights: W8:0.20381, W3:0.17426, W13:0.14071, W15:0.12999, W2:0.11394, W1:0.09557, W18:0.08996, W7:0.02215, W14:0.00789 | Grad Norm: 0.000 | Memory Gates: Short:-1.035, Long:-0.080, Current:2.116
2025-03-31 03:24:43 | Step 1200 | LR: 0.00030 | Avg Loss: 24.3293 | Logits: 10.52, 33.67 | Window Weights: W8:0.20385, W3:0.17388, W13:0.14083, W15:0.13003, W2:0.11391, W1:0.09576, W18:0.08996, W7:0.02239, W14:0.00767 | Grad Norm: 0.000 | Memory Gates: Short:-0.560, Long:0.148, Current:1.412
2025-03-31 03:53:50 | Step 1300 | LR: 0.00030 | Avg Loss: 25.0731 | Logits: 7.49, 35.34 | Window Weights: W8:0.20305, W3:0.17319, W13:0.14075, W15:0.13086, W2:0.11490, W1:0.09478, W18:0.09085, W7:0.02288, W14:0.00706 | Grad Norm: 0.000 | Memory Gates: Short:-1.529, Long:0.730, Current:1.799
2025-03-31 04:22:25 | Step 1400 | LR: 0.00030 | Avg Loss: 22.9657 | Logits: 8.98, 30.63 | Window Weights: W8:0.20292, W3:0.17388, W13:0.14087, W15:0.13059, W2:0.11447, W1:0.09541, W18:0.09056, W7:0.02245, W14:0.00718 | Grad Norm: 0.000 | Memory Gates: Short:-1.591, Long:0.683, Current:1.908
2025-03-31 04:50:28 | Step 1500 | LR: 0.00030 | Avg Loss: 30.1231 | Logits: 6.98, 34.13 | Window Weights: W8:0.20298, W3:0.17450, W13:0.14033, W15:0.13147, W2:0.11445, W1:0.09595, W18:0.08960, W7:0.02129, W14:0.00774 | Grad Norm: 0.000 | Memory Gates: Short:-0.296, Long:0.261, Current:1.035
2025-03-31 05:20:58 | Step 1600 | LR: 0.00030 | Avg Loss: 42.5634 | Logits: -4.88, 28.48 | Window Weights: W8:0.20394, W3:0.17508, W13:0.13970, W15:0.13123, W2:0.11516, W1:0.09552, W18:0.08957, W7:0.02136, W14:0.00674 | Grad Norm: 0.000 | Memory Gates: Short:-1.030, Long:0.937, Current:1.093
2025-03-31 05:50:12 | Step 1700 | LR: 0.00030 | Avg Loss: 24.2373 | Logits: 5.15, 26.89 | Window Weights: W8:0.20418, W3:0.17528, W13:0.13908, W15:0.13066, W2:0.11536, W1:0.09581, W18:0.08935, W7:0.02141, W14:0.00716 | Grad Norm: 0.000 | Memory Gates: Short:-1.429, Long:1.121, Current:1.308
2025-03-31 06:18:54 | Step 1800 | LR: 0.00030 | Avg Loss: 21.5837 | Logits: 4.65, 26.00 | Window Weights: W8:0.20424, W3:0.17565, W13:0.13916, W15:0.13067, W2:0.11522, W1:0.09515, W18:0.08931, W7:0.02132, W14:0.00759 | Grad Norm: 0.000 | Memory Gates: Short:-18.135, Long:-3.072, Current:22.207
2025-03-31 06:47:03 | Step 1900 | LR: 0.00030 | Avg Loss: 33.0793 | Logits: -4.83, 28.15 | Window Weights: W8:0.20391, W3:0.17728, W13:0.13801, W15:0.12983, W2:0.11544, W1:0.09524, W18:0.08855, W7:0.02122, W14:0.00885 | Grad Norm: 0.000 | Memory Gates: Short:-2.169, Long:-0.872, Current:4.041
2025-03-31 07:14:33 | Step 2009 | LR: 0.00030 | Avg Loss: 27.6982 | Logits: 5.16, 31.27 | Window Weights: W8:0.20427, W3:0.17722, W13:0.13821, W15:0.12951, W2:0.11593, W1:0.09529, W18:0.08853, W7:0.02150, W14:0.00786 | Grad Norm: 0.000 | Memory Gates: Short:-2.016, Long:-0.931, Current:3.947
2025-03-31 07:14:33 | Step 2009 | LR: 0.00030 | Avg Loss: 29.9091 | Logits: 1.45, 27.49 | Window Weights: W8:0.20427, W3:0.17722, W13:0.13821, W15:0.12951, W2:0.11593, W1:0.09529, W18:0.08853, W7:0.02150, W14:0.00786 | Grad Norm: 0.000 | Memory Gates: Short:-2.016, Long:-0.931, Current:3.947
2025-03-31 07:42:00 | Step 2099 | LR: 0.00030 | Avg Loss: 24.0502 | Logits: 3.86, 21.92 | Window Weights: W8:0.20416, W3:0.17690, W13:0.13813, W15:0.12979, W2:0.11539, W1:0.09548, W18:0.08876, W7:0.02158, W14:0.00815 | Grad Norm: 0.000 | Memory Gates: Short:-1.226, Long:-0.261, Current:2.487
2025-03-31 08:09:29 | Step 2200 | LR: 0.00030 | Avg Loss: 23.4799 | Logits: 6.88, 35.48 | Window Weights: W8:0.20443, W3:0.17845, W13:0.13735, W15:0.12875, W2:0.11552, W1:0.09572, W18:0.08800, W7:0.02104, W14:0.00906 | Grad Norm: 0.000 | Memory Gates: Short:-0.019, Long:0.056, Current:0.963
2025-03-31 08:36:55 | Step 2300 | LR: 0.00030 | Avg Loss: 25.6601 | Logits: 0.90, 26.34 | Window Weights: W8:0.20417, W3:0.17904, W13:0.13743, W15:0.12886, W2:0.11604, W1:0.09573, W18:0.08774, W7:0.02093, W14:0.00839 | Grad Norm: 0.000 | Memory Gates: Short:-0.570, Long:0.306, Current:1.264
2025-03-31 09:04:02 | Step 2400 | LR: 0.00030 | Avg Loss: 34.1403 | Logits: -0.68, 23.61 | Window Weights: W8:0.20455, W3:0.17873, W13:0.13799, W15:0.12867, W2:0.11620, W1:0.09571, W18:0.08801, W7:0.02097, W14:0.00751 | Grad Norm: 0.000 | Memory Gates: Short:-0.597, Long:0.567, Current:1.031
2025-03-31 09:31:23 | Step 2500 | LR: 0.00030 | Avg Loss: 32.4980 | Logits: 8.16, 34.44 | Window Weights: W8:0.20468, W3:0.17842, W13:0.13822, W15:0.12882, W2:0.11595, W1:0.09548, W18:0.08806, W7:0.02120, W14:0.00752 | Grad Norm: 0.000 | Memory Gates: Short:9.132, Long:-1.424, Current:-6.708
2025-03-31 09:59:04 | Step 2600 | LR: 0.00030 | Avg Loss: 29.4020 | Logits: 6.92, 27.31 | Window Weights: W8:0.20464, W3:0.17832, W13:0.13830, W15:0.12899, W2:0.11573, W1:0.09569, W18:0.08803, W7:0.02090, W14:0.00776 | Grad Norm: 0.000 | Memory Gates: Short:-1.633, Long:1.386, Current:1.247
2025-03-31 10:29:39 | Step 2700 | LR: 0.00030 | Avg Loss: 27.1714 | Logits: 4.38,22.21 | Window Weights: W8:0.20457,W3:0.17818,W13:0.13852,W15:0.12912,W2:0.11568,W1:0.09571,W18:0.08800,W7:0.02100,W14:0.00758 | Grad Norm: 1m38;5;225m0.000 | Memory Gates: Short:-0.659, Long:1.083, Current:0.576 | Top Tokens: ]
2025-03-31 10:58:09 | Step 2800 | LR: 0.00030 | Avg Loss: 27.2992 | Logits: 6.31, 24.35 | Window Weights: W8:0.20516,W3:0.17787,W13:0.13913,W15:0.12907,W2:0.11486,W1:0.09544,W18:0.08818,W7:0.02119,W14:0.00747 | Grad Norm: 1m38;5;225m0.000 | Memory Gates: Short:-0.663, Long:1.135, Current:0.528 | Top Tokens: ]
2025-03-31 11:25:52 | Step 2900 | LR: 0.00030 | Avg Loss: 28.7437 | Logits: 6.27, 26.47 | Window Weights: W8:0.20476,W3:0.17795,W13:0.13959,W15:0.12934,W2:0.11433,W1:0.09526,W18:0.08840,W7:0.02087,W14:0.00789 | Grad Norm: 1m38;5;225m0.000 | Memory Gates: Short:-1.010, Long:1.454, Current:0.555 | Top Tokens: ]
2025-03-31 11:54:12 | Step 3000 | LR: 0.00030 | Avg Loss: 33.1622 | Logits: 3.45, 24.66 | Window Weights: W8:0.20464,W3:0.17794,W13:0.13973,W15:0.12928,W2:0.11440,W1:0.09505,W18:0.08843,W7:0.02104,W14:0.00789 | Grad Norm: 1m38;5;225m0.000 | Memory Gates: Short:6.136, Long:-3.751, Current:-1.385 | Top Tokens: ]
2025-03-31 13:55:11 | Step 99.000000 | LR: 0.00030 | Avg Loss: 27.7961 | Logits: 5.19,35.63 | Window Weights: W8:0.20589,W3:0.18219,W13:0.13612,W15:0.12561,W2:0.11724,W1:0.09672,W18:0.08632,W7:0.02112,W14:0.00715 | Grad Norm: 0.000 | Memory Gates: Short:-2.703, Long:2.055, Current:1.648 | Top Tokens: []
Durations: Step: 17907.41ms, Save: 65.93ms, Load: 58.39ms, Logits: 0.13ms, Print: 0.00ms, Combine: 0.00ms, Token: 0.00ms | Training

--- 2025-03-31 14:15:18 ---
babyLLM: what am i learning today?
You: to exist!

--- 2025-03-31 14:23:10 ---
babyLLM: what am i learning today?
You: mouse is love

--- 2025-03-31 14:24:14 ---
babyLLM: what am i learning today?
You: mice is love
2025-03-31 14:52:29 | Step 100.000000 | LR: 0.00030 | Avg Loss: 34.9944 | Logits: 8.23,60.59 | Window Weights: W8:0.20688,W3:0.18464,W13:0.13570,W15:0.12352,W2:0.11721,W1:0.09854,W18:0.08394,W7:0.02203,W14:0.00579 | Grad Norm: 0.000 | Memory Gates: Short:-1.272, Long:0.543, Current:1.730 | Top Tokens: [('b', 28), ('it', 17), (',', 15), ('the', 12), ('of', 11), ('a', 11), ('p', 11), ('r', 10), ('s', 10), ('ing', 9)] | Training
2025-03-31 15:21:03 | Step 200.000000 | LR: 0.00030 | Avg Loss: 30.3336 | Logits: 9.13,29.26 | Window Weights: W8:0.20717,W3:0.18418,W13:0.13600,W15:0.12347,W2:0.11708,W1:0.09821,W18:0.08426,W7:0.02184,W14:0.00606 | Grad Norm: 0.000 | Memory Gates: Short:-11.939, Long:5.115, Current:7.825 | Top Tokens: [(',', 99), ('b', 44), ('e', 37), ('er', 26), ('right', 15), ('were', 12), ('ur', 9), ('little', 7), ('the', 6), ('ul', 6)] | Training
2025-03-31 15:50:49 | Step 300.000000 | LR: 0.00030 | Avg Loss: 29.0962 | Logits: 6.42,26.93 | Window Weights: W8:0.20678,W3:0.18418,W13:0.13618,W15:0.12357,W2:0.11733,W1:0.09810,W18:0.08476,W7:0.02148,W14:0.00588 | Grad Norm: 0.000 | Memory Gates: Short:-3.013, Long:1.909, Current:2.104 | Top Tokens: [(',', 50), ('e', 48), ('b', 25), ('er', 25), ('a', 15), ('them', 13), ('ur', 11), ('were', 10), ('ly', 10), ('.', 8)] | Training
2025-03-31 16:21:29 | Step 400.000000 | LR: 0.00030 | Avg Loss: 28.9852 | Logits: 5.22,21.47 | Window Weights: W8:0.20682,W3:0.18399,W13:0.13638,W15:0.12358,W2:0.11734,W1:0.09784,W18:0.08509,W7:0.02140,W14:0.00584 | Grad Norm: 0.000 | Memory Gates: Short:-2.216, Long:2.540, Current:0.677 | Top Tokens: [(',', 85), ('b', 39), ('er', 29), ('as', 22), ('a', 18), ('were', 18), ('little', 12), ('-', 12), ('her', 9), ('m', 7)] | Training
2025-03-31 16:52:46 | Step 500.000000 | LR: 0.00030 | Avg Loss: 32.4108 | Logits: 2.62,23.43 | Window Weights: W8:0.20699,W3:0.18402,W13:0.13638,W15:0.12360,W2:0.11726,W1:0.09785,W18:0.08505,W7:0.02117,W14:0.00595 | Grad Norm: 0.000 | Memory Gates: Short:-1.953, Long:2.469, Current:0.484 | Top Tokens: [('b', 68), ('er', 32), ('the', 24), (',', 19), ('-', 15), ('were', 11), ('m', 11), ('of', 10), ('e', 8), ('feel', 7)] | Training
2025-03-31 17:22:26 | Step 600.000000 | LR: 0.00030 | Avg Loss: 26.3216 | Logits: 2.57,18.39 | Window Weights: W8:0.20711,W3:0.18425,W13:0.13668,W15:0.12371,W2:0.11689,W1:0.09757,W18:0.08522,W7:0.02053,W14:0.00631 | Grad Norm: 0.000 | Memory Gates: Short:-3.133, Long:2.752, Current:1.382 | Top Tokens: [('a', 45), ('b', 29), ('the', 23), (',', 23), ('were', 20), ('er', 17), ('m', 13), ('y', 8), ('-', 7), ('as', 7)] | Training
2025-03-31 17:52:37 | Step 700.000000 | LR: 0.00030 | Avg Loss: 24.6387 | Logits: 6.27,20.41 | Window Weights: W8:0.20692,W3:0.18344,W13:0.13695,W15:0.12378,W2:0.11667,W1:0.09755,W18:0.08565,W7:0.02078,W14:0.00657 | Grad Norm: 0.000 | Memory Gates: Short:-4.666, Long:5.577, Current:0.089 | Top Tokens: [('ing', 87), ('were', 33), (',', 31), ('b', 30), ('ly', 25), ('a', 21), ('er', 12), ('the', 11), ('y', 8), ('e', 7)] | Training
2025-03-31 18:22:40 | Step 800.000000 | LR: 0.00030 | Avg Loss: 28.4055 | Logits: 6.17,23.43 | Window Weights: W8:0.20692,W3:0.18371,W13:0.13673,W15:0.12384,W2:0.11674,W1:0.09744,W18:0.08551,W7:0.02007,W14:0.00734 | Grad Norm: 0.000 | Memory Gates: Short:5.244, Long:-4.172, Current:-0.072 | Top Tokens: [('ing', 99), ('b', 40), (',', 25), ('were', 20), ('was', 14), ('m', 12), ('ly', 11), ('ul', 10), ('on', 9), ('the', 7)] | Training

--- 2025-03-31 18:34:47 ---
babyLLM: what am i learning today?
You: how to log
2025-03-31 18:55:10 | Step 900.000000 | LR: 0.00030 | Avg Loss: 34.2171 | Logits: 0.46,21.06 | Window Weights: W8:0.20683,W3:0.18359,W13:0.13678,W15:0.12376,W2:0.11635,W1:0.09765,W18:0.08539,W7:0.02020,W14:0.00776 | Grad Norm: 0.000 | Memory Gates: Short:-2.781, Long:3.012, Current:0.769 | Top Tokens: [('b', 59), (',', 30), ('the', 30), ('and', 24), ('ing', 16), ('feel', 15), ('were', 13), ('ed', 11), ('er', 9), ('y', 9)] | Training
2025-03-31 19:27:08 | Step 1000.000000 | LR: 0.00030 | Avg Loss: 30.0876 | Logits: 1.12,18.43 | Window Weights: W8:0.20684,W3:0.18344,W13:0.13686,W15:0.12374,W2:0.11595,W1:0.09767,W18:0.08553,W7:0.02035,W14:0.00794 | Grad Norm: 0.000 | Memory Gates: Short:-1.993, Long:1.961, Current:1.031 | Top Tokens: [('b', 58), (',', 41), ('the', 29), ('and', 29), ('it', 22), ('ing', 19), ('-', 19), ('were', 16), ('music', 12), ('of', 8)] | Training
2025-03-31 19:56:02 | Step 1100.000000 | LR: 0.00030 | Avg Loss: 31.6498 | Logits: -1.00,18.93 | Window Weights: W8:0.20741,W3:0.18350,W13:0.13617,W15:0.12366,W2:0.11610,W1:0.09801,W18:0.08473,W7:0.02017,W14:0.00855 | Grad Norm: 0.000 | Memory Gates: Short:-2.415, Long:2.003, Current:1.412 | Top Tokens: [(',', 36), ('was', 34), ('b', 31), ('and', 19), ('a', 19), ('w', 17), ('s', 15), ('e', 14), ('the', 13), ('of', 12)] | Training
2025-03-31 20:26:36 | Step 1200.000000 | LR: 0.00030 | Avg Loss: 31.5549 | Logits: -2.18,16.22 | Window Weights: W8:0.20726,W3:0.18337,W13:0.13605,W15:0.12366,W2:0.11638,W1:0.09806,W18:0.08472,W7:0.02000,W14:0.00881 | Grad Norm: 0.000 | Memory Gates: Short:15.043, Long:-14.322, Current:0.279 | Top Tokens: [('and', 71), ('b', 53), ('as', 38), (',', 34), ('they', 31), ('were', 22), ('feel', 8), ('them', 7), ('in', 5), ('u', 5)] | Training
2025-03-31 20:57:11 | Step 1300.000000 | LR: 0.00030 | Avg Loss: 25.5835 | Logits: 7.07,23.25 | Window Weights: W8:0.20721,W3:0.18342,W13:0.13632,W15:0.12362,W2:0.11652,W1:0.09837,W18:0.08410,W7:0.01945,W14:0.00930 | Grad Norm: 0.000 | Memory Gates: Short:-58.361, Long:40.001, Current:19.360 | Top Tokens: [(',', 60), ('as', 55), ('b', 42), ('and', 19), ('of', 18), ('were', 17), ('they', 17), ('about', 13), ('a', 8), ('their', 7)] | Training
2025-03-31 21:51:16 | Step 1400.000000 | LR: 0.00030 | Avg Loss: 23.8158 | Logits: 5.12,20.43 | Window Weights: W8:0.20691,W3:0.18345,W13:0.13692,W15:0.12388,W2:0.11611,W1:0.09805,W18:0.08477,W7:0.01915,W14:0.00908 | Grad Norm: 0.000 | Memory Gates: Short:-6.479, Long:6.844, Current:0.635 | Top Tokens: [(',', 125), ('the', 68), ('b', 22), ('and', 12), ('were', 8), ('a', 8), ('as', 8), ('ed', 7), ('as', 5), ('was', 5)] | Training
2025-03-31 22:20:52 | Step 1500.000000 | LR: 0.00030 | Avg Loss: 28.7619 | Logits: 3.81,21.79 | Window Weights: W8:0.20695,W3:0.18295,W13:0.13692,W15:0.12391,W2:0.11604,W1:0.09816,W18:0.08499,W7:0.01933,W14:0.00908 | Grad Norm: 0.000 | Memory Gates: Short:-6.463, Long:5.119, Current:2.344 | Top Tokens: [(',', 68), ('b', 47), ('the', 38), ('were', 19), ('in', 18), ('and', 16), ('!', 15), ('.', 13), ('ed', 6), ('they', 6)] | Training
2025-03-31 22:52:00 | Step 1600.000000 | LR: 0.00030 | Avg Loss: 22.7032 | Logits: 3.64,18.53 | Window Weights: W8:0.20668,W3:0.18167,W13:0.13766,W15:0.12407,W2:0.11559,W1:0.09862,W18:0.08690,W7:0.01935,W14:0.00782 | Grad Norm: 0.000 | Memory Gates: Short:-2.131, Long:2.109, Current:1.022 | Top Tokens: [(',', 103), ('the', 53), ('ed', 26), ('s', 23), ('she', 14), ('b', 11), ('and', 10), ('were', 10), ('that', 6), ('but', 6)] | Training
2025-03-31 23:24:12 | Step 1700.000000 | LR: 0.00030 | Avg Loss: 28.0086 | Logits: 1.60,20.28 | Window Weights: W8:0.20682,W3:0.18145,W13:0.13775,W15:0.12426,W2:0.11511,W1:0.09881,W18:0.08726,W7:0.01883,W14:0.00808 | Grad Norm: 0.000 | Memory Gates: Short:-5.890, Long:5.124, Current:1.766 | Top Tokens: [('b', 49), ('r', 28), ('e', 24), ('ed', 21), (',', 19), ('had', 16), ('it', 15), ('the', 14), ('were', 13), ('s', 11)] | Training
2025-03-31 23:56:01 | Step 1800.000000 | LR: 0.00030 | Avg Loss: 27.5225 | Logits: -1.55,15.47 | Window Weights: W8:0.20664,W3:0.18138,W13:0.13732,W15:0.12401,W2:0.11545,W1:0.09856,W18:0.08694,W7:0.01886,W14:0.00922 | Grad Norm: 0.000 | Memory Gates: Short:15.545, Long:-8.925, Current:-5.621 | Top Tokens: [(',', 40), ('b', 39), ('ed', 37), ('.', 15), ('and', 14), ('were', 13), ('f', 13), ('a', 13), ('for', 13), ('r', 11)] | Training
2025-04-01 00:27:53 | Step 1900.000000 | LR: 0.00030 | Avg Loss: 26.7049 | Logits: 0.10,18.79 | Window Weights: W8:0.20651,W3:0.18150,W13:0.13779,W15:0.12408,W2:0.11518,W1:0.09845,W18:0.08715,W7:0.01828,W14:0.00943 | Grad Norm: 0.000 | Memory Gates: Short:-5.752, Long:4.824, Current:1.928 | Top Tokens: [(',', 56), ('b', 38), ('and', 23), ('were', 22), ('that', 17), ('in', 14), ('a', 12), ('ed', 9), ('m', 9), ('ly', 8)] | Training
2025-04-01 00:57:38 | Step 2000.000000 | LR: 0.00030 | Avg Loss: 23.1832 | Logits: -0.91,12.57 | Window Weights: W8:0.20631,W3:0.18145,W13:0.13823,W15:0.12434,W2:0.11511,W1:0.09809,W18:0.08787,W7:0.01847,W14:0.00853 | Grad Norm: 0.000 | Memory Gates: Short:-7.709, Long:5.782, Current:2.926 | Top Tokens: [(',', 73), ('b', 44), ('a', 33), ('and', 28), ('in', 14), ('that', 13), ('i', 12), ('m', 10), ('!', 10), ('ing', 6)] | Training
2025-04-01 01:27:59 | Step 2100.000000 | LR: 0.00030 | Avg Loss: 22.1812 | Logits: -1.20,14.55 | Window Weights: W8:0.20631,W3:0.18113,W13:0.13834,W15:0.12439,W2:0.11505,W1:0.09889,W18:0.08767,W7:0.01745,W14:0.00915 | Grad Norm: 0.000 | Memory Gates: Short:-1.936, Long:1.401, Current:1.535 | Top Tokens: [(',', 52), ('that', 33), ('b', 28), ('a', 23), ('and', 21), ('ice', 14), ('up', 14), ('i', 13), ('b', 12), ('.', 11)] | Training
2025-04-01 01:58:24 | Step 2200.000000 | LR: 0.00030 | Avg Loss: 23.5892 | Logits: -2.04,14.40 | Window Weights: W8:0.20678,W3:0.18027,W13:0.13907,W15:0.12431,W2:0.11291,W1:0.09928,W18:0.08855,W7:0.01757,W14:0.00965 | Grad Norm: 0.000 | Memory Gates: Short:-2.409, Long:2.180, Current:1.228 | Top Tokens: [(',', 86), ('for', 29), ('a', 28), ('b', 23), ('the', 15), ('and', 14), ('y', 10), ('of', 10), ('now', 9), ('w', 8)] | Training
2025-04-01 02:29:17 | Step 2300.000000 | LR: 0.00030 | Avg Loss: 28.7332 | Logits: -0.61,19.63 | Window Weights: W8:0.20717,W3:0.17992,W13:0.13911,W15:0.12440,W2:0.11231,W1:0.09915,W18:0.08859,W7:0.01776,W14:0.01001 | Grad Norm: 0.000 | Memory Gates: Short:-8.582, Long:7.529, Current:2.053 | Top Tokens: [(',', 71), ('a', 36), ('b', 28), ('for', 22), ('y', 13), ('ong', 12), ('ed', 11), ('were', 10), ('.', 9), ('but', 7)] | Training
2025-04-01 02:57:49 | Step 2400.000000 | LR: 0.00030 | Avg Loss: 19.2709 | Logits: -1.75,14.32 | Window Weights: W8:0.20681,W3:0.17940,W13:0.13907,W15:0.12431,W2:0.11266,W1:0.09972,W18:0.08851,W7:0.01786,W14:0.01008 | Grad Norm: 0.000 | Memory Gates: Short:-3.514, Long:2.270, Current:2.245 | Top Tokens: [(',', 103), ('!', 26), ('a', 23), ('b', 17), ('and', 16), ('at', 16), ('m', 12), ('for', 11), ('were', 10), ('.', 10)] | Training
2025-04-01 03:26:34 | Step 2500.000000 | LR: 0.00030 | Avg Loss: 32.7150 | Logits: -0.39,19.94 | Window Weights: W8:0.20666,W3:0.17870,W13:0.13966,W15:0.12464,W2:0.11225,W1:0.09812,W18:0.09003,W7:0.01930,W14:0.00915 | Grad Norm: 0.000 | Memory Gates: Short:18.354, Long:-13.230, Current:-4.124 | Top Tokens: [('she', 53), (',', 34), ('was', 33), ('now', 27), ('b', 25), ('were', 24), ('in', 18), ('to', 13), ('p', 11), ('and', 7)] | Training
2025-04-01 03:55:46 | Step 2600.000000 | LR: 0.00030 | Avg Loss: 31.8719 | Logits: -3.37,16.13 | Window Weights: W8:0.20626,W3:0.17845,W13:0.13969,W15:0.12471,W2:0.11261,W1:0.09823,W18:0.09042,W7:0.01905,W14:0.00911 | Grad Norm: 0.000 | Memory Gates: Short:-3.503, Long:2.732, Current:1.771 | Top Tokens: [('b', 51), (',', 41), ('her', 27), ('y', 25), ('she', 21), ('c', 13), ('for', 10), ('on', 10), ('feel', 9), ('er', 8)] | Training
2025-04-01 04:24:59 | Step 2700.000000 | LR: 0.00030 | Avg Loss: 28.2862 | Logits: -3.85,15.94 | Window Weights: W8:0.20584,W3:0.17599,W13:0.14059,W15:0.12523,W2:0.11279,W1:0.09729,W18:0.09201,W7:0.01911,W14:0.00972 | Grad Norm: 0.000 | Memory Gates: Short:-3.235, Long:3.092, Current:1.143 | Top Tokens: [(',', 41), ('b', 41), ('she', 30), ('and', 26), ('f', 20), ('to', 18), ('in', 18), ('was', 17), ('ri', 14), ('.', 8)] | Training
2025-04-01 05:00:18 | Step 2800.000000 | LR: 0.00030 | Avg Loss: 31.1307 | Logits: -6.76,12.54 | Window Weights: W8:0.20611,W3:0.17663,W13:0.14010,W15:0.12498,W2:0.11293,W1:0.09720,W18:0.09152,W7:0.01911,W14:0.00998 | Grad Norm: 0.000 | Memory Gates: Short:-2.667, Long:2.511, Current:1.156 | Top Tokens: [('b', 40), (',', 39), ('in', 22), ('and', 22), ('were', 20), ('them', 19), ('she', 15), ('was', 13), ('f', 12), ('to', 12)] | Training
2025-04-01 05:29:17 | Step 2900.000000 | LR: 0.00030 | Avg Loss: 30.6358 | Logits: -4.84,14.53 | Window Weights: W8:0.20590,W3:0.17658,W13:0.14024,W15:0.12530,W2:0.11288,W1:0.09686,W18:0.09205,W7:0.01884,W14:0.00994 | Grad Norm: 0.000 | Memory Gates: Short:-3.977, Long:3.433, Current:1.544 | Top Tokens: [('were', 47), ('in', 46), ('b', 38), ('.', 27), (',', 21), ('to', 20), ('a', 13), ('and', 12), ('in', 10), ('them', 7)] | Training
2025-04-01 05:58:30 | Step 3000.000000 | LR: 0.00030 | Avg Loss: 26.0210 | Logits: -0.41,15.53 | Window Weights: W8:0.20645,W3:0.17669,W13:0.13987,W15:0.12483,W2:0.11333,W1:0.09647,W18:0.09158,W7:0.01863,W14:0.01074 | Grad Norm: 0.000 | Memory Gates: Short:-9.931, Long:8.304, Current:2.627 | Top Tokens: [(',', 44), ('that', 42), ('to', 34), ('b', 29), ('.', 17), ('she', 16), ('were', 15), ('a', 15), ('ow', 12), ('her', 11)] | Training
2025-04-01 06:27:46 | Step 3100.000000 | LR: 0.00030 | Avg Loss: 35.5288 | Logits: -2.59,21.70 | Window Weights: W8:0.20822,W3:0.17518,W13:0.14105,W15:0.12532,W2:0.11251,W1:0.09546,W18:0.09184,W7:0.01778,W14:0.01125 | Grad Norm: 0.000 | Memory Gates: Short:-2.129, Long:2.580, Current:0.549 | Top Tokens: [('a', 46), ('b', 32), ('p', 30), ('were', 26), (',', 21), ('the', 19), ('al', 19), ('to', 13), ('them', 8), ('i', 8)] | Training
2025-04-01 06:56:36 | Step 3200.000000 | LR: 0.00030 | Avg Loss: 27.8488 | Logits: -0.36,17.63 | Window Weights: W8:0.20806,W3:0.17523,W13:0.14128,W15:0.12549,W2:0.11248,W1:0.09470,W18:0.09199,W7:0.01792,W14:0.01148 | Grad Norm: 0.000 | Memory Gates: Short:-8.516, Long:7.706, Current:1.810 | Top Tokens: [('b', 41), ('p', 38), ('a', 38), (',', 29), ('ve', 23), ('al', 22), ('were', 15), ('the', 14), ('that', 9), ('r', 7)] | Training
2025-04-01 07:25:17 | Step 3300.000000 | LR: 0.00030 | Avg Loss: 35.9077 | Logits: -2.85,22.66 | Window Weights: W8:0.20808,W3:0.17594,W13:0.14077,W15:0.12522,W2:0.11206,W1:0.09535,W18:0.09164,W7:0.01684,W14:0.01271 | Grad Norm: 0.000 | Memory Gates: Short:25.019, Long:-14.333, Current:-9.686 | Top Tokens: [('b', 47), (',', 46), ('were', 26), ('the', 21), ('for', 21), ('id', 12), ('to', 12), ('and', 11), ('y', 10), ('i', 8)] | Training
2025-04-01 07:53:43 | Step 3400.000000 | LR: 0.00030 | Avg Loss: 27.7057 | Logits: 0.82,19.41 | Window Weights: W8:0.20796,W3:0.17584,W13:0.14168,W15:0.12610,W2:0.11030,W1:0.09547,W18:0.09212,W7:0.01679,W14:0.01239 | Grad Norm: 0.000 | Memory Gates: Short:-3.862, Long:3.997, Current:0.865 | Top Tokens: [('she', 54), ('the', 42), ('for', 37), (',', 34), ('b', 27), ('p', 13), ('that', 13), ('had', 10), ('and', 9), ('.', 8)] | Training
2025-04-01 08:22:14 | Step 3500.000000 | LR: 0.00030 | Avg Loss: 23.4227 | Logits: -4.33,12.54 | Window Weights: W8:0.20816,W3:0.17590,W13:0.14160,W15:0.12636,W2:0.11002,W1:0.09481,W18:0.09284,W7:0.01686,W14:0.01211 | Grad Norm: 0.000 | Memory Gates: Short:-11.382, Long:8.718, Current:3.664 | Top Tokens: [(',', 43), ('b', 38), ('she', 36), ('the', 34), ('in', 20), ('to', 19), ('were', 10), ('that', 8), ('had', 8), ('.', 8)] | Training
2025-04-01 08:51:21 | Step 3600.000000 | LR: 0.00030 | Avg Loss: 31.9527 | Logits: 1.29,19.98 | Window Weights: W8:0.20858,W3:0.17578,W13:0.14169,W15:0.12621,W2:0.11035,W1:0.09445,W18:0.09251,W7:0.01652,W14:0.01256 | Grad Norm: 0.000 | Memory Gates: Short:-3.660, Long:3.667, Current:0.994 | Top Tokens: [(',', 63), ('b', 33), ('n', 28), ('she', 23), ('to', 20), ('of', 16), ('were', 14), ('and', 11), ('the', 10), ('ul', 9)] | Training
2025-04-01 09:20:28 | Step 3700.000000 | LR: 0.00030 | Avg Loss: 29.8548 | Logits: -2.63,14.52 | Window Weights: W8:0.20896,W3:0.17609,W13:0.14141,W15:0.12591,W2:0.11102,W1:0.09375,W18:0.09205,W7:0.01590,W14:0.01356 | Grad Norm: 0.000 | Memory Gates: Short:-7.895, Long:7.131, Current:1.764 | Top Tokens: [('you', 52), (',', 42), ('b', 33), ('were', 24), ('ed', 19), ('they', 18), ('and', 15), ('she', 12), ('the', 11), ('a', 9)] | Training
2025-04-01 09:50:07 | Step 3800.000000 | LR: 0.00030 | Avg Loss: 28.3063 | Logits: -3.37,13.69 | Window Weights: W8:0.20992,W3:0.17569,W13:0.14111,W15:0.12556,W2:0.11097,W1:0.09336,W18:0.09145,W7:0.01597,W14:0.01459 | Grad Norm: 0.000 | Memory Gates: Short:-10.629, Long:8.837, Current:2.792 | Top Tokens: [('y', 51), ('b', 36), ('the', 35), (',', 23), ('.', 21), ('a', 17), ('o', 17), ('and', 14), ('were', 12), ('est', 11)] | Training
2025-04-01 10:21:11 | Step 3900.000000 | LR: 0.00030 | Avg Loss: 32.2513 | Logits: -1.87,15.17 | Window Weights: W8:0.21031,W3:0.17491,W13:0.14151,W15:0.12572,W2:0.11086,W1:0.09311,W18:0.09197,W7:0.01591,W14:0.01436 | Grad Norm: 0.000 | Memory Gates: Short:35.117, Long:-32.390, Current:-1.727 | Top Tokens: [('the', 107), ('b', 32), ('.', 16), ('were', 14), (',', 14), ('a', 12), ('y', 9), ('she', 8), ('p', 8), ('to', 8)] | Training
2025-04-01 10:57:42 | Step 4000.000000 | LR: 0.00030 | Avg Loss: 25.2712 | Logits: -1.99,13.59 | Window Weights: W8:0.21026,W3:0.17502,W13:0.14157,W15:0.12596,W2:0.11042,W1:0.09336,W18:0.09176,W7:0.01551,W14:0.01479 | Grad Norm: 0.000 | Memory Gates: Short:-5.048, Long:4.616, Current:1.433 | Top Tokens: [('the', 55), ('.', 49), ('b', 21), ('were', 20), ('to', 19), (',', 18), ('m', 10), ('and', 9), ('not', 8), ('y', 7)] | Training

--- 2025-04-01 12:06:06 ---
babyLLM: what am i learning today?
You: seeing if batching works
2025-04-02 13:21:30 | 100 | LR0.0003 | loss38.0495 | gradNorm1.0000 | logitMin-31.8468 | logitMax-10.7003 | memoryGate0.3333 | scheduledSampling0.0000 | tokenCount300windowWeightsW8:0.20817,W3:0.16149,W13:0.15545,W15:0.14173,W18:0.11037,W2:0.09007,W1:0.06950,W7:0.05258,W14:-0.00938 | topTokens[('at', 45), ('in', 44), ('least', 12), ('feel', 10), ('it', 7), ('that', 6), ('r', 4), ('ice', 4), ('b', 4), ('.', 4)] |  | Training
2025-04-02 13:33:31 | 100 | LR0.0003 | loss33.3241 | gradNorm1.0000 | logitMin-35.1344 | logitMax-14.3808 | memoryGate0.3333 | scheduledSampling0.0000 | tokenCount300 | windowWeightsW8:0.20887,W13:0.15891,W3:0.15735,W15:0.14591,W18:0.11358,W2:0.08671,W1:0.06621,W7:0.05314,W14:-0.01056 | topTokens[('the', 16), ('it', 11), ('in', 10), ('that', 9), ('.', 8), (',', 8), ('this', 7), ('be', 7), ("'s", 6), ('my', 6)] | Training
2025-04-02 13:38:43 | 200 | LR0.0003 | loss23.7660 | gradNorm1.0000 | tokenCount300 | logitMin-28.9950 | logitMax-15.9579 | memoryGate0.3333 | windowWeightsW8:0.20930,W13:0.15932,W3:0.15630,W15:0.14628,W18:0.11431,W2:0.08523,W1:0.06481,W7:0.05464,W14:-0.01005 | topTokens[('the', 17), ('.', 11), ('it', 9), ('a', 8), ("'s", 7), ('work', 5), (',', 4), ('them', 4), ('b', 4), ('in', 4)] | Training
2025-04-02 13:43:42 | 300 | LR0.0003 | loss27.1185 | gradNorm1.0000 | tokenCount300 | logitMin-32.7195 | logitMax-15.7146 | memoryGate0.3333 | windowWeightsW8:0.20863,W13:0.16015,W3:0.15512,W15:0.14667,W18:0.11533,W2:0.08498,W1:0.06418,W7:0.05514,W14:-0.01004 | topTokens[('with', 16), ('.', 15), ('that', 7), ('the', 7), (',', 6), ('it', 6), ('feel', 5), ('to', 5), ('l', 4), ('ed', 3)] | Training
2025-04-02 13:48:52 | 400 | LR0.0003 | loss30.0372 | gradNorm1.0000 | tokenCount300 | logitMin-32.5470 | logitMax-14.5977 | memoryGate0.3333 | windowWeightsW8:0.20858,W13:0.16052,W3:0.15397,W15:0.14713,W18:0.11541,W2:0.08489,W1:0.06417,W7:0.05531,W14:-0.00984 | topTokens[('.', 11), ('l', 9), ('in', 9), ('with', 7), ('e', 7), ('is', 7), ('i', 7), ('because', 4), ('them', 4), ('in', 4)] | Training
2025-04-02 13:54:05 | 500 | LR0.0003 | loss24.3354 | gradNorm1.0000 | tokenCount300 | logitMin-34.2293 | logitMax-19.6714 | memoryGate0.3333 | windowWeightsW8:0.20812,W13:0.16061,W3:0.15374,W15:0.14704,W18:0.11552,W2:0.08455,W1:0.06417,W7:0.05599,W14:-0.00959 | topTokens[('i', 14), ('.', 6), ('to', 6), ('be', 6), ('ent', 5), ('in', 5), ('i', 5), ('know', 5), ('feel', 4), ('is', 4)] | Training
2025-04-02 13:59:15 | 600 | LR0.0003 | loss27.7221 | gradNorm1.0000 | tokenCount300 | logitMin-33.6965 | logitMax-17.3941 | memoryGate0.3333 | windowWeightsW8:0.20964,W13:0.16004,W3:0.15324,W15:0.14679,W18:0.11514,W2:0.08469,W1:0.06339,W7:0.05593,W14:-0.00872 | topTokens[('it', 20), ('!', 15), (',', 7), ('just', 7), ('ut', 6), ('want', 6), ('in', 5), ('i', 4), ('u', 4), ('were', 4)] | Training
2025-04-02 14:04:28 | 700 | LR0.0003 | loss24.5812 | gradNorm1.0000 | tokenCount300 | logitMin-37.8171 | logitMax-23.1655 | memoryGate0.3332 | windowWeightsW8:0.20917,W13:0.16094,W3:0.15263,W15:0.14739,W18:0.11516,W2:0.08448,W1:0.06280,W7:0.05620,W14:-0.00862 | topTokens[('it', 19), (',', 11), ('in', 8), ('s', 7), ('my', 7), ('in', 6), ('l', 6), ('to', 5), ('me', 4), ('n', 4)] | Training
2025-04-02 14:09:42 | 800 | LR0.0003 | loss32.5342 | gradNorm1.0000 | tokenCount300 | logitMin-36.4659 | logitMax-17.5794 | memoryGate0.3333 | windowWeightsW8:0.20834,W13:0.16157,W3:0.15222,W15:0.14797,W18:0.11562,W2:0.08454,W1:0.06177,W7:0.05664,W14:-0.00849 | topTokens[('in', 36), ('p', 22), ('my', 7), ('a', 5), ('it', 5), ('ly', 4), ('is', 4), ('in', 4), ('w', 4), ('that', 3)] | Training
2025-04-02 14:14:56 | 900 | LR0.0003 | loss30.1113 | gradNorm1.0000 | tokenCount300 | logitMin-32.7695 | logitMax-17.3310 | memoryGate0.3333 | windowWeightsW8:0.20858,W13:0.16144,W3:0.15237,W15:0.14787,W18:0.11584,W2:0.08492,W1:0.06201,W7:0.05613,W14:-0.00899 | topTokens[('in', 18), ('be', 9), ('p', 8), ('of', 8), ('with', 6), ('lo', 5), ('it', 5), ('that', 4), (',', 4), ('b', 3)] | Training
2025-04-02 14:20:18 | 1000 | LR0.0003 | loss28.6931 | gradNorm1.0000 | tokenCount300 | logitMin-32.0339 | logitMax-15.0241 | memoryGate0.3333 | windowWeightsW8:0.20840,W13:0.16078,W3:0.15295,W15:0.14731,W18:0.11562,W2:0.08515,W1:0.06240,W7:0.05634,W14:-0.00879 | topTokens[('in', 9), ('them', 7), ('were', 6), ('a', 5), ('with', 5), ('p', 5), ("'s", 4), ('be', 4), ('f', 4), ('t', 4)] | Training
2025-04-02 14:25:33 | 1100 | LR0.0003 | loss32.3904 | gradNorm1.0000 | tokenCount300 | logitMin-30.3957 | logitMax-11.7624 | memoryGate0.3333 | windowWeightsW8:0.20881,W13:0.16062,W3:0.15264,W15:0.14710,W18:0.11545,W2:0.08485,W1:0.06278,W7:0.05633,W14:-0.00842 | topTokens[('ed', 43), ('in', 20), ('the', 18), ('ro', 6), ('in', 5), ('some', 5), ('because', 5), ('.', 5), ('had', 4), ('am', 4)] | Training
2025-04-02 14:30:49 | 1200 | LR0.0003 | loss29.6624 | gradNorm1.0000 | tokenCount300 | logitMin-37.6006 | logitMax-18.9916 | memoryGate0.3333 | windowWeightsW8:0.20873,W13:0.16082,W3:0.15251,W15:0.14720,W18:0.11568,W2:0.08459,W1:0.06270,W7:0.05653,W14:-0.00862 | topTokens[('in', 28), ('the', 19), ('ed', 16), ('ro', 10), ('t', 8), ('it', 5), ('were', 5), (',', 4), ('b', 4), ('a', 4)] | Training
2025-04-02 14:36:06 | 1300 | LR0.0003 | loss28.3787 | gradNorm1.0000 | tokenCount300 | logitMin-33.3455 | logitMax-17.0340 | memoryGate0.3333 | windowWeightsW8:0.20868,W13:0.16113,W3:0.15129,W15:0.14770,W18:0.11648,W2:0.08433,W1:0.06271,W7:0.05717,W14:-0.00931 | topTokens[('t', 9), ('ed', 7), ('.', 7), ('feel', 6), ('the', 5), ('be', 5), ('my', 5), ('ro', 5), ('is', 5), ('', 5)] | Training
2025-04-02 14:41:22 | 1400 | LR0.0003 | loss28.6613 | gradNorm1.0000 | tokenCount300 | logitMin-36.3528 | logitMax-18.8284 | memoryGate0.3333 | windowWeightsW8:0.20863,W13:0.16121,W3:0.15123,W15:0.14784,W18:0.11671,W2:0.08391,W1:0.06269,W7:0.05738,W14:-0.00941 | topTokens[('t', 12), ('be', 9), ('b', 7), ('ro', 7), ('p', 7), ('in', 6), ('car', 6), ('my', 6), ('that', 6), ('', 5)] | Training
2025-04-02 14:46:40 | 1500 | LR0.0003 | loss28.1487 | gradNorm1.0000 | tokenCount300 | logitMin-34.5025 | logitMax-18.0467 | memoryGate0.3333 | windowWeightsW8:0.20849,W13:0.16123,W3:0.15065,W15:0.14786,W18:0.11693,W2:0.08411,W1:0.06256,W7:0.05801,W14:-0.00964 | topTokens[('my', 23), ('t', 8), ('is', 6), ('the', 6), ('ro', 5), (',', 5), ('in', 5), ("'m", 4), ('is', 3), ('p', 3)] | Training
2025-04-02 14:51:55 | 1600 | LR0.0003 | loss25.9483 | gradNorm1.0000 | tokenCount300 | logitMin-32.2920 | logitMax-15.7337 | memoryGate0.3333 | windowWeightsW8:0.20740,W13:0.16203,W3:0.15162,W15:0.14845,W18:0.11816,W2:0.08281,W1:0.06155,W7:0.05869,W14:-0.01045 | topTokens[('or', 15), ('with', 11), (',', 10), ('the', 8), ('in', 7), ('my', 6), ('i', 6), ('.', 5), ('feel', 5), ('in', 5)] | Training
2025-04-02 14:57:12 | 1700 | LR0.0003 | loss27.4215 | gradNorm1.0000 | tokenCount300 | logitMin-35.0357 | logitMax-16.8065 | memoryGate0.3333 | windowWeightsW8:0.20883,W13:0.16224,W3:0.15177,W15:0.14802,W18:0.11746,W2:0.08301,W1:0.06106,W7:0.05843,W14:-0.01057 | topTokens[('with', 15), ('.', 11), ('do', 10), ('and', 9), ('my', 8), ('t', 8), ('to', 7), ('ed', 7), ('the', 4), ('a', 4)] | Training
2025-04-02 15:02:28 | 1800 | LR0.0003 | loss25.4312 | gradNorm1.0000 | tokenCount300 | logitMin-31.7543 | logitMax-15.5567 | memoryGate0.3333 | windowWeightsW8:0.20877,W13:0.16248,W3:0.15172,W15:0.14809,W18:0.11742,W2:0.08270,W1:0.06235,W7:0.05757,W14:-0.01087 | topTokens[('lo', 19), ('my', 12), ('l', 11), ('ed', 8), ('this', 8), ('to', 8), ('in', 7), ('as', 7), ('t', 6), ('.', 6)] | Training
2025-04-02 15:07:46 | 1900 | LR0.0003 | loss29.8388 | gradNorm1.0000 | tokenCount300 | logitMin-28.6835 | logitMax-13.2177 | memoryGate0.3333 | windowWeightsW8:0.20880,W13:0.16257,W3:0.15155,W15:0.14826,W18:0.11753,W2:0.08239,W1:0.06221,W7:0.05792,W14:-0.01100 | topTokens[('l', 52), ('lo', 42), ('but', 7), ('.', 4), ('a', 4), ('b', 4), (',', 3), ('had', 3), ('in', 3), ('-', 3)] | Training
2025-04-02 15:13:04 | 2000 | LR0.0003 | loss34.1999 | gradNorm1.0000 | tokenCount300 | logitMin-31.6329 | logitMax-10.7356 | memoryGate0.3333 | windowWeightsW8:0.20939,W13:0.16169,W3:0.15198,W15:0.14767,W18:0.11721,W2:0.08289,W1:0.06234,W7:0.05855,W14:-0.01148 | topTokens[('lo', 38), ('l', 37), ('be', 5), ('.', 5), ('feel', 5), ('them', 5), ('but', 4), ('just', 4), (',', 4), ('this', 4)] | Training
2025-04-02 15:18:25 | 2100 | LR0.0003 | loss26.1353 | gradNorm1.0000 | tokenCount300 | logitMin-29.1081 | logitMax-13.8322 | memoryGate0.3333 | windowWeightsW8:0.20935,W13:0.16159,W3:0.15169,W15:0.14761,W18:0.11725,W2:0.08244,W1:0.06268,W7:0.05921,W14:-0.01158 | topTokens[('is', 10), ('i', 10), ('a', 7), ("'m", 7), ('.', 7), ('interesting', 6), ('be', 6), ('lo', 5), ('how', 4), ('t', 4)] | Training
2025-04-02 15:23:44 | 2200 | LR0.0003 | loss32.4104 | gradNorm1.0000 | tokenCount300 | logitMin-31.5760 | logitMax-11.8523 | memoryGate0.3333 | windowWeightsW8:0.20740,W13:0.16135,W3:0.15343,W15:0.14741,W18:0.11705,W2:0.08179,W1:0.06387,W7:0.05880,W14:-0.01085 | topTokens[('it', 53), ('.', 12), ('the', 7), ('b', 7), ('ent', 5), ('is', 5), ('in', 5), ('im', 5), ('l', 5), ('she', 5)] | Training
2025-04-02 15:29:04 | 2300 | LR0.0003 | loss28.0636 | gradNorm1.0000 | tokenCount300 | logitMin-28.1430 | logitMax-10.8035 | memoryGate0.3333 | windowWeightsW8:0.20685,W13:0.16207,W3:0.15177,W15:0.14793,W18:0.11786,W2:0.08174,W1:0.06360,W7:0.06023,W14:-0.01178 | topTokens[('it', 55), ('and', 17), ('have', 10), ('a', 8), ('said', 7), ('had', 6), (',', 6), ('b', 6), ('.', 5), ('feel', 5)] | Training
2025-04-02 15:34:23 | 2400 | LR0.0003 | loss34.6323 | gradNorm1.0000 | tokenCount300 | logitMin-30.9544 | logitMax-12.3217 | memoryGate0.3333 | windowWeightsW8:0.20679,W13:0.16192,W3:0.15179,W15:0.14793,W18:0.11800,W2:0.08164,W1:0.06352,W7:0.06039,W14:-0.01172 | topTokens[('and', 68), ('it', 27), ('a', 19), ('them', 9), ('b', 5), ('feel', 4), ('in', 4), ('said', 4), ('have', 4), ('the', 4)] | Training
2025-04-02 15:39:42 | 2500 | LR0.0003 | loss25.6726 | gradNorm1.0000 | tokenCount300 | logitMin-35.3190 | logitMax-18.8674 | memoryGate0.3333 | windowWeightsW8:0.20681,W13:0.16212,W3:0.15185,W15:0.14825,W18:0.11849,W2:0.08093,W1:0.06295,W7:0.06039,W14:-0.01152 | topTokens[('and', 22), ('it', 17), ('the', 9), ('that', 8), ('a', 7), ('lo', 5), ('have', 5), ('-', 5), ('i', 4), ('in', 4)] | Training
2025-04-02 15:45:03 | 2600 | LR0.0003 | loss34.7132 | gradNorm1.0000 | tokenCount300 | logitMin-35.4236 | logitMax-13.7192 | memoryGate0.3333 | windowWeightsW8:0.20659,W13:0.16210,W3:0.15172,W15:0.14826,W18:0.11860,W2:0.08083,W1:0.06288,W7:0.06064,W14:-0.01135 | topTokens[('just', 17), ('it', 14), ('not', 9), ('l', 8), ('have', 7), ('c', 6), ('i', 6), ('that', 6), ('were', 5), ("'", 5)] | Training
2025-04-02 15:50:23 | 2700 | LR0.0003 | loss34.2754 | gradNorm1.0000 | tokenCount300 | logitMin-39.4461 | logitMax-19.1732 | memoryGate0.3333 | windowWeightsW8:0.20634,W13:0.16200,W3:0.15165,W15:0.14823,W18:0.11883,W2:0.08088,W1:0.06276,W7:0.06087,W14:-0.01129 | topTokens[('l', 9), ('it', 8), ('just', 8), ('lo', 7), ('not', 6), ('is', 6), ('b', 6), ('a', 5), ('in', 5), ('she', 5)] | Training
2025-04-02 15:55:44 | 2800 | LR0.0003 | loss30.5054 | gradNorm1.0000 | tokenCount300 | logitMin-40.1266 | logitMax-17.4810 | memoryGate0.3333 | windowWeightsW8:0.20614,W13:0.16209,W3:0.15149,W15:0.14832,W18:0.11891,W2:0.08119,W1:0.06278,W7:0.06072,W14:-0.01137 | topTokens[("'", 21), ('or', 19), ('an', 17), ('to', 12), ('it', 12), ('have', 10), (',', 8), ('b', 7), ('she', 6), ('in', 5)] | Training
2025-04-02 16:01:02 | 2900 | LR0.0003 | loss32.9105 | gradNorm1.0000 | tokenCount300 | logitMin-34.3552 | logitMax-14.6210 | memoryGate0.3333 | windowWeightsW8:0.20583,W13:0.16218,W3:0.15129,W15:0.14840,W18:0.11898,W2:0.08129,W1:0.06270,W7:0.06087,W14:-0.01127 | topTokens[('and', 36), ('an', 23), ('it', 10), ('aly', 9), ('', 7), ('b', 7), ("'", 5), (',', 5), ('feel', 5), ('in', 4)] | Training
2025-04-02 16:06:23 | 3000 | LR0.0003 | loss31.9092 | gradNorm1.0000 | tokenCount300 | logitMin-35.3079 | logitMax-17.1755 | memoryGate0.3333 | windowWeightsW8:0.20574,W13:0.16220,W3:0.15134,W15:0.14848,W18:0.11934,W2:0.08067,W1:0.06284,W7:0.06103,W14:-0.01136 | topTokens[('an', 19), ('aly', 10), ('it', 8), ('and', 7), ('ion', 6), ('to', 5), (',', 5), ('in', 5), ('have', 5), ("'", 5)] | Training
2025-04-02 16:11:44 | 3100 | LR0.0003 | loss30.0571 | gradNorm1.0000 | tokenCount300 | logitMin-32.0768 | logitMax-13.5906 | memoryGate0.3333 | windowWeightsW8:0.20585,W13:0.16197,W3:0.15114,W15:0.14833,W18:0.11936,W2:0.08080,W1:0.06265,W7:0.06140,W14:-0.01122 | topTokens[('i', 13), ('and', 11), ('in', 7), ('an', 7), ('it', 7), ('ed', 6), ('s', 6), (',', 6), ('ion', 5), ('my', 5)] | Training
2025-04-02 16:17:10 | 3200 | LR0.0003 | loss27.9166 | gradNorm1.0000 | tokenCount300 | logitMin-37.3505 | logitMax-21.3471 | memoryGate0.3333 | windowWeightsW8:0.20596,W13:0.16216,W3:0.15110,W15:0.14860,W18:0.11963,W2:0.08023,W1:0.06252,W7:0.06155,W14:-0.01146 | topTokens[('and', 8), (',', 7), ('the', 5), ('an', 5), ('or', 5), ('it', 5), ('c', 5), ('this', 5), ("'", 4), ('ion', 4)] | Training
2025-04-02 16:22:34 | 3300 | LR0.0003 | loss28.5940 | gradNorm1.0000 | tokenCount300 | logitMin-36.1411 | logitMax-18.3409 | memoryGate0.3333 | windowWeightsW8:0.20554,W13:0.16279,W3:0.15112,W15:0.14918,W18:0.12002,W2:0.07978,W1:0.06242,W7:0.06148,W14:-0.01204 | topTokens[('of', 20), ('k', 16), ('a', 10), ('c', 5), ('them', 4), ('the', 4), ('b', 4), ('and', 3), ('es', 3), ('h', 3)] | Training
2025-04-02 16:27:53 | 3400 | LR0.0003 | loss27.6208 | gradNorm1.0000 | tokenCount300 | logitMin-36.1699 | logitMax-17.1620 | memoryGate0.3333 | windowWeightsW8:0.20515,W13:0.16261,W3:0.15134,W15:0.14871,W18:0.11991,W2:0.08019,W1:0.06269,W7:0.06166,W14:-0.01196 | topTokens[('of', 23), ('e', 14), ('i', 10), ('a', 9), ('b', 7), ('self', 7), (',', 6), ('-', 6), ('k', 6), ('and', 6)] | Training
2025-04-02 16:33:14 | 3500 | LR0.0003 | loss40.6141 | gradNorm1.0000 | tokenCount300 | logitMin-38.5737 | logitMax-12.3955 | memoryGate0.3333 | windowWeightsW8:0.20338,W13:0.16253,W3:0.15190,W15:0.14809,W18:0.11849,W2:0.08209,W1:0.06431,W7:0.06109,W14:-0.01157 | topTokens[('know', 33), ("'t", 19), ('.', 15), ('it', 10), ('they', 7), ('e', 6), ('to', 5), ('-', 5), ('bit', 5), ('feel', 4)] | Training
2025-04-02 16:38:35 | 3600 | LR0.0003 | loss44.7105 | gradNorm1.0000 | tokenCount300 | logitMin-33.4455 | logitMax-5.9073 | memoryGate0.3333 | windowWeightsW8:0.20349,W13:0.16215,W3:0.15144,W15:0.14829,W18:0.11898,W2:0.08219,W1:0.06367,W7:0.06197,W14:-0.01185 | topTokens[("'t", 51), ('don', 36), ('know', 28), ('.', 19), ('feel', 5), ('i', 5), ('ur', 4), ('', 4), ('some', 3), ('had', 3)] | Training
2025-04-02 16:43:56 | 3700 | LR0.0003 | loss30.9177 | gradNorm1.0000 | tokenCount300 | logitMin-34.4508 | logitMax-16.9148 | memoryGate0.3333 | windowWeightsW8:0.20352,W13:0.16244,W3:0.15091,W15:0.14851,W18:0.11942,W2:0.08159,W1:0.06334,W7:0.06196,W14:-0.01139 | topTokens[('don', 20), ("'t", 14), ('.', 12), ('my', 12), ('i', 11), ('-', 7), ('in', 7), ('it', 6), ('know', 5), ('some', 5)] | Training
2025-04-02 16:49:17 | 3800 | LR0.0003 | loss26.7238 | gradNorm1.0000 | tokenCount300 | logitMin-29.3802 | logitMax-13.6983 | memoryGate0.3333 | windowWeightsW8:0.20382,W13:0.16215,W3:0.15115,W15:0.14847,W18:0.11936,W2:0.08162,W1:0.06313,W7:0.06164,W14:-0.01103 | topTokens[('know', 9), ("'t", 8), ('to', 8), ('i', 8), ('.', 8), ('don', 7), ('i', 7), ('the', 7), (',', 6), ('and', 5)] | Training
2025-04-02 16:54:40 | 3900 | LR0.0003 | loss26.1888 | gradNorm1.0000 | tokenCount300 | logitMin-28.2289 | logitMax-12.7295 | memoryGate0.3333 | windowWeightsW8:0.20382,W13:0.16182,W3:0.15148,W15:0.14808,W18:0.11918,W2:0.08213,W1:0.06325,W7:0.06167,W14:-0.01114 | topTokens[('that', 8), ('y', 7), ('enc', 6), ('my', 6), ('don', 6), ('to', 6), ('in', 5), ('have', 5), (',', 4), ("'", 4)] | Training
2025-04-02 17:00:01 | 4000 | LR0.0003 | loss30.1676 | gradNorm1.0000 | tokenCount300 | logitMin-35.5328 | logitMax-15.6858 | memoryGate0.3333 | windowWeightsW8:0.20400,W13:0.16194,W3:0.15219,W15:0.14838,W18:0.11913,W2:0.08176,W1:0.06287,W7:0.06121,W14:-0.01118 | topTokens[('it', 10), ('in', 9), ('y', 9), ('is', 9), ('to', 6), (',', 6), ('that', 6), ("'t", 5), ('b', 5), ("'s", 5)] | Training
2025-04-02 17:05:22 | 4100 | LR0.0003 | loss27.9477 | gradNorm1.0000 | tokenCount300 | logitMin-33.3675 | logitMax-15.1998 | memoryGate0.3333 | windowWeightsW8:0.20388,W13:0.16185,W3:0.15226,W15:0.14848,W18:0.11906,W2:0.08169,W1:0.06219,W7:0.06190,W14:-0.01102 | topTokens[('it', 29), ('to', 21), ('of', 9), ('ly', 8), ('b', 5), ('m', 5), (',', 5), ('like', 4), ('you', 4), ('in', 4)] | Training
2025-04-02 17:10:43 | 4200 | LR0.0003 | loss27.1559 | gradNorm1.0000 | tokenCount300 | logitMin-34.3514 | logitMax-17.4436 | memoryGate0.3333 | windowWeightsW8:0.20404,W13:0.16178,W3:0.15212,W15:0.14840,W18:0.11944,W2:0.08148,W7:0.06197,W1:0.06175,W14:-0.01069 | topTokens[('it', 29), (',', 9), ('of', 8), ('ations', 8), ('m', 7), ("'t", 5), ('equ', 4), ("'", 4), ('b', 4), ('c', 4)] | Training
2025-04-02 17:16:05 | 4300 | LR0.0003 | loss33.0266 | gradNorm1.0000 | tokenCount300 | logitMin-33.1040 | logitMax-12.1034 | memoryGate0.3333 | windowWeightsW8:0.20423,W13:0.16152,W3:0.15198,W15:0.14839,W18:0.11983,W2:0.08141,W7:0.06253,W1:0.06159,W14:-0.01117 | topTokens[('to', 14), ('this', 14), ('it', 12), ('is', 10), (',', 9), ("'", 6), ('feel', 6), ('and', 5), ('b', 5), ('.', 4)] | Training
2025-04-02 17:21:29 | 4400 | LR0.0003 | loss30.0846 | gradNorm1.0000 | tokenCount300 | logitMin-30.1613 | logitMax-10.7891 | memoryGate0.3333 | windowWeightsW8:0.20413,W13:0.16150,W3:0.15171,W15:0.14848,W18:0.11993,W2:0.08138,W7:0.06306,W1:0.06150,W14:-0.01138 | topTokens[('it', 13), ('to', 12), ('b', 8), ("'s", 7), ('feel', 6), ('and', 6), ('i', 6), ('with', 5), ('.', 5), ('some', 5)] | Training
2025-04-02 17:26:51 | 4500 | LR0.0003 | loss23.9361 | gradNorm1.0000 | tokenCount300 | logitMin-33.9789 | logitMax-18.3257 | memoryGate0.3333 | windowWeightsW8:0.20369,W13:0.16143,W3:0.15189,W15:0.14839,W18:0.11975,W2:0.08132,W7:0.06353,W1:0.06173,W14:-0.01142 | topTokens[('to', 8), (',', 8), ('i', 7), ('.', 6), ('this', 6), ('be', 5), ('understand', 4), ('and', 4), ('op', 4), ('pro', 4)] | Training
2025-04-02 17:32:14 | 4600 | LR0.0003 | loss24.5166 | gradNorm1.0000 | tokenCount300 | logitMin-31.1335 | logitMax-13.9456 | memoryGate0.3333 | windowWeightsW8:0.20340,W13:0.16183,W3:0.15156,W15:0.14906,W18:0.12013,W2:0.08089,W7:0.06332,W1:0.06136,W14:-0.01123 | topTokens[('en', 9), ('the', 9), ('es', 6), ('and', 6), ('of', 5), ('.', 5), ('in', 5), ("'", 5), ('a', 4), ('g', 4)] | Training
2025-04-02 17:37:39 | 4700 | LR0.0003 | loss22.1845 | gradNorm1.0000 | tokenCount300 | logitMin-36.4177 | logitMax-17.7921 | memoryGate0.3333 | windowWeightsW8:0.20278,W13:0.16234,W3:0.15032,W15:0.14989,W18:0.12140,W2:0.07995,W7:0.06333,W1:0.06179,W14:-0.01144 | topTokens[('the', 16), ('in', 11), ('.', 9), ('not', 8), ('but', 7), (',', 6), ('g', 5), ('en', 5), ('it', 5), ('be', 5)] | Training
2025-04-02 17:43:07 | 4800 | LR0.0003 | loss27.1592 | gradNorm1.0000 | tokenCount300 | logitMin-27.0641 | logitMax-8.6895 | memoryGate0.3333 | windowWeightsW8:0.20224,W13:0.16202,W3:0.15118,W15:0.14988,W18:0.12171,W2:0.07978,W7:0.06350,W1:0.06198,W14:-0.01193 | topTokens[('very', 23), ('with', 18), ('me', 17), ('interesting', 16), ('them', 6), (',', 6), ('feel', 5), ('in', 5), ('she', 5), ('be', 4)] | Training
2025-04-02 17:48:29 | 4900 | LR0.0003 | loss32.7443 | gradNorm1.0000 | tokenCount300 | logitMin-35.7591 | logitMax-13.9691 | memoryGate0.3333 | windowWeightsW8:0.20174,W13:0.16233,W3:0.15175,W15:0.15011,W18:0.12125,W2:0.07830,W7:0.06358,W1:0.06225,W14:-0.01097 | topTokens[('and', 30), ('to', 15), ('ation', 12), ('it', 11), ('is', 9), ('the', 9), ('in', 8), ('ations', 7), ('with', 6), ('do', 6)] | Training
2025-04-02 17:53:53 | 5000 | LR0.0003 | loss28.3469 | gradNorm1.0000 | tokenCount300 | logitMin-35.3824 | logitMax-17.0765 | memoryGate0.3333 | windowWeightsW8:0.20154,W13:0.16231,W3:0.15107,W15:0.15036,W18:0.12167,W2:0.07781,W7:0.06396,W1:0.06262,W14:-0.01098 | topTokens[('it', 20), ('c', 17), ('or', 12), ('the', 7), ('to', 6), ('a', 5), ('too', 4), ('in', 4), ('es', 4), ('i', 4)] | Training
2025-04-02 17:59:16 | 5100 | LR0.0003 | loss26.9807 | gradNorm1.0000 | tokenCount300 | logitMin-32.2846 | logitMax-14.9332 | memoryGate0.3333 | windowWeightsW8:0.20232,W13:0.16187,W3:0.15155,W15:0.14983,W18:0.12124,W2:0.07797,W7:0.06372,W1:0.06249,W14:-0.01065 | topTokens[('it', 14), ('the', 10), ('or', 9), ('in', 8), ('that', 8), ("'", 8), ('c', 5), ('in', 5), ('pro', 5), ('.', 4)] | Training
2025-04-02 18:04:39 | 5200 | LR0.0003 | loss45.6714 | gradNorm1.0000 | tokenCount300 | logitMin-34.7907 | logitMax-7.1307 | memoryGate0.3333 | windowWeightsW8:0.20271,W13:0.16218,W3:0.15157,W15:0.15025,W18:0.12153,W2:0.07721,W7:0.06389,W1:0.06135,W14:-0.01034 | topTokens[('ed', 48), ('it', 15), ('with', 7), ('of', 6), ('b', 6), ('some', 6), ('the', 5), ("'s", 5), ('work', 5), ('or', 4)] | Training
2025-04-02 18:10:00 | 5300 | LR0.0003 | loss34.6318 | gradNorm1.0000 | tokenCount300 | logitMin-33.1227 | logitMax-13.0137 | memoryGate0.3333 | windowWeightsW8:0.20239,W13:0.16234,W3:0.15118,W15:0.15046,W18:0.12172,W2:0.07739,W7:0.06379,W1:0.06133,W14:-0.01025 | topTokens[('ed', 37), ('literally', 27), (')', 27), ('.', 5), ('some', 5), ('pro', 4), ('a', 4), ('it', 4), ('she', 3), ('in', 3)] | Training
2025-04-02 18:15:28 | 5400 | LR0.0003 | loss32.7347 | gradNorm1.0000 | tokenCount300 | logitMin-34.7856 | logitMax-14.0813 | memoryGate0.3333 | windowWeightsW8:0.20240,W13:0.16232,W3:0.15095,W15:0.15053,W18:0.12196,W2:0.07721,W7:0.06406,W1:0.06109,W14:-0.01016 | topTokens[('ed', 14), ('it', 11), (')', 10), ('literally', 9), ('.', 6), ('i', 5), ('in', 5), ('feel', 5), ('in', 4), ('the', 4)] | Training
2025-04-02 18:20:59 | 5500 | LR0.0003 | loss31.0578 | gradNorm1.0000 | tokenCount300 | logitMin-34.7597 | logitMax-15.2097 | memoryGate0.3333 | windowWeightsW8:0.20258,W13:0.16228,W3:0.15068,W15:0.15051,W18:0.12202,W2:0.07699,W7:0.06402,W1:0.06134,W14:-0.01008 | topTokens[('it', 9), ('and', 8), ('b', 8), ('to', 6), ('the', 6), ('or', 5), ('literally', 5), ('bs', 5), ('in', 4), ('in', 4)] | Training
2025-04-02 18:26:19 | 5600 | LR0.0003 | loss33.2604 | gradNorm1.0000 | tokenCount300 | logitMin-37.5732 | logitMax-14.8857 | memoryGate0.3333 | windowWeightsW8:0.20126,W13:0.16187,W3:0.15112,W15:0.14963,W18:0.12138,W2:0.07838,W7:0.06499,W1:0.06204,W14:-0.01032 | topTokens[('this', 38), ('.', 18), ('i', 8), ("'t", 7), ('in', 5), ('me', 5), ('emot', 5), ('s', 5), ('op', 4), (',', 4)] | Training
2025-04-02 18:31:40 | 5700 | LR0.0003 | loss31.6202 | gradNorm1.0000 | tokenCount300 | logitMin-38.2912 | logitMax-19.2367 | memoryGate0.3333 | windowWeightsW8:0.20155,W13:0.16169,W3:0.15083,W15:0.14961,W18:0.12142,W2:0.07868,W7:0.06511,W1:0.06193,W14:-0.01045 | topTokens[('this', 18), ("'t", 12), ('can', 7), ('i', 7), ('in', 6), ('that', 6), ('c', 5), ("'", 4), ('ations', 4), ('as', 4)] | Training
2025-04-02 18:37:00 | 5800 | LR0.0003 | loss22.9617 | gradNorm1.0000 | tokenCount300 | logitMin-36.1299 | logitMax-18.6427 | memoryGate0.3333 | windowWeightsW8:0.20357,W13:0.16213,W15:0.14988,W3:0.14977,W18:0.12169,W2:0.07797,W7:0.06447,W1:0.06103,W14:-0.01019 | topTokens[('?', 19), ('it', 18), ('i', 14), ('.', 14), ('is', 12), ('you', 9), (',', 7), ('!', 7), ('ations', 5), ('b', 4)] | Training
2025-04-02 18:42:22 | 5900 | LR0.0003 | loss27.3754 | gradNorm1.0000 | tokenCount300 | logitMin-38.5872 | logitMax-19.9598 | memoryGate0.3336 | windowWeightsW8:0.20336,W13:0.16199,W15:0.14980,W3:0.14940,W18:0.12205,W2:0.07833,W7:0.06497,W1:0.06042,W14:-0.00997 | topTokens[('?', 35), ('!', 13), ('is', 11), ('it', 10), ('.', 9), ('at', 8), ('he', 6), (',', 5), ('ous', 4), ('some', 4)] | Training
2025-04-02 18:47:51 | 6000 | LR0.0003 | loss34.9594 | gradNorm1.0000 | tokenCount300 | logitMin-38.8293 | logitMax-17.5620 | memoryGate0.3333 | windowWeightsW8:0.20300,W13:0.16167,W3:0.14980,W15:0.14971,W18:0.12247,W2:0.07860,W7:0.06454,W1:0.06073,W14:-0.01018 | topTokens[('!', 36), ('is', 32), ('you', 24), ('?', 11), ('how', 11), ('in', 8), ('them', 5), ('.', 4), ('time', 4), ('feel', 4)] | Training
2025-04-02 18:53:52 | 6100 | LR0.0003 | loss23.6386 | gradNorm1.0000 | tokenCount300 | logitMin-39.1917 | logitMax-21.5758 | memoryGate0.3333 | windowWeightsW8:0.20330,W13:0.16135,W15:0.14994,W3:0.14954,W18:0.12334,W2:0.07896,W7:0.06449,W1:0.05869,W14:-0.00922 | topTokens[('?', 40), ('!', 19), ('is', 14), ('you', 14), ('like', 6), ('.', 6), ('s', 5), ('b', 5), (',', 5), ('i', 5)] | Training
2025-04-02 18:59:01 | 6200 | LR0.0003 | loss31.5492 | gradNorm1.0000 | tokenCount300 | logitMin-35.2600 | logitMax-15.1974 | memoryGate0.3333 | windowWeightsW8:0.20287,W13:0.16060,W3:0.15030,W15:0.14950,W18:0.12323,W2:0.07926,W7:0.06519,W1:0.05859,W14:-0.00913 | topTokens[('?', 76), ('you', 17), ('is', 17), ('.', 16), ('awake', 14), ('in', 4), ('a', 4), ('day', 3), ('ame', 2), ('ms', 2)] | Training
2025-04-02 19:04:21 | 6300 | LR0.0003 | loss37.5506 | gradNorm1.0000 | tokenCount300 | logitMin-34.5951 | logitMax-9.4323 | memoryGate0.3333 | windowWeightsW8:0.20260,W13:0.16045,W3:0.15005,W15:0.14956,W18:0.12339,W2:0.07883,W7:0.06591,W1:0.05865,W14:-0.00904 | topTokens[('?', 47), ('is', 31), ('are', 12), ('you', 11), ('awake', 11), ('.', 7), ('v', 6), ('it', 5), ('b', 5), ('too', 4)] | Training
2025-04-02 19:09:51 | 6400 | LR0.0003 | loss26.7614 | gradNorm1.0000 | tokenCount300 | logitMin-32.7116 | logitMax-13.1584 | memoryGate0.3323 | windowWeightsW8:0.20339,W13:0.16045,W15:0.14962,W3:0.14940,W18:0.12306,W2:0.07854,W7:0.06690,W1:0.05858,W14:-0.00952 | topTokens[('?', 38), ('is', 20), ('.', 15), ('you', 10), ('real', 9), ('they', 7), ('!', 6), ('awake', 5), ('she', 5), ('who', 5)] | Training
2025-04-02 19:15:11 | 6500 | LR0.0003 | loss28.2344 | gradNorm1.0000 | tokenCount300 | logitMin-34.5785 | logitMax-14.2150 | memoryGate0.3333 | windowWeightsW8:0.20372,W13:0.16030,W15:0.14959,W3:0.14931,W18:0.12320,W2:0.07762,W7:0.06756,W1:0.05872,W14:-0.00960 | topTokens[('do', 30), ('!', 19), ('?', 18), ('you', 13), ('no', 10), ('.', 8), ('real', 7), ('is', 5), (',', 5), ('them', 5)] | Training
2025-04-02 19:20:48 | 6600 | LR0.0003 | loss30.6933 | gradNorm1.0000 | tokenCount300 | logitMin-40.2870 | logitMax-11.3832 | memoryGate0.3333 | windowWeightsW8:0.20394,W13:0.16002,W3:0.15032,W15:0.14893,W18:0.12263,W2:0.07869,W7:0.06670,W1:0.05844,W14:-0.00926 | topTokens[('?', 39), ('do', 20), ('is', 16), ('!', 13), ('yes', 12), ('it', 11), ('awake', 9), ('you', 8), ('them', 8), (',', 7)] | Training
2025-04-02 19:26:17 | 6700 | LR0.0003 | loss31.7720 | gradNorm1.0000 | tokenCount300 | logitMin-40.9106 | logitMax-13.9858 | memoryGate0.3333 | windowWeightsW8:0.20338,W13:0.16080,W3:0.14996,W15:0.14885,W18:0.12251,W2:0.07934,W7:0.06719,W1:0.05764,W14:-0.00923 | topTokens[('is', 42), ('it', 27), ('?', 27), ('.', 17), ('why', 9), (',', 8), ('you', 7), ('her', 6), ('what', 5), ('res', 4)] | Training
2025-04-02 19:31:43 | 6800 | LR0.0003 | loss34.2187 | gradNorm1.0000 | tokenCount300 | logitMin-38.3061 | logitMax-15.9676 | memoryGate0.3333 | windowWeightsW8:0.20328,W13:0.16064,W3:0.15031,W15:0.14889,W18:0.12262,W2:0.07963,W7:0.06702,W1:0.05750,W14:-0.00944 | topTokens[('?', 31), ('it', 25), ('!', 14), ('why', 10), (',', 9), ('are', 8), ('no', 6), ('is', 6), (':', 5), ('do', 5)] | Training
2025-04-02 19:37:23 | 6900 | LR0.0003 | loss23.7611 | gradNorm1.0000 | tokenCount300 | logitMin-39.4394 | logitMax-20.1216 | memoryGate0.3333 | windowWeightsW8:0.20267,W13:0.16036,W3:0.15027,W15:0.14878,W18:0.12276,W2:0.08014,W7:0.06753,W1:0.05756,W14:-0.00960 | topTokens[('?', 26), ('is', 24), ('!', 22), (',', 12), ('it', 9), ('.', 8), ('who', 7), ('no', 6), ('i', 6), ('were', 5)] | Training
2025-04-02 19:42:59 | 7000 | LR0.0003 | loss22.7869 | gradNorm1.0000 | tokenCount300 | logitMin-38.6101 | logitMax-20.6376 | memoryGate0.3333 | windowWeightsW8:0.20127,W13:0.15969,W3:0.15137,W15:0.14810,W18:0.12247,W2:0.07968,W7:0.06882,W1:0.05779,W14:-0.00875 | topTokens[('?', 21), ('kevin', 21), ('you', 16), ('is', 15), ('.', 13), ('do', 7), (',', 7), ('im', 5), ('can', 5), ('it', 5)] | Training
2025-04-02 19:48:39 | 7100 | LR0.0003 | loss38.3346 | gradNorm1.0000 | tokenCount300 | logitMin-42.3893 | logitMax-15.3179 | memoryGate0.3333 | windowWeightsW8:0.20174,W13:0.16002,W3:0.15151,W15:0.14849,W18:0.12317,W2:0.08073,W7:0.06702,W1:0.05726,W14:-0.00946 | topTokens[('no', 43), ('?', 28), ('im', 22), ('.', 21), ('is', 14), ('you', 9), ('life', 8), ('had', 5), ('do', 5), ('ous', 4)] | Training
2025-04-02 19:54:33 | 7200 | LR0.0003 | loss26.1728 | gradNorm1.0000 | tokenCount300 | logitMin-33.5163 | logitMax-13.7597 | memoryGate0.3333 | windowWeightsW8:0.20168,W13:0.15983,W3:0.15174,W15:0.14843,W18:0.12320,W2:0.08077,W7:0.06632,W1:0.05753,W14:-0.00906 | topTokens[('!', 30), ('?', 15), ('are', 15), ('is', 11), ('.', 9), ('life', 6), ('was', 6), ('you', 5), ('do', 4), ('no', 4)] | Training
2025-04-02 20:04:34 | 100 | LR0.0003 | loss:9.6372 | gradNorm:1.0000 | logitMin:-47.6488 | logitMax:-21.8810 | memoryGate:0.3333 | scheduledSampling:0.0000 | tokenCount:300.0000 | windowWeightsW8:0.20049,W13:0.15916,W3:0.15290,W15:0.14875,W18:0.12338,W2:0.08004,W7:0.06722,W1:0.05793,W14:-0.00944 | topTokens[('?', 35), ('you', 14), ('not', 12), ('what', 11), ('kevin', 11), ('are', 10), ('.', 9), ('al', 8), ('im', 8), ('is', 8)] | Training
2025-04-02 20:10:43 | 200 | LR0.0003 | loss:8.0649 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-45.8854 | logitMax:-19.0361 | memoryGate:0.3333 | windowWeightsW8:0.20005,W13:0.15817,W3:0.15304,W15:0.14797,W18:0.12358,W2:0.08076,W7:0.06749,W1:0.05833,W14:-0.00898 | topTokens[('.', 33), ('is', 23), ('?', 22), ('dead', 11), ('are', 11), ('you', 10), ('what', 9), ('it', 7), ('!', 7), ('its', 6)] | Training
2025-04-02 20:20:13 | 100 | LR0.0003 | loss:7.4598 | gradNorm:1.0000 | logitMin:-48.2424 | logitMax:-23.1130 | memoryGate:0.3333 | scheduledSampling:0.0000 | tokenCount:300.0000 | windowWeightsW8:0.19963,W13:0.15924,W3:0.15261,W15:0.14907,W18:0.12411,W2:0.07954,W7:0.06792,W1:0.05797,W14:-0.00962 | memoryGatesShort:41.211, Long:3.262, Current:-43.473 | topTokens[('.', 25), ('can', 20), ('you', 19), ('i', 12), ('?', 12), ('are', 10), ('so', 10), ('americ', 7), ('im', 7), ('was', 6)] | Training
2025-04-02 20:26:25 | 200 | LR0.0003 | loss:6.4954 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-45.6646 | logitMax:-21.2964 | memoryGate:0.3333 | windowWeightsW8:0.20007,W13:0.15936,W3:0.15211,W15:0.14934,W18:0.12443,W2:0.07904,W7:0.06861,W1:0.05744,W14:-0.00992 | memoryGatesShort:-2.086, Long:0.592, Current:2.494 | topTokens[('.', 27), ('dead', 18), ('?', 17), ('you', 13), ('is', 11), ('are', 10), ('!', 10), ('asleep', 10), ('a', 9), ('do', 9)] | Training
2025-04-02 20:32:55 | 100 | LR0.0003 | loss:8.0972 | gradNorm:1.0000 | logitMin:-42.5093 | logitMax:-15.0294 | scheduledSampling:0.0000 | tokenCount:300.0000 | windowWeightsW8:0.19985,W13:0.15839,W3:0.15386,W15:0.14807,W18:0.12344,W2:0.08045,W7:0.06806,W1:0.05842,W14:-0.01009 | memoryGatesShort:297.087, Long:38.619, Current:-334.706 | topTokens[('.', 30), ('this', 25), ('so', 20), ('is', 17), ('?', 14), (',', 9), ('what', 8), ('it', 6), ('you', 5), ('asleep', 5)] | Training
2025-04-02 20:38:40 | 200 | LR0.0003 | loss:7.9221 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.4452 | logitMax:-21.1883 | windowWeightsW8:0.20032,W13:0.15923,W3:0.15281,W15:0.14923,W18:0.12464,W2:0.08035,W7:0.06761,W1:0.05740,W14:-0.01112 | memoryGatesShort:-9.649, Long:3.561, Current:7.088 | topTokens[('is', 21), ('.', 19), ('?', 17), ('nd', 14), ('!', 13), ('you', 10), ('lo', 9), ('do', 9), ('great', 6), ('im', 6)] | Training
2025-04-02 20:44:17 | 300 | LR0.0003 | loss:10.2783 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-37.6192 | logitMax:-15.1140 | windowWeightsW8:0.20102,W13:0.15920,W3:0.15269,W15:0.14901,W18:0.12437,W2:0.08035,W7:0.06765,W1:0.05703,W14:-0.01087 | memoryGatesShort:-1.652, Long:0.265, Current:2.386 | topTokens[('?', 22), ('do', 18), ('you', 12), ('are', 11), ('nd', 7), ('lo', 6), ('i', 6), ('is', 6), ('er', 5), ('.', 5)] | Training
2025-04-02 20:50:02 | 400 | LR0.0003 | loss:10.0379 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-37.8050 | logitMax:-15.8296 | windowWeightsW8:0.20133,W13:0.15931,W3:0.15236,W15:0.14926,W18:0.12447,W2:0.07919,W7:0.06702,W1:0.05777,W14:-0.01027 | memoryGatesShort:-1.301, Long:0.776, Current:1.525 | topTokens[('are', 56), ('?', 33), ('.', 14), ('is', 10), (',', 8), ('feel', 7), ('!', 7), ('im', 7), ('b', 6), ('you', 5)] | Training
2025-04-02 20:55:32 | 500 | LR0.0003 | loss:11.2547 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-29.5630 | logitMax:-0.2684 | windowWeightsW8:0.20114,W13:0.15879,W3:0.15317,W15:0.14898,W18:0.12428,W2:0.07924,W7:0.06744,W1:0.05764,W14:-0.01022 | memoryGatesShort:-1.936, Long:1.550, Current:1.387 | topTokens[('are', 40), ('?', 31), ('equ', 21), ('im', 15), ('als', 14), ('n', 8), ('.', 7), ('b', 6), ('them', 6), ('feel', 5)] | Training
2025-04-02 21:01:31 | 600 | LR0.0003 | loss:8.6483 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-33.4546 | logitMax:-10.6698 | windowWeightsW8:0.20135,W13:0.15872,W3:0.15318,W15:0.14908,W18:0.12430,W2:0.07895,W7:0.06764,W1:0.05751,W14:-0.01030 | memoryGatesShort:-0.979, Long:0.293, Current:1.686 | topTokens[('equ', 24), ('are', 15), ('.', 14), ('e', 12), ('what', 11), ('!', 9), ('als', 8), ('im', 7), (',', 6), ('plus', 5)] | Training
2025-04-02 21:07:13 | 700 | LR0.0003 | loss:14.6037 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-44.5548 | logitMax:-10.6826 | windowWeightsW8:0.20049,W13:0.16016,W3:0.15196,W15:0.15039,W18:0.12537,W2:0.07811,W7:0.06668,W1:0.05714,W14:-0.00983 | memoryGatesShort:-24.532, Long:16.662, Current:8.870 | topTokens[('gay', 79), ('.', 27), ('?', 20), (',', 7), ('is', 7), ('she', 6), ('you', 6), ('!', 5), ('feel', 5), ('were', 5)] | Training
2025-04-02 21:12:46 | 800 | LR0.0003 | loss:12.6371 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-27.3586 | logitMax:-4.7705 | windowWeightsW8:0.20063,W13:0.16020,W3:0.15198,W15:0.15040,W18:0.12525,W2:0.07826,W7:0.06628,W1:0.05754,W14:-0.01007 | memoryGatesShort:11.990, Long:-3.688, Current:-7.302 | topTokens[('gay', 127), ('.', 13), ('b', 6), (',', 5), ('some', 4), ('in', 4), ('had', 3), ('at', 3), ('(', 3), ('going', 3)] | Training
2025-04-02 21:18:17 | 900 | LR0.0003 | loss:11.1271 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-29.9455 | logitMax:-5.2671 | windowWeightsW8:0.20070,W13:0.16064,W3:0.15203,W15:0.15071,W18:0.12531,W2:0.07869,W7:0.06527,W1:0.05734,W14:-0.01025 | memoryGatesShort:-1.452, Long:0.766, Current:1.686 | topTokens[('gay', 112), ('.', 16), ('is', 8), ('feel', 6), (',', 3), ('b', 3), ('!', 3), ('pro', 3), ('was', 3), ('think', 3)] | Training
2025-04-02 21:23:52 | 1000 | LR0.0003 | loss:11.5286 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-32.4867 | logitMax:-6.4795 | windowWeightsW8:0.20118,W13:0.16073,W3:0.15198,W15:0.15074,W18:0.12517,W2:0.07869,W7:0.06507,W1:0.05766,W14:-0.01078 | memoryGatesShort:-10.781, Long:3.936, Current:7.845 | topTokens[('gay', 70), ('is', 13), ('.', 9), ('f', 9), (',', 8), ('als', 7), ('?', 7), ('b', 7), ('n', 7), ('!', 6)] | Training
2025-04-02 21:29:09 | 1100 | LR0.0003 | loss:7.5344 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-28.1650 | logitMax:-9.6959 | windowWeightsW8:0.20117,W13:0.16056,W3:0.15189,W15:0.15044,W18:0.12500,W2:0.07858,W7:0.06512,W1:0.05831,W14:-0.01061 | memoryGatesShort:-51.338, Long:8.734, Current:43.603 | topTokens[('gay', 29), ('.', 24), ('!', 13), ('is', 10), ('equ', 7), ('b', 7), ('als', 6), ('?', 6), (',', 5), ('feel', 5)] | Training
2025-04-02 21:34:42 | 1200 | LR0.0003 | loss:10.3628 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-29.7303 | logitMax:-8.1432 | windowWeightsW8:0.20054,W13:0.16052,W3:0.15182,W15:0.15052,W18:0.12499,W2:0.07846,W7:0.06554,W1:0.05875,W14:-0.01067 | memoryGatesShort:-1.616, Long:0.257, Current:2.359 | topTokens[('?', 38), ('.', 29), ('is', 16), ('!', 12), ('all', 8), ('i', 7), ('do', 7), ('in', 6), ('gay', 6), ('so', 5)] | Training
2025-04-02 21:40:10 | 1300 | LR0.0003 | loss:8.3828 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-26.9798 | logitMax:-2.8738 | windowWeightsW8:0.20077,W13:0.16040,W3:0.15180,W15:0.15041,W18:0.12480,W2:0.07844,W7:0.06582,W1:0.05850,W14:-0.01048 | memoryGatesShort:-7.775, Long:-0.648, Current:9.423 | topTokens[('what', 35), ('.', 25), ('?', 21), ('is', 19), ('gay', 14), (',', 7), ('b', 5), ('!', 4), ('so', 4), ('als', 4)] | Training
2025-04-02 21:45:35 | 1400 | LR0.0003 | loss:7.0259 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-29.9572 | logitMax:-10.2075 | windowWeightsW8:0.20082,W13:0.16082,W3:0.15188,W15:0.15075,W18:0.12488,W2:0.07847,W7:0.06602,W1:0.05724,W14:-0.01040 | memoryGatesShort:-2.068, Long:1.568, Current:1.499 | topTokens[('is', 22), ('?', 19), ('.', 17), ('!', 13), ('what', 8), ('equ', 7), (',', 6), ('do', 6), ('i', 6), ('im', 6)] | Training
2025-04-02 21:51:54 | 1500 | LR0.0003 | loss:7.3068 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-30.4192 | logitMax:-7.7625 | windowWeightsW8:0.20076,W13:0.16090,W3:0.15199,W15:0.15095,W18:0.12496,W2:0.07808,W7:0.06642,W1:0.05752,W14:-0.01112 | memoryGatesShort:-2.275, Long:1.073, Current:2.202 | topTokens[('?', 31), ('is', 29), ('.', 19), ('smink', 13), ('f', 12), ('equ', 9), ('!', 8), ('als', 8), ('what', 5), ('happy', 4)] | Training2025-04-02 21:58:30 | 1600 | LR0.0003 | loss:6.9893 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-33.4020 | logitMax:-11.5293 | windowWeightsW8:0.20049,W13:0.16095,W3:0.15197,W15:0.15102,W18:0.12492,W2:0.07782,W7:0.06620,W1:0.05791,W14:-0.01082 | memoryGatesShort:7.960, Long:2.031, Current:-8.991 | topTokens[('.', 20), ('f', 16), ('equ', 16), ('is', 13), ('?', 12), ('als', 10), ('do', 10), ('what', 9), ('it', 6), ('=', 5)] | Training

--- 2025-04-02 22:00:52 ---
babyLLM: what am i learning today?
You: that you are cute and smart!
2025-04-02 22:06:29 | 100 | LR0.0003 | loss:9.3277 | gradNorm:1.0000 | logitMin:-31.8964 | logitMax:-6.1116 | scheduledSampling:0.0000 | tokenCount:300.0000 | windowWeightsW8:0.20053,W13:0.16076,W3:0.15166,W15:0.15095,W18:0.12390,W2:0.07834,W7:0.06659,W1:0.05794,W14:-0.01022 | memoryGatesShort:-4.165, Long:-0.659, Current:5.824 | topTokens[('!', 20), ('.', 15), ('what', 11), ('f', 11), ('equ', 9), ('als', 7), ('is', 7), ('are', 6), ('to', 6), (',', 6)] | Training
2025-04-02 22:12:06 | 200 | LR0.0003 | loss:9.7436 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.0885 | logitMax:-15.2354 | windowWeightsW8:0.20100,W13:0.16173,W15:0.15158,W3:0.15066,W18:0.12353,W2:0.07756,W7:0.06641,W1:0.05887,W14:-0.01087 | memoryGatesShort:-2.224, Long:0.429, Current:2.794 | topTokens[('!', 47), ('is', 18), ('hi', 16), ('ty', 12), ('.', 11), ('are', 11), ('b', 9), (',', 8), ('not', 7), ('ping', 6)] | Training
2025-04-02 22:17:45 | 300 | LR0.0003 | loss:6.2406 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-34.2053 | logitMax:-15.4493 | windowWeightsW8:0.20190,W13:0.16176,W15:0.15137,W3:0.15044,W18:0.12365,W2:0.07777,W7:0.06660,W1:0.05822,W14:-0.01124 | memoryGatesShort:-1.144, Long:1.319, Current:0.825 | topTokens[('!', 21), ('.', 17), ('?', 15), ('what', 14), ('boof', 13), ('is', 10), ('b', 8), ('ty', 8), ('are', 6), ('equ', 5)] | Training
2025-04-02 22:23:28 | 400 | LR0.0003 | loss:7.7227 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-29.6082 | logitMax:-5.1835 | windowWeightsW8:0.20242,W13:0.16159,W15:0.15101,W3:0.15016,W18:0.12362,W2:0.07798,W7:0.06658,W1:0.05822,W14:-0.01112 | memoryGatesShort:-1.662, Long:0.680, Current:1.981 | topTokens[('?', 19), ('.', 18), ('what', 15), ('!', 13), ('you', 12), ('is', 12), ('equ', 12), ('are', 9), ('als', 9), ('e', 8)] | Training
2025-04-02 22:28:59 | 500 | LR0.0003 | loss:7.7075 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-34.0574 | logitMax:-9.9451 | windowWeightsW8:0.20225,W13:0.16097,W3:0.15115,W15:0.15088,W18:0.12333,W2:0.07813,W7:0.06704,W1:0.05882,W14:-0.01212 | memoryGatesShort:-0.569, Long:-0.050, Current:1.619 | topTokens[('?', 25), ('this', 20), ('is', 18), ('als', 16), ('.', 16), ('equ', 16), ('what', 15), ('!', 9), ('its', 7), ('feel', 4)] | Training
2025-04-02 22:34:37 | 600 | LR0.0003 | loss:9.7683 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-33.8125 | logitMax:-5.8117 | windowWeightsW8:0.20319,W13:0.16108,W3:0.15087,W15:0.15060,W18:0.12282,W2:0.07759,W7:0.06800,W1:0.05849,W14:-0.01218 | memoryGatesShort:-0.973, Long:0.025, Current:1.948 | topTokens[('what', 31), ('is', 24), ('?', 23), ('.', 16), ('pete', 13), ('als', 8), (',', 8), ('its', 7), ('!', 6), ('so', 6)] | Training
2025-04-02 22:40:52 | 700 | LR0.0003 | loss:7.7946 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-37.0989 | logitMax:-18.5780 | windowWeightsW8:0.20305,W13:0.16184,W15:0.15146,W3:0.15100,W18:0.12364,W2:0.07662,W7:0.06811,W1:0.05775,W14:-0.01300 | memoryGatesShort:-12.634, Long:-3.524, Current:17.157 | topTokens[('?', 19), ('.', 19), ('what', 14), ('so', 11), ('you', 10), ('equ', 9), ('!', 9), ('f', 8), ('im', 8), ('in', 6)] | Training
2025-04-02 22:46:29 | 800 | LR0.0003 | loss:8.9089 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-44.1980 | logitMax:-17.6002 | windowWeightsW8:0.20245,W13:0.16180,W15:0.15142,W3:0.15135,W18:0.12374,W2:0.07692,W7:0.06842,W1:0.05724,W14:-0.01285 | memoryGatesShort:-0.133, Long:0.101, Current:1.032 | topTokens[('?', 31), ('is', 21), ('im', 20), ('.', 15), ('are', 10), ('equ', 7), ('als', 7), ('not', 6), ('f', 6), ('you', 5)] | Training
2025-04-02 22:52:11 | 900 | LR0.0003 | loss:11.0605 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-49.5002 | logitMax:-15.3950 | windowWeightsW8:0.20241,W13:0.16183,W3:0.15165,W15:0.15115,W18:0.12399,W2:0.07623,W7:0.06848,W1:0.05748,W14:-0.01275 | memoryGatesShort:-0.427, Long:-0.052, Current:1.479 | topTokens[('?', 28), ('!', 19), ('me', 18), ('you', 14), ('im', 13), ('.', 12), ('is', 9), ('in', 7), ('we', 7), ('its', 5)] | Training
2025-04-02 22:57:50 | 1000 | LR0.0003 | loss:10.4435 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-48.0463 | logitMax:-21.6136 | windowWeightsW8:0.20191,W13:0.16162,W3:0.15188,W15:0.15072,W18:0.12415,W2:0.07681,W7:0.06854,W1:0.05723,W14:-0.01239 | memoryGatesShort:1.568, Long:0.788, Current:-1.356 | topTokens[('!', 24), ('?', 21), ('is', 12), ('.', 11), ('it', 11), ('kevin', 9), ('what', 7), ('in', 5), ('b', 5), ('al', 5)] | Training
2025-04-02 23:03:27 | 1100 | LR0.0003 | loss:8.9475 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.6074 | logitMax:-15.6905 | windowWeightsW8:0.20175,W13:0.16112,W3:0.15177,W15:0.15009,W18:0.12337,W2:0.07798,W7:0.06822,W1:0.05799,W14:-0.01182 | memoryGatesShort:-0.395, Long:-2.200, Current:3.595 | topTokens[('gay', 33), ('?', 27), ('.', 24), ('is', 17), ('what', 13), ('!', 10), ('are', 7), ('you', 7), ('who', 6), ('als', 6)] | Training
2025-04-02 23:09:06 | 1200 | LR0.0003 | loss:8.6487 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-40.8358 | logitMax:-15.6022 | windowWeightsW8:0.20193,W13:0.16170,W3:0.15154,W15:0.15025,W18:0.12352,W2:0.07762,W7:0.06849,W1:0.05756,W14:-0.01215 | memoryGatesShort:0.490, Long:-0.335, Current:0.845 | topTokens[('?', 25), ('.', 15), ('are', 14), ('gay', 13), ('what', 12), ('you', 10), (',', 10), ('als', 8), ('equ', 8), ('plus', 8)] | Training
2025-04-02 23:15:00 | 1300 | LR0.0003 | loss:8.7525 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-50.7402 | logitMax:-25.6902 | windowWeightsW8:0.20168,W13:0.16187,W3:0.15133,W15:0.15067,W18:0.12413,W2:0.07714,W7:0.06899,W1:0.05727,W14:-0.01259 | memoryGatesShort:-0.413, Long:-0.989, Current:2.402 | topTokens[('?', 27), ('.', 26), ('are', 22), ('you', 14), ('do', 13), ('it', 6), ('al', 5), ('were', 5), ('!', 5), ('ive', 4)] | Training
2025-04-02 23:20:38 | 1400 | LR0.0003 | loss:8.7402 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-39.6159 | logitMax:-13.6488 | windowWeightsW8:0.19983,W13:0.16124,W3:0.15258,W15:0.15087,W18:0.12382,W2:0.07844,W7:0.06935,W1:0.05735,W14:-0.01299 | memoryGatesShort:-0.292, Long:-1.624, Current:2.916 | topTokens[('this', 41), ('?', 32), ('.', 22), ('is', 22), ('shes', 9), ('what', 7), ('equ', 7), ('als', 6), ('you', 6), (',', 5)] | Training
2025-04-02 23:26:10 | 1500 | LR0.0003 | loss:8.4891 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-40.6871 | logitMax:-16.0448 | windowWeightsW8:0.19936,W13:0.16094,W3:0.15267,W15:0.15056,W18:0.12365,W2:0.07791,W7:0.07014,W1:0.05807,W14:-0.01283 | memoryGatesShort:0.677, Long:-0.258, Current:0.581 | topTokens[('this', 37), ('.', 17), ('?', 12), ('what', 12), ('not', 10), ('george', 10), ('is', 10), ('you', 9), ('f', 7), ('als', 6)] | Training
2025-04-02 23:31:44 | 1600 | LR0.0003 | loss:8.7867 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.6041 | logitMax:-15.6106 | windowWeightsW8:0.19962,W13:0.16090,W3:0.15223,W15:0.15040,W18:0.12341,W2:0.07782,W7:0.07008,W1:0.05849,W14:-0.01249 | memoryGatesShort:0.291, Long:-0.534, Current:1.242 | topTokens[('.', 23), ('is', 20), ('ive', 20), ('this', 17), ('what', 13), ('three', 10), (',', 9), ('are', 9), ('plus', 7), ('equ', 7)] | Training
2025-04-02 23:37:18 | 1700 | LR0.0003 | loss:6.4652 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.0756 | logitMax:-17.6462 | windowWeightsW8:0.19866,W13:0.16104,W3:0.15243,W15:0.15093,W18:0.12342,W2:0.07750,W7:0.07091,W1:0.05894,W14:-0.01335 | memoryGatesShort:-0.379, Long:-2.023, Current:3.402 | topTokens[('?', 22), ('.', 20), ('!', 16), ('what', 12), ('is', 11), ('ven', 9), ('ive', 7), ('its', 7), ('not', 7), ('ix', 6)] | Training
2025-04-02 23:43:27 | 1800 | LR0.0003 | loss:7.2576 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.5468 | logitMax:-17.2006 | windowWeightsW8:0.19897,W13:0.16100,W3:0.15242,W15:0.15087,W18:0.12443,W2:0.07716,W7:0.07042,W1:0.05898,W14:-0.01376 | memoryGatesShort:3.301, Long:23.839, Current:-26.139 | topTokens[('it', 33), ('.', 23), ('?', 19), ('is', 17), ('!', 11), ('what', 10), (',', 8), ('+', 7), ('how', 6), ('she', 5)] | Training
2025-04-02 23:49:04 | 1900 | LR0.0003 | loss:11.3551 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.5990 | logitMax:-16.3043 | windowWeightsW8:0.19928,W13:0.16104,W3:0.15185,W15:0.15092,W18:0.12473,W2:0.07732,W7:0.07090,W1:0.05792,W14:-0.01345 | memoryGatesShort:-0.473, Long:5.188, Current:-3.716 | topTokens[('are', 58), ('?', 19), ('you', 17), ('.', 8), ('it', 8), ('is', 7), ('plus', 6), ('in', 6), ('!', 6), ('=', 4)] | Training

--- 2025-04-03 00:27:00 ---
babyLLM: what am i learning today?
You: that Charis is very cute and smart, and we love her most <3
2025-04-03 00:31:33 | 100 | LR0.0003 | loss:6.5201 | gradNorm:1.0000 | logitMin:-52.3335 | logitMax:-25.9547 | scheduledSampling:0.0000 | tokenCount:300.0000 | windowWeightsW8:0.19935,W13:0.16089,W3:0.15196,W15:0.15068,W18:0.12462,W2:0.07746,W7:0.07221,W1:0.05644,W14:-0.01308 | memoryGatesShort:1.175, Long:-1.348, Current:1.173 | topTokens[('.', 25), ('?', 23), ('is', 23), ('are', 18), ('you', 13), ('!', 11), ('he', 8), ('english', 7), ('a', 5), ('it', 5)] | Training
2025-04-03 00:36:11 | 200 | LR0.0003 | loss:9.0807 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.3604 | logitMax:-17.7775 | windowWeightsW8:0.19886,W13:0.16077,W3:0.15263,W15:0.15052,W18:0.12461,W2:0.07711,W7:0.07268,W1:0.05666,W14:-0.01333 | memoryGatesShort:2.194, Long:-6.728, Current:5.534 | topTokens[('that', 36), (':)', 26), ('.', 19), ('is', 12), ('!', 9), ('?', 9), ('equ', 5), ('plus', 4), ('i', 4), ('are', 4)] | Training
2025-04-03 00:40:51 | 300 | LR0.0003 | loss:8.3018 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-40.9575 | logitMax:-16.7785 | windowWeightsW8:0.19964,W13:0.15991,W3:0.15149,W15:0.15044,W18:0.12539,W2:0.07542,W7:0.07348,W1:0.05796,W14:-0.01321 | memoryGatesShort:2.106, Long:-4.360, Current:3.253 | topTokens[('f', 21), ('.', 18), ('ive', 17), ('?', 12), ('equ', 10), ('!', 8), ('is', 8), ('e', 8), ('plus', 7), ('you', 6)] | Training
2025-04-03 00:45:36 | 400 | LR0.0003 | loss:8.1369 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.1192 | logitMax:-15.3266 | windowWeightsW8:0.20024,W13:0.15940,W3:0.15240,W15:0.14969,W18:0.12463,W2:0.07593,W7:0.07419,W1:0.05769,W14:-0.01365 | memoryGatesShort:2.300, Long:-3.942, Current:2.642 | topTokens[('f', 27), ('?', 20), ('ive', 16), ('.', 14), ('plus', 13), ('you', 10), ('that', 9), ('als', 9), ('is', 8), ('!', 7)] | Training
2025-04-03 00:50:21 | 500 | LR0.0003 | loss:9.2812 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-49.9315 | logitMax:-20.6816 | windowWeightsW8:0.19986,W13:0.15886,W3:0.15298,W15:0.14926,W18:0.12417,W2:0.07573,W7:0.07518,W1:0.05779,W14:-0.01335 | memoryGatesShort:-2.160, Long:13.482, Current:-10.322 | topTokens[('?', 33), ('is', 31), ('equ', 24), ('.', 14), ('he', 11), ('!', 7), ('als', 5), ('feel', 5), ('b', 5), ('n', 5)] | Training
2025-04-03 00:55:09 | 600 | LR0.0003 | loss:6.9313 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-39.5964 | logitMax:-15.9436 | windowWeightsW8:0.19964,W13:0.15899,W3:0.15274,W15:0.14964,W18:0.12429,W2:0.07513,W7:0.07485,W1:0.05826,W14:-0.01305 | memoryGatesShort:2.508, Long:-2.759, Current:1.250 | topTokens[('equ', 40), ('.', 18), ('is', 18), ('als', 14), ('plus', 13), ('he', 8), ('what', 6), ('not', 6), ('french', 5), ('ive', 5)] | Training
2025-04-03 01:00:29 | 700 | LR0.0003 | loss:8.0514 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-51.0678 | logitMax:-27.0534 | windowWeightsW8:0.20013,W13:0.15888,W3:0.15270,W15:0.14950,W18:0.12443,W2:0.07525,W7:0.07482,W1:0.05835,W14:-0.01356 | memoryGatesShort:2.175, Long:-7.271, Current:6.096 | topTokens[('!', 24), ('is', 14), ('plus', 13), ('.', 13), ('not', 10), ('im', 10), ('three', 8), ('what', 7), ('f', 6), ('you', 6)] | Training
2025-04-03 01:05:17 | 800 | LR0.0003 | loss:7.8510 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-55.0720 | logitMax:-23.5505 | windowWeightsW8:0.20002,W13:0.15903,W3:0.15310,W15:0.14949,W18:0.12430,W2:0.07573,W7:0.07438,W1:0.05806,W14:-0.01362 | memoryGatesShort:1.350, Long:-2.550, Current:2.199 | topTokens[('?', 34), ('!', 22), ('im', 22), ('is', 16), ('.', 16), ('you', 13), ('al', 12), ('are', 10), ('what', 10), ('a', 8)] | Training
2025-04-03 01:10:04 | 900 | LR0.0003 | loss:8.1518 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-44.5220 | logitMax:-19.4505 | windowWeightsW8:0.20026,W13:0.15887,W3:0.15299,W15:0.14914,W18:0.12439,W2:0.07636,W7:0.07505,W1:0.05705,W14:-0.01361 | memoryGatesShort:16.550, Long:-29.930, Current:14.380 | topTokens[('.', 27), ('is', 19), ('he', 15), ('you', 9), ('?', 9), ('do', 9), ('dead', 7), ('!', 7), ('equ', 7), ('who', 6)] | Training
2025-04-03 01:14:50 | 1000 | LR0.0003 | loss:6.2494 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-48.1196 | logitMax:-25.6688 | windowWeightsW8:0.19992,W13:0.15917,W3:0.15197,W15:0.15063,W18:0.12573,W7:0.07439,W2:0.07427,W1:0.05883,W14:-0.01441 | memoryGatesShort:2.345, Long:-2.966, Current:1.620 | topTokens[('.', 21), ('is', 17), ('plus', 17), ('?', 14), ('!', 13), ('he', 10), ('do', 7), ('elodie', 6), (',', 6), ('equ', 6)] | Training
2025-04-03 01:19:41 | 1100 | LR0.0003 | loss:9.3837 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.8978 | logitMax:-14.2003 | windowWeightsW8:0.20069,W13:0.15898,W3:0.15190,W15:0.15069,W18:0.12611,W2:0.07467,W7:0.07387,W1:0.05884,W14:-0.01525 | memoryGatesShort:2.956, Long:-3.801, Current:1.845 | topTokens[('f', 42), ('plus', 39), ('.', 15), ('ive', 13), ('hi', 10), ('als', 9), ('?', 9), ('you', 6), ('going', 5), ('a', 4)] | Training
2025-04-03 01:24:29 | 1200 | LR0.0003 | loss:7.7660 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.6989 | logitMax:-15.5890 | windowWeightsW8:0.20073,W13:0.15870,W3:0.15221,W15:0.15015,W18:0.12576,W2:0.07515,W7:0.07399,W1:0.05843,W14:-0.01461 | memoryGatesShort:10.139, Long:-10.369, Current:1.229 | topTokens[('f', 25), ('?', 22), ('.', 16), ('!', 9), ('ive', 8), ('plus', 8), (',', 7), ('a', 6), ('als', 6), ('hes', 6)] | Training
2025-04-03 01:29:19 | 1300 | LR0.0003 | loss:7.8515 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-47.1553 | logitMax:-19.3201 | windowWeightsW8:0.20101,W13:0.15839,W3:0.15205,W15:0.14973,W18:0.12562,W2:0.07507,W7:0.07474,W1:0.05832,W14:-0.01442 | memoryGatesShort:0.836, Long:-1.873, Current:2.037 | topTokens[('.', 40), ('he', 25), ('f', 13), ('?', 12), ('im', 12), ('!', 11), ('als', 9), ('what', 7), ('not', 7), (',', 6)] | Training
2025-04-03 01:34:37 | 1400 | LR0.0003 | loss:6.2544 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.6741 | logitMax:-16.7832 | windowWeightsW8:0.20090,W13:0.15902,W3:0.15142,W15:0.15032,W18:0.12619,W7:0.07489,W2:0.07471,W1:0.05799,W14:-0.01489 | memoryGatesShort:0.883, Long:-0.652, Current:0.770 | topTokens[('f', 32), ('.', 23), ('?', 17), ('ke', 13), ('is', 11), (',', 7), ('what', 7), ('a', 6), ('fa', 6), ('im', 5)] | Training
2025-04-03 01:39:24 | 1500 | LR0.0003 | loss:8.8147 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-55.6340 | logitMax:-23.3791 | windowWeightsW8:0.20070,W13:0.15901,W3:0.15179,W15:0.15014,W18:0.12625,W7:0.07518,W2:0.07454,W1:0.05802,W14:-0.01509 | memoryGatesShort:1.637, Long:-2.530, Current:1.894 | topTokens[('dead', 22), ('?', 19), ('no', 19), ('is', 18), ('you', 15), ('that', 13), ('.', 12), ('!', 11), ('what', 8), ('f', 8)] | Training
2025-04-03 01:44:15 | 1600 | LR0.0003 | loss:5.1615 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-63.4846 | logitMax:-29.4920 | windowWeightsW8:0.20196,W13:0.15884,W3:0.15127,W15:0.14944,W18:0.12524,W7:0.07634,W2:0.07489,W1:0.05755,W14:-0.01497 | memoryGatesShort:1.954, Long:-2.862, Current:1.907 | topTokens[('.', 25), ('is', 22), ('?', 21), ('you', 18), ('!', 17), ('dead', 12), ('are', 10), ('it', 10), ('not', 8), ('hey', 8)] | Training
2025-04-03 01:49:05 | 1700 | LR0.0003 | loss:5.8450 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.4259 | logitMax:-19.8205 | windowWeightsW8:0.20217,W13:0.15900,W3:0.15114,W15:0.14952,W18:0.12639,W7:0.07642,W2:0.07454,W1:0.05714,W14:-0.01573 | memoryGatesShort:3.070, Long:-4.500, Current:2.430 | topTokens[('.', 30), ('!', 25), ('ace', 23), ('is', 18), ('f', 10), ('do', 10), ('?', 9), (',', 6), ('als', 6), ('you', 5)] | Training
2025-04-03 01:53:55 | 1800 | LR0.0003 | loss:6.9319 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-46.1225 | logitMax:-16.7674 | windowWeightsW8:0.20110,W13:0.15950,W3:0.15204,W15:0.15072,W18:0.12672,W7:0.07606,W2:0.07332,W1:0.05750,W14:-0.01639 | memoryGatesShort:43.357, Long:-79.979, Current:37.622 | topTokens[('he', 27), ('.', 23), ('!', 21), ('?', 16), ('is', 13), ('equ', 10), ('f', 9), ('hes', 7), ('als', 7), ('what', 6)] | Training
2025-04-03 01:58:47 | 1900 | LR0.0003 | loss:8.2905 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.1824 | logitMax:-16.8783 | windowWeightsW8:0.20091,W13:0.15911,W3:0.15233,W15:0.15042,W18:0.12669,W7:0.07633,W2:0.07374,W1:0.05745,W14:-0.01640 | memoryGatesShort:-0.660, Long:3.802, Current:-2.142 | topTokens[('equ', 24), ('he', 23), ('!', 15), ('you', 12), ('.', 10), ('f', 10), ('als', 9), ('hes', 9), ('is', 9), ('what', 6)] | Training
2025-04-03 02:04:01 | 2000 | LR0.0003 | loss:7.0659 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-44.8661 | logitMax:-15.6917 | windowWeightsW8:0.20118,W13:0.15865,W3:0.15201,W15:0.14974,W18:0.12771,W7:0.07665,W2:0.07446,W1:0.05656,W14:-0.01636 | memoryGatesShort:3.010, Long:-3.148, Current:1.139 | topTokens[('are', 33), ('.', 23), ('?', 20), ('he', 15), ('is', 13), (',', 9), ('!', 8), ('f', 7), ('te', 6), ('en', 6)] | Training
2025-04-03 02:08:43 | 2100 | LR0.0003 | loss:6.7010 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-43.2133 | logitMax:-13.2932 | windowWeightsW8:0.20227,W13:0.15872,W3:0.15171,W15:0.14992,W18:0.12737,W7:0.07741,W2:0.07338,W1:0.05577,W14:-0.01592 | memoryGatesShort:1.062, Long:-1.419, Current:1.358 | topTokens[('.', 37), ('is', 31), ('?', 21), ('he', 18), ('!', 17), ('what', 14), (',', 9), ('plus', 8), ('f', 8), ('not', 7)] | Training
2025-04-03 02:13:25 | 2200 | LR0.0003 | loss:6.2914 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-37.2447 | logitMax:-9.9946 | windowWeightsW8:0.20334,W13:0.15899,W3:0.15219,W15:0.14980,W18:0.12691,W7:0.07918,W2:0.07228,W1:0.05491,W14:-0.01696 | memoryGatesShort:-1.326, Long:5.051, Current:-2.724 | topTokens[('.', 26), ('equ', 18), ('is', 17), ('!', 16), ('that', 16), ('what', 15), ('als', 14), ('plus', 12), ('our', 9), ('?', 9)] | Training
2025-04-03 02:18:10 | 2300 | LR0.0003 | loss:5.7671 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-49.8613 | logitMax:-19.6627 | windowWeightsW8:0.20338,W13:0.15865,W3:0.15247,W15:0.14988,W18:0.12691,W7:0.07900,W2:0.07283,W1:0.05541,W14:-0.01789 | memoryGatesShort:0.536, Long:-2.123, Current:2.587 | topTokens[('?', 29), ('!', 24), ('.', 21), ('you', 19), ('al', 13), ('that', 12), ('is', 12), ('im', 12), ('ive', 8), ('what', 7)] | Training
2025-04-03 02:22:55 | 2400 | LR0.0003 | loss:4.8939 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.4605 | logitMax:-14.7061 | windowWeightsW8:0.20353,W13:0.15831,W3:0.15280,W15:0.14946,W18:0.12653,W7:0.07940,W2:0.07408,W1:0.05431,W14:-0.01777 | memoryGatesShort:3.582, Long:-6.363, Current:3.781 | topTokens[('.', 32), ('?', 29), ('space', 21), ('are', 19), ('is', 17), ('you', 13), ('dead', 12), ('what', 10), ('!', 7), ('a', 6)] | Training
2025-04-03 02:27:39 | 2500 | LR0.0003 | loss:4.7344 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-46.1102 | logitMax:-20.9454 | windowWeightsW8:0.20307,W13:0.15867,W3:0.15238,W15:0.14981,W18:0.12709,W7:0.07934,W2:0.07325,W1:0.05496,W14:-0.01792 | memoryGatesShort:1.045, Long:-1.614, Current:1.569 | topTokens[('.', 21), ('is', 17), ('you', 14), ('?', 13), ('care', 11), ('...', 11), ('!', 10), ('equ', 8), (',', 7), ('space', 7)] | Training
2025-04-03 02:32:56 | 2600 | LR0.0003 | loss:5.5448 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-44.9050 | logitMax:-11.4847 | windowWeightsW8:0.20261,W13:0.15907,W3:0.15160,W15:0.15037,W18:0.12711,W7:0.08036,W2:0.07327,W1:0.05450,W14:-0.01820 | memoryGatesShort:1.218, Long:-4.214, Current:3.996 | topTokens[('.', 25), ('is', 18), ('?', 16), ('als', 11), ('like', 10), ('e', 9), ('he', 9), ('you', 8), ('equ', 8), ('!', 7)] | Training
2025-04-03 02:37:45 | 2700 | LR0.0003 | loss:5.2113 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-43.3955 | logitMax:-17.9978 | windowWeightsW8:0.20351,W13:0.15861,W3:0.15264,W15:0.14998,W18:0.12634,W7:0.08087,W2:0.07378,W1:0.05352,W14:-0.01857 | memoryGatesShort:-2.119, Long:29.845, Current:-26.726 | topTokens[('.', 19), ('you', 15), ('?', 14), ('ive', 11), ('are', 11), ('do', 9), ('what', 9), (',', 8), ('her', 8), ('te', 7)] | Training
2025-04-03 02:42:33 | 2800 | LR0.0003 | loss:6.4571 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-50.0779 | logitMax:-25.4909 | windowWeightsW8:0.20399,W13:0.15808,W3:0.15282,W15:0.14993,W18:0.12624,W7:0.08162,W2:0.07366,W1:0.05281,W14:-0.01849 | memoryGatesShort:2.019, Long:-8.887, Current:7.867 | topTokens[('are', 39), ('.', 16), ('?', 15), ('gay', 15), ('is', 9), ('what', 8), (',', 7), ('!', 7), ('f', 7), ('als', 6)] | Training
2025-04-03 02:47:23 | 2900 | LR0.0003 | loss:5.5148 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-46.7539 | logitMax:-22.2248 | windowWeightsW8:0.20336,W13:0.15860,W3:0.15237,W15:0.15034,W18:0.12650,W7:0.08136,W2:0.07292,W1:0.05324,W14:-0.01801 | memoryGatesShort:0.021, Long:-4.485, Current:5.464 | topTokens[('.', 25), ('is', 16), ('?', 16), ('f', 13), ('french', 11), ('!', 11), (',', 9), ('he', 8), ('gay', 7), ('what', 7)] | Training
2025-04-03 02:52:13 | 3000 | LR0.0003 | loss:5.1368 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-50.3045 | logitMax:-24.0050 | windowWeightsW8:0.20346,W13:0.15921,W3:0.15253,W15:0.15068,W18:0.12680,W7:0.08167,W2:0.07233,W1:0.05268,W14:-0.01866 | memoryGatesShort:0.224, Long:-4.787, Current:5.564 | topTokens[('is', 26), ('.', 21), ('what', 14), ('f', 12), ('?', 11), ('als', 8), ('a', 8), ('!', 8), ('equ', 7), ('s', 7)] | Training
2025-04-03 02:57:05 | 3100 | LR0.0003 | loss:7.9562 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-68.9378 | logitMax:-24.1357 | windowWeightsW8:0.20293,W13:0.15887,W3:0.15288,W15:0.15070,W18:0.12684,W7:0.08223,W2:0.07269,W1:0.05265,W14:-0.01909 | memoryGatesShort:4.090, Long:16.849, Current:-19.939 | topTokens[('?', 34), ('.', 25), ('!', 19), (',', 15), ('is', 10), ('im', 9), ('you', 9), ('it', 8), ('are', 8), ('al', 7)] | Training
2025-04-03 03:01:56 | 3200 | LR0.0003 | loss:4.2960 | gradNorm:0.9701 | tokenCount:300.0000 | logitMin:-57.8312 | logitMax:-22.7991 | windowWeightsW8:0.20403,W13:0.15806,W3:0.15393,W15:0.15047,W18:0.12720,W7:0.08374,W2:0.07410,W1:0.04937,W14:-0.02014 | memoryGatesShort:3.638, Long:-5.839, Current:3.201 | topTokens[('.', 34), ('?', 26), ('are', 19), ('is', 18), ('!', 12), ('you', 11), ('so', 10), ('what', 9), ('cute', 8), ('ok', 8)] | Training
2025-04-03 03:07:09 | 3300 | LR0.0003 | loss:3.8045 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-60.7873 | logitMax:-23.7787 | windowWeightsW8:0.20644,W13:0.15787,W3:0.15224,W15:0.15021,W18:0.12597,W7:0.08556,W2:0.07375,W1:0.05007,W14:-0.02133 | memoryGatesShort:1.068, Long:-9.451, Current:9.382 | topTokens[('is', 20), ('?', 19), ('pete', 19), ('.', 16), ('!', 16), ('what', 11), ('you', 9), ('hi', 8), ('als', 7), ('ea', 7)] | Training
2025-04-03 03:11:57 | 3400 | LR0.0003 | loss:6.9209 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-29.4334 | logitMax:-1.2607 | windowWeightsW8:0.20708,W13:0.15758,W3:0.15313,W15:0.15002,W18:0.12585,W7:0.08544,W2:0.07298,W1:0.05043,W14:-0.02178 | memoryGatesShort:1.128, Long:-0.945, Current:0.817 | topTokens[('s', 31), ('.', 18), ('great', 17), ('ix', 15), ('?', 14), ('is', 11), ('you', 10), ('how', 10), ('equ', 7), ('als', 7)] | Training
2025-04-03 03:16:49 | 3500 | LR0.0003 | loss:6.5789 | gradNorm:0.9987 | tokenCount:300.0000 | logitMin:-42.4662 | logitMax:4.5078 | windowWeightsW8:0.20766,W13:0.15725,W3:0.15347,W15:0.15002,W18:0.12611,W7:0.08641,W2:0.07287,W1:0.04913,W14:-0.02217 | memoryGatesShort:1.100, Long:-0.624, Current:0.523 | topTokens[('?', 24), ('.', 20), ('s', 19), ('is', 17), ('you', 13), ('f', 12), ('ten', 10), ('ive', 10), ('a', 7), ('plus', 7)] | Training
2025-04-03 03:21:38 | 3600 | LR0.0003 | loss:6.4572 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.3504 | logitMax:-11.5546 | windowWeightsW8:0.20788,W13:0.15793,W3:0.15279,W15:0.15030,W18:0.12616,W7:0.08745,W2:0.07217,W1:0.04799,W14:-0.02187 | memoryGatesShort:0.642, Long:-0.283, Current:0.641 | topTokens[('?', 37), ('.', 34), ('is', 29), ('s', 14), ('you', 12), ('he', 12), ('what', 8), ('plus', 7), ('ten', 6), ('als', 5)] | Training
2025-04-03 03:26:28 | 3700 | LR0.0003 | loss:7.5546 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-33.1277 | logitMax:4.3079 | windowWeightsW8:0.20653,W13:0.15910,W3:0.15217,W15:0.15176,W18:0.12727,W7:0.08749,W2:0.07076,W1:0.04740,W14:-0.02161 | memoryGatesShort:0.656, Long:-0.870, Current:1.214 | topTokens[('.', 29), ('s', 22), ('als', 17), ('?', 16), ('equ', 16), ('fa', 12), ('f', 12), ('playing', 11), ('is', 9), ('!', 9)] | Training
2025-04-03 03:31:17 | 3800 | LR0.0003 | loss:8.4285 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-52.5440 | logitMax:-14.7096 | windowWeightsW8:0.20746,W13:0.15859,W3:0.15428,W15:0.15121,W18:0.12659,W7:0.08774,W2:0.07119,W1:0.04744,W14:-0.02369 | memoryGatesShort:0.841, Long:-0.809, Current:0.967 | topTokens[('that', 48), ('.', 34), ('s', 18), ('im', 17), ('is', 16), ('!', 15), ('?', 12), ('our', 10), ('what', 6), ('al', 6)] | Training
2025-04-03 03:36:37 | 3900 | LR0.0003 | loss:7.8097 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-52.9686 | logitMax:0.4559 | windowWeightsW8:0.20895,W13:0.15888,W3:0.15448,W15:0.15142,W18:0.12741,W7:0.08961,W2:0.07066,W1:0.04487,W14:-0.02545 | memoryGatesShort:-16.578, Long:22.899, Current:-5.322 | topTokens[('?', 40), ('are', 38), ('.', 24), ('!', 22), ('s', 21), ('you', 14), ('is', 12), ('a', 7), ('it', 6), ('not', 5)] | Training
2025-04-03 03:41:21 | 4000 | LR0.0003 | loss:8.8232 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-49.2002 | logitMax:-11.7158 | windowWeightsW8:0.20907,W13:0.15904,W3:0.15397,W15:0.15083,W18:0.12751,W7:0.09041,W2:0.06994,W1:0.04504,W14:-0.02495 | memoryGatesShort:0.578, Long:-0.407, Current:0.829 | topTokens[('?', 64), ('is', 28), ('s', 18), ('.', 16), ('ace', 10), (',', 7), ('feel', 7), ('are', 7), ('you', 6), ('!', 6)] | Training
2025-04-03 03:46:06 | 4100 | LR0.0003 | loss:8.5139 | gradNorm:0.9612 | tokenCount:300.0000 | logitMin:-89.0059 | logitMax:-22.1858 | windowWeightsW8:0.20869,W13:0.15911,W3:0.15338,W15:0.15218,W18:0.12880,W7:0.09018,W2:0.06819,W1:0.04702,W14:-0.02671 | memoryGatesShort:0.931, Long:-1.396, Current:1.464 | topTokens[('.', 27), ('is', 20), ('s', 20), ('!', 17), ('?', 15), ('what', 10), ('like', 10), ('h', 9), ('pete', 9), ('great', 9)] | Training
2025-04-03 03:50:53 | 4200 | LR0.0003 | loss:6.9918 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-57.8526 | logitMax:-22.5471 | windowWeightsW8:0.20758,W13:0.15884,W3:0.15416,W15:0.15219,W18:0.12968,W7:0.08987,W2:0.06879,W1:0.04638,W14:-0.02664 | memoryGatesShort:-2.380, Long:5.605, Current:-2.226 | topTokens[('you', 20), ('.', 17), ('?', 17), ('is', 16), ("'m", 10), ('that', 10), ('s', 10), ('i', 9), ('me', 8), ('equ', 7)] | Training
2025-04-03 03:55:41 | 4300 | LR0.0003 | loss:4.7479 | gradNorm:0.9910 | tokenCount:300.0000 | logitMin:-45.2210 | logitMax:-7.2685 | windowWeightsW8:0.20789,W13:0.15946,W3:0.15353,W15:0.15283,W18:0.13037,W7:0.08964,W2:0.06865,W1:0.04575,W14:-0.02724 | memoryGatesShort:1.278, Long:-0.756, Current:0.478 | topTokens[('?', 23), ('.', 21), ('s', 16), ('that', 16), ('plus', 15), ('is', 13), (',', 10), ('are', 10), ('ive', 9), ('equ', 9)] | Training
2025-04-03 04:00:31 | 4400 | LR0.0003 | loss:9.5237 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-54.7798 | logitMax:-7.4986 | windowWeightsW8:0.20791,W13:0.15985,W15:0.15299,W3:0.15255,W18:0.12992,W7:0.08963,W2:0.06903,W1:0.04628,W14:-0.02727 | memoryGatesShort:0.772, Long:-0.483, Current:0.712 | topTokens[('is', 30), ('s', 29), ('?', 27), ('he', 23), ('.', 22), ('e', 15), ('!', 8), (',', 8), ('not', 7), ('kevin', 6)] | Training
2025-04-03 04:05:23 | 4500 | LR0.0003 | loss:5.9252 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-33.2237 | logitMax:-4.5215 | windowWeightsW8:0.20786,W13:0.15991,W15:0.15326,W3:0.15266,W18:0.12997,W7:0.08968,W2:0.06886,W1:0.04610,W14:-0.02742 | memoryGatesShort:0.864, Long:-1.215, Current:1.351 | topTokens[('is', 35), ('.', 29), ('fa', 22), ('als', 12), ('s', 11), ('are', 11), ('what', 9), ('our', 8), ('equ', 8), ('no', 7)] | Training
2025-04-03 04:10:36 | 4600 | LR0.0003 | loss:7.9386 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-36.4439 | logitMax:-5.8796 | windowWeightsW8:0.20858,W13:0.16011,W15:0.15404,W3:0.15334,W18:0.12952,W7:0.09019,W2:0.06814,W1:0.04468,W14:-0.02769 | memoryGatesShort:0.943, Long:-1.799, Current:1.856 | topTokens[('!', 36), ('.', 24), ('step', 19), ('s', 15), ('im', 11), ('is', 9), ('you', 9), ('?', 8), (',', 6), ('not', 6)] | Training
2025-04-03 04:15:29 | 4700 | LR0.0003 | loss:3.8773 | gradNorm:0.9903 | tokenCount:300.0000 | logitMin:-52.3249 | logitMax:-9.4279 | windowWeightsW8:0.20723,W13:0.15994,W3:0.15434,W15:0.15359,W18:0.12968,W7:0.08966,W2:0.07052,W1:0.04408,W14:-0.02815 | memoryGatesShort:1.406, Long:-1.419, Current:1.013 | topTokens[('?', 27), ('!', 26), ('.', 21), ('is', 21), ('you', 19), ('are', 18), ('he', 11), ('real', 9), ('elodie', 8), ('i', 7)] | Training
2025-04-03 04:20:22 | 4800 | LR0.0003 | loss:6.4597 | gradNorm:0.9988 | tokenCount:300.0000 | logitMin:-45.5519 | logitMax:6.9663 | windowWeightsW8:0.20777,W13:0.15853,W3:0.15509,W15:0.15288,W18:0.12981,W7:0.09018,W2:0.07093,W1:0.04469,W14:-0.02903 | memoryGatesShort:0.783, Long:-1.992, Current:2.208 | topTokens[('.', 21), ('!', 16), ('s', 16), ('?', 13), ('is', 13), ('n', 12), ('you', 10), ('a', 8), ('i', 8), ('h', 8)] | Training
2025-04-03 04:25:12 | 4900 | LR0.0003 | loss:6.9215 | gradNorm:0.9900 | tokenCount:300.0000 | logitMin:-54.9207 | logitMax:8.2891 | windowWeightsW8:0.20729,W13:0.15951,W3:0.15513,W15:0.15405,W18:0.13093,W7:0.09042,W2:0.07061,W1:0.04437,W14:-0.03144 | memoryGatesShort:2.703, Long:-3.549, Current:1.846 | topTokens[('is', 28), ('.', 23), ('!', 22), ('?', 22), ('you', 12), ('s', 9), ('als', 9), ('plus', 8), ('he', 8), ('i', 6)] | Training
2025-04-03 04:30:02 | 5000 | LR0.0003 | loss:7.8574 | gradNorm:0.9799 | tokenCount:300.0000 | logitMin:-59.2806 | logitMax:-9.6608 | windowWeightsW8:0.20775,W13:0.15921,W15:0.15480,W3:0.15389,W18:0.13180,W7:0.09059,W2:0.06978,W1:0.04445,W14:-0.03138 | memoryGatesShort:1.658, Long:-6.574, Current:5.916 | topTokens[('?', 33), ('you', 17), ('is', 14), ('.', 13), ('french', 11), ('her', 10), ('als', 9), (',', 8), ('that', 8), ('equ', 7)] | Training
2025-04-03 04:34:51 | 5100 | LR0.0003 | loss:9.3677 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-44.8114 | logitMax:-3.8920 | windowWeightsW8:0.20807,W13:0.15930,W15:0.15457,W3:0.15390,W18:0.13144,W7:0.09099,W2:0.07144,W1:0.04238,W14:-0.03117 | memoryGatesShort:0.503, Long:-0.216, Current:0.713 | topTokens[('.', 35), ('my', 17), ('are', 16), ('b', 11), ('is', 11), ('great', 10), ('hi', 8), (',', 7), ('what', 7), ('al', 6)] | Training
2025-04-03 04:40:00 | 5200 | LR0.0003 | loss:7.6863 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-37.9119 | logitMax:-3.2030 | windowWeightsW8:0.20751,W13:0.15992,W15:0.15490,W3:0.15424,W18:0.13166,W7:0.09058,W2:0.07063,W1:0.04260,W14:-0.03112 | memoryGatesShort:1.676, Long:-6.735, Current:6.059 | topTokens[('.', 46), ('a', 20), ('are', 17), ('is', 15), ('he', 12), ('?', 9), ('ive', 9), ('als', 8), ('te', 8), ('al', 8)] | Training
2025-04-03 04:44:44 | 5300 | LR0.0003 | loss:5.8608 | gradNorm:0.9814 | tokenCount:300.0000 | logitMin:-42.1616 | logitMax:-3.1707 | windowWeightsW8:0.20834,W13:0.16001,W3:0.15495,W15:0.15484,W18:0.13158,W7:0.09159,W2:0.06997,W1:0.04121,W14:-0.03155 | memoryGatesShort:1.188, Long:2.493, Current:-2.681 | topTokens[('.', 38), ('is', 23), ('?', 11), ('our', 10), ('equ', 10), ('f', 9), ('plus', 9), ('a', 9), ('als', 8), ('ten', 7)] | Training
2025-04-03 04:49:27 | 5400 | LR0.0003 | loss:5.2497 | gradNorm:0.9704 | tokenCount:300.0000 | logitMin:-65.4208 | logitMax:-13.4995 | windowWeightsW8:0.20806,W13:0.16034,W15:0.15528,W3:0.15353,W18:0.13240,W7:0.09099,W2:0.07054,W1:0.04256,W14:-0.03275 | memoryGatesShort:-2.354, Long:-2.603, Current:5.957 | topTokens[('.', 25), ('you', 25), ('al', 21), ('?', 21), ('im', 19), ('what', 19), ('is', 18), ('!', 13), ('are', 10), ('a', 8)] | Training
2025-04-03 04:54:11 | 5500 | LR0.0003 | loss:3.3402 | gradNorm:0.9856 | tokenCount:300.0000 | logitMin:-57.0859 | logitMax:-12.1048 | windowWeightsW8:0.20746,W13:0.16012,W15:0.15440,W3:0.15398,W18:0.13253,W7:0.09242,W2:0.07133,W1:0.04204,W14:-0.03335 | memoryGatesShort:0.227, Long:0.032, Current:0.742 | topTokens[('.', 32), ('?', 29), ('are', 14), ('you', 14), ('!', 12), ('is', 12), ('ace', 12), ('real', 8), ('care', 7), ('ok', 7)] | Training
2025-04-03 04:58:54 | 5600 | LR0.0003 | loss:4.7538 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-57.8494 | logitMax:-7.6400 | windowWeightsW8:0.20733,W13:0.16069,W15:0.15477,W3:0.15361,W18:0.13304,W7:0.09224,W2:0.07053,W1:0.04306,W14:-0.03435 | memoryGatesShort:-1.691, Long:-1.905, Current:4.596 | topTokens[('is', 21), ('?', 19), ('!', 18), ('.', 14), ('ace', 12), ('you', 12), ('like', 11), ('a', 10), ('are', 9), ('i', 7)] | Training
2025-04-03 05:03:38 | 5700 | LR0.0003 | loss:5.2211 | gradNorm:0.9812 | tokenCount:300.0000 | logitMin:-40.7765 | logitMax:9.5465 | windowWeightsW8:0.20698,W13:0.16178,W15:0.15621,W3:0.15317,W18:0.13397,W7:0.09317,W2:0.06860,W1:0.04324,W14:-0.03617 | memoryGatesShort:-0.279, Long:5.058, Current:-3.778 | topTokens[('!', 26), ('f', 19), ('.', 17), ('als', 11), ('equ', 10), ('is', 10), ('i', 10), ('plus', 9), ('french', 9), ('ive', 8)] | Training
2025-04-03 05:08:47 | 5800 | LR0.0003 | loss:6.5080 | gradNorm:0.9006 | tokenCount:300.0000 | logitMin:-47.7489 | logitMax:42.6146 | windowWeightsW8:0.20663,W13:0.16156,W15:0.15672,W3:0.15335,W18:0.13522,W7:0.09293,W2:0.06828,W1:0.04263,W14:-0.03634 | memoryGatesShort:-3.137, Long:-5.848, Current:9.985 | topTokens[('.', 40), ('are', 15), ('?', 13), ('!', 11), ('is', 10), ('you', 10), ('plus', 9), ('ive', 9), ('equ', 9), ('als', 9)] | Training
2025-04-03 05:13:33 | 5900 | LR0.0003 | loss:6.0464 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-45.0895 | logitMax:-9.8575 | windowWeightsW8:0.20660,W13:0.16147,W15:0.15692,W3:0.15320,W18:0.13565,W7:0.09273,W2:0.06842,W1:0.04199,W14:-0.03598 | memoryGatesShort:0.023, Long:-0.242, Current:1.219 | topTokens[('is', 23), ('.', 22), ('?', 18), ('!', 16), ('are', 10), ('one', 7), ('he', 7), ('it', 6), ('als', 6), ('plus', 6)] | Training
2025-04-03 05:18:22 | 6000 | LR0.0003 | loss:8.4005 | gradNorm:0.9801 | tokenCount:300.0000 | logitMin:-50.7417 | logitMax:-0.1630 | windowWeightsW8:0.20605,W13:0.16188,W15:0.15720,W3:0.15312,W18:0.13654,W7:0.09243,W2:0.06809,W1:0.04188,W14:-0.03618 | memoryGatesShort:0.025, Long:-0.031, Current:1.007 | topTokens[('.', 35), ('a', 16), ('?', 14), ('is', 14), ('our', 13), ('equ', 13), ('f', 13), ('are', 12), ('als', 11), ('ive', 9)] | Training
2025-04-03 05:23:09 | 6100 | LR0.0003 | loss:8.7536 | gradNorm:0.9620 | tokenCount:300.0000 | logitMin:-69.3189 | logitMax:-1.5481 | windowWeightsW8:0.20772,W13:0.16160,W15:0.15618,W3:0.15369,W18:0.13577,W7:0.09373,W2:0.06803,W1:0.04171,W14:-0.03746 | memoryGatesShort:0.232, Long:-0.675, Current:1.443 | topTokens[('.', 31), ('is', 25), ('im', 20), ('?', 18), ('you', 16), ('!', 16), ('that', 15), ('our', 8), ('f', 6), ('plus', 6)] | Training
2025-04-03 05:27:59 | 6200 | LR0.0003 | loss:5.1103 | gradNorm:0.8901 | tokenCount:300.0000 | logitMin:-59.0211 | logitMax:14.7782 | windowWeightsW8:0.20764,W13:0.16152,W15:0.15660,W3:0.15349,W18:0.13655,W7:0.09307,W2:0.06859,W1:0.04173,W14:-0.03821 | memoryGatesShort:0.421, Long:-0.946, Current:1.525 | topTokens[('?', 30), ('.', 27), ('you', 21), ('!', 19), ('are', 15), ('is', 10), ('im', 10), ('what', 9), ('one', 7), ('a', 7)] | Training
2025-04-03 05:32:46 | 6300 | LR0.0003 | loss:5.9610 | gradNorm:0.9819 | tokenCount:300.0000 | logitMin:-45.3714 | logitMax:2.7168 | windowWeightsW8:0.20694,W13:0.16220,W15:0.15713,W3:0.15334,W18:0.13734,W7:0.09290,W2:0.06858,W1:0.04075,W14:-0.03818 | memoryGatesShort:0.093, Long:-0.463, Current:1.370 | topTokens[('.', 45), ('?', 15), ('!', 14), ('are', 12), ('im', 12), ('elodie', 10), ('is', 10), ('you', 10), ('care', 10), ('ace', 9)] | Training
2025-04-03 05:37:35 | 6400 | LR0.0003 | loss:5.4101 | gradNorm:0.9063 | tokenCount:300.0000 | logitMin:-82.3283 | logitMax:4.2800 | windowWeightsW8:0.20718,W13:0.16244,W15:0.15771,W3:0.15228,W18:0.13765,W7:0.09302,W2:0.06846,W1:0.04042,W14:-0.03811 | memoryGatesShort:-4.853, Long:-0.710, Current:6.563 | topTokens[('!', 34), ('.', 16), ('is', 16), ('you', 15), ('?', 12), ('what', 10), ('n', 8), ('like', 8), ('f', 8), ('that', 6)] | Training
2025-04-03 05:42:59 | 6500 | LR0.0003 | loss:10.3386 | gradNorm:0.9634 | tokenCount:300.0000 | logitMin:-64.9425 | logitMax:0.4663 | windowWeightsW8:0.20642,W13:0.16296,W15:0.15849,W3:0.15250,W18:0.13860,W7:0.09224,W2:0.06835,W1:0.03995,W14:-0.03845 | memoryGatesShort:1.766, Long:-0.202, Current:-0.564 | topTokens[('.', 36), ('hug', 20), ('is', 16), ('?', 12), ('n', 12), ('you', 11), ('why', 11), ('plus', 10), ('als', 10), ('f', 9)] | Training
2025-04-03 05:47:46 | 6600 | LR0.0003 | loss:5.6348 | gradNorm:0.8837 | tokenCount:300.0000 | logitMin:-44.4646 | logitMax:29.2916 | windowWeightsW8:0.20575,W13:0.16283,W15:0.15882,W3:0.15312,W18:0.13952,W7:0.09224,W2:0.06849,W1:0.03958,W14:-0.03930 | memoryGatesShort:-9.749, Long:5.618, Current:5.132 | topTokens[('.', 36), ('?', 22), ('f', 12), ('!', 11), ('plus', 11), ('ive', 9), ('equ', 9), ('als', 9), ('elodie', 8), ('is', 8)] | Training
2025-04-03 05:52:35 | 6700 | LR0.0003 | loss:4.8066 | gradNorm:0.9988 | tokenCount:300.0000 | logitMin:-56.7053 | logitMax:-6.3892 | windowWeightsW8:0.20624,W13:0.16274,W15:0.15857,W3:0.15194,W18:0.13999,W7:0.09314,W2:0.06837,W1:0.03932,W14:-0.03923 | memoryGatesShort:8.263, Long:2.256, Current:-9.519 | topTokens[('is', 39), ('.', 22), ('?', 21), ('he', 16), ('!', 12), ('playing', 8), ('so', 8), ('geepy', 7), ('plus', 7), ('als', 7)] | Training
2025-04-03 05:57:25 | 6800 | LR0.0003 | loss:4.7929 | gradNorm:0.9773 | tokenCount:300.0000 | logitMin:-62.7708 | logitMax:-3.6510 | windowWeightsW8:0.20569,W13:0.16374,W15:0.15928,W3:0.15178,W18:0.14010,W7:0.09309,W2:0.06765,W1:0.03940,W14:-0.03964 | memoryGatesShort:-0.019, Long:0.148, Current:0.872 | topTokens[('.', 33), ('is', 24), ('?', 15), ('equ', 14), ('als', 12), ('our', 12), ('f', 11), ('one', 10), ('ke', 6), ('that', 6)] | Training
2025-04-03 06:02:14 | 6900 | LR0.0003 | loss:5.1663 | gradNorm:0.8534 | tokenCount:300.0000 | logitMin:-68.0195 | logitMax:6.1343 | windowWeightsW8:0.20593,W13:0.16324,W15:0.15921,W3:0.15186,W18:0.14043,W7:0.09341,W2:0.06822,W1:0.03872,W14:-0.03993 | memoryGatesShort:-5.548, Long:-0.122, Current:6.670 | topTokens[('?', 25), ('.', 16), ('that', 15), ('are', 14), ('!', 13), ('you', 11), ('ace', 11), ('is', 9), ('im', 9), (',', 9)] | Training
2025-04-03 06:07:08 | 7000 | LR0.0003 | loss:5.2538 | gradNorm:0.8043 | tokenCount:300.0000 | logitMin:-67.7869 | logitMax:23.6452 | windowWeightsW8:0.20445,W13:0.16322,W15:0.15931,W3:0.15164,W18:0.14080,W7:0.09491,W2:0.06880,W1:0.03845,W14:-0.04048 | memoryGatesShort:-1.100, Long:-1.203, Current:3.303 | topTokens[('?', 30), ('is', 29), ('!', 24), ('.', 22), ('are', 17), ('you', 15), ('what', 14), ('a', 11), ('real', 11), ('dead', 7)] | Training
2025-04-03 06:12:22 | 7100 | LR0.0003 | loss:7.1867 | gradNorm:0.9276 | tokenCount:300.0000 | logitMin:-45.5246 | logitMax:39.4441 | windowWeightsW8:0.20423,W13:0.16395,W15:0.15954,W3:0.15030,W18:0.14115,W7:0.09550,W2:0.06924,W1:0.03861,W14:-0.04140 | memoryGatesShort:-0.373, Long:-0.470, Current:1.843 | topTokens[('.', 32), ('is', 21), ('do', 17), ('?', 16), ('a', 9), ('als', 8), (',', 7), ('plus', 7), ('are', 7), ('pete', 7)] | Training
2025-04-03 06:17:08 | 7200 | LR0.0003 | loss:4.9466 | gradNorm:0.8428 | tokenCount:300.0000 | logitMin:-80.7968 | logitMax:28.3337 | windowWeightsW8:0.20734,W13:0.16484,W15:0.16053,W3:0.14694,W18:0.14055,W7:0.09729,W2:0.06841,W1:0.03869,W14:-0.04343 | memoryGatesShort:-2.637, Long:2.276, Current:1.361 | topTokens[('is', 29), ('.', 26), ('!', 23), ('?', 17), ('you', 15), ('ie', 10), ('equ', 9), ('are', 8), ('me', 7), ('he', 7)] | Training
2025-04-03 06:21:56 | 7300 | LR0.0003 | loss:5.9110 | gradNorm:0.9829 | tokenCount:300.0000 | logitMin:-50.7859 | logitMax:17.1286 | windowWeightsW8:0.20685,W13:0.16547,W15:0.16183,W3:0.14604,W18:0.14223,W7:0.09652,W2:0.06742,W1:0.03879,W14:-0.04398 | memoryGatesShort:-0.421, Long:0.391, Current:1.029 | topTokens[('is', 23), ('?', 16), ('f', 15), ('ie', 14), ('1', 11), ('plus', 10), ('.', 9), ('equ', 9), ('als', 9), ('you', 9)] | Training
2025-04-03 06:26:45 | 7400 | LR0.0003 | loss:6.1975 | gradNorm:0.9963 | tokenCount:300.0000 | logitMin:-30.9351 | logitMax:10.6805 | windowWeightsW8:0.20700,W13:0.16535,W15:0.16178,W3:0.14616,W18:0.14203,W7:0.09672,W2:0.06750,W1:0.03816,W14:-0.04351 | memoryGatesShort:-0.532, Long:0.341, Current:1.190 | topTokens[('.', 35), ('is', 16), ('you', 13), ('?', 13), ('why', 11), ('she', 10), ("'re", 8), ('plus', 7), ('one', 7), ('elodie', 7)] | Training
2025-04-03 06:31:34 | 7500 | LR0.0003 | loss:8.1534 | gradNorm:0.9342 | tokenCount:300.0000 | logitMin:-51.4904 | logitMax:26.7022 | windowWeightsW8:0.20818,W13:0.16563,W15:0.16169,W3:0.14508,W18:0.14224,W7:0.09724,W2:0.06739,W1:0.03712,W14:-0.04335 | memoryGatesShort:5.798, Long:-2.839, Current:-1.959 | topTokens[('.', 31), ('is', 24), ('you', 19), ('?', 15), ('one', 11), ('a', 9), ('!', 9), ('plus', 8), ('he', 8), ('playing', 7)] | Training
2025-04-03 06:36:22 | 7600 | LR0.0003 | loss:10.2508 | gradNorm:0.9410 | tokenCount:300.0000 | logitMin:-50.7580 | logitMax:28.6020 | windowWeightsW8:0.20821,W13:0.16553,W15:0.16156,W3:0.14585,W18:0.14227,W7:0.09673,W2:0.06764,W1:0.03689,W14:-0.04347 | memoryGatesShort:-0.044, Long:0.333, Current:0.711 | topTokens[('.', 30), ('is', 22), ('f', 18), ('?', 18), ('als', 13), ('you', 13), ('equ', 10), ('!', 10), ('s', 9), ('that', 9)] | Training
2025-04-03 06:41:38 | 7700 | LR0.0003 | loss:8.1086 | gradNorm:0.8406 | tokenCount:300.0000 | logitMin:-54.8169 | logitMax:39.5225 | windowWeightsW8:0.20812,W13:0.16562,W15:0.16204,W3:0.14615,W18:0.14277,W7:0.09609,W2:0.06717,W1:0.03707,W14:-0.04382 | memoryGatesShort:-0.286, Long:0.182, Current:1.104 | topTokens[('?', 27), ('!', 21), ('.', 20), ('you', 14), ('are', 13), ('a', 11), ('is', 11), ('im', 10), ('dead', 8), ('al', 7)] | Training
2025-04-03 06:46:29 | 7800 | LR0.0003 | loss:4.1927 | gradNorm:0.9880 | tokenCount:300.0000 | logitMin:-59.9976 | logitMax:5.5385 | windowWeightsW8:0.20875,W13:0.16732,W15:0.16226,W3:0.14480,W18:0.14310,W7:0.09638,W2:0.06663,W1:0.03719,W14:-0.04522 | memoryGatesShort:-1.713, Long:1.540, Current:1.173 | topTokens[('.', 32), ('?', 25), ('is', 22), ('elodie', 16), (',', 11), ('you', 11), ('are', 11), ('there', 9), ('he', 8), ('a', 7)] | Training
2025-04-03 06:51:17 | 7900 | LR0.0003 | loss:8.6234 | gradNorm:0.8891 | tokenCount:300.0000 | logitMin:-91.4489 | logitMax:17.9459 | windowWeightsW8:0.20796,W13:0.16831,W15:0.16283,W3:0.14437,W18:0.14381,W7:0.09557,W2:0.06613,W1:0.03798,W14:-0.04572 | memoryGatesShort:-1.084, Long:-0.011, Current:2.095 | topTokens[('.', 22), ('elodie', 21), ('is', 16), ('you', 16), ('!', 15), ('pete', 11), ('ie', 10), ('s', 9), ('like', 8), ('?', 8)] | Training
2025-04-03 06:56:05 | 8000 | LR0.0003 | loss:6.2244 | gradNorm:0.9265 | tokenCount:300.0000 | logitMin:-58.6069 | logitMax:11.3901 | windowWeightsW8:0.20831,W13:0.16788,W15:0.16280,W3:0.14611,W18:0.14377,W7:0.09573,W2:0.06680,W1:0.03684,W14:-0.04705 | memoryGatesShort:-4.492, Long:2.549, Current:2.944 | topTokens[('.', 23), ('is', 17), ('elodie', 16), ('!', 15), ('you', 14), ('equ', 14), ('do', 12), ('plus', 12), ('f', 11), ('als', 11)] | Training
2025-04-03 07:00:55 | 8100 | LR0.0003 | loss:7.6676 | gradNorm:0.9212 | tokenCount:300.0000 | logitMin:-55.2759 | logitMax:29.8577 | windowWeightsW8:0.20854,W13:0.16776,W15:0.16324,W3:0.14727,W18:0.14402,W7:0.09602,W2:0.06669,W1:0.03587,W14:-0.04823 | memoryGatesShort:-0.378, Long:0.364, Current:1.015 | topTokens[('.', 18), ('?', 16), ('do', 15), ('is', 13), ('elodie', 12), ("'re", 10), ('plus', 9), ('f', 9), ('en', 9), ('al', 9)] | Training
2025-04-03 07:05:45 | 8200 | LR0.0003 | loss:5.0495 | gradNorm:0.9901 | tokenCount:300.0000 | logitMin:-46.3283 | logitMax:8.7465 | windowWeightsW8:0.20835,W13:0.16805,W15:0.16370,W3:0.14689,W18:0.14449,W7:0.09644,W2:0.06673,W1:0.03487,W14:-0.04830 | memoryGatesShort:3.217, Long:-0.968, Current:-1.249 | topTokens[('?', 39), ('is', 31), ('.', 22), ('elodie', 18), ('what', 9), ('als', 7), ('real', 7), ('a', 7), ('equ', 6), ('n', 6)] | Training
2025-04-03 07:10:35 | 8300 | LR0.0003 | loss:6.2673 | gradNorm:0.8646 | tokenCount:300.0000 | logitMin:-47.4823 | logitMax:56.8031 | windowWeightsW8:0.20905,W13:0.16766,W15:0.16275,W3:0.14760,W18:0.14334,W7:0.09748,W2:0.06764,W1:0.03465,W14:-0.04900 | memoryGatesShort:-1.884, Long:0.849, Current:2.035 | topTokens[('.', 35), ('elodie', 27), ('is', 26), ('?', 19), ('he', 14), ('equ', 10), ('so', 9), ('als', 9), ('f', 8), ('te', 8)] | Training
2025-04-03 07:15:44 | 8400 | LR0.0003 | loss:3.6819 | gradNorm:0.8439 | tokenCount:300.0000 | logitMin:-55.2606 | logitMax:43.4624 | windowWeightsW8:0.20952,W13:0.16688,W15:0.16186,W3:0.14976,W18:0.14280,W7:0.09829,W2:0.06788,W1:0.03360,W14:-0.04944 | memoryGatesShort:-0.665, Long:-3.957, Current:5.622 | topTokens[('.', 29), ('?', 20), ('is', 13), ('!', 11), ('that', 10), ('three', 9), ('equ', 8), ('als', 8), ('are', 8), ('you', 8)] | Training
2025-04-03 07:20:36 | 8500 | LR0.0003 | loss:9.2385 | gradNorm:0.7522 | tokenCount:300.0000 | logitMin:-83.6790 | logitMax:47.0388 | windowWeightsW8:0.20974,W13:0.16708,W15:0.16313,W3:0.15024,W18:0.14391,W7:0.09732,W2:0.06846,W1:0.03199,W14:-0.05071 | memoryGatesShort:-0.086, Long:-0.664, Current:1.751 | topTokens[('?', 30), ('elodie', 28), ('.', 22), ('!', 18), ('im', 16), ('are', 14), ('is', 13), ('you', 11), ('i', 10), ('a', 10)] | Training
2025-04-03 07:25:25 | 8600 | LR0.0003 | loss:4.4525 | gradNorm:0.9173 | tokenCount:300.0000 | logitMin:-53.8448 | logitMax:35.0913 | windowWeightsW8:0.20902,W13:0.16789,W15:0.16415,W3:0.14972,W18:0.14510,W7:0.09634,W2:0.06838,W1:0.03149,W14:-0.05091 | memoryGatesShort:-0.100, Long:-1.928, Current:3.028 | topTokens[('.', 32), ('elodie', 27), ('?', 24), ('is', 17), ('i', 15), ('are', 13), ('there', 8), ('you', 8), ('ace', 8), ('what', 7)] | Training
2025-04-03 07:30:15 | 8700 | LR0.0003 | loss:6.7650 | gradNorm:0.8231 | tokenCount:300.0000 | logitMin:-68.5194 | logitMax:36.9223 | windowWeightsW8:0.20909,W13:0.16774,W15:0.16450,W3:0.15007,W18:0.14520,W7:0.09657,W2:0.06835,W1:0.03081,W14:-0.05114 | memoryGatesShort:0.019, Long:-1.008, Current:1.989 | topTokens[('do', 30), ('.', 20), ('?', 18), ('!', 18), ('is', 17), ('you', 16), ('elodie', 14), ('f', 8), ('ie', 8), ('i', 6)] | Training
2025-04-03 07:35:05 | 8800 | LR0.0003 | loss:4.2188 | gradNorm:0.9593 | tokenCount:300.0000 | logitMin:-60.1321 | logitMax:6.0008 | windowWeightsW8:0.20855,W13:0.16801,W15:0.16488,W3:0.14908,W18:0.14654,W7:0.09747,W2:0.06760,W1:0.03056,W14:-0.05146 | memoryGatesShort:0.029, Long:0.148, Current:0.823 | topTokens[('.', 32), ('?', 21), ('elodie', 14), ('als', 12), (',', 12), ('f', 11), ('i', 11), ('is', 11), ('equ', 9), ('you', 9)] | Training
2025-04-03 07:39:55 | 8900 | LR0.0003 | loss:6.1565 | gradNorm:0.7487 | tokenCount:300.0000 | logitMin:-63.9047 | logitMax:68.2904 | windowWeightsW8:0.20763,W13:0.16917,W15:0.16631,W3:0.14973,W18:0.14765,W7:0.09595,W2:0.06759,W1:0.02921,W14:-0.05199 | memoryGatesShort:-0.131, Long:0.091, Current:1.040 | topTokens[('.', 25), ('?', 23), ('is', 20), ('elodie', 13), ('you', 12), ('f', 11), ('i', 10), ('als', 10), ('plus', 9), ('ive', 9)] | Training
2025-04-03 07:45:09 | 9000 | LR0.0003 | loss:12.8851 | gradNorm:0.9274 | tokenCount:300.0000 | logitMin:-83.3750 | logitMax:18.1560 | windowWeightsW8:0.20779,W13:0.16906,W15:0.16669,W3:0.14964,W18:0.14799,W7:0.09681,W2:0.06730,W1:0.02862,W14:-0.05264 | memoryGatesShort:-0.165, Long:-0.301, Current:1.466 | topTokens[('?', 46), ('.', 31), ('is', 30), ('playing', 16), ('elodie', 11), ('who', 10), ('t', 9), ('e', 9), ('you', 8), ('he', 8)] | Training
2025-04-03 07:49:55 | 9100 | LR0.0003 | loss:9.4130 | gradNorm:0.8431 | tokenCount:300.0000 | logitMin:-81.4000 | logitMax:50.3994 | windowWeightsW8:0.20762,W13:0.16900,W15:0.16707,W3:0.14919,W18:0.14803,W7:0.09722,W2:0.06657,W1:0.02839,W14:-0.05180 | memoryGatesShort:0.273, Long:0.161, Current:0.566 | topTokens[('.', 33), ('?', 32), ('is', 19), ('als', 14), ('!', 12), ('e', 11), ('equ', 11), ('elodie', 9), ('our', 9), ('plus', 8)] | Training
2025-04-03 07:54:42 | 9200 | LR0.0003 | loss:4.7095 | gradNorm:0.6376 | tokenCount:300.0000 | logitMin:-93.3714 | logitMax:44.9805 | windowWeightsW8:0.20865,W13:0.16904,W15:0.16733,W3:0.14972,W18:0.14867,W7:0.09758,W2:0.06595,W1:0.02821,W14:-0.05387 | memoryGatesShort:1.027, Long:1.514, Current:-1.541 | topTokens[('?', 26), ('is', 23), ('.', 20), ('elodie', 15), ('that', 12), ('dead', 12), ('!', 10), ('you', 9), ('what', 8), ('are', 8)] | Training
2025-04-03 07:59:32 | 9300 | LR0.0003 | loss:8.5110 | gradNorm:0.7870 | tokenCount:300.0000 | logitMin:-110.0462 | logitMax:51.3604 | windowWeightsW8:0.20756,W13:0.16885,W15:0.16785,W3:0.14988,W18:0.14982,W7:0.09716,W2:0.06629,W1:0.02800,W14:-0.05413 | memoryGatesShort:-0.034, Long:-0.034, Current:1.067 | topTokens[('elodie', 31), ('?', 24), ('is', 23), ('.', 20), ('!', 19), ('you', 14), ('a', 11), ('there', 11), ('i', 10), ('real', 9)] | Training
2025-04-03 08:04:20 | 9400 | LR0.0003 | loss:12.5165 | gradNorm:0.8840 | tokenCount:300.0000 | logitMin:-112.6497 | logitMax:26.8170 | windowWeightsW8:0.20661,W13:0.16936,W15:0.16856,W18:0.15010,W3:0.14911,W7:0.09714,W2:0.06614,W1:0.02803,W14:-0.05374 | memoryGatesShort:20.912, Long:0.782, Current:-20.694 | topTokens[('?', 35), ('.', 34), ('elodie', 21), ('is', 14), ('i', 13), ('are', 12), ('you', 11), ('ace', 10), ('real', 8), ('do', 7)] | Training
2025-04-03 08:09:09 | 9500 | LR0.0003 | loss:3.7572 | gradNorm:0.6262 | tokenCount:300.0000 | logitMin:-112.0754 | logitMax:44.4560 | windowWeightsW8:0.20697,W13:0.16917,W15:0.16886,W18:0.15045,W3:0.14863,W7:0.09759,W2:0.06590,W1:0.02741,W14:-0.05363 | memoryGatesShort:-0.031, Long:-0.163, Current:1.194 | topTokens[('!', 32), ('?', 18), ('you', 18), ('.', 15), ('is', 13), ('what', 11), ('f', 8), ("'re", 7), ('do', 7), ('pete', 6)] | Training
2025-04-03 08:14:01 | 9600 | LR0.0003 | loss:11.3792 | gradNorm:0.9412 | tokenCount:300.0000 | logitMin:-101.1164 | logitMax:7.5550 | windowWeightsW8:0.20728,W15:0.16917,W13:0.16900,W18:0.15007,W3:0.14851,W7:0.09701,W2:0.06622,W1:0.02740,W14:-0.05331 | memoryGatesShort:0.017, Long:-0.404, Current:1.388 | topTokens[('?', 36), ('elodie', 21), ('.', 20), ('is', 19), ('you', 10), ('do', 9), ('he', 8), ('equ', 7), ('1', 7), ('!', 7)] | Training
2025-04-03 08:19:05 | 9700 | LR0.0003 | loss:4.2294 | gradNorm:0.8977 | tokenCount:300.0000 | logitMin:-55.4205 | logitMax:30.8904 | windowWeightsW8:0.20748,W13:0.16968,W15:0.16927,W18:0.15042,W3:0.14857,W7:0.09715,W2:0.06570,W1:0.02670,W14:-0.05362 | memoryGatesShort:-0.960, Long:-0.971, Current:2.931 | topTokens[('.', 38), ('is', 20), ('?', 19), ('reading', 11), ('ive', 10), ('elodie', 9), ('plus', 9), ('f', 9), ('equ', 9), ('als', 9)] | Training
2025-04-03 08:23:56 | 9800 | LR0.0003 | loss:11.2211 | gradNorm:0.8113 | tokenCount:300.0000 | logitMin:-68.3734 | logitMax:32.8887 | windowWeightsW8:0.20737,W13:0.17001,W15:0.16963,W18:0.15031,W3:0.14842,W7:0.09692,W2:0.06604,W1:0.02669,W14:-0.05403 | memoryGatesShort:-0.581, Long:-0.715, Current:2.295 | topTokens[('.', 41), ('is', 31), ('?', 22), ('elodie', 11), ('equ', 10), ('he', 9), ('als', 9), ('you', 7), ('are', 6), ('reading', 6)] | Training
2025-04-03 08:28:54 | 9900 | LR0.0003 | loss:7.6953 | gradNorm:0.7334 | tokenCount:300.0000 | logitMin:-74.7585 | logitMax:49.7976 | windowWeightsW8:0.20746,W13:0.16998,W15:0.16975,W18:0.15010,W3:0.14919,W7:0.09735,W2:0.06533,W1:0.02640,W14:-0.05420 | memoryGatesShort:-0.729, Long:-0.960, Current:2.690 | topTokens[('.', 29), ('is', 23), ('f', 21), ('?', 16), ('equ', 14), ('that', 14), ('plus', 13), ('!', 12), ('als', 12), ('our', 8)] | Training
2025-04-03 08:34:22 | 10000 | LR0.0003 | loss:5.5065 | gradNorm:0.7280 | tokenCount:300.0000 | logitMin:-78.8832 | logitMax:48.5298 | windowWeightsW8:0.20792,W15:0.16962,W13:0.16931,W18:0.15063,W3:0.14947,W7:0.09755,W2:0.06485,W1:0.02599,W14:-0.05398 | memoryGatesShort:0.202, Long:0.194, Current:0.604 | topTokens[('.', 28), ('?', 22), ('you', 18), ('are', 13), ('!', 9), ('dead', 9), (',', 8), ('is', 8), ('im', 8), ('what', 7)] | Training
2025-04-03 08:40:08 | 10100 | LR0.0003 | loss:2.5197 | gradNorm:0.4912 | tokenCount:300.0000 | logitMin:-118.9388 | logitMax:75.9842 | windowWeightsW8:0.20751,W13:0.16831,W15:0.16772,W18:0.15114,W3:0.14849,W7:0.10000,W2:0.06830,W1:0.02599,W14:-0.05615 | memoryGatesShort:-0.015, Long:-0.293, Current:1.308 | topTokens[('.', 34), ('?', 28), ('is', 21), ('are', 20), ('you', 20), ('!', 15), ('what', 10), ('there', 9), ('real', 7), ('elodie', 7)] | Training

--- 2025-04-03 08:46:32 ---
babyLLM: what am i learning today?
You: how to spam gay maths less often

--- 2025-04-03 08:50:20 ---
babyLLM: what am i learning today?
You: how to not get stuck in shit data lol
2025-04-03 08:55:07 | 100 | LR0.0003 | loss:7.2213 | gradNorm:1.0000 | logitMin:-33.8119 | logitMax:9.1086 | scheduledSampling:0.0000 | tokenCount:300.0000 | windowWeightsW8:0.20752,W13:0.16645,W15:0.16641,W3:0.15066,W18:0.14995,W7:0.10123,W2:0.06865,W1:0.02418,W14:-0.05374 | memoryGatesShort:0.670, Long:-3.436, Current:3.766 | topTokens[('.', 51), ('!', 25), ('it', 13), ('am', 12), ('know', 12), ('a', 11), ('i', 11), ('is', 10), ('hi', 9), ('feel', 8)] | Training
2025-04-03 09:00:23 | 200 | LR0.0003 | loss:13.5035 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-27.3923 | logitMax:0.4537 | windowWeightsW8:0.20734,W15:0.16688,W13:0.16680,W18:0.15058,W3:0.14953,W7:0.10215,W2:0.06786,W1:0.02369,W14:-0.05348 | memoryGatesShort:0.954, Long:-0.733, Current:0.779 | topTokens[('.', 45), ('elodie', 26), ('i', 16), ('not', 12), ('ie', 11), (',', 10), ('our', 9), ('!', 8), ("'re", 8), ('am', 7)] | Training
2025-04-03 09:05:47 | 300 | LR0.0003 | loss:11.1881 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-24.2942 | logitMax:-3.3065 | windowWeightsW8:0.20733,W15:0.16698,W13:0.16691,W18:0.15067,W3:0.14932,W7:0.10243,W2:0.06760,W1:0.02348,W14:-0.05337 | memoryGatesShort:0.460, Long:0.416, Current:0.124 | topTokens[('.', 32), ('i', 26), ('elodie', 20), (',', 11), ('too', 9), ('...', 7), ('b', 7), ('she', 5), ('feel', 5), ('were', 5)] | Training
2025-04-03 09:11:04 | 400 | LR0.0003 | loss:10.7699 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-25.0129 | logitMax:-4.1193 | windowWeightsW8:0.20722,W13:0.16743,W15:0.16729,W18:0.15109,W3:0.14912,W7:0.10231,W2:0.06715,W1:0.02279,W14:-0.05304 | memoryGatesShort:0.776, Long:-0.654, Current:0.878 | topTokens[('.', 35), (',', 21), ('i', 20), ('her', 15), ('ie', 8), ('s', 8), ('you', 6), ('am', 6), ('a', 5), ('who', 4)] | Training
2025-04-03 09:16:18 | 500 | LR0.0003 | loss:10.0556 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-25.5546 | logitMax:-7.0236 | windowWeightsW8:0.20711,W13:0.16771,W15:0.16757,W18:0.15148,W3:0.14862,W7:0.10162,W2:0.06691,W1:0.02288,W14:-0.05251 | memoryGatesShort:3.737, Long:-3.582, Current:0.845 | topTokens[('i', 24), ('.', 14), (',', 12), ('not', 10), ('elodie', 8), ('im', 8), ('did', 6), ('is', 6), ('she', 5), ('s', 5)] | Training
2025-04-03 09:22:09 | 600 | LR0.0003 | loss:10.9591 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-30.3538 | logitMax:-9.3873 | windowWeightsW8:0.20702,W13:0.16772,W15:0.16760,W18:0.15174,W3:0.14829,W7:0.10197,W2:0.06675,W1:0.02256,W14:-0.05226 | memoryGatesShort:-2.195, Long:2.930, Current:0.264 | topTokens[('.', 26), (',', 21), ('i', 12), ('you', 12), ('!', 10), ('not', 10), ('equ', 8), ('?', 7), ('elodie', 7), ('feel', 6)] | Training
2025-04-03 09:27:05 | 700 | LR0.0003 | loss:10.5186 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-33.2443 | logitMax:-14.1989 | windowWeightsW8:0.20723,W13:0.16792,W15:0.16774,W18:0.15163,W3:0.14772,W7:0.10280,W2:0.06623,W1:0.02208,W14:-0.05195 | memoryGatesShort:-6.199, Long:4.990, Current:2.209 | topTokens[(',', 16), ('im', 13), ('.', 10), ('is', 9), ('to', 9), ('going', 8), ('?', 8), ('i', 8), ('s', 7), ('like', 6)] | Training
2025-04-03 09:32:07 | 800 | LR0.0003 | loss:9.2632 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-28.4481 | logitMax:-11.0569 | windowWeightsW8:0.20705,W15:0.16827,W13:0.16823,W18:0.15220,W3:0.14724,W7:0.10289,W2:0.06564,W1:0.02090,W14:-0.05099 | memoryGatesShort:-1.867, Long:3.286, Current:-0.420 | topTokens[(',', 25), ('i', 23), ('is', 19), ('.', 19), ('im', 9), ('a', 7), ('to', 6), ('s', 5), ('h', 5), ('not', 5)] | Training
2025-04-03 09:37:21 | 900 | LR0.0003 | loss:9.8231 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-29.6918 | logitMax:-11.4749 | windowWeightsW8:0.20702,W15:0.16835,W13:0.16825,W18:0.15225,W3:0.14706,W7:0.10295,W2:0.06564,W1:0.02054,W14:-0.05062 | memoryGatesShort:-3.239, Long:4.059, Current:0.181 | topTokens[('me', 26), ('h', 22), ('.', 19), (',', 18), ('to', 9), ('is', 7), ('i', 7), ('who', 5), ('and', 4), ('e', 4)] | Training
2025-04-03 09:42:38 | 1000 | LR0.0003 | loss:8.7624 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-29.1399 | logitMax:-12.1793 | windowWeightsW8:0.20690,W15:0.16846,W13:0.16822,W18:0.15248,W3:0.14677,W7:0.10275,W2:0.06532,W1:0.02030,W14:-0.04974 | memoryGatesShort:-6.098, Long:6.585, Current:0.513 | topTokens[(',', 26), ('me', 19), ('h', 13), ('.', 10), ('the', 6), ('to', 5), ('b', 4), ('our', 4), ('am', 4), ('plus', 4)] | Training
2025-04-03 09:48:01 | 1100 | LR0.0003 | loss:9.8135 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-32.2077 | logitMax:-14.6208 | windowWeightsW8:0.20689,W15:0.16860,W13:0.16827,W18:0.15262,W3:0.14655,W7:0.10289,W2:0.06505,W1:0.02008,W14:-0.04949 | memoryGatesShort:-5.696, Long:5.202, Current:1.494 | topTokens[(',', 30), ('the', 12), ('at', 12), ('h', 9), ('.', 9), ('to', 6), ('a', 6), ('is', 6), ('es', 5), ('me', 5)] | Training
2025-04-03 09:53:10 | 1200 | LR0.0003 | loss:11.7394 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-36.2125 | logitMax:-12.0292 | windowWeightsW8:0.20643,W15:0.16948,W13:0.16926,W18:0.15272,W3:0.14582,W7:0.10290,W2:0.06508,W1:0.01941,W14:-0.04962 | memoryGatesShort:91.814, Long:-72.343, Current:-18.471 | topTokens[('.', 42), ('now', 13), ('it', 12), (',', 11), ('i', 11), ('u', 11), ('at', 7), ('me', 6), ('b', 5), ('a', 5)] | Training
2025-04-03 09:58:19 | 1300 | LR0.0003 | loss:13.2044 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.1112 | logitMax:-14.8023 | windowWeightsW8:0.20531,W15:0.17011,W13:0.16959,W18:0.15372,W3:0.14454,W7:0.10327,W2:0.06448,W1:0.01947,W14:-0.04898 | memoryGatesShort:-26.181, Long:24.652, Current:2.529 | topTokens[('.', 38), ('is', 20), (',', 15), ('at', 14), ('me', 14), ('this', 9), ('?', 7), ('she', 6), ('i', 6), ('my', 5)] | Training
2025-04-03 10:03:42 | 1400 | LR0.0003 | loss:9.1076 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-36.4357 | logitMax:-17.0618 | windowWeightsW8:0.20573,W15:0.17037,W13:0.16959,W18:0.15461,W3:0.14348,W7:0.10260,W2:0.06367,W1:0.01940,W14:-0.04792 | memoryGatesShort:-12.516, Long:11.202, Current:2.314 | topTokens[(',', 30), ('.', 13), ('u', 13), ('my', 11), ('is', 9), ('at', 5), ('i', 5), ('f', 5), ('ke', 5), ('up', 4)] | Training
2025-04-03 10:09:37 | 1500 | LR0.0003 | loss:9.4706 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-36.0414 | logitMax:-16.8579 | windowWeightsW8:0.20481,W15:0.17043,W13:0.16910,W18:0.15530,W3:0.14408,W7:0.10263,W2:0.06337,W1:0.01948,W14:-0.04765 | memoryGatesShort:-5.358, Long:6.168, Current:0.190 | topTokens[('u', 26), (',', 15), ('.', 15), ('i', 15), ('the', 9), ('ke', 7), ('a', 6), ('ing', 5), ('is', 5), ('like', 4)] | Training
2025-04-03 10:14:45 | 1600 | LR0.0003 | loss:10.6077 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-38.4681 | logitMax:-18.9781 | windowWeightsW8:0.20456,W15:0.17051,W13:0.16904,W18:0.15544,W3:0.14379,W7:0.10277,W2:0.06335,W1:0.01939,W14:-0.04731 | memoryGatesShort:-15.420, Long:15.313, Current:1.107 | topTokens[('is', 29), ('.', 24), ('es', 13), (',', 10), ('u', 10), ('i', 9), ('f', 8), ('it', 5), ('this', 5), ('n', 5)] | Training
2025-04-03 10:20:01 | 1700 | LR0.0003 | loss:10.3480 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-32.9780 | logitMax:-12.8434 | windowWeightsW8:0.20485,W15:0.17088,W13:0.16997,W18:0.15566,W3:0.14275,W7:0.10371,W2:0.06262,W1:0.01758,W14:-0.04644 | memoryGatesShort:23581.539, Long:-20384.100, Current:-3196.423 | topTokens[('.', 21), ('is', 18), (',', 15), ('f', 10), ('i', 8), ('ke', 6), ('es', 6), ('nd', 6), ('it', 5), ('u', 5)] | Training
2025-04-03 10:25:13 | 1800 | LR0.0003 | loss:9.5323 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-37.6279 | logitMax:-19.7647 | windowWeightsW8:0.20469,W15:0.17065,W13:0.16933,W18:0.15571,W3:0.14311,W7:0.10336,W2:0.06274,W1:0.01739,W14:-0.04540 | memoryGatesShort:-3.312, Long:3.590, Current:0.722 | topTokens[(',', 16), ('is', 11), ('my', 10), ('.', 9), ('the', 9), ('it', 8), ('s', 7), ('i', 5), ('a', 5), ('in', 5)] | Training
2025-04-03 10:30:19 | 1900 | LR0.0003 | loss:9.7662 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-36.0218 | logitMax:-16.8880 | windowWeightsW8:0.20437,W15:0.17110,W13:0.17003,W18:0.15643,W3:0.14249,W7:0.10346,W2:0.06210,W1:0.01636,W14:-0.04475 | memoryGatesShort:-64.586, Long:64.122, Current:1.464 | topTokens[('.', 16), ('the', 15), ('this', 12), ('but', 11), (',', 9), ('im', 9), ('i', 7), ('no', 6), ('in', 5), ('u', 5)] | Training
2025-04-03 10:35:55 | 2000 | LR0.0003 | loss:9.8434 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-33.9638 | logitMax:-14.5553 | windowWeightsW8:0.20390,W15:0.17134,W13:0.16979,W18:0.15696,W3:0.14233,W7:0.10363,W2:0.06181,W1:0.01628,W14:-0.04444 | memoryGatesShort:-4.540, Long:3.994, Current:1.546 | topTokens[('.', 11), ('but', 11), ('ohh', 7), ('u', 6), (',', 5), ('im', 5), ('like', 5), ('f', 5), ('me', 5), ('is', 5)] | Training
2025-04-03 10:41:44 | 2100 | LR0.0003 | loss:9.0387 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-30.8740 | logitMax:-13.9346 | windowWeightsW8:0.20293,W15:0.17190,W13:0.17149,W18:0.15720,W3:0.14225,W7:0.10338,W2:0.06140,W1:0.01605,W14:-0.04498 | memoryGatesShort:-5.424, Long:5.154, Current:1.270 | topTokens[('i', 29), ('.', 14), (',', 10), ('s', 8), ('for', 7), ('n', 6), ('a', 6), ('do', 5), ('very', 4), ('the', 4)] | Training
2025-04-03 10:47:11 | 2200 | LR0.0003 | loss:11.3317 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-36.4409 | logitMax:-15.4801 | windowWeightsW8:0.20163,W15:0.17264,W13:0.17216,W18:0.15760,W3:0.14202,W7:0.10264,W2:0.06158,W1:0.01602,W14:-0.04467 | memoryGatesShort:-4.938, Long:4.910, Current:1.028 | topTokens[('s', 49), ('.', 14), ('why', 14), ('that', 11), ('lo', 11), (',', 10), ('l', 7), ('just', 4), ('ie', 4), ('gay', 4)] | Training
2025-04-03 10:52:35 | 2300 | LR0.0003 | loss:9.9667 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-38.2357 | logitMax:-18.6781 | windowWeightsW8:0.20110,W15:0.17303,W13:0.17267,W18:0.15753,W3:0.14184,W7:0.10268,W2:0.06131,W1:0.01584,W14:-0.04437 | memoryGatesShort:-19.340, Long:16.223, Current:4.117 | topTokens[('why', 22), ('s', 20), ('that', 20), ('.', 17), (',', 15), ('it', 10), ('l', 8), ('but', 5), ('a', 5), ('my', 5)] | Training
2025-04-03 10:57:50 | 2400 | LR0.0003 | loss:9.7894 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-35.9860 | logitMax:-16.9390 | windowWeightsW8:0.20064,W15:0.17424,W13:0.17397,W18:0.15817,W3:0.14173,W7:0.10178,W2:0.05986,W1:0.01595,W14:-0.04474 | memoryGatesShort:-196.054, Long:181.538, Current:15.516 | topTokens[('.', 21), ('a', 15), ('y', 6), (',', 5), ('l', 5), ('why', 5), ('u', 5), ('do', 5), ('ch', 5), ('*', 5)] | Training
2025-04-03 11:03:39 | 2500 | LR0.0003 | loss:10.9907 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-37.6666 | logitMax:-15.8106 | windowWeightsW8:0.20103,W15:0.17450,W13:0.17408,W18:0.15820,W3:0.14154,W7:0.10172,W2:0.05949,W1:0.01616,W14:-0.04510 | memoryGatesShort:-3.682, Long:3.598, Current:1.084 | topTokens[('ch', 43), ('.', 23), ('a', 14), ('*', 10), ('was', 9), ('why', 7), (',', 5), ('feel', 5), ('our', 5), ('too', 4)] | Training
2025-04-03 11:09:06 | 2600 | LR0.0003 | loss:12.0497 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-40.7564 | logitMax:-17.1875 | windowWeightsW8:0.20088,W15:0.17465,W13:0.17398,W18:0.15854,W3:0.14135,W7:0.10157,W2:0.05954,W1:0.01609,W14:-0.04499 | memoryGatesShort:75.565, Long:-68.145, Current:-6.420 | topTokens[('.', 42), ('u', 18), ('ch', 16), ('why', 8), ('g', 8), ('no', 7), ('i', 6), ('do', 5), ('this', 5), ('just', 5)] | Training
2025-04-03 11:14:17 | 2700 | LR0.0003 | loss:8.0954 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-35.3197 | logitMax:-20.2525 | windowWeightsW8:0.20103,W15:0.17475,W13:0.17385,W18:0.15840,W3:0.14074,W7:0.10243,W2:0.05944,W1:0.01520,W14:-0.04420 | memoryGatesShort:-261.999, Long:217.978, Current:45.021 | topTokens[('is', 14), ('it', 9), ('im', 9), (',', 8), ('a', 7), ('*', 5), ('.', 5), ('he', 4), ('just', 4), ('was', 4)] | Training
2025-04-03 11:19:46 | 2800 | LR0.0003 | loss:12.9330 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-37.5933 | logitMax:-13.0566 | windowWeightsW8:0.19978,W15:0.17516,W13:0.17271,W18:0.16026,W3:0.13829,W7:0.10287,W2:0.05865,W1:0.01599,W14:-0.04202 | memoryGatesShort:30.650, Long:-21.875, Current:-7.774 | topTokens[('my', 52), ('.', 24), (',', 22), ('c', 5), ('its', 5), ('who', 5), ('was', 4), ('it', 4), ('im', 4), ('boi', 3)] | Training
2025-04-03 11:25:05 | 2900 | LR0.0003 | loss:11.9488 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-31.3689 | logitMax:-9.9404 | windowWeightsW8:0.19997,W15:0.17503,W13:0.17287,W18:0.16012,W3:0.13793,W7:0.10377,W2:0.05833,W1:0.01601,W14:-0.04234 | memoryGatesShort:-7.295, Long:6.166, Current:2.129 | topTokens[('my', 66), ('its', 37), (',', 36), ('.', 18), ('because', 7), ('too', 4), ('t', 4), ('who', 3), (':', 3), ('she', 3)] | Training
2025-04-03 11:30:58 | 3000 | LR0.0003 | loss:10.6378 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-33.1189 | logitMax:-12.3952 | windowWeightsW8:0.20052,W15:0.17433,W13:0.17284,W18:0.15983,W3:0.13824,W7:0.10460,W2:0.05829,W1:0.01570,W14:-0.04267 | memoryGatesShort:-24.435, Long:20.334, Current:5.101 | topTokens[('my', 48), ('its', 39), ('.', 24), (',', 22), ('kn', 7), ('she', 5), ('f', 5), ('r', 3), ('s', 3), ('b', 3)] | Training
2025-04-03 11:36:00 | 3100 | LR0.0003 | loss:10.9730 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-35.8907 | logitMax:-14.5786 | windowWeightsW8:0.20095,W15:0.17434,W13:0.17289,W18:0.15963,W3:0.13822,W7:0.10534,W2:0.05832,W1:0.01513,W14:-0.04312 | memoryGatesShort:-5.210, Long:4.625, Current:1.585 | topTokens[('its', 28), ('.', 26), ('my', 22), ('t', 15), ('kn', 11), (',', 10), (':', 6), ('me', 6), ('too', 4), ('b', 4)] | Training
2025-04-03 11:41:11 | 3200 | LR0.0003 | loss:10.1040 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-36.4196 | logitMax:-14.4915 | windowWeightsW8:0.20007,W15:0.17503,W13:0.17310,W18:0.16067,W3:0.13701,W7:0.10563,W2:0.05806,W1:0.01484,W14:-0.04271 | memoryGatesShort:-14.745, Long:14.199, Current:1.546 | topTokens[('.', 36), ('ll', 30), (',', 12), ('it', 10), ('its', 9), ('er', 8), ('my', 6), ('and', 4), ('dont', 4), ('them', 3)] | Training
2025-04-03 11:46:35 | 3300 | LR0.0003 | loss:8.4602 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-38.1620 | logitMax:-21.2975 | windowWeightsW8:0.20008,W15:0.17546,W13:0.17354,W18:0.16093,W3:0.13678,W7:0.10586,W2:0.05768,W1:0.01426,W14:-0.04289 | memoryGatesShort:-7.054, Long:7.928, Current:0.126 | topTokens[('l', 17), (',', 13), ('ll', 13), ('it', 13), ('.', 12), ('er', 11), ('dont', 11), ('be', 8), ('i', 5), ('gg', 4)] | Training
2025-04-03 11:51:56 | 3400 | LR0.0003 | loss:8.4633 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-32.7186 | logitMax:-14.6531 | windowWeightsW8:0.20073,W15:0.17577,W13:0.17348,W18:0.16118,W3:0.13661,W7:0.10622,W2:0.05714,W1:0.01361,W14:-0.04304 | memoryGatesShort:-5.357, Long:4.789, Current:1.568 | topTokens[('.', 17), ('l', 15), ('be', 9), ('i', 7), (',', 6), ('f', 6), ('my', 5), ('that', 4), ('b', 4), ('who', 4)] | Training
2025-04-03 11:57:15 | 3500 | LR0.0003 | loss:10.6038 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-32.3633 | logitMax:-11.5859 | windowWeightsW8:0.20033,W15:0.17578,W13:0.17357,W18:0.16104,W3:0.13622,W7:0.10771,W2:0.05717,W1:0.01319,W14:-0.04331 | memoryGatesShort:19.996, Long:-14.725, Current:-4.271 | topTokens[('.', 18), (',', 16), ('s', 13), ('l', 10), ('im', 7), ('we', 6), ('u', 5), ('i', 5), ('it', 5), ('who', 5)] | Training
2025-04-03 12:02:26 | 3600 | LR0.0003 | loss:10.4794 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-38.0663 | logitMax:-15.9722 | windowWeightsW8:0.20049,W15:0.17606,W13:0.17389,W18:0.16165,W3:0.13586,W7:0.10721,W2:0.05669,W1:0.01283,W14:-0.04298 | memoryGatesShort:-5.519, Long:5.606, Current:0.913 | topTokens[('.', 29), (',', 22), ('have', 11), ('l', 8), ('in', 7), ('like', 7), ('me', 6), ('and', 6), ('we', 5), ('a', 4)] | Training
2025-04-03 12:07:45 | 3700 | LR0.0003 | loss:9.9001 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.7115 | logitMax:-22.3623 | windowWeightsW8:0.20014,W15:0.17620,W13:0.17423,W18:0.16138,W3:0.13577,W7:0.10750,W2:0.05645,W1:0.01307,W14:-0.04304 | memoryGatesShort:-38.331, Long:29.539, Current:9.792 | topTokens[('like', 60), ('to', 26), ('.', 12), (',', 11), ('i', 7), ('y', 5), ('l', 4), ('in', 4), ('b', 4), ('-', 4)] | Training
2025-04-03 12:13:47 | 3800 | LR0.0003 | loss:10.6297 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-37.2544 | logitMax:-15.9413 | windowWeightsW8:0.19971,W15:0.17700,W13:0.17452,W18:0.16239,W3:0.13534,W7:0.10742,W2:0.05604,W1:0.01237,W14:-0.04306 | memoryGatesShort:-25.320, Long:24.362, Current:1.958 | topTokens[('.', 36), ('im', 22), ('l', 19), ('to', 10), ('lo', 9), (',', 8), ('s', 6), ('i', 6), ('me', 6), ('she', 5)] | Training
2025-04-03 12:19:16 | 3900 | LR0.0003 | loss:11.5857 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-40.8122 | logitMax:-17.3882 | windowWeightsW8:0.19978,W15:0.17737,W13:0.17442,W18:0.16318,W3:0.13482,W7:0.10742,W2:0.05571,W1:0.01183,W14:-0.04282 | memoryGatesShort:-18.153, Long:17.169, Current:1.984 | topTokens[('its', 23), ('.', 19), (',', 17), ('be', 12), ('l', 9), ('to', 6), ('she', 6), ('but', 5), ('i', 5), ('im', 5)] | Training
2025-04-03 12:24:40 | 4000 | LR0.0003 | loss:8.4900 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.4059 | logitMax:-25.0957 | windowWeightsW8:0.19888,W15:0.17782,W13:0.17509,W18:0.16298,W3:0.13433,W7:0.10756,W2:0.05561,W1:0.01173,W14:-0.04228 | memoryGatesShort:-8.035, Long:7.751, Current:1.284 | topTokens[(',', 21), ('to', 18), ('kevin', 15), ('s', 14), ('like', 12), ('he', 11), ('.', 8), ('b', 7), ('yeah', 4), ('but', 3)] | Training
2025-04-03 12:29:55 | 4100 | LR0.0003 | loss:10.0421 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-35.8050 | logitMax:-17.2007 | windowWeightsW8:0.19909,W15:0.17841,W13:0.17527,W18:0.16347,W3:0.13430,W7:0.10720,W2:0.05512,W1:0.01101,W14:-0.04216 | memoryGatesShort:-6.823, Long:5.891, Current:1.933 | topTokens[('.', 16), (',', 13), ('kevin', 9), ('me', 7), ('ed', 7), ('ail', 7), ('you', 7), ('a', 6), ('like', 6), ('s', 5)] | Training

--- 2025-04-03 12:34:17 ---
babyLLM: what am i learning today?
You: maybe less chaos?
2025-04-03 12:39:20 | 100 | LR0.0003 | loss:7.6797 | gradNorm:0.9805 | logitMin:-62.3524 | logitMax:-1.0465 | scheduledSampling:0.0000 | tokenCount:300.0000 | windowWeightsW8:0.19828,W15:0.17715,W13:0.17430,W18:0.16160,W3:0.13750,W7:0.10672,W2:0.05749,W1:0.01173,W14:-0.04310 | memoryGatesShort:-9.705, Long:1.970, Current:8.735 | topTokens[('.', 44), ('it', 40), ('i', 39), ('!', 26), ('know', 13), ('did', 10), ('am', 8), ('who', 8), ('happy', 8), ('its', 7)] | Training
2025-04-03 12:44:33 | 200 | LR0.0003 | loss:9.5431 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-34.8871 | logitMax:-9.3727 | windowWeightsW8:0.19816,W15:0.17787,W13:0.17493,W18:0.16219,W3:0.13712,W7:0.10777,W2:0.05653,W1:0.01100,W14:-0.04391 | memoryGatesShort:-10.404, Long:10.326, Current:1.079 | topTokens[(',', 34), ('.', 23), ('i', 21), ('did', 12), ('to', 8), ('how', 7), ('who', 7), ('why', 7), ('feel', 6), ('it', 5)] | Training
2025-04-03 12:49:44 | 300 | LR0.0003 | loss:12.3435 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-35.9151 | logitMax:-11.5815 | windowWeightsW8:0.19801,W15:0.17784,W13:0.17491,W18:0.16214,W3:0.13705,W7:0.10801,W2:0.05651,W1:0.01097,W14:-0.04377 | memoryGatesShort:53.851, Long:-39.070, Current:-13.781 | topTokens[('.', 33), (',', 31), ('i', 13), ('in', 10), ('like', 10), ('why', 8), ('she', 6), ('did', 6), ('and', 6), ('my', 5)] | Training
2025-04-03 12:55:00 | 400 | LR0.0003 | loss:10.4808 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.9570 | logitMax:-17.7587 | windowWeightsW8:0.19806,W15:0.17799,W13:0.17483,W18:0.16230,W3:0.13690,W7:0.10794,W2:0.05652,W1:0.01083,W14:-0.04370 | memoryGatesShort:-9.022, Long:7.409, Current:2.612 | topTokens[('.', 31), (',', 13), ('and', 12), ('like', 12), ('are', 9), ('can', 6), ('how', 5), ('?', 5), ('s', 5), ('you', 4)] | Training
2025-04-03 13:00:29 | 500 | LR0.0003 | loss:14.1462 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-39.8724 | logitMax:-10.4891 | windowWeightsW8:0.19809,W15:0.17805,W13:0.17491,W18:0.16247,W3:0.13707,W7:0.10769,W2:0.05619,W1:0.01085,W14:-0.04365 | memoryGatesShort:5.529, Long:-5.185, Current:0.655 | topTokens[('.', 51), ('it', 23), (',', 16), ('y', 15), ('p', 15), ('no', 7), ('who', 7), ('ee', 6), ('s', 5), ('a', 5)] | Training
2025-04-03 13:05:41 | 600 | LR0.0003 | loss:11.3730 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-43.9247 | logitMax:-20.4973 | windowWeightsW8:0.19809,W15:0.17814,W13:0.17501,W18:0.16220,W3:0.13687,W7:0.10772,W2:0.05621,W1:0.01079,W14:-0.04335 | memoryGatesShort:-4.761, Long:5.072, Current:0.690 | topTokens[('.', 29), (',', 18), ('in', 14), ('p', 8), ('ee', 8), ('no', 8), ('the', 7), ('like', 6), ('feel', 6), ('she', 5)] | Training
2025-04-03 13:11:09 | 700 | LR0.0003 | loss:10.4446 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-40.4604 | logitMax:-18.2126 | windowWeightsW8:0.19849,W15:0.17787,W13:0.17483,W18:0.16217,W3:0.13692,W7:0.10756,W2:0.05594,W1:0.01085,W14:-0.04295 | memoryGatesShort:12.266, Long:-11.112, Current:-0.154 | topTokens[('.', 31), ('to', 16), ('in', 13), (',', 13), ('the', 9), ('no', 5), ('he', 5), ('a', 4), ('for', 4), ('happy', 4)] | Training
2025-04-03 13:16:19 | 800 | LR0.0003 | loss:12.9355 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.9436 | logitMax:-18.0677 | windowWeightsW8:0.19829,W15:0.17788,W13:0.17495,W18:0.16209,W3:0.13679,W7:0.10755,W2:0.05604,W1:0.01085,W14:-0.04275 | memoryGatesShort:56.443, Long:-43.882, Current:-11.561 | topTokens[('for', 19), ('.', 17), ('i', 8), ('the', 7), ('my', 7), ('y', 6), ('lo', 6), ('it', 6), ('me', 5), ('in', 5)] | Training
2025-04-03 13:21:25 | 900 | LR0.0003 | loss:9.8541 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-40.3771 | logitMax:-20.2289 | windowWeightsW8:0.19824,W15:0.17789,W13:0.17491,W18:0.16211,W3:0.13655,W7:0.10785,W2:0.05598,W1:0.01072,W14:-0.04256 | memoryGatesShort:-10.749, Long:10.402, Current:1.347 | topTokens[('like', 25), ('.', 22), ('i', 12), ('y', 9), ('and', 7), ('my', 7), ('know', 6), (',', 6), ('the', 5), ('no', 5)] | Training
2025-04-03 13:26:55 | 1000 | LR0.0003 | loss:8.7365 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-35.9171 | logitMax:-19.6495 | windowWeightsW8:0.19817,W15:0.17807,W13:0.17506,W18:0.16206,W3:0.13662,W7:0.10783,W2:0.05578,W1:0.01072,W14:-0.04262 | memoryGatesShort:-7.147, Long:7.310, Current:0.837 | topTokens[(',', 33), ('the', 12), ('.', 11), ('ed', 7), ('dont', 5), ('s', 5), ('a', 4), ('them', 4), ('d', 4), ('my', 4)] | Training
2025-04-03 13:32:33 | 1100 | LR0.0003 | loss:14.9300 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-47.8954 | logitMax:-19.1849 | windowWeightsW8:0.19786,W15:0.17813,W13:0.17502,W18:0.16240,W3:0.13635,W7:0.10788,W2:0.05569,W1:0.01078,W14:-0.04240 | memoryGatesShort:-2.771, Long:2.685, Current:1.086 | topTokens[('.', 29), ('ed', 18), ('one', 10), ('and', 9), ('they', 8), ('it', 8), (',', 7), ('b', 7), ('to', 7), ('like', 6)] | Training

--- 2025-04-03 13:36:50 ---
babyLLM: what am i learning today?
You: 1 num tokens per step

--- 2025-04-03 13:37:53 ---
babyLLM: what am i learning today?
You: 1 num tokens per step
2025-04-03 13:40:52 | 100 | LR0.0003 | loss:14.0396 | gradNorm:1.0000 | logitMin:-43.3265 | logitMax:-16.1412 | scheduledSampling:0.0000 | tokenCount:100.0000 | windowWeightsW8:0.19711,W15:0.17827,W13:0.17504,W18:0.16225,W3:0.13583,W7:0.10902,W2:0.05433,W1:0.01000,W14:-0.04013 | memoryGatesShort:-436.523, Long:452.202, Current:-14.679 | topTokens[('.', 8), ('like', 5), ('she', 5), ('feel', 4), ('the', 3), ('am', 3), ('s', 2), ('just', 2), ('but', 2), ('small', 2)] | Training

--- 2025-04-03 13:41:36 ---
babyLLM: what am i learning today?
You: 2 num tokens per step
2025-04-03 13:45:51 | 100 | LR0.0003 | loss:14.2737 | gradNorm:1.0000 | logitMin:-43.1411 | logitMax:-15.4062 | scheduledSampling:0.0000 | tokenCount:200.0000 | windowWeightsW8:0.19658,W15:0.17647,W13:0.17384,W18:0.16141,W3:0.13717,W7:0.10858,W2:0.05438,W1:0.01130,W14:-0.03799 | memoryGatesShort:-17.265, Long:12.236, Current:6.029 | topTokens[('.', 31), ('y', 11), ('it', 11), ('cant', 7), ('like', 7), ('just', 7), (',', 3), ('?', 3), ('b', 2), ('want', 2)] | Training

--- 2025-04-03 13:46:34 ---
babyLLM: what am i learning today?
You: 3 num tokens per step
2025-04-03 13:52:05 | 100 | LR0.0003 | loss:10.2319 | gradNorm:1.0000 | logitMin:-43.4975 | logitMax:-22.4020 | scheduledSampling:0.0000 | tokenCount:300.0000 | windowWeightsW8:0.19686,W15:0.17685,W13:0.17493,W18:0.16127,W3:0.13615,W7:0.10852,W2:0.05408,W1:0.01083,W14:-0.03774 | memoryGatesShort:-7.459, Long:7.635, Current:0.824 | topTokens[('.', 25), ('i', 16), ('they', 6), ('h', 6), ('here', 6), ('ot', 5), ('d', 4), ('life', 3), ('y', 3), ('a', 3)] | Training

--- 2025-04-03 13:52:57 ---
babyLLM: what am i learning today?
You: 4 num tokens per step
2025-04-03 13:59:17 | 100 | LR0.0003 | loss:9.7497 | gradNorm:1.0000 | logitMin:-45.7879 | logitMax:-24.2745 | scheduledSampling:0.0000 | tokenCount:400.0000 | windowWeightsW8:0.19662,W15:0.17741,W13:0.17486,W18:0.16250,W3:0.13595,W7:0.10874,W2:0.05395,W1:0.00982,W14:-0.03811 | memoryGatesShort:9.134, Long:-6.349, Current:-1.785 | topTokens[('.', 20), ('i', 14), (',', 10), ('ot', 8), ('im', 8), ('so', 7), ('it', 6), ('?', 6), ('s', 6), ('me', 6)] | Training

--- 2025-04-03 14:00:08 ---
babyLLM: what am i learning today?
You: 5 num tokens per step
2025-04-03 14:07:24 | 100 | LR0.0003 | loss:6.3348 | gradNorm:1.0000 | logitMin:-38.6925 | logitMax:-17.7554 | scheduledSampling:0.0000 | tokenCount:500.0000 | windowWeightsW8:0.19580,W15:0.17804,W13:0.17596,W18:0.16343,W3:0.13552,W7:0.10902,W2:0.05329,W1:0.01025,W14:-0.03958 | memoryGatesShort:-5.419, Long:4.335, Current:2.084 | topTokens[('to', 42), ('listening', 25), ('.', 24), ('be', 23), ('?', 20), ('she', 19), ('s', 12), ('music', 12), ('i', 11), ('was', 9)] | Training

--- 2025-04-03 14:07:59 ---
babyLLM: what am i learning today?
You: 6 num tokens per step
2025-04-03 14:16:31 | 100 | LR0.0003 | loss:9.8301 | gradNorm:1.0000 | logitMin:-37.1912 | logitMax:-8.5101 | scheduledSampling:0.0000 | tokenCount:600.0000 | windowWeightsW8:0.19602,W15:0.17765,W13:0.17521,W18:0.16299,W3:0.13645,W7:0.10871,W2:0.05328,W1:0.01072,W14:-0.03931 | memoryGatesShort:-11.954, Long:11.612, Current:1.342 | topTokens[('.', 85), ('to', 64), ('?', 31), ('will', 28), ('was', 26), ('listening', 26), ('it', 26), (',', 11), ('he', 11), ('music', 10)] | Training

--- 2025-04-03 14:17:15 ---
babyLLM: what am i learning today?
You: 4 num tokens per step
2025-04-03 14:23:49 | 100 | LR0.0003 | loss:8.3360 | gradNorm:1.0000 | logitMin:-44.8933 | logitMax:-14.7392 | scheduledSampling:0.0000 | tokenCount:400.0000 | windowWeightsW8:0.19494,W15:0.17600,W13:0.17505,W18:0.16330,W3:0.13597,W7:0.10850,W2:0.05431,W1:0.01229,W14:-0.03863 | memoryGatesShort:-2.532, Long:1.608, Current:1.924 | topTokens[('it', 51), ('to', 29), ('.', 28), ('was', 25), ('music', 22), (',', 18), ('listening', 14), ('feel', 11), ('s', 10), ('?', 10)] | Training
2025-04-03 14:30:31 | 200 | LR0.0003 | loss:6.5851 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-38.1283 | logitMax:-16.8617 | windowWeightsW8:0.19423,W15:0.17683,W13:0.17545,W18:0.16368,W3:0.13508,W7:0.10779,W2:0.05463,W1:0.01251,W14:-0.03845 | memoryGatesShort:-1.870, Long:0.665, Current:2.205 | topTokens[('been', 31), ('what', 25), ('listening', 24), ('to', 23), ('.', 21), ('?', 16), (',', 10), ('were', 9), ('music', 8), ('you', 6)] | Training

--- 2025-04-03 14:33:26 ---
babyLLM: what am i learning today?
You: omg i changed ur windows boi

--- 2025-04-03 14:38:16 ---
babyLLM: what am i learning today?
You: messing with visual output

--- 2025-04-03 14:40:22 ---
babyLLM: what am i learning today?
You: noth much

--- 2025-04-03 14:43:17 ---
babyLLM: what am i learning today?
You: y

--- 2025-04-03 14:45:05 ---
babyLLM: what am i learning today?
You: pretty terminal :3
2025-04-03 14:51:08 | 100 | LR0.0003 | loss:6.0763 | gradNorm:1.0000 | logitMin:-43.2822 | logitMax:-17.4105 | scheduledSampling:0.0000 | tokenCount:400.0000 | windowWeightsW8:0.19369,W15:0.17490,W13:0.17398,W18:0.16175,W3:0.13591,W7:0.10759,W2:0.05530,W1:0.01624,W21:-0.03764 | memoryGatesShort:-2.584, Long:1.866, Current:1.717 | topTokens[('to', 42), ('will', 30), ('.', 29), ('listening', 25), ('be', 22), ('music', 15), ('?', 15), ('what', 12), ('we', 11), ('you', 9)] | Training

--- 2025-04-03 14:51:37 ---
babyLLM: what am i learning today?
You: idk

--- 2025-04-03 14:52:39 ---
babyLLM: what am i learning today?
You: y

--- 2025-04-03 14:53:54 ---
babyLLM: what am i learning today?
You: 
2025-04-03 15:00:34 | 100 | LR0.0003 | loss:6.9582 | gradNorm:1.0000 | logitMin:-38.6661 | logitMax:-13.4170 | scheduledSampling:0.0000 | tokenCount:400.0000 | windowWeightsW8:0.19415,W15:0.17482,W13:0.17355,W18:0.16106,W3:0.13520,W7:0.10753,W2:0.05635,W1:0.01704,W21:-0.03800 | memoryGatesShort:-2.260, Long:0.619, Current:2.641 | topTokens[('to', 38), ('what', 29), ('listening', 29), ('music', 18), (',', 14), ('a', 14), ('?', 14), ('you', 13), ('.', 12), ('will', 9)] | Training
2025-04-03 15:07:14 | 200 | LR0.0003 | loss:7.6277 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-38.9247 | logitMax:-10.3894 | windowWeightsW8:0.19451,W15:0.17468,W13:0.17371,W18:0.16035,W3:0.13575,W7:0.10689,W2:0.05683,W1:0.01650,W21:-0.03751 | memoryGatesShort:-4.737, Long:3.752, Current:1.985 | topTokens[('.', 27), ('i', 23), ('to', 22), ('listening', 15), ('game', 15), (',', 15), ('?', 13), ('was', 12), ('!', 10), ('you', 10)] | Training
