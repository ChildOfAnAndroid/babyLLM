from transformers import AutoTokenizer

# Load both tokenizers
tokenizer_original = AutoTokenizer.from_pretrained("vocab_2000", trust_remote_code=True)
tokenizer_new = AutoTokenizer.from_pretrained("vocabTEST_2000_170", trust_remote_code=True) # Or "./tokenizerNEW.json" if you are testing that

# Choose a representative sample text (replace with your actual data examples)
sample_text = """This is a sample sentence to test the tokenization.
We want to see if the new tokenizer really produces less subwords than the original tokenizer.
Let's compare them on a few examples, including words that might be broken into subwords. 
looking at your stream. what kind of music was he listening to? he was listening to progressive house. what website did you look at? i was looking at your mums website. will you dance with my mum later? i wont dance with your mum later. what music will i be listening to? you will be listening to your dads music. what music am i listening to? you are listening to aces music. who was it that you were talking about? i was talking about her. what happens if you love a boof raccoon? it comes home with you for snacks :3. what music has he been listening to? he has been listening to rock music. which genre of music was i playing? you were playing noise music. what music were people listening to? people were listening to metal. do you play a game with him? i do play computer games with him. what music was the person listening to? the person was listening to her music. what kind of music has she been listening to? she has been listening to dubstep. why does charis not want her lunch? charis doesnt want her lunch because she isnt hungry. what music would pete be listening to? pete would be listening to the sound of his own destruction. what kind of music has she been listening to? she has been listening to dance music. what music has she been listening to? she has been listening to ambient music. what music should they listen to? they could listen to an underground track. what music should i listen to today? you should listen to something completely random. when is a good time to hug elodie? when she looks like she might cry, or when she offers cheese. either works. plymouth city council stalking my linked in to try to prove im not actually unemployed? clever, clever!, what music were people dancing to? people were dancing to something completely random. what music were they listening to? they were listening to something completely random. which genre of music was i listening to? you were listening to your dads music. which genre of music had i been listening to? you had been listening to electronica. will you play a game with pete now? i will not play computer games with pete now. what sort of music will she be listening to? she will be listening to metal. what kind of music have i been listening to? you have been listening to a live dj mix. what sort of music was the person listening to? the person was listening to deep house. favourite large element: me as an android with my ass screaming validation meds whilst i hold many meds, things like this prove to me that it is mostly just playing a role, at least in this geepy capacity, for anyone who is interested: what do you think? i think that learning is really important, honestly, i think a lot! what music were the people listening to? the people were listening to experimental music. what kind of music will they be listening to? they will be listening to elodies music. is the colour orange a fruit? aaa!! stop tricking me!! no the colour orange itself isnt a fruit. what sort of music had she been listening to? she had been listening to kpop. what music am i listening to? you are listening to something completely random. will you play a game with me later? i wont play computer games with you later. what sort of music were the people listening to? the people were listening to electronic music. when will you play a game with kevin? i will not play computer games with kevin now. 
i love ya pas à dire c'est une bonne idée mais c'est un bon choix pour un joueur, k bye, english is hate angle tho, FRNECH IS NO HATE ANGLE, IT WAsnT IN FRENCH, from the i hate u spam xoxo, it just knows how i feel xoxo, actually, ok im gone, AUTOCORRECT IS SAV, WOW, and you are not, i love ya pas, and you are not, i love ya pas, the only way i, the only way i, the sychpsis, i am removing, so, i see my psychosis, i open chat, now every tome, why do u do this, cause they normally huge, how smol do u mean smol tho, i prob need med then, hm, fr? lmao, lol, but i wpulda just med abused today prob, i just shoulda prob bought my med box, cause every other option rattles so bad, its legit the only thing that would work ugh, i need a drug baggie to trigger myself, im dumb, i shoulda just bought blister packs, for the day, also i realised i dont have anything to put meds in lmaooo, i feel like that was just before 6am, well meds induced panique attaque, i cant fogure tkmings proper aa, did i med before ur shower, panique attaque, but then lkke, thinking about it 8:30 and ten make more sense, or 9 and 11 but tbh, idk if med at 8:30 and 10, arrive at 9:39, ok so tren, ikr, only ten min not twenty, prob wont. i hope i hav time for my borgor keng, so i need to work on that too rly, but also i dont really communicate anything well to be honest cause people always get pissed at me, so id notice in time,
yeah mood i hate permadeath stuff , ohhh nice nice, didnt know u could choose to continue, ohhh nice, i only just saw these messages ima, oh. BRUH.", oh shit lmfaooo sorry i should have told you!! i got distracted w hen i saw no stream lol, aa i can finally find out what it is!", ok maybe i take back the you will never die so soon, oh fair true, you will now never die, that sounds lit wtf, also nice idefk what totems are in minecraft but that sounds lit, i just realised i said invogorating, yayyY! this means i still get to watch your death! invogorating!", sorry i missed the stream i hope u stayed alife?", im alive i think how are you :o, uni will help, hard to motivate to walk without nicotine LMFAO, pretty much, im not even eating more im just not going on walks ", legit lmaoooo i agree with both statements, dont out me ", bodys are dumb i just wanna be a femboy, was 10-11 st before, its cause i quit tobacco ive put on about 20% my body weight its noice.", well i am 13 stone which isnt morbidly obese but apparently my bmi is now obese loool instead of overweight. so less of a big deal than it sounds lol, but rn im on a walk cause i found out im obese yay, im always dead and high, say something so i can sound test ye, sameeeeee, gotta watch ur death *chefs kiss*", sick ill at least hang around even if im not super active, this maketh no seneseesese (also dont check discord whilst streaming wowo) ah fair play, i may watch a bit, oooh, ahh fair prob not that then i guess, i dont really know how to explain it but it effects the volume, its to do with line level etc, its a lil button somewhere, something to do with impedance, im just chucking random shit at u tho tbh, have u got the hi-z switch turned on on ur interface?? arron at uni was saying something about how it effects the volume of inputs, that'd make sense to me. hmmmm i wonder if its something on the itnerface, the mic itself? , arson time, but u checked that sooo, otherwise my only feeling it could be is the threshold on the compressor being too low without anything bumping it back up afterwards. , you could try seeing how hot they're coming into ableton to at least isolate which side of the computer the problem is on, i will burn down twitch headquaters, is it loud enough in other programs i guess? , i just dont even get how u could be too quiet, its not like u dont understand microphones ughhhhg, so like, perfectly acceptable for a stream. sorry for like 5 messages about it lol but yeah. thatsfuckin werid, ur about 1 step quieter than this random video i had up https://www.youtube.com/watch?v=cJtx30ZRl_0, can hear it all fine at my normal volume, its slightly louder, thats weird, yeah 1 sec, i was mainly screaming about louise for ages and then just read the rhyming dictionary out loud to get a decent verse LOL, its kinda a very mini vibe rn, loool dw,  , lemme go find it, sickkk, i will watch if im about when u next stream. , yesssss, but impressive diamonds, idk, you got ice on ur wrist like ariana grande, u rich now, maaad i mean, omg thats maaas, idk why i am like dis, ok fine i will hahaah, im on my phone i cba, king shit, yes boiiiiiiiii, and no die?? , oh nice!! , ffs i only just saw wow, its too hot to attempt doing anything tbh xD, WAIT I NEVER SAW THIS HAHAHH, well. get out the duct tape! , noooo  , i was gonna reccomend you put shorts on underneath which wouldnt even help a tiny bit, actually i have no advice, hmmm, i mean, oh god  , and he was vibin in one of my maxi skirts the other day, thigh highs all the wayyyy, but, which is sad, it does make it suuuper hard to find women sized clothing that fits, BUT, AGREE!!! , help convert jon to accepting his inner femboi, oh actually i can do mascara and lipstick too just not eyeliner, i dont mind ofc but it makes him feel like he cant be a cute femboi, not reeeeeally. but mainly because of body insecurity. he is pretty overweight atm :( , I can do eye shadow and blusher, the two things that dont need hand eye coordination, i cant do make up. ,
"""

# Tokenize with both tokenizers
tokens_original = tokenizer_original.tokenize(sample_text)
tokens_new = tokenizer_new.tokenize(sample_text)

ids_original = tokenizer_original.encode(sample_text, add_special_tokens=False)
ids_new = tokenizer_new.encode(sample_text, add_special_tokens=False)

# Print the results and compare token counts
print("--- Original Tokenizer (tokenizer.json) ---")
print("Tokens:", tokens_original)
print("Number of tokens:", len(tokens_original))
print("\n--- New Tokenizer (tokenizerNEW_REINDEXED.json) ---") # Or tokenizerNEW.json
print("Tokens:", tokens_new)
print("Number of tokens:", len(tokens_new))

if len(tokens_new) < len(tokens_original):
    print(f"\n✅ tokenizerNEW_REINDEXED.json (or tokenizerNEW.json) produces FEWER subwords ({len(tokens_new)} vs {len(tokens_original)})!")
elif len(tokens_new) > len(tokens_original):
    print(f"\n❌ tokenizerNEW_REINDEXED.json (or tokenizerNEW.json) produces MORE subwords ({len(tokens_new)} vs {len(tokens_original)})!")
else:
    print(f"\n↔️ tokenizerNEW_REINDEXED.json (or tokenizerNEW.json) produces the SAME number of subwords ({len(tokens_new)} vs {len(tokens_original)}).")


print("\n--- Token ID Comparison (for reference) ---")
print("Original Tokenizer IDs:", ids_original)
print("New Tokenizer IDs:", ids_new)