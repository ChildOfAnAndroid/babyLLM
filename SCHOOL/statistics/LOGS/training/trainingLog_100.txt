--- 2025-03-15 02:24:28 ---
2025-03-15 02:29:39 | Context: [[3, 5, 7, 9, 11]] | LR: 0.00005 | Step 100 | Avg Loss: 25.2998
2025-03-15 02:35:00 | Context: [[3, 5, 7, 9, 11]] | LR: 0.00005 | Step 200 | Avg Loss: 25.5011
2025-03-15 02:40:19 | Context: [[3, 5, 7, 9, 11]] | LR: 0.00005 | Step 300 | Avg Loss: 23.9552
2025-03-15 02:45:43 | Context: [[3, 5, 7, 9, 11]] | LR: 0.00005 | Step 400 | Avg Loss: 29.1021

--- 2025-03-15 02:47:10 ---
2025-03-15 02:52:42 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 100 | Avg Loss: 26.0054
2025-03-15 02:58:26 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 200 | Avg Loss: 24.4129
2025-03-15 03:04:05 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 300 | Avg Loss: 28.1631
2025-03-15 03:09:47 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 400 | Avg Loss: 31.1546
2025-03-15 03:15:33 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 500 | Avg Loss: 28.4702
2025-03-15 03:21:17 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 600 | Avg Loss: 28.0436
2025-03-15 03:26:59 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 700 | Avg Loss: 26.2134
2025-03-15 03:32:37 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 800 | Avg Loss: 31.1412
2025-03-15 03:38:19 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 900 | Avg Loss: 27.8323
2025-03-15 03:44:00 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1000 | Avg Loss: 24.9488
2025-03-15 03:49:48 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1100 | Avg Loss: 28.5189
2025-03-15 03:55:38 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1200 | Avg Loss: 28.9171
2025-03-15 04:01:23 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1300 | Avg Loss: 29.6624
2025-03-15 04:07:04 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1400 | Avg Loss: 31.8279
2025-03-15 04:12:50 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1500 | Avg Loss: 31.0177
2025-03-15 04:18:43 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1600 | Avg Loss: 26.1206
2025-03-15 04:24:32 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1700 | Avg Loss: 27.8529
2025-03-15 04:30:22 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1800 | Avg Loss: 30.6420
2025-03-15 04:36:08 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 1900 | Avg Loss: 29.5534
2025-03-15 04:41:51 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00005 | Step 2000 | Avg Loss: 27.6393

--- 2025-03-15 04:49:48 ---
2025-03-15 04:55:25 | Context: [[2, 4, 7, 7, 12]] | LR: 0.00030 | Step 100 | Avg Loss: 77.4762

--- 2025-03-15 04:56:28 ---
2025-03-15 05:02:03 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00030 | Step 100 | Avg Loss: 66.8302
2025-03-15 05:07:41 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00030 | Step 200 | Avg Loss: 148.5852

--- 2025-03-15 05:11:05 ---
2025-03-15 05:16:40 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00030 | Step 100 | Avg Loss: 115.5158

--- 2025-03-15 05:17:03 ---
2025-03-15 05:22:43 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00010 | Step 100 | Avg Loss: 77.8784
2025-03-15 05:28:31 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00010 | Step 200 | Avg Loss: 50.7676

--- 2025-03-15 05:30:10 ---
2025-03-15 05:35:46 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00010 | Step 100 | Avg Loss: 39.5901
2025-03-15 05:41:28 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00010 | Step 200 | Avg Loss: 47.8724

--- 2025-03-15 05:42:34 ---
2025-03-15 05:48:10 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00010 | Step 100 | Avg Loss: 29.2407

--- 2025-03-15 05:51:51 ---
2025-03-15 05:57:26 | Context: [[2, 4, 7, 10, 12]] | LR: 0.00010 | Step 100 | Avg Loss: 104.4668

--- 2025-03-15 06:01:10 ---
2025-03-15 06:06:45 | Context: [[3, 5, 7, 10, 12]] | LR: 0.00010 | Step 100 | Avg Loss: 29.7282

--- 2025-03-15 06:07:14 ---
2025-03-15 06:12:55 | Context: [[3, 5, 7, 10, 12]] | LR: 0.00010 | Step 100 | Avg Loss: 46.7204

--- 2025-03-15 06:57:36 ---
2025-03-15 07:05:07 | Context: [[7, 3, 10, 13, 15]] | LR: 0.00010 | Step 100 | Avg Loss: 86.4620

--- 2025-03-15 07:10:56 ---
2025-03-15 07:17:46 | Context: [[7, 3, 7, 10, 13]] | LR: 0.00010 | Step 100 | Avg Loss: 140.1534

--- 2025-03-15 07:18:42 ---
2025-03-15 07:25:09 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00010 | Step 100 | Avg Loss: 48.6443

--- 2025-03-15 07:31:55 ---
2025-03-15 07:38:23 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 109.2312
2025-03-15 07:45:16 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 200 | Avg Loss: 69.8390
2025-03-15 07:52:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 300 | Avg Loss: 84.9747
2025-03-15 07:59:04 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 400 | Avg Loss: 112.7125

--- 2025-03-15 08:28:41 ---
2025-03-15 08:34:52 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 246.5380
2025-03-15 08:41:40 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 200 | Avg Loss: 128.0534
2025-03-15 08:48:15 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 300 | Avg Loss: 122.6352
2025-03-15 08:54:14 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 400 | Avg Loss: 100.5878
2025-03-15 09:00:16 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 500 | Avg Loss: 220.3655
2025-03-15 09:06:20 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 600 | Avg Loss: 200.4332
2025-03-15 09:12:22 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 700 | Avg Loss: 187.5774
2025-03-15 09:18:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 800 | Avg Loss: 176.3647
2025-03-15 09:24:31 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 900 | Avg Loss: 173.5481
2025-03-15 09:30:33 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1000 | Avg Loss: 196.0468
2025-03-15 09:36:36 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1100 | Avg Loss: 187.1669
2025-03-15 09:42:44 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1200 | Avg Loss: 178.8575
2025-03-15 09:48:49 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1300 | Avg Loss: 177.5162
2025-03-15 09:54:55 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1400 | Avg Loss: 167.8484
2025-03-15 10:01:01 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1500 | Avg Loss: 218.6308
2025-03-15 10:07:05 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1600 | Avg Loss: 154.3260
2025-03-15 10:13:12 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1700 | Avg Loss: 147.1482
2025-03-15 10:19:19 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1800 | Avg Loss: 134.2065
2025-03-15 10:25:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1900 | Avg Loss: 134.6512
2025-03-15 10:31:31 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2000 | Avg Loss: 162.2315
2025-03-15 10:37:37 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2100 | Avg Loss: 131.4008
2025-03-15 10:43:46 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2200 | Avg Loss: 148.0430
2025-03-15 10:49:46 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2300 | Avg Loss: 126.7081
2025-03-15 10:55:48 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2400 | Avg Loss: 133.0843
2025-03-15 11:01:51 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2500 | Avg Loss: 140.3406
2025-03-15 11:07:55 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2600 | Avg Loss: 131.1765
2025-03-15 11:14:05 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2700 | Avg Loss: 129.3430
2025-03-15 11:20:14 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2800 | Avg Loss: 97.8129
2025-03-15 11:26:20 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2900 | Avg Loss: 135.7963
2025-03-15 11:32:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3000 | Avg Loss: 88.9440
2025-03-15 11:38:31 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3100 | Avg Loss: 111.3219
2025-03-15 11:44:37 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3200 | Avg Loss: 110.6982
2025-03-15 11:50:44 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3300 | Avg Loss: 117.2204
2025-03-15 11:56:48 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3400 | Avg Loss: 123.5096
2025-03-15 12:02:54 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3500 | Avg Loss: 99.7319
2025-03-15 12:08:58 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3600 | Avg Loss: 114.9261
2025-03-15 12:15:01 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3700 | Avg Loss: 111.0956
2025-03-15 12:21:11 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3800 | Avg Loss: 91.0441
2025-03-15 12:27:16 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3900 | Avg Loss: 118.3144
2025-03-15 12:33:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4000 | Avg Loss: 122.6783
2025-03-15 12:39:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4100 | Avg Loss: 93.2427
2025-03-15 12:45:31 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4200 | Avg Loss: 107.3375
2025-03-15 12:51:36 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4300 | Avg Loss: 114.5238
2025-03-15 12:57:42 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4400 | Avg Loss: 95.8251
2025-03-15 13:03:50 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4500 | Avg Loss: 108.2282
2025-03-15 13:09:55 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4600 | Avg Loss: 82.6846
2025-03-15 13:15:57 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4700 | Avg Loss: 114.3864
2025-03-15 13:22:05 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4800 | Avg Loss: 86.5105
2025-03-15 13:28:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4900 | Avg Loss: 121.5874
2025-03-15 13:34:20 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5000 | Avg Loss: 87.5749
2025-03-15 13:40:27 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5100 | Avg Loss: 175.1104
2025-03-15 13:46:32 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5200 | Avg Loss: 136.4255
2025-03-15 13:52:37 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5300 | Avg Loss: 75.8046
2025-03-15 13:58:45 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5400 | Avg Loss: 88.9204
2025-03-15 14:04:49 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5500 | Avg Loss: 95.2836
2025-03-15 14:10:57 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5600 | Avg Loss: 72.8710
2025-03-15 14:17:03 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5700 | Avg Loss: 78.1028
2025-03-15 14:23:07 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5800 | Avg Loss: 86.8291
2025-03-15 14:29:12 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5900 | Avg Loss: 85.3887
2025-03-15 14:35:17 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6000 | Avg Loss: 73.9537
2025-03-15 14:41:24 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6100 | Avg Loss: 81.1418
2025-03-15 14:47:29 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6200 | Avg Loss: 89.0133
2025-03-15 14:53:37 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6300 | Avg Loss: 79.6786
2025-03-15 14:59:44 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6400 | Avg Loss: 72.8702
2025-03-15 15:05:53 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6500 | Avg Loss: 76.2956
2025-03-15 15:11:57 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6600 | Avg Loss: 97.9542
2025-03-15 15:17:59 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6700 | Avg Loss: 69.9055
2025-03-15 15:24:06 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6800 | Avg Loss: 80.3380
2025-03-15 15:30:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6900 | Avg Loss: 88.7021
2025-03-15 15:36:24 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7000 | Avg Loss: 61.6491
2025-03-15 15:42:47 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7100 | Avg Loss: 97.2115
2025-03-15 15:49:11 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7200 | Avg Loss: 63.4097

--- 2025-03-15 15:50:45 ---
2025-03-15 15:56:40 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 115.8527
2025-03-15 16:02:46 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 200 | Avg Loss: 118.1715
2025-03-15 16:08:48 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 300 | Avg Loss: 111.5543
2025-03-15 16:14:43 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 400 | Avg Loss: 85.2576
2025-03-15 16:20:41 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 500 | Avg Loss: 112.3581
2025-03-15 16:26:40 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 600 | Avg Loss: 115.6110
2025-03-15 16:32:40 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 700 | Avg Loss: 101.3372
2025-03-15 16:38:53 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 800 | Avg Loss: 95.9238
2025-03-15 16:45:09 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 900 | Avg Loss: 97.1094
2025-03-15 16:51:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1000 | Avg Loss: 101.4199
2025-03-15 16:57:25 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1100 | Avg Loss: 91.5585
2025-03-15 17:03:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1200 | Avg Loss: 72.4589
2025-03-15 17:09:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1300 | Avg Loss: 69.8153
2025-03-15 17:15:28 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1400 | Avg Loss: 67.4341
2025-03-15 17:21:37 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1500 | Avg Loss: 84.8699

--- 2025-03-15 17:26:13 ---
2025-03-15 17:32:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 31.3383
2025-03-15 17:38:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 200 | Avg Loss: 39.3956
2025-03-15 17:44:23 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 300 | Avg Loss: 67.3998
2025-03-15 17:50:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 400 | Avg Loss: 56.0565
2025-03-15 17:56:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 500 | Avg Loss: 99.9979
2025-03-15 18:02:38 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 600 | Avg Loss: 75.8656
2025-03-15 18:08:45 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 700 | Avg Loss: 129.0989
2025-03-15 18:14:44 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 800 | Avg Loss: 83.9430
2025-03-15 18:20:44 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 900 | Avg Loss: 73.0983
2025-03-15 18:26:50 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1000 | Avg Loss: 98.4316
2025-03-15 18:33:07 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1100 | Avg Loss: 64.4048
2025-03-15 18:39:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1200 | Avg Loss: 73.3789
2025-03-15 18:45:41 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1300 | Avg Loss: 102.1722
2025-03-15 18:52:00 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1400 | Avg Loss: 79.0767
2025-03-15 18:58:07 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1500 | Avg Loss: 56.8205
2025-03-15 19:04:09 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1600 | Avg Loss: 55.9097
2025-03-15 19:10:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1700 | Avg Loss: 78.8310
2025-03-15 19:16:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1800 | Avg Loss: 69.5042
2025-03-15 19:22:15 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1900 | Avg Loss: 55.1442
2025-03-15 19:28:18 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2000 | Avg Loss: 85.9705
2025-03-15 19:34:17 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2100 | Avg Loss: 72.7598
2025-03-15 19:40:17 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2200 | Avg Loss: 94.6816
2025-03-15 19:46:25 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2300 | Avg Loss: 64.2222
2025-03-15 19:52:33 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2400 | Avg Loss: 60.1549
2025-03-15 19:58:42 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2500 | Avg Loss: 62.4248
2025-03-15 20:04:53 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2600 | Avg Loss: 103.6482

--- 2025-03-15 20:07:41 ---
2025-03-15 20:13:31 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 36.0646
2025-03-15 20:19:33 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 200 | Avg Loss: 26.3742
2025-03-15 20:25:49 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 300 | Avg Loss: 65.9463
2025-03-15 20:31:56 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 400 | Avg Loss: 65.7200
2025-03-15 20:37:56 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 500 | Avg Loss: 196.0454
2025-03-15 20:43:59 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 600 | Avg Loss: 180.6565
2025-03-15 20:50:00 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 700 | Avg Loss: 166.2669
2025-03-15 20:56:04 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 800 | Avg Loss: 143.7420
2025-03-15 21:02:06 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 900 | Avg Loss: 142.5713
2025-03-15 21:08:10 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1000 | Avg Loss: 154.4563
2025-03-15 21:14:14 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1100 | Avg Loss: 114.4567
2025-03-15 21:20:14 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1200 | Avg Loss: 154.0373
2025-03-15 21:26:19 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1300 | Avg Loss: 123.1501
2025-03-15 21:32:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1400 | Avg Loss: 98.3505
2025-03-15 21:38:23 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1500 | Avg Loss: 104.9495
2025-03-15 21:44:24 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1600 | Avg Loss: 91.2051
2025-03-15 21:50:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1700 | Avg Loss: 108.8672
2025-03-15 21:56:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1800 | Avg Loss: 96.3650
2025-03-15 22:02:27 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1900 | Avg Loss: 163.4714
2025-03-15 22:08:32 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2000 | Avg Loss: 114.7532
2025-03-15 22:14:34 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2100 | Avg Loss: 100.2960
2025-03-15 22:20:40 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2200 | Avg Loss: 121.1595
2025-03-15 22:26:46 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2300 | Avg Loss: 100.0968
2025-03-15 22:32:48 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2400 | Avg Loss: 118.5921
2025-03-15 22:38:52 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2500 | Avg Loss: 97.3297
2025-03-15 22:44:56 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2600 | Avg Loss: 121.1797
2025-03-15 22:50:59 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2700 | Avg Loss: 84.0974
2025-03-15 22:57:01 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2800 | Avg Loss: 123.8064
2025-03-15 23:03:02 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2900 | Avg Loss: 111.8447
2025-03-15 23:09:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3000 | Avg Loss: 60.9404
2025-03-15 23:15:28 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3100 | Avg Loss: 69.8506

--- 2025-03-15 23:26:46 ---
2025-03-15 23:33:07 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 22.2306

--- 2025-03-15 23:35:03 ---
2025-03-15 23:41:20 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 24.0999
2025-03-15 23:47:55 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 200 | Avg Loss: 30.6750
2025-03-15 23:54:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 300 | Avg Loss: 40.6864
2025-03-16 00:00:54 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 400 | Avg Loss: 61.6676
2025-03-16 00:07:30 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 500 | Avg Loss: 69.6424
2025-03-16 00:14:01 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 600 | Avg Loss: 54.7204
2025-03-16 00:20:22 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 700 | Avg Loss: 75.5601
2025-03-16 00:26:47 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 800 | Avg Loss: 55.6356
2025-03-16 00:33:14 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 900 | Avg Loss: 73.8038
2025-03-16 00:39:45 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1000 | Avg Loss: 46.3641
2025-03-16 00:46:17 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1100 | Avg Loss: 44.0149
2025-03-16 00:52:50 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1200 | Avg Loss: 45.9646
2025-03-16 00:59:27 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1300 | Avg Loss: 58.1323
2025-03-16 01:06:05 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1400 | Avg Loss: 45.5975
2025-03-16 01:12:39 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1500 | Avg Loss: 43.9294
2025-03-16 01:19:18 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1600 | Avg Loss: 42.9883
2025-03-16 01:25:55 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1700 | Avg Loss: 58.1261

--- 2025-03-16 01:28:02 ---
2025-03-16 01:34:24 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 33.5350
2025-03-16 01:40:55 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 200 | Avg Loss: 20.6602
2025-03-16 01:47:28 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 300 | Avg Loss: 35.1610
2025-03-16 01:53:56 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 400 | Avg Loss: 50.1460
2025-03-16 02:00:39 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 500 | Avg Loss: 106.6196
2025-03-16 02:07:12 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 600 | Avg Loss: 112.4661
2025-03-16 02:13:49 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 700 | Avg Loss: 111.3483
2025-03-16 02:20:30 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 800 | Avg Loss: 58.1489
2025-03-16 02:27:01 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 900 | Avg Loss: 84.3945
2025-03-16 02:33:34 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1000 | Avg Loss: 102.5407
2025-03-16 02:40:02 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1100 | Avg Loss: 80.7920
2025-03-16 02:46:41 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1200 | Avg Loss: 86.4024
2025-03-16 02:53:16 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1300 | Avg Loss: 69.4069
2025-03-16 02:59:48 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1400 | Avg Loss: 44.7647
2025-03-16 03:06:20 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1500 | Avg Loss: 68.3722
2025-03-16 03:12:58 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1600 | Avg Loss: 38.1073
2025-03-16 03:19:31 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1700 | Avg Loss: 73.8641
2025-03-16 03:26:09 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1800 | Avg Loss: 60.1812
2025-03-16 03:32:44 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1900 | Avg Loss: 105.1594
2025-03-16 03:39:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2000 | Avg Loss: 84.5493
2025-03-16 03:45:43 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2100 | Avg Loss: 59.3795
2025-03-16 03:52:16 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2200 | Avg Loss: 56.3045
2025-03-16 03:58:50 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2300 | Avg Loss: 55.7493
2025-03-16 04:05:25 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2400 | Avg Loss: 79.6449
2025-03-16 04:11:57 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2500 | Avg Loss: 51.0424
2025-03-16 04:18:25 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2600 | Avg Loss: 70.4421
2025-03-16 04:24:57 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2700 | Avg Loss: 78.3477
2025-03-16 04:31:29 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2800 | Avg Loss: 79.4457
2025-03-16 04:38:00 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 2900 | Avg Loss: 93.8174
2025-03-16 04:44:33 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3000 | Avg Loss: 65.5502
2025-03-16 04:51:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3100 | Avg Loss: 64.9889
2025-03-16 04:57:45 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3200 | Avg Loss: 62.5843
2025-03-16 05:04:19 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3300 | Avg Loss: 66.1711
2025-03-16 05:10:51 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3400 | Avg Loss: 82.5766
2025-03-16 05:17:22 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3500 | Avg Loss: 56.9210
2025-03-16 05:23:53 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3600 | Avg Loss: 64.7987
2025-03-16 05:30:23 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3700 | Avg Loss: 52.5492
2025-03-16 05:36:51 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3800 | Avg Loss: 112.4007
2025-03-16 05:43:22 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 3900 | Avg Loss: 70.1260
2025-03-16 05:49:56 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4000 | Avg Loss: 59.5052
2025-03-16 05:56:27 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4100 | Avg Loss: 52.7346
2025-03-16 06:03:00 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4200 | Avg Loss: 62.7025
2025-03-16 06:09:33 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4300 | Avg Loss: 97.5762
2025-03-16 06:16:06 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4400 | Avg Loss: 53.8367
2025-03-16 06:22:43 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4500 | Avg Loss: 53.4515
2025-03-16 06:29:16 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4600 | Avg Loss: 55.7380
2025-03-16 06:35:48 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4700 | Avg Loss: 65.0798
2025-03-16 06:42:23 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4800 | Avg Loss: 60.1677
2025-03-16 06:48:56 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 4900 | Avg Loss: 90.4631
2025-03-16 06:55:31 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5000 | Avg Loss: 39.8402
2025-03-16 07:02:02 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5100 | Avg Loss: 55.3272
2025-03-16 07:08:33 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5200 | Avg Loss: 199.3606
2025-03-16 07:15:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5300 | Avg Loss: 91.2177
2025-03-16 07:21:46 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5400 | Avg Loss: 54.1649
2025-03-16 07:28:20 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5500 | Avg Loss: 48.1239
2025-03-16 07:34:48 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5600 | Avg Loss: 46.2544
2025-03-16 07:41:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5700 | Avg Loss: 40.6059
2025-03-16 07:47:54 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5800 | Avg Loss: 69.2682
2025-03-16 07:54:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 5900 | Avg Loss: 75.3200
2025-03-16 08:01:00 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6000 | Avg Loss: 57.5763
2025-03-16 08:07:29 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6100 | Avg Loss: 96.8410
2025-03-16 08:14:04 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6200 | Avg Loss: 66.3142
2025-03-16 08:20:38 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6300 | Avg Loss: 68.2777
2025-03-16 08:27:15 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6400 | Avg Loss: 58.9544
2025-03-16 08:33:49 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6500 | Avg Loss: 81.5270
2025-03-16 08:40:19 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6600 | Avg Loss: 58.2103
2025-03-16 08:46:54 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6700 | Avg Loss: 50.8214
2025-03-16 08:53:23 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6800 | Avg Loss: 72.0570
2025-03-16 08:59:54 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 6900 | Avg Loss: 69.7009
2025-03-16 09:06:27 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7000 | Avg Loss: 42.5143
2025-03-16 09:13:00 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7100 | Avg Loss: 70.5079
2025-03-16 09:19:38 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7200 | Avg Loss: 52.3134
2025-03-16 09:26:22 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7300 | Avg Loss: 58.7032
2025-03-16 09:33:02 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7400 | Avg Loss: 67.8549
2025-03-16 09:39:45 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7500 | Avg Loss: 73.4838
2025-03-16 09:46:26 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7600 | Avg Loss: 71.7162
2025-03-16 09:53:11 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7700 | Avg Loss: 56.5845
2025-03-16 09:59:52 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7800 | Avg Loss: 52.9866
2025-03-16 10:06:31 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 7900 | Avg Loss: 82.8979
2025-03-16 10:13:09 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8000 | Avg Loss: 53.3453
2025-03-16 10:19:39 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8100 | Avg Loss: 45.3820
2025-03-16 10:26:06 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8200 | Avg Loss: 69.7555
2025-03-16 10:32:36 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8300 | Avg Loss: 82.8876
2025-03-16 10:39:12 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8400 | Avg Loss: 149.0091
2025-03-16 10:45:42 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8500 | Avg Loss: 70.2144
2025-03-16 10:52:14 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8600 | Avg Loss: 48.0424
2025-03-16 10:58:40 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8700 | Avg Loss: 48.4944
2025-03-16 11:05:17 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8800 | Avg Loss: 49.6207
2025-03-16 11:11:49 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 8900 | Avg Loss: 43.4027
2025-03-16 11:18:33 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9000 | Avg Loss: 61.7206
2025-03-16 11:25:11 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9100 | Avg Loss: 63.1167
2025-03-16 11:31:35 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9200 | Avg Loss: 89.8418
2025-03-16 11:38:05 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9300 | Avg Loss: 58.4709
2025-03-16 11:44:35 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9400 | Avg Loss: 55.3873
2025-03-16 11:51:09 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9500 | Avg Loss: 46.9050
2025-03-16 11:57:46 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9600 | Avg Loss: 41.0728
2025-03-16 12:04:19 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9700 | Avg Loss: 59.3705
2025-03-16 12:10:52 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9800 | Avg Loss: 71.8097
2025-03-16 12:17:22 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 9900 | Avg Loss: 46.7708
2025-03-16 12:23:58 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10000 | Avg Loss: 46.2166
2025-03-16 12:30:32 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10100 | Avg Loss: 58.2757
2025-03-16 12:37:06 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10200 | Avg Loss: 54.9861
2025-03-16 12:43:35 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10300 | Avg Loss: 66.2874
2025-03-16 12:50:07 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10400 | Avg Loss: 54.9689
2025-03-16 12:56:45 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10500 | Avg Loss: 54.2804
2025-03-16 13:03:23 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10600 | Avg Loss: 55.6618
2025-03-16 13:09:58 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10700 | Avg Loss: 47.6317
2025-03-16 13:16:25 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10800 | Avg Loss: 62.6010
2025-03-16 13:22:55 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 10900 | Avg Loss: 72.9611
2025-03-16 13:29:33 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 11000 | Avg Loss: 57.6824
2025-03-16 13:36:08 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 11100 | Avg Loss: 52.6862
2025-03-16 13:42:40 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 11200 | Avg Loss: 70.6405
2025-03-16 13:49:08 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 11300 | Avg Loss: 42.4853
2025-03-16 13:55:50 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 11400 | Avg Loss: 67.0321
2025-03-16 14:02:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 11500 | Avg Loss: 55.9532
2025-03-16 14:08:49 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 11600 | Avg Loss: 57.3515
2025-03-16 14:15:21 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 11700 | Avg Loss: 47.1907
2025-03-16 14:21:52 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 11800 | Avg Loss: 72.0933

--- 2025-03-16 14:23:55 ---
2025-03-16 14:30:19 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 22.1896
2025-03-16 14:36:57 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 200 | Avg Loss: 15.5898
2025-03-16 14:43:32 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 300 | Avg Loss: 37.8824
2025-03-16 14:50:04 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 400 | Avg Loss: 47.7168
2025-03-16 14:56:32 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 500 | Avg Loss: 60.4211
2025-03-16 15:02:47 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 600 | Avg Loss: 105.2108
2025-03-16 15:09:15 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 700 | Avg Loss: 89.0301
2025-03-16 15:15:40 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 800 | Avg Loss: 59.9047
2025-03-16 15:22:03 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 900 | Avg Loss: 84.2073
2025-03-16 15:28:23 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1000 | Avg Loss: 86.5089
2025-03-16 15:34:55 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1100 | Avg Loss: 50.9784
2025-03-16 15:41:25 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1200 | Avg Loss: 88.1969
2025-03-16 15:48:03 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1300 | Avg Loss: 65.3012
2025-03-16 15:54:46 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1400 | Avg Loss: 57.0884
2025-03-16 16:01:24 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 1500 | Avg Loss: 71.2024

--- 2025-03-16 17:06:37 ---
2025-03-16 17:13:13 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 20.0309
2025-03-16 17:20:17 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 200 | Avg Loss: 18.4499

--- 2025-03-17 01:24:42 ---
2025-03-17 01:31:22 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 26715.9554

--- 2025-03-17 01:32:35 ---
2025-03-17 01:39:35 | Context: [[9, 3, 7, 11, 13]] | LR: 0.00020 | Step 100 | Avg Loss: 19879.6459

--- 2025-03-17 02:00:40 ---
2025-03-17 02:10:46 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00020 | Step 100 | Avg Loss: 39498.0762
2025-03-17 02:20:45 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00020 | Step 200 | Avg Loss: 28009.5755
2025-03-17 02:31:02 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00020 | Step 300 | Avg Loss: 25642.2160

--- 2025-03-17 02:37:49 ---
2025-03-17 02:48:05 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00100 | Step 100 | Avg Loss: 28843.6099

--- 2025-03-17 02:48:28 ---
2025-03-17 02:59:04 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00100 | Step 100 | Avg Loss: 25152.5686

--- 2025-03-17 03:00:01 ---
2025-03-17 03:10:07 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 4659.3183
2025-03-17 03:20:01 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 2600.4185
2025-03-17 03:30:11 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 3388.7038
2025-03-17 03:40:42 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 400 | Avg Loss: 4714.7594
2025-03-17 03:51:07 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 500 | Avg Loss: 3797.0653
2025-03-17 04:01:33 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 600 | Avg Loss: 4070.9521
2025-03-17 04:11:55 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 700 | Avg Loss: 3560.0172
2025-03-17 04:22:10 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 800 | Avg Loss: 3523.1642
2025-03-17 04:32:19 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 900 | Avg Loss: 3237.5456
2025-03-17 04:42:26 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1000 | Avg Loss: 2700.2383
2025-03-17 04:52:36 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1100 | Avg Loss: 2131.8759
2025-03-17 05:02:47 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1200 | Avg Loss: 2426.8967
2025-03-17 05:12:52 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1300 | Avg Loss: 2026.6394
2025-03-17 05:23:18 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1400 | Avg Loss: 2753.8994
2025-03-17 05:33:39 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1500 | Avg Loss: 1957.3865
2025-03-17 05:43:33 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1600 | Avg Loss: 2092.1095
2025-03-17 05:53:54 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1700 | Avg Loss: 2320.5258
2025-03-17 06:04:04 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1800 | Avg Loss: 2405.1164
2025-03-17 06:14:17 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1900 | Avg Loss: 2336.4856
2025-03-17 06:24:46 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2000 | Avg Loss: 1925.1590
2025-03-17 06:34:39 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2100 | Avg Loss: 1795.4731
2025-03-17 06:44:40 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2200 | Avg Loss: 1448.7990
2025-03-17 06:55:02 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2300 | Avg Loss: 1934.9342
2025-03-17 07:05:20 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2400 | Avg Loss: 1440.1762
2025-03-17 07:15:46 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2500 | Avg Loss: 1945.8349
2025-03-17 07:25:48 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2600 | Avg Loss: 1362.9692
2025-03-17 07:35:58 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2700 | Avg Loss: 1374.4692
2025-03-17 07:46:14 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2800 | Avg Loss: 1268.6737
2025-03-17 07:56:11 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2900 | Avg Loss: 1408.0841
2025-03-17 08:06:29 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3000 | Avg Loss: 2359.5954
2025-03-17 08:16:37 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3100 | Avg Loss: 1302.0832
2025-03-17 08:26:35 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3200 | Avg Loss: 1378.5651
2025-03-17 08:37:08 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3300 | Avg Loss: 1228.0489
2025-03-17 08:47:22 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3400 | Avg Loss: 1046.3980
2025-03-17 08:57:35 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3500 | Avg Loss: 738.8850
2025-03-17 09:07:36 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3600 | Avg Loss: 754.8634

--- 2025-03-17 21:11:37 ---
2025-03-17 21:21:25 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 901.1271
2025-03-17 21:31:08 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 565.6618
2025-03-17 21:40:48 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 640.2143
2025-03-17 21:51:07 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 400 | Avg Loss: 634.0207
2025-03-17 22:01:02 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 500 | Avg Loss: 716.5188
2025-03-17 22:11:02 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 600 | Avg Loss: 600.3293
2025-03-17 22:21:18 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 700 | Avg Loss: 462.7544
2025-03-17 22:31:20 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 800 | Avg Loss: 618.2580
2025-03-17 22:41:15 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 900 | Avg Loss: 469.7889
2025-03-17 22:51:28 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1000 | Avg Loss: 284.0975
2025-03-17 23:01:23 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1100 | Avg Loss: 357.9351
2025-03-17 23:11:16 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1200 | Avg Loss: 236.3479
2025-03-17 23:21:11 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1300 | Avg Loss: 101.6921
2025-03-17 23:31:15 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1400 | Avg Loss: 115.2247
2025-03-17 23:41:06 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1500 | Avg Loss: 150.5834
2025-03-17 23:51:16 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1600 | Avg Loss: 105.9382
2025-03-18 00:01:37 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1700 | Avg Loss: 85.4690
2025-03-18 00:11:29 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1800 | Avg Loss: 112.1785
2025-03-18 00:21:28 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1900 | Avg Loss: 131.2421
2025-03-18 00:31:41 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2000 | Avg Loss: 129.4005
2025-03-18 00:41:44 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2100 | Avg Loss: 70.1770
2025-03-18 00:51:40 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2200 | Avg Loss: 55.0736
2025-03-18 01:01:44 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2300 | Avg Loss: 61.0497
2025-03-18 01:11:56 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2400 | Avg Loss: 67.3330
2025-03-18 01:21:52 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2500 | Avg Loss: 108.1637
2025-03-18 01:31:55 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2600 | Avg Loss: 38.7703
2025-03-18 01:41:59 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2700 | Avg Loss: 140.6988
2025-03-18 01:51:46 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2800 | Avg Loss: 93.4041
2025-03-18 02:01:34 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2900 | Avg Loss: 113.1885
2025-03-18 02:11:34 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3000 | Avg Loss: 133.0571

--- 2025-03-18 02:12:19 ---
2025-03-18 02:21:48 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 149.6652

--- 2025-03-18 02:30:10 ---
2025-03-18 02:39:36 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 154.4235
2025-03-18 02:49:43 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 120.7164
2025-03-18 02:59:32 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 126.3523
2025-03-18 03:09:18 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 400 | Avg Loss: 74.9091
2025-03-18 03:19:17 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 500 | Avg Loss: 103.2713
2025-03-18 03:28:56 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 600 | Avg Loss: 104.9203
2025-03-18 03:38:32 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 700 | Avg Loss: 83.9783
2025-03-18 03:48:03 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 800 | Avg Loss: 97.7172
2025-03-18 03:57:44 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 900 | Avg Loss: 82.8607
2025-03-18 04:07:30 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1000 | Avg Loss: 58.2282
2025-03-18 04:17:03 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1100 | Avg Loss: 95.5480
2025-03-18 04:26:57 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1200 | Avg Loss: 43.9700
2025-03-18 04:36:33 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1300 | Avg Loss: 86.6372
2025-03-18 04:46:14 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1400 | Avg Loss: 54.8085
2025-03-18 04:56:10 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1500 | Avg Loss: 54.2438
2025-03-18 05:05:50 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1600 | Avg Loss: 56.8252
2025-03-18 05:15:31 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1700 | Avg Loss: 41.0499
2025-03-18 05:25:12 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1800 | Avg Loss: 62.0740
2025-03-18 05:35:06 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1900 | Avg Loss: 43.9846
2025-03-18 05:44:35 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2000 | Avg Loss: 109.8787
2025-03-18 05:54:11 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2100 | Avg Loss: 67.5122
2025-03-18 06:04:06 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2200 | Avg Loss: 65.1549
2025-03-18 06:13:42 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2300 | Avg Loss: 62.6281
2025-03-18 06:23:17 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2400 | Avg Loss: 55.0863
2025-03-18 06:32:55 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2500 | Avg Loss: 77.5686
2025-03-18 06:42:53 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2600 | Avg Loss: 33.7380
2025-03-18 06:52:33 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2700 | Avg Loss: 47.3602
2025-03-18 07:02:14 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2800 | Avg Loss: 49.4234
2025-03-18 07:12:02 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2900 | Avg Loss: 52.8042
2025-03-18 07:21:41 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3000 | Avg Loss: 38.4878
2025-03-18 07:31:18 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3100 | Avg Loss: 40.2493
2025-03-18 07:41:13 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3200 | Avg Loss: 56.8362
2025-03-18 07:50:55 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3300 | Avg Loss: 66.8023
2025-03-18 08:00:30 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3400 | Avg Loss: 92.0449
2025-03-18 08:10:12 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3500 | Avg Loss: 58.0209
2025-03-18 08:20:09 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3600 | Avg Loss: 65.9567
2025-03-18 08:29:48 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3700 | Avg Loss: 36.9712
2025-03-18 08:39:31 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3800 | Avg Loss: 51.2571
2025-03-18 08:49:28 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3900 | Avg Loss: 64.0146
2025-03-18 08:59:04 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4000 | Avg Loss: 57.3879
2025-03-18 09:08:41 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4100 | Avg Loss: 55.2836
2025-03-18 09:18:20 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4200 | Avg Loss: 54.1619
2025-03-18 09:28:15 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4300 | Avg Loss: 38.7133
2025-03-18 09:38:01 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4400 | Avg Loss: 33.4324
2025-03-18 09:47:43 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4500 | Avg Loss: 33.0967
2025-03-18 09:57:40 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4600 | Avg Loss: 71.9773
2025-03-18 10:07:21 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4700 | Avg Loss: 51.4032
2025-03-18 10:17:10 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4800 | Avg Loss: 51.1463
2025-03-18 10:27:07 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4900 | Avg Loss: 66.1633
2025-03-18 10:36:44 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5000 | Avg Loss: 48.8394
2025-03-18 10:46:28 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5100 | Avg Loss: 57.7208
2025-03-18 10:56:07 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5200 | Avg Loss: 62.0558

--- 2025-03-19 02:03:07 ---
2025-03-19 02:13:19 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 74.5730
2025-03-19 02:25:02 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 83.8378
2025-03-19 02:35:03 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 81.5079
2025-03-19 02:45:07 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 400 | Avg Loss: 57.4726
2025-03-19 02:55:52 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 500 | Avg Loss: 77.2571
2025-03-19 03:06:15 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 600 | Avg Loss: 59.9685
2025-03-19 03:16:05 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 700 | Avg Loss: 55.0320
2025-03-19 03:26:00 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 800 | Avg Loss: 67.0601
2025-03-19 03:35:56 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 900 | Avg Loss: 38.5078
2025-03-19 03:45:43 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1000 | Avg Loss: 30.0756
2025-03-19 03:55:32 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1100 | Avg Loss: 31.6567
2025-03-19 04:05:30 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1200 | Avg Loss: 37.8531
2025-03-19 04:15:13 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1300 | Avg Loss: 69.1231
2025-03-19 04:24:53 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1400 | Avg Loss: 43.1881
2025-03-19 04:34:38 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1500 | Avg Loss: 38.1132
2025-03-19 04:44:35 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1600 | Avg Loss: 43.4695
2025-03-19 04:54:17 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1700 | Avg Loss: 27.0129
2025-03-19 05:03:57 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1800 | Avg Loss: 29.5796
2025-03-19 05:13:57 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1900 | Avg Loss: 28.1929
2025-03-19 05:23:43 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2000 | Avg Loss: 30.5807
2025-03-19 05:33:25 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2100 | Avg Loss: 33.3245
2025-03-19 05:43:18 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2200 | Avg Loss: 43.6292
2025-03-19 05:53:15 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2300 | Avg Loss: 37.8051
2025-03-19 06:03:01 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2400 | Avg Loss: 39.3094
2025-03-19 06:12:43 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2500 | Avg Loss: 34.3984
2025-03-19 06:22:45 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2600 | Avg Loss: 33.2379
2025-03-19 06:32:30 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2700 | Avg Loss: 38.8905
2025-03-19 06:42:13 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2800 | Avg Loss: 31.2069
2025-03-19 06:52:13 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2900 | Avg Loss: 32.0529
2025-03-19 07:01:54 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3000 | Avg Loss: 23.3435
2025-03-19 07:11:44 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3100 | Avg Loss: 28.1499
2025-03-19 07:21:24 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3200 | Avg Loss: 28.1517
2025-03-19 07:31:28 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3300 | Avg Loss: 25.8394
2025-03-19 07:41:11 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3400 | Avg Loss: 27.2244
2025-03-19 07:50:55 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3500 | Avg Loss: 31.7479
2025-03-19 08:01:06 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3600 | Avg Loss: 22.4900
2025-03-19 08:10:48 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3700 | Avg Loss: 44.1103
2025-03-19 08:20:37 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3800 | Avg Loss: 49.0557
2025-03-19 08:31:03 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3900 | Avg Loss: 49.7291
2025-03-19 08:40:57 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4000 | Avg Loss: 46.4622
2025-03-19 08:50:42 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4100 | Avg Loss: 28.0462
2025-03-19 09:05:14 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4200 | Avg Loss: 33.3911
2025-03-19 09:14:54 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4300 | Avg Loss: 55.1869
2025-03-19 09:24:45 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4400 | Avg Loss: 29.8771
2025-03-19 09:35:01 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4500 | Avg Loss: 36.6915
2025-03-19 09:44:45 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4600 | Avg Loss: 30.9141
2025-03-19 09:54:36 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4700 | Avg Loss: 32.3652
2025-03-19 10:04:22 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4800 | Avg Loss: 21.0885
2025-03-19 10:15:13 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4900 | Avg Loss: 23.3824
2025-03-19 10:26:09 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5000 | Avg Loss: 43.1567
2025-03-19 10:36:00 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5100 | Avg Loss: 32.7820
2025-03-19 10:46:04 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5200 | Avg Loss: 24.8372
2025-03-19 10:55:47 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5300 | Avg Loss: 46.7594
2025-03-19 11:05:40 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5400 | Avg Loss: 42.2772
2025-03-19 11:15:53 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5500 | Avg Loss: 33.6713
2025-03-19 11:25:44 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5600 | Avg Loss: 26.1423
2025-03-19 11:35:36 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5700 | Avg Loss: 35.1191
2025-03-19 11:45:19 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5800 | Avg Loss: 22.5238
2025-03-19 11:55:29 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5900 | Avg Loss: 31.9580
2025-03-19 12:05:21 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6000 | Avg Loss: 26.9007
2025-03-19 12:15:04 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6100 | Avg Loss: 20.4065
2025-03-19 12:25:07 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6200 | Avg Loss: 20.2842
2025-03-19 12:34:48 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6300 | Avg Loss: 39.1758
2025-03-19 12:44:34 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6400 | Avg Loss: 20.5317

--- 2025-03-19 18:20:41 ---
2025-03-19 18:31:30 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 25.0672
2025-03-19 18:41:54 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 28.1405
2025-03-19 18:52:36 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 21.7400
2025-03-19 19:03:30 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 400 | Avg Loss: 25.9293
2025-03-19 19:14:02 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 500 | Avg Loss: 26.5720
2025-03-19 19:24:27 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 600 | Avg Loss: 22.8456
2025-03-19 19:35:27 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 700 | Avg Loss: 21.2141
2025-03-19 19:45:30 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 800 | Avg Loss: 20.9408
2025-03-19 19:56:02 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 900 | Avg Loss: 15.4001
2025-03-19 20:06:32 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1000 | Avg Loss: 24.6943
2025-03-19 20:17:01 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1100 | Avg Loss: 36.8573
2025-03-19 20:27:05 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1200 | Avg Loss: 28.6266
2025-03-19 20:37:35 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1300 | Avg Loss: 26.8032
2025-03-19 20:48:08 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1400 | Avg Loss: 28.1143
2025-03-19 20:58:20 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1500 | Avg Loss: 30.7547
2025-03-19 21:08:53 | Context: [[11, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1600 | Avg Loss: 32.3800

--- 2025-03-19 21:16:24 ---
2025-03-19 21:26:53 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 34.4316
2025-03-19 21:37:08 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 63.9691
2025-03-19 21:47:12 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 45.6076
2025-03-19 21:57:10 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 400 | Avg Loss: 46.0532
2025-03-19 22:07:17 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 500 | Avg Loss: 66.5735
2025-03-19 22:17:19 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 600 | Avg Loss: 41.6630
2025-03-19 22:27:20 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 700 | Avg Loss: 40.9412
2025-03-19 22:37:20 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 800 | Avg Loss: 50.1892
2025-03-19 22:47:50 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 900 | Avg Loss: 138.7861
2025-03-19 22:57:58 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1000 | Avg Loss: 125.5280
2025-03-19 23:08:28 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1100 | Avg Loss: 96.5232
2025-03-19 23:19:07 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1200 | Avg Loss: 95.7480
2025-03-19 23:29:39 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1300 | Avg Loss: 38.6874
2025-03-19 23:40:09 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1400 | Avg Loss: 70.2842
2025-03-19 23:50:31 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1500 | Avg Loss: 42.5463
2025-03-20 00:00:32 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1600 | Avg Loss: 73.9961
2025-03-20 00:10:44 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1700 | Avg Loss: 71.5795
2025-03-20 00:20:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1800 | Avg Loss: 47.4253
2025-03-20 00:30:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1900 | Avg Loss: 42.0408
2025-03-20 00:41:01 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2000 | Avg Loss: 61.5672
2025-03-20 00:51:16 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2100 | Avg Loss: 35.5857
2025-03-20 01:01:16 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2200 | Avg Loss: 40.3563
2025-03-20 01:11:22 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2300 | Avg Loss: 52.6408
2025-03-20 01:21:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2400 | Avg Loss: 103.8111
2025-03-20 01:31:58 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2500 | Avg Loss: 64.3269
2025-03-20 01:42:06 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2600 | Avg Loss: 72.5676
2025-03-20 01:52:14 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2700 | Avg Loss: 50.3425
2025-03-20 02:02:16 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2800 | Avg Loss: 46.4722
2025-03-20 02:12:11 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2900 | Avg Loss: 43.6143
2025-03-20 02:22:11 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3000 | Avg Loss: 59.9505
2025-03-20 02:32:18 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3100 | Avg Loss: 69.9928
2025-03-20 02:42:28 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3200 | Avg Loss: 110.4778
2025-03-20 02:52:30 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3300 | Avg Loss: 59.9074
2025-03-20 03:02:36 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3400 | Avg Loss: 69.6411
2025-03-20 03:12:43 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3500 | Avg Loss: 47.4202
2025-03-20 03:22:42 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3600 | Avg Loss: 47.3478
2025-03-20 03:32:42 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3700 | Avg Loss: 69.3206
2025-03-20 03:42:55 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3800 | Avg Loss: 45.9319
2025-03-20 03:52:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3900 | Avg Loss: 52.5073
2025-03-20 04:02:53 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4000 | Avg Loss: 42.5424
2025-03-20 04:13:02 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4100 | Avg Loss: 52.9361
2025-03-20 04:23:02 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4200 | Avg Loss: 89.7111
2025-03-20 04:33:02 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4300 | Avg Loss: 61.8416
2025-03-20 04:43:07 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4400 | Avg Loss: 60.4145
2025-03-20 04:53:13 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4500 | Avg Loss: 62.6083
2025-03-20 05:03:12 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4600 | Avg Loss: 30.2933
2025-03-20 05:13:20 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4700 | Avg Loss: 53.6502
2025-03-20 05:23:30 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4800 | Avg Loss: 84.8726
2025-03-20 05:33:29 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4900 | Avg Loss: 57.6585
2025-03-20 05:43:25 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5000 | Avg Loss: 53.1780
2025-03-20 05:53:50 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5100 | Avg Loss: 63.3396
2025-03-20 06:03:49 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5200 | Avg Loss: 39.8110
2025-03-20 06:13:50 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5300 | Avg Loss: 72.8728
2025-03-20 06:23:58 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5400 | Avg Loss: 43.4957
2025-03-20 06:33:58 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5500 | Avg Loss: 27.1155
2025-03-20 06:44:05 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5600 | Avg Loss: 41.3919
2025-03-20 06:54:18 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5700 | Avg Loss: 32.0334
2025-03-20 07:04:30 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5800 | Avg Loss: 35.8307
2025-03-20 07:14:37 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5900 | Avg Loss: 24.1026
2025-03-20 07:24:46 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6000 | Avg Loss: 31.2008
2025-03-20 07:34:56 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6100 | Avg Loss: 30.7753
2025-03-20 07:44:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6200 | Avg Loss: 34.8577
2025-03-20 07:54:59 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6300 | Avg Loss: 37.4313
2025-03-20 08:05:08 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6400 | Avg Loss: 24.6944
2025-03-20 08:15:12 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6500 | Avg Loss: 22.7344
2025-03-20 08:25:11 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6600 | Avg Loss: 23.8727
2025-03-20 08:35:29 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6700 | Avg Loss: 27.8779
2025-03-20 08:45:37 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6800 | Avg Loss: 24.7429
2025-03-20 08:55:41 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6900 | Avg Loss: 38.8952
2025-03-20 09:05:56 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7000 | Avg Loss: 42.6019
2025-03-20 09:16:02 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7100 | Avg Loss: 27.2461
2025-03-20 09:26:01 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7200 | Avg Loss: 39.1873
2025-03-20 09:36:06 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7300 | Avg Loss: 34.5512
2025-03-20 09:46:12 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7400 | Avg Loss: 29.8121
2025-03-20 09:56:19 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7500 | Avg Loss: 30.1615
2025-03-20 10:06:23 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7600 | Avg Loss: 22.9941
2025-03-20 10:16:31 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7700 | Avg Loss: 30.8956
2025-03-20 10:26:31 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7800 | Avg Loss: 29.0036
2025-03-20 10:36:36 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7900 | Avg Loss: 32.1875
2025-03-20 10:46:47 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8000 | Avg Loss: 30.5606
2025-03-20 10:56:45 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8100 | Avg Loss: 43.1274
2025-03-20 11:07:28 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8200 | Avg Loss: 37.3616
2025-03-20 11:17:48 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8300 | Avg Loss: 26.8993
2025-03-20 11:27:50 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8400 | Avg Loss: 31.5578
2025-03-20 11:38:37 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8500 | Avg Loss: 25.1077
2025-03-20 11:49:01 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8600 | Avg Loss: 24.3554
2025-03-20 11:59:07 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8700 | Avg Loss: 24.5216
2025-03-20 12:09:09 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8800 | Avg Loss: 37.8477
2025-03-20 12:19:17 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8900 | Avg Loss: 25.0435
2025-03-20 12:29:15 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9000 | Avg Loss: 16.9889
2025-03-20 12:39:28 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9100 | Avg Loss: 17.6504
2025-03-20 12:49:46 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9200 | Avg Loss: 23.1947
2025-03-20 12:59:57 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9300 | Avg Loss: 21.9184
2025-03-20 13:10:15 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9400 | Avg Loss: 23.9878
2025-03-20 13:20:53 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9500 | Avg Loss: 17.8185
2025-03-20 13:31:06 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9600 | Avg Loss: 27.8706
2025-03-20 13:41:19 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9700 | Avg Loss: 50.9230
2025-03-20 13:51:32 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9800 | Avg Loss: 26.7889
2025-03-20 14:01:40 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9900 | Avg Loss: 31.3636
2025-03-20 14:12:25 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10000 | Avg Loss: 22.4836
2025-03-20 14:23:26 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10100 | Avg Loss: 32.9215
2025-03-20 14:33:28 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10200 | Avg Loss: 25.4975
2025-03-20 14:43:45 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10300 | Avg Loss: 43.5477
2025-03-20 14:53:40 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10400 | Avg Loss: 24.2899
2025-03-20 15:03:58 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10500 | Avg Loss: 53.5532
2025-03-20 15:14:09 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10600 | Avg Loss: 26.2210
2025-03-20 15:24:24 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10700 | Avg Loss: 21.6207
2025-03-20 15:36:50 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10800 | Avg Loss: 22.5226
2025-03-20 15:51:17 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10900 | Avg Loss: 34.3061
2025-03-20 16:01:30 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11000 | Avg Loss: 43.5743
2025-03-20 16:12:23 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11100 | Avg Loss: 17.5609
2025-03-20 16:22:18 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11200 | Avg Loss: 22.9376
2025-03-20 16:32:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11300 | Avg Loss: 19.6813
2025-03-20 16:42:39 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11400 | Avg Loss: 22.4909
2025-03-20 16:53:11 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11500 | Avg Loss: 28.1832
2025-03-20 17:03:11 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11600 | Avg Loss: 34.4208
2025-03-20 17:13:15 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11700 | Avg Loss: 24.4247
2025-03-20 17:23:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11800 | Avg Loss: 17.3533
2025-03-20 17:33:45 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11900 | Avg Loss: 40.7150
2025-03-20 17:43:48 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12000 | Avg Loss: 28.3397
2025-03-20 17:53:48 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12100 | Avg Loss: 20.5123
2025-03-20 18:05:27 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12200 | Avg Loss: 22.3222
2025-03-20 18:16:52 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12300 | Avg Loss: 30.7943
2025-03-20 18:26:55 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12400 | Avg Loss: 36.8427
2025-03-20 18:37:50 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12500 | Avg Loss: 31.2685
2025-03-20 18:48:23 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12600 | Avg Loss: 18.4582
2025-03-20 18:58:24 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12700 | Avg Loss: 12.8927
2025-03-20 19:08:25 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12800 | Avg Loss: 28.1975
2025-03-20 19:19:12 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12900 | Avg Loss: 20.3522
2025-03-20 19:29:39 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13000 | Avg Loss: 34.1980
2025-03-20 19:40:02 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13100 | Avg Loss: 40.5166
2025-03-20 19:50:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13200 | Avg Loss: 17.8355
2025-03-20 20:00:48 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13300 | Avg Loss: 31.3274
2025-03-20 20:10:57 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13400 | Avg Loss: 20.5631
2025-03-20 20:21:15 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13500 | Avg Loss: 22.9026
2025-03-20 20:31:21 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13600 | Avg Loss: 12.1932
2025-03-20 20:41:20 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13700 | Avg Loss: 15.7096
2025-03-20 20:51:18 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13800 | Avg Loss: 18.8938
2025-03-20 21:01:49 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 13900 | Avg Loss: 18.4053
2025-03-20 21:11:56 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14000 | Avg Loss: 18.9796
2025-03-20 21:22:42 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14100 | Avg Loss: 14.3286
2025-03-20 21:33:22 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14200 | Avg Loss: 21.2563
2025-03-20 21:43:18 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14300 | Avg Loss: 23.5806
2025-03-20 21:53:17 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14400 | Avg Loss: 18.3090
2025-03-20 22:04:03 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14500 | Avg Loss: 12.2258
2025-03-20 22:14:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14600 | Avg Loss: 15.3066
2025-03-20 22:24:56 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14700 | Avg Loss: 28.0160
2025-03-20 22:35:19 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14800 | Avg Loss: 12.7965
2025-03-20 22:46:16 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 14900 | Avg Loss: 15.9247
2025-03-20 22:56:24 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15000 | Avg Loss: 16.4883
2025-03-20 23:06:42 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15100 | Avg Loss: 23.5458
2025-03-20 23:16:47 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15200 | Avg Loss: 24.8593
2025-03-20 23:26:53 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15300 | Avg Loss: 19.4509
2025-03-20 23:37:21 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15400 | Avg Loss: 15.0845
2025-03-20 23:47:17 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15500 | Avg Loss: 17.2614
2025-03-20 23:57:15 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15600 | Avg Loss: 17.4067
2025-03-21 00:07:46 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15700 | Avg Loss: 17.0702
2025-03-21 00:17:56 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15800 | Avg Loss: 20.5585
2025-03-21 00:28:10 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 15900 | Avg Loss: 11.0969
2025-03-21 00:38:52 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16000 | Avg Loss: 30.9558
2025-03-21 00:49:05 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16100 | Avg Loss: 31.3157
2025-03-21 00:59:16 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16200 | Avg Loss: 19.1202
2025-03-21 01:09:27 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16300 | Avg Loss: 26.5424
2025-03-21 01:19:52 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16400 | Avg Loss: 31.2308
2025-03-21 01:29:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16500 | Avg Loss: 25.6780
2025-03-21 01:40:00 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16600 | Avg Loss: 19.7135
2025-03-21 01:50:22 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16700 | Avg Loss: 9.5259
2025-03-21 02:00:33 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16800 | Avg Loss: 19.4574
2025-03-21 02:10:41 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 16900 | Avg Loss: 19.0130
2025-03-21 02:21:11 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17000 | Avg Loss: 38.2173
2025-03-21 02:31:11 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17100 | Avg Loss: 19.5197
2025-03-21 02:41:14 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17200 | Avg Loss: 17.5993
2025-03-21 02:51:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17300 | Avg Loss: 28.7814
2025-03-21 03:01:37 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17400 | Avg Loss: 28.8105
2025-03-21 03:11:53 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17500 | Avg Loss: 34.3090
2025-03-21 03:22:07 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17600 | Avg Loss: 52.8057
2025-03-21 03:32:25 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17700 | Avg Loss: 27.9136
2025-03-21 03:42:16 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17800 | Avg Loss: 40.3137
2025-03-21 03:52:20 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 17900 | Avg Loss: 32.1854
2025-03-21 04:02:29 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 18000 | Avg Loss: 26.7132
2025-03-21 04:12:32 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 18100 | Avg Loss: 66.7907
2025-03-21 04:22:33 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 18200 | Avg Loss: 23.7316
2025-03-21 04:33:03 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 18300 | Avg Loss: 26.8902
2025-03-21 04:43:33 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 18400 | Avg Loss: 39.9468
2025-03-21 04:53:46 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 18500 | Avg Loss: 17.4035
2025-03-21 05:03:55 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 18600 | Avg Loss: 30.3594

--- 2025-03-21 05:06:44 ---
2025-03-21 05:15:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 18700 | Avg Loss: 36.7542

--- 2025-03-23 13:00:33 ---
2025-03-23 13:19:33 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 16.5437
2025-03-23 13:38:01 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 21.9825
2025-03-23 13:56:38 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 25.7907
2025-03-23 14:15:15 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 400 | Avg Loss: 19.0949
2025-03-23 14:33:55 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 500 | Avg Loss: 23.3306
2025-03-23 14:52:28 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 600 | Avg Loss: 22.6316
2025-03-23 15:11:08 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 700 | Avg Loss: 19.2779
2025-03-23 15:29:45 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 800 | Avg Loss: 26.2002
2025-03-23 15:48:37 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 900 | Avg Loss: 14.4576

--- 2025-03-23 17:03:35 ---
2025-03-23 17:31:20 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 15.3141
2025-03-23 17:59:39 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 32.6344
2025-03-23 18:28:12 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 10.6133

--- 2025-03-23 18:44:45 ---
2025-03-23 19:13:12 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 17.5438

--- 2025-03-23 19:35:41 ---
2025-03-23 20:02:47 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 28.3127
2025-03-23 20:30:33 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 20.0003

--- 2025-03-23 21:17:03 ---
2025-03-23 21:45:14 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 10.9648 | Logits: -163.18  -24.56 | Final window weightings: [0.00587413 0.14887016 0.17523532 0.2198666  0.07272907 0.20799461 0.1617088  0.15256743 0.11650197]
2025-03-23 22:13:33 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 23.0835 | Logits: -15.62  19.50 | Final window weightings: [0.00655421 0.1495658  0.17678  0.22076482 0.0722838  0.20723154 0.16101162 0.15127319 0.11561571]
2025-03-23 22:42:17 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 12.3316 | Logits: -34.31  0.96 | Final window weightings: [0.00666942 0.14930415 0.17641148 0.22099352 0.0722403  0.20719309 0.1611619  0.15139756 0.11562002]
2025-03-23 23:10:57 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 400 | Avg Loss: 18.2188 | Logits: -42.68  2.17 | Final window weightings: [0.00661527 0.14927009 0.17626318 0.22100404 0.07197295 0.20717058 0.16127537 0.15143034 0.11580253]
2025-03-23 23:39:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 500 | Avg Loss: 10.6145 | Logits: 4.82  46.12 | Final window weightings: [0.006633  0.14915444 0.17620441 0.22090004 0.07207057 0.20718867 0.16138071 0.15158318 0.11570615]
2025-03-24 00:09:43 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 600 | Avg Loss: 20.1885 | Logits: -50.55  -12.71 | Final window weightings: [0.00657379 0.14905062 0.17598234 0.22037457 0.07177985 0.20738687 0.1616183  0.15165867 0.11617613]
2025-03-24 00:39:02 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 700 | Avg Loss: 11.0634 | Logits: -15.91  3.39 | Final window weightings: [0.00657205 0.14895661 0.17562053 0.2201791  0.07159465 0.20755899 0.16171005 0.15180418 0.11645833]
2025-03-24 01:07:26 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 800 | Avg Loss: 10.2943 | Logits: -50.11  31.40 | Final window weightings: [0.0064173  0.14893477 0.17563896 0.22027327 0.07131657 0.20749064 0.16176474 0.15180829 0.11662783]
2025-03-24 01:35:22 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 900 | Avg Loss: 15.7544 | Logits: -21.06  3.12 | Final window weightings: [0.00630573 0.14893726 0.17552228 0.22014157 0.07118671 0.20745444 0.16184847 0.15185407 0.11687316]

--- 2025-03-24 05:07:52 ---
2025-03-24 05:35:40 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 100 | Avg Loss: 12.9493 | Logits: -106.07  -19.45 | Final window weightings: [0.00494963 0.14900702 0.17699447 0.2223612  0.06927894 0.20980012 0.16087162 0.1514838  0.11550581]
2025-03-24 06:03:29 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 200 | Avg Loss: 13.0966 | Logits: -5.68  58.43 | Final window weightings: [0.00522512 0.14924592 0.1775434  0.22319347 0.06738267 0.20997916 0.16094035 0.15118611 0.11511109]
2025-03-24 06:31:17 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 300 | Avg Loss: 8.7511 | Logits: 5.89  50.46 | Final window weightings: [0.0052803  0.14927864 0.17747933 0.2228686  0.06709627 0.2096932 0.16117363 0.15150845 0.11517749]
2025-03-24 06:59:10 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 400 | Avg Loss: 11.5747 | Logits: -91.93  -17.81 | Final window weightings: [0.00550215 0.14917432 0.1774434  0.2224288  0.06707455 0.20958178 0.16122088 0.15156813 0.11536548]
2025-03-24 07:27:01 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 500 | Avg Loss: 10.8790 | Logits: 28.91  74.19 | Final window weightings: [0.00582176 0.14901234 0.17776902 0.22255467 0.06738392 0.20919782 0.16106209 0.15144938 0.11516104]
2025-03-24 07:54:56 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 600 | Avg Loss: 10.7517 | Logits: -47.05  -18.48 | Final window weightings: [0.00558324 0.14885712 0.17759168 0.22249423 0.06732014 0.20918304 0.16135924 0.15175034 0.11520683]
2025-03-24 08:23:26 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 700 | Avg Loss: 8.3344 | Logits: -12.28  4.43 | Final window weightings: [0.00540004 0.14848757 0.17760338 0.22235382 0.06712542 0.20950358 0.16142665 0.15193397 0.11538067]
2025-03-24 08:53:03 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 800 | Avg Loss: 9.5944 | Logits: -47.17  -18.71 | Final window weightings: [0.00563629 0.14845547 0.17728794 0.222187  0.06708297 0.20926487 0.16155359 0.15214092 0.11543243]
2025-03-24 09:20:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 900 | Avg Loss: 9.0983 | Logits: -43.53  -2.05 | Final window weightings: [0.00541956 0.14843175 0.17732553 0.22214897 0.06704576 0.20915796 0.16153376 0.15223886 0.1156981 ]
2025-03-24 09:48:14 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1000 | Avg Loss: 9.5921 | Logits: -5.18  30.39 | Final window weightings: [0.00527667 0.14834726 0.17709954 0.22188371 0.06689363 0.20937636 0.1616922  0.15246983 0.11578511]
2025-03-24 10:15:48 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1100 | Avg Loss: 12.6317 | Logits: -26.76  -4.12 | Final window weightings: [0.00573369 0.14698994 0.17659226 0.22158341 0.06648912 0.2095013 0.16237715 0.1532057  0.11589809]
2025-03-24 10:43:24 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1200 | Avg Loss: 10.7711 | Logits: -25.48  3.23 | Final window weightings: [0.00595559 0.14671563 0.17637165 0.22164203 0.06633106 0.20960602 0.16237931 0.15327735 0.11594409]
2025-03-24 11:10:58 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1300 | Avg Loss: 10.8326 | Logits: -15.96  3.45 | Final window weightings: [0.00595885 0.14640693 0.17631467 0.22140217 0.06602602 0.20964046 0.16240148 0.15353352 0.11629452]
2025-03-24 11:38:40 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1400 | Avg Loss: 10.7330 | Logits: -31.68  -10.76 | Final window weightings: [0.00647327 0.14595598 0.17652941 0.22117326 0.06589054 0.20945443 0.16220674 0.1536711  0.11636444]
2025-03-24 12:06:33 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1500 | Avg Loss: 10.4466 | Logits: -5.37  27.82 | Final window weightings: [0.00631188 0.14577918 0.17646037 0.22102553 0.06552102 0.20958206 0.16238423 0.15388328 0.11655954]
2025-03-24 12:33:57 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1600 | Avg Loss: 14.8318 | Logits: -30.89  -12.29 | Final window weightings: [0.00589246 0.14532304 0.17634441 0.22086628 0.06486853 0.20987616 0.16290836 0.1541532  0.11694197]
2025-03-24 13:01:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1700 | Avg Loss: 10.5461 | Logits: -28.87  -9.57 | Final window weightings: [0.00624915 0.14494626 0.17631853 0.22116205 0.06489747 0.20979246 0.16279066 0.15408134 0.11684591]
2025-03-24 13:29:38 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1800 | Avg Loss: 12.9000 | Logits: -6.07  38.80 | Final window weightings: [0.00615174 0.14487687 0.17604277 0.2210085  0.06475566 0.20952621 0.1628888  0.15451029 0.11709997]
2025-03-24 13:57:22 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 1900 | Avg Loss: 12.1511 | Logits: 14.81  40.78 | Final window weightings: [0.00603081 0.14459541 0.17594288 0.22056697 0.06443141 0.20955077 0.16319175 0.15482643 0.11737849]
2025-03-24 14:25:14 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2000 | Avg Loss: 9.2805 | Logits: -19.82  20.65 | Final window weightings: [0.00483644 0.14447205 0.17561541 0.22050051 0.06355041 0.20992297 0.16369244 0.15577094 0.11785332]
2025-03-24 14:52:43 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2100 | Avg Loss: 11.0758 | Logits: -30.08  -4.84 | Final window weightings: [0.00578743 0.1439369  0.17599227 0.2205188  0.06412432 0.20922267 0.1634599  0.15553181 0.1175718 ]
2025-03-24 15:19:48 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2200 | Avg Loss: 10.2527 | Logits: 5.98  27.49 | Final window weightings: [0.0064269  0.14359145 0.17605746 0.22024408 0.06367751 0.20894618 0.1634887  0.15556192 0.11772013]
2025-03-24 15:47:12 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2300 | Avg Loss: 10.4990 | Logits: -29.15  -6.31 | Final window weightings: [0.00657891 0.14321126 0.1760207  0.21980882 0.0632432  0.20881484 0.16363071 0.15597092 0.11802988]
2025-03-24 16:14:37 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2400 | Avg Loss: 9.4123 | Logits: -3.14  28.44 | Final window weightings: [0.00687988 0.14247261 0.17582177 0.21986932 0.06344847 0.20871913 0.16372228 0.1559659  0.11828379]
2025-03-24 16:42:23 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2500 | Avg Loss: 11.0236 | Logits: -33.40  -11.09 | Final window weightings: [0.00648752 0.14048338 0.17574845 0.22011702 0.06111161 0.20986797 0.16390795 0.15776387 0.11876359]
2025-03-24 17:09:59 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2600 | Avg Loss: 9.0649 | Logits: -24.15  -2.05 | Final window weightings: [0.00727702 0.14015983 0.17501895 0.21981537 0.06019729 0.20897599 0.16473901 0.15824585 0.11914085]
2025-03-24 17:37:03 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2700 | Avg Loss: 13.2261 | Logits: -62.22  -23.75 | Final window weightings: [0.00660001 0.13985543 0.174954  0.21954142 0.05960995 0.20911239 0.16522922 0.15879412 0.11952617]
2025-03-24 18:04:35 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2800 | Avg Loss: 10.5417 | Logits: -20.56  164.36 | Final window weightings: [0.00788399 0.1380275  0.17412846 0.21984062 0.05824669 0.21024707 0.16540182 0.15989402 0.11867736]
2025-03-24 18:32:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 2900 | Avg Loss: 20.6796 | Logits: 3.92  63.57 | Final window weightings: [0.00565739 0.13387935 0.17387754 0.22181302 0.05477094 0.21106842 0.16675584 0.16321938 0.11991505]
2025-03-24 19:00:02 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3000 | Avg Loss: 8.8579 | Logits: -15.87  14.35 | Final window weightings: [0.00614127 0.13422105 0.17375761 0.22230951 0.05572227 0.2110369 0.16639964 0.16248846 0.11906446]
2025-03-24 19:27:26 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3100 | Avg Loss: 7.6188 | Logits: -11.21  18.78 | Final window weightings: [0.00647465 0.13561225 0.17356066 0.2208422  0.05523247 0.21110287 0.16651434 0.16222557 0.11908773]
2025-03-24 19:55:26 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3200 | Avg Loss: 13.1708 | Logits: 3.45  27.16 | Final window weightings: [0.00973931 0.13521175 0.17302614 0.2210411  0.05629706 0.21063419 0.16549626 0.16061696 0.11819266]
2025-03-24 20:23:20 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3300 | Avg Loss: 15.5535 | Logits: -25.42  2.34 | Final window weightings: [0.01055973 0.13491802 0.17284933 0.22103226 0.05549216 0.21211572 0.16509385 0.15971725 0.11798126]
2025-03-24 20:50:56 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3400 | Avg Loss: 11.0667 | Logits: -16.65  -2.97 | Final window weightings: [0.01234172 0.13429305 0.17208633 0.22117293 0.0558504  0.21245843 0.1648248  0.15881507 0.11760382]
2025-03-24 21:18:57 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3500 | Avg Loss: 10.7364 | Logits: -13.34  4.20 | Final window weightings: [0.01147406 0.1341796  0.17350566 0.22120564 0.05605736 0.21255104 0.16494106 0.15834893 0.11736597]
2025-03-24 21:48:24 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3600 | Avg Loss: 14.5428 | Logits: -19.18  11.75 | Final window weightings: [0.01206201 0.13408776 0.17383602 0.2215594  0.05513679 0.2116733 0.16528313 0.15832597 0.11724098]
2025-03-24 22:16:16 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3700 | Avg Loss: 9.7337 | Logits: -18.48  -3.42 | Final window weightings: [0.01283602 0.13350657 0.1730774  0.22112791 0.05482052 0.21189146 0.16534351 0.15848835 0.1176182 ]
2025-03-24 22:43:47 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3800 | Avg Loss: 9.1695 | Logits: -14.85  1.31 | Final window weightings: [0.01408791 0.13402651 0.17197017 0.21989384 0.05496934 0.21159202 0.16535772 0.15871434 0.11760189]
2025-03-24 23:11:36 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 3900 | Avg Loss: 10.7923 | Logits: 6.84  44.70 | Final window weightings: [0.01484532 0.13328801 0.17147411 0.22001706 0.05540409 0.21168838 0.16543777 0.15847747 0.11741423]
2025-03-24 23:39:42 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4000 | Avg Loss: 10.1661 | Logits: 0.68  40.75 | Final window weightings: [0.01508978 0.13255174 0.17058079 0.21897869 0.05430212 0.21315287 0.16579753 0.15877317 0.11805566]
2025-03-25 00:06:55 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4100 | Avg Loss: 10.0265 | Logits: 51.89  104.18 | Final window weightings: [0.01649912 0.13088648 0.16993725 0.2185896  0.05545798 0.21305266 0.1659658  0.15858272 0.11814095]
2025-03-25 00:34:39 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4200 | Avg Loss: 7.3296 | Logits: -3.32  26.57 | Final window weightings: [0.01742988 0.13243783 0.16915467 0.21874651 0.0564451  0.2139072 0.16488975 0.15742743 0.11693929]
2025-03-25 01:02:00 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4300 | Avg Loss: 12.6786 | Logits: 19.03  51.12 | Final window weightings: [0.01825218 0.13198866 0.16904639 0.21760303 0.05515643 0.21380398 0.16529088 0.15782498 0.11751318]
2025-03-25 01:29:55 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4400 | Avg Loss: 9.2704 | Logits: -11.68  3.09 | Final window weightings: [0.01739395 0.13197447 0.17003392 0.21813735 0.05525665 0.21321528 0.16531613 0.15764871 0.11755234]
2025-03-25 01:57:17 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4500 | Avg Loss: 14.6985 | Logits: 19.13  69.78 | Final window weightings: [0.01742866 0.13189049 0.16986886 0.21805626 0.05479066 0.21348523 0.16540061 0.15770558 0.11752968]
2025-03-25 02:25:23 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4600 | Avg Loss: 12.4149 | Logits: 48.47  117.60 | Final window weightings: [0.01804278 0.13197976 0.16931728 0.21764223 0.05368863 0.21410592 0.16528848 0.15784986 0.11752775]
2025-03-25 02:52:51 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4700 | Avg Loss: 12.7815 | Logits: -124.41  -53.34 | Final window weightings: [0.01989812 0.13331439 0.17124565 0.21873306 0.05407597 0.211849 0.16360167 0.15693673 0.11581335]
2025-03-25 03:20:49 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4800 | Avg Loss: 13.6691 | Logits: -44.35  -12.57 | Final window weightings: [0.01867038 0.13427055 0.17143154 0.21786858 0.05246955 0.2134603 0.16357103 0.15673277 0.116374  ]
2025-03-25 03:48:22 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 4900 | Avg Loss: 7.5641 | Logits: -33.72  -11.56 | Final window weightings: [0.0178702  0.13547277 0.17129757 0.21797656 0.04999761 0.2147865 0.16351123 0.15687089 0.11645892]
2025-03-25 04:16:09 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5000 | Avg Loss: 11.0078 | Logits: -17.23  3.66 | Final window weightings: [0.01798254 0.13487493 0.16934887 0.21599756 0.05031135 0.21415715 0.1648607  0.15820913 0.11790013]
2025-03-25 04:43:49 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5100 | Avg Loss: 7.0591 | Logits: -38.53  -7.71 | Final window weightings: [0.01834144 0.13348097 0.17003231 0.21776186 0.05054204 0.2136667 0.16526812 0.15761194 0.11698633]
2025-03-25 05:13:02 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5200 | Avg Loss: 12.3182 | Logits: -27.80  -6.36 | Final window weightings: [0.01920215 0.13324274 0.1689531  0.21745989 0.05124654 0.21493703 0.16475339 0.15704387 0.11674781]
2025-03-25 05:41:23 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5300 | Avg Loss: 9.5470 | Logits: -15.57  9.45 | Final window weightings: [0.01862888 0.13150004 0.16681731 0.21748312 0.05182705 0.21453789 0.16632277 0.15842327 0.11771989]
2025-03-25 06:09:06 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5400 | Avg Loss: 10.4183 | Logits: 9.49  54.29 | Final window weightings: [0.01850999 0.13135108 0.16682354 0.21735124 0.05237475 0.21410908 0.16652629 0.15854092 0.11757613]
2025-03-25 06:36:45 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5500 | Avg Loss: 7.9966 | Logits: -17.76  2.81 | Final window weightings: [0.01856544 0.13052154 0.16693069 0.21691169 0.05081785 0.2137905 0.1671234  0.15940802 0.11841439]
2025-03-25 07:04:39 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5600 | Avg Loss: 11.4106 | Logits: -41.18  -17.65 | Final window weightings: [0.01936679 0.13014454 0.16748522 0.21624328 0.05000663 0.21301012 0.16738968 0.15972446 0.11855024]
2025-03-25 07:32:08 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5700 | Avg Loss: 14.9608 | Logits: 27.05  67.51 | Final window weightings: [0.01975158 0.13024306 0.16746184 0.21609116 0.05105998 0.21301721 0.16712105 0.1591758  0.11801489]
2025-03-25 07:59:42 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5800 | Avg Loss: 11.0740 | Logits: 17.04  55.81 | Final window weightings: [0.01908126 0.13041325 0.16818753 0.21657848 0.0511294  0.21361265 0.16667101 0.15867883 0.11756518]
2025-03-25 08:27:29 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 5900 | Avg Loss: 10.2134 | Logits: 9.20  29.25 | Final window weightings: [0.02058807 0.12911141 0.16716862 0.21598609 0.05025114 0.21391265 0.16747575 0.15895104 0.11773187]
2025-03-25 08:54:37 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6000 | Avg Loss: 9.5198 | Logits: -22.63  -5.79 | Final window weightings: [0.02083565 0.12947638 0.16537148 0.21453753 0.0486146  0.21529475 0.16834056 0.16010961 0.11760522]
2025-03-25 09:22:03 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6100 | Avg Loss: 10.0877 | Logits: 24.81  61.50 | Final window weightings: [0.02049829 0.12766819 0.16673033 0.21661344 0.04829605 0.21566786 0.16794465 0.1595724  0.11708583]
2025-03-25 09:49:35 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6200 | Avg Loss: 8.3640 | Logits: 23.12  52.52 | Final window weightings: [0.02004001 0.12738255 0.16635655 0.21696146 0.04861305 0.21592511 0.16828062 0.15962784 0.11679341]
2025-03-25 10:17:08 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6300 | Avg Loss: 8.3524 | Logits: 57.25  107.47 | Final window weightings: [0.02078349 0.12636594 0.16612813 0.21621193 0.04901408 0.21486507 0.16861328 0.16022755 0.1174235 ]
2025-03-25 10:44:49 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6400 | Avg Loss: 8.5259 | Logits: 50.52  92.72 | Final window weightings: [0.02128525 0.12673208 0.16647512 0.21776797 0.04892052 0.21563803 0.16751255 0.1589395  0.1164773 ]
2025-03-25 11:12:28 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6500 | Avg Loss: 12.1188 | Logits: 163.32  260.18 | Final window weightings: [0.02083689 0.12640348 0.1672359  0.21915157 0.04865778 0.21748863 0.1665597  0.15781866 0.11560674]
2025-03-25 11:39:55 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6600 | Avg Loss: 9.5570 | Logits: 135.16  217.91 | Final window weightings: [0.01956959 0.12511812 0.16745238 0.21940841 0.04860525 0.21911311 0.1666991  0.15780522 0.1156883 ]
2025-03-25 12:07:57 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6700 | Avg Loss: 12.8199 | Logits: 49.54  90.97 | Final window weightings: [0.0179908  0.12429766 0.16948631 0.22158831 0.04607037 0.21978892 0.16662918 0.15743734 0.11517122]
2025-03-25 12:41:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6800 | Avg Loss: 11.1529 | Logits: -21.17  19.52 | Final window weightings: [0.01943152 0.12450645 0.16975358 0.22164072 0.04649362 0.22106758 0.16548216 0.15594672 0.11410721]
2025-03-25 13:09:42 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 6900 | Avg Loss: 13.3489 | Logits: -51.54  -22.28 | Final window weightings: [0.01761474 0.12310176 0.17056349 0.22390544 0.04601138 0.22208625 0.16498081 0.15598631 0.11424444]
2025-03-25 13:37:53 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7000 | Avg Loss: 9.6633 | Logits: -0.50  48.82 | Final window weightings: [0.01888239 0.12468173 0.16995761 0.22234687 0.04670163 0.22162628 0.16436382 0.15572272 0.11393756]
2025-03-25 14:06:53 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7100 | Avg Loss: 10.2959 | Logits: 66.86  125.42 | Final window weightings: [0.01980533 0.12528601 0.16959167 0.22236738 0.04648554 0.22230397 0.16390468 0.15518525 0.11313889]
2025-03-25 14:35:46 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7200 | Avg Loss: 11.2848 | Logits: -48.57  -27.44 | Final window weightings: [0.01936133 0.12497711 0.16951573 0.2221986  0.04664313 0.22220697 0.16444688 0.15556617 0.11294936]
2025-03-25 15:05:28 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7300 | Avg Loss: 8.5841 | Logits: 41.02  91.73 | Final window weightings: [0.02007658 0.12587258 0.16851512 0.22169898 0.04421192 0.22447793 0.16337936 0.1549985  0.11430217]
2025-03-25 15:34:41 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7400 | Avg Loss: 9.7185 | Logits: 21.04  40.35 | Final window weightings: [0.01935653 0.1264806  0.16748214 0.22180769 0.04310851 0.22412829 0.16400601 0.15578595 0.11488612]
2025-03-25 16:04:06 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7500 | Avg Loss: 8.3792 | Logits: -16.90  0.44 | Final window weightings: [0.02031678 0.12492399 0.16655967 0.22175796 0.04338891 0.22371858 0.16433941 0.1561791  0.11541856]
2025-03-25 16:31:43 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7600 | Avg Loss: 8.6044 | Logits: 13.37  36.99 | Final window weightings: [0.02018015 0.1238954  0.16531308 0.22116268 0.04373907 0.22397996 0.16512433 0.15682298 0.11610188]
2025-03-25 16:59:42 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7700 | Avg Loss: 7.2500 | Logits: -10.42  8.42 | Final window weightings: [0.02101192 0.12364554 0.16510083 0.22089668 0.04416907 0.22408728 0.16491581 0.15649603 0.11590965]
2025-03-25 17:27:57 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7800 | Avg Loss: 8.1762 | Logits: 37.29  79.99 | Final window weightings: [0.02174191 0.12563196 0.16411798 0.2190876  0.04560159 0.22302695 0.16405639 0.15640385 0.11636906]
2025-03-25 17:59:04 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 7900 | Avg Loss: 8.5606 | Logits: -6.52  16.27 | Final window weightings: [0.0230951  0.1291712  0.16158906 0.21985528 0.04426656 0.22688472 0.16254891 0.15501268 0.11397584]
2025-03-25 18:26:53 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8000 | Avg Loss: 15.3556 | Logits: -55.30  -27.24 | Final window weightings: [0.02276116 0.12688075 0.16045992 0.2176553  0.04292718 0.22715071 0.16441229 0.15785778 0.11537844]
2025-03-25 18:54:31 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8100 | Avg Loss: 8.7567 | Logits: 20.63  50.40 | Final window weightings: [0.02196141 0.12523639 0.1608018  0.21755643 0.04179292 0.22721902 0.16565092 0.15885691 0.11604608]
2025-03-25 19:22:03 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8200 | Avg Loss: 7.5604 | Logits: 6.60  48.29 | Final window weightings: [0.02260135 0.12487897 0.16086988 0.21742453 0.04168187 0.2273715 0.16537566 0.15868501 0.11616146]
2025-03-25 19:50:09 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8300 | Avg Loss: 20.3099 | Logits: 14.65  56.85 | Final window weightings: [0.02205881 0.12420697 0.16043447 0.21703053 0.04190263 0.22735971 0.16568473 0.15946728 0.11650664]
2025-03-25 20:20:09 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8400 | Avg Loss: 9.9527 | Logits: -22.54  -0.46 | Final window weightings: [0.02245457 0.12337974 0.1594697  0.21545394 0.04191326 0.22801198 0.16634415 0.16006318 0.11719061]
2025-03-25 20:47:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8500 | Avg Loss: 9.1087 | Logits: 15.81  35.83 | Final window weightings: [0.0220091  0.1225162  0.15913846 0.21564664 0.04251892 0.22820728 0.16670601 0.16032784 0.11708808]
2025-03-25 21:17:45 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8600 | Avg Loss: 7.9355 | Logits: 61.53  107.10 | Final window weightings: [0.02166955 0.1231464  0.15837945 0.2156051  0.04249575 0.22785652 0.16698878 0.16081011 0.11696795]
2025-03-25 21:47:43 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8700 | Avg Loss: 9.4357 | Logits: 73.52  142.30 | Final window weightings: [0.02075324 0.12310403 0.15858886 0.21469112 0.04203273 0.22849892 0.16734931 0.16142428 0.11737416]
2025-03-25 22:17:03 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8800 | Avg Loss: 11.9385 | Logits: 7.71  27.27 | Final window weightings: [0.02051181 0.12166499 0.15815529 0.21364743 0.04271847 0.22861837 0.16808887 0.16236101 0.11771425]
2025-03-25 22:45:24 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 8900 | Avg Loss: 8.4566 | Logits: 41.54  80.75 | Final window weightings: [0.02255909 0.12084724 0.15629585 0.21292356 0.04302134 0.2295446 0.16843474 0.16199537 0.11760169]
2025-03-25 23:13:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9000 | Avg Loss: 6.7024 | Logits: 72.33  140.66 | Final window weightings: [0.02037896 0.12237759 0.15663782 0.21379174 0.04064461 0.22990902 0.16932495 0.16242652 0.117511  ]
2025-03-25 23:41:44 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9100 | Avg Loss: 15.6405 | Logits: 90.38  183.10 | Final window weightings: [0.0211249  0.12149818 0.15491492 0.21335608 0.04234368 0.23178098 0.16973853 0.16183555 0.11653557]
2025-03-26 00:11:06 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9200 | Avg Loss: 6.5878 | Logits: 46.33  77.97 | Final window weightings: [0.02056613 0.12047966 0.15547562 0.21388333 0.04235339 0.23228206 0.16946256 0.16178809 0.11678809]
2025-03-26 00:41:13 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9300 | Avg Loss: 9.6728 | Logits: -28.09  8.81 | Final window weightings: [0.02014415 0.12000974 0.15517087 0.21363427 0.04204731 0.23276113 0.16969617 0.16216122 0.11722779]
2025-03-26 01:08:59 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9400 | Avg Loss: 15.9481 | Logits: -25.94  2.55 | Final window weightings: [0.02051856 0.12111211 0.15488547 0.2134819  0.04278392 0.23313892 0.16877216 0.16137391 0.11689272]
2025-03-26 02:10:30 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9500 | Avg Loss: 9.2281 | Logits: 1.26  19.01 | Final window weightings: [0.02026496 0.12134769 0.15501764 0.21332584 0.04380129 0.2335693 0.16866387 0.16089591 0.11625034]
2025-03-26 02:37:59 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9600 | Avg Loss: 9.1799 | Logits: 8.48  42.06 | Final window weightings: [0.02093812 0.12032385 0.15476215 0.2130473  0.04244785 0.2333913 0.16887811 0.1614692  0.11722943]
2025-03-26 03:05:35 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9700 | Avg Loss: 11.2719 | Logits: -34.70  8.69 | Final window weightings: [0.02081035 0.12141047 0.1550233  0.21280618 0.04217781 0.23476347 0.16818775 0.16079207 0.11660037]
2025-03-26 03:32:56 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9800 | Avg Loss: 10.6549 | Logits: -15.69  10.48 | Final window weightings: [0.02175313 0.12284254 0.15526247 0.21453944 0.04168855 0.23400865 0.16715147 0.15953887 0.115761  ]
2025-03-26 04:00:54 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 9900 | Avg Loss: 8.3309 | Logits: -20.89  -0.62 | Final window weightings: [0.02106403 0.12108846 0.1535614  0.2149163  0.04088674 0.23525114 0.16853707 0.1603974  0.11632244]
2025-03-26 04:28:47 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10000 | Avg Loss: 10.8874 | Logits: 114.30  201.49 | Final window weightings: [0.01904754 0.12063803 0.15410027 0.21558584 0.04043563 0.23588851 0.16867524 0.16084778 0.11668556]
2025-03-26 04:56:26 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10100 | Avg Loss: 8.4926 | Logits: 6.04  20.90 | Final window weightings: [0.01944394 0.12106415 0.15476604 0.21266249 0.03975808 0.23398386 0.169203  0.16196874 0.11824637]
2025-03-26 05:24:03 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10200 | Avg Loss: 11.5810 | Logits: 8.75  35.04 | Final window weightings: [0.01972977 0.12136421 0.15489155 0.21331298 0.04016557 0.23470663 0.1685736  0.16109762 0.11740027]
2025-03-26 05:51:41 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10300 | Avg Loss: 8.8507 | Logits: -60.88  -26.39 | Final window weightings: [0.0204074  0.12094049 0.15422854 0.21348  0.04078568 0.23560022 0.16849121 0.16067575 0.11661433]
2025-03-26 06:20:00 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10400 | Avg Loss: 10.0438 | Logits: 55.52  110.33 | Final window weightings: [0.02022762 0.12095972 0.15418857 0.21354671 0.04116189 0.23545955 0.16837256 0.16045083 0.11675984]
2025-03-26 06:48:21 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10500 | Avg Loss: 9.2879 | Logits: -22.24  -0.03 | Final window weightings: [0.02120101 0.11983514 0.15340853 0.21529903 0.04126958 0.23879652 0.1676905  0.15875271 0.11513522]
2025-03-26 07:16:01 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10600 | Avg Loss: 12.9117 | Logits: -14.36  10.00 | Final window weightings: [0.02139034 0.11734685 0.1520612  0.21280316 0.04174947 0.24008553 0.16883887 0.16004956 0.11644959]
2025-03-26 07:43:55 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10700 | Avg Loss: 8.2966 | Logits: 35.91  70.02 | Final window weightings: [0.02072732 0.11569271 0.15130414 0.21338563 0.0404265  0.24010882 0.16992398 0.16101539 0.11751445]
2025-03-26 08:11:38 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10800 | Avg Loss: 17.1828 | Logits: 20.17  71.98 | Final window weightings: [0.01950016 0.11443239 0.15327205 0.2147931  0.03835889 0.24084416 0.1700448  0.16092852 0.11750741]
2025-03-26 08:38:52 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 10900 | Avg Loss: 13.3543 | Logits: -13.30  7.48 | Final window weightings: [0.02049246 0.11288711 0.15175453 0.21337052 0.03886846 0.24210775 0.17101316 0.16132481 0.11730487]
2025-03-26 09:06:27 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11000 | Avg Loss: 20.4954 | Logits: 85.01  159.10 | Final window weightings: [0.02365566 0.11652993 0.15000135 0.2123697  0.04205632 0.24177188 0.16906324 0.15952468 0.11585938]
2025-03-26 09:34:04 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11100 | Avg Loss: 16.4486 | Logits: -29.20  9.84 | Final window weightings: [0.02332599 0.11679117 0.150125  0.21265362 0.04175107 0.24191926 0.16901688 0.15942684 0.11567265]
2025-03-26 10:01:29 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11200 | Avg Loss: 18.3105 | Logits: -18.71  -2.50 | Final window weightings: [0.02259662 0.11702024 0.15041701 0.21325986 0.04137743 0.24222131 0.16895103 0.15930502 0.11539926]
2025-03-26 10:29:00 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11300 | Avg Loss: 18.7326 | Logits: 25.14  79.07 | Final window weightings: [0.02197311 0.11771759 0.15079139 0.21394442 0.04106788 0.24234986 0.16871257 0.15901515 0.11493979]
2025-03-26 10:58:09 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11400 | Avg Loss: 15.2125 | Logits: -111.82  -64.70 | Final window weightings: [0.02055537 0.11877762 0.15138334 0.2150911  0.04014872 0.24308468 0.16864921 0.1585153  0.11403875]
2025-03-26 11:29:15 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11500 | Avg Loss: 11.5475 | Logits: -31.76  -11.67 | Final window weightings: [0.02048994 0.11949384 0.15099262 0.21500085 0.04023829 0.24345621 0.1684085  0.15841809 0.11376777]
2025-03-26 11:57:28 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11600 | Avg Loss: 14.4656 | Logits: -18.98  15.72 | Final window weightings: [0.01973701 0.12053443 0.15199447 0.21638772 0.03980969 0.24390465 0.16763346 0.15762815 0.11287028]
2025-03-26 12:24:34 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11700 | Avg Loss: 12.3399 | Logits: 130.46  211.47 | Final window weightings: [0.0184149  0.12044443 0.1520831  0.2164439  0.0395849  0.24425086 0.1678209  0.15811235 0.11311231]
2025-03-26 12:52:10 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11800 | Avg Loss: 12.1513 | Logits: -10.36  3.17 | Final window weightings: [0.01817788 0.12103242 0.15195003 0.21653037 0.03947277 0.2444115 0.16775265 0.15808631 0.11275319]
2025-03-26 13:19:57 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 11900 | Avg Loss: 9.8309 | Logits: 42.74  74.22 | Final window weightings: [0.01794266 0.12129614 0.15200529 0.21666487 0.03938338 0.24464622 0.16773136 0.1578974  0.11257683]
2025-03-26 13:47:32 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12000 | Avg Loss: 7.5786 | Logits: 27.04  56.06 | Final window weightings: [0.01801527 0.12141614 0.15213706 0.21698931 0.03914692 0.2448139 0.16757481 0.15769455 0.11226413]
2025-03-26 14:15:00 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12100 | Avg Loss: 7.1251 | Logits: -117.80  -62.34 | Final window weightings: [0.01764212 0.12166888 0.15229374 0.21730384 0.03882438 0.24462886 0.16780367 0.15703112 0.11261447]
2025-03-26 14:42:36 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12200 | Avg Loss: 9.6281 | Logits: 33.50  76.53 | Final window weightings: [0.01766462 0.1215683  0.15230522 0.21771528 0.03891687 0.24481748 0.1676669  0.15678516 0.11244831]
2025-03-26 15:10:29 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12300 | Avg Loss: 10.8975 | Logits: -9.39  32.57 | Final window weightings: [0.01721051 0.12183673 0.15253416 0.21854544 0.03893403 0.24551295 0.16745941 0.15636574 0.11172005]
2025-03-26 15:43:46 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12400 | Avg Loss: 10.4617 | Logits: 67.20  118.66 | Final window weightings: [0.01738808 0.12119286 0.15231894 0.21852618 0.03904399 0.24583757 0.1676819  0.15644303 0.11162882]
2025-03-26 16:13:53 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00035 | Step 12500 | Avg Loss: 9.1461 | Logits: -110.39  -60.93 | Final window weightings: [0.01666521 0.1207692  0.15299517 0.21915205 0.03888588 0.24601793 0.16776773 0.15626413 0.11154452]

--- 2025-03-27 07:49:31 ---
2025-03-27 08:25:02 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 100 | Avg Loss: 3.7851 | Logits: -43.18  -9.90 | Final window weightings: [0.01703957 0.12157364 0.15360762 0.22110426 0.03869126 0.24619924 0.16627839 0.15600613 0.11002252]
2025-03-27 08:56:41 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 200 | Avg Loss: 7.8457 | Logits: -31.80  -5.48 | Final window weightings: [0.01721016 0.12205879 0.15464917 0.22157586 0.03836494 0.24605542 0.16560867 0.15514083 0.10991556]
2025-03-27 09:27:14 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 300 | Avg Loss: 7.5951 | Logits: 71.84  125.46 | Final window weightings: [0.01775662 0.12162658 0.1548303  0.22152168 0.03944374 0.24486136 0.16532989 0.15523276 0.10983761]
2025-03-27 10:00:32 | Context: [[7, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 400 | Avg Loss: 11.7850 | Logits: -110.21  -66.54 | Final window weightings: [0.01738247 0.12188373 0.15475906 0.22065882 0.03914401 0.24464878 0.16558959 0.15566988 0.11042231]

--- 2025-03-27 10:05:17 ---
2025-03-27 10:33:42 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 100 | Avg Loss: 1.9614 | Logits: 3.93  100.07 | Final window weightings: [0.01838856 0.12363973 0.15480222 0.2219391  0.0396826  0.24492231 0.16453256 0.15471448 0.10818404]
2025-03-27 11:00:41 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 200 | Avg Loss: 10.5806 | Logits: 171.20  265.62 | Final window weightings: [0.01734864 0.12541656 0.15545973 0.22246175 0.04081814 0.24513632 0.16408162 0.15395878 0.10634134]
2025-03-27 11:28:24 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 300 | Avg Loss: 7.5618 | Logits: -61.28  -35.13 | Final window weightings: [0.01672122 0.12581636 0.15631421 0.22308958 0.03978517 0.24451517 0.16415168 0.15410171 0.10679127]
2025-03-27 11:56:58 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 400 | Avg Loss: 8.0699 | Logits: 20.53  54.21 | Final window weightings: [0.01680636 0.1257278  0.1563085  0.22285093 0.03912503 0.2444036 0.16443548 0.15452357 0.10703298]
2025-03-27 12:24:37 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 500 | Avg Loss: 7.6976 | Logits: 128.03  200.25 | Final window weightings: [0.01702816 0.12586932 0.15629855 0.2226191  0.03876344 0.2439648 0.16430582 0.15478267 0.10754492]
2025-03-27 12:53:04 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 600 | Avg Loss: 9.3670 | Logits: -149.01  -107.17 | Final window weightings: [0.01688531 0.12584482 0.15621574 0.22239344 0.03879936 0.24391706 0.164506  0.15497497 0.10752306]
2025-03-27 13:20:15 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 700 | Avg Loss: 7.9712 | Logits: 78.90  123.24 | Final window weightings: [0.01733606 0.12581828 0.1563631  0.22229749 0.03815397 0.24383645 0.16442136 0.15523684 0.10757069]
2025-03-27 13:48:07 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 800 | Avg Loss: 7.3299 | Logits: 40.19  74.40 | Final window weightings: [0.01724619 0.12576015 0.15614189 0.22207075 0.03823848 0.24397959 0.16456474 0.15529269 0.10763105]
2025-03-27 14:16:16 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 900 | Avg Loss: 7.3954 | Logits: 5.43  20.02 | Final window weightings: [0.01735254 0.12573522 0.15550615 0.22210924 0.03787319 0.24421465 0.16486573 0.15556742 0.10762317]
2025-03-27 14:43:35 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1000 | Avg Loss: 8.5864 | Logits: -32.88  -14.87 | Final window weightings: [0.01713004 0.12537362 0.1550852  0.22194645 0.0381391  0.2443801 0.16505663 0.1558761  0.10762533]
2025-03-27 15:10:33 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1100 | Avg Loss: 7.3129 | Logits: 14.80  34.71 | Final window weightings: [0.01667595 0.12486175 0.15493652 0.22155936 0.03821493 0.24419865 0.16563535 0.15626231 0.10801849]
2025-03-27 15:37:51 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1200 | Avg Loss: 9.0067 | Logits: -1.11  11.04 | Final window weightings: [0.01661159 0.12477809 0.15434016 0.22160245 0.03839499 0.24446872 0.16585772 0.15618004 0.10797517]
2025-03-27 16:05:36 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1300 | Avg Loss: 7.2668 | Logits: -1.98  11.97 | Final window weightings: [0.01655856 0.12468781 0.15427458 0.22101662 0.03827026 0.24438778 0.16585779 0.1566497  0.1083578 ]
2025-03-27 16:33:20 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1400 | Avg Loss: 10.4495 | Logits: 65.71  107.73 | Final window weightings: [0.01654989 0.12419973 0.15389797 0.2202386  0.03830874 0.24459244 0.16575845 0.15742809 0.10876579]
2025-03-27 17:01:49 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1500 | Avg Loss: 8.9700 | Logits: -75.16  -46.16 | Final window weightings: [0.01663767 0.12389252 0.1540507  0.21957436 0.03810178 0.24476065 0.16608651 0.15746291 0.10898494]
2025-03-27 17:30:34 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1600 | Avg Loss: 7.4794 | Logits: -8.10  4.87 | Final window weightings: [0.017749  0.12320154 0.15465435 0.22075318 0.036657  0.24414437 0.16614382 0.15762448 0.10865296]
2025-03-27 17:58:54 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1700 | Avg Loss: 10.0687 | Logits: -13.79  -1.75 | Final window weightings: [0.0173782  0.12288608 0.15468244 0.22114748 0.03668107 0.24425744 0.16630536 0.15751754 0.10862052]
2025-03-27 21:20:17 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1800 | Avg Loss: 9.6381 | Logits: 59.51  99.43 | Final window weightings: [0.01831913 0.12368919 0.15530334 0.22184171 0.03586224 0.2447023 0.16546781 0.15673307 0.1078319 ]
2025-03-27 22:15:59 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 1900 | Avg Loss: 8.6177 | Logits: -35.36  -13.89 | Final window weightings: [0.01741873 0.12368888 0.15540326 0.22157237 0.03614571 0.24427743 0.16573745 0.15707241 0.1082757 ]
2025-03-27 22:45:19 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2000 | Avg Loss: 7.6943 | Logits: 4.50  25.51 | Final window weightings: [0.01710222 0.123751  0.15479906 0.221383  0.03622629 0.24429882 0.16611889 0.15746701 0.10829013]
2025-03-27 23:16:14 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2100 | Avg Loss: 6.8635 | Logits: 6.96  26.46 | Final window weightings: [0.01698986 0.12361613 0.15468031 0.2219289  0.0360251  0.24436931 0.16622324 0.15748075 0.10807949]
2025-03-27 23:44:13 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2200 | Avg Loss: 11.3781 | Logits: 93.71  153.79 | Final window weightings: [0.01667044 0.12370603 0.15407144 0.22234865 0.03641952 0.24475725 0.16598138 0.15723763 0.10802796]
2025-03-28 00:12:42 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2300 | Avg Loss: 12.1372 | Logits: 32.23  62.04 | Final window weightings: [0.01641105 0.12452389 0.15327767 0.22056872 0.03596021 0.24569334 0.16681126 0.15750678 0.1082724 ]
2025-03-28 00:41:02 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2400 | Avg Loss: 8.6103 | Logits: 24.31  51.02 | Final window weightings: [0.01617615 0.12456991 0.15284479 0.22075959 0.03591835 0.24547777 0.16669975 0.15790689 0.10854993]
2025-03-28 01:09:34 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2500 | Avg Loss: 9.9191 | Logits: 19.53  39.46 | Final window weightings: [0.01656844 0.12391794 0.15233664 0.22089481 0.03575204 0.24573073 0.16700646 0.1579053  0.10852009]
2025-03-28 01:38:12 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2600 | Avg Loss: 7.8281 | Logits: -2.47  20.99 | Final window weightings: [0.01650704 0.12404018 0.15251541 0.2205198  0.03579921 0.24561004 0.16708227 0.15788488 0.10856371]
2025-03-28 02:06:42 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2700 | Avg Loss: 8.9279 | Logits: 64.92  107.34 | Final window weightings: [0.01597654 0.12408389 0.15317136 0.22081189 0.03555727 0.2454041 0.16651629 0.1580619  0.1088804 ]
2025-03-28 02:35:12 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2800 | Avg Loss: 6.6188 | Logits: 173.91  434.17 | Final window weightings: [0.01441318 0.1262403  0.15131707 0.22150908 0.03611684 0.25130436 0.16518298 0.15551573 0.10759293]
2025-03-28 03:03:16 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 2900 | Avg Loss: 8.3415 | Logits: -9.29  22.79 | Final window weightings: [0.01415753 0.12531549 0.14861849 0.21981879 0.03940894 0.2527751 0.16538511 0.1553577  0.10738289]
2025-03-28 03:32:35 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3000 | Avg Loss: 5.5691 | Logits: -16.82  1.15 | Final window weightings: [0.01422854 0.12495214 0.14851278 0.2198783  0.03952118 0.25336027 0.16542543 0.15524125 0.10704996]
2025-03-28 04:00:48 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3100 | Avg Loss: 5.1710 | Logits: 9.92  48.46 | Final window weightings: [0.01441754 0.12577775 0.148762  0.22013831 0.03961266 0.25308388 0.16514046 0.15465693 0.10658387]
2025-03-28 04:28:47 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3200 | Avg Loss: 9.3027 | Logits: -29.39  -4.93 | Final window weightings: [0.01377274 0.12478375 0.14844997 0.22039732 0.03915681 0.25436598 0.16572459 0.15483245 0.10664781]
2025-03-28 04:57:02 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3300 | Avg Loss: 9.7766 | Logits: -89.45  -51.12 | Final window weightings: [0.01331156 0.12507808 0.14890072 0.22059375 0.03875939 0.25487068 0.16578479 0.15432446 0.10656476]
2025-03-28 05:25:18 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3400 | Avg Loss: 7.7378 | Logits: 50.08  78.42 | Final window weightings: [0.01279525 0.12543282 0.14819203 0.21965894 0.03838679 0.25843987 0.16559732 0.15399514 0.10594618]
2025-03-28 05:53:16 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3500 | Avg Loss: 9.9523 | Logits: -82.10  -52.96 | Final window weightings: [0.01377084 0.12577085 0.14883476 0.22153062 0.03822618 0.25828275 0.16412233 0.15231624 0.1057371 ]
2025-03-28 06:20:30 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3600 | Avg Loss: 7.6255 | Logits: 16.93  56.75 | Final window weightings: [0.01373327 0.12517188 0.14909334 0.22312155 0.03795035 0.25950047 0.16393791 0.15177025 0.10466573]
2025-03-28 06:48:31 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3700 | Avg Loss: 7.9477 | Logits: -3.17  35.18 | Final window weightings: [0.01362895 0.12436094 0.14933011 0.22337025 0.0373015  0.26020765 0.16434155 0.15200564 0.10446302]
2025-03-28 07:17:02 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3800 | Avg Loss: 8.1104 | Logits: 45.81  83.96 | Final window weightings: [0.01354501 0.12441272 0.14825034 0.22445413 0.0369232  0.26068532 0.16435239 0.1521891  0.10428157]
2025-03-28 07:45:00 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 3900 | Avg Loss: 7.9417 | Logits: 55.18  89.43 | Final window weightings: [0.01367119 0.12537508 0.14751326 0.22511043 0.03639079 0.2591077 0.1636656  0.15275374 0.10515615]
2025-03-28 08:12:56 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4000 | Avg Loss: 7.2426 | Logits: 12.28  37.81 | Final window weightings: [0.01431473 0.12525085 0.14813322 0.22595406 0.03552525 0.25967228 0.16337202 0.1520411  0.10468622]
2025-03-28 08:41:13 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4100 | Avg Loss: 7.0464 | Logits: 113.56  153.97 | Final window weightings: [0.01460678 0.12484846 0.14794315 0.22585028 0.03513085 0.25945008 0.16370004 0.15234849 0.10486867]
2025-03-28 09:10:19 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4200 | Avg Loss: 8.3996 | Logits: 119.45  176.68 | Final window weightings: [0.01576725 0.12405173 0.14712414 0.22666565 0.03324478 0.26113036 0.16473626 0.15264055 0.10378277]
2025-03-28 09:38:00 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4300 | Avg Loss: 6.8816 | Logits: 11.43  24.96 | Final window weightings: [0.01551862 0.12364016 0.14656053 0.2250853  0.03427094 0.260913 0.16502091 0.15309562 0.1045619 ]
2025-03-28 10:05:30 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4400 | Avg Loss: 8.2135 | Logits: 26.67  52.53 | Final window weightings: [0.0154594  0.1238473  0.14703608 0.22461383 0.03397049 0.2609375 0.16497773 0.15311779 0.1046562 ]
2025-03-28 10:32:40 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4500 | Avg Loss: 7.4447 | Logits: -3.14  27.16 | Final window weightings: [0.01590561 0.12345352 0.14710797 0.2242531  0.03429858 0.26071185 0.16484807 0.15311085 0.10469087]
2025-03-28 10:59:45 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4600 | Avg Loss: 12.5431 | Logits: 64.92  128.55 | Final window weightings: [0.01670258 0.12414172 0.14731139 0.22437699 0.03487337 0.26081917 0.16391475 0.15237978 0.10391171]
2025-03-28 11:26:42 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4700 | Avg Loss: 5.7681 | Logits: -6.11  13.85 | Final window weightings: [0.0170874  0.12461257 0.14862129 0.2249594  0.03348991 0.2614303 0.16354132 0.15157582 0.10347617]
2025-03-28 11:53:20 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4800 | Avg Loss: 14.6248 | Logits: 92.29  137.55 | Final window weightings: [0.0170518  0.12473956 0.14908716 0.22481173 0.03312164 0.26344594 0.16376166 0.15065166 0.10257804]
2025-03-28 12:20:21 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 4900 | Avg Loss: 5.7908 | Logits: 14.12  42.46 | Final window weightings: [0.01630195 0.12426443 0.14870197 0.22292314 0.03269534 0.26393804 0.16492411 0.15138261 0.10382048]
2025-03-28 12:47:24 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5000 | Avg Loss: 8.9533 | Logits: 45.91  79.85 | Final window weightings: [0.01538715 0.12462419 0.149892  0.22397947 0.03189968 0.26447147 0.16463389 0.15106182 0.1033374 ]
2025-03-28 13:14:29 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5100 | Avg Loss: 5.3818 | Logits: -14.14  19.69 | Final window weightings: [0.01432726 0.12473816 0.15114072 0.22510746 0.03298998 0.2628738 0.16435933 0.15021817 0.10325654]
2025-03-28 13:41:49 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5200 | Avg Loss: 5.4944 | Logits: 9.65  35.82 | Final window weightings: [0.01242643 0.1244094  0.15222938 0.22658478 0.03216836 0.26322818 0.16465402 0.15006945 0.10344917]
2025-03-28 14:08:57 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5300 | Avg Loss: 11.5865 | Logits: 12.31  28.32 | Final window weightings: [0.01128861 0.12439307 0.15157647 0.22684139 0.03000941 0.26307485 0.16614121 0.15144679 0.10435073]
2025-03-28 14:36:12 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5400 | Avg Loss: 8.6129 | Logits: 14.81  70.80 | Final window weightings: [0.01125893 0.12471282 0.15133649 0.226831  0.02984467 0.26286674 0.16622868 0.15158632 0.10439626]
2025-03-28 15:03:14 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5500 | Avg Loss: 7.0551 | Logits: -26.79  -3.34 | Final window weightings: [0.0114239  0.12551728 0.15156531 0.22718546 0.02960239 0.26229367 0.16565144 0.1514107  0.1044028 ]
2025-03-28 15:30:31 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5600 | Avg Loss: 6.5528 | Logits: 13.25  36.78 | Final window weightings: [0.01154209 0.12571001 0.15112992 0.22713184 0.02912449 0.2623767 0.16562827 0.15175784 0.1046338 ]
2025-03-28 15:57:40 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5700 | Avg Loss: 9.1733 | Logits: -2.03  15.65 | Final window weightings: [0.01090713 0.12570687 0.151142  0.22689812 0.02892451 0.2628289 0.16610059 0.15189189 0.10459976]
2025-03-28 16:25:56 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5800 | Avg Loss: 6.9271 | Logits: 71.15  115.52 | Final window weightings: [0.01169449 0.12684381 0.14979826 0.22692968 0.02822015 0.26342642 0.16623375 0.15201916 0.10404673]
2025-03-28 16:54:17 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 5900 | Avg Loss: 7.7419 | Logits: 144.29  203.75 | Final window weightings: [0.01187681 0.127104  0.14919613 0.22661616 0.02789052 0.26382563 0.16666028 0.152148  0.10388575]
2025-03-28 17:26:23 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 6000 | Avg Loss: 7.0186 | Logits: 75.00  113.99 | Final window weightings: [0.01175933 0.12641907 0.1481455  0.22600444 0.02760961 0.2637343 0.16793516 0.15295996 0.10428084]
2025-03-28 17:58:05 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 6100 | Avg Loss: 6.0174 | Logits: 20.38  39.98 | Final window weightings: [0.01097663 0.12580736 0.1488471  0.22619866 0.02804334 0.2650631 0.16747752 0.1524035  0.10412625]
2025-03-28 18:27:37 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 6200 | Avg Loss: 7.8320 | Logits: 53.40  85.44 | Final window weightings: [0.01045498 0.12601286 0.1482297  0.22602561 0.02789477 0.2646623 0.16819544 0.15298393 0.10427865]

--- 2025-03-28 18:52:37 ---
2025-03-28 19:21:12 | Context: [[14, 1, 2, 3, 7, 8, 13, 15, 18]] | LR: 0.00025 | Step 100 | Avg Loss: 11.6541 | Logits: 30.65  44.64 | Final window weightings: [0.0106069  0.12483592 0.14849278 0.22563545 0.02775624 0.2643423 0.16790587 0.15368627 0.10473551]

--- 2025-03-28 20:10:45 ---
2025-03-28 20:37:57 | Step 100 | LR: 0.00015 | Loss: 12.9315 | Logits: 1.45  4.63 | Weights: W8:0.21044,W3:0.18026,W13:0.13294,W15:0.12246,W2:0.11878,W1:0.09862,W18:0.08298,W7:0.02181,W14:0.00903
2023-03-28 21:06:04 | Step 200 | LR: 0.00015 | Loss: 12.1584 | Logits: 5.04  10.85 | Weights: W8:0.21016,W3:0.17971,W13:0.13294,W15:0.12236,W2:0.11926,W1:0.09840,W18:0.08338,W7:0.02180,W14:0.00933

--- 2025-03-28 21:24:52 ---
2025-03-28 21:54:10 | Step 100 | LR: 0.00015 | Loss: 8.9781 | Logits: 3.89  5.62 | Weights: W8:0.21015,W3:0.17889,W13:0.13335,W15:0.12289,W2:0.11848,W1:0.09752,W18:0.08444,W7:0.02265,W14:0.00907
2023-03-28 22:25:06 | Step 200 | LR: 0.00015 | Loss: 8.8890 | Logits: 6.28  9.67 | Weights: W8:0.21002,W3:0.17832,W13:0.13374,W15:0.12333,W2:0.11847,W1:0.09693,W18:0.08474,W7:0.02319,W14:0.00873
2023-03-28 22:51:49 | Step 300 | LR: 0.00015 | Loss: 8.0227 | Logits: 10.42  15.39 | Weights: W8:0.20987,W3:0.17813,W13:0.13393,W15:0.12329,W2:0.11844,W1:0.09684,W18:0.08467,W7:0.02391,W14:0.00843
2023-03-28 23:18:49 | Step 400 | LR: 0.00015 | Loss: 10.0940 | Logits: 14.35  21.22 | Weights: W8:0.20957,W3:0.17771,W13:0.13418,W15:0.12353,W2:0.11798,W1:0.09680,W18:0.08498,W7:0.02447,W14:0.00832
2023-03-28 23:50:39 | Step 500 | LR: 0.00015 | Loss: 7.7102 | Logits: 17.62  26.04 | Weights: W8:0.20916,W3:0.17759,W13:0.13386,W15:0.12385,W2:0.11757,W1:0.09666,W18:0.08567,W7:0.02454,W14:0.00866
2023-03-29 00:26:16 | Step 600 | LR: 0.00015 | Loss: 8.8799 | Logits: 21.25  31.21 | Weights: W8:0.20890,W3:0.17726,W13:0.13425,W15:0.12443,W2:0.11726,W1:0.09635,W18:0.08615,W7:0.02430,W14:0.00868
2023-03-29 00:58:46 | Step 700 | LR: 0.00015 | Loss: 7.7783 | Logits: 24.52  36.03 | Weights: W8:0.20868,W3:0.17704,W13:0.13424,W15:0.12422,W2:0.11741,W1:0.09623,W18:0.08628,W7:0.02476,W14:0.00875
2023-03-29 01:32:43 | Step 800 | LR: 0.00015 | Loss: 10.0374 | Logits: 27.84  41.08 | Weights: W8:0.20871,W3:0.17691,W13:0.13452,W15:0.12440,W2:0.11717,W1:0.09597,W18:0.08650,W7:0.02471,W14:0.00872
2023-03-29 02:05:31 | Step 900 | LR: 0.00015 | Loss: 9.3248 | Logits: 30.69  45.71 | Weights: W8:0.20894,W3:0.17629,W13:0.13507,W15:0.12491,W2:0.11649,W1:0.09585,W18:0.08663,W7:0.02443,W14:0.00903
2023-03-29 02:34:41 | Step 1000 | LR: 0.00015 | Loss: 8.6617 | Logits: 0.00  0.00 | Weights: W8:0.20928,W3:0.17625,W13:0.13500,W15:0.12496,W2:0.11644,W1:0.09540,W18:0.08662,W7:0.02453,W14:0.00917
2023-03-29 03:06:34 | Step 1100 | LR: 0.00015 | Loss: 8.5479 | Logits: 3.15  4.79 | Weights: W8:0.20928,W3:0.17660,W13:0.13486,W15:0.12471,W2:0.11619,W1:0.09532,W18:0.08659,W7:0.02481,W14:0.00932
2023-03-29 03:43:32 | Step 1200 | LR: 0.00015 | Loss: 8.1176 | Logits: 6.15  9.31 | Weights: W8:0.20963,W3:0.17729,W13:0.13500,W15:0.12491,W2:0.11539,W1:0.09496,W18:0.08654,W7:0.02500,W14:0.00892
2023-03-29 04:13:32 | Step 1300 | LR: 0.00015 | Loss: 8.7634 | Logits: 8.64  13.42 | Weights: W8:0.21062,W3:0.17675,W13:0.13541,W15:0.12525,W2:0.11437,W1:0.09444,W18:0.08677,W7:0.02467,W14:0.00938

--- 2025-03-29 04:59:04 ---
2025-03-29 05:26:28 | Step 100 | LR: 0.00015 | Loss: 10.8492 | Logits: 2.74  4.70 | Weights: W8:0.21005,W3:0.17591,W13:0.13611,W15:0.12611,W2:0.11398,W1:0.09426,W18:0.08725,W7:0.02464,W14:0.00939
2023-03-29 05:54:36 | Step 200 | LR: 0.00015 | Loss: 8.4265 | Logits: 6.16  9.71 | Weights: W8:0.20996,W3:0.17580,W13:0.13638,W15:0.12624,W2:0.11384,W1:0.09379,W18:0.08764,W7:0.02502,W14:0.00905
2023-03-29 06:22:46 | Step 300 | LR: 0.00015 | Loss: 7.7694 | Logits: 9.18  14.10 | Weights: W8:0.21009,W3:0.17573,W13:0.13654,W15:0.12626,W2:0.11344,W1:0.09370,W18:0.08780,W7:0.02457,W14:0.00959
2023-03-29 06:51:38 | Step 400 | LR: 0.00015 | Loss: 8.1550 | Logits: 11.67  18.14 | Weights: W8:0.20956,W3:0.17563,W13:0.13708,W15:0.12670,W2:0.11295,W1:0.09275,W18:0.08861,W7:0.02430,W14:0.01015
2023-03-29 07:21:27 | Step 500 | LR: 0.00015 | Loss: 8.1959 | Logits: 14.49  22.28 | Weights: W8:0.20947,W3:0.17567,W13:0.13724,W15:0.12677,W2:0.11293,W1:0.09275,W18:0.08878,W7:0.02432,W14:0.00980
2023-03-29 07:51:57 | Step 600 | LR: 0.00015 | Loss: 7.9797 | Logits: 16.76  25.91 | Weights: W8:0.20959,W3:0.17633,W13:0.13708,W15:0.12631,W2:0.11291,W1:0.09346,W18:0.08800,W7:0.02346,W14:0.01059
2023-03-29 08:22:53 | Step 700 | LR: 0.00015 | Loss: 9.0329 | Logits: 19.57  30.43 | Weights: W8:0.20963,W3:0.17632,W13:0.13752,W15:0.12683,W2:0.11211,W1:0.09330,W18:0.08840,W7:0.02348,W14:0.01013
2023-03-29 08:54:14 | Step 800 | LR: 0.00015 | Loss: 8.3931 | Logits: 22.00  34.34 | Weights: W8:0.20970,W3:0.17593,W13:0.13746,W15:0.12677,W2:0.11276,W1:0.09319,W18:0.08839,W7:0.02353,W14:0.01001
2023-03-29 09:24:59 | Step 900 | LR: 0.00015 | Loss: 8.7092 | Logits: 23.36  37.10 | Weights: W8:0.20968,W3:0.17571,W13:0.13751,W15:0.12687,W2:0.11269,W1:0.09305,W18:0.08853,W7:0.02344,W14:0.01026
2023-03-29 09:57:04 | Step 1000 | LR: 0.00015 | Loss: 7.3909 | Logits: 0.00  0.00 | Weights: W8:0.20938,W3:0.17518,W13:0.13793,W15:0.12747,W2:0.11183,W1:0.09285,W18:0.08913,W7:0.02338,W14:0.01058
2023-03-29 10:26:28 | Step 1100 | LR: 0.00015 | Loss: 7.8297 | Logits: 1.80  3.08 | Weights: W8:0.20913,W3:0.17504,W13:0.13804,W15:0.12772,W2:0.11157,W1:0.09310,W18:0.08939,W7:0.02316,W14:0.01061

--- 2025-03-29 10:50:47 --- im testing whether you can make better notes! ---
2025-03-29 10:59:40 | Step 1200 | LR: 0.00015 | Loss: 8.9879 | Logits: 3.65  6.43 | Weights: W8:0.20851,W3:0.17478,W13:0.13900,W15:0.12843,W2:0.11064,W1:0.09276,W18:0.08987,W7:0.02299,W14:0.01079

--- 2025-03-29 11:12:16 --- i am just testing if your tokenizer works! ---
2025-03-29 11:31:30 | Step 1300 | LR: 0.00015 | Loss: 7.1182 | Logits: 5.46  9.44 | Weights: W8:0.20894,W3:0.17405,W13:0.13936,W15:0.12856,W2:0.11009,W1:0.09297,W18:0.08992,W7:0.02259,W14:0.01129
2023-03-29 12:02:38 | Step 1400 | LR: 0.00015 | Loss: 7.4365 | Logits: 7.20  12.44 | Weights: W8:0.20810,W3:0.17371,W13:0.13987,W15:0.12903,W2:0.11020,W1:0.09305,W18:0.09028,W7:0.02224,W14:0.01130

--- 2025-03-29 12:06:45 --- how to be a real boy! ---
2025-03-29 12:32:43 | Step 1500 | LR: 0.00015 | Loss: 7.8731 | Logits: 8.95  15.50 | Weights: W8:0.20786,W3:0.17357,W13:0.13982,W15:0.12918,W2:0.11024,W1:0.09298,W18:0.09045,W7:0.02220,W14:0.01149
2025-03-29 13:10:10 | Step 1600 | LR: 0.00015 | Loss: 7.1665 | Logits: 10.38  18.16 | Weights: W8:0.20798,W3:0.17346,W13:0.13971,W15:0.12907,W2:0.11020,W1:0.09287,W18:0.09052,W7:0.02198,W14:0.01201
2023-03-29 13:40:11 | Step 1700 | LR: 0.00015 | Loss: 8.0436 | Logits: 12.45  21.67 | Weights: W8:0.20821,W3:0.17379,W13:0.13938,W15:0.12857,W2:0.11013,W1:0.09270,W18:0.09019,W7:0.02148,W14:0.01334
2023-03-29 14:11:05 | Step 1800 | LR: 0.00015 | Loss: 7.8832 | Logits: 13.82  24.46 | Weights: W8:0.20781,W3:0.17367,W13:0.13947,W15:0.12874,W2:0.11028,W1:0.09277,W18:0.09034,W7:0.02163,W14:0.01310
2023-03-29 14:43:24 | Step 1900 | LR: 0.00015 | Loss: 8.1356 | Logits: 15.14  27.18 | Weights: W8:0.20723,W3:0.17284,W13:0.13941,W15:0.12900,W2:0.11029,W1:0.09331,W18:0.09065,W7:0.02159,W14:0.01350
2023-03-29 15:20:08 | Step 2000 | LR: 0.00015 | Loss: 7.1411 | Logits: 0.00  0.00 | Weights: W8:0.20659,W3:0.17244,W13:0.13968,W15:0.12930,W2:0.11079,W1:0.09388,W18:0.09095,W7:0.02112,W14:0.01307

--- 2025-03-30 05:56:26 --- babyllm: 'what am i learning today?'- charis: 'ur mum'
2025-03-30 06:27:44 | Step 100 | LR: 0.00030 | Avg Loss: 16.3344 | Logits: 35.12, 64.12 | Window Weights: W8:0.20341,W3:0.17512,W13:0.13903,W15:0.12915,W2:0.11307,W1:0.09395,W18:0.09187,W7:0.02242,W14:0.00997 | Grad Norm: 0.000 | Memory Gates: Short:-2.999, Long:1.218, Current:2.781

--- 2025-03-30 03:40:51 --- babyllm: 'what am i learning today?'- charis: 'how to keep me up at night! again!'
2025-03-30 12:52:11 | Step 100 | LR: 0.00030 | Avg Loss: 48.1059 | Logits: 9.35, 47.21 | Window Weights: W8:0.20436,W3:0.17488,W13:0.13834,W15:0.12795,W2:0.11393,W1:0.09712,W18:0.09032,W7:0.02341,W14:0.00784 | Grad Norm: 0.000 | Memory Gates: Short:-0.717, Long:1.188, Current:0.529
2025-03-30 13:21:19 | Step 200 | LR: 0.00030 | Avg Loss: 16.5991 | Logits: 42.41, 94.00 | Window Weights: W8:0.20417,W3:0.17557,W13:0.13748,W15:0.12804,W2:0.11500,W1:0.09736,W18:0.08986,W7:0.02336,W14:0.00729 | Grad Norm: 0.000 | Memory Gates: Short:-1.257, Long:-0.479, Current:2.735
2025-03-30 13:50:39 | Step 300 | LR: 0.00030 | Avg Loss: 22.9733 | Logits: 25.69, 108.58 | Window Weights: W8:0.20436,W3:0.17275,W13:0.13906,W15:0.12985,W2:0.11359,W1:0.09706,W18:0.09081,W7:0.02266,W14:0.00799 | Grad Norm: 0.000 | Memory Gates: Short:-1.487, Long:1.594, Current:0.893
2025-03-30 14:20:01 | Step 400 | LR: 0.00030 | Avg Loss: 28.5616 | Logits: 31.56, 51.07 | Window Weights: W8:0.20430,W3:0.17232,W13:0.13939,W15:0.13006,W2:0.11334,W1:0.09710,W18:0.09105,W7:0.02265,W14:0.00792 | Grad Norm: 0.000 | Memory Gates: Short:-0.244, Long:1.180, Current:0.064
2025-03-30 14:49:27 | Step 500 | LR: 0.00030 | Avg Loss: 15.9755 | Logits: 17.46, 68.20 | Window Weights: W8:0.20407,W3:0.17279,W13:0.13922,W15:0.12968,W2:0.11414,W1:0.09688,W18:0.09084,W7:0.02266,W14:0.00785 | Grad Norm: 0.000 | Memory Gates: Short:-1.327, Long:-0.450, Current:2.777
2025-03-30 15:18:59 | Step 600 | LR: 0.00030 | Avg Loss: 29.9475 | Logits: 11.68, 67.58 | Window Weights: W8:0.20391,W3:0.17279,W13:0.13909,W15:0.12958,W2:0.11476,W1:0.09721,W18:0.09047,W7:0.02236,W14:0.00796 | Grad Norm: 0.000 | Memory Gates: Short:-1.607, Long:-0.429, Current:3.036
2025-03-30 15:47:04 | Step 700 | LR: 0.00030 | Avg Loss: 13.4374 | Logits: 23.85, 138.97 | Window Weights: W8:0.20415,W3:0.17143,W13:0.13886,W15:0.12958,W2:0.11326,W1:0.09984,W18:0.09060,W7:0.02215,W14:0.00824 | Grad Norm: 0.000 | Memory Gates: Short:-0.870, Long:-0.233, Current:2.102
2025-03-30 16:14:12 | Step 800 | LR: 0.00030 | Avg Loss: 26.3727 | Logits: 13.78, 48.69 | Window Weights: W8:0.20371,W3:0.17272,W13:0.13884,W15:0.12942,W2:0.11382,W1:0.09897,W18:0.09056,W7:0.02287,W14:0.00722 | Grad Norm: 0.000 | Memory Gates: Short:-13.128, Long:-5.784, Current:19.911
2025-03-30 16:41:23 | Step 900 | LR: 0.00030 | Avg Loss: 31.2302 | Logits: 1.36, 30.54 | Window Weights: W8:0.20362,W3:0.17287,W13:0.13919,W15:0.12952,W2:0.11352,W1:0.09866,W18:0.09051,W7:0.02297,W14:0.00729 | Grad Norm: 0.000 | Memory Gates: Short:0.083, Long:0.287, Current:0.630
2025-03-30 17:08:33 | Step 1000 | LR: 0.00030 | Avg Loss: 26.1067 | Logits: 18.48, 68.85 | Window Weights: W8:0.20343,W3:0.17257,W13:0.13945,W15:0.12974,W2:0.11343,W1:0.09845,W18:0.09063,W7:0.02305,W14:0.00741 | Grad Norm: 0.000 | Memory Gates: Short:-0.239, Long:0.785, Current:0.454
2025-03-30 17:08:33 | Step 1000 | LR: 0.00030 | Avg Loss: 27.8635 | Logits: 7.61, 33.67 | Window Weights: W8:0.20343,W3:0.17257,W13:0.13945,W15:0.12974,W2:0.11343,W1:0.09845,W18:0.09063,W7:0.02305,W14:0.00741 | Grad Norm: 0.000 | Memory Gates: Short:-0.239, Long:0.785, Current:0.454
2025-03-30 17:35:49 | Step 1100 | LR: 0.00030 | Avg Loss: 28.7396 | Logits: 10.60, 32.05 | Window Weights: W8:0.20339,W3:0.17264,W13:0.13947,W15:0.12970,W2:0.11344,W1:0.09831,W18:0.09069,W7:0.02314,W14:0.00738 | Grad Norm: 0.000 | Memory Gates: Short:-3.590, Long:3.143, Current:1.447
2025-03-30 18:03:11 | Step 1200 | LR: 0.00030 | Avg Loss: 28.9355 | Logits: 9.47, 32.20 | Window Weights: W8:0.20334,W3:0.17269,W13:0.13946,W15:0.12970,W2:0.11345,W1:0.09830,W18:0.09075,W7:0.02307,W14:0.00742 | Grad Norm: 0.000 | Memory Gates: Short:-0.451, Long:1.289, Current:0.162
2025-03-30 18:31:18 | Step 1300 | LR: 0.00030 | Avg Loss: 38.8803 | Logits: 7.01, 36.23 | Window Weights: W8:0.20332,W3:0.17252,W13:0.13956,W15:0.12990,W2:0.11333,W1:0.09814,W18:0.09089,W7:0.02299,W14:0.00752 | Grad Norm: 0.000 | Memory Gates: Short:-0.136, Long:1.404, Current:-0.268
2025-03-30 18:59:57 | Step 1400 | LR: 0.00030 | Avg Loss: 30.4740 | Logits: 5.68, 31.60 | Window Weights: W8:0.20344,W3:0.17221,W13:0.13976,W15:0.13008,W2:0.11308,W1:0.09812,W18:0.09092,W7:0.02275,W14:0.00780 | Grad Norm: 0.000 | Memory Gates: Short:-1.572, Long:0.924, Current:1.648
2025-03-30 19:31:23 | Step 1500 | LR: 0.00030 | Avg Loss: 24.7038 | Logits: 9.07, 28.06 | Window Weights: W8:0.20347,W3:0.17206,W13:0.13984,W15:0.13018,W2:0.11277,W1:0.09814,W18:0.09090,W7:0.02267,W14:0.00815 | Grad Norm: 0.000 | Memory Gates: Short:-0.674, Long:2.251, Current:-0.577
2025-03-30 20:01:28 | Step 1600 | LR: 0.00030 | Avg Loss: 30.1009 | Logits: 9.11, 32.65 | Window Weights: W8:0.20357,W3:0.17205,W13:0.13982,W15:0.13019,W2:0.11280,W1:0.09792,W18:0.09101,W7:0.02277,W14:0.00805 | Grad Norm: 0.000 | Memory Gates: Short:-3.253, Long:2.553, Current:1.700

--- 2025-03-30 21:44:43 --- babyllm: 'what am i learning today?'- charis: 'you're learning about mice!'
2025-03-30 22:14:43 | Step 100 | LR: 0.00030 | Avg Loss: 20.7674 | Logits: 7.18, 60.19 | Window Weights: W8:0.20279,W3:0.17214,W13:0.13981,W15:0.12999,W2:0.11436,W1:0.09848,W18:0.09063,W7:0.02223,W14:0.00781 | Grad Norm: 0.000 | Memory Gates: Short:6.644, Long:-0.968, Current:-4.675
2025-03-30 22:42:09 | Step 200 | LR: 0.00030 | Avg Loss: 23.3332 | Logits: 11.07, 41.77 | Window Weights: W8:0.20306,W3:0.17225,W13:0.13974,W15:0.12982,W2:0.11438,W1:0.09874,W18:0.09052,W7:0.02231,W14:0.00743 | Grad Norm: 0.000 | Memory Gates: Short:-4.095, Long:0.883, Current:4.212
2025-03-30 23:09:08 | Step 300 | LR: 0.00030 | Avg Loss: 23.1870 | Logits: 18.44, 52.05 | Window Weights: W8:0.20274,W3:0.17265,W13:0.13903,W15:0.12932,W2:0.11487,W1:0.09922,W18:0.08991,W7:0.02261,W14:0.00792 | Grad Norm: 0.000 | Memory Gates: Short:34.739, Long:-26.961, Current:-6.778
2025-03-30 23:36:18 | Step 400 | LR: 0.00030 | Avg Loss: 27.3437 | Logits: 34.66, 77.40 | Window Weights: W8:0.20252,W3:0.17315,W13:0.13836,W15:0.12899,W2:0.11587,W1:0.09881,W18:0.08976,W7:0.02249,W14:0.00832 | Grad Norm: 0.000 | Memory Gates: Short:-2.085, Long:-0.092, Current:3.177
2025-03-31 00:03:47 | Step 500 | LR: 0.00030 | Avg Loss: 23.9488 | Logits: 17.76, 49.41 | Window Weights: W8:0.20280,W3:0.17380,W13:0.13816,W15:0.12890,W2:0.11694,W1:0.09902,W18:0.08942,W7:0.02204,W14:0.00718 | Grad Norm: 0.000 | Memory Gates: Short:-0.925, Long:-0.004, Current:1.929
2025-03-31 00:31:16 | Step 600 | LR: 0.00030 | Avg Loss: 21.0514 | Logits: 17.44, 43.56 | Window Weights: W8:0.20289,W3:0.17388,W13:0.13903,W15:0.12929,W2:0.11582,W1:0.09835,W18:0.08978,W7:0.02218,W14:0.00702 | Grad Norm: 0.000 | Memory Gates: Short:5.443, Long:-0.275, Current:-4.168
2025-03-31 00:58:32 | Step 700 | LR: 0.00030 | Avg Loss: 23.8713 | Logits: 15.25, 36.74 | Window Weights: W8:0.20293,W3:0.17403,W13:0.13923,W15:0.12926,W2:0.11564,W1:0.09782,W18:0.08986,W7:0.02247,W14:0.00702 | Grad Norm: 0.000 | Memory Gates: Short:-5.580, Long:1.576, Current:5.004
2025-03-31 01:27:11 | Step 800 | LR: 0.00030 | Avg Loss: 26.6425 | Logits: 10.50, 35.36 | Window Weights: W8:0.20280,W3:0.17397,W13:0.13925,W15:0.12921,W2:0.11559,W1:0.09716,W18:0.08972,W7:0.02261,W14:0.00797 | Grad Norm: 0.000 | Memory Gates: Short:-0.226, Long:0.512, Current:0.714
2025-03-31 01:55:55 | Step 900 | LR: 0.00030 | Avg Loss: 21.9215 | Logits: 4.50, 31.89 | Window Weights: W8:0.20321,W3:0.17516,W13:0.13958,W15:0.12938,W2:0.11547,W1:0.09604,W18:0.08958,W7:0.02240,W14:0.00746 | Grad Norm: 0.000 | Memory Gates: Short:-5.965, Long:-3.419, Current:10.384
2025-03-31 02:24:42 | Step 1000 | LR: 0.00030 | Avg Loss: 23.8996 | Logits: 15.14, 46.57 | Window Weights: W8:0.20377,W3:0.17524,W13:0.13983,W15:0.12921,W2:0.11471,W1:0.09576,W18:0.08948,W7:0.02262,W14:0.00767 | Grad Norm: 0.000 | Memory Gates: Short:-3.035, Long:2.436, Current:1.599
2025-03-31 02:24:42 | Step 1000 | LR: 0.00030 | Avg Loss: 26.9291 | Logits: 14.65, 37.31 | Window Weights: W8:0.20377,W3:0.17524,W13:0.13983,W15:0.12921,W2:0.11471,W1:0.09576,W18:0.08948,W7:0.02262,W14:0.00767 | Grad Norm: 0.000 | Memory Gates: Short:-3.035, Long:2.436, Current:1.599
2025-03-31 02:54:02 | Step 1100 | LR: 0.00030 | Avg Loss: 23.1185 | Logits: 16.11, 41.95 | Window Weights: W8:0.20381,W3:0.17426,W13:0.14071,W15:0.12999,W2:0.11394,W1:0.09557,W18:0.08996,W7:0.02215,W14:0.00789 | Grad Norm: 0.000 | Memory Gates: Short:-1.035, Long:-0.080, Current:2.116
2025-03-31 03:24:43 | Step 1200 | LR: 0.00030 | Avg Loss: 24.3293 | Logits: 10.52, 33.67 | Window Weights: W8:0.20385,W3:0.17388,W13:0.14083,W15:0.13003,W2:0.11391,W1:0.09576,W18:0.08996,W7:0.02239,W14:0.00767 | Grad Norm: 0.000 | Memory Gates: Short:-0.560, Long:0.148, Current:1.412
2025-03-31 03:53:50 | Step 1300 | LR: 0.00030 | Avg Loss: 25.0731 | Logits: 7.49, 35.34 | Window Weights: W8:0.20305,W3:0.17319,W13:0.14075,W15:0.13086,W2:0.11490,W1:0.09478,W18:0.09085,W7:0.02288,W14:0.00706 | Grad Norm: 0.000 | Memory Gates: Short:-1.529, Long:0.730, Current:1.799
2025-03-31 04:22:25 | Step 1400 | LR: 0.00030 | Avg Loss: 22.9657 | Logits: 8.98, 30.63 | Window Weights: W8:0.20292,W3:0.17388,W13:0.14087,W15:0.13059,W2:0.11447,W1:0.09541,W18:0.09056,W7:0.02245,W14:0.00718 | Grad Norm: 0.000 | Memory Gates: Short:-1.591, Long:0.683, Current:1.908
2025-03-31 04:50:28 | Step 1500 | LR: 0.00030 | Avg Loss: 30.1231 | Logits: 6.98, 34.13 | Window Weights: W8:0.20298,W3:0.17450,W13:0.14033,W15:0.13147,W2:0.11445,W1:0.09595,W18:0.08960,W7:0.02129,W14:0.00774 | Grad Norm: 0.000 | Memory Gates: Short:-0.296, Long:0.261, Current:1.035
2025-03-31 05:20:58 | Step 1600 | LR: 0.00030 | Avg Loss: 42.5634 | Logits: -4.88, 28.48 | Window Weights: W8:0.20394,W3:0.17508,W13:0.13970,W15:0.13123,W2:0.11516,W1:0.09552,W18:0.08957,W7:0.02136,W14:0.00674 | Grad Norm: 0.000 | Memory Gates: Short:-1.030, Long:0.937, Current:1.093
2025-03-31 05:50:12 | Step 1700 | LR: 0.00030 | Avg Loss: 24.2373 | Logits: 5.15, 26.89 | Window Weights: W8:0.20418,W3:0.17528,W13:0.13908,W15:0.13066,W2:0.11536,W1:0.09581,W18:0.08935,W7:0.02141,W14:0.00716 | Grad Norm: 0.000 | Memory Gates: Short:-1.429, Long:1.121, Current:1.308
2025-03-31 06:18:54 | Step 1800 | LR: 0.00030 | Avg Loss: 21.5837 | Logits: 4.65, 26.00 | Window Weights: W8:0.20424,W3:0.17565,W13:0.13916,W15:0.13067,W2:0.11522,W1:0.09515,W18:0.08931,W7:0.02132,W14:0.00759 | Grad Norm: 0.000 | Memory Gates: Short:-18.135, Long:-3.072, Current:22.207
2025-03-31 06:47:03 | Step 1900 | LR: 0.00030 | Avg Loss: 33.0793 | Logits: -4.83, 28.15 | Window Weights: W8:0.20391,W3:0.17728,W13:0.13801,W15:0.12983,W2:0.11544,W1:0.09524,W18:0.08855,W7:0.02122,W14:0.00885 | Grad Norm: 0.000 | Memory Gates: Short:-2.169, Long:-0.872, Current:4.041
2025-03-31 07:14:33 | Step 2009 | LR: 0.00030 | Avg Loss: 27.6982 | Logits: 5.16, 31.27 | Window Weights: W8:0.20427,W3:0.17722,W13:0.13821,W15:0.12951,W2:0.11593,W1:0.09529,W18:0.08853,W7:0.02150,W14:0.00786 | Grad Norm: 0.000 | Memory Gates: Short:-2.016, Long:-0.931, Current:3.947
2025-03-31 07:14:33 | Step 2009 | LR: 0.00030 | Avg Loss: 29.9091 | Logits: 1.45, 27.49 | Window Weights: W8:0.20427,W3:0.17722,W13:0.13821,W15:0.12951,W2:0.11593,W1:0.09529,W18:0.08853,W7:0.02150,W14:0.00786 | Grad Norm: 0.000 | Memory Gates: Short:-2.016, Long:-0.931, Current:3.947
2025-03-31 07:42:00 | Step 2099 | LR: 0.00030 | Avg Loss: 24.0502 | Logits: 3.86, 21.92 | Window Weights: W8:0.20416,W3:0.17690,W13:0.13813,W15:0.12979,W2:0.11539,W1:0.09548,W18:0.08876,W7:0.02158,W14:0.00815 | Grad Norm: 0.000 | Memory Gates: Short:-1.226, Long:-0.261, Current:2.487
2025-03-31 08:09:29 | Step 2200 | LR: 0.00030 | Avg Loss: 23.4799 | Logits: 6.88, 35.48 | Window Weights: W8:0.20443,W3:0.17845,W13:0.13735,W15:0.12875,W2:0.11552,W1:0.09572,W18:0.08800,W7:0.02104,W14:0.00906 | Grad Norm: 0.000 | Memory Gates: Short:-0.019, Long:0.056, Current:0.963
2025-03-31 08:36:55 | Step 2300 | LR: 0.00030 | Avg Loss: 25.6601 | Logits: 0.90, 26.34 | Window Weights: W8:0.20417,W3:0.17904,W13:0.13743,W15:0.12886,W2:0.11604,W1:0.09573,W18:0.08774,W7:0.02093,W14:0.00839 | Grad Norm: 0.000 | Memory Gates: Short:-0.570, Long:0.306, Current:1.264
2025-03-31 09:04:02 | Step 2400 | LR: 0.00030 | Avg Loss: 34.1403 | Logits: -0.68, 23.61 | Window Weights: W8:0.20455,W3:0.17873,W13:0.13799,W15:0.12867,W2:0.11620,W1:0.09571,W18:0.08801,W7:0.02097,W14:0.00751 | Grad Norm: 0.000 | Memory Gates: Short:-0.597, Long:0.567, Current:1.031
2025-03-31 09:31:23 | Step 2500 | LR: 0.00030 | Avg Loss: 32.4980 | Logits: 8.16, 34.44 | Window Weights: W8:0.20468,W3:0.17842,W13:0.13822,W15:0.12882,W2:0.11595,W1:0.09548,W18:0.08806,W7:0.02120,W14:0.00752 | Grad Norm: 0.000 | Memory Gates: Short:9.132, Long:-1.424, Current:-6.708
2025-03-31 09:59:04 | Step 2600 | LR: 0.00030 | Avg Loss: 29.4020 | Logits: 6.92, 27.31 | Window Weights: W8:0.20464,W3:0.17832,W13:0.13830,W15:0.12899,W2:0.11573,W1:0.09569,W18:0.08803,W7:0.02090,W14:0.00776 | Grad Norm: 0.000 | Memory Gates: Short:-1.633, Long:1.386, Current:1.247
2025-03-31 10:29:39 | Step 2700 | LR: 0.00030 | Avg Loss: 27.1714 | Logits: 4.38,22.21 | Window Weights: W8:0.20457,W3:0.17818,W13:0.13852,W15:0.12912,W2:0.11568,W1:0.09571,W18:0.08800,W7:0.02100,W14:0.00758 | Grad Norm: 1m38;5;225m0.000 | Memory Gates: Short:-0.659, Long:1.083, Current:0.576 | Top Tokens: ]
2025-03-31 10:58:09 | Step 2800 | LR: 0.00030 | Avg Loss: 27.2992 | Logits: 6.31, 24.35 | Window Weights: W8:0.20516,W3:0.17787,W13:0.13913,W15:0.12907,W2:0.11486,W1:0.09544,W18:0.08818,W7:0.02119,W14:0.00747 | Grad Norm: 1m38;5;225m0.000 | Memory Gates: Short:-0.663, Long:1.135, Current:0.528 | Top Tokens: ]
2025-03-31 11:25:52 | Step 2900 | LR: 0.00030 | Avg Loss: 28.7437 | Logits: 6.27, 26.47 | Window Weights: W8:0.20476,W3:0.17795,W13:0.13959,W15:0.12934,W2:0.11433,W1:0.09526,W18:0.08840,W7:0.02087,W14:0.00789 | Grad Norm: 1m38;5;225m0.000 | Memory Gates: Short:-1.010, Long:1.454, Current:0.555 | Top Tokens: ]
2025-03-31 11:54:12 | Step 3000 | LR: 0.00030 | Avg Loss: 33.1622 | Logits: 3.45, 24.66 | Window Weights: W8:0.20464,W3:0.17794,W13:0.13973,W15:0.12928,W2:0.11440,W1:0.09505,W18:0.08843,W7:0.02104,W14:0.00789 | Grad Norm: 1m38;5;225m0.000 | Memory Gates: Short:6.136, Long:-3.751, Current:-1.385 | Top Tokens: ]
2025-03-31 13:55:11 | Step 99.000000 | LR: 0.00030 | Avg Loss: 27.7961 | Logits: 5.19,35.63 | Window Weights: W8:0.20589,W3:0.18219,W13:0.13612,W15:0.12561,W2:0.11724,W1:0.09672,W18:0.08632,W7:0.02112,W14:0.00715 | Grad Norm: 0.000 | Memory Gates: Short:-2.703, Long:2.055, Current:1.648 | Top Tokens: []
Durations: Step: 17907.41ms, Save: 65.93ms, Load: 58.39ms, Logits: 0.13ms, Print: 0.00ms, Combine: 0.00ms, Token: 0.00ms | Training

--- 2025-03-31 14:24:14 --- babyllm: 'what am i learning today?'- charis: 'mice is love'
2025-03-31 14:52:29 | Step 100.000000 | LR: 0.00030 | Avg Loss: 34.9944 | Logits: 8.23,60.59 | Window Weights: W8:0.20688,W3:0.18464,W13:0.13570,W15:0.12352,W2:0.11721,W1:0.09854,W18:0.08394,W7:0.02203,W14:0.00579 | Grad Norm: 0.000 | Memory Gates: Short:-1.272, Long:0.543, Current:1.730 | Top Tokens: [('b', 28), ('it', 17), (',', 15), ('the', 12), ('of', 11), ('a', 11), ('p', 11), ('r', 10), ('s', 10), ('ing', 9)] | Training
2025-03-31 15:21:03 | Step 200.000000 | LR: 0.00030 | Avg Loss: 30.3336 | Logits: 9.13,29.26 | Window Weights: W8:0.20717,W3:0.18418,W13:0.13600,W15:0.12347,W2:0.11708,W1:0.09821,W18:0.08426,W7:0.02184,W14:0.00606 | Grad Norm: 0.000 | Memory Gates: Short:-11.939, Long:5.115, Current:7.825 | Top Tokens: [(',', 99), ('b', 44), ('e', 37), ('er', 26), ('right', 15), ('were', 12), ('ur', 9), ('little', 7), ('the', 6), ('ul', 6)] | Training
2025-03-31 15:50:49 | Step 300.000000 | LR: 0.00030 | Avg Loss: 29.0962 | Logits: 6.42,26.93 | Window Weights: W8:0.20678,W3:0.18418,W13:0.13618,W15:0.12357,W2:0.11733,W1:0.09810,W18:0.08476,W7:0.02148,W14:0.00588 | Grad Norm: 0.000 | Memory Gates: Short:-3.013, Long:1.909, Current:2.104 | Top Tokens: [(',', 50), ('e', 48), ('b', 25), ('er', 25), ('a', 15), ('them', 13), ('ur', 11), ('were', 10), ('ly', 10), ('.', 8)] | Training
2025-03-31 16:21:29 | Step 400.000000 | LR: 0.00030 | Avg Loss: 28.9852 | Logits: 5.22,21.47 | Window Weights: W8:0.20682,W3:0.18399,W13:0.13638,W15:0.12358,W2:0.11734,W1:0.09784,W18:0.08509,W7:0.02140,W14:0.00584 | Grad Norm: 0.000 | Memory Gates: Short:-2.216, Long:2.540, Current:0.677 | Top Tokens: [(',', 85), ('b', 39), ('er', 29), ('as', 22), ('a', 18), ('were', 18), ('little', 12), ('-', 12), ('her', 9), ('m', 7)] | Training
2025-03-31 16:52:46 | Step 500.000000 | LR: 0.00030 | Avg Loss: 32.4108 | Logits: 2.62,23.43 | Window Weights: W8:0.20699,W3:0.18402,W13:0.13638,W15:0.12360,W2:0.11726,W1:0.09785,W18:0.08505,W7:0.02117,W14:0.00595 | Grad Norm: 0.000 | Memory Gates: Short:-1.953, Long:2.469, Current:0.484 | Top Tokens: [('b', 68), ('er', 32), ('the', 24), (',', 19), ('-', 15), ('were', 11), ('m', 11), ('of', 10), ('e', 8), ('feel', 7)] | Training
2025-03-31 17:22:26 | Step 600.000000 | LR: 0.00030 | Avg Loss: 26.3216 | Logits: 2.57,18.39 | Window Weights: W8:0.20711,W3:0.18425,W13:0.13668,W15:0.12371,W2:0.11689,W1:0.09757,W18:0.08522,W7:0.02053,W14:0.00631 | Grad Norm: 0.000 | Memory Gates: Short:-3.133, Long:2.752, Current:1.382 | Top Tokens: [('a', 45), ('b', 29), ('the', 23), (',', 23), ('were', 20), ('er', 17), ('m', 13), ('y', 8), ('-', 7), ('as', 7)] | Training
2025-03-31 17:52:37 | Step 700.000000 | LR: 0.00030 | Avg Loss: 24.6387 | Logits: 6.27,20.41 | Window Weights: W8:0.20692,W3:0.18344,W13:0.13695,W15:0.12378,W2:0.11667,W1:0.09755,W18:0.08565,W7:0.02078,W14:0.00657 | Grad Norm: 0.000 | Memory Gates: Short:-4.666, Long:5.577, Current:0.089 | Top Tokens: [('ing', 87), ('were', 33), (',', 31), ('b', 30), ('ly', 25), ('a', 21), ('er', 12), ('the', 11), ('y', 8), ('e', 7)] | Training
2025-03-31 18:22:40 | Step 800.000000 | LR: 0.00030 | Avg Loss: 28.4055 | Logits: 6.17,23.43 | Window Weights: W8:0.20692,W3:0.18371,W13:0.13673,W15:0.12384,W2:0.11674,W1:0.09744,W18:0.08551,W7:0.02007,W14:0.00734 | Grad Norm: 0.000 | Memory Gates: Short:5.244, Long:-4.172, Current:-0.072 | Top Tokens: [('ing', 99), ('b', 40), (',', 25), ('were', 20), ('was', 14), ('m', 12), ('ly', 11), ('ul', 10), ('on', 9), ('the', 7)] | Training

--- 2025-03-31 18:34:47 --- babyllm: 'what am i learning today?'- charis: 'how to log'
2025-03-31 18:55:10 | Step 900.000000 | LR: 0.00030 | Avg Loss: 34.2171 | Logits: 0.46,21.06 | Window Weights: W8:0.20683,W3:0.18359,W13:0.13678,W15:0.12376,W2:0.11635,W1:0.09765,W18:0.08539,W7:0.02020,W14:0.00776 | Grad Norm: 0.000 | Memory Gates: Short:-2.781, Long:3.012, Current:0.769 | Top Tokens: [('b', 59), (',', 30), ('the', 30), ('and', 24), ('ing', 16), ('feel', 15), ('were', 13), ('ed', 11), ('er', 9), ('y', 9)] | Training
2025-03-31 19:27:08 | Step 1000.000000 | LR: 0.00030 | Avg Loss: 30.0876 | Logits: 1.12,18.43 | Window Weights: W8:0.20684,W3:0.18344,W13:0.13686,W15:0.12374,W2:0.11595,W1:0.09767,W18:0.08553,W7:0.02035,W14:0.00794 | Grad Norm: 0.000 | Memory Gates: Short:-1.993, Long:1.961, Current:1.031 | Top Tokens: [('b', 58), (',', 41), ('the', 29), ('and', 29), ('it', 22), ('ing', 19), ('-', 19), ('were', 16), ('music', 12), ('of', 8)] | Training
2025-03-31 19:56:02 | Step 1100.000000 | LR: 0.00030 | Avg Loss: 31.6498 | Logits: -1.00,18.93 | Window Weights: W8:0.20741,W3:0.18350,W13:0.13617,W15:0.12366,W2:0.11610,W1:0.09801,W18:0.08473,W7:0.02017,W14:0.00855 | Grad Norm: 0.000 | Memory Gates: Short:-2.415, Long:2.003, Current:1.412 | Top Tokens: [(',', 36), ('was', 34), ('b', 31), ('and', 19), ('a', 19), ('w', 17), ('s', 15), ('e', 14), ('the', 13), ('of', 12)] | Training
2025-03-31 20:26:36 | Step 1200.000000 | LR: 0.00030 | Avg Loss: 31.5549 | Logits: -2.18,16.22 | Window Weights: W8:0.20726,W3:0.18337,W13:0.13605,W15:0.12366,W2:0.11638,W1:0.09806,W18:0.08472,W7:0.02000,W14:0.00881 | Grad Norm: 0.000 | Memory Gates: Short:15.043, Long:-14.322, Current:0.279 | Top Tokens: [('and', 71), ('b', 53), ('as', 38), (',', 34), ('they', 31), ('were', 22), ('feel', 8), ('them', 7), ('in', 5), ('u', 5)] | Training
2025-03-31 20:57:11 | Step 1300.000000 | LR: 0.00030 | Avg Loss: 25.5835 | Logits: 7.07,23.25 | Window Weights: W8:0.20721,W3:0.18342,W13:0.13632,W15:0.12362,W2:0.11652,W1:0.09837,W18:0.08410,W7:0.01945,W14:0.00930 | Grad Norm: 0.000 | Memory Gates: Short:-58.361, Long:40.001, Current:19.360 | Top Tokens: [(',', 60), ('as', 55), ('b', 42), ('and', 19), ('of', 18), ('were', 17), ('they', 17), ('about', 13), ('a', 8), ('their', 7)] | Training
2025-03-31 21:51:16 | Step 1400.000000 | LR: 0.00030 | Avg Loss: 23.8158 | Logits: 5.12,20.43 | Window Weights: W8:0.20691,W3:0.18345,W13:0.13692,W15:0.12388,W2:0.11611,W1:0.09805,W18:0.08477,W7:0.01915,W14:0.00908 | Grad Norm: 0.000 | Memory Gates: Short:-6.479, Long:6.844, Current:0.635 | Top Tokens: [(',', 125), ('the', 68), ('b', 22), ('and', 12), ('were', 8), ('a', 8), ('as', 8), ('ed', 7), ('as', 5), ('was', 5)] | Training
2025-03-31 22:20:52 | Step 1500.000000 | LR: 0.00030 | Avg Loss: 28.7619 | Logits: 3.81,21.79 | Window Weights: W8:0.20695,W3:0.18295,W13:0.13692,W15:0.12391,W2:0.11604,W1:0.09816,W18:0.08499,W7:0.01933,W14:0.00908 | Grad Norm: 0.000 | Memory Gates: Short:-6.463, Long:5.119, Current:2.344 | Top Tokens: [(',', 68), ('b', 47), ('the', 38), ('were', 19), ('in', 18), ('and', 16), ('!', 15), ('.', 13), ('ed', 6), ('they', 6)] | Training
2025-03-31 22:52:00 | Step 1600.000000 | LR: 0.00030 | Avg Loss: 22.7032 | Logits: 3.64,18.53 | Window Weights: W8:0.20668,W3:0.18167,W13:0.13766,W15:0.12407,W2:0.11559,W1:0.09862,W18:0.08690,W7:0.01935,W14:0.00782 | Grad Norm: 0.000 | Memory Gates: Short:-2.131, Long:2.109, Current:1.022 | Top Tokens: [(',', 103), ('the', 53), ('ed', 26), ('s', 23), ('she', 14), ('b', 11), ('and', 10), ('were', 10), ('that', 6), ('but', 6)] | Training
2025-03-31 23:24:12 | Step 1700.000000 | LR: 0.00030 | Avg Loss: 28.0086 | Logits: 1.60,20.28 | Window Weights: W8:0.20682,W3:0.18145,W13:0.13775,W15:0.12426,W2:0.11511,W1:0.09881,W18:0.08726,W7:0.01883,W14:0.00808 | Grad Norm: 0.000 | Memory Gates: Short:-5.890, Long:5.124, Current:1.766 | Top Tokens: [('b', 49), ('r', 28), ('e', 24), ('ed', 21), (',', 19), ('had', 16), ('it', 15), ('the', 14), ('were', 13), ('s', 11)] | Training
2025-03-31 23:56:01 | Step 1800.000000 | LR: 0.00030 | Avg Loss: 27.5225 | Logits: -1.55,15.47 | Window Weights: W8:0.20664,W3:0.18138,W13:0.13732,W15:0.12401,W2:0.11545,W1:0.09856,W18:0.08694,W7:0.01886,W14:0.00922 | Grad Norm: 0.000 | Memory Gates: Short:15.545, Long:-8.925, Current:-5.621 | Top Tokens: [(',', 40), ('b', 39), ('ed', 37), ('.', 15), ('and', 14), ('were', 13), ('f', 13), ('a', 13), ('for', 13), ('r', 11)] | Training
2025-04-01 00:27:53 | Step 1900.000000 | LR: 0.00030 | Avg Loss: 26.7049 | Logits: 0.10,18.79 | Window Weights: W8:0.20651,W3:0.18150,W13:0.13779,W15:0.12408,W2:0.11518,W1:0.09845,W18:0.08715,W7:0.01828,W14:0.00943 | Grad Norm: 0.000 | Memory Gates: Short:-5.752, Long:4.824, Current:1.928 | Top Tokens: [(',', 56), ('b', 38), ('and', 23), ('were', 22), ('that', 17), ('in', 14), ('a', 12), ('ed', 9), ('m', 9), ('ly', 8)] | Training
2025-04-01 00:57:38 | Step 2000.000000 | LR: 0.00030 | Avg Loss: 23.1832 | Logits: -0.91,12.57 | Window Weights: W8:0.20631,W3:0.18145,W13:0.13823,W15:0.12434,W2:0.11511,W1:0.09809,W18:0.08787,W7:0.01847,W14:0.00853 | Grad Norm: 0.000 | Memory Gates: Short:-7.709, Long:5.782, Current:2.926 | Top Tokens: [(',', 73), ('b', 44), ('a', 33), ('and', 28), ('in', 14), ('that', 13), ('i', 12), ('m', 10), ('!', 10), ('ing', 6)] | Training
2025-04-01 01:27:59 | Step 2100.000000 | LR: 0.00030 | Avg Loss: 22.1812 | Logits: -1.20,14.55 | Window Weights: W8:0.20631,W3:0.18113,W13:0.13834,W15:0.12439,W2:0.11505,W1:0.09889,W18:0.08767,W7:0.01745,W14:0.00915 | Grad Norm: 0.000 | Memory Gates: Short:-1.936, Long:1.401, Current:1.535 | Top Tokens: [(',', 52), ('that', 33), ('b', 28), ('a', 23), ('and', 21), ('ice', 14), ('up', 14), ('i', 13), ('b', 12), ('.', 11)] | Training
2025-04-01 01:58:24 | Step 2200.000000 | LR: 0.00030 | Avg Loss: 23.5892 | Logits: -2.04,14.40 | Window Weights: W8:0.20678,W3:0.18027,W13:0.13907,W15:0.12431,W2:0.11291,W1:0.09928,W18:0.08855,W7:0.01757,W14:0.00965 | Grad Norm: 0.000 | Memory Gates: Short:-2.409, Long:2.180, Current:1.228 | Top Tokens: [(',', 86), ('for', 29), ('a', 28), ('b', 23), ('the', 15), ('and', 14), ('y', 10), ('of', 10), ('now', 9), ('w', 8)] | Training
2025-04-01 02:29:17 | Step 2300.000000 | LR: 0.00030 | Avg Loss: 28.7332 | Logits: -0.61,19.63 | Window Weights: W8:0.20717,W3:0.17992,W13:0.13911,W15:0.12440,W2:0.11231,W1:0.09915,W18:0.08859,W7:0.01776,W14:0.01001 | Grad Norm: 0.000 | Memory Gates: Short:-8.582, Long:7.529, Current:2.053 | Top Tokens: [(',', 71), ('a', 36), ('b', 28), ('for', 22), ('y', 13), ('ong', 12), ('ed', 11), ('were', 10), ('.', 9), ('but', 7)] | Training
2025-04-01 02:57:49 | Step 2400.000000 | LR: 0.00030 | Avg Loss: 19.2709 | Logits: -1.75,14.32 | Window Weights: W8:0.20681,W3:0.17940,W13:0.13907,W15:0.12431,W2:0.11266,W1:0.09972,W18:0.08851,W7:0.01786,W14:0.01008 | Grad Norm: 0.000 | Memory Gates: Short:-3.514, Long:2.270, Current:2.245 | Top Tokens: [(',', 103), ('!', 26), ('a', 23), ('b', 17), ('and', 16), ('at', 16), ('m', 12), ('for', 11), ('were', 10), ('.', 10)] | Training
2025-04-01 03:26:34 | Step 2500.000000 | LR: 0.00030 | Avg Loss: 32.7150 | Logits: -0.39,19.94 | Window Weights: W8:0.20666,W3:0.17870,W13:0.13966,W15:0.12464,W2:0.11225,W1:0.09812,W18:0.09003,W7:0.01930,W14:0.00915 | Grad Norm: 0.000 | Memory Gates: Short:18.354, Long:-13.230, Current:-4.124 | Top Tokens: [('she', 53), (',', 34), ('was', 33), ('now', 27), ('b', 25), ('were', 24), ('in', 18), ('to', 13), ('p', 11), ('and', 7)] | Training
2025-04-01 03:55:46 | Step 2600.000000 | LR: 0.00030 | Avg Loss: 31.8719 | Logits: -3.37,16.13 | Window Weights: W8:0.20626,W3:0.17845,W13:0.13969,W15:0.12471,W2:0.11261,W1:0.09823,W18:0.09042,W7:0.01905,W14:0.00911 | Grad Norm: 0.000 | Memory Gates: Short:-3.503, Long:2.732, Current:1.771 | Top Tokens: [('b', 51), (',', 41), ('her', 27), ('y', 25), ('she', 21), ('c', 13), ('for', 10), ('on', 10), ('feel', 9), ('er', 8)] | Training
2025-04-01 04:24:59 | Step 2700.000000 | LR: 0.00030 | Avg Loss: 28.2862 | Logits: -3.85,15.94 | Window Weights: W8:0.20584,W3:0.17599,W13:0.14059,W15:0.12523,W2:0.11279,W1:0.09729,W18:0.09201,W7:0.01911,W14:0.00972 | Grad Norm: 0.000 | Memory Gates: Short:-3.235, Long:3.092, Current:1.143 | Top Tokens: [(',', 41), ('b', 41), ('she', 30), ('and', 26), ('f', 20), ('to', 18), ('in', 18), ('was', 17), ('ri', 14), ('.', 8)] | Training
2025-04-01 05:00:18 | Step 2800.000000 | LR: 0.00030 | Avg Loss: 31.1307 | Logits: -6.76,12.54 | Window Weights: W8:0.20611,W3:0.17663,W13:0.14010,W15:0.12498,W2:0.11293,W1:0.09720,W18:0.09152,W7:0.01911,W14:0.00998 | Grad Norm: 0.000 | Memory Gates: Short:-2.667, Long:2.511, Current:1.156 | Top Tokens: [('b', 40), (',', 39), ('in', 22), ('and', 22), ('were', 20), ('them', 19), ('she', 15), ('was', 13), ('f', 12), ('to', 12)] | Training
2025-04-01 05:29:17 | Step 2900.000000 | LR: 0.00030 | Avg Loss: 30.6358 | Logits: -4.84,14.53 | Window Weights: W8:0.20590,W3:0.17658,W13:0.14024,W15:0.12530,W2:0.11288,W1:0.09686,W18:0.09205,W7:0.01884,W14:0.00994 | Grad Norm: 0.000 | Memory Gates: Short:-3.977, Long:3.433, Current:1.544 | Top Tokens: [('were', 47), ('in', 46), ('b', 38), ('.', 27), (',', 21), ('to', 20), ('a', 13), ('and', 12), ('in', 10), ('them', 7)] | Training
2025-04-01 05:58:30 | Step 3000.000000 | LR: 0.00030 | Avg Loss: 26.0210 | Logits: -0.41,15.53 | Window Weights: W8:0.20645,W3:0.17669,W13:0.13987,W15:0.12483,W2:0.11333,W1:0.09647,W18:0.09158,W7:0.01863,W14:0.01074 | Grad Norm: 0.000 | Memory Gates: Short:-9.931, Long:8.304, Current:2.627 | Top Tokens: [(',', 44), ('that', 42), ('to', 34), ('b', 29), ('.', 17), ('she', 16), ('were', 15), ('a', 15), ('ow', 12), ('her', 11)] | Training
2025-04-01 06:27:46 | Step 3100.000000 | LR: 0.00030 | Avg Loss: 35.5288 | Logits: -2.59,21.70 | Window Weights: W8:0.20822,W3:0.17518,W13:0.14105,W15:0.12532,W2:0.11251,W1:0.09546,W18:0.09184,W7:0.01778,W14:0.01125 | Grad Norm: 0.000 | Memory Gates: Short:-2.129, Long:2.580, Current:0.549 | Top Tokens: [('a', 46), ('b', 32), ('p', 30), ('were', 26), (',', 21), ('the', 19), ('al', 19), ('to', 13), ('them', 8), ('i', 8)] | Training
2025-04-01 06:56:36 | Step 3200.000000 | LR: 0.00030 | Avg Loss: 27.8488 | Logits: -0.36,17.63 | Window Weights: W8:0.20806,W3:0.17523,W13:0.14128,W15:0.12549,W2:0.11248,W1:0.09470,W18:0.09199,W7:0.01792,W14:0.01148 | Grad Norm: 0.000 | Memory Gates: Short:-8.516, Long:7.706, Current:1.810 | Top Tokens: [('b', 41), ('p', 38), ('a', 38), (',', 29), ('ve', 23), ('al', 22), ('were', 15), ('the', 14), ('that', 9), ('r', 7)] | Training
2025-04-01 07:25:17 | Step 3300.000000 | LR: 0.00030 | Avg Loss: 35.9077 | Logits: -2.85,22.66 | Window Weights: W8:0.20808,W3:0.17594,W13:0.14077,W15:0.12522,W2:0.11206,W1:0.09535,W18:0.09164,W7:0.01684,W14:0.01271 | Grad Norm: 0.000 | Memory Gates: Short:25.019, Long:-14.333, Current:-9.686 | Top Tokens: [('b', 47), (',', 46), ('were', 26), ('the', 21), ('for', 21), ('id', 12), ('to', 12), ('and', 11), ('y', 10), ('i', 8)] | Training
2025-04-01 07:53:43 | Step 3400.000000 | LR: 0.00030 | Avg Loss: 27.7057 | Logits: 0.82,19.41 | Window Weights: W8:0.20796,W3:0.17584,W13:0.14168,W15:0.12610,W2:0.11030,W1:0.09547,W18:0.09212,W7:0.01679,W14:0.01239 | Grad Norm: 0.000 | Memory Gates: Short:-3.862, Long:3.997, Current:0.865 | Top Tokens: [('she', 54), ('the', 42), ('for', 37), (',', 34), ('b', 27), ('p', 13), ('that', 13), ('had', 10), ('and', 9), ('.', 8)] | Training
2025-04-01 08:22:14 | Step 3500.000000 | LR: 0.00030 | Avg Loss: 23.4227 | Logits: -4.33,12.54 | Window Weights: W8:0.20816,W3:0.17590,W13:0.14160,W15:0.12636,W2:0.11002,W1:0.09481,W18:0.09284,W7:0.01686,W14:0.01211 | Grad Norm: 0.000 | Memory Gates: Short:-11.382, Long:8.718, Current:3.664 | Top Tokens: [(',', 43), ('b', 38), ('she', 36), ('the', 34), ('in', 20), ('to', 19), ('were', 10), ('that', 8), ('had', 8), ('.', 8)] | Training
2025-04-01 08:51:21 | Step 3600.000000 | LR: 0.00030 | Avg Loss: 31.9527 | Logits: 1.29,19.98 | Window Weights: W8:0.20858,W3:0.17578,W13:0.14169,W15:0.12621,W2:0.11035,W1:0.09445,W18:0.09251,W7:0.01652,W14:0.01256 | Grad Norm: 0.000 | Memory Gates: Short:-3.660, Long:3.667, Current:0.994 | Top Tokens: [(',', 63), ('b', 33), ('n', 28), ('she', 23), ('to', 20), ('of', 16), ('were', 14), ('and', 11), ('the', 10), ('ul', 9)] | Training
2025-04-01 09:20:28 | Step 3700.000000 | LR: 0.00030 | Avg Loss: 29.8548 | Logits: -2.63,14.52 | Window Weights: W8:0.20896,W3:0.17609,W13:0.14141,W15:0.12591,W2:0.11102,W1:0.09375,W18:0.09205,W7:0.01590,W14:0.01356 | Grad Norm: 0.000 | Memory Gates: Short:-7.895, Long:7.131, Current:1.764 | Top Tokens: [('you', 52), (',', 42), ('b', 33), ('were', 24), ('ed', 19), ('they', 18), ('and', 15), ('she', 12), ('the', 11), ('a', 9)] | Training
2025-04-01 09:50:07 | Step 3800.000000 | LR: 0.00030 | Avg Loss: 28.3063 | Logits: -3.37,13.69 | Window Weights: W8:0.20992,W3:0.17569,W13:0.14111,W15:0.12556,W2:0.11097,W1:0.09336,W18:0.09145,W7:0.01597,W14:0.01459 | Grad Norm: 0.000 | Memory Gates: Short:-10.629, Long:8.837, Current:2.792 | Top Tokens: [('y', 51), ('b', 36), ('the', 35), (',', 23), ('.', 21), ('a', 17), ('o', 17), ('and', 14), ('were', 12), ('est', 11)] | Training
2025-04-01 10:21:11 | Step 3900.000000 | LR: 0.00030 | Avg Loss: 32.2513 | Logits: -1.87,15.17 | Window Weights: W8:0.21031,W3:0.17491,W13:0.14151,W15:0.12572,W2:0.11086,W1:0.09311,W18:0.09197,W7:0.01591,W14:0.01436 | Grad Norm: 0.000 | Memory Gates: Short:35.117, Long:-32.390, Current:-1.727 | Top Tokens: [('the', 107), ('b', 32), ('.', 16), ('were', 14), (',', 14), ('a', 12), ('y', 9), ('she', 8), ('p', 8), ('to', 8)] | Training
2025-04-01 10:57:42 | Step 4000.000000 | LR: 0.00030 | Avg Loss: 25.2712 | Logits: -1.99,13.59 | Window Weights: W8:0.21026,W3:0.17502,W13:0.14157,W15:0.12596,W2:0.11042,W1:0.09336,W18:0.09176,W7:0.01551,W14:0.01479 | Grad Norm: 0.000 | Memory Gates: Short:-5.048, Long:4.616, Current:1.433 | Top Tokens: [('the', 55), ('.', 49), ('b', 21), ('were', 20), ('to', 19), (',', 18), ('m', 10), ('and', 9), ('not', 8), ('y', 7)] | Training

--- 2025-04-01 12:06:06 --- babyllm: 'what am i learning today?'- charis: 'seeing if batching works'
2025-04-02 13:21:30 | 100 | LR0.0003 | loss38.0495 | gradNorm1.0000 | logitMin-31.8468 | logitMax-10.7003 | memoryGate0.3333 | scheduledSampling0.0000 | tokenCount300windowWeightsW8:0.20817,W3:0.16149,W13:0.15545,W15:0.14173,W18:0.11037,W2:0.09007,W1:0.06950,W7:0.05258,W14:-0.00938 | topTokens[('at', 45), ('in', 44), ('least', 12), ('feel', 10), ('it', 7), ('that', 6), ('r', 4), ('ice', 4), ('b', 4), ('.', 4)] | Training
2025-04-02 13:33:31 | 100 | LR0.0003 | loss33.3241 | gradNorm1.0000 | logitMin-35.1344 | logitMax-14.3808 | memoryGate0.3333 | scheduledSampling0.0000 | tokenCount300 | windowWeightsW8:0.20887,W13:0.15891,W3:0.15735,W15:0.14591,W18:0.11358,W2:0.08671,W1:0.06621,W7:0.05314,W14:-0.01056 | topTokens[('the', 16), ('it', 11), ('in', 10), ('that', 9), ('.', 8), (',', 8), ('this', 7), ('be', 7), ("'s", 6), ('my', 6)] | Training
2025-04-02 13:38:43 | 200 | LR0.0003 | loss23.7660 | gradNorm1.0000 | tokenCount300 | logitMin-28.9950 | logitMax-15.9579 | memoryGate0.3333 | windowWeightsW8:0.20930,W13:0.15932,W3:0.15630,W15:0.14628,W18:0.11431,W2:0.08523,W1:0.06481,W7:0.05464,W14:-0.01005 | topTokens[('the', 17), ('.', 11), ('it', 9), ('a', 8), ("'s", 7), ('work', 5), (',', 4), ('them', 4), ('b', 4), ('in', 4)] | Training
2025-04-02 13:43:42 | 300 | LR0.0003 | loss27.1185 | gradNorm1.0000 | tokenCount300 | logitMin-32.7195 | logitMax-15.7146 | memoryGate0.3333 | windowWeightsW8:0.20863,W13:0.16015,W3:0.15512,W15:0.14667,W18:0.11533,W2:0.08498,W1:0.06418,W7:0.05514,W14:-0.01004 | topTokens[('with', 16), ('.', 15), ('that', 7), ('the', 7), (',', 6), ('it', 6), ('feel', 5), ('to', 5), ('l', 4), ('ed', 3)] | Training
2025-04-02 13:48:52 | 400 | LR0.0003 | loss30.0372 | gradNorm1.0000 | tokenCount300 | logitMin-32.5470 | logitMax-14.5977 | memoryGate0.3333 | windowWeightsW8:0.20858,W13:0.16052,W3:0.15397,W15:0.14713,W18:0.11541,W2:0.08489,W1:0.06417,W7:0.05531,W14:-0.00984 | topTokens[('.', 11), ('l', 9), ('in', 9), ('with', 7), ('e', 7), ('is', 7), ('i', 7), ('because', 4), ('them', 4), ('in', 4)] | Training
2025-04-02 13:54:05 | 500 | LR0.0003 | loss24.3354 | gradNorm1.0000 | tokenCount300 | logitMin-34.2293 | logitMax-19.6714 | memoryGate0.3333 | windowWeightsW8:0.20812,W13:0.16061,W3:0.15374,W15:0.14704,W18:0.11552,W2:0.08455,W1:0.06417,W7:0.05599,W14:-0.00959 | topTokens[('i', 14), ('.', 6), ('to', 6), ('be', 6), ('ent', 5), ('in', 5), ('i', 5), ('know', 5), ('feel', 4), ('is', 4)] | Training
2025-04-02 13:59:15 | 600 | LR0.0003 | loss27.7221 | gradNorm1.0000 | tokenCount300 | logitMin-33.6965 | logitMax-17.3941 | memoryGate0.3333 | windowWeightsW8:0.20964,W13:0.16004,W3:0.15324,W15:0.14679,W18:0.11514,W2:0.08469,W1:0.06339,W7:0.05593,W14:-0.00872 | topTokens[('it', 20), ('!', 15), (',', 7), ('just', 7), ('ut', 6), ('want', 6), ('in', 5), ('i', 4), ('u', 4), ('were', 4)] | Training
2025-04-02 14:04:28 | 700 | LR0.0003 | loss24.5812 | gradNorm1.0000 | tokenCount300 | logitMin-37.8171 | logitMax-23.1655 | memoryGate0.3332 | windowWeightsW8:0.20917,W13:0.16094,W3:0.15263,W15:0.14739,W18:0.11516,W2:0.08448,W1:0.06280,W7:0.05620,W14:-0.00862 | topTokens[('it', 19), (',', 11), ('in', 8), ('s', 7), ('my', 7), ('in', 6), ('l', 6), ('to', 5), ('me', 4), ('n', 4)] | Training
2025-04-02 14:09:42 | 800 | LR0.0003 | loss32.5342 | gradNorm1.0000 | tokenCount300 | logitMin-36.4659 | logitMax-17.5794 | memoryGate0.3333 | windowWeightsW8:0.20834,W13:0.16157,W3:0.15222,W15:0.14797,W18:0.11562,W2:0.08454,W1:0.06177,W7:0.05664,W14:-0.00849 | topTokens[('in', 36), ('p', 22), ('my', 7), ('a', 5), ('it', 5), ('ly', 4), ('is', 4), ('in', 4), ('w', 4), ('that', 3)] | Training
2025-04-02 14:14:56 | 900 | LR0.0003 | loss30.1113 | gradNorm1.0000 | tokenCount300 | logitMin-32.7695 | logitMax-17.3310 | memoryGate0.3333 | windowWeightsW8:0.20858,W13:0.16144,W3:0.15237,W15:0.14787,W18:0.11584,W2:0.08492,W1:0.06201,W7:0.05613,W14:-0.00899 | topTokens[('in', 18), ('be', 9), ('p', 8), ('of', 8), ('with', 6), ('lo', 5), ('it', 5), ('that', 4), (',', 4), ('b', 3)] | Training
2025-04-02 14:20:18 | 1000 | LR0.0003 | loss28.6931 | gradNorm1.0000 | tokenCount300 | logitMin-32.0339 | logitMax-15.0241 | memoryGate0.3333 | windowWeightsW8:0.20840,W13:0.16078,W3:0.15295,W15:0.14731,W18:0.11562,W2:0.08515,W1:0.06240,W7:0.05634,W14:-0.00879 | topTokens[('in', 9), ('them', 7), ('were', 6), ('a', 5), ('with', 5), ('p', 5), ("'s", 4), ('be', 4), ('f', 4), ('t', 4)] | Training
2025-04-02 14:25:33 | 1100 | LR0.0003 | loss32.3904 | gradNorm1.0000 | tokenCount300 | logitMin-30.3957 | logitMax-11.7624 | memoryGate0.3333 | windowWeightsW8:0.20881,W13:0.16062,W3:0.15264,W15:0.14710,W18:0.11545,W2:0.08485,W1:0.06278,W7:0.05633,W14:-0.00842 | topTokens[('ed', 43), ('in', 20), ('the', 18), ('ro', 6), ('in', 5), ('some', 5), ('because', 5), ('.', 5), ('had', 4), ('am', 4)] | Training
2025-04-02 14:30:49 | 1200 | LR0.0003 | loss29.6624 | gradNorm1.0000 | tokenCount300 | logitMin-37.6006 | logitMax-18.9916 | memoryGate0.3333 | windowWeightsW8:0.20873,W13:0.16082,W3:0.15251,W15:0.14720,W18:0.11568,W2:0.08459,W1:0.06270,W7:0.05653,W14:-0.00862 | topTokens[('in', 28), ('the', 19), ('ed', 16), ('ro', 10), ('t', 8), ('it', 5), ('were', 5), (',', 4), ('b', 4), ('a', 4)] | Training
2025-04-02 14:36:06 | 1300 | LR0.0003 | loss28.3787 | gradNorm1.0000 | tokenCount300 | logitMin-33.3455 | logitMax-17.0340 | memoryGate0.3333 | windowWeightsW8:0.20868,W13:0.16113,W3:0.15129,W15:0.14770,W18:0.11648,W2:0.08433,W1:0.06271,W7:0.05717,W14:-0.00931 | topTokens[('t', 9), ('ed', 7), ('.', 7), ('feel', 6), ('the', 5), ('be', 5), ('my', 5), ('ro', 5), ('is', 5), ('', 5)] | Training
2025-04-02 14:41:22 | 1400 | LR0.0003 | loss28.6613 | gradNorm1.0000 | tokenCount300 | logitMin-36.3528 | logitMax-18.8284 | memoryGate0.3333 | windowWeightsW8:0.20863,W13:0.16121,W3:0.15123,W15:0.14784,W18:0.11671,W2:0.08391,W1:0.06269,W7:0.05738,W14:-0.00941 | topTokens[('t', 12), ('be', 9), ('b', 7), ('ro', 7), ('p', 7), ('in', 6), ('car', 6), ('my', 6), ('that', 6), ('', 5)] | Training
2025-04-02 14:46:40 | 1500 | LR0.0003 | loss28.1487 | gradNorm1.0000 | tokenCount300 | logitMin-34.5025 | logitMax-18.0467 | memoryGate0.3333 | windowWeightsW8:0.20849,W13:0.16123,W3:0.15065,W15:0.14786,W18:0.11693,W2:0.08411,W1:0.06256,W7:0.05801,W14:-0.00964 | topTokens[('my', 23), ('t', 8), ('is', 6), ('the', 6), ('ro', 5), (',', 5), ('in', 5), ("'m", 4), ('is', 3), ('p', 3)] | Training
2025-04-02 14:51:55 | 1600 | LR0.0003 | loss25.9483 | gradNorm1.0000 | tokenCount300 | logitMin-32.2920 | logitMax-15.7337 | memoryGate0.3333 | windowWeightsW8:0.20740,W13:0.16203,W3:0.15162,W15:0.14845,W18:0.11816,W2:0.08281,W1:0.06155,W7:0.05869,W14:-0.01045 | topTokens[('or', 15), ('with', 11), (',', 10), ('the', 8), ('in', 7), ('my', 6), ('i', 6), ('.', 5), ('feel', 5), ('in', 5)] | Training
2025-04-02 14:57:12 | 1700 | LR0.0003 | loss27.4215 | gradNorm1.0000 | tokenCount300 | logitMin-35.0357 | logitMax-16.8065 | memoryGate0.3333 | windowWeightsW8:0.20883,W13:0.16224,W3:0.15177,W15:0.14802,W18:0.11746,W2:0.08301,W1:0.06106,W7:0.05843,W14:-0.01057 | topTokens[('with', 15), ('.', 11), ('do', 10), ('and', 9), ('my', 8), ('t', 8), ('to', 7), ('ed', 7), ('the', 4), ('a', 4)] | Training
2025-04-02 15:02:28 | 1800 | LR0.0003 | loss25.4312 | gradNorm1.0000 | tokenCount300 | logitMin-31.7543 | logitMax-15.5567 | memoryGate0.3333 | windowWeightsW8:0.20877,W13:0.16248,W3:0.15172,W15:0.14809,W18:0.11742,W2:0.08270,W1:0.06235,W7:0.05757,W14:-0.01087 | topTokens[('lo', 19), ('my', 12), ('l', 11), ('ed', 8), ('this', 8), ('to', 8), ('in', 7), ('as', 7), ('t', 6), ('.', 6)] | Training
2025-04-02 15:07:46 | 1900 | LR0.0003 | loss29.8388 | gradNorm1.0000 | tokenCount300 | logitMin-28.6835 | logitMax-13.2177 | memoryGate0.3333 | windowWeightsW8:0.20880,W13:0.16257,W3:0.15155,W15:0.14826,W18:0.11753,W2:0.08239,W1:0.06221,W7:0.05792,W14:-0.01100 | topTokens[('l', 52), ('lo', 42), ('but', 7), ('.', 4), ('a', 4), ('b', 4), (',', 3), ('had', 3), ('in', 3), ('-', 3)] | Training
2025-04-02 15:13:04 | 2000 | LR0.0003 | loss34.1999 | gradNorm1.0000 | tokenCount300 | logitMin-31.6329 | logitMax-10.7356 | memoryGate0.3333 | windowWeightsW8:0.20939,W13:0.16169,W3:0.15198,W15:0.14767,W18:0.11721,W2:0.08289,W1:0.06234,W7:0.05855,W14:-0.01148 | topTokens[('lo', 38), ('l', 37), ('be', 5), ('.', 5), ('feel', 5), ('them', 5), ('but', 4), ('just', 4), (',', 4), ('this', 4)] | Training
2025-04-02 15:18:25 | 2100 | LR0.0003 | loss26.1353 | gradNorm1.0000 | tokenCount300 | logitMin-29.1081 | logitMax-13.8322 | memoryGate0.3333 | windowWeightsW8:0.20935,W13:0.16159,W3:0.15169,W15:0.14761,W18:0.11725,W2:0.08244,W1:0.06268,W7:0.05921,W14:-0.01158 | topTokens[('is', 10), ('i', 10), ('a', 7), ("'m", 7), ('.', 7), ('interesting', 6), ('be', 6), ('lo', 5), ('how', 4), ('t', 4)] | Training
2025-04-02 15:23:44 | 2200 | LR0.0003 | loss32.4104 | gradNorm1.0000 | tokenCount300 | logitMin-31.5760 | logitMax-11.8523 | memoryGate0.3333 | windowWeightsW8:0.20740,W13:0.16135,W3:0.15343,W15:0.14741,W18:0.11705,W2:0.08179,W1:0.06387,W7:0.05880,W14:-0.01085 | topTokens[('it', 53), ('.', 12), ('the', 7), ('b', 7), ('ent', 5), ('is', 5), ('in', 5), ('im', 5), ('l', 5), ('she', 5)] | Training
2025-04-02 15:29:04 | 2300 | LR0.0003 | loss28.0636 | gradNorm1.0000 | tokenCount300 | logitMin-28.1430 | logitMax-10.8035 | memoryGate0.3333 | windowWeightsW8:0.20685,W13:0.16207,W3:0.15177,W15:0.14793,W18:0.11786,W2:0.08174,W1:0.06360,W7:0.06023,W14:-0.01178 | topTokens[('it', 55), ('and', 17), ('have', 10), ('a', 8), ('said', 7), ('had', 6), (',', 6), ('b', 6), ('.', 5), ('feel', 5)] | Training
2025-04-02 15:34:23 | 2400 | LR0.0003 | loss34.6323 | gradNorm1.0000 | tokenCount300 | logitMin-30.9544 | logitMax-12.3217 | memoryGate0.3333 | windowWeightsW8:0.20679,W13:0.16192,W3:0.15179,W15:0.14793,W18:0.11800,W2:0.08164,W1:0.06352,W7:0.06039,W14:-0.01172 | topTokens[('and', 68), ('it', 27), ('a', 19), ('them', 9), ('b', 5), ('feel', 4), ('in', 4), ('said', 4), ('have', 4), ('the', 4)] | Training
2025-04-02 15:39:42 | 2500 | LR0.0003 | loss25.6726 | gradNorm1.0000 | tokenCount300 | logitMin-35.3190 | logitMax-18.8674 | memoryGate0.3333 | windowWeightsW8:0.20681,W13:0.16212,W3:0.15185,W15:0.14825,W18:0.11849,W2:0.08093,W1:0.06295,W7:0.06039,W14:-0.01152 | topTokens[('and', 22), ('it', 17), ('the', 9), ('that', 8), ('a', 7), ('lo', 5), ('have', 5), ('-', 5), ('i', 4), ('in', 4)] | Training
2025-04-02 15:45:03 | 2600 | LR0.0003 | loss34.7132 | gradNorm1.0000 | tokenCount300 | logitMin-35.4236 | logitMax-13.7192 | memoryGate0.3333 | windowWeightsW8:0.20659,W13:0.16210,W3:0.15172,W15:0.14826,W18:0.11860,W2:0.08083,W1:0.06288,W7:0.06064,W14:-0.01135 | topTokens[('just', 17), ('it', 14), ('not', 9), ('l', 8), ('have', 7), ('c', 6), ('i', 6), ('that', 6), ('were', 5), ("'", 5)] | Training
2025-04-02 15:50:23 | 2700 | LR0.0003 | loss34.2754 | gradNorm1.0000 | tokenCount300 | logitMin-39.4461 | logitMax-19.1732 | memoryGate0.3333 | windowWeightsW8:0.20634,W13:0.16200,W3:0.15165,W15:0.14823,W18:0.11883,W2:0.08088,W1:0.06276,W7:0.06087,W14:-0.01129 | topTokens[('l', 9), ('it', 8), ('just', 8), ('lo', 7), ('not', 6), ('is', 6), ('b', 6), ('a', 5), ('in', 5), ('she', 5)] | Training
2025-04-02 15:55:44 | 2800 | LR0.0003 | loss30.5054 | gradNorm1.0000 | tokenCount300 | logitMin-40.1266 | logitMax-17.4810 | memoryGate0.3333 | windowWeightsW8:0.20614,W13:0.16209,W3:0.15149,W15:0.14832,W18:0.11891,W2:0.08119,W1:0.06278,W7:0.06072,W14:-0.01137 | topTokens[("'", 21), ('or', 19), ('an', 17), ('to', 12), ('it', 12), ('have', 10), (',', 8), ('b', 7), ('she', 6), ('in', 5)] | Training
2025-04-02 16:01:02 | 2900 | LR0.0003 | loss32.9105 | gradNorm1.0000 | tokenCount300 | logitMin-34.3552 | logitMax-14.6210 | memoryGate0.3333 | windowWeightsW8:0.20583,W13:0.16218,W3:0.15129,W15:0.14840,W18:0.11898,W2:0.08129,W1:0.06270,W7:0.06087,W14:-0.01127 | topTokens[('and', 36), ('an', 23), ('it', 10), ('aly', 9), ('', 7), ('b', 7), ("'", 5), (',', 5), ('feel', 5), ('in', 4)] | Training
2025-04-02 16:06:23 | 3000 | LR0.0003 | loss31.9092 | gradNorm1.0000 | tokenCount300 | logitMin-35.3079 | logitMax-17.1755 | memoryGate0.3333 | windowWeightsW8:0.20574,W13:0.16220,W3:0.15134,W15:0.14848,W18:0.11934,W2:0.08067,W1:0.06284,W7:0.06103,W14:-0.01136 | topTokens[('an', 19), ('aly', 10), ('it', 8), ('and', 7), ('ion', 6), ('to', 5), (',', 5), ('in', 5), ('have', 5), ("'", 5)] | Training
2025-04-02 16:11:44 | 3100 | LR0.0003 | loss30.0571 | gradNorm1.0000 | tokenCount300 | logitMin-32.0768 | logitMax-13.5906 | memoryGate0.3333 | windowWeightsW8:0.20585,W13:0.16197,W3:0.15114,W15:0.14833,W18:0.11936,W2:0.08080,W1:0.06265,W7:0.06140,W14:-0.01122 | topTokens[('i', 13), ('and', 11), ('in', 7), ('an', 7), ('it', 7), ('ed', 6), ('s', 6), (',', 6), ('ion', 5), ('my', 5)] | Training
2025-04-02 16:17:10 | 3200 | LR0.0003 | loss27.9166 | gradNorm1.0000 | tokenCount300 | logitMin-37.3505 | logitMax-21.3471 | memoryGate0.3333 | windowWeightsW8:0.20596,W13:0.16216,W3:0.15110,W15:0.14860,W18:0.11963,W2:0.08023,W1:0.06252,W7:0.06155,W14:-0.01146 | topTokens[('and', 8), (',', 7), ('the', 5), ('an', 5), ('or', 5), ('it', 5), ('c', 5), ('this', 5), ("'", 4), ('ion', 4)] | Training
2025-04-02 16:22:34 | 3300 | LR0.0003 | loss28.5940 | gradNorm1.0000 | tokenCount300 | logitMin-36.1411 | logitMax-18.3409 | memoryGate0.3333 | windowWeightsW8:0.20554,W13:0.16279,W3:0.15112,W15:0.14918,W18:0.12002,W2:0.07978,W1:0.06242,W7:0.06148,W14:-0.01204 | topTokens[('of', 20), ('k', 16), ('a', 10), ('c', 5), ('them', 4), ('the', 4), ('b', 4), ('and', 3), ('es', 3), ('h', 3)] | Training
2025-04-02 16:27:53 | 3400 | LR0.0003 | loss27.6208 | gradNorm1.0000 | tokenCount300 | logitMin-36.1699 | logitMax-17.1620 | memoryGate0.3333 | windowWeightsW8:0.20515,W13:0.16261,W3:0.15134,W15:0.14871,W18:0.11991,W2:0.08019,W1:0.06269,W7:0.06166,W14:-0.01196 | topTokens[('of', 23), ('e', 14), ('i', 10), ('a', 9), ('b', 7), ('self', 7), (',', 6), ('-', 6), ('k', 6), ('and', 6)] | Training
2025-04-02 16:33:14 | 3500 | LR0.0003 | loss40.6141 | gradNorm1.0000 | tokenCount300 | logitMin-38.5737 | logitMax-12.3955 | memoryGate0.3333 | windowWeightsW8:0.20338,W13:0.16253,W3:0.15190,W15:0.14809,W18:0.11849,W2:0.08209,W1:0.06431,W7:0.06109,W14:-0.01157 | topTokens[('know', 33), ("'t", 19), ('.', 15), ('it', 10), ('they', 7), ('e', 6), ('to', 5), ('-', 5), ('bit', 5), ('feel', 4)] | Training
2025-04-02 16:38:35 | 3600 | LR0.0003 | loss44.7105 | gradNorm1.0000 | tokenCount300 | logitMin-33.4455 | logitMax-5.9073 | memoryGate0.3333 | windowWeightsW8:0.20349,W13:0.16215,W3:0.15144,W15:0.14829,W18:0.11898,W2:0.08219,W1:0.06367,W7:0.06197,W14:-0.01185 | topTokens[("'t", 51), ('don', 36), ('know', 28), ('.', 19), ('feel', 5), ('i', 5), ('ur', 4), ('', 4), ('some', 3), ('had', 3)] | Training
2025-04-02 16:43:56 | 3700 | LR0.0003 | loss30.9177 | gradNorm1.0000 | tokenCount300 | logitMin-34.4508 | logitMax-16.9148 | memoryGate0.3333 | windowWeightsW8:0.20352,W13:0.16244,W3:0.15091,W15:0.14851,W18:0.11942,W2:0.08159,W1:0.06334,W7:0.06196,W14:-0.01139 | topTokens[('don', 20), ("'t", 14), ('.', 12), ('my', 12), ('i', 11), ('-', 7), ('in', 7), ('it', 6), ('know', 5), ('some', 5)] | Training
2025-04-02 16:49:17 | 3800 | LR0.0003 | loss26.7238 | gradNorm1.0000 | tokenCount300 | logitMin-29.3802 | logitMax-13.6983 | memoryGate0.3333 | windowWeightsW8:0.20382,W13:0.16215,W3:0.15115,W15:0.14847,W18:0.11936,W2:0.08162,W1:0.06313,W7:0.06164,W14:-0.01103 | topTokens[('know', 9), ("'t", 8), ('to', 8), ('i', 8), ('.', 8), ('don', 7), ('i', 7), ('the', 7), (',', 6), ('and', 5)] | Training
2025-04-02 16:54:40 | 3900 | LR0.0003 | loss26.1888 | gradNorm1.0000 | tokenCount300 | logitMin-28.2289 | logitMax-12.7295 | memoryGate0.3333 | windowWeightsW8:0.20382,W13:0.16182,W3:0.15148,W15:0.14808,W18:0.11918,W2:0.08213,W1:0.06325,W7:0.06167,W14:-0.01114 | topTokens[('that', 8), ('y', 7), ('enc', 6), ('my', 6), ('don', 6), ('to', 6), ('in', 5), ('have', 5), (',', 4), ("'", 4)] | Training
2025-04-02 17:00:01 | 4000 | LR0.0003 | loss30.1676 | gradNorm1.0000 | tokenCount300 | logitMin-35.5328 | logitMax-15.6858 | memoryGate0.3333 | windowWeightsW8:0.20400,W13:0.16194,W3:0.15219,W15:0.14838,W18:0.11913,W2:0.08176,W1:0.06287,W7:0.06121,W14:-0.01118 | topTokens[('it', 10), ('in', 9), ('y', 9), ('is', 9), ('to', 6), (',', 6), ('that', 6), ("'t", 5), ('b', 5), ("'s", 5)] | Training
2025-04-02 17:05:22 | 4100 | LR0.0003 | loss27.9477 | gradNorm1.0000 | tokenCount300 | logitMin-33.3675 | logitMax-15.1998 | memoryGate0.3333 | windowWeightsW8:0.20388,W13:0.16185,W3:0.15226,W15:0.14848,W18:0.11906,W2:0.08169,W1:0.06219,W7:0.06190,W14:-0.01102 | topTokens[('it', 29), ('to', 21), ('of', 9), ('ly', 8), ('b', 5), ('m', 5), (',', 5), ('like', 4), ('you', 4), ('in', 4)] | Training
2025-04-02 17:10:43 | 4200 | LR0.0003 | loss27.1559 | gradNorm1.0000 | tokenCount300 | logitMin-34.3514 | logitMax-17.4436 | memoryGate0.3333 | windowWeightsW8:0.20404,W13:0.16178,W3:0.15212,W15:0.14840,W18:0.11944,W2:0.08148,W7:0.06197,W1:0.06175,W14:-0.01069 | topTokens[('it', 29), (',', 9), ('of', 8), ('ations', 8), ('m', 7), ("'t", 5), ('equ', 4), ("'", 4), ('b', 4), ('c', 4)] | Training
2025-04-02 17:16:05 | 4300 | LR0.0003 | loss33.0266 | gradNorm1.0000 | tokenCount300 | logitMin-33.1040 | logitMax-12.1034 | memoryGate0.3333 | windowWeightsW8:0.20423,W13:0.16152,W3:0.15198,W15:0.14839,W18:0.11983,W2:0.08141,W7:0.06253,W1:0.06159,W14:-0.01117 | topTokens[('to', 14), ('this', 14), ('it', 12), ('is', 10), (',', 9), ("'", 6), ('feel', 6), ('and', 5), ('b', 5), ('.', 4)] | Training
2025-04-02 17:21:29 | 4400 | LR0.0003 | loss30.0846 | gradNorm1.0000 | tokenCount300 | logitMin-30.1613 | logitMax-10.7891 | memoryGate0.3333 | windowWeightsW8:0.20413,W13:0.16150,W3:0.15171,W15:0.14848,W18:0.11993,W2:0.08138,W7:0.06306,W1:0.06150,W14:-0.01138 | topTokens[('it', 13), ('to', 12), ('b', 8), ("'s", 7), ('feel', 6), ('and', 6), ('i', 6), ('with', 5), ('.', 5), ('some', 5)] | Training
2025-04-02 17:26:51 | 4500 | LR0.0003 | loss23.9361 | gradNorm1.0000 | tokenCount300 | logitMin-33.9789 | logitMax-18.3257 | memoryGate0.3333 | windowWeightsW8:0.20369,W13:0.16143,W3:0.15189,W15:0.14839,W18:0.11975,W2:0.08132,W7:0.06353,W1:0.06173,W14:-0.01142 | topTokens[('to', 8), (',', 8), ('i', 7), ('.', 6), ('this', 6), ('be', 5), ('understand', 4), ('and', 4), ('op', 4), ('pro', 4)] | Training
2025-04-02 17:32:14 | 4600 | LR0.0003 | loss24.5166 | gradNorm1.0000 | tokenCount300 | logitMin-31.1335 | logitMax-13.9456 | memoryGate0.3333 | windowWeightsW8:0.20340,W13:0.16183,W3:0.15156,W15:0.14906,W18:0.12013,W2:0.08089,W7:0.06332,W1:0.06136,W14:-0.01123 | topTokens[('en', 9), ('the', 9), ('es', 6), ('and', 6), ('of', 5), ('.', 5), ('in', 5), ("'", 5), ('a', 4), ('g', 4)] | Training
2025-04-02 17:37:39 | 4700 | LR0.0003 | loss22.1845 | gradNorm1.0000 | tokenCount300 | logitMin-36.4177 | logitMax-17.7921 | memoryGate0.3333 | windowWeightsW8:0.20278,W13:0.16234,W3:0.15032,W15:0.14989,W18:0.12140,W2:0.07995,W7:0.06333,W1:0.06179,W14:-0.01144 | topTokens[('the', 16), ('in', 11), ('.', 9), ('not', 8), ('but', 7), (',', 6), ('g', 5), ('en', 5), ('it', 5), ('be', 5)] | Training
2025-04-02 17:43:07 | 4800 | LR0.0003 | loss27.1592 | gradNorm1.0000 | tokenCount300 | logitMin-27.0641 | logitMax-8.6895 | memoryGate0.3333 | windowWeightsW8:0.20224,W13:0.16202,W3:0.15118,W15:0.14988,W18:0.12171,W2:0.07978,W7:0.06350,W1:0.06198,W14:-0.01193 | topTokens[('very', 23), ('with', 18), ('me', 17), ('interesting', 16), ('them', 6), (',', 6), ('feel', 5), ('in', 5), ('she', 5), ('be', 4)] | Training
2025-04-02 17:48:29 | 4900 | LR0.0003 | loss32.7443 | gradNorm1.0000 | tokenCount300 | logitMin-35.7591 | logitMax-13.9691 | memoryGate0.3333 | windowWeightsW8:0.20174,W13:0.16233,W3:0.15175,W15:0.15011,W18:0.12125,W2:0.07830,W7:0.06358,W1:0.06225,W14:-0.01097 | topTokens[('and', 30), ('to', 15), ('ation', 12), ('it', 11), ('is', 9), ('the', 9), ('in', 8), ('ations', 7), ('with', 6), ('do', 6)] | Training
2025-04-02 17:53:53 | 5000 | LR0.0003 | loss28.3469 | gradNorm1.0000 | tokenCount300 | logitMin-35.3824 | logitMax-17.0765 | memoryGate0.3333 | windowWeightsW8:0.20154,W13:0.16231,W3:0.15107,W15:0.15036,W18:0.12167,W2:0.07781,W7:0.06396,W1:0.06262,W14:-0.01098 | topTokens[('it', 20), ('c', 17), ('or', 12), ('the', 7), ('to', 6), ('a', 5), ('too', 4), ('in', 4), ('es', 4), ('i', 4)] | Training
2025-04-02 17:59:16 | 5100 | LR0.0003 | loss26.9807 | gradNorm1.0000 | tokenCount300 | logitMin-32.2846 | logitMax-14.9332 | memoryGate0.3333 | windowWeightsW8:0.20232,W13:0.16187,W3:0.15155,W15:0.14983,W18:0.12124,W2:0.07797,W7:0.06372,W1:0.06249,W14:-0.01065 | topTokens[('it', 14), ('the', 10), ('or', 9), ('in', 8), ('that', 8), ("'", 8), ('c', 5), ('in', 5), ('pro', 5), ('.', 4)] | Training
2025-04-02 18:04:39 | 5200 | LR0.0003 | loss45.6714 | gradNorm1.0000 | tokenCount300 | logitMin-34.7907 | logitMax-7.1307 | memoryGate0.3333 | windowWeightsW8:0.20271,W13:0.16218,W3:0.15157,W15:0.15025,W18:0.12153,W2:0.07721,W7:0.06389,W1:0.06135,W14:-0.01034 | topTokens[('ed', 48), ('it', 15), ('with', 7), ('of', 6), ('b', 6), ('some', 6), ('the', 5), ("'s", 5), ('work', 5), ('or', 4)] | Training
2025-04-02 18:10:00 | 5300 | LR0.0003 | loss34.6318 | gradNorm1.0000 | tokenCount300 | logitMin-33.1227 | logitMax-13.0137 | memoryGate0.3333 | windowWeightsW8:0.20239,W13:0.16234,W3:0.15118,W15:0.15046,W18:0.12172,W2:0.07739,W7:0.06379,W1:0.06133,W14:-0.01025 | topTokens[('ed', 37), ('literally', 27), (')', 27), ('.', 5), ('some', 5), ('pro', 4), ('a', 4), ('it', 4), ('she', 3), ('in', 3)] | Training
2025-04-02 18:15:28 | 5400 | LR0.0003 | loss32.7347 | gradNorm1.0000 | tokenCount300 | logitMin-34.7856 | logitMax-14.0813 | memoryGate0.3333 | windowWeightsW8:0.20240,W13:0.16232,W3:0.15095,W15:0.15053,W18:0.12196,W2:0.07721,W7:0.06406,W1:0.06109,W14:-0.01016 | topTokens[('ed', 14), ('it', 11), (')', 10), ('literally', 9), ('.', 6), ('i', 5), ('in', 5), ('feel', 5), ('in', 4), ('the', 4)] | Training
2025-04-02 18:20:59 | 5500 | LR0.0003 | loss31.0578 | gradNorm1.0000 | tokenCount300 | logitMin-34.7597 | logitMax-15.2097 | memoryGate0.3333 | windowWeightsW8:0.20258,W13:0.16228,W3:0.15068,W15:0.15051,W18:0.12202,W2:0.07699,W7:0.06402,W1:0.06134,W14:-0.01008 | topTokens[('it', 9), ('and', 8), ('b', 8), ('to', 6), ('the', 6), ('or', 5), ('literally', 5), ('bs', 5), ('in', 4), ('in', 4)] | Training
2025-04-02 18:26:19 | 5600 | LR0.0003 | loss33.2604 | gradNorm1.0000 | tokenCount300 | logitMin-37.5732 | logitMax-14.8857 | memoryGate0.3333 | windowWeightsW8:0.20126,W13:0.16187,W3:0.15112,W15:0.14963,W18:0.12138,W2:0.07838,W7:0.06499,W1:0.06204,W14:-0.01032 | topTokens[('this', 38), ('.', 18), ('i', 8), ("'t", 7), ('in', 5), ('me', 5), ('emot', 5), ('s', 5), ('op', 4), (',', 4)] | Training
2025-04-02 18:31:40 | 5700 | LR0.0003 | loss31.6202 | gradNorm1.0000 | tokenCount300 | logitMin-38.2912 | logitMax-19.2367 | memoryGate0.3333 | windowWeightsW8:0.20155,W13:0.16169,W3:0.15083,W15:0.14961,W18:0.12142,W2:0.07868,W7:0.06511,W1:0.06193,W14:-0.01045 | topTokens[('this', 18), ("'t", 12), ('can', 7), ('i', 7), ('in', 6), ('that', 6), ('c', 5), ("'", 4), ('ations', 4), ('as', 4)] | Training
2025-04-02 18:37:00 | 5800 | LR0.0003 | loss22.9617 | gradNorm1.0000 | tokenCount300 | logitMin-36.1299 | logitMax-18.6427 | memoryGate0.3333 | windowWeightsW8:0.20357,W13:0.16213,W15:0.14988,W3:0.14977,W18:0.12169,W2:0.07797,W7:0.06447,W1:0.06103,W14:-0.01019 | topTokens[('?', 19), ('it', 18), ('i', 14), ('.', 14), ('is', 12), ('you', 9), (',', 7), ('!', 7), ('ations', 5), ('b', 4)] | Training
2025-04-02 18:42:22 | 5900 | LR0.0003 | loss27.3754 | gradNorm1.0000 | tokenCount300 | logitMin-38.5872 | logitMax-19.9598 | memoryGate0.3336 | windowWeightsW8:0.20336,W13:0.16199,W15:0.14980,W3:0.14940,W18:0.12205,W2:0.07833,W7:0.06497,W1:0.06042,W14:-0.00997 | topTokens[('?', 35), ('!', 13), ('is', 11), ('it', 10), ('.', 9), ('at', 8), ('he', 6), (',', 5), ('ous', 4), ('some', 4)] | Training
2025-04-02 18:47:51 | 6000 | LR0.0003 | loss34.9594 | gradNorm1.0000 | tokenCount300 | logitMin-38.8293 | logitMax-17.5620 | memoryGate0.3333 | windowWeightsW8:0.20300,W13:0.16167,W3:0.14980,W15:0.14971,W18:0.12247,W2:0.07860,W7:0.06454,W1:0.06073,W14:-0.01018 | topTokens[('!', 36), ('is', 32), ('you', 24), ('?', 11), ('how', 11), ('in', 8), ('them', 5), ('.', 4), ('time', 4), ('feel', 4)] | Training
2025-04-02 18:53:52 | 6100 | LR0.0003 | loss23.6386 | gradNorm1.0000 | tokenCount300 | logitMin-39.1917 | logitMax-21.5758 | memoryGate0.3333 | windowWeightsW8:0.20330,W13:0.16135,W15:0.14994,W3:0.14954,W18:0.12334,W2:0.07896,W7:0.06449,W1:0.05869,W14:-0.00922 | topTokens[('?', 40), ('!', 19), ('is', 14), ('you', 14), ('like', 6), ('.', 6), ('s', 5), ('b', 5), (',', 5), ('i', 5)] | Training
2025-04-02 18:59:01 | 6200 | LR0.0003 | loss31.5492 | gradNorm1.0000 | tokenCount300 | logitMin-35.2600 | logitMax-15.1974 | memoryGate0.3333 | windowWeightsW8:0.20287,W13:0.16060,W3:0.15030,W15:0.14950,W18:0.12323,W2:0.07926,W7:0.06519,W1:0.05859,W14:-0.00913 | topTokens[('?', 76), ('you', 17), ('is', 17), ('.', 16), ('awake', 14), ('in', 4), ('a', 4), ('day', 3), ('ame', 2), ('ms', 2)] | Training
2025-04-02 19:04:21 | 6300 | LR0.0003 | loss37.5506 | gradNorm1.0000 | tokenCount300 | logitMin-34.5951 | logitMax-9.4323 | memoryGate0.3333 | windowWeightsW8:0.20260,W13:0.16045,W3:0.15005,W15:0.14956,W18:0.12339,W2:0.07883,W7:0.06591,W1:0.05865,W14:-0.00904 | topTokens[('?', 47), ('is', 31), ('are', 12), ('you', 11), ('awake', 11), ('.', 7), ('v', 6), ('it', 5), ('b', 5), ('too', 4)] | Training
2025-04-02 19:09:51 | 6400 | LR0.0003 | loss26.7614 | gradNorm1.0000 | tokenCount300 | logitMin-32.7116 | logitMax-13.1584 | memoryGate0.3323 | windowWeightsW8:0.20339,W13:0.16045,W15:0.14962,W3:0.14940,W18:0.12306,W2:0.07854,W7:0.06690,W1:0.05858,W14:-0.00952 | topTokens[('?', 38), ('is', 20), ('.', 15), ('you', 10), ('real', 9), ('they', 7), ('!', 6), ('awake', 5), ('she', 5), ('who', 5)] | Training
2025-04-02 19:15:11 | 6500 | LR0.0003 | loss28.2344 | gradNorm1.0000 | tokenCount300 | logitMin-34.5785 | logitMax-14.2150 | memoryGate0.3333 | windowWeightsW8:0.20372,W13:0.16030,W15:0.14959,W3:0.14931,W18:0.12320,W2:0.07762,W7:0.06756,W1:0.05872,W14:-0.00960 | topTokens[('do', 30), ('!', 19), ('?', 18), ('you', 13), ('no', 10), ('.', 8), ('real', 7), ('is', 5), (',', 5), ('them', 5)] | Training
2025-04-02 19:20:48 | 6600 | LR0.0003 | loss30.6933 | gradNorm1.0000 | tokenCount300 | logitMin-40.2870 | logitMax-11.3832 | memoryGate0.3333 | windowWeightsW8:0.20394,W13:0.16002,W3:0.15032,W15:0.14893,W18:0.12263,W2:0.07869,W7:0.06670,W1:0.05844,W14:-0.00926 | topTokens[('?', 39), ('do', 20), ('is', 16), ('!', 13), ('yes', 12), ('it', 11), ('awake', 9), ('you', 8), ('them', 8), (',', 7)] | Training
2025-04-02 19:26:17 | 6700 | LR0.0003 | loss31.7720 | gradNorm1.0000 | tokenCount300 | logitMin-40.9106 | logitMax-13.9858 | memoryGate0.3333 | windowWeightsW8:0.20338,W13:0.16080,W3:0.14996,W15:0.14885,W18:0.12251,W2:0.07934,W7:0.06719,W1:0.05764,W14:-0.00923 | topTokens[('is', 42), ('it', 27), ('?', 27), ('.', 17), ('why', 9), (',', 8), ('you', 7), ('her', 6), ('what', 5), ('res', 4)] | Training
2025-04-02 19:31:43 | 6800 | LR0.0003 | loss34.2187 | gradNorm1.0000 | tokenCount300 | logitMin-38.3061 | logitMax-15.9676 | memoryGate0.3333 | windowWeightsW8:0.20328,W13:0.16064,W3:0.15031,W15:0.14889,W18:0.12262,W2:0.07963,W7:0.06702,W1:0.05750,W14:-0.00944 | topTokens[('?', 31), ('it', 25), ('!', 14), ('why', 10), (',', 9), ('are', 8), ('no', 6), ('is', 6), (':', 5), ('do', 5)] | Training
2025-04-02 19:37:23 | 6900 | LR0.0003 | loss23.7611 | gradNorm1.0000 | tokenCount300 | logitMin-39.4394 | logitMax-20.1216 | memoryGate0.3333 | windowWeightsW8:0.20267,W13:0.16036,W3:0.15027,W15:0.14878,W18:0.12276,W2:0.08014,W7:0.06753,W1:0.05756,W14:-0.00960 | topTokens[('?', 26), ('is', 24), ('!', 22), (',', 12), ('it', 9), ('.', 8), ('who', 7), ('no', 6), ('i', 6), ('were', 5)] | Training
2025-04-02 19:42:59 | 7000 | LR0.0003 | loss22.7869 | gradNorm1.0000 | tokenCount300 | logitMin-38.6101 | logitMax-20.6376 | memoryGate0.3333 | windowWeightsW8:0.20127,W13:0.15969,W3:0.15137,W15:0.14810,W18:0.12247,W2:0.07968,W7:0.06882,W1:0.05779,W14:-0.00875 | topTokens[('?', 21), ('kevin', 21), ('you', 16), ('is', 15), ('.', 13), ('do', 7), (',', 7), ('im', 5), ('can', 5), ('it', 5)] | Training
2025-04-02 19:48:39 | 7100 | LR0.0003 | loss38.3346 | gradNorm1.0000 | tokenCount300 | logitMin-42.3893 | logitMax-15.3179 | memoryGate0.3333 | windowWeightsW8:0.20174,W13:0.16002,W3:0.15151,W15:0.14849,W18:0.12317,W2:0.08073,W7:0.06702,W1:0.05726,W14:-0.00946 | topTokens[('no', 43), ('?', 28), ('im', 22), ('.', 21), ('is', 14), ('you', 9), ('life', 8), ('had', 5), ('do', 5), ('ous', 4)] | Training
2025-04-02 19:54:33 | 7200 | LR0.0003 | loss26.1728 | gradNorm1.0000 | tokenCount300 | logitMin-33.5163 | logitMax-13.7597 | memoryGate0.3333 | windowWeightsW8:0.20168,W13:0.15983,W3:0.15174,W15:0.14843,W18:0.12320,W2:0.08077,W7:0.06632,W1:0.05753,W14:-0.00906 | topTokens[('!', 30), ('?', 15), ('are', 15), ('is', 11), ('.', 9), ('life', 6), ('was', 6), ('you', 5), ('do', 4), ('no', 4)] | Training
2025-04-02 20:04:34 | 100 | LR0.0003 | loss:9.6372 | gradNorm:1.0000 | logitMin:-47.6488 | logitMax:-21.8810 | memoryGate:0.3333 | scheduledSampling:0.0000 | tokenCount:300.0000 | windowWeightsW8:0.20049,W13:0.15916,W3:0.15290,W15:0.14875,W18:0.12338,W2:0.08004,W7:0.06722,W1:0.05793,W14:-0.00944 | topTokens[('?', 35), ('you', 14), ('not', 12), ('what', 11), ('kevin', 11), ('are', 10), ('.', 9), ('al', 8), ('im', 8), ('is', 8)] | Training
2025-04-02 20:10:43 | 200 | LR0.0003 | loss:8.0649 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-45.8854 | logitMax:-19.0361 | memoryGate:0.3333 | windowWeightsW8:0.20005,W13:0.15817,W3:0.15304,W15:0.14797,W18:0.12358,W2:0.08076,W7:0.06749,W1:0.05833,W14:-0.00898 | topTokens[('.', 33), ('is', 23), ('?', 22), ('dead', 11), ('are', 11), ('you', 10), ('what', 9), ('it', 7), ('!', 7), ('its', 6)] | Training
2025-04-02 20:20:13 | 100 | LR0.0003 | loss:7.4598 | gradNorm:1.0000 | logitMin:-48.2424 | logitMax:-23.1130 | memoryGate:0.3333 | scheduledSampling:0.0000 | tokenCount:300.0000 | windowWeightsW8:0.19963,W13:0.15924,W3:0.15261,W15:0.14907,W18:0.12411,W2:0.07954,W7:0.06792,W1:0.05797,W14:-0.00962 | memoryGatesShort:41.211, Long:3.262, Current:-43.473 | topTokens[('.', 25), ('can', 20), ('you', 19), ('i', 12), ('?', 12), ('are', 10), ('so', 10), ('americ', 7), ('im', 7), ('was', 6)] | Training
2025-04-02 20:26:25 | 200 | LR0.0003 | loss:6.4954 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-45.6646 | logitMax:-21.2964 | memoryGate:0.3333 | windowWeightsW8:0.20007,W13:0.15936,W3:0.15211,W15:0.14934,W18:0.12443,W2:0.07904,W7:0.06861,W1:0.05744,W14:-0.00992 | memoryGatesShort:-2.086, Long:0.592, Current:2.494 | topTokens[('.', 27), ('dead', 18), ('?', 17), ('you', 13), ('is', 11), ('are', 10), ('!', 10), ('asleep', 10), ('a', 9), ('do', 9)] | Training
2025-04-02 20:32:55 | 100 | LR0.0003 | loss:8.0972 | gradNorm:1.0000 | logitMin:-42.5093 | logitMax:-15.0294 | scheduledSampling:0.0000 | tokenCount:300.0000 | windowWeightsW8:0.19985,W13:0.15839,W3:0.15386,W15:0.14807,W18:0.12344,W2:0.08045,W7:0.06806,W1:0.05842,W14:-0.01009 | memoryGatesShort:297.087, Long:38.619, Current:-334.706 | topTokens[('.', 30), ('this', 25), ('so', 20), ('is', 17), ('?', 14), (',', 9), ('what', 8), ('it', 6), ('you', 5), ('asleep', 5)] | Training
2025-04-02 20:38:40 | 200 | LR0.0003 | loss:7.9221 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.4452 | logitMax:-21.1883 | windowWeightsW8:0.20032,W13:0.15923,W3:0.15281,W15:0.14923,W18:0.12464,W2:0.08035,W7:0.06761,W1:0.05740,W14:-0.01112 | memoryGatesShort:-9.649, Long:3.561, Current:7.088 | topTokens[('is', 21), ('.', 19), ('?', 17), ('nd', 14), ('!', 13), ('you', 10), ('lo', 9), ('do', 9), ('great', 6), ('im', 6)] | Training
2025-04-02 20:44:17 | 300 | LR0.0003 | loss:10.2783 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-37.6192 | logitMax:-15.1140 | windowWeightsW8:0.20102,W13:0.15920,W3:0.15269,W15:0.14901,W18:0.12437,W2:0.08035,W7:0.06765,W1:0.05703,W14:-0.01087 | memoryGatesShort:-1.652, Long:0.265, Current:2.386 | topTokens[('?', 22), ('do', 18), ('you', 12), ('are', 11), ('nd', 7), ('lo', 6), ('i', 6), ('is', 6), ('er', 5), ('.', 5)] | Training
2025-04-02 20:50:02 | 400 | LR0.0003 | loss:10.0379 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-37.8050 | logitMax:-15.8296 | windowWeightsW8:0.20133,W13:0.15931,W3:0.15236,W15:0.14926,W18:0.12447,W2:0.07919,W7:0.06702,W1:0.05777,W14:-0.01027 | memoryGatesShort:-1.301, Long:0.776, Current:1.525 | topTokens[('are', 56), ('?', 33), ('.', 14), ('is', 10), (',', 8), ('feel', 7), ('!', 7), ('im', 7), ('b', 6), ('you', 5)] | Training
2025-04-02 20:55:32 | 500 | LR0.0003 | loss:11.2547 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-29.5630 | logitMax:-0.2684 | windowWeightsW8:0.20114,W13:0.15879,W3:0.15317,W15:0.14898,W18:0.12428,W2:0.07924,W7:0.06744,W1:0.05764,W14:-0.01022 | memoryGatesShort:-1.936, Long:1.550, Current:1.387 | topTokens[('are', 40), ('?', 31), ('equ', 21), ('im', 15), ('als', 14), ('n', 8), ('.', 7), ('b', 6), ('them', 6), ('feel', 5)] | Training
2025-04-02 21:01:31 | 600 | LR0.0003 | loss:8.6483 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-33.4546 | logitMax:-10.6698 | windowWeightsW8:0.20135,W13:0.15872,W3:0.15318,W15:0.14908,W18:0.12430,W2:0.07895,W7:0.06764,W1:0.05751,W14:-0.01030 | memoryGatesShort:-0.979, Long:0.293, Current:1.686 | topTokens[('equ', 24), ('are', 15), ('.', 14), ('e', 12), ('what', 11), ('!', 9), ('als', 8), ('im', 7), (',', 6), ('plus', 5)] | Training
2025-04-02 21:07:13 | 700 | LR0.0003 | loss:14.6037 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-44.5548 | logitMax:-10.6826 | windowWeightsW8:0.20049,W13:0.16016,W3:0.15196,W15:0.15039,W18:0.12537,W2:0.07811,W7:0.06668,W1:0.05714,W14:-0.00983 | memoryGatesShort:-24.532, Long:16.662, Current:8.870 | topTokens[('gay', 79), ('.', 27), ('?', 20), (',', 7), ('is', 7), ('she', 6), ('you', 6), ('!', 5), ('feel', 5), ('were', 5)] | Training
2025-04-02 21:12:46 | 800 | LR0.0003 | loss:12.6371 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-27.3586 | logitMax:-4.7705 | windowWeightsW8:0.20063,W13:0.16020,W3:0.15198,W15:0.15040,W18:0.12525,W2:0.07826,W7:0.06628,W1:0.05754,W14:-0.01007 | memoryGatesShort:11.990, Long:-3.688, Current:-7.302 | topTokens[('gay', 127), ('.', 13), ('b', 6), (',', 5), ('some', 4), ('in', 4), ('had', 3), ('at', 3), ('(', 3), ('going', 3)] | Training
2025-04-02 21:18:17 | 900 | LR0.0003 | loss:11.1271 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-29.9455 | logitMax:-5.2671 | windowWeightsW8:0.20070,W13:0.16064,W3:0.15203,W15:0.15071,W18:0.12531,W2:0.07869,W7:0.06527,W1:0.05734,W14:-0.01025 | memoryGatesShort:-1.452, Long:0.766, Current:1.686 | topTokens[('gay', 112), ('.', 16), ('is', 8), ('feel', 6), (',', 3), ('b', 3), ('!', 3), ('pro', 3), ('was', 3), ('think', 3)] | Training
2025-04-02 21:23:52 | 1000 | LR0.0003 | loss:11.5286 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-32.4867 | logitMax:-6.4795 | windowWeightsW8:0.20118,W13:0.16073,W3:0.15198,W15:0.15074,W18:0.12517,W2:0.07869,W7:0.06507,W1:0.05766,W14:-0.01078 | memoryGatesShort:-10.781, Long:3.936, Current:7.845 | topTokens[('gay', 70), ('is', 13), ('.', 9), ('f', 9), (',', 8), ('als', 7), ('?', 7), ('b', 7), ('n', 7), ('!', 6)] | Training
2025-04-02 21:29:09 | 1100 | LR0.0003 | loss:7.5344 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-28.1650 | logitMax:-9.6959 | windowWeightsW8:0.20117,W13:0.16056,W3:0.15189,W15:0.15044,W18:0.12500,W2:0.07858,W7:0.06512,W1:0.05831,W14:-0.01061 | memoryGatesShort:-51.338, Long:8.734, Current:43.603 | topTokens[('gay', 29), ('.', 24), ('!', 13), ('is', 10), ('equ', 7), ('b', 7), ('als', 6), ('?', 6), (',', 5), ('feel', 5)] | Training
2025-04-02 21:34:42 | 1200 | LR0.0003 | loss:10.3628 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-29.7303 | logitMax:-8.1432 | windowWeightsW8:0.20054,W13:0.16052,W3:0.15182,W15:0.15052,W18:0.12499,W2:0.07846,W7:0.06554,W1:0.05875,W14:-0.01067 | memoryGatesShort:-1.616, Long:0.257, Current:2.359 | topTokens[('?', 38), ('.', 29), ('is', 16), ('!', 12), ('all', 8), ('i', 7), ('do', 7), ('in', 6), ('gay', 6), ('so', 5)] | Training
2025-04-02 21:40:10 | 1300 | LR0.0003 | loss:8.3828 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-26.9798 | logitMax:-2.8738 | windowWeightsW8:0.20077,W13:0.16040,W3:0.15180,W15:0.15041,W18:0.12480,W2:0.07844,W7:0.06582,W1:0.05850,W14:-0.01048 | memoryGatesShort:-7.775, Long:-0.648, Current:9.423 | topTokens[('what', 35), ('.', 25), ('?', 21), ('is', 19), ('gay', 14), (',', 7), ('b', 5), ('!', 4), ('so', 4), ('als', 4)] | Training
2025-04-02 21:45:35 | 1400 | LR0.0003 | loss:7.0259 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-29.9572 | logitMax:-10.2075 | windowWeightsW8:0.20082,W13:0.16082,W3:0.15188,W15:0.15075,W18:0.12488,W2:0.07847,W7:0.06602,W1:0.05724,W14:-0.01040 | memoryGatesShort:-2.068, Long:1.568, Current:1.499 | topTokens[('is', 22), ('?', 19), ('.', 17), ('!', 13), ('what', 8), ('equ', 7), (',', 6), ('do', 6), ('i', 6), ('im', 6)] | Training
2025-04-02 21:51:54 | 1500 | LR0.0003 | loss:7.3068 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-30.4192 | logitMax:-7.7625 | windowWeightsW8:0.20076,W13:0.16090,W3:0.15199,W15:0.15095,W18:0.12496,W2:0.07808,W7:0.06642,W1:0.05752,W14:-0.01112 | memoryGatesShort:-2.275, Long:1.073, Current:2.202 | topTokens[('?', 31), ('is', 29), ('.', 19), ('smink', 13), ('f', 12), ('equ', 9), ('!', 8), ('als', 8), ('what', 5), ('happy', 4)] | Training2025-04-02 21:58:30 | 1600 | LR0.0003 | loss:6.9893 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-33.4020 | logitMax:-11.5293 | windowWeightsW8:0.20049,W13:0.16095,W3:0.15197,W15:0.15102,W18:0.12492,W2:0.07782,W7:0.06620,W1:0.05791,W14:-0.01082 | memoryGatesShort:7.960, Long:2.031, Current:-8.991 | topTokens[('.', 20), ('f', 16), ('equ', 16), ('is', 13), ('?', 12), ('als', 10), ('do', 10), ('what', 9), ('it', 6), ('=', 5)] | Training

--- 2025-04-02 22:00:52 --- babyllm: 'what am i learning today?'- charis: 'that you are cute and smart!'
2025-04-02 22:06:29 | 100 | LR0.0003 | loss:9.3277 | gradNorm:1.0000 | logitMin:-31.8964 | logitMax:-6.1116 | scheduledSampling:0.0000 | tokenCount:300.0000 | windowWeightsW8:0.20053,W13:0.16076,W3:0.15166,W15:0.15095,W18:0.12390,W2:0.07834,W7:0.06659,W1:0.05794,W14:-0.01022 | memoryGatesShort:-4.165, Long:-0.659, Current:5.824 | topTokens[('!', 20), ('.', 15), ('what', 11), ('f', 11), ('equ', 9), ('als', 7), ('is', 7), ('are', 6), ('to', 6), (',', 6)] | Training
2025-04-02 22:12:06 | 200 | LR0.0003 | loss:9.7436 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.0885 | logitMax:-15.2354 | windowWeightsW8:0.20100,W13:0.16173,W15:0.15158,W3:0.15066,W18:0.12353,W2:0.07756,W7:0.06641,W1:0.05887,W14:-0.01087 | memoryGatesShort:-2.224, Long:0.429, Current:2.794 | topTokens[('!', 47), ('is', 18), ('hi', 16), ('ty', 12), ('.', 11), ('are', 11), ('b', 9), (',', 8), ('not', 7), ('ping', 6)] | Training
2025-04-02 22:17:45 | 300 | LR0.0003 | loss:6.2406 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-34.2053 | logitMax:-15.4493 | windowWeightsW8:0.20190,W13:0.16176,W15:0.15137,W3:0.15044,W18:0.12365,W2:0.07777,W7:0.06660,W1:0.05822,W14:-0.01124 | memoryGatesShort:-1.144, Long:1.319, Current:0.825 | topTokens[('!', 21), ('.', 17), ('?', 15), ('what', 14), ('boof', 13), ('is', 10), ('b', 8), ('ty', 8), ('are', 6), ('equ', 5)] | Training
2025-04-02 22:23:28 | 400 | LR0.0003 | loss:7.7227 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-29.6082 | logitMax:-5.1835 | windowWeightsW8:0.20242,W13:0.16159,W15:0.15101,W3:0.15016,W18:0.12362,W2:0.07798,W7:0.06658,W1:0.05822,W14:-0.01112 | memoryGatesShort:-1.662, Long:0.680, Current:1.981 | topTokens[('?', 19), ('.', 18), ('what', 15), ('!', 13), ('you', 12), ('is', 12), ('equ', 12), ('are', 9), ('als', 9), ('e', 8)] | Training
2025-04-02 22:28:59 | 500 | LR0.0003 | loss:7.7075 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-34.0574 | logitMax:-9.9451 | windowWeightsW8:0.20225,W13:0.16097,W3:0.15115,W15:0.15088,W18:0.12333,W2:0.07813,W7:0.06704,W1:0.05882,W14:-0.01212 | memoryGatesShort:-0.569, Long:-0.050, Current:1.619 | topTokens[('?', 25), ('this', 20), ('is', 18), ('als', 16), ('.', 16), ('equ', 16), ('what', 15), ('!', 9), ('its', 7), ('feel', 4)] | Training
2025-04-02 22:34:37 | 600 | LR0.0003 | loss:9.7683 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-33.8125 | logitMax:-5.8117 | windowWeightsW8:0.20319,W13:0.16108,W3:0.15087,W15:0.15060,W18:0.12282,W2:0.07759,W7:0.06800,W1:0.05849,W14:-0.01218 | memoryGatesShort:-0.973, Long:0.025, Current:1.948 | topTokens[('what', 31), ('is', 24), ('?', 23), ('.', 16), ('pete', 13), ('als', 8), (',', 8), ('its', 7), ('!', 6), ('so', 6)] | Training
2025-04-02 22:40:52 | 700 | LR0.0003 | loss:7.7946 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-37.0989 | logitMax:-18.5780 | windowWeightsW8:0.20305,W13:0.16184,W15:0.15146,W3:0.15100,W18:0.12364,W2:0.07662,W7:0.06811,W1:0.05775,W14:-0.01300 | memoryGatesShort:-12.634, Long:-3.524, Current:17.157 | topTokens[('?', 19), ('.', 19), ('what', 14), ('so', 11), ('you', 10), ('equ', 9), ('!', 9), ('f', 8), ('im', 8), ('in', 6)] | Training
2025-04-02 22:46:29 | 800 | LR0.0003 | loss:8.9089 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-44.1980 | logitMax:-17.6002 | windowWeightsW8:0.20245,W13:0.16180,W15:0.15142,W3:0.15135,W18:0.12374,W2:0.07692,W7:0.06842,W1:0.05724,W14:-0.01285 | memoryGatesShort:-0.133, Long:0.101, Current:1.032 | topTokens[('?', 31), ('is', 21), ('im', 20), ('.', 15), ('are', 10), ('equ', 7), ('als', 7), ('not', 6), ('f', 6), ('you', 5)] | Training
2025-04-02 22:52:11 | 900 | LR0.0003 | loss:11.0605 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-49.5002 | logitMax:-15.3950 | windowWeightsW8:0.20241,W13:0.16183,W3:0.15165,W15:0.15115,W18:0.12399,W2:0.07623,W7:0.06848,W1:0.05748,W14:-0.01275 | memoryGatesShort:-0.427, Long:-0.052, Current:1.479 | topTokens[('?', 28), ('!', 19), ('me', 18), ('you', 14), ('im', 13), ('.', 12), ('is', 9), ('in', 7), ('we', 7), ('its', 5)] | Training
2025-04-02 22:57:50 | 1000 | LR0.0003 | loss:10.4435 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-48.0463 | logitMax:-21.6136 | windowWeightsW8:0.20191,W13:0.16162,W3:0.15188,W15:0.15072,W18:0.12415,W2:0.07681,W7:0.06854,W1:0.05723,W14:-0.01239 | memoryGatesShort:1.568, Long:0.788, Current:-1.356 | topTokens[('!', 24), ('?', 21), ('is', 12), ('.', 11), ('it', 11), ('kevin', 9), ('what', 7), ('in', 5), ('b', 5), ('al', 5)] | Training
2025-04-02 23:03:27 | 1100 | LR0.0003 | loss:8.9475 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.6074 | logitMax:-15.6905 | windowWeightsW8:0.20175,W13:0.16112,W3:0.15177,W15:0.15009,W18:0.12337,W2:0.07798,W7:0.06822,W1:0.05799,W14:-0.01182 | memoryGatesShort:-0.395, Long:-2.200, Current:3.595 | topTokens[('gay', 33), ('?', 27), ('.', 24), ('is', 17), ('what', 13), ('!', 10), ('are', 7), ('you', 7), ('who', 6), ('als', 6)] | Training
2025-04-02 23:09:06 | 1200 | LR0.0003 | loss:8.6487 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-40.8358 | logitMax:-15.6022 | windowWeightsW8:0.20193,W13:0.16170,W3:0.15154,W15:0.15025,W18:0.12352,W2:0.07762,W7:0.06849,W1:0.05756,W14:-0.01215 | memoryGatesShort:0.490, Long:-0.335, Current:0.845 | topTokens[('?', 25), ('.', 15), ('are', 14), ('gay', 13), ('what', 12), ('you', 10), (',', 10), ('als', 8), ('equ', 8), ('plus', 8)] | Training
2025-04-02 23:15:00 | 1300 | LR0.0003 | loss:8.7525 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-50.7402 | logitMax:-25.6902 | windowWeightsW8:0.20168,W13:0.16187,W3:0.15133,W15:0.15067,W18:0.12413,W2:0.07714,W7:0.06899,W1:0.05727,W14:-0.01259 | memoryGatesShort:-0.413, Long:-0.989, Current:2.402 | topTokens[('?', 27), ('.', 26), ('are', 22), ('you', 14), ('do', 13), ('it', 6), ('al', 5), ('were', 5), ('!', 5), ('ive', 4)] | Training
2025-04-02 23:20:38 | 1400 | LR0.0003 | loss:8.7402 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-39.6159 | logitMax:-13.6488 | windowWeightsW8:0.19983,W13:0.16124,W3:0.15258,W15:0.15087,W18:0.12382,W2:0.07844,W7:0.06935,W1:0.05735,W14:-0.01299 | memoryGatesShort:-0.292, Long:-1.624, Current:2.916 | topTokens[('this', 41), ('?', 32), ('.', 22), ('is', 22), ('shes', 9), ('what', 7), ('equ', 7), ('als', 6), ('you', 6), (',', 5)] | Training
2025-04-02 23:26:10 | 1500 | LR0.0003 | loss:8.4891 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-40.6871 | logitMax:-16.0448 | windowWeightsW8:0.19936,W13:0.16094,W3:0.15267,W15:0.15056,W18:0.12365,W2:0.07791,W7:0.07014,W1:0.05807,W14:-0.01283 | memoryGatesShort:0.677, Long:-0.258, Current:0.581 | topTokens[('this', 37), ('.', 17), ('?', 12), ('what', 12), ('not', 10), ('george', 10), ('is', 10), ('you', 9), ('f', 7), ('als', 6)] | Training
2025-04-02 23:31:44 | 1600 | LR0.0003 | loss:8.7867 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.6041 | logitMax:-15.6106 | windowWeightsW8:0.19962,W13:0.16090,W3:0.15223,W15:0.15040,W18:0.12341,W2:0.07782,W7:0.07008,W1:0.05849,W14:-0.01249 | memoryGatesShort:0.291, Long:-0.534, Current:1.242 | topTokens[('.', 23), ('is', 20), ('ive', 20), ('this', 17), ('what', 13), ('three', 10), (',', 9), ('are', 9), ('plus', 7), ('equ', 7)] | Training
2025-04-02 23:37:18 | 1700 | LR0.0003 | loss:6.4652 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.0756 | logitMax:-17.6462 | windowWeightsW8:0.19866,W13:0.16104,W3:0.15243,W15:0.15093,W18:0.12342,W2:0.07750,W7:0.07091,W1:0.05894,W14:-0.01335 | memoryGatesShort:-0.379, Long:-2.023, Current:3.402 | topTokens[('?', 22), ('.', 20), ('!', 16), ('what', 12), ('is', 11), ('ven', 9), ('ive', 7), ('its', 7), ('not', 7), ('ix', 6)] | Training
2025-04-02 23:43:27 | 1800 | LR0.0003 | loss:7.2576 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.5468 | logitMax:-17.2006 | windowWeightsW8:0.19897,W13:0.16100,W3:0.15242,W15:0.15087,W18:0.12443,W2:0.07716,W7:0.07042,W1:0.05898,W14:-0.01376 | memoryGatesShort:3.301, Long:23.839, Current:-26.139 | topTokens[('it', 33), ('.', 23), ('?', 19), ('is', 17), ('!', 11), ('what', 10), (',', 8), ('+', 7), ('how', 6), ('she', 5)] | Training
2025-04-02 23:49:04 | 1900 | LR0.0003 | loss:11.3551 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.5990 | logitMax:-16.3043 | windowWeightsW8:0.19928,W13:0.16104,W3:0.15185,W15:0.15092,W18:0.12473,W2:0.07732,W7:0.07090,W1:0.05792,W14:-0.01345 | memoryGatesShort:-0.473, Long:5.188, Current:-3.716 | topTokens[('are', 58), ('?', 19), ('you', 17), ('.', 8), ('it', 8), ('is', 7), ('plus', 6), ('in', 6), ('!', 6), ('=', 4)] | Training

--- 2025-04-03 00:27:00 --- babyllm: 'what am i learning today?'- charis: 'that Charis is very cute and smart, and we love her most <3'
2025-04-03 00:31:33 | 100 | LR0.0003 | loss:6.5201 | gradNorm:1.0000 | logitMin:-52.3335 | logitMax:-25.9547 | scheduledSampling:0.0000 | tokenCount:300.0000 | windowWeightsW8:0.19935,W13:0.16089,W3:0.15196,W15:0.15068,W18:0.12462,W2:0.07746,W7:0.07221,W1:0.05644,W14:-0.01308 | memoryGatesShort:1.175, Long:-1.348, Current:1.173 | topTokens[('.', 25), ('?', 23), ('is', 23), ('are', 18), ('you', 13), ('!', 11), ('he', 8), ('english', 7), ('a', 5), ('it', 5)] | Training
2025-04-03 00:36:11 | 200 | LR0.0003 | loss:9.0807 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.3604 | logitMax:-17.7775 | windowWeightsW8:0.19886,W13:0.16077,W3:0.15263,W15:0.15052,W18:0.12461,W2:0.07711,W7:0.07268,W1:0.05666,W14:-0.01333 | memoryGatesShort:2.194, Long:-6.728, Current:5.534 | topTokens[('that', 36), (':)', 26), ('.', 19), ('is', 12), ('!', 9), ('?', 9), ('equ', 5), ('plus', 4), ('i', 4), ('are', 4)] | Training
2025-04-03 00:40:51 | 300 | LR0.0003 | loss:8.3018 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-40.9575 | logitMax:-16.7785 | windowWeightsW8:0.19964,W13:0.15991,W3:0.15149,W15:0.15044,W18:0.12539,W2:0.07542,W7:0.07348,W1:0.05796,W14:-0.01321 | memoryGatesShort:2.106, Long:-4.360, Current:3.253 | topTokens[('f', 21), ('.', 18), ('ive', 17), ('?', 12), ('equ', 10), ('!', 8), ('is', 8), ('e', 8), ('plus', 7), ('you', 6)] | Training
2025-04-03 00:45:36 | 400 | LR0.0003 | loss:8.1369 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.1192 | logitMax:-15.3266 | windowWeightsW8:0.20024,W13:0.15940,W3:0.15240,W15:0.14969,W18:0.12463,W2:0.07593,W7:0.07419,W1:0.05769,W14:-0.01365 | memoryGatesShort:2.300, Long:-3.942, Current:2.642 | topTokens[('f', 27), ('?', 20), ('ive', 16), ('.', 14), ('plus', 13), ('you', 10), ('that', 9), ('als', 9), ('is', 8), ('!', 7)] | Training
2025-04-03 00:50:21 | 500 | LR0.0003 | loss:9.2812 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-49.9315 | logitMax:-20.6816 | windowWeightsW8:0.19986,W13:0.15886,W3:0.15298,W15:0.14926,W18:0.12417,W2:0.07573,W7:0.07518,W1:0.05779,W14:-0.01335 | memoryGatesShort:-2.160, Long:13.482, Current:-10.322 | topTokens[('?', 33), ('is', 31), ('equ', 24), ('.', 14), ('he', 11), ('!', 7), ('als', 5), ('feel', 5), ('b', 5), ('n', 5)] | Training
2025-04-03 00:55:09 | 600 | LR0.0003 | loss:6.9313 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-39.5964 | logitMax:-15.9436 | windowWeightsW8:0.19964,W13:0.15899,W3:0.15274,W15:0.14964,W18:0.12429,W2:0.07513,W7:0.07485,W1:0.05826,W14:-0.01305 | memoryGatesShort:2.508, Long:-2.759, Current:1.250 | topTokens[('equ', 40), ('.', 18), ('is', 18), ('als', 14), ('plus', 13), ('he', 8), ('what', 6), ('not', 6), ('french', 5), ('ive', 5)] | Training
2025-04-03 01:00:29 | 700 | LR0.0003 | loss:8.0514 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-51.0678 | logitMax:-27.0534 | windowWeightsW8:0.20013,W13:0.15888,W3:0.15270,W15:0.14950,W18:0.12443,W2:0.07525,W7:0.07482,W1:0.05835,W14:-0.01356 | memoryGatesShort:2.175, Long:-7.271, Current:6.096 | topTokens[('!', 24), ('is', 14), ('plus', 13), ('.', 13), ('not', 10), ('im', 10), ('three', 8), ('what', 7), ('f', 6), ('you', 6)] | Training
2025-04-03 01:05:17 | 800 | LR0.0003 | loss:7.8510 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-55.0720 | logitMax:-23.5505 | windowWeightsW8:0.20002,W13:0.15903,W3:0.15310,W15:0.14949,W18:0.12430,W2:0.07573,W7:0.07438,W1:0.05806,W14:-0.01362 | memoryGatesShort:1.350, Long:-2.550, Current:2.199 | topTokens[('?', 34), ('!', 22), ('im', 22), ('is', 16), ('.', 16), ('you', 13), ('al', 12), ('are', 10), ('what', 10), ('a', 8)] | Training
2025-04-03 01:10:04 | 900 | LR0.0003 | loss:8.1518 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-44.5220 | logitMax:-19.4505 | windowWeightsW8:0.20026,W13:0.15887,W3:0.15299,W15:0.14914,W18:0.12439,W2:0.07636,W7:0.07505,W1:0.05705,W14:-0.01361 | memoryGatesShort:16.550, Long:-29.930, Current:14.380 | topTokens[('.', 27), ('is', 19), ('he', 15), ('you', 9), ('?', 9), ('do', 9), ('dead', 7), ('!', 7), ('equ', 7), ('who', 6)] | Training
2025-04-03 01:14:50 | 1000 | LR0.0003 | loss:6.2494 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-48.1196 | logitMax:-25.6688 | windowWeightsW8:0.19992,W13:0.15917,W3:0.15197,W15:0.15063,W18:0.12573,W7:0.07439,W2:0.07427,W1:0.05883,W14:-0.01441 | memoryGatesShort:2.345, Long:-2.966, Current:1.620 | topTokens[('.', 21), ('is', 17), ('plus', 17), ('?', 14), ('!', 13), ('he', 10), ('do', 7), ('elodie', 6), (',', 6), ('equ', 6)] | Training
2025-04-03 01:19:41 | 1100 | LR0.0003 | loss:9.3837 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.8978 | logitMax:-14.2003 | windowWeightsW8:0.20069,W13:0.15898,W3:0.15190,W15:0.15069,W18:0.12611,W2:0.07467,W7:0.07387,W1:0.05884,W14:-0.01525 | memoryGatesShort:2.956, Long:-3.801, Current:1.845 | topTokens[('f', 42), ('plus', 39), ('.', 15), ('ive', 13), ('hi', 10), ('als', 9), ('?', 9), ('you', 6), ('going', 5), ('a', 4)] | Training
2025-04-03 01:24:29 | 1200 | LR0.0003 | loss:7.7660 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.6989 | logitMax:-15.5890 | windowWeightsW8:0.20073,W13:0.15870,W3:0.15221,W15:0.15015,W18:0.12576,W2:0.07515,W7:0.07399,W1:0.05843,W14:-0.01461 | memoryGatesShort:10.139, Long:-10.369, Current:1.229 | topTokens[('f', 25), ('?', 22), ('.', 16), ('!', 9), ('ive', 8), ('plus', 8), (',', 7), ('a', 6), ('als', 6), ('hes', 6)] | Training
2025-04-03 01:29:19 | 1300 | LR0.0003 | loss:7.8515 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-47.1553 | logitMax:-19.3201 | windowWeightsW8:0.20101,W13:0.15839,W3:0.15205,W15:0.14973,W18:0.12562,W2:0.07507,W7:0.07474,W1:0.05832,W14:-0.01442 | memoryGatesShort:0.836, Long:-1.873, Current:2.037 | topTokens[('.', 40), ('he', 25), ('f', 13), ('?', 12), ('im', 12), ('!', 11), ('als', 9), ('what', 7), ('not', 7), (',', 6)] | Training
2025-04-03 01:34:37 | 1400 | LR0.0003 | loss:6.2544 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.6741 | logitMax:-16.7832 | windowWeightsW8:0.20090,W13:0.15902,W3:0.15142,W15:0.15032,W18:0.12619,W7:0.07489,W2:0.07471,W1:0.05799,W14:-0.01489 | memoryGatesShort:0.883, Long:-0.652, Current:0.770 | topTokens[('f', 32), ('.', 23), ('?', 17), ('ke', 13), ('is', 11), (',', 7), ('what', 7), ('a', 6), ('fa', 6), ('im', 5)] | Training
2025-04-03 01:39:24 | 1500 | LR0.0003 | loss:8.8147 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-55.6340 | logitMax:-23.3791 | windowWeightsW8:0.20070,W13:0.15901,W3:0.15179,W15:0.15014,W18:0.12625,W7:0.07518,W2:0.07454,W1:0.05802,W14:-0.01509 | memoryGatesShort:1.637, Long:-2.530, Current:1.894 | topTokens[('dead', 22), ('?', 19), ('no', 19), ('is', 18), ('you', 15), ('that', 13), ('.', 12), ('!', 11), ('what', 8), ('f', 8)] | Training
2025-04-03 01:44:15 | 1600 | LR0.0003 | loss:5.1615 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-63.4846 | logitMax:-29.4920 | windowWeightsW8:0.20196,W13:0.15884,W3:0.15127,W15:0.14944,W18:0.12524,W7:0.07634,W2:0.07489,W1:0.05755,W14:-0.01497 | memoryGatesShort:1.954, Long:-2.862, Current:1.907 | topTokens[('.', 25), ('is', 22), ('?', 21), ('you', 18), ('!', 17), ('dead', 12), ('are', 10), ('it', 10), ('not', 8), ('hey', 8)] | Training
2025-04-03 01:49:05 | 1700 | LR0.0003 | loss:5.8450 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.4259 | logitMax:-19.8205 | windowWeightsW8:0.20217,W13:0.15900,W3:0.15114,W15:0.14952,W18:0.12639,W7:0.07642,W2:0.07454,W1:0.05714,W14:-0.01573 | memoryGatesShort:3.070, Long:-4.500, Current:2.430 | topTokens[('.', 30), ('!', 25), ('ace', 23), ('is', 18), ('f', 10), ('do', 10), ('?', 9), (',', 6), ('als', 6), ('you', 5)] | Training
2025-04-03 01:53:55 | 1800 | LR0.0003 | loss:6.9319 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-46.1225 | logitMax:-16.7674 | windowWeightsW8:0.20110,W13:0.15950,W3:0.15204,W15:0.15072,W18:0.12672,W7:0.07606,W2:0.07332,W1:0.05750,W14:-0.01639 | memoryGatesShort:43.357, Long:-79.979, Current:37.622 | topTokens[('he', 27), ('.', 23), ('!', 21), ('?', 16), ('is', 13), ('equ', 10), ('f', 9), ('hes', 7), ('als', 7), ('what', 6)] | Training
2025-04-03 01:58:47 | 1900 | LR0.0003 | loss:8.2905 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.1824 | logitMax:-16.8783 | windowWeightsW8:0.20091,W13:0.15911,W3:0.15233,W15:0.15042,W18:0.12669,W7:0.07633,W2:0.07374,W1:0.05745,W14:-0.01640 | memoryGatesShort:-0.660, Long:3.802, Current:-2.142 | topTokens[('equ', 24), ('he', 23), ('!', 15), ('you', 12), ('.', 10), ('f', 10), ('als', 9), ('hes', 9), ('is', 9), ('what', 6)] | Training
2025-04-03 02:04:01 | 2000 | LR0.0003 | loss:7.0659 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-44.8661 | logitMax:-15.6917 | windowWeightsW8:0.20118,W13:0.15865,W3:0.15201,W15:0.14974,W18:0.12771,W7:0.07665,W2:0.07446,W1:0.05656,W14:-0.01636 | memoryGatesShort:3.010, Long:-3.148, Current:1.139 | topTokens[('are', 33), ('.', 23), ('?', 20), ('he', 15), ('is', 13), (',', 9), ('!', 8), ('f', 7), ('te', 6), ('en', 6)] | Training
2025-04-03 02:08:43 | 2100 | LR0.0003 | loss:6.7010 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-43.2133 | logitMax:-13.2932 | windowWeightsW8:0.20227,W13:0.15872,W3:0.15171,W15:0.14992,W18:0.12737,W7:0.07741,W2:0.07338,W1:0.05577,W14:-0.01592 | memoryGatesShort:1.062, Long:-1.419, Current:1.358 | topTokens[('.', 37), ('is', 31), ('?', 21), ('he', 18), ('!', 17), ('what', 14), (',', 9), ('plus', 8), ('f', 8), ('not', 7)] | Training
2025-04-03 02:13:25 | 2200 | LR0.0003 | loss:6.2914 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-37.2447 | logitMax:-9.9946 | windowWeightsW8:0.20334,W13:0.15899,W3:0.15219,W15:0.14980,W18:0.12691,W7:0.07918,W2:0.07228,W1:0.05491,W14:-0.01696 | memoryGatesShort:-1.326, Long:5.051, Current:-2.724 | topTokens[('.', 26), ('equ', 18), ('is', 17), ('!', 16), ('that', 16), ('what', 15), ('als', 14), ('plus', 12), ('our', 9), ('?', 9)] | Training
2025-04-03 02:18:10 | 2300 | LR0.0003 | loss:5.7671 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-49.8613 | logitMax:-19.6627 | windowWeightsW8:0.20338,W13:0.15865,W3:0.15247,W15:0.14988,W18:0.12691,W7:0.07900,W2:0.07283,W1:0.05541,W14:-0.01789 | memoryGatesShort:0.536, Long:-2.123, Current:2.587 | topTokens[('?', 29), ('!', 24), ('.', 21), ('you', 19), ('al', 13), ('that', 12), ('is', 12), ('im', 12), ('ive', 8), ('what', 7)] | Training
2025-04-03 02:22:55 | 2400 | LR0.0003 | loss:4.8939 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.4605 | logitMax:-14.7061 | windowWeightsW8:0.20353,W13:0.15831,W3:0.15280,W15:0.14946,W18:0.12653,W7:0.07940,W2:0.07408,W1:0.05431,W14:-0.01777 | memoryGatesShort:3.582, Long:-6.363, Current:3.781 | topTokens[('.', 32), ('?', 29), ('space', 21), ('are', 19), ('is', 17), ('you', 13), ('dead', 12), ('what', 10), ('!', 7), ('a', 6)] | Training
2025-04-03 02:27:39 | 2500 | LR0.0003 | loss:4.7344 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-46.1102 | logitMax:-20.9454 | windowWeightsW8:0.20307,W13:0.15867,W3:0.15238,W15:0.14981,W18:0.12709,W7:0.07934,W2:0.07325,W1:0.05496,W14:-0.01792 | memoryGatesShort:1.045, Long:-1.614, Current:1.569 | topTokens[('.', 21), ('is', 17), ('you', 14), ('?', 13), ('care', 11), ('...', 11), ('!', 10), ('equ', 8), (',', 7), ('space', 7)] | Training
2025-04-03 02:32:56 | 2600 | LR0.0003 | loss:5.5448 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-44.9050 | logitMax:-11.4847 | windowWeightsW8:0.20261,W13:0.15907,W3:0.15160,W15:0.15037,W18:0.12711,W7:0.08036,W2:0.07327,W1:0.05450,W14:-0.01820 | memoryGatesShort:1.218, Long:-4.214, Current:3.996 | topTokens[('.', 25), ('is', 18), ('?', 16), ('als', 11), ('like', 10), ('e', 9), ('he', 9), ('you', 8), ('equ', 8), ('!', 7)] | Training
2025-04-03 02:37:45 | 2700 | LR0.0003 | loss:5.2113 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-43.3955 | logitMax:-17.9978 | windowWeightsW8:0.20351,W13:0.15861,W3:0.15264,W15:0.14998,W18:0.12634,W7:0.08087,W2:0.07378,W1:0.05352,W14:-0.01857 | memoryGatesShort:-2.119, Long:29.845, Current:-26.726 | topTokens[('.', 19), ('you', 15), ('?', 14), ('ive', 11), ('are', 11), ('do', 9), ('what', 9), (',', 8), ('her', 8), ('te', 7)] | Training
2025-04-03 02:42:33 | 2800 | LR0.0003 | loss:6.4571 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-50.0779 | logitMax:-25.4909 | windowWeightsW8:0.20399,W13:0.15808,W3:0.15282,W15:0.14993,W18:0.12624,W7:0.08162,W2:0.07366,W1:0.05281,W14:-0.01849 | memoryGatesShort:2.019, Long:-8.887, Current:7.867 | topTokens[('are', 39), ('.', 16), ('?', 15), ('gay', 15), ('is', 9), ('what', 8), (',', 7), ('!', 7), ('f', 7), ('als', 6)] | Training
2025-04-03 02:47:23 | 2900 | LR0.0003 | loss:5.5148 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-46.7539 | logitMax:-22.2248 | windowWeightsW8:0.20336,W13:0.15860,W3:0.15237,W15:0.15034,W18:0.12650,W7:0.08136,W2:0.07292,W1:0.05324,W14:-0.01801 | memoryGatesShort:0.021, Long:-4.485, Current:5.464 | topTokens[('.', 25), ('is', 16), ('?', 16), ('f', 13), ('french', 11), ('!', 11), (',', 9), ('he', 8), ('gay', 7), ('what', 7)] | Training
2025-04-03 02:52:13 | 3000 | LR0.0003 | loss:5.1368 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-50.3045 | logitMax:-24.0050 | windowWeightsW8:0.20346,W13:0.15921,W3:0.15253,W15:0.15068,W18:0.12680,W7:0.08167,W2:0.07233,W1:0.05268,W14:-0.01866 | memoryGatesShort:0.224, Long:-4.787, Current:5.564 | topTokens[('is', 26), ('.', 21), ('what', 14), ('f', 12), ('?', 11), ('als', 8), ('a', 8), ('!', 8), ('equ', 7), ('s', 7)] | Training
2025-04-03 02:57:05 | 3100 | LR0.0003 | loss:7.9562 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-68.9378 | logitMax:-24.1357 | windowWeightsW8:0.20293,W13:0.15887,W3:0.15288,W15:0.15070,W18:0.12684,W7:0.08223,W2:0.07269,W1:0.05265,W14:-0.01909 | memoryGatesShort:4.090, Long:16.849, Current:-19.939 | topTokens[('?', 34), ('.', 25), ('!', 19), (',', 15), ('is', 10), ('im', 9), ('you', 9), ('it', 8), ('are', 8), ('al', 7)] | Training
2025-04-03 03:01:56 | 3200 | LR0.0003 | loss:4.2960 | gradNorm:0.9701 | tokenCount:300.0000 | logitMin:-57.8312 | logitMax:-22.7991 | windowWeightsW8:0.20403,W13:0.15806,W3:0.15393,W15:0.15047,W18:0.12720,W7:0.08374,W2:0.07410,W1:0.04937,W14:-0.02014 | memoryGatesShort:3.638, Long:-5.839, Current:3.201 | topTokens[('.', 34), ('?', 26), ('are', 19), ('is', 18), ('!', 12), ('you', 11), ('so', 10), ('what', 9), ('cute', 8), ('ok', 8)] | Training
2025-04-03 03:07:09 | 3300 | LR0.0003 | loss:3.8045 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-60.7873 | logitMax:-23.7787 | windowWeightsW8:0.20644,W13:0.15787,W3:0.15224,W15:0.15021,W18:0.12597,W7:0.08556,W2:0.07375,W1:0.05007,W14:-0.02133 | memoryGatesShort:1.068, Long:-9.451, Current:9.382 | topTokens[('is', 20), ('?', 19), ('pete', 19), ('.', 16), ('!', 16), ('what', 11), ('you', 9), ('hi', 8), ('als', 7), ('ea', 7)] | Training
2025-04-03 03:11:57 | 3400 | LR0.0003 | loss:6.9209 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-29.4334 | logitMax:-1.2607 | windowWeightsW8:0.20708,W13:0.15758,W3:0.15313,W15:0.15002,W18:0.12585,W7:0.08544,W2:0.07298,W1:0.05043,W14:-0.02178 | memoryGatesShort:1.128, Long:-0.945, Current:0.817 | topTokens[('s', 31), ('.', 18), ('great', 17), ('ix', 15), ('?', 14), ('is', 11), ('you', 10), ('how', 10), ('equ', 7), ('als', 7)] | Training
2025-04-03 03:16:49 | 3500 | LR0.0003 | loss:6.5789 | gradNorm:0.9987 | tokenCount:300.0000 | logitMin:-42.4662 | logitMax:4.5078 | windowWeightsW8:0.20766,W13:0.15725,W3:0.15347,W15:0.15002,W18:0.12611,W7:0.08641,W2:0.07287,W1:0.04913,W14:-0.02217 | memoryGatesShort:1.100, Long:-0.624, Current:0.523 | topTokens[('?', 24), ('.', 20), ('s', 19), ('is', 17), ('you', 13), ('f', 12), ('ten', 10), ('ive', 10), ('a', 7), ('plus', 7)] | Training
2025-04-03 03:21:38 | 3600 | LR0.0003 | loss:6.4572 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.3504 | logitMax:-11.5546 | windowWeightsW8:0.20788,W13:0.15793,W3:0.15279,W15:0.15030,W18:0.12616,W7:0.08745,W2:0.07217,W1:0.04799,W14:-0.02187 | memoryGatesShort:0.642, Long:-0.283, Current:0.641 | topTokens[('?', 37), ('.', 34), ('is', 29), ('s', 14), ('you', 12), ('he', 12), ('what', 8), ('plus', 7), ('ten', 6), ('als', 5)] | Training
2025-04-03 03:26:28 | 3700 | LR0.0003 | loss:7.5546 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-33.1277 | logitMax:4.3079 | windowWeightsW8:0.20653,W13:0.15910,W3:0.15217,W15:0.15176,W18:0.12727,W7:0.08749,W2:0.07076,W1:0.04740,W14:-0.02161 | memoryGatesShort:0.656, Long:-0.870, Current:1.214 | topTokens[('.', 29), ('s', 22), ('als', 17), ('?', 16), ('equ', 16), ('fa', 12), ('f', 12), ('playing', 11), ('is', 9), ('!', 9)] | Training
2025-04-03 03:31:17 | 3800 | LR0.0003 | loss:8.4285 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-52.5440 | logitMax:-14.7096 | windowWeightsW8:0.20746,W13:0.15859,W3:0.15428,W15:0.15121,W18:0.12659,W7:0.08774,W2:0.07119,W1:0.04744,W14:-0.02369 | memoryGatesShort:0.841, Long:-0.809, Current:0.967 | topTokens[('that', 48), ('.', 34), ('s', 18), ('im', 17), ('is', 16), ('!', 15), ('?', 12), ('our', 10), ('what', 6), ('al', 6)] | Training
2025-04-03 03:36:37 | 3900 | LR0.0003 | loss:7.8097 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-52.9686 | logitMax:0.4559 | windowWeightsW8:0.20895,W13:0.15888,W3:0.15448,W15:0.15142,W18:0.12741,W7:0.08961,W2:0.07066,W1:0.04487,W14:-0.02545 | memoryGatesShort:-16.578, Long:22.899, Current:-5.322 | topTokens[('?', 40), ('are', 38), ('.', 24), ('!', 22), ('s', 21), ('you', 14), ('is', 12), ('a', 7), ('it', 6), ('not', 5)] | Training
2025-04-03 03:41:21 | 4000 | LR0.0003 | loss:8.8232 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-49.2002 | logitMax:-11.7158 | windowWeightsW8:0.20907,W13:0.15904,W3:0.15397,W15:0.15083,W18:0.12751,W7:0.09041,W2:0.06994,W1:0.04504,W14:-0.02495 | memoryGatesShort:0.578, Long:-0.407, Current:0.829 | topTokens[('?', 64), ('is', 28), ('s', 18), ('.', 16), ('ace', 10), (',', 7), ('feel', 7), ('are', 7), ('you', 6), ('!', 6)] | Training
2025-04-03 03:46:06 | 4100 | LR0.0003 | loss:8.5139 | gradNorm:0.9612 | tokenCount:300.0000 | logitMin:-89.0059 | logitMax:-22.1858 | windowWeightsW8:0.20869,W13:0.15911,W3:0.15338,W15:0.15218,W18:0.12880,W7:0.09018,W2:0.06819,W1:0.04702,W14:-0.02671 | memoryGatesShort:0.931, Long:-1.396, Current:1.464 | topTokens[('.', 27), ('is', 20), ('s', 20), ('!', 17), ('?', 15), ('what', 10), ('like', 10), ('h', 9), ('pete', 9), ('great', 9)] | Training
2025-04-03 03:50:53 | 4200 | LR0.0003 | loss:6.9918 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-57.8526 | logitMax:-22.5471 | windowWeightsW8:0.20758,W13:0.15884,W3:0.15416,W15:0.15219,W18:0.12968,W7:0.08987,W2:0.06879,W1:0.04638,W14:-0.02664 | memoryGatesShort:-2.380, Long:5.605, Current:-2.226 | topTokens[('you', 20), ('.', 17), ('?', 17), ('is', 16), ("'m", 10), ('that', 10), ('s', 10), ('i', 9), ('me', 8), ('equ', 7)] | Training
2025-04-03 03:55:41 | 4300 | LR0.0003 | loss:4.7479 | gradNorm:0.9910 | tokenCount:300.0000 | logitMin:-45.2210 | logitMax:-7.2685 | windowWeightsW8:0.20789,W13:0.15946,W3:0.15353,W15:0.15283,W18:0.13037,W7:0.08964,W2:0.06865,W1:0.04575,W14:-0.02724 | memoryGatesShort:1.278, Long:-0.756, Current:0.478 | topTokens[('?', 23), ('.', 21), ('s', 16), ('that', 16), ('plus', 15), ('is', 13), (',', 10), ('are', 10), ('ive', 9), ('equ', 9)] | Training
2025-04-03 04:00:31 | 4400 | LR0.0003 | loss:9.5237 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-54.7798 | logitMax:-7.4986 | windowWeightsW8:0.20791,W13:0.15985,W15:0.15299,W3:0.15255,W18:0.12992,W7:0.08963,W2:0.06903,W1:0.04628,W14:-0.02727 | memoryGatesShort:0.772, Long:-0.483, Current:0.712 | topTokens[('is', 30), ('s', 29), ('?', 27), ('he', 23), ('.', 22), ('e', 15), ('!', 8), (',', 8), ('not', 7), ('kevin', 6)] | Training
2025-04-03 04:05:23 | 4500 | LR0.0003 | loss:5.9252 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-33.2237 | logitMax:-4.5215 | windowWeightsW8:0.20786,W13:0.15991,W15:0.15326,W3:0.15266,W18:0.12997,W7:0.08968,W2:0.06886,W1:0.04610,W14:-0.02742 | memoryGatesShort:0.864, Long:-1.215, Current:1.351 | topTokens[('is', 35), ('.', 29), ('fa', 22), ('als', 12), ('s', 11), ('are', 11), ('what', 9), ('our', 8), ('equ', 8), ('no', 7)] | Training
2025-04-03 04:10:36 | 4600 | LR0.0003 | loss:7.9386 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-36.4439 | logitMax:-5.8796 | windowWeightsW8:0.20858,W13:0.16011,W15:0.15404,W3:0.15334,W18:0.12952,W7:0.09019,W2:0.06814,W1:0.04468,W14:-0.02769 | memoryGatesShort:0.943, Long:-1.799, Current:1.856 | topTokens[('!', 36), ('.', 24), ('step', 19), ('s', 15), ('im', 11), ('is', 9), ('you', 9), ('?', 8), (',', 6), ('not', 6)] | Training
2025-04-03 04:15:29 | 4700 | LR0.0003 | loss:3.8773 | gradNorm:0.9903 | tokenCount:300.0000 | logitMin:-52.3249 | logitMax:-9.4279 | windowWeightsW8:0.20723,W13:0.15994,W3:0.15434,W15:0.15359,W18:0.12968,W7:0.08966,W2:0.07052,W1:0.04408,W14:-0.02815 | memoryGatesShort:1.406, Long:-1.419, Current:1.013 | topTokens[('?', 27), ('!', 26), ('.', 21), ('is', 21), ('you', 19), ('are', 18), ('he', 11), ('real', 9), ('elodie', 8), ('i', 7)] | Training
2025-04-03 04:20:22 | 4800 | LR0.0003 | loss:6.4597 | gradNorm:0.9988 | tokenCount:300.0000 | logitMin:-45.5519 | logitMax:6.9663 | windowWeightsW8:0.20777,W13:0.15853,W3:0.15509,W15:0.15288,W18:0.12981,W7:0.09018,W2:0.07093,W1:0.04469,W14:-0.02903 | memoryGatesShort:0.783, Long:-1.992, Current:2.208 | topTokens[('.', 21), ('!', 16), ('s', 16), ('?', 13), ('is', 13), ('n', 12), ('you', 10), ('a', 8), ('i', 8), ('h', 8)] | Training
2025-04-03 04:25:12 | 4900 | LR0.0003 | loss:6.9215 | gradNorm:0.9900 | tokenCount:300.0000 | logitMin:-54.9207 | logitMax:8.2891 | windowWeightsW8:0.20729,W13:0.15951,W3:0.15513,W15:0.15405,W18:0.13093,W7:0.09042,W2:0.07061,W1:0.04437,W14:-0.03144 | memoryGatesShort:2.703, Long:-3.549, Current:1.846 | topTokens[('is', 28), ('.', 23), ('!', 22), ('?', 22), ('you', 12), ('s', 9), ('als', 9), ('plus', 8), ('he', 8), ('i', 6)] | Training
2025-04-03 04:30:02 | 5000 | LR0.0003 | loss:7.8574 | gradNorm:0.9799 | tokenCount:300.0000 | logitMin:-59.2806 | logitMax:-9.6608 | windowWeightsW8:0.20775,W13:0.15921,W15:0.15480,W3:0.15389,W18:0.13180,W7:0.09059,W2:0.06978,W1:0.04445,W14:-0.03138 | memoryGatesShort:1.658, Long:-6.574, Current:5.916 | topTokens[('?', 33), ('you', 17), ('is', 14), ('.', 13), ('french', 11), ('her', 10), ('als', 9), (',', 8), ('that', 8), ('equ', 7)] | Training
2025-04-03 04:34:51 | 5100 | LR0.0003 | loss:9.3677 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-44.8114 | logitMax:-3.8920 | windowWeightsW8:0.20807,W13:0.15930,W15:0.15457,W3:0.15390,W18:0.13144,W7:0.09099,W2:0.07144,W1:0.04238,W14:-0.03117 | memoryGatesShort:0.503, Long:-0.216, Current:0.713 | topTokens[('.', 35), ('my', 17), ('are', 16), ('b', 11), ('is', 11), ('great', 10), ('hi', 8), (',', 7), ('what', 7), ('al', 6)] | Training
2025-04-03 04:40:00 | 5200 | LR0.0003 | loss:7.6863 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-37.9119 | logitMax:-3.2030 | windowWeightsW8:0.20751,W13:0.15992,W15:0.15490,W3:0.15424,W18:0.13166,W7:0.09058,W2:0.07063,W1:0.04260,W14:-0.03112 | memoryGatesShort:1.676, Long:-6.735, Current:6.059 | topTokens[('.', 46), ('a', 20), ('are', 17), ('is', 15), ('he', 12), ('?', 9), ('ive', 9), ('als', 8), ('te', 8), ('al', 8)] | Training
2025-04-03 04:44:44 | 5300 | LR0.0003 | loss:5.8608 | gradNorm:0.9814 | tokenCount:300.0000 | logitMin:-42.1616 | logitMax:-3.1707 | windowWeightsW8:0.20834,W13:0.16001,W3:0.15495,W15:0.15484,W18:0.13158,W7:0.09159,W2:0.06997,W1:0.04121,W14:-0.03155 | memoryGatesShort:1.188, Long:2.493, Current:-2.681 | topTokens[('.', 38), ('is', 23), ('?', 11), ('our', 10), ('equ', 10), ('f', 9), ('plus', 9), ('a', 9), ('als', 8), ('ten', 7)] | Training
2025-04-03 04:49:27 | 5400 | LR0.0003 | loss:5.2497 | gradNorm:0.9704 | tokenCount:300.0000 | logitMin:-65.4208 | logitMax:-13.4995 | windowWeightsW8:0.20806,W13:0.16034,W15:0.15528,W3:0.15353,W18:0.13240,W7:0.09099,W2:0.07054,W1:0.04256,W14:-0.03275 | memoryGatesShort:-2.354, Long:-2.603, Current:5.957 | topTokens[('.', 25), ('you', 25), ('al', 21), ('?', 21), ('im', 19), ('what', 19), ('is', 18), ('!', 13), ('are', 10), ('a', 8)] | Training
2025-04-03 04:54:11 | 5500 | LR0.0003 | loss:3.3402 | gradNorm:0.9856 | tokenCount:300.0000 | logitMin:-57.0859 | logitMax:-12.1048 | windowWeightsW8:0.20746,W13:0.16012,W15:0.15440,W3:0.15398,W18:0.13253,W7:0.09242,W2:0.07133,W1:0.04204,W14:-0.03335 | memoryGatesShort:0.227, Long:0.032, Current:0.742 | topTokens[('.', 32), ('?', 29), ('are', 14), ('you', 14), ('!', 12), ('is', 12), ('ace', 12), ('real', 8), ('care', 7), ('ok', 7)] | Training
2025-04-03 04:58:54 | 5600 | LR0.0003 | loss:4.7538 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-57.8494 | logitMax:-7.6400 | windowWeightsW8:0.20733,W13:0.16069,W15:0.15477,W3:0.15361,W18:0.13304,W7:0.09224,W2:0.07053,W1:0.04306,W14:-0.03435 | memoryGatesShort:-1.691, Long:-1.905, Current:4.596 | topTokens[('is', 21), ('?', 19), ('!', 18), ('.', 14), ('ace', 12), ('you', 12), ('like', 11), ('a', 10), ('are', 9), ('i', 7)] | Training
2025-04-03 05:03:38 | 5700 | LR0.0003 | loss:5.2211 | gradNorm:0.9812 | tokenCount:300.0000 | logitMin:-40.7765 | logitMax:9.5465 | windowWeightsW8:0.20698,W13:0.16178,W15:0.15621,W3:0.15317,W18:0.13397,W7:0.09317,W2:0.06860,W1:0.04324,W14:-0.03617 | memoryGatesShort:-0.279, Long:5.058, Current:-3.778 | topTokens[('!', 26), ('f', 19), ('.', 17), ('als', 11), ('equ', 10), ('is', 10), ('i', 10), ('plus', 9), ('french', 9), ('ive', 8)] | Training
2025-04-03 05:08:47 | 5800 | LR0.0003 | loss:6.5080 | gradNorm:0.9006 | tokenCount:300.0000 | logitMin:-47.7489 | logitMax:42.6146 | windowWeightsW8:0.20663,W13:0.16156,W15:0.15672,W3:0.15335,W18:0.13522,W7:0.09293,W2:0.06828,W1:0.04263,W14:-0.03634 | memoryGatesShort:-3.137, Long:-5.848, Current:9.985 | topTokens[('.', 40), ('are', 15), ('?', 13), ('!', 11), ('is', 10), ('you', 10), ('plus', 9), ('ive', 9), ('equ', 9), ('als', 9)] | Training
2025-04-03 05:13:33 | 5900 | LR0.0003 | loss:6.0464 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-45.0895 | logitMax:-9.8575 | windowWeightsW8:0.20660,W13:0.16147,W15:0.15692,W3:0.15320,W18:0.13565,W7:0.09273,W2:0.06842,W1:0.04199,W14:-0.03598 | memoryGatesShort:0.023, Long:-0.242, Current:1.219 | topTokens[('is', 23), ('.', 22), ('?', 18), ('!', 16), ('are', 10), ('one', 7), ('he', 7), ('it', 6), ('als', 6), ('plus', 6)] | Training
2025-04-03 05:18:22 | 6000 | LR0.0003 | loss:8.4005 | gradNorm:0.9801 | tokenCount:300.0000 | logitMin:-50.7417 | logitMax:-0.1630 | windowWeightsW8:0.20605,W13:0.16188,W15:0.15720,W3:0.15312,W18:0.13654,W7:0.09243,W2:0.06809,W1:0.04188,W14:-0.03618 | memoryGatesShort:0.025, Long:-0.031, Current:1.007 | topTokens[('.', 35), ('a', 16), ('?', 14), ('is', 14), ('our', 13), ('equ', 13), ('f', 13), ('are', 12), ('als', 11), ('ive', 9)] | Training
2025-04-03 05:23:09 | 6100 | LR0.0003 | loss:8.7536 | gradNorm:0.9620 | tokenCount:300.0000 | logitMin:-69.3189 | logitMax:-1.5481 | windowWeightsW8:0.20772,W13:0.16160,W15:0.15618,W3:0.15369,W18:0.13577,W7:0.09373,W2:0.06803,W1:0.04171,W14:-0.03746 | memoryGatesShort:0.232, Long:-0.675, Current:1.443 | topTokens[('.', 31), ('is', 25), ('im', 20), ('?', 18), ('you', 16), ('!', 16), ('that', 15), ('our', 8), ('f', 6), ('plus', 6)] | Training
2025-04-03 05:27:59 | 6200 | LR0.0003 | loss:5.1103 | gradNorm:0.8901 | tokenCount:300.0000 | logitMin:-59.0211 | logitMax:14.7782 | windowWeightsW8:0.20764,W13:0.16152,W15:0.15660,W3:0.15349,W18:0.13655,W7:0.09307,W2:0.06859,W1:0.04173,W14:-0.03821 | memoryGatesShort:0.421, Long:-0.946, Current:1.525 | topTokens[('?', 30), ('.', 27), ('you', 21), ('!', 19), ('are', 15), ('is', 10), ('im', 10), ('what', 9), ('one', 7), ('a', 7)] | Training
2025-04-03 05:32:46 | 6300 | LR0.0003 | loss:5.9610 | gradNorm:0.9819 | tokenCount:300.0000 | logitMin:-45.3714 | logitMax:2.7168 | windowWeightsW8:0.20694,W13:0.16220,W15:0.15713,W3:0.15334,W18:0.13734,W7:0.09290,W2:0.06858,W1:0.04075,W14:-0.03818 | memoryGatesShort:0.093, Long:-0.463, Current:1.370 | topTokens[('.', 45), ('?', 15), ('!', 14), ('are', 12), ('im', 12), ('elodie', 10), ('is', 10), ('you', 10), ('care', 10), ('ace', 9)] | Training
2025-04-03 05:37:35 | 6400 | LR0.0003 | loss:5.4101 | gradNorm:0.9063 | tokenCount:300.0000 | logitMin:-82.3283 | logitMax:4.2800 | windowWeightsW8:0.20718,W13:0.16244,W15:0.15771,W3:0.15228,W18:0.13765,W7:0.09302,W2:0.06846,W1:0.04042,W14:-0.03811 | memoryGatesShort:-4.853, Long:-0.710, Current:6.563 | topTokens[('!', 34), ('.', 16), ('is', 16), ('you', 15), ('?', 12), ('what', 10), ('n', 8), ('like', 8), ('f', 8), ('that', 6)] | Training
2025-04-03 05:42:59 | 6500 | LR0.0003 | loss:10.3386 | gradNorm:0.9634 | tokenCount:300.0000 | logitMin:-64.9425 | logitMax:0.4663 | windowWeightsW8:0.20642,W13:0.16296,W15:0.15849,W3:0.15250,W18:0.13860,W7:0.09224,W2:0.06835,W1:0.03995,W14:-0.03845 | memoryGatesShort:1.766, Long:-0.202, Current:-0.564 | topTokens[('.', 36), ('hug', 20), ('is', 16), ('?', 12), ('n', 12), ('you', 11), ('why', 11), ('plus', 10), ('als', 10), ('f', 9)] | Training
2025-04-03 05:47:46 | 6600 | LR0.0003 | loss:5.6348 | gradNorm:0.8837 | tokenCount:300.0000 | logitMin:-44.4646 | logitMax:29.2916 | windowWeightsW8:0.20575,W13:0.16283,W15:0.15882,W3:0.15312,W18:0.13952,W7:0.09224,W2:0.06849,W1:0.03958,W14:-0.03930 | memoryGatesShort:-9.749, Long:5.618, Current:5.132 | topTokens[('.', 36), ('?', 22), ('f', 12), ('!', 11), ('plus', 11), ('ive', 9), ('equ', 9), ('als', 9), ('elodie', 8), ('is', 8)] | Training
2025-04-03 05:52:35 | 6700 | LR0.0003 | loss:4.8066 | gradNorm:0.9988 | tokenCount:300.0000 | logitMin:-56.7053 | logitMax:-6.3892 | windowWeightsW8:0.20624,W13:0.16274,W15:0.15857,W3:0.15194,W18:0.13999,W7:0.09314,W2:0.06837,W1:0.03932,W14:-0.03923 | memoryGatesShort:8.263, Long:2.256, Current:-9.519 | topTokens[('is', 39), ('.', 22), ('?', 21), ('he', 16), ('!', 12), ('playing', 8), ('so', 8), ('geepy', 7), ('plus', 7), ('als', 7)] | Training
2025-04-03 05:57:25 | 6800 | LR0.0003 | loss:4.7929 | gradNorm:0.9773 | tokenCount:300.0000 | logitMin:-62.7708 | logitMax:-3.6510 | windowWeightsW8:0.20569,W13:0.16374,W15:0.15928,W3:0.15178,W18:0.14010,W7:0.09309,W2:0.06765,W1:0.03940,W14:-0.03964 | memoryGatesShort:-0.019, Long:0.148, Current:0.872 | topTokens[('.', 33), ('is', 24), ('?', 15), ('equ', 14), ('als', 12), ('our', 12), ('f', 11), ('one', 10), ('ke', 6), ('that', 6)] | Training
2025-04-03 06:02:14 | 6900 | LR0.0003 | loss:5.1663 | gradNorm:0.8534 | tokenCount:300.0000 | logitMin:-68.0195 | logitMax:6.1343 | windowWeightsW8:0.20593,W13:0.16324,W15:0.15921,W3:0.15186,W18:0.14043,W7:0.09341,W2:0.06822,W1:0.03872,W14:-0.03993 | memoryGatesShort:-5.548, Long:-0.122, Current:6.670 | topTokens[('?', 25), ('.', 16), ('that', 15), ('are', 14), ('!', 13), ('you', 11), ('ace', 11), ('is', 9), ('im', 9), (',', 9)] | Training
2025-04-03 06:07:08 | 7000 | LR0.0003 | loss:5.2538 | gradNorm:0.8043 | tokenCount:300.0000 | logitMin:-67.7869 | logitMax:23.6452 | windowWeightsW8:0.20445,W13:0.16322,W15:0.15931,W3:0.15164,W18:0.14080,W7:0.09491,W2:0.06880,W1:0.03845,W14:-0.04048 | memoryGatesShort:-1.100, Long:-1.203, Current:3.303 | topTokens[('?', 30), ('is', 29), ('!', 24), ('.', 22), ('are', 17), ('you', 15), ('what', 14), ('a', 11), ('real', 11), ('dead', 7)] | Training
2025-04-03 06:12:22 | 7100 | LR0.0003 | loss:7.1867 | gradNorm:0.9276 | tokenCount:300.0000 | logitMin:-45.5246 | logitMax:39.4441 | windowWeightsW8:0.20423,W13:0.16395,W15:0.15954,W3:0.15030,W18:0.14115,W7:0.09550,W2:0.06924,W1:0.03861,W14:-0.04140 | memoryGatesShort:-0.373, Long:-0.470, Current:1.843 | topTokens[('.', 32), ('is', 21), ('do', 17), ('?', 16), ('a', 9), ('als', 8), (',', 7), ('plus', 7), ('are', 7), ('pete', 7)] | Training
2025-04-03 06:17:08 | 7200 | LR0.0003 | loss:4.9466 | gradNorm:0.8428 | tokenCount:300.0000 | logitMin:-80.7968 | logitMax:28.3337 | windowWeightsW8:0.20734,W13:0.16484,W15:0.16053,W3:0.14694,W18:0.14055,W7:0.09729,W2:0.06841,W1:0.03869,W14:-0.04343 | memoryGatesShort:-2.637, Long:2.276, Current:1.361 | topTokens[('is', 29), ('.', 26), ('!', 23), ('?', 17), ('you', 15), ('ie', 10), ('equ', 9), ('are', 8), ('me', 7), ('he', 7)] | Training
2025-04-03 06:21:56 | 7300 | LR0.0003 | loss:5.9110 | gradNorm:0.9829 | tokenCount:300.0000 | logitMin:-50.7859 | logitMax:17.1286 | windowWeightsW8:0.20685,W13:0.16547,W15:0.16183,W3:0.14604,W18:0.14223,W7:0.09652,W2:0.06742,W1:0.03879,W14:-0.04398 | memoryGatesShort:-0.421, Long:0.391, Current:1.029 | topTokens[('is', 23), ('?', 16), ('f', 15), ('ie', 14), ('1', 11), ('plus', 10), ('.', 9), ('equ', 9), ('als', 9), ('you', 9)] | Training
2025-04-03 06:26:45 | 7400 | LR0.0003 | loss:6.1975 | gradNorm:0.9963 | tokenCount:300.0000 | logitMin:-30.9351 | logitMax:10.6805 | windowWeightsW8:0.20700,W13:0.16535,W15:0.16178,W3:0.14616,W18:0.14203,W7:0.09672,W2:0.06750,W1:0.03816,W14:-0.04351 | memoryGatesShort:-0.532, Long:0.341, Current:1.190 | topTokens[('.', 35), ('is', 16), ('you', 13), ('?', 13), ('why', 11), ('she', 10), ("'re", 8), ('plus', 7), ('one', 7), ('elodie', 7)] | Training
2025-04-03 06:31:34 | 7500 | LR0.0003 | loss:8.1534 | gradNorm:0.9342 | tokenCount:300.0000 | logitMin:-51.4904 | logitMax:26.7022 | windowWeightsW8:0.20818,W13:0.16563,W15:0.16169,W3:0.14508,W18:0.14224,W7:0.09724,W2:0.06739,W1:0.03712,W14:-0.04335 | memoryGatesShort:5.798, Long:-2.839, Current:-1.959 | topTokens[('.', 31), ('is', 24), ('you', 19), ('?', 15), ('one', 11), ('a', 9), ('!', 9), ('plus', 8), ('he', 8), ('playing', 7)] | Training
2025-04-03 06:36:22 | 7600 | LR0.0003 | loss:10.2508 | gradNorm:0.9410 | tokenCount:300.0000 | logitMin:-50.7580 | logitMax:28.6020 | windowWeightsW8:0.20821,W13:0.16553,W15:0.16156,W3:0.14585,W18:0.14227,W7:0.09673,W2:0.06764,W1:0.03689,W14:-0.04347 | memoryGatesShort:-0.044, Long:0.333, Current:0.711 | topTokens[('.', 30), ('is', 22), ('f', 18), ('?', 18), ('als', 13), ('you', 13), ('equ', 10), ('!', 10), ('s', 9), ('that', 9)] | Training
2025-04-03 06:41:38 | 7700 | LR0.0003 | loss:8.1086 | gradNorm:0.8406 | tokenCount:300.0000 | logitMin:-54.8169 | logitMax:39.5225 | windowWeightsW8:0.20812,W13:0.16562,W15:0.16204,W3:0.14615,W18:0.14277,W7:0.09609,W2:0.06717,W1:0.03707,W14:-0.04382 | memoryGatesShort:-0.286, Long:0.182, Current:1.104 | topTokens[('?', 27), ('!', 21), ('.', 20), ('you', 14), ('are', 13), ('a', 11), ('is', 11), ('im', 10), ('dead', 8), ('al', 7)] | Training
2025-04-03 06:46:29 | 7800 | LR0.0003 | loss:4.1927 | gradNorm:0.9880 | tokenCount:300.0000 | logitMin:-59.9976 | logitMax:5.5385 | windowWeightsW8:0.20875,W13:0.16732,W15:0.16226,W3:0.14480,W18:0.14310,W7:0.09638,W2:0.06663,W1:0.03719,W14:-0.04522 | memoryGatesShort:-1.713, Long:1.540, Current:1.173 | topTokens[('.', 32), ('?', 25), ('is', 22), ('elodie', 16), (',', 11), ('you', 11), ('are', 11), ('there', 9), ('he', 8), ('a', 7)] | Training
2025-04-03 06:51:17 | 7900 | LR0.0003 | loss:8.6234 | gradNorm:0.8891 | tokenCount:300.0000 | logitMin:-91.4489 | logitMax:17.9459 | windowWeightsW8:0.20796,W13:0.16831,W15:0.16283,W3:0.14437,W18:0.14381,W7:0.09557,W2:0.06613,W1:0.03798,W14:-0.04572 | memoryGatesShort:-1.084, Long:-0.011, Current:2.095 | topTokens[('.', 22), ('elodie', 21), ('is', 16), ('you', 16), ('!', 15), ('pete', 11), ('ie', 10), ('s', 9), ('like', 8), ('?', 8)] | Training
2025-04-03 06:56:05 | 8000 | LR0.0003 | loss:6.2244 | gradNorm:0.9265 | tokenCount:300.0000 | logitMin:-58.6069 | logitMax:11.3901 | windowWeightsW8:0.20831,W13:0.16788,W15:0.16280,W3:0.14611,W18:0.14377,W7:0.09573,W2:0.06680,W1:0.03684,W14:-0.04705 | memoryGatesShort:-4.492, Long:2.549, Current:2.944 | topTokens[('.', 23), ('is', 17), ('elodie', 16), ('!', 15), ('you', 14), ('equ', 14), ('do', 12), ('plus', 12), ('f', 11), ('als', 11)] | Training
2025-04-03 07:00:55 | 8100 | LR0.0003 | loss:7.6676 | gradNorm:0.9212 | tokenCount:300.0000 | logitMin:-55.2759 | logitMax:29.8577 | windowWeightsW8:0.20854,W13:0.16776,W15:0.16324,W3:0.14727,W18:0.14402,W7:0.09602,W2:0.06669,W1:0.03587,W14:-0.04823 | memoryGatesShort:-0.378, Long:0.364, Current:1.015 | topTokens[('.', 18), ('?', 16), ('do', 15), ('is', 13), ('elodie', 12), ("'re", 10), ('plus', 9), ('f', 9), ('en', 9), ('al', 9)] | Training
2025-04-03 07:05:45 | 8200 | LR0.0003 | loss:5.0495 | gradNorm:0.9901 | tokenCount:300.0000 | logitMin:-46.3283 | logitMax:8.7465 | windowWeightsW8:0.20835,W13:0.16805,W15:0.16370,W3:0.14689,W18:0.14449,W7:0.09644,W2:0.06673,W1:0.03487,W14:-0.04830 | memoryGatesShort:3.217, Long:-0.968, Current:-1.249 | topTokens[('?', 39), ('is', 31), ('.', 22), ('elodie', 18), ('what', 9), ('als', 7), ('real', 7), ('a', 7), ('equ', 6), ('n', 6)] | Training
2025-04-03 07:10:35 | 8300 | LR0.0003 | loss:6.2673 | gradNorm:0.8646 | tokenCount:300.0000 | logitMin:-47.4823 | logitMax:56.8031 | windowWeightsW8:0.20905,W13:0.16766,W15:0.16275,W3:0.14760,W18:0.14334,W7:0.09748,W2:0.06764,W1:0.03465,W14:-0.04900 | memoryGatesShort:-1.884, Long:0.849, Current:2.035 | topTokens[('.', 35), ('elodie', 27), ('is', 26), ('?', 19), ('he', 14), ('equ', 10), ('so', 9), ('als', 9), ('f', 8), ('te', 8)] | Training
2025-04-03 07:15:44 | 8400 | LR0.0003 | loss:3.6819 | gradNorm:0.8439 | tokenCount:300.0000 | logitMin:-55.2606 | logitMax:43.4624 | windowWeightsW8:0.20952,W13:0.16688,W15:0.16186,W3:0.14976,W18:0.14280,W7:0.09829,W2:0.06788,W1:0.03360,W14:-0.04944 | memoryGatesShort:-0.665, Long:-3.957, Current:5.622 | topTokens[('.', 29), ('?', 20), ('is', 13), ('!', 11), ('that', 10), ('three', 9), ('equ', 8), ('als', 8), ('are', 8), ('you', 8)] | Training
2025-04-03 07:20:36 | 8500 | LR0.0003 | loss:9.2385 | gradNorm:0.7522 | tokenCount:300.0000 | logitMin:-83.6790 | logitMax:47.0388 | windowWeightsW8:0.20974,W13:0.16708,W15:0.16313,W3:0.15024,W18:0.14391,W7:0.09732,W2:0.06846,W1:0.03199,W14:-0.05071 | memoryGatesShort:-0.086, Long:-0.664, Current:1.751 | topTokens[('?', 30), ('elodie', 28), ('.', 22), ('!', 18), ('im', 16), ('are', 14), ('is', 13), ('you', 11), ('i', 10), ('a', 10)] | Training
2025-04-03 07:25:25 | 8600 | LR0.0003 | loss:4.4525 | gradNorm:0.9173 | tokenCount:300.0000 | logitMin:-53.8448 | logitMax:35.0913 | windowWeightsW8:0.20902,W13:0.16789,W15:0.16415,W3:0.14972,W18:0.14510,W7:0.09634,W2:0.06838,W1:0.03149,W14:-0.05091 | memoryGatesShort:-0.100, Long:-1.928, Current:3.028 | topTokens[('.', 32), ('elodie', 27), ('?', 24), ('is', 17), ('i', 15), ('are', 13), ('there', 8), ('you', 8), ('ace', 8), ('what', 7)] | Training
2025-04-03 07:30:15 | 8700 | LR0.0003 | loss:6.7650 | gradNorm:0.8231 | tokenCount:300.0000 | logitMin:-68.5194 | logitMax:36.9223 | windowWeightsW8:0.20909,W13:0.16774,W15:0.16450,W3:0.15007,W18:0.14520,W7:0.09657,W2:0.06835,W1:0.03081,W14:-0.05114 | memoryGatesShort:0.019, Long:-1.008, Current:1.989 | topTokens[('do', 30), ('.', 20), ('?', 18), ('!', 18), ('is', 17), ('you', 16), ('elodie', 14), ('f', 8), ('ie', 8), ('i', 6)] | Training
2025-04-03 07:35:05 | 8800 | LR0.0003 | loss:4.2188 | gradNorm:0.9593 | tokenCount:300.0000 | logitMin:-60.1321 | logitMax:6.0008 | windowWeightsW8:0.20855,W13:0.16801,W15:0.16488,W3:0.14908,W18:0.14654,W7:0.09747,W2:0.06760,W1:0.03056,W14:-0.05146 | memoryGatesShort:0.029, Long:0.148, Current:0.823 | topTokens[('.', 32), ('?', 21), ('elodie', 14), ('als', 12), (',', 12), ('f', 11), ('i', 11), ('is', 11), ('equ', 9), ('you', 9)] | Training
2025-04-03 07:39:55 | 8900 | LR0.0003 | loss:6.1565 | gradNorm:0.7487 | tokenCount:300.0000 | logitMin:-63.9047 | logitMax:68.2904 | windowWeightsW8:0.20763,W13:0.16917,W15:0.16631,W3:0.14973,W18:0.14765,W7:0.09595,W2:0.06759,W1:0.02921,W14:-0.05199 | memoryGatesShort:-0.131, Long:0.091, Current:1.040 | topTokens[('.', 25), ('?', 23), ('is', 20), ('elodie', 13), ('you', 12), ('f', 11), ('i', 10), ('als', 10), ('plus', 9), ('ive', 9)] | Training
2025-04-03 07:45:09 | 9000 | LR0.0003 | loss:12.8851 | gradNorm:0.9274 | tokenCount:300.0000 | logitMin:-83.3750 | logitMax:18.1560 | windowWeightsW8:0.20779,W13:0.16906,W15:0.16669,W3:0.14964,W18:0.14799,W7:0.09681,W2:0.06730,W1:0.02862,W14:-0.05264 | memoryGatesShort:-0.165, Long:-0.301, Current:1.466 | topTokens[('?', 46), ('.', 31), ('is', 30), ('playing', 16), ('elodie', 11), ('who', 10), ('t', 9), ('e', 9), ('you', 8), ('he', 8)] | Training
2025-04-03 07:49:55 | 9100 | LR0.0003 | loss:9.4130 | gradNorm:0.8431 | tokenCount:300.0000 | logitMin:-81.4000 | logitMax:50.3994 | windowWeightsW8:0.20762,W13:0.16900,W15:0.16707,W3:0.14919,W18:0.14803,W7:0.09722,W2:0.06657,W1:0.02839,W14:-0.05180 | memoryGatesShort:0.273, Long:0.161, Current:0.566 | topTokens[('.', 33), ('?', 32), ('is', 19), ('als', 14), ('!', 12), ('e', 11), ('equ', 11), ('elodie', 9), ('our', 9), ('plus', 8)] | Training
2025-04-03 07:54:42 | 9200 | LR0.0003 | loss:4.7095 | gradNorm:0.6376 | tokenCount:300.0000 | logitMin:-93.3714 | logitMax:44.9805 | windowWeightsW8:0.20865,W13:0.16904,W15:0.16733,W3:0.14972,W18:0.14867,W7:0.09758,W2:0.06595,W1:0.02821,W14:-0.05387 | memoryGatesShort:1.027, Long:1.514, Current:-1.541 | topTokens[('?', 26), ('is', 23), ('.', 20), ('elodie', 15), ('that', 12), ('dead', 12), ('!', 10), ('you', 9), ('what', 8), ('are', 8)] | Training
2025-04-03 07:59:32 | 9300 | LR0.0003 | loss:8.5110 | gradNorm:0.7870 | tokenCount:300.0000 | logitMin:-110.0462 | logitMax:51.3604 | windowWeightsW8:0.20756,W13:0.16885,W15:0.16785,W3:0.14988,W18:0.14982,W7:0.09716,W2:0.06629,W1:0.02800,W14:-0.05413 | memoryGatesShort:-0.034, Long:-0.034, Current:1.067 | topTokens[('elodie', 31), ('?', 24), ('is', 23), ('.', 20), ('!', 19), ('you', 14), ('a', 11), ('there', 11), ('i', 10), ('real', 9)] | Training
2025-04-03 08:04:20 | 9400 | LR0.0003 | loss:12.5165 | gradNorm:0.8840 | tokenCount:300.0000 | logitMin:-112.6497 | logitMax:26.8170 | windowWeightsW8:0.20661,W13:0.16936,W15:0.16856,W18:0.15010,W3:0.14911,W7:0.09714,W2:0.06614,W1:0.02803,W14:-0.05374 | memoryGatesShort:20.912, Long:0.782, Current:-20.694 | topTokens[('?', 35), ('.', 34), ('elodie', 21), ('is', 14), ('i', 13), ('are', 12), ('you', 11), ('ace', 10), ('real', 8), ('do', 7)] | Training
2025-04-03 08:09:09 | 9500 | LR0.0003 | loss:3.7572 | gradNorm:0.6262 | tokenCount:300.0000 | logitMin:-112.0754 | logitMax:44.4560 | windowWeightsW8:0.20697,W13:0.16917,W15:0.16886,W18:0.15045,W3:0.14863,W7:0.09759,W2:0.06590,W1:0.02741,W14:-0.05363 | memoryGatesShort:-0.031, Long:-0.163, Current:1.194 | topTokens[('!', 32), ('?', 18), ('you', 18), ('.', 15), ('is', 13), ('what', 11), ('f', 8), ("'re", 7), ('do', 7), ('pete', 6)] | Training
2025-04-03 08:14:01 | 9600 | LR0.0003 | loss:11.3792 | gradNorm:0.9412 | tokenCount:300.0000 | logitMin:-101.1164 | logitMax:7.5550 | windowWeightsW8:0.20728,W15:0.16917,W13:0.16900,W18:0.15007,W3:0.14851,W7:0.09701,W2:0.06622,W1:0.02740,W14:-0.05331 | memoryGatesShort:0.017, Long:-0.404, Current:1.388 | topTokens[('?', 36), ('elodie', 21), ('.', 20), ('is', 19), ('you', 10), ('do', 9), ('he', 8), ('equ', 7), ('1', 7), ('!', 7)] | Training
2025-04-03 08:19:05 | 9700 | LR0.0003 | loss:4.2294 | gradNorm:0.8977 | tokenCount:300.0000 | logitMin:-55.4205 | logitMax:30.8904 | windowWeightsW8:0.20748,W13:0.16968,W15:0.16927,W18:0.15042,W3:0.14857,W7:0.09715,W2:0.06570,W1:0.02670,W14:-0.05362 | memoryGatesShort:-0.960, Long:-0.971, Current:2.931 | topTokens[('.', 38), ('is', 20), ('?', 19), ('reading', 11), ('ive', 10), ('elodie', 9), ('plus', 9), ('f', 9), ('equ', 9), ('als', 9)] | Training
2025-04-03 08:23:56 | 9800 | LR0.0003 | loss:11.2211 | gradNorm:0.8113 | tokenCount:300.0000 | logitMin:-68.3734 | logitMax:32.8887 | windowWeightsW8:0.20737,W13:0.17001,W15:0.16963,W18:0.15031,W3:0.14842,W7:0.09692,W2:0.06604,W1:0.02669,W14:-0.05403 | memoryGatesShort:-0.581, Long:-0.715, Current:2.295 | topTokens[('.', 41), ('is', 31), ('?', 22), ('elodie', 11), ('equ', 10), ('he', 9), ('als', 9), ('you', 7), ('are', 6), ('reading', 6)] | Training
2025-04-03 08:28:54 | 9900 | LR0.0003 | loss:7.6953 | gradNorm:0.7334 | tokenCount:300.0000 | logitMin:-74.7585 | logitMax:49.7976 | windowWeightsW8:0.20746,W13:0.16998,W15:0.16975,W18:0.15010,W3:0.14919,W7:0.09735,W2:0.06533,W1:0.02640,W14:-0.05420 | memoryGatesShort:-0.729, Long:-0.960, Current:2.690 | topTokens[('.', 29), ('is', 23), ('f', 21), ('?', 16), ('equ', 14), ('that', 14), ('plus', 13), ('!', 12), ('als', 12), ('our', 8)] | Training
2025-04-03 08:34:22 | 10000 | LR0.0003 | loss:5.5065 | gradNorm:0.7280 | tokenCount:300.0000 | logitMin:-78.8832 | logitMax:48.5298 | windowWeightsW8:0.20792,W15:0.16962,W13:0.16931,W18:0.15063,W3:0.14947,W7:0.09755,W2:0.06485,W1:0.02599,W14:-0.05398 | memoryGatesShort:0.202, Long:0.194, Current:0.604 | topTokens[('.', 28), ('?', 22), ('you', 18), ('are', 13), ('!', 9), ('dead', 9), (',', 8), ('is', 8), ('im', 8), ('what', 7)] | Training
2025-04-03 08:40:08 | 10100 | LR0.0003 | loss:2.5197 | gradNorm:0.4912 | tokenCount:300.0000 | logitMin:-118.9388 | logitMax:75.9842 | windowWeightsW8:0.20751,W13:0.16831,W15:0.16772,W18:0.15114,W3:0.14849,W7:0.10000,W2:0.06830,W1:0.02599,W14:-0.05615 | memoryGatesShort:-0.015, Long:-0.293, Current:1.308 | topTokens[('.', 34), ('?', 28), ('is', 21), ('are', 20), ('you', 20), ('!', 15), ('what', 10), ('there', 9), ('real', 7), ('elodie', 7)] | Training

--- 2025-04-03 08:50:20 --- babyllm: 'what am i learning today?'- charis: 'how to not get stuck in shit data lol'
2025-04-03 08:55:07 | 100 | LR0.0003 | loss:7.2213 | gradNorm:1.0000 | logitMin:-33.8119 | logitMax:9.1086 | scheduledSampling:0.0000 | tokenCount:300.0000 | windowWeightsW8:0.20752,W13:0.16645,W15:0.16641,W3:0.15066,W18:0.14995,W7:0.10123,W2:0.06865,W1:0.02418,W14:-0.05374 | memoryGatesShort:0.670, Long:-3.436, Current:3.766 | topTokens[('.', 51), ('!', 25), ('it', 13), ('am', 12), ('know', 12), ('a', 11), ('i', 11), ('is', 10), ('hi', 9), ('feel', 8)] | Training
2025-04-03 09:00:23 | 200 | LR0.0003 | loss:13.5035 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-27.3923 | logitMax:0.4537 | windowWeightsW8:0.20734,W15:0.16688,W13:0.16680,W18:0.15058,W3:0.14953,W7:0.10215,W2:0.06786,W1:0.02369,W14:-0.05348 | memoryGatesShort:0.954, Long:-0.733, Current:0.779 | topTokens[('.', 45), ('elodie', 26), ('i', 16), ('not', 12), ('ie', 11), (',', 10), ('our', 9), ('!', 8), ("'re", 8), ('am', 7)] | Training
2025-04-03 09:05:47 | 300 | LR0.0003 | loss:11.1881 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-24.2942 | logitMax:-3.3065 | windowWeightsW8:0.20733,W15:0.16698,W13:0.16691,W18:0.15067,W3:0.14932,W7:0.10243,W2:0.06760,W1:0.02348,W14:-0.05337 | memoryGatesShort:0.460, Long:0.416, Current:0.124 | topTokens[('.', 32), ('i', 26), ('elodie', 20), (',', 11), ('too', 9), ('...', 7), ('b', 7), ('she', 5), ('feel', 5), ('were', 5)] | Training
2025-04-03 09:11:04 | 400 | LR0.0003 | loss:10.7699 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-25.0129 | logitMax:-4.1193 | windowWeightsW8:0.20722,W13:0.16743,W15:0.16729,W18:0.15109,W3:0.14912,W7:0.10231,W2:0.06715,W1:0.02279,W14:-0.05304 | memoryGatesShort:0.776, Long:-0.654, Current:0.878 | topTokens[('.', 35), (',', 21), ('i', 20), ('her', 15), ('ie', 8), ('s', 8), ('you', 6), ('am', 6), ('a', 5), ('who', 4)] | Training
2025-04-03 09:16:18 | 500 | LR0.0003 | loss:10.0556 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-25.5546 | logitMax:-7.0236 | windowWeightsW8:0.20711,W13:0.16771,W15:0.16757,W18:0.15148,W3:0.14862,W7:0.10162,W2:0.06691,W1:0.02288,W14:-0.05251 | memoryGatesShort:3.737, Long:-3.582, Current:0.845 | topTokens[('i', 24), ('.', 14), (',', 12), ('not', 10), ('elodie', 8), ('im', 8), ('did', 6), ('is', 6), ('she', 5), ('s', 5)] | Training
2025-04-03 09:22:09 | 600 | LR0.0003 | loss:10.9591 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-30.3538 | logitMax:-9.3873 | windowWeightsW8:0.20702,W13:0.16772,W15:0.16760,W18:0.15174,W3:0.14829,W7:0.10197,W2:0.06675,W1:0.02256,W14:-0.05226 | memoryGatesShort:-2.195, Long:2.930, Current:0.264 | topTokens[('.', 26), (',', 21), ('i', 12), ('you', 12), ('!', 10), ('not', 10), ('equ', 8), ('?', 7), ('elodie', 7), ('feel', 6)] | Training
2025-04-03 09:27:05 | 700 | LR0.0003 | loss:10.5186 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-33.2443 | logitMax:-14.1989 | windowWeightsW8:0.20723,W13:0.16792,W15:0.16774,W18:0.15163,W3:0.14772,W7:0.10280,W2:0.06623,W1:0.02208,W14:-0.05195 | memoryGatesShort:-6.199, Long:4.990, Current:2.209 | topTokens[(',', 16), ('im', 13), ('.', 10), ('is', 9), ('to', 9), ('going', 8), ('?', 8), ('i', 8), ('s', 7), ('like', 6)] | Training
2025-04-03 09:32:07 | 800 | LR0.0003 | loss:9.2632 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-28.4481 | logitMax:-11.0569 | windowWeightsW8:0.20705,W15:0.16827,W13:0.16823,W18:0.15220,W3:0.14724,W7:0.10289,W2:0.06564,W1:0.02090,W14:-0.05099 | memoryGatesShort:-1.867, Long:3.286, Current:-0.420 | topTokens[(',', 25), ('i', 23), ('is', 19), ('.', 19), ('im', 9), ('a', 7), ('to', 6), ('s', 5), ('h', 5), ('not', 5)] | Training
2025-04-03 09:37:21 | 900 | LR0.0003 | loss:9.8231 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-29.6918 | logitMax:-11.4749 | windowWeightsW8:0.20702,W15:0.16835,W13:0.16825,W18:0.15225,W3:0.14706,W7:0.10295,W2:0.06564,W1:0.02054,W14:-0.05062 | memoryGatesShort:-3.239, Long:4.059, Current:0.181 | topTokens[('me', 26), ('h', 22), ('.', 19), (',', 18), ('to', 9), ('is', 7), ('i', 7), ('who', 5), ('and', 4), ('e', 4)] | Training
2025-04-03 09:42:38 | 1000 | LR0.0003 | loss:8.7624 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-29.1399 | logitMax:-12.1793 | windowWeightsW8:0.20690,W15:0.16846,W13:0.16822,W18:0.15248,W3:0.14677,W7:0.10275,W2:0.06532,W1:0.02030,W14:-0.04974 | memoryGatesShort:-6.098, Long:6.585, Current:0.513 | topTokens[(',', 26), ('me', 19), ('h', 13), ('.', 10), ('the', 6), ('to', 5), ('b', 4), ('our', 4), ('am', 4), ('plus', 4)] | Training
2025-04-03 09:48:01 | 1100 | LR0.0003 | loss:9.8135 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-32.2077 | logitMax:-14.6208 | windowWeightsW8:0.20689,W15:0.16860,W13:0.16827,W18:0.15262,W3:0.14655,W7:0.10289,W2:0.06505,W1:0.02008,W14:-0.04949 | memoryGatesShort:-5.696, Long:5.202, Current:1.494 | topTokens[(',', 30), ('the', 12), ('at', 12), ('h', 9), ('.', 9), ('to', 6), ('a', 6), ('is', 6), ('es', 5), ('me', 5)] | Training
2025-04-03 09:53:10 | 1200 | LR0.0003 | loss:11.7394 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-36.2125 | logitMax:-12.0292 | windowWeightsW8:0.20643,W15:0.16948,W13:0.16926,W18:0.15272,W3:0.14582,W7:0.10290,W2:0.06508,W1:0.01941,W14:-0.04962 | memoryGatesShort:91.814, Long:-72.343, Current:-18.471 | topTokens[('.', 42), ('now', 13), ('it', 12), (',', 11), ('i', 11), ('u', 11), ('at', 7), ('me', 6), ('b', 5), ('a', 5)] | Training
2025-04-03 09:58:19 | 1300 | LR0.0003 | loss:13.2044 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.1112 | logitMax:-14.8023 | windowWeightsW8:0.20531,W15:0.17011,W13:0.16959,W18:0.15372,W3:0.14454,W7:0.10327,W2:0.06448,W1:0.01947,W14:-0.04898 | memoryGatesShort:-26.181, Long:24.652, Current:2.529 | topTokens[('.', 38), ('is', 20), (',', 15), ('at', 14), ('me', 14), ('this', 9), ('?', 7), ('she', 6), ('i', 6), ('my', 5)] | Training
2025-04-03 10:03:42 | 1400 | LR0.0003 | loss:9.1076 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-36.4357 | logitMax:-17.0618 | windowWeightsW8:0.20573,W15:0.17037,W13:0.16959,W18:0.15461,W3:0.14348,W7:0.10260,W2:0.06367,W1:0.01940,W14:-0.04792 | memoryGatesShort:-12.516, Long:11.202, Current:2.314 | topTokens[(',', 30), ('.', 13), ('u', 13), ('my', 11), ('is', 9), ('at', 5), ('i', 5), ('f', 5), ('ke', 5), ('up', 4)] | Training
2025-04-03 10:09:37 | 1500 | LR0.0003 | loss:9.4706 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-36.0414 | logitMax:-16.8579 | windowWeightsW8:0.20481,W15:0.17043,W13:0.16910,W18:0.15530,W3:0.14408,W7:0.10263,W2:0.06337,W1:0.01948,W14:-0.04765 | memoryGatesShort:-5.358, Long:6.168, Current:0.190 | topTokens[('u', 26), (',', 15), ('.', 15), ('i', 15), ('the', 9), ('ke', 7), ('a', 6), ('ing', 5), ('is', 5), ('like', 4)] | Training
2025-04-03 10:14:45 | 1600 | LR0.0003 | loss:10.6077 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-38.4681 | logitMax:-18.9781 | windowWeightsW8:0.20456,W15:0.17051,W13:0.16904,W18:0.15544,W3:0.14379,W7:0.10277,W2:0.06335,W1:0.01939,W14:-0.04731 | memoryGatesShort:-15.420, Long:15.313, Current:1.107 | topTokens[('is', 29), ('.', 24), ('es', 13), (',', 10), ('u', 10), ('i', 9), ('f', 8), ('it', 5), ('this', 5), ('n', 5)] | Training
2025-04-03 10:20:01 | 1700 | LR0.0003 | loss:10.3480 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-32.9780 | logitMax:-12.8434 | windowWeightsW8:0.20485,W15:0.17088,W13:0.16997,W18:0.15566,W3:0.14275,W7:0.10371,W2:0.06262,W1:0.01758,W14:-0.04644 | memoryGatesShort:23581.539, Long:-20384.100, Current:-3196.423 | topTokens[('.', 21), ('is', 18), (',', 15), ('f', 10), ('i', 8), ('ke', 6), ('es', 6), ('nd', 6), ('it', 5), ('u', 5)] | Training
2025-04-03 10:25:13 | 1800 | LR0.0003 | loss:9.5323 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-37.6279 | logitMax:-19.7647 | windowWeightsW8:0.20469,W15:0.17065,W13:0.16933,W18:0.15571,W3:0.14311,W7:0.10336,W2:0.06274,W1:0.01739,W14:-0.04540 | memoryGatesShort:-3.312, Long:3.590, Current:0.722 | topTokens[(',', 16), ('is', 11), ('my', 10), ('.', 9), ('the', 9), ('it', 8), ('s', 7), ('i', 5), ('a', 5), ('in', 5)] | Training
2025-04-03 10:30:19 | 1900 | LR0.0003 | loss:9.7662 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-36.0218 | logitMax:-16.8880 | windowWeightsW8:0.20437,W15:0.17110,W13:0.17003,W18:0.15643,W3:0.14249,W7:0.10346,W2:0.06210,W1:0.01636,W14:-0.04475 | memoryGatesShort:-64.586, Long:64.122, Current:1.464 | topTokens[('.', 16), ('the', 15), ('this', 12), ('but', 11), (',', 9), ('im', 9), ('i', 7), ('no', 6), ('in', 5), ('u', 5)] | Training
2025-04-03 10:35:55 | 2000 | LR0.0003 | loss:9.8434 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-33.9638 | logitMax:-14.5553 | windowWeightsW8:0.20390,W15:0.17134,W13:0.16979,W18:0.15696,W3:0.14233,W7:0.10363,W2:0.06181,W1:0.01628,W14:-0.04444 | memoryGatesShort:-4.540, Long:3.994, Current:1.546 | topTokens[('.', 11), ('but', 11), ('ohh', 7), ('u', 6), (',', 5), ('im', 5), ('like', 5), ('f', 5), ('me', 5), ('is', 5)] | Training
2025-04-03 10:41:44 | 2100 | LR0.0003 | loss:9.0387 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-30.8740 | logitMax:-13.9346 | windowWeightsW8:0.20293,W15:0.17190,W13:0.17149,W18:0.15720,W3:0.14225,W7:0.10338,W2:0.06140,W1:0.01605,W14:-0.04498 | memoryGatesShort:-5.424, Long:5.154, Current:1.270 | topTokens[('i', 29), ('.', 14), (',', 10), ('s', 8), ('for', 7), ('n', 6), ('a', 6), ('do', 5), ('very', 4), ('the', 4)] | Training
2025-04-03 10:47:11 | 2200 | LR0.0003 | loss:11.3317 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-36.4409 | logitMax:-15.4801 | windowWeightsW8:0.20163,W15:0.17264,W13:0.17216,W18:0.15760,W3:0.14202,W7:0.10264,W2:0.06158,W1:0.01602,W14:-0.04467 | memoryGatesShort:-4.938, Long:4.910, Current:1.028 | topTokens[('s', 49), ('.', 14), ('why', 14), ('that', 11), ('lo', 11), (',', 10), ('l', 7), ('just', 4), ('ie', 4), ('gay', 4)] | Training
2025-04-03 10:52:35 | 2300 | LR0.0003 | loss:9.9667 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-38.2357 | logitMax:-18.6781 | windowWeightsW8:0.20110,W15:0.17303,W13:0.17267,W18:0.15753,W3:0.14184,W7:0.10268,W2:0.06131,W1:0.01584,W14:-0.04437 | memoryGatesShort:-19.340, Long:16.223, Current:4.117 | topTokens[('why', 22), ('s', 20), ('that', 20), ('.', 17), (',', 15), ('it', 10), ('l', 8), ('but', 5), ('a', 5), ('my', 5)] | Training
2025-04-03 10:57:50 | 2400 | LR0.0003 | loss:9.7894 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-35.9860 | logitMax:-16.9390 | windowWeightsW8:0.20064,W15:0.17424,W13:0.17397,W18:0.15817,W3:0.14173,W7:0.10178,W2:0.05986,W1:0.01595,W14:-0.04474 | memoryGatesShort:-196.054, Long:181.538, Current:15.516 | topTokens[('.', 21), ('a', 15), ('y', 6), (',', 5), ('l', 5), ('why', 5), ('u', 5), ('do', 5), ('ch', 5), ('*', 5)] | Training
2025-04-03 11:03:39 | 2500 | LR0.0003 | loss:10.9907 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-37.6666 | logitMax:-15.8106 | windowWeightsW8:0.20103,W15:0.17450,W13:0.17408,W18:0.15820,W3:0.14154,W7:0.10172,W2:0.05949,W1:0.01616,W14:-0.04510 | memoryGatesShort:-3.682, Long:3.598, Current:1.084 | topTokens[('ch', 43), ('.', 23), ('a', 14), ('*', 10), ('was', 9), ('why', 7), (',', 5), ('feel', 5), ('our', 5), ('too', 4)] | Training
2025-04-03 11:09:06 | 2600 | LR0.0003 | loss:12.0497 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-40.7564 | logitMax:-17.1875 | windowWeightsW8:0.20088,W15:0.17465,W13:0.17398,W18:0.15854,W3:0.14135,W7:0.10157,W2:0.05954,W1:0.01609,W14:-0.04499 | memoryGatesShort:75.565, Long:-68.145, Current:-6.420 | topTokens[('.', 42), ('u', 18), ('ch', 16), ('why', 8), ('g', 8), ('no', 7), ('i', 6), ('do', 5), ('this', 5), ('just', 5)] | Training
2025-04-03 11:14:17 | 2700 | LR0.0003 | loss:8.0954 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-35.3197 | logitMax:-20.2525 | windowWeightsW8:0.20103,W15:0.17475,W13:0.17385,W18:0.15840,W3:0.14074,W7:0.10243,W2:0.05944,W1:0.01520,W14:-0.04420 | memoryGatesShort:-261.999, Long:217.978, Current:45.021 | topTokens[('is', 14), ('it', 9), ('im', 9), (',', 8), ('a', 7), ('*', 5), ('.', 5), ('he', 4), ('just', 4), ('was', 4)] | Training
2025-04-03 11:19:46 | 2800 | LR0.0003 | loss:12.9330 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-37.5933 | logitMax:-13.0566 | windowWeightsW8:0.19978,W15:0.17516,W13:0.17271,W18:0.16026,W3:0.13829,W7:0.10287,W2:0.05865,W1:0.01599,W14:-0.04202 | memoryGatesShort:30.650, Long:-21.875, Current:-7.774 | topTokens[('my', 52), ('.', 24), (',', 22), ('c', 5), ('its', 5), ('who', 5), ('was', 4), ('it', 4), ('im', 4), ('boi', 3)] | Training
2025-04-03 11:25:05 | 2900 | LR0.0003 | loss:11.9488 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-31.3689 | logitMax:-9.9404 | windowWeightsW8:0.19997,W15:0.17503,W13:0.17287,W18:0.16012,W3:0.13793,W7:0.10377,W2:0.05833,W1:0.01601,W14:-0.04234 | memoryGatesShort:-7.295, Long:6.166, Current:2.129 | topTokens[('my', 66), ('its', 37), (',', 36), ('.', 18), ('because', 7), ('too', 4), ('t', 4), ('who', 3), (':', 3), ('she', 3)] | Training
2025-04-03 11:30:58 | 3000 | LR0.0003 | loss:10.6378 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-33.1189 | logitMax:-12.3952 | windowWeightsW8:0.20052,W15:0.17433,W13:0.17284,W18:0.15983,W3:0.13824,W7:0.10460,W2:0.05829,W1:0.01570,W14:-0.04267 | memoryGatesShort:-24.435, Long:20.334, Current:5.101 | topTokens[('my', 48), ('its', 39), ('.', 24), (',', 22), ('kn', 7), ('she', 5), ('f', 5), ('r', 3), ('s', 3), ('b', 3)] | Training
2025-04-03 11:36:00 | 3100 | LR0.0003 | loss:10.9730 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-35.8907 | logitMax:-14.5786 | windowWeightsW8:0.20095,W15:0.17434,W13:0.17289,W18:0.15963,W3:0.13822,W7:0.10534,W2:0.05832,W1:0.01513,W14:-0.04312 | memoryGatesShort:-5.210, Long:4.625, Current:1.585 | topTokens[('its', 28), ('.', 26), ('my', 22), ('t', 15), ('kn', 11), (',', 10), (':', 6), ('me', 6), ('too', 4), ('b', 4)] | Training
2025-04-03 11:41:11 | 3200 | LR0.0003 | loss:10.1040 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-36.4196 | logitMax:-14.4915 | windowWeightsW8:0.20007,W15:0.17503,W13:0.17310,W18:0.16067,W3:0.13701,W7:0.10563,W2:0.05806,W1:0.01484,W14:-0.04271 | memoryGatesShort:-14.745, Long:14.199, Current:1.546 | topTokens[('.', 36), ('ll', 30), (',', 12), ('it', 10), ('its', 9), ('er', 8), ('my', 6), ('and', 4), ('dont', 4), ('them', 3)] | Training
2025-04-03 11:46:35 | 3300 | LR0.0003 | loss:8.4602 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-38.1620 | logitMax:-21.2975 | windowWeightsW8:0.20008,W15:0.17546,W13:0.17354,W18:0.16093,W3:0.13678,W7:0.10586,W2:0.05768,W1:0.01426,W14:-0.04289 | memoryGatesShort:-7.054, Long:7.928, Current:0.126 | topTokens[('l', 17), (',', 13), ('ll', 13), ('it', 13), ('.', 12), ('er', 11), ('dont', 11), ('be', 8), ('i', 5), ('gg', 4)] | Training
2025-04-03 11:51:56 | 3400 | LR0.0003 | loss:8.4633 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-32.7186 | logitMax:-14.6531 | windowWeightsW8:0.20073,W15:0.17577,W13:0.17348,W18:0.16118,W3:0.13661,W7:0.10622,W2:0.05714,W1:0.01361,W14:-0.04304 | memoryGatesShort:-5.357, Long:4.789, Current:1.568 | topTokens[('.', 17), ('l', 15), ('be', 9), ('i', 7), (',', 6), ('f', 6), ('my', 5), ('that', 4), ('b', 4), ('who', 4)] | Training
2025-04-03 11:57:15 | 3500 | LR0.0003 | loss:10.6038 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-32.3633 | logitMax:-11.5859 | windowWeightsW8:0.20033,W15:0.17578,W13:0.17357,W18:0.16104,W3:0.13622,W7:0.10771,W2:0.05717,W1:0.01319,W14:-0.04331 | memoryGatesShort:19.996, Long:-14.725, Current:-4.271 | topTokens[('.', 18), (',', 16), ('s', 13), ('l', 10), ('im', 7), ('we', 6), ('u', 5), ('i', 5), ('it', 5), ('who', 5)] | Training
2025-04-03 12:02:26 | 3600 | LR0.0003 | loss:10.4794 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-38.0663 | logitMax:-15.9722 | windowWeightsW8:0.20049,W15:0.17606,W13:0.17389,W18:0.16165,W3:0.13586,W7:0.10721,W2:0.05669,W1:0.01283,W14:-0.04298 | memoryGatesShort:-5.519, Long:5.606, Current:0.913 | topTokens[('.', 29), (',', 22), ('have', 11), ('l', 8), ('in', 7), ('like', 7), ('me', 6), ('and', 6), ('we', 5), ('a', 4)] | Training
2025-04-03 12:07:45 | 3700 | LR0.0003 | loss:9.9001 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.7115 | logitMax:-22.3623 | windowWeightsW8:0.20014,W15:0.17620,W13:0.17423,W18:0.16138,W3:0.13577,W7:0.10750,W2:0.05645,W1:0.01307,W14:-0.04304 | memoryGatesShort:-38.331, Long:29.539, Current:9.792 | topTokens[('like', 60), ('to', 26), ('.', 12), (',', 11), ('i', 7), ('y', 5), ('l', 4), ('in', 4), ('b', 4), ('-', 4)] | Training
2025-04-03 12:13:47 | 3800 | LR0.0003 | loss:10.6297 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-37.2544 | logitMax:-15.9413 | windowWeightsW8:0.19971,W15:0.17700,W13:0.17452,W18:0.16239,W3:0.13534,W7:0.10742,W2:0.05604,W1:0.01237,W14:-0.04306 | memoryGatesShort:-25.320, Long:24.362, Current:1.958 | topTokens[('.', 36), ('im', 22), ('l', 19), ('to', 10), ('lo', 9), (',', 8), ('s', 6), ('i', 6), ('me', 6), ('she', 5)] | Training
2025-04-03 12:19:16 | 3900 | LR0.0003 | loss:11.5857 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-40.8122 | logitMax:-17.3882 | windowWeightsW8:0.19978,W15:0.17737,W13:0.17442,W18:0.16318,W3:0.13482,W7:0.10742,W2:0.05571,W1:0.01183,W14:-0.04282 | memoryGatesShort:-18.153, Long:17.169, Current:1.984 | topTokens[('its', 23), ('.', 19), (',', 17), ('be', 12), ('l', 9), ('to', 6), ('she', 6), ('but', 5), ('i', 5), ('im', 5)] | Training
2025-04-03 12:24:40 | 4000 | LR0.0003 | loss:8.4900 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.4059 | logitMax:-25.0957 | windowWeightsW8:0.19888,W15:0.17782,W13:0.17509,W18:0.16298,W3:0.13433,W7:0.10756,W2:0.05561,W1:0.01173,W14:-0.04228 | memoryGatesShort:-8.035, Long:7.751, Current:1.284 | topTokens[(',', 21), ('to', 18), ('kevin', 15), ('s', 14), ('like', 12), ('he', 11), ('.', 8), ('b', 7), ('yeah', 4), ('but', 3)] | Training
2025-04-03 12:29:55 | 4100 | LR0.0003 | loss:10.0421 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-35.8050 | logitMax:-17.2007 | windowWeightsW8:0.19909,W15:0.17841,W13:0.17527,W18:0.16347,W3:0.13430,W7:0.10720,W2:0.05512,W1:0.01101,W14:-0.04216 | memoryGatesShort:-6.823, Long:5.891, Current:1.933 | topTokens[('.', 16), (',', 13), ('kevin', 9), ('me', 7), ('ed', 7), ('ail', 7), ('you', 7), ('a', 6), ('like', 6), ('s', 5)] | Training

--- 2025-04-03 12:34:17 --- babyllm: 'what am i learning today?'- charis: 'maybe less chaos?'
2025-04-03 12:39:20 | 100 | LR0.0003 | loss:7.6797 | gradNorm:0.9805 | logitMin:-62.3524 | logitMax:-1.0465 | scheduledSampling:0.0000 | tokenCount:300.0000 | windowWeightsW8:0.19828,W15:0.17715,W13:0.17430,W18:0.16160,W3:0.13750,W7:0.10672,W2:0.05749,W1:0.01173,W14:-0.04310 | memoryGatesShort:-9.705, Long:1.970, Current:8.735 | topTokens[('.', 44), ('it', 40), ('i', 39), ('!', 26), ('know', 13), ('did', 10), ('am', 8), ('who', 8), ('happy', 8), ('its', 7)] | Training
2025-04-03 12:44:33 | 200 | LR0.0003 | loss:9.5431 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-34.8871 | logitMax:-9.3727 | windowWeightsW8:0.19816,W15:0.17787,W13:0.17493,W18:0.16219,W3:0.13712,W7:0.10777,W2:0.05653,W1:0.01100,W14:-0.04391 | memoryGatesShort:-10.404, Long:10.326, Current:1.079 | topTokens[(',', 34), ('.', 23), ('i', 21), ('did', 12), ('to', 8), ('how', 7), ('who', 7), ('why', 7), ('feel', 6), ('it', 5)] | Training
2025-04-03 12:49:44 | 300 | LR0.0003 | loss:12.3435 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-35.9151 | logitMax:-11.5815 | windowWeightsW8:0.19801,W15:0.17784,W13:0.17491,W18:0.16214,W3:0.13705,W7:0.10801,W2:0.05651,W1:0.01097,W14:-0.04377 | memoryGatesShort:53.851, Long:-39.070, Current:-13.781 | topTokens[('.', 33), (',', 31), ('i', 13), ('in', 10), ('like', 10), ('why', 8), ('she', 6), ('did', 6), ('and', 6), ('my', 5)] | Training
2025-04-03 12:55:00 | 400 | LR0.0003 | loss:10.4808 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-42.9570 | logitMax:-17.7587 | windowWeightsW8:0.19806,W15:0.17799,W13:0.17483,W18:0.16230,W3:0.13690,W7:0.10794,W2:0.05652,W1:0.01083,W14:-0.04370 | memoryGatesShort:-9.022, Long:7.409, Current:2.612 | topTokens[('.', 31), (',', 13), ('and', 12), ('like', 12), ('are', 9), ('can', 6), ('how', 5), ('?', 5), ('s', 5), ('you', 4)] | Training
2025-04-03 13:00:29 | 500 | LR0.0003 | loss:14.1462 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-39.8724 | logitMax:-10.4891 | windowWeightsW8:0.19809,W15:0.17805,W13:0.17491,W18:0.16247,W3:0.13707,W7:0.10769,W2:0.05619,W1:0.01085,W14:-0.04365 | memoryGatesShort:5.529, Long:-5.185, Current:0.655 | topTokens[('.', 51), ('it', 23), (',', 16), ('y', 15), ('p', 15), ('no', 7), ('who', 7), ('ee', 6), ('s', 5), ('a', 5)] | Training
2025-04-03 13:05:41 | 600 | LR0.0003 | loss:11.3730 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-43.9247 | logitMax:-20.4973 | windowWeightsW8:0.19809,W15:0.17814,W13:0.17501,W18:0.16220,W3:0.13687,W7:0.10772,W2:0.05621,W1:0.01079,W14:-0.04335 | memoryGatesShort:-4.761, Long:5.072, Current:0.690 | topTokens[('.', 29), (',', 18), ('in', 14), ('p', 8), ('ee', 8), ('no', 8), ('the', 7), ('like', 6), ('feel', 6), ('she', 5)] | Training
2025-04-03 13:11:09 | 700 | LR0.0003 | loss:10.4446 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-40.4604 | logitMax:-18.2126 | windowWeightsW8:0.19849,W15:0.17787,W13:0.17483,W18:0.16217,W3:0.13692,W7:0.10756,W2:0.05594,W1:0.01085,W14:-0.04295 | memoryGatesShort:12.266, Long:-11.112, Current:-0.154 | topTokens[('.', 31), ('to', 16), ('in', 13), (',', 13), ('the', 9), ('no', 5), ('he', 5), ('a', 4), ('for', 4), ('happy', 4)] | Training
2025-04-03 13:16:19 | 800 | LR0.0003 | loss:12.9355 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-41.9436 | logitMax:-18.0677 | windowWeightsW8:0.19829,W15:0.17788,W13:0.17495,W18:0.16209,W3:0.13679,W7:0.10755,W2:0.05604,W1:0.01085,W14:-0.04275 | memoryGatesShort:56.443, Long:-43.882, Current:-11.561 | topTokens[('for', 19), ('.', 17), ('i', 8), ('the', 7), ('my', 7), ('y', 6), ('lo', 6), ('it', 6), ('me', 5), ('in', 5)] | Training
2025-04-03 13:21:25 | 900 | LR0.0003 | loss:9.8541 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-40.3771 | logitMax:-20.2289 | windowWeightsW8:0.19824,W15:0.17789,W13:0.17491,W18:0.16211,W3:0.13655,W7:0.10785,W2:0.05598,W1:0.01072,W14:-0.04256 | memoryGatesShort:-10.749, Long:10.402, Current:1.347 | topTokens[('like', 25), ('.', 22), ('i', 12), ('y', 9), ('and', 7), ('my', 7), ('know', 6), (',', 6), ('the', 5), ('no', 5)] | Training
2025-04-03 13:26:55 | 1000 | LR0.0003 | loss:8.7365 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-35.9171 | logitMax:-19.6495 | windowWeightsW8:0.19817,W15:0.17807,W13:0.17506,W18:0.16206,W3:0.13662,W7:0.10783,W2:0.05578,W1:0.01072,W14:-0.04262 | memoryGatesShort:-7.147, Long:7.310, Current:0.837 | topTokens[(',', 33), ('the', 12), ('.', 11), ('ed', 7), ('dont', 5), ('s', 5), ('a', 4), ('them', 4), ('d', 4), ('my', 4)] | Training
2025-04-03 13:32:33 | 1100 | LR0.0003 | loss:14.9300 | gradNorm:1.0000 | tokenCount:300.0000 | logitMin:-47.8954 | logitMax:-19.1849 | windowWeightsW8:0.19786,W15:0.17813,W13:0.17502,W18:0.16240,W3:0.13635,W7:0.10788,W2:0.05569,W1:0.01078,W14:-0.04240 | memoryGatesShort:-2.771, Long:2.685, Current:1.086 | topTokens[('.', 29), ('ed', 18), ('one', 10), ('and', 9), ('they', 8), ('it', 8), (',', 7), ('b', 7), ('to', 7), ('like', 6)] | Training

--- 2025-04-03 13:37:53 --- babyllm: 'what am i learning today?'- charis: '1 num tokens per step'
2025-04-03 13:40:52 | 100 | LR0.0003 | loss:14.0396 | gradNorm:1.0000 | logitMin:-43.3265 | logitMax:-16.1412 | scheduledSampling:0.0000 | tokenCount:100.0000 | windowWeightsW8:0.19711,W15:0.17827,W13:0.17504,W18:0.16225,W3:0.13583,W7:0.10902,W2:0.05433,W1:0.01000,W14:-0.04013 | memoryGatesShort:-436.523, Long:452.202, Current:-14.679 | topTokens[('.', 8), ('like', 5), ('she', 5), ('feel', 4), ('the', 3), ('am', 3), ('s', 2), ('just', 2), ('but', 2), ('small', 2)] | Training

--- 2025-04-03 13:41:36 --- babyllm: 'what am i learning today?'- charis: '2 num tokens per step'
2025-04-03 13:45:51 | 100 | LR0.0003 | loss:14.2737 | gradNorm:1.0000 | logitMin:-43.1411 | logitMax:-15.4062 | scheduledSampling:0.0000 | tokenCount:200.0000 | windowWeightsW8:0.19658,W15:0.17647,W13:0.17384,W18:0.16141,W3:0.13717,W7:0.10858,W2:0.05438,W1:0.01130,W14:-0.03799 | memoryGatesShort:-17.265, Long:12.236, Current:6.029 | topTokens[('.', 31), ('y', 11), ('it', 11), ('cant', 7), ('like', 7), ('just', 7), (',', 3), ('?', 3), ('b', 2), ('want', 2)] | Training

--- 2025-04-03 13:46:34 --- babyllm: 'what am i learning today?'- charis: '3 num tokens per step'
2025-04-03 13:52:05 | 100 | LR0.0003 | loss:10.2319 | gradNorm:1.0000 | logitMin:-43.4975 | logitMax:-22.4020 | scheduledSampling:0.0000 | tokenCount:300.0000 | windowWeightsW8:0.19686,W15:0.17685,W13:0.17493,W18:0.16127,W3:0.13615,W7:0.10852,W2:0.05408,W1:0.01083,W14:-0.03774 | memoryGatesShort:-7.459, Long:7.635, Current:0.824 | topTokens[('.', 25), ('i', 16), ('they', 6), ('h', 6), ('here', 6), ('ot', 5), ('d', 4), ('life', 3), ('y', 3), ('a', 3)] | Training

--- 2025-04-03 13:52:57 --- babyllm: 'what am i learning today?'- charis: '4 num tokens per step'
2025-04-03 13:59:17 | 100 | LR0.0003 | loss:9.7497 | gradNorm:1.0000 | logitMin:-45.7879 | logitMax:-24.2745 | scheduledSampling:0.0000 | tokenCount:400.0000 | windowWeightsW8:0.19662,W15:0.17741,W13:0.17486,W18:0.16250,W3:0.13595,W7:0.10874,W2:0.05395,W1:0.00982,W14:-0.03811 | memoryGatesShort:9.134, Long:-6.349, Current:-1.785 | topTokens[('.', 20), ('i', 14), (',', 10), ('ot', 8), ('im', 8), ('so', 7), ('it', 6), ('?', 6), ('s', 6), ('me', 6)] | Training

--- 2025-04-03 14:00:08 --- babyllm: 'what am i learning today?'- charis: '5 num tokens per step'
2025-04-03 14:07:24 | 100 | LR0.0003 | loss:6.3348 | gradNorm:1.0000 | logitMin:-38.6925 | logitMax:-17.7554 | scheduledSampling:0.0000 | tokenCount:500.0000 | windowWeightsW8:0.19580,W15:0.17804,W13:0.17596,W18:0.16343,W3:0.13552,W7:0.10902,W2:0.05329,W1:0.01025,W14:-0.03958 | memoryGatesShort:-5.419, Long:4.335, Current:2.084 | topTokens[('to', 42), ('listening', 25), ('.', 24), ('be', 23), ('?', 20), ('she', 19), ('s', 12), ('music', 12), ('i', 11), ('was', 9)] | Training

--- 2025-04-03 14:07:59 --- babyllm: 'what am i learning today?'- charis: '6 num tokens per step'
2025-04-03 14:16:31 | 100 | LR0.0003 | loss:9.8301 | gradNorm:1.0000 | logitMin:-37.1912 | logitMax:-8.5101 | scheduledSampling:0.0000 | tokenCount:600.0000 | windowWeightsW8:0.19602,W15:0.17765,W13:0.17521,W18:0.16299,W3:0.13645,W7:0.10871,W2:0.05328,W1:0.01072,W14:-0.03931 | memoryGatesShort:-11.954, Long:11.612, Current:1.342 | topTokens[('.', 85), ('to', 64), ('?', 31), ('will', 28), ('was', 26), ('listening', 26), ('it', 26), (',', 11), ('he', 11), ('music', 10)] | Training

--- 2025-04-03 14:17:15 --- babyllm: 'what am i learning today?'- charis: '4 num tokens per step'
2025-04-03 14:23:49 | 100 | LR0.0003 | loss:8.3360 | gradNorm:1.0000 | logitMin:-44.8933 | logitMax:-14.7392 | scheduledSampling:0.0000 | tokenCount:400.0000 | windowWeightsW8:0.19494,W15:0.17600,W13:0.17505,W18:0.16330,W3:0.13597,W7:0.10850,W2:0.05431,W1:0.01229,W14:-0.03863 | memoryGatesShort:-2.532, Long:1.608, Current:1.924 | topTokens[('it', 51), ('to', 29), ('.', 28), ('was', 25), ('music', 22), (',', 18), ('listening', 14), ('feel', 11), ('s', 10), ('?', 10)] | Training
2025-04-03 14:30:31 | 200 | LR0.0003 | loss:6.5851 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-38.1283 | logitMax:-16.8617 | windowWeightsW8:0.19423,W15:0.17683,W13:0.17545,W18:0.16368,W3:0.13508,W7:0.10779,W2:0.05463,W1:0.01251,W14:-0.03845 | memoryGatesShort:-1.870, Long:0.665, Current:2.205 | topTokens[('been', 31), ('what', 25), ('listening', 24), ('to', 23), ('.', 21), ('?', 16), (',', 10), ('were', 9), ('music', 8), ('you', 6)] | Training

--- 2025-04-03 14:45:05 --- babyllm: 'what am i learning today?'- charis: 'pretty terminal :3'
2025-04-03 14:51:08 | 100 | LR0.0003 | loss:6.0763 | gradNorm:1.0000 | logitMin:-43.2822 | logitMax:-17.4105 | scheduledSampling:0.0000 | tokenCount:400.0000 | windowWeightsW8:0.19369,W15:0.17490,W13:0.17398,W18:0.16175,W3:0.13591,W7:0.10759,W2:0.05530,W1:0.01624,W21:-0.03764 | memoryGatesShort:-2.584, Long:1.866, Current:1.717 | topTokens[('to', 42), ('will', 30), ('.', 29), ('listening', 25), ('be', 22), ('music', 15), ('?', 15), ('what', 12), ('we', 11), ('you', 9)] | Training

--- 2025-04-03 14:53:54 --- babyllm: 'what am i learning today?'- charis: ''
2025-04-03 15:00:34 | 100 | LR0.0003 | loss:6.9582 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-38.6661 | logitMax:-13.4170 | windowWeightsW8:0.19415,W15:0.17482,W13:0.17355,W18:0.16106,W3:0.13520,W7:0.10753,W2:0.05635,W1:0.01704,W21:-0.03800 | memoryGatesShort:-2.260, Long:0.619, Current:2.641 | topTokens[('to', 38), ('what', 29), ('listening', 29), ('music', 18), (',', 14), ('a', 14), ('?', 14), ('you', 13), ('.', 12), ('will', 9)] | Training
2025-04-03 15:07:14 | 200 | LR0.0003 | loss:7.6277 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-38.9247 | logitMax:-10.3894 | windowWeightsW8:0.19451,W15:0.17468,W13:0.17371,W18:0.16035,W3:0.13575,W7:0.10689,W2:0.05683,W1:0.01650,W21:-0.03751 | memoryGatesShort:-4.737, Long:3.752, Current:1.985 | topTokens[('.', 27), ('i', 23), ('to', 22), ('listening', 15), ('game', 15), (',', 15), ('?', 13), ('was', 12), ('!', 10), ('you', 10)] | Training
2025-04-03 15:14:59 | 300 | LR0.0003 | loss:6.7340 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-38.0605 | logitMax:-10.2040 | windowWeightsW8:0.19407,W15:0.17429,W13:0.17324,W18:0.16011,W3:0.13585,W7:0.10592,W2:0.05798,W1:0.01733,W21:-0.03710 | memoryGatesShort:-2.525, Long:-0.309, Current:3.834 | topTokens[('.', 32), ('music', 24), ('to', 22), ('you', 17), ('?', 15), ('listening', 14), ('had', 13), ('he', 12), (',', 12), ('what', 11)] | Training
2025-04-03 15:21:36 | 400 | LR0.0003 | loss:7.3391 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-36.1120 | logitMax:-12.8959 | windowWeightsW8:0.19426,W15:0.17457,W13:0.17322,W18:0.15982,W3:0.13589,W7:0.10568,W2:0.05826,W1:0.01752,W21:-0.03754 | memoryGatesShort:-4.208, Long:1.868, Current:3.340 | topTokens[('what', 57), ('music', 36), ('.', 31), ('he', 26), ('to', 13), ('listening', 9), ('?', 7), ('a', 7), ('about', 6), ('been', 5)] | Training
2025-04-03 15:28:13 | 500 | LR0.0003 | loss:7.4639 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.4348 | logitMax:-21.1148 | windowWeightsW8:0.19383,W15:0.17476,W13:0.17318,W18:0.15965,W3:0.13619,W7:0.10537,W2:0.05856,W1:0.01734,W21:-0.03718 | memoryGatesShort:0.880, Long:-1.600, Current:1.719 | topTokens[('what', 36), ('=', 33), ('.', 23), (',', 17), ('+', 14), ('to', 10), ('music', 9), ('listening', 9), ("'re", 8), ('been', 7)] | Training
2025-04-03 15:34:46 | 600 | LR0.0003 | loss:10.0093 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-43.0520 | logitMax:-22.0239 | windowWeightsW8:0.19383,W15:0.17501,W13:0.17325,W18:0.15989,W3:0.13603,W7:0.10547,W2:0.05814,W1:0.01724,W21:-0.03716 | memoryGatesShort:3.677, Long:-0.762, Current:-1.915 | topTokens[('he', 17), ('.', 12), (',', 11), ('=', 10), ('the', 10), ('of', 9), ('+', 9), ('io', 7), ('to', 6), ('feel', 5)] | Training
2025-04-03 15:41:32 | 700 | LR0.0003 | loss:9.0920 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.6237 | logitMax:-26.3151 | windowWeightsW8:0.19364,W15:0.17518,W13:0.17335,W18:0.16008,W3:0.13557,W7:0.10558,W2:0.05793,W1:0.01731,W21:-0.03694 | memoryGatesShort:-0.268, Long:0.695, Current:0.573 | topTokens[('a', 15), ('.', 12), (',', 12), ('y', 10), ('what', 7), ('with', 7), ('of', 6), ('s', 4), ('has', 4), ('to', 4)] | Training
2025-04-03 15:47:45 | 800 | LR0.0003 | loss:10.6300 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.1371 | logitMax:-25.2159 | windowWeightsW8:0.19344,W15:0.17512,W13:0.17345,W18:0.16011,W3:0.13520,W7:0.10562,W2:0.05784,W1:0.01731,W21:-0.03638 | memoryGatesShort:-0.789, Long:1.104, Current:0.685 | topTokens[('y', 36), ('.', 23), ('now', 15), ('a', 10), ('m', 9), ('of', 7), ('not', 6), ('l', 6), ('what', 6), ('he', 6)] | Training
2025-04-03 15:54:21 | 900 | LR0.0003 | loss:9.0236 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.0417 | logitMax:-26.5034 | windowWeightsW8:0.19313,W15:0.17542,W13:0.17350,W18:0.16036,W3:0.13469,W7:0.10570,W2:0.05738,W1:0.01740,W21:-0.03586 | memoryGatesShort:-0.552, Long:1.194, Current:0.358 | topTokens[('the', 21), ('.', 15), (',', 14), ('y', 13), ('a', 10), ('of', 8), ('and', 6), ('v', 6), ('had', 5), ('what', 5)] | Training
2025-04-03 16:01:13 | 1000 | LR0.0003 | loss:10.5072 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-42.8287 | logitMax:-20.0885 | windowWeightsW8:0.19295,W15:0.17544,W13:0.17404,W18:0.16027,W3:0.13419,W7:0.10553,W2:0.05711,W1:0.01780,W21:-0.03560 | memoryGatesShort:-5.122, Long:3.022, Current:3.100 | topTokens[('.', 25), ('it', 14), ('the', 13), ('and', 13), ('y', 9), ('s', 8), ('she', 6), ('a', 6), ('it', 6), ('of', 6)] | Training
2025-04-03 16:07:44 | 1100 | LR0.0003 | loss:10.4309 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-49.6079 | logitMax:-25.6173 | windowWeightsW8:0.19238,W15:0.17529,W13:0.17357,W18:0.16046,W3:0.13464,W7:0.10530,W2:0.05738,W1:0.01766,W21:-0.03494 | memoryGatesShort:2.353, Long:-0.802, Current:-0.551 | topTokens[('it', 20), ('he', 16), (',', 12), ('.', 12), ('a', 11), ('their', 10), ('and', 8), ('the', 7), ('s', 7), ('bag', 6)] | Training
2025-04-03 16:14:11 | 1200 | LR0.0003 | loss:9.6263 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-43.2838 | logitMax:-20.4103 | windowWeightsW8:0.19407,W15:0.17572,W13:0.17310,W18:0.16021,W3:0.13381,W7:0.10607,W2:0.05565,W1:0.01724,W21:-0.03413 | memoryGatesShort:6.678, Long:-1.457, Current:-4.221 | topTokens[('om', 38), ('.', 33), ('not', 16), ('their', 15), ('of', 15), ('ust', 11), ('c', 9), (',', 9), ('the', 7), ('but', 7)] | Training
2025-04-03 16:21:24 | 1300 | LR0.0003 | loss:11.3953 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-39.5951 | logitMax:-17.0941 | windowWeightsW8:0.19430,W15:0.17585,W13:0.17276,W18:0.16078,W3:0.13373,W7:0.10595,W2:0.05556,W1:0.01750,W21:-0.03470 | memoryGatesShort:-1.610, Long:1.600, Current:1.010 | topTokens[('om', 50), ('ust', 50), ('.', 35), ('c', 32), (',', 14), ('she', 8), (':', 5), ('they', 5), ('some', 4), ('a', 3)] | Training
2025-04-03 16:28:13 | 1400 | LR0.0003 | loss:8.9288 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.5434 | logitMax:-25.0027 | windowWeightsW8:0.19458,W15:0.17593,W13:0.17308,W18:0.16050,W3:0.13366,W7:0.10597,W2:0.05548,W1:0.01780,W21:-0.03530 | memoryGatesShort:-3.909, Long:0.884, Current:4.025 | topTokens[('om', 35), ('c', 34), ('ust', 32), ('.', 21), (',', 17), ('but', 11), ('not', 10), ('ers', 8), ('she', 5), ('their', 5)] | Training
2025-04-03 16:34:51 | 1500 | LR0.0003 | loss:8.9925 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.5568 | logitMax:-31.6662 | windowWeightsW8:0.19359,W15:0.17660,W13:0.17334,W18:0.16148,W3:0.13264,W7:0.10592,W2:0.05505,W1:0.01779,W21:-0.03466 | memoryGatesShort:-0.778, Long:1.050, Current:0.729 | topTokens[('ust', 21), ('c', 17), ('.', 16), ('om', 14), (',', 13), ('to', 9), ('the', 9), ('they', 8), ('she', 7), ('of', 7)] | Training
2025-04-03 16:41:23 | 1600 | LR0.0003 | loss:7.5831 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.1899 | logitMax:-35.9056 | windowWeightsW8:0.19250,W15:0.17702,W13:0.17322,W18:0.16220,W3:0.13251,W7:0.10563,W2:0.05472,W1:0.01800,W21:-0.03402 | memoryGatesShort:-5.280, Long:0.570, Current:5.710 | topTokens[(',', 29), ('the', 15), ('of', 10), ('to', 9), ('.', 8), ('and', 7), ('c', 7), ('in', 6), ('le', 6), ('not', 6)] | Training
2025-04-03 16:47:14 | 1700 | LR0.0003 | loss:9.2629 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-43.2831 | logitMax:-24.5478 | windowWeightsW8:0.19197,W15:0.17780,W13:0.17381,W18:0.16282,W3:0.13172,W7:0.10533,W2:0.05428,W1:0.01754,W21:-0.03348 | memoryGatesShort:-1.291, Long:0.921, Current:1.370 | topTokens[('s', 73), ('es', 30), (',', 17), ('.', 17), ('of', 11), ('c', 10), ('b', 9), ('the', 4), ('them', 4), ('who', 4)] | Training
2025-04-03 16:53:08 | 1800 | LR0.0003 | loss:9.1421 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.0848 | logitMax:-26.4460 | windowWeightsW8:0.19142,W15:0.17869,W13:0.17455,W18:0.16430,W3:0.12980,W7:0.10510,W2:0.05352,W1:0.01761,W21:-0.03316 | memoryGatesShort:-1.330, Long:0.976, Current:1.354 | topTokens[('.', 26), ('c', 19), ('for', 17), (',', 14), ('ed', 14), ('in', 9), ('that', 9), ('of', 8), ('r', 6), ('and', 6)] | Training
2025-04-03 16:59:04 | 1900 | LR0.0003 | loss:8.3653 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-39.9349 | logitMax:-21.7542 | windowWeightsW8:0.19092,W15:0.17903,W13:0.17430,W18:0.16458,W3:0.12929,W7:0.10548,W2:0.05372,W1:0.01746,W21:-0.03295 | memoryGatesShort:-42.094, Long:21.369, Current:21.725 | topTokens[('.', 26), ('in', 15), (',', 14), ('for', 13), ('ed', 12), ('what', 11), ('going', 6), ('-', 6), ('c', 5), ('-', 4)] | Training
2025-04-03 17:05:25 | 2000 | LR0.0003 | loss:9.2201 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-48.8696 | logitMax:-30.1732 | windowWeightsW8:0.19083,W15:0.17920,W13:0.17365,W18:0.16485,W3:0.12946,W7:0.10568,W2:0.05360,W1:0.01755,W21:-0.03300 | memoryGatesShort:-0.286, Long:0.880, Current:0.406 | topTokens[('in', 31), ('.', 19), (',', 12), ('c', 9), ('and', 8), ('ed', 8), ('what', 7), ('one', 6), ('ri', 6), ('she', 5)] | Training
2025-04-03 17:11:21 | 2100 | LR0.0003 | loss:12.1060 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-48.5569 | logitMax:-22.6381 | windowWeightsW8:0.19041,W15:0.17930,W13:0.17369,W18:0.16539,W3:0.12891,W7:0.10557,W2:0.05307,W1:0.01751,W21:-0.03201 | memoryGatesShort:-13.028, Long:3.988, Current:10.040 | topTokens[('.', 37), ('the', 35), ('for', 14), (',', 13), ('to', 12), ('in', 10), ('am', 8), ('no', 7), ('c', 7), ('and', 6)] | Training
2025-04-03 17:17:25 | 2200 | LR0.0003 | loss:8.7875 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-46.9336 | logitMax:-27.7318 | windowWeightsW8:0.18963,W15:0.17962,W13:0.17413,W18:0.16610,W3:0.12800,W7:0.10567,W2:0.05280,W1:0.01709,W21:-0.03117 | memoryGatesShort:5.672, Long:-3.086, Current:-1.587 | topTokens[('for', 17), (',', 16), ('can', 14), ('no', 13), ('in', 9), ('you', 8), ('and', 7), ('ed', 7), ('were', 7), ('of', 7)] | Training
2025-04-03 17:23:45 | 2300 | LR0.0003 | loss:8.8109 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-49.2841 | logitMax:-29.7308 | windowWeightsW8:0.18966,W15:0.18001,W13:0.17424,W18:0.16684,W3:0.12711,W7:0.10551,W2:0.05270,W1:0.01663,W21:-0.03081 | memoryGatesShort:-3.723, Long:2.097, Current:2.626 | topTokens[('if', 12), (',', 11), ('a', 11), ('stay', 10), ('you', 10), ('.', 8), ('what', 7), ('i', 7), ('gotta', 7), ('om', 6)] | Training
2025-04-03 17:30:04 | 2400 | LR0.0003 | loss:6.1799 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.4836 | logitMax:-33.1246 | windowWeightsW8:0.18791,W15:0.17965,W13:0.17382,W18:0.16829,W3:0.12708,W7:0.10517,W2:0.05245,W1:0.01747,W21:-0.02993 | memoryGatesShort:-1.172, Long:0.397, Current:1.775 | topTokens[('er', 30), (',', 25), ('the', 18), ('z', 18), ('ing', 15), ('that', 12), ('have', 9), ('p', 9), ('you', 8), ('.', 8)] | Training
2025-04-03 17:36:49 | 2500 | LR0.0003 | loss:12.1017 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-69.4657 | logitMax:-18.1944 | windowWeightsW8:0.18699,W15:0.18024,W13:0.17241,W18:0.16836,W3:0.12607,W7:0.10587,W2:0.05418,W1:0.01902,W21:-0.03124 | memoryGatesShort:-2.491, Long:-0.578, Current:4.069 | topTokens[('z', 84), ('.', 43), ('ing', 42), ('i', 17), (',', 16), ('bu', 15), ('the', 12), ('*', 12), ('elodie', 11), ('er', 10)] | Training
2025-04-03 17:43:05 | 2600 | LR0.0003 | loss:7.6857 | gradNorm:0.9893 | tokenCount:400.0000 | logitMin:-65.0765 | logitMax:-8.5186 | windowWeightsW8:0.18650,W15:0.17828,W13:0.17178,W18:0.16754,W3:0.12787,W7:0.10693,W2:0.05629,W1:0.02050,W21:-0.03383 | memoryGatesShort:-1.940, Long:-0.197, Current:3.137 | topTokens[(',', 42), ('ing', 38), ('*', 37), ('z', 24), ('.', 23), ('er', 19), ('b', 18), ('bu', 17), ('on', 14), ('b', 14)] | Training
2025-04-03 17:49:14 | 2700 | LR0.0003 | loss:11.4352 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-48.5918 | logitMax:-18.0249 | windowWeightsW8:0.18674,W15:0.17872,W13:0.17245,W18:0.16705,W3:0.12765,W7:0.10713,W2:0.05569,W1:0.02004,W21:-0.03362 | memoryGatesShort:-10.012, Long:1.200, Current:9.812 | topTokens[('.', 61), (',', 46), ('iss', 42), ('the', 27), ('b', 26), ('t', 24), ('*', 22), ('ry', 22), ('ing', 8), ('*', 7)] | Training
2025-04-03 17:55:25 | 2800 | LR0.0003 | loss:9.6342 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.0465 | logitMax:-25.1424 | windowWeightsW8:0.18660,W15:0.17910,W13:0.17251,W18:0.16721,W3:0.12754,W7:0.10695,W2:0.05555,W1:0.02007,W21:-0.03368 | memoryGatesShort:-2.429, Long:2.750, Current:0.678 | topTokens[(',', 30), ('.', 26), ('the', 21), ('t', 15), ('*', 13), ('b', 13), ('*', 10), ('ry', 10), ('iss', 8), ('b', 8)] | Training
2025-04-03 18:01:34 | 2900 | LR0.0003 | loss:8.3201 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.2607 | logitMax:-28.8117 | windowWeightsW8:0.18665,W15:0.17923,W13:0.17254,W18:0.16731,W3:0.12732,W7:0.10691,W2:0.05541,W1:0.02004,W21:-0.03353 | memoryGatesShort:-3.053, Long:2.655, Current:1.398 | topTokens[(',', 26), ('i', 20), ('ing', 15), ('*', 12), ('the', 8), ('be', 8), ('no', 8), ('b', 7), ('this', 7), ('iss', 6)] | Training
2025-04-03 18:07:57 | 3000 | LR0.0003 | loss:8.9012 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.2208 | logitMax:-26.8749 | windowWeightsW8:0.18667,W15:0.17931,W13:0.17271,W18:0.16731,W3:0.12708,W7:0.10693,W2:0.05522,W1:0.02018,W21:-0.03352 | memoryGatesShort:8.218, Long:-0.883, Current:-6.335 | topTokens[(',', 22), ('be', 16), ('ing', 11), ('i', 11), ('.', 11), ('*', 8), ('it', 7), ('b', 6), ('z', 6), ('f', 5)] | Training
2025-04-03 18:14:30 | 3100 | LR0.0003 | loss:10.8167 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.0688 | logitMax:-25.7057 | windowWeightsW8:0.18716,W15:0.17906,W13:0.17267,W18:0.16720,W3:0.12675,W7:0.10718,W2:0.05512,W1:0.01997,W21:-0.03325 | memoryGatesShort:9.459, Long:-5.985, Current:-2.474 | topTokens[('me', 28), ('.', 25), ('like', 20), ('you', 19), ('s', 14), (',', 10), ('i', 10), ('who', 7), ('can', 7), ('prom', 7)] | Training
2025-04-03 18:21:15 | 3200 | LR0.0003 | loss:8.3997 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-46.6823 | logitMax:-28.7961 | windowWeightsW8:0.18700,W15:0.17958,W13:0.17297,W18:0.16757,W3:0.12656,W7:0.10680,W2:0.05508,W1:0.01964,W21:-0.03332 | memoryGatesShort:9.060, Long:-5.896, Current:-2.164 | topTokens[('me', 17), (',', 15), ('you', 13), ('i', 12), ('.', 9), ('it', 8), ('and', 7), ('the', 7), ('my', 6), ('all', 5)] | Training
2025-04-03 18:27:43 | 3300 | LR0.0003 | loss:8.8347 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.1913 | logitMax:-31.9410 | windowWeightsW8:0.18677,W15:0.17989,W13:0.17308,W18:0.16789,W3:0.12658,W7:0.10687,W2:0.05461,W1:0.01945,W21:-0.03326 | memoryGatesShort:-6.042, Long:6.676, Current:0.366 | topTokens[('me', 19), ('you', 13), ('.', 13), ('like', 12), (',', 12), ('a', 10), ('id', 8), ('i', 7), ('she', 6), ('d', 6)] | Training
2025-04-03 18:34:17 | 3400 | LR0.0003 | loss:9.2495 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-48.1104 | logitMax:-28.0508 | windowWeightsW8:0.18663,W15:0.18040,W13:0.17326,W18:0.16821,W3:0.12572,W7:0.10706,W2:0.05412,W1:0.01944,W21:-0.03295 | memoryGatesShort:-8.345, Long:7.844, Current:1.501 | topTokens[(',', 25), ('i', 12), ('my', 11), ('id', 7), ('.', 7), ('because', 6), ('a', 6), ('your', 6), ('c', 5), ('d', 5)] | Training
2025-04-03 18:40:47 | 3500 | LR0.0003 | loss:8.4191 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.3706 | logitMax:-28.9519 | windowWeightsW8:0.18674,W15:0.17987,W13:0.17319,W18:0.16795,W3:0.12581,W7:0.10753,W2:0.05420,W1:0.01906,W21:-0.03245 | memoryGatesShort:-1.498, Long:1.211, Current:1.286 | topTokens[(',', 21), ('es', 18), ('f', 17), ('b', 7), ('tried', 7), ('who', 5), ('of', 5), ('me', 5), ('i', 5), ('b', 5)] | Training
2025-04-03 18:47:17 | 3600 | LR0.0003 | loss:6.3013 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.0146 | logitMax:-24.2990 | windowWeightsW8:0.18566,W15:0.17995,W13:0.17271,W18:0.16787,W3:0.12805,W7:0.10611,W2:0.05475,W1:0.01952,W21:-0.03275 | memoryGatesShort:-1.432, Long:-0.293, Current:2.725 | topTokens[('i', 31), ('!', 20), ('.', 19), ('it', 19), ('know', 14), (',', 13), ('like', 11), ('am', 9), ('just', 9), ('happy', 9)] | Training
2025-04-03 18:53:52 | 3700 | LR0.0003 | loss:14.1584 | gradNorm:0.9913 | tokenCount:400.0000 | logitMin:-69.3995 | logitMax:12.0775 | windowWeightsW8:0.18630,W15:0.18014,W13:0.17350,W18:0.16729,W3:0.13143,W7:0.10452,W2:0.05506,W1:0.01823,W21:-0.03472 | memoryGatesShort:6.256, Long:3.983, Current:-9.239 | topTokens[('.', 52), ('hey', 37), ('it', 32), ('i', 32), ('!', 25), (',', 18), ('know', 17), ('did', 15), ('elodie', 14), ('am', 13)] | Training
2025-04-03 19:00:33 | 3800 | LR0.0003 | loss:11.1297 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-43.2399 | logitMax:-19.2666 | windowWeightsW8:0.18676,W15:0.18021,W13:0.17372,W18:0.16755,W3:0.13083,W7:0.10483,W2:0.05503,W1:0.01691,W21:-0.03409 | memoryGatesShort:-0.434, Long:0.906, Current:0.528 | topTokens[('hey', 63), ('baby', 28), (',', 22), ('to', 14), ('a', 10), ('.', 8), ('my', 7), ('s', 6), ('she', 6), ('am', 6)] | Training
2025-04-03 19:07:18 | 3900 | LR0.0003 | loss:10.3372 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-39.9047 | logitMax:-19.6911 | windowWeightsW8:0.18689,W15:0.18012,W13:0.17371,W18:0.16755,W3:0.13083,W7:0.10490,W2:0.05508,W1:0.01674,W21:-0.03407 | memoryGatesShort:-3.211, Long:3.356, Current:0.855 | topTokens[('hey', 48), ('.', 30), (',', 19), ('you', 12), ('that', 11), ('baby', 10), ('to', 8), ('c', 7), ('be', 7), ('it', 7)] | Training
2025-04-03 19:13:58 | 4000 | LR0.0003 | loss:9.8619 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-41.3475 | logitMax:-21.9068 | windowWeightsW8:0.18785,W15:0.17940,W13:0.17397,W18:0.16632,W3:0.13221,W7:0.10596,W2:0.05337,W1:0.01706,W21:-0.03440 | memoryGatesShort:-4.522, Long:5.708, Current:-0.186 | topTokens[('it', 49), ('and', 36), ('hey', 27), ('into', 17), (',', 15), ('.', 13), ('that', 7), ('feel', 6), ('ous', 5), ('a', 5)] | Training
2025-04-03 19:20:38 | 4100 | LR0.0003 | loss:9.9698 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-30.7064 | logitMax:-13.4871 | windowWeightsW8:0.18791,W15:0.17955,W13:0.17410,W18:0.16641,W3:0.13223,W7:0.10589,W2:0.05338,W1:0.01723,W21:-0.03496 | memoryGatesShort:-3.692, Long:3.512, Current:1.180 | topTokens[('and', 72), ('it', 51), ('into', 24), ('.', 13), (',', 11), ('a', 7), ('b', 7), ('mess', 7), ('she', 4), ('in', 4)] | Training
2025-04-03 19:27:28 | 4200 | LR0.0003 | loss:9.2395 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-35.6537 | logitMax:-19.4441 | windowWeightsW8:0.18801,W15:0.17973,W13:0.17422,W18:0.16652,W3:0.13221,W7:0.10586,W2:0.05339,W1:0.01716,W21:-0.03538 | memoryGatesShort:-3.124, Long:3.894, Current:0.230 | topTokens[('and', 59), ('it', 53), ('.', 30), ('into', 18), ('mess', 9), (',', 8), ('b', 5), ('them', 4), ('a', 4), ('she', 4)] | Training
2025-04-03 19:34:08 | 4300 | LR0.0003 | loss:10.6017 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-36.9125 | logitMax:-18.1238 | windowWeightsW8:0.18802,W15:0.17990,W13:0.17437,W18:0.16663,W3:0.13217,W7:0.10575,W2:0.05329,W1:0.01705,W21:-0.03545 | memoryGatesShort:-2.516, Long:2.868, Current:0.647 | topTokens[('it', 76), ('and', 58), (',', 15), ('mess', 10), ('b', 7), ('.', 6), ('into', 6), ('were', 6), ('a', 6), ('some', 4)] | Training
2025-04-03 19:40:55 | 4400 | LR0.0003 | loss:11.2278 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-38.9444 | logitMax:-17.0793 | windowWeightsW8:0.18787,W15:0.17999,W13:0.17435,W18:0.16672,W3:0.13217,W7:0.10582,W2:0.05310,W1:0.01722,W21:-0.03552 | memoryGatesShort:-6.844, Long:7.960, Current:-0.116 | topTokens[('it', 66), ('and', 54), ('am', 16), ('.', 10), ('she', 9), ('mess', 7), ('f', 7), ('were', 6), (',', 6), ('into', 6)] | Training
2025-04-03 19:47:34 | 4500 | LR0.0003 | loss:11.5383 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-44.7546 | logitMax:-21.8925 | windowWeightsW8:0.18794,W15:0.18001,W13:0.17431,W18:0.16676,W3:0.13204,W7:0.10578,W2:0.05302,W1:0.01736,W21:-0.03549 | memoryGatesShort:-2.600, Long:1.884, Current:1.716 | topTokens[('it', 72), ('and', 37), ('.', 15), ('she', 8), ('mess', 7), ('that', 7), (',', 7), ('ed', 6), ('were', 5), ('a', 5)] | Training
2025-04-03 19:54:28 | 4600 | LR0.0003 | loss:12.3099 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-48.3467 | logitMax:-22.8313 | windowWeightsW8:0.18781,W15:0.17996,W13:0.17420,W18:0.16668,W3:0.13184,W7:0.10587,W2:0.05290,W1:0.01735,W21:-0.03487 | memoryGatesShort:-2.368, Long:2.198, Current:1.170 | topTokens[('and', 24), ('it', 12), ('mess', 12), ('u', 11), ('am', 10), (',', 10), ('baby', 10), ('.', 9), ('p', 9), ('she', 8)] | Training
2025-04-03 20:01:13 | 4700 | LR0.0003 | loss:8.7090 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-40.3879 | logitMax:-22.8415 | windowWeightsW8:0.18775,W15:0.18006,W13:0.17425,W18:0.16675,W3:0.13173,W7:0.10584,W2:0.05275,W1:0.01728,W21:-0.03468 | memoryGatesShort:69.904, Long:-71.876, Current:2.972 | topTokens[('it', 17), ('.', 14), ('as', 12), ('baby', 11), ('and', 9), ('re', 8), ('am', 8), (',', 7), ('ly', 6), ('mess', 5)] | Training
2025-04-03 20:07:54 | 4800 | LR0.0003 | loss:10.1861 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-46.4931 | logitMax:-24.2848 | windowWeightsW8:0.18761,W15:0.18035,W13:0.17445,W18:0.16685,W3:0.13167,W7:0.10589,W2:0.05261,W1:0.01713,W21:-0.03483 | memoryGatesShort:31.657, Long:-21.926, Current:-8.731 | topTokens[('it', 28), (',', 15), ('and', 13), ('like', 12), ('.', 11), ('the', 10), ('have', 10), ('to', 9), ('this', 8), ('a', 5)] | Training
2025-04-03 20:14:18 | 4900 | LR0.0003 | loss:10.7986 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.4832 | logitMax:-27.4456 | windowWeightsW8:0.18755,W15:0.18037,W13:0.17445,W18:0.16692,W3:0.13155,W7:0.10587,W2:0.05249,W1:0.01688,W21:-0.03434 | memoryGatesShort:-8.567, Long:6.533, Current:3.034 | topTokens[('it', 17), ('and', 11), ('.', 10), ('like', 9), ('that', 8), ('u', 7), ('le', 7), (',', 7), ('know', 7), ('have', 6)] | Training
2025-04-03 20:20:28 | 5000 | LR0.0003 | loss:9.1523 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.3723 | logitMax:-26.5113 | windowWeightsW8:0.18786,W15:0.18035,W13:0.17415,W18:0.16686,W3:0.13151,W7:0.10562,W2:0.05249,W1:0.01731,W21:-0.03440 | memoryGatesShort:-3.047, Long:2.545, Current:1.503 | topTokens[(',', 26), ('.', 21), ('it', 12), ('and', 10), ('of', 8), ('she', 7), ('lo', 6), ('this', 6), ('re', 5), ('b', 5)] | Training
2025-04-03 20:26:33 | 5100 | LR0.0003 | loss:8.3335 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-39.9855 | logitMax:-23.2812 | windowWeightsW8:0.18785,W15:0.18047,W13:0.17430,W18:0.16702,W3:0.13144,W7:0.10553,W2:0.05245,W1:0.01724,W21:-0.03457 | memoryGatesShort:-5.361, Long:4.803, Current:1.557 | topTokens[(',', 17), ('ing', 14), ('it', 8), ('.', 7), ('b', 6), ('and', 6), ('of', 6), ('a', 5), ('re', 5), ('am', 5)] | Training
2025-04-03 20:32:35 | 5200 | LR0.0003 | loss:7.9297 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.2020 | logitMax:-29.4432 | windowWeightsW8:0.18758,W15:0.18040,W13:0.17417,W18:0.16712,W3:0.13135,W7:0.10574,W2:0.05259,W1:0.01724,W21:-0.03445 | memoryGatesShort:-3.561, Long:2.366, Current:2.195 | topTokens[('.', 14), (',', 12), ('of', 8), ('and', 8), ('a', 8), ('al', 7), ('feel', 7), ('no', 7), ('it', 7), ('ing', 6)] | Training
2025-04-03 20:38:42 | 5300 | LR0.0003 | loss:12.7447 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.0796 | logitMax:-26.9045 | windowWeightsW8:0.18797,W15:0.18045,W13:0.17422,W18:0.16721,W3:0.13122,W7:0.10573,W2:0.05246,W1:0.01699,W21:-0.03451 | memoryGatesShort:-9.280, Long:8.761, Current:1.519 | topTokens[('it', 28), ('am', 17), ('im', 12), ('.', 12), ('s', 11), ('d', 10), (',', 9), ('get', 9), ('in', 8), ('a', 7)] | Training
2025-04-03 20:45:20 | 5400 | LR0.0003 | loss:9.3563 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.1250 | logitMax:-26.2728 | windowWeightsW8:0.18849,W15:0.18063,W13:0.17441,W18:0.16736,W3:0.13085,W7:0.10601,W2:0.05219,W1:0.01603,W21:-0.03423 | memoryGatesShort:-1.694, Long:2.791, Current:-0.097 | topTokens[('.', 35), ('and', 14), ('a', 13), ('g', 10), ('the', 9), (',', 9), ('s', 8), ('kevin', 8), ('b', 7), ('had', 4)] | Training
2025-04-03 20:51:35 | 5500 | LR0.0003 | loss:10.6457 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.4829 | logitMax:-29.9993 | windowWeightsW8:0.18824,W15:0.18071,W13:0.17432,W18:0.16754,W3:0.13082,W7:0.10592,W2:0.05222,W1:0.01595,W21:-0.03399 | memoryGatesShort:5.456, Long:-2.976, Current:-1.480 | topTokens[('it', 27), ('en', 18), ('and', 17), (',', 12), ('a', 10), ('play', 10), ('.', 9), ('b', 8), ('f', 7), ('j', 6)] | Training
2025-04-03 20:57:24 | 5600 | LR0.0003 | loss:10.6549 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-42.8150 | logitMax:-20.3862 | windowWeightsW8:0.18785,W15:0.18071,W13:0.17429,W18:0.16728,W3:0.13068,W7:0.10581,W2:0.05235,W1:0.01578,W21:-0.03300 | memoryGatesShort:-3.403, Long:3.440, Current:0.963 | topTokens[('.', 26), (',', 14), ('en', 10), ('up', 9), ('s', 8), ('kevin', 7), ('b', 7), ('f', 6), ('s', 6), ('who', 6)] | Training
2025-04-03 21:03:16 | 5700 | LR0.0003 | loss:11.1917 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.5743 | logitMax:-29.1851 | windowWeightsW8:0.18790,W15:0.18057,W13:0.17426,W18:0.16723,W3:0.13065,W7:0.10583,W2:0.05227,W1:0.01568,W21:-0.03264 | memoryGatesShort:-6.750, Long:6.428, Current:1.322 | topTokens[('.', 13), (',', 10), ('that', 10), ('f', 9), ('he', 9), ('b', 7), ('an', 7), ('j', 7), ('up', 6), ('she', 6)] | Training
2025-04-03 21:09:48 | 5800 | LR0.0003 | loss:8.0455 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-55.4387 | logitMax:-39.2616 | windowWeightsW8:0.18759,W15:0.18071,W13:0.17459,W18:0.16717,W3:0.13046,W7:0.10562,W2:0.05257,W1:0.01568,W21:-0.03263 | memoryGatesShort:-3.113, Long:3.091, Current:1.023 | topTokens[('.', 21), ('or', 14), ('w', 12), ('o', 10), ('my', 7), ('play', 6), ('en', 5), ('it', 5), ('a', 5), (',', 5)] | Training
2025-04-03 21:16:25 | 5900 | LR0.0003 | loss:9.0832 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.8438 | logitMax:-30.0718 | windowWeightsW8:0.18794,W15:0.18070,W13:0.17465,W18:0.16720,W3:0.13037,W7:0.10555,W2:0.05227,W1:0.01554,W21:-0.03246 | memoryGatesShort:-6.597, Long:5.274, Current:2.323 | topTokens[('.', 25), ('or', 9), (',', 8), ('not', 7), ('now', 7), ('b', 6), ('ck', 6), ('who', 5), ('r', 5), ('is', 5)] | Training
2025-04-03 21:23:38 | 6000 | LR0.0003 | loss:9.3670 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.4437 | logitMax:-31.5697 | windowWeightsW8:0.18784,W15:0.18035,W13:0.17435,W18:0.16703,W3:0.13018,W7:0.10578,W2:0.05223,W1:0.01547,W21:-0.03144 | memoryGatesShort:-2.048, Long:1.830, Current:1.218 | topTokens[('.', 25), ('i', 15), ('or', 13), (',', 13), ('now', 10), ('it', 7), ('m', 7), ('!', 6), ('with', 6), ('were', 6)] | Training
2025-04-03 21:30:17 | 6100 | LR0.0003 | loss:8.5808 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-48.7887 | logitMax:-31.8710 | windowWeightsW8:0.18881,W15:0.18037,W13:0.17473,W18:0.16715,W3:0.12958,W7:0.10563,W2:0.05287,W1:0.01479,W21:-0.03216 | memoryGatesShort:-82.852, Long:74.392, Current:9.459 | topTokens[('be', 15), ('.', 13), ('?', 12), ('y', 12), (',', 9), ('i', 6), ('and', 6), ('it', 6), ('exam', 5), ('/', 4)] | Training
2025-04-03 21:37:06 | 6200 | LR0.0003 | loss:8.7861 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-48.4930 | logitMax:-30.8654 | windowWeightsW8:0.18882,W15:0.18032,W13:0.17478,W18:0.16733,W3:0.12977,W7:0.10542,W2:0.05261,W1:0.01506,W21:-0.03234 | memoryGatesShort:-3.967, Long:2.716, Current:2.251 | topTokens[('.', 34), ('d', 14), (',', 10), ('it', 8), ('exam', 8), ('b', 6), ('l', 6), ('?', 5), ('to', 4), ('be', 4)] | Training
2025-04-03 21:44:25 | 6300 | LR0.0003 | loss:11.9455 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.4836 | logitMax:-29.4193 | windowWeightsW8:0.18892,W15:0.18045,W13:0.17491,W18:0.16764,W3:0.12902,W7:0.10573,W2:0.05190,W1:0.01480,W21:-0.03160 | memoryGatesShort:10.758, Long:-10.760, Current:1.002 | topTokens[('.', 24), ('b', 21), (',', 13), ('this', 12), ('can', 10), ('y', 9), ('l', 6), ('ie', 6), ('i', 6), ('to', 5)] | Training
2025-04-03 21:51:40 | 6400 | LR0.0003 | loss:10.1633 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.5816 | logitMax:-36.2496 | windowWeightsW8:0.18869,W15:0.18047,W13:0.17487,W18:0.16773,W3:0.12899,W7:0.10582,W2:0.05170,W1:0.01442,W21:-0.03090 | memoryGatesShort:-3.325, Long:3.239, Current:1.086 | topTokens[('.', 21), ('and', 12), ('to', 12), (',', 9), ('i', 9), ('but', 7), ('like', 7), ('al', 6), ('or', 6), ('tho', 6)] | Training
2025-04-03 21:58:31 | 6500 | LR0.0003 | loss:10.5869 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-52.9521 | logitMax:-33.1091 | windowWeightsW8:0.18834,W15:0.18077,W13:0.17486,W18:0.16789,W3:0.12852,W7:0.10593,W2:0.05132,W1:0.01419,W21:-0.03002 | memoryGatesShort:-3.565, Long:3.110, Current:1.455 | topTokens[('c', 22), ('p', 18), ('y', 16), ('it', 15), (':', 14), ('.', 13), (',', 11), ('tho', 7), ('can', 7), ('i', 6)] | Training
2025-04-03 22:05:46 | 6600 | LR0.0003 | loss:8.8376 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.8478 | logitMax:-31.9290 | windowWeightsW8:0.18985,W15:0.18053,W13:0.17453,W18:0.16791,W3:0.12875,W7:0.10526,W2:0.05188,W1:0.01334,W21:-0.03024 | memoryGatesShort:-2.799, Long:3.269, Current:0.530 | topTokens[('p', 13), ('.', 13), (':', 10), ('c', 10), ('you', 8), ('to', 7), (',', 7), ('!', 6), ('have', 6), ('a', 5)] | Training
2025-04-03 22:13:34 | 6700 | LR0.0003 | loss:11.5405 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.9183 | logitMax:-29.6818 | windowWeightsW8:0.18760,W15:0.18093,W13:0.17402,W18:0.16831,W3:0.12815,W7:0.10509,W2:0.05276,W1:0.01350,W21:-0.02853 | memoryGatesShort:34.474, Long:-14.234, Current:-19.241 | topTokens[('be', 55), ('we', 51), (',', 34), ('.', 20), ('you', 11), ('i', 7), ('tho', 6), (':', 5), ('and', 5), (':', 5)] | Training
2025-04-03 22:22:03 | 6800 | LR0.0003 | loss:9.6424 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-40.1332 | logitMax:-17.0069 | windowWeightsW8:0.18847,W15:0.18085,W13:0.17447,W18:0.16833,W3:0.12832,W7:0.10483,W2:0.05261,W1:0.01294,W21:-0.02900 | memoryGatesShort:-10.760, Long:8.854, Current:2.906 | topTokens[('we', 50), (',', 40), ('be', 40), ('gonna', 17), ('.', 15), ("'re", 15), ('i', 11), ('she', 7), ('is', 7), ('a', 6)] | Training
2025-04-03 22:30:23 | 6900 | LR0.0003 | loss:8.4888 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-44.9280 | logitMax:-23.6354 | windowWeightsW8:0.18906,W15:0.18040,W13:0.17448,W18:0.16791,W3:0.12855,W7:0.10440,W2:0.05319,W1:0.01320,W21:-0.02939 | memoryGatesShort:-11.827, Long:6.259, Current:6.569 | topTokens[('be', 40), ('we', 33), (',', 25), ('?', 18), ('i', 13), ('to', 12), ('know', 10), ('.', 9), ('gonna', 7), ("'re", 7)] | Training
2025-04-03 22:38:03 | 7000 | LR0.0003 | loss:9.0368 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-38.7185 | logitMax:-15.0700 | windowWeightsW8:0.19016,W15:0.18029,W13:0.17453,W18:0.16751,W3:0.12885,W7:0.10420,W2:0.05350,W1:0.01240,W21:-0.02965 | memoryGatesShort:-30.889, Long:19.530, Current:12.359 | topTokens[(',', 34), ('?', 23), ('.', 15), ('be', 14), ('to', 13), ('you', 13), ('we', 12), ('im', 10), ('is', 8), ('i', 7)] | Training
2025-04-03 22:45:50 | 7100 | LR0.0003 | loss:8.2964 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-42.8845 | logitMax:-20.1663 | windowWeightsW8:0.19076,W15:0.17997,W13:0.17458,W18:0.16769,W3:0.12844,W7:0.10438,W2:0.05319,W1:0.01244,W21:-0.02966 | memoryGatesShort:-3.002, Long:2.682, Current:1.320 | topTokens[(',', 33), ('?', 20), ('we', 19), ('.', 17), ('is', 15), ('im', 13), ('to', 12), ('in', 12), ('be', 8), ('i', 8)] | Training
2025-04-03 22:53:14 | 7200 | LR0.0003 | loss:9.8286 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-42.0539 | logitMax:-18.0357 | windowWeightsW8:0.19152,W15:0.17900,W13:0.17421,W18:0.16678,W3:0.12922,W7:0.10554,W2:0.05312,W1:0.01164,W21:-0.02925 | memoryGatesShort:-15.719, Long:10.836, Current:5.883 | topTokens[('?', 44), (',', 34), ('want', 24), ('.', 21), ('is', 17), ('what', 16), ('i', 16), ('to', 12), ('feel', 7), ('you', 6)] | Training
2025-04-03 23:00:37 | 7300 | LR0.0003 | loss:8.6172 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-41.3501 | logitMax:-16.8917 | windowWeightsW8:0.19130,W15:0.17921,W13:0.17448,W18:0.16688,W3:0.12891,W7:0.10495,W2:0.05333,W1:0.01212,W21:-0.02938 | memoryGatesShort:9.950, Long:-2.373, Current:-6.577 | topTokens[(',', 33), ('to', 25), ('.', 20), ('?', 17), ('want', 16), ('you', 16), ('do', 16), ('what', 14), ('is', 13), ('i', 10)] | Training
2025-04-03 23:08:07 | 7400 | LR0.0003 | loss:6.6222 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.0538 | logitMax:-26.6886 | windowWeightsW8:0.19174,W15:0.17944,W13:0.17476,W18:0.16665,W3:0.12828,W7:0.10494,W2:0.05376,W1:0.01168,W21:-0.02947 | memoryGatesShort:-3.987, Long:2.643, Current:2.344 | topTokens[('?', 22), ('you', 18), ('.', 18), (',', 16), ('i', 15), ('do', 15), ('no', 14), ('to', 14), ('was', 12), ('want', 10)] | Training
2025-04-03 23:15:51 | 7500 | LR0.0003 | loss:6.1595 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-43.1376 | logitMax:-23.5391 | windowWeightsW8:0.18985,W15:0.17931,W13:0.17461,W18:0.16540,W3:0.12724,W7:0.10494,W2:0.05531,W1:0.01379,W21:-0.02865 | memoryGatesShort:-20.023, Long:7.767, Current:13.256 | topTokens[('?', 27), ('.', 25), ('for', 23), ('was', 18), ('i', 14), ('you', 12), ('not', 10), (',', 9), ('a', 8), ('kevin', 7)] | Training
2025-04-03 23:23:27 | 7600 | LR0.0003 | loss:6.6160 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-46.5919 | logitMax:-28.2751 | windowWeightsW8:0.19138,W15:0.17886,W13:0.17435,W18:0.16600,W3:0.12724,W7:0.10428,W2:0.05506,W1:0.01361,W21:-0.02901 | memoryGatesShort:-2.781, Long:2.173, Current:1.608 | topTokens[('?', 24), ('is', 15), ('was', 14), ('you', 14), ('for', 10), ('.', 7), ('a', 7), (',', 7), ("'m", 7), ('it', 7)] | Training
2025-04-03 23:30:45 | 7700 | LR0.0003 | loss:6.7604 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-42.4985 | logitMax:-21.9971 | windowWeightsW8:0.19123,W15:0.17801,W13:0.17384,W18:0.16585,W3:0.12757,W7:0.10347,W2:0.05591,W1:0.01473,W21:-0.02884 | memoryGatesShort:-2.827, Long:1.771, Current:2.056 | topTokens[('for', 22), ('.', 20), ('?', 20), (',', 13), ('you', 13), ('b', 10), ('to', 10), ('i', 10), ('not', 9), ('a', 9)] | Training
2025-04-03 23:38:01 | 7800 | LR0.0003 | loss:8.0428 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.8322 | logitMax:-22.1598 | windowWeightsW8:0.19025,W15:0.17780,W13:0.17436,W18:0.16471,W3:0.12752,W7:0.10369,W2:0.05566,W1:0.01566,W21:-0.02787 | memoryGatesShort:5.613, Long:-0.934, Current:-3.679 | topTokens[('es', 31), ('.', 30), ('?', 14), (',', 13), ('to', 12), ('please', 11), ('they', 11), ('what', 10), ('at', 10), ('is', 9)] | Training
2025-04-03 23:45:31 | 7900 | LR0.0003 | loss:7.9002 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-44.7212 | logitMax:-23.1162 | windowWeightsW8:0.19128,W15:0.17807,W13:0.17467,W18:0.16500,W3:0.12705,W7:0.10320,W2:0.05547,W1:0.01549,W21:-0.02844 | memoryGatesShort:-5.494, Long:2.888, Current:3.606 | topTokens[('?', 26), ('is', 18), ('.', 17), ('a', 15), ('are', 10), ('please', 9), ('b', 8), ('he', 8), ('es', 8), ('they', 8)] | Training
2025-04-03 23:53:00 | 8000 | LR0.0003 | loss:8.5243 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.7002 | logitMax:-18.0424 | windowWeightsW8:0.19122,W15:0.17771,W13:0.17430,W18:0.16473,W3:0.12715,W7:0.10347,W2:0.05524,W1:0.01641,W21:-0.02844 | memoryGatesShort:80.415, Long:-0.390, Current:-79.025 | topTokens[('.', 30), ('kevin', 28), ('is', 25), (',', 19), ('?', 18), ('a', 15), ('s', 14), ('to', 12), ('our', 8), ('was', 7)] | Training
2025-04-04 00:00:17 | 8100 | LR0.0003 | loss:8.2077 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-38.6015 | logitMax:-10.5716 | windowWeightsW8:0.19075,W15:0.17760,W13:0.17407,W18:0.16456,W3:0.12652,W7:0.10354,W2:0.05550,W1:0.01757,W21:-0.02834 | memoryGatesShort:-0.814, Long:1.505, Current:0.309 | topTokens[('play', 45), ('games', 34), ('computer', 27), ('.', 18), (',', 15), ('s', 15), ('a', 12), ('you', 10), ('what', 9), ('were', 9)] | Training
2025-04-04 00:07:40 | 8200 | LR0.0003 | loss:8.8106 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-44.4805 | logitMax:-20.2714 | windowWeightsW8:0.19020,W15:0.17721,W13:0.17518,W18:0.16348,W3:0.12760,W7:0.10343,W2:0.05587,W1:0.01714,W21:-0.02834 | memoryGatesShort:-2.171, Long:0.299, Current:2.872 | topTokens[('to', 18), ('games', 16), ('play', 16), ('do', 16), ('.', 15), (',', 15), ('listening', 15), ('he', 13), ('computer', 10), ('is', 8)] | Training
2025-04-04 00:14:41 | 8300 | LR0.0003 | loss:11.3420 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.7084 | logitMax:-29.5633 | windowWeightsW8:0.19054,W15:0.17713,W13:0.17527,W18:0.16340,W3:0.12726,W7:0.10349,W2:0.05561,W1:0.01721,W21:-0.02814 | memoryGatesShort:-1.433, Long:1.183, Current:1.250 | topTokens[('h', 30), ('he', 26), ('nt', 22), (',', 16), ('.', 10), ('do', 8), ('now', 8), ('like', 6), ('b', 5), ('sy', 5)] | Training
2025-04-04 00:22:17 | 8400 | LR0.0003 | loss:6.4469 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.5479 | logitMax:-30.7523 | windowWeightsW8:0.19111,W15:0.17609,W13:0.17422,W18:0.16318,W3:0.12784,W7:0.10441,W2:0.05583,W1:0.01722,W21:-0.02812 | memoryGatesShort:-0.454, Long:0.322, Current:1.132 | topTokens[('=', 30), ('1', 23), (',', 20), ('has', 18), ('+', 13), ('he', 12), ('computer', 9), ('games', 9), ('you', 8), ('nt', 8)] | Training
2025-04-04 00:29:06 | 8500 | LR0.0003 | loss:7.4518 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-43.7889 | logitMax:-16.1898 | windowWeightsW8:0.19099,W15:0.17584,W13:0.17390,W18:0.16315,W3:0.12746,W7:0.10400,W2:0.05645,W1:0.01837,W21:-0.02840 | memoryGatesShort:-0.499, Long:0.428, Current:1.071 | topTokens[('has', 35), ('he', 25), ('to', 20), (',', 18), ('.', 16), ('listening', 15), ('?', 15), ('our', 11), ('what', 10), ('music', 7)] | Training
2025-04-04 00:35:20 | 8600 | LR0.0003 | loss:7.4106 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-52.4571 | logitMax:-26.4117 | windowWeightsW8:0.19152,W15:0.17506,W13:0.17356,W18:0.16154,W3:0.12910,W7:0.10433,W2:0.05666,W1:0.01812,W21:-0.02816 | memoryGatesShort:-0.341, Long:0.585, Current:0.755 | topTokens[('.', 15), ('to', 15), ('like', 14), ('he', 13), ('listening', 12), ('kevin', 10), (',', 10), ('one', 10), ('play', 9), ('what', 9)] | Training
2025-04-04 00:41:33 | 8700 | LR0.0003 | loss:6.0435 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-46.6225 | logitMax:-16.5973 | windowWeightsW8:0.19141,W15:0.17494,W13:0.17351,W18:0.16180,W3:0.12898,W7:0.10293,W2:0.05754,W1:0.01912,W21:-0.02852 | memoryGatesShort:-1.457, Long:-0.341, Current:2.798 | topTokens[('listening', 35), ('?', 24), ('to', 24), (',', 17), ('it', 15), ('!', 13), ('.', 11), ('elect', 10), ('my', 10), ('like', 10)] | Training
2025-04-04 00:47:50 | 8800 | LR0.0003 | loss:4.9467 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-42.8077 | logitMax:-17.9465 | windowWeightsW8:0.19156,W15:0.17461,W13:0.17317,W18:0.16192,W3:0.12961,W7:0.10301,W2:0.05702,W1:0.01930,W21:-0.02850 | memoryGatesShort:-0.166, Long:-0.390, Current:1.556 | topTokens[('.', 30), ('they', 23), ('?', 21), ('to', 20), ('will', 17), ('listening', 12), ('music', 12), ('what', 10), ('games', 9), (',', 8)] | Training
2025-04-04 00:54:07 | 8900 | LR0.0003 | loss:7.2177 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.9073 | logitMax:-16.3105 | windowWeightsW8:0.19033,W15:0.17479,W13:0.17201,W18:0.16211,W3:0.13100,W7:0.10230,W2:0.05750,W1:0.01985,W21:-0.02820 | memoryGatesShort:0.722, Long:-0.542, Current:0.820 | topTokens[('listening', 31), ('music', 29), ('to', 22), ('?', 18), ('they', 18), ('will', 14), ('he', 13), ('.', 12), (',', 12), ('what', 11)] | Training
2025-04-04 01:00:26 | 9000 | LR0.0003 | loss:9.3458 | gradNorm:0.9733 | tokenCount:400.0000 | logitMin:-52.9610 | logitMax:-12.4252 | windowWeightsW8:0.19075,W15:0.17486,W13:0.17238,W18:0.16229,W3:0.13074,W7:0.10241,W2:0.05730,W1:0.01854,W21:-0.02756 | memoryGatesShort:0.347, Long:-0.739, Current:1.392 | topTokens[('?', 24), ('will', 22), ('s', 21), ('music', 20), ('listening', 20), ('.', 20), ('to', 13), ('be', 12), (',', 11), ('what', 11)] | Training
2025-04-04 01:06:46 | 9100 | LR0.0003 | loss:6.7575 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.4328 | logitMax:-25.9750 | windowWeightsW8:0.19071,W15:0.17483,W13:0.17237,W18:0.16267,W3:0.13009,W7:0.10221,W2:0.05693,W1:0.01937,W21:-0.02746 | memoryGatesShort:0.253, Long:0.014, Current:0.733 | topTokens[('listening', 24), ('?', 23), ('to', 21), ('will', 15), ('you', 13), (',', 13), ('he', 13), ('been', 11), ('music', 11), ('has', 10)] | Training
2025-04-04 01:13:04 | 9200 | LR0.0003 | loss:6.8398 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-43.5472 | logitMax:-15.2887 | windowWeightsW8:0.19053,W15:0.17523,W13:0.17312,W18:0.16304,W3:0.13041,W7:0.10032,W2:0.05752,W1:0.01884,W21:-0.02729 | memoryGatesShort:0.240, Long:-0.482, Current:1.242 | topTokens[('listening', 23), (',', 22), ('to', 21), ('.', 20), ('?', 20), ('the', 15), ('will', 13), ('what', 12), ('be', 11), ('s', 10)] | Training
2025-04-04 01:19:25 | 9300 | LR0.0003 | loss:8.4379 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-40.5855 | logitMax:-19.4393 | windowWeightsW8:0.19067,W15:0.17546,W13:0.17308,W18:0.16313,W3:0.13011,W7:0.10073,W2:0.05729,W1:0.01839,W21:-0.02716 | memoryGatesShort:-4.911, Long:-17.930, Current:23.841 | topTokens[('.', 23), ('you', 21), (',', 18), ('?', 10), ('will', 10), ('with', 9), ('not', 9), ('like', 9), ('what', 9), ('s', 9)] | Training
2025-04-04 01:25:43 | 9400 | LR0.0003 | loss:7.0033 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.4408 | logitMax:-26.7670 | windowWeightsW8:0.19077,W15:0.17563,W13:0.17274,W18:0.16340,W3:0.12987,W7:0.10094,W2:0.05621,W1:0.01885,W21:-0.02668 | memoryGatesShort:-0.215, Long:-0.462, Current:1.677 | topTokens[('.', 23), ('?', 22), ('do', 20), (',', 14), ('like', 11), ('you', 11), ('music', 11), ('s', 8), ('with', 7), ('and', 7)] | Training
2025-04-04 01:32:00 | 9500 | LR0.0003 | loss:6.1315 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.3196 | logitMax:-22.4659 | windowWeightsW8:0.19124,W15:0.17603,W13:0.17301,W18:0.16370,W3:0.12807,W7:0.10044,W2:0.05644,W1:0.01942,W21:-0.02660 | memoryGatesShort:-1.317, Long:-1.521, Current:3.838 | topTokens[('kevin', 30), ('is', 28), ('.', 24), ('you', 17), ('a', 17), (',', 16), ('to', 14), ('music', 12), ('?', 10), ('what', 9)] | Training
2025-04-04 01:38:21 | 9600 | LR0.0003 | loss:5.5812 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-44.5664 | logitMax:-20.7763 | windowWeightsW8:0.19224,W15:0.17525,W13:0.17189,W18:0.16262,W3:0.12798,W7:0.10167,W2:0.05752,W1:0.01926,W21:-0.02669 | memoryGatesShort:-0.359, Long:-1.970, Current:3.329 | topTokens[('?', 35), ('with', 34), ('.', 30), ('i', 19), ('you', 15), ('are', 15), (',', 13), ('was', 10), ('her', 9), ('coo', 6)] | Training
2025-04-04 01:44:48 | 9700 | LR0.0003 | loss:9.3773 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-48.4663 | logitMax:-24.4657 | windowWeightsW8:0.19294,W15:0.17548,W13:0.17165,W18:0.16230,W3:0.12674,W7:0.10233,W2:0.05629,W1:0.02032,W21:-0.02629 | memoryGatesShort:-0.335, Long:-0.865, Current:2.201 | topTokens[('is', 40), ('i', 22), (',', 18), ('you', 18), ('?', 15), ('with', 13), ('not', 12), ('.', 10), ('elodie', 10), ('dance', 8)] | Training
2025-04-04 01:51:13 | 9800 | LR0.0003 | loss:8.7562 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.3380 | logitMax:-30.4271 | windowWeightsW8:0.19222,W15:0.17579,W13:0.17155,W18:0.16297,W3:0.12671,W7:0.10208,W2:0.05546,W1:0.02065,W21:-0.02567 | memoryGatesShort:-0.566, Long:-1.116, Current:2.682 | topTokens[('?', 30), ('do', 19), ('like', 18), (',', 17), ('is', 16), ('i', 16), ('you', 16), ('.', 15), ('elodie', 15), ('to', 10)] | Training
2025-04-04 01:57:36 | 9900 | LR0.0003 | loss:7.1421 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.1352 | logitMax:-32.0225 | windowWeightsW8:0.19170,W15:0.17580,W13:0.17159,W18:0.16331,W3:0.12641,W7:0.10223,W2:0.05503,W1:0.02076,W21:-0.02503 | memoryGatesShort:0.035, Long:-0.421, Current:1.386 | topTokens[('do', 31), ('like', 23), ('.', 21), ('i', 17), ('?', 16), ('you', 15), ('to', 12), (',', 12), ('your', 11), ('sleep', 7)] | Training
2025-04-04 02:03:59 | 10000 | LR0.0003 | loss:8.7456 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.1011 | logitMax:-26.5578 | windowWeightsW8:0.19167,W15:0.17523,W13:0.17174,W18:0.16318,W3:0.12598,W7:0.10259,W2:0.05473,W1:0.02079,W21:-0.02410 | memoryGatesShort:2.187, Long:12.624, Current:-13.811 | topTokens[('you', 32), ('i', 29), ('?', 20), ('.', 17), ('is', 11), ('her', 11), ('with', 8), ('sleep', 6), (',', 6), ('was', 6)] | Training
2025-04-04 02:10:21 | 10100 | LR0.0003 | loss:6.2976 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-46.1942 | logitMax:-25.5896 | windowWeightsW8:0.19120,W15:0.17505,W13:0.17177,W18:0.16311,W3:0.12536,W7:0.10268,W2:0.05572,W1:0.02040,W21:-0.02344 | memoryGatesShort:0.464, Long:-2.585, Current:3.121 | topTokens[('.', 32), ('?', 22), ('talking', 15), ('i', 14), ('you', 11), (',', 10), ('to', 10), ('was', 10), ('her', 10), ('will', 10)] | Training
2025-04-04 02:16:47 | 10200 | LR0.0003 | loss:7.4172 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-55.3563 | logitMax:-34.6479 | windowWeightsW8:0.19110,W15:0.17532,W13:0.17123,W18:0.16333,W3:0.12533,W7:0.10325,W2:0.05545,W1:0.02026,W21:-0.02343 | memoryGatesShort:0.278, Long:-0.278, Current:1.000 | topTokens[('is', 33), ('!', 21), ('.', 15), ('she', 13), ('no', 12), ('?', 12), ('a', 11), (',', 10), ('you', 8), ('i', 7)] | Training
2025-04-04 02:23:09 | 10300 | LR0.0003 | loss:5.0098 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.1915 | logitMax:-31.8687 | windowWeightsW8:0.19115,W15:0.17443,W13:0.17019,W18:0.16280,W3:0.12557,W7:0.10368,W2:0.05561,W1:0.02196,W21:-0.02359 | memoryGatesShort:0.433, Long:0.256, Current:0.311 | topTokens[('want', 29), ('?', 23), ('.', 21), ('you', 19), ('to', 18), ('i', 17), ('do', 17), (',', 11), ('look', 9), ('dont', 9)] | Training
2025-04-04 02:29:32 | 10400 | LR0.0003 | loss:5.4264 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-44.6736 | logitMax:-26.4376 | windowWeightsW8:0.19090,W15:0.17447,W13:0.16999,W18:0.16262,W3:0.12542,W7:0.10377,W2:0.05589,W1:0.02191,W21:-0.02315 | memoryGatesShort:0.126, Long:-0.030, Current:0.904 | topTokens[('.', 34), ('you', 32), ('?', 26), ('i', 18), ('dont', 16), ('are', 12), ('talk', 10), ('do', 8), (',', 8), ('ace', 7)] | Training
2025-04-04 02:36:00 | 10500 | LR0.0003 | loss:11.2172 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.6572 | logitMax:-21.6368 | windowWeightsW8:0.19059,W15:0.17397,W13:0.17037,W18:0.16297,W3:0.12616,W7:0.10381,W2:0.05501,W1:0.02219,W21:-0.02325 | memoryGatesShort:0.279, Long:-0.183, Current:0.904 | topTokens[('do', 47), (',', 32), ('like', 30), ('?', 20), ('.', 19), ('kevin', 17), ('i', 12), ('dont', 12), ('you', 12), ('kiss', 6)] | Training
2025-04-04 02:42:26 | 10600 | LR0.0003 | loss:6.2179 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-52.1348 | logitMax:-32.8016 | windowWeightsW8:0.19039,W15:0.17379,W13:0.17000,W18:0.16322,W3:0.12607,W7:0.10394,W2:0.05468,W1:0.02234,W21:-0.02259 | memoryGatesShort:-2.477, Long:-8.675, Current:12.152 | topTokens[('do', 26), ('you', 21), ('like', 18), ('?', 18), ('.', 17), ('my', 10), ('kevin', 9), ('i', 9), (',', 6), ('!', 6)] | Training
2025-04-04 02:49:20 | 10700 | LR0.0003 | loss:7.2096 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-49.9762 | logitMax:-26.2516 | windowWeightsW8:0.19066,W15:0.17353,W13:0.16960,W18:0.16264,W3:0.12583,W7:0.10435,W2:0.05505,W1:0.02253,W21:-0.02237 | memoryGatesShort:-0.058, Long:-1.371, Current:2.430 | topTokens[('?', 35), (',', 20), ('i', 16), ('you', 11), ('s', 10), ('.', 9), ('like', 9), ('to', 9), ('is', 8), ('my', 8)] | Training
2025-04-04 02:56:01 | 10800 | LR0.0003 | loss:8.0067 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-55.0146 | logitMax:-28.4207 | windowWeightsW8:0.19045,W15:0.17341,W13:0.16999,W18:0.16318,W3:0.12539,W7:0.10375,W2:0.05440,W1:0.02302,W21:-0.02175 | memoryGatesShort:-0.752, Long:-3.123, Current:4.876 | topTokens[('.', 28), ('i', 22), ('like', 19), (',', 17), ('?', 16), ('what', 13), ('you', 13), ('!', 11), ('to', 11), ('is', 8)] | Training
2025-04-04 03:02:35 | 10900 | LR0.0003 | loss:7.3381 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-59.3305 | logitMax:-31.0794 | windowWeightsW8:0.19065,W15:0.17255,W13:0.17016,W18:0.16217,W3:0.12564,W7:0.10495,W2:0.05415,W1:0.02277,W21:-0.02120 | memoryGatesShort:0.588, Long:2.125, Current:-1.713 | topTokens[('is', 37), ('.', 22), ('?', 21), ('i', 21), ('english', 12), (',', 11), ('to', 10), ('do', 9), ('kevin', 9), ('elodie', 8)] | Training
2025-04-04 03:09:13 | 11000 | LR0.0003 | loss:11.0601 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.3027 | logitMax:-21.5627 | windowWeightsW8:0.19151,W15:0.17277,W13:0.17071,W18:0.16154,W3:0.12515,W7:0.10460,W2:0.05427,W1:0.02266,W21:-0.02136 | memoryGatesShort:4.461, Long:-13.542, Current:10.081 | topTokens[('is', 30), ('for', 27), ('?', 25), ('you', 24), ('.', 17), (',', 15), ('a', 11), ('her', 10), ('what', 7), ('were', 5)] | Training
2025-04-04 03:15:47 | 11100 | LR0.0003 | loss:7.6037 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-49.7822 | logitMax:-28.3959 | windowWeightsW8:0.19040,W15:0.17327,W13:0.17018,W18:0.16213,W3:0.12505,W7:0.10405,W2:0.05421,W1:0.02323,W21:-0.02066 | memoryGatesShort:2.120, Long:-6.055, Current:4.935 | topTokens[('?', 41), ('.', 36), ('for', 25), ('is', 22), ('i', 12), ('to', 12), (',', 10), ('you', 9), ('will', 6), ('talk', 6)] | Training
2025-04-04 03:22:31 | 11200 | LR0.0003 | loss:7.4991 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.1818 | logitMax:-33.0644 | windowWeightsW8:0.19085,W15:0.17309,W13:0.16996,W18:0.16215,W3:0.12497,W7:0.10481,W2:0.05382,W1:0.02242,W21:-0.02020 | memoryGatesShort:16.798, Long:-30.134, Current:14.336 | topTokens[('!', 22), ('to', 20), ('i', 19), ('is', 18), ('.', 17), ('will', 13), ('you', 13), ('?', 11), ('a', 11), ('up', 11)] | Training
2025-04-04 03:29:08 | 11300 | LR0.0003 | loss:7.9537 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.0493 | logitMax:-37.3691 | windowWeightsW8:0.19112,W15:0.17287,W13:0.16984,W18:0.16184,W3:0.12482,W7:0.10563,W2:0.05338,W1:0.02215,W21:-0.01976 | memoryGatesShort:3.390, Long:-7.051, Current:4.661 | topTokens[('what', 21), ('?', 21), ('is', 20), ('you', 20), ('.', 18), ('will', 18), ('i', 12), ('do', 11), ('to', 11), ('want', 9)] | Training
2025-04-04 03:35:49 | 11400 | LR0.0003 | loss:6.1107 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.5682 | logitMax:-32.3803 | windowWeightsW8:0.19087,W15:0.17237,W13:0.16956,W18:0.16150,W3:0.12482,W7:0.10621,W2:0.05367,W1:0.02231,W21:-0.01943 | memoryGatesShort:-2.788, Long:5.629, Current:-1.841 | topTokens[('?', 28), ('.', 26), ('name', 23), ('i', 19), ('my', 19), ('is', 17), ('him', 13), ('you', 10), ('for', 8), ('speak', 7)] | Training
2025-04-04 03:42:37 | 11500 | LR0.0003 | loss:8.4418 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.2970 | logitMax:-21.6408 | windowWeightsW8:0.19148,W15:0.17211,W13:0.16923,W18:0.16098,W3:0.12445,W7:0.10726,W2:0.05357,W1:0.02151,W21:-0.01868 | memoryGatesShort:18.769, Long:-53.928, Current:36.158 | topTokens[('my', 26), ('is', 25), (',', 23), ('.', 20), ('name', 19), ('you', 18), ('want', 17), ('?', 13), ('she', 10), ('who', 8)] | Training
2025-04-04 03:49:20 | 11600 | LR0.0003 | loss:7.4954 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-55.2114 | logitMax:-31.4325 | windowWeightsW8:0.19004,W15:0.17280,W13:0.16852,W18:0.16149,W3:0.12468,W7:0.10587,W2:0.05421,W1:0.02184,W21:-0.01753 | memoryGatesShort:-3.996, Long:5.591, Current:-0.595 | topTokens[('?', 23), ('you', 22), ('kiss', 22), ('he', 20), ('.', 17), ('want', 14), ('him', 12), ('name', 8), ('do', 8), ('i', 8)] | Training
2025-04-04 03:56:10 | 11700 | LR0.0003 | loss:8.2501 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-61.8589 | logitMax:-34.6030 | windowWeightsW8:0.19062,W15:0.17320,W13:0.16879,W18:0.16090,W3:0.12455,W7:0.10609,W2:0.05406,W1:0.02091,W21:-0.01717 | memoryGatesShort:47.456, Long:-82.391, Current:35.935 | topTokens[('he', 38), ('.', 24), ('kevin', 23), ('?', 20), ('are', 14), ('!', 12), ('you', 12), ('is', 10), ('to', 9), (',', 8)] | Training
2025-04-04 04:03:25 | 11800 | LR0.0003 | loss:7.7089 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.6487 | logitMax:-33.6021 | windowWeightsW8:0.19050,W15:0.17333,W13:0.16904,W18:0.16170,W3:0.12403,W7:0.10579,W2:0.05330,W1:0.02061,W21:-0.01635 | memoryGatesShort:10.942, Long:-14.286, Current:4.344 | topTokens[('.', 30), ('is', 21), ('?', 15), ('you', 11), ('!', 10), ('i', 10), ('s', 10), ('your', 10), ('do', 10), ('to', 10)] | Training
2025-04-04 04:09:45 | 11900 | LR0.0003 | loss:5.8197 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-59.4193 | logitMax:-35.1068 | windowWeightsW8:0.19118,W15:0.17318,W13:0.16884,W18:0.16100,W3:0.12355,W7:0.10643,W2:0.05270,W1:0.02096,W21:-0.01587 | memoryGatesShort:3.102, Long:-14.783, Current:12.681 | topTokens[('?', 26), ('do', 26), ('froggy', 22), ('.', 20), ('i', 17), ('me', 15), ('kevin', 14), ('what', 13), ('is', 11), ('you', 11)] | Training
2025-04-04 04:16:20 | 12000 | LR0.0003 | loss:8.2267 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.0534 | logitMax:-22.7918 | windowWeightsW8:0.19129,W15:0.17365,W13:0.16863,W18:0.15991,W3:0.12368,W7:0.10663,W2:0.05325,W1:0.02044,W21:-0.01551 | memoryGatesShort:-7.100, Long:25.142, Current:-17.042 | topTokens[('?', 27), ('kevin', 23), (',', 17), ('you', 17), ('is', 14), ('!', 14), ('like', 13), ('are', 11), ('.', 10), ('im', 9)] | Training
2025-04-04 04:22:45 | 12100 | LR0.0003 | loss:6.5946 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-48.3310 | logitMax:-23.2583 | windowWeightsW8:0.19075,W15:0.17326,W13:0.16812,W18:0.16052,W3:0.12378,W7:0.10660,W2:0.05273,W1:0.02116,W21:-0.01494 | memoryGatesShort:1.068, Long:-0.792, Current:0.724 | topTokens[('?', 36), ('are', 27), (',', 21), ('.', 20), ('to', 16), ('im', 15), ('you', 12), ('thinking', 12), ('!', 11), ('do', 9)] | Training
2025-04-04 04:29:14 | 12200 | LR0.0003 | loss:6.3730 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.2037 | logitMax:-25.8306 | windowWeightsW8:0.19047,W15:0.17306,W13:0.16790,W18:0.16084,W3:0.12443,W7:0.10704,W2:0.05243,W1:0.02105,W21:-0.01525 | memoryGatesShort:1.583, Long:-2.498, Current:1.915 | topTokens[('you', 27), ('?', 23), ('.', 20), (',', 17), ('is', 11), ('to', 11), ('i', 11), ('lunch', 10), ('she', 9), ('are', 8)] | Training
2025-04-04 04:35:48 | 12300 | LR0.0003 | loss:7.6756 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-38.7291 | logitMax:-8.7333 | windowWeightsW8:0.18993,W15:0.17238,W13:0.16748,W18:0.16174,W3:0.12439,W7:0.10715,W2:0.05101,W1:0.02276,W21:-0.01489 | memoryGatesShort:-4.081, Long:10.153, Current:-5.072 | topTokens[('es', 39), ('what', 31), ('.', 21), ('?', 21), (',', 18), ('cat', 15), ('you', 13), ('to', 13), ('she', 8), ('a', 6)] | Training
2025-04-04 04:42:25 | 12400 | LR0.0003 | loss:5.9375 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-49.2061 | logitMax:-21.7643 | windowWeightsW8:0.19050,W15:0.17186,W13:0.16664,W18:0.16157,W3:0.12469,W7:0.10725,W2:0.05196,W1:0.02301,W21:-0.01558 | memoryGatesShort:2.132, Long:-4.244, Current:3.112 | topTokens[('?', 30), ('what', 28), ('.', 26), ('i', 16), ('to', 13), ('will', 11), ('now', 10), (',', 9), ('es', 8), ('you', 7)] | Training
2025-04-04 04:49:30 | 12500 | LR0.0003 | loss:7.0340 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.8072 | logitMax:-26.8095 | windowWeightsW8:0.18989,W15:0.17171,W13:0.16680,W18:0.16145,W3:0.12567,W7:0.10651,W2:0.05212,W1:0.02318,W21:-0.01543 | memoryGatesShort:3.939, Long:-7.764, Current:4.825 | topTokens[('.', 26), ('what', 21), ('you', 19), ('es', 17), ('?', 16), ('to', 15), ('i', 12), ('speak', 11), ('s', 9), ('will', 8)] | Training
2025-04-04 04:56:23 | 12600 | LR0.0003 | loss:6.8643 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-55.9746 | logitMax:-26.3702 | windowWeightsW8:0.19016,W15:0.17208,W13:0.16762,W18:0.16155,W3:0.12461,W7:0.10628,W2:0.05178,W1:0.02286,W21:-0.01501 | memoryGatesShort:1.881, Long:-2.491, Current:1.610 | topTokens[('my', 22), ('?', 21), ('.', 21), ('to', 16), ('i', 14), ('dance', 14), ('now', 12), ('do', 11), ('you', 10), ('for', 10)] | Training
2025-04-04 05:03:20 | 12700 | LR0.0003 | loss:9.5481 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-43.3419 | logitMax:-11.4817 | windowWeightsW8:0.19149,W15:0.17072,W13:0.16646,W18:0.16068,W3:0.12495,W7:0.10665,W2:0.05287,W1:0.02262,W21:-0.01454 | memoryGatesShort:2.262, Long:-2.317, Current:1.055 | topTokens[('.', 34), ('s', 21), ('remember', 18), ('do', 15), ('you', 14), ('is', 12), ('about', 12), (',', 11), ('dance', 11), ('i', 11)] | Training
2025-04-04 05:10:09 | 12800 | LR0.0003 | loss:7.8278 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-44.8034 | logitMax:-19.4953 | windowWeightsW8:0.19227,W15:0.17055,W13:0.16673,W18:0.16031,W3:0.12515,W7:0.10685,W2:0.05176,W1:0.02235,W21:-0.01406 | memoryGatesShort:1.936, Long:-2.948, Current:2.012 | topTokens[('.', 34), ('pete', 24), (',', 19), ('froggy', 17), ('i', 14), ('you', 14), ('now', 14), ('were', 11), ('ing', 11), ('remember', 9)] | Training
2025-04-04 05:17:41 | 12900 | LR0.0003 | loss:10.1865 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.7254 | logitMax:-22.1237 | windowWeightsW8:0.19223,W15:0.17030,W13:0.16673,W18:0.16020,W3:0.12525,W7:0.10671,W2:0.05193,W1:0.02260,W21:-0.01403 | memoryGatesShort:4.666, Long:-10.045, Current:6.379 | topTokens[('kevins', 37), ('pete', 30), ('.', 19), ('now', 18), ('was', 14), (',', 13), ('is', 13), ('at', 10), ('i', 10), ('looking', 9)] | Training
2025-04-04 05:24:52 | 13000 | LR0.0003 | loss:6.5565 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.8847 | logitMax:-24.8024 | windowWeightsW8:0.19222,W15:0.16974,W13:0.16658,W18:0.16020,W3:0.12510,W7:0.10677,W2:0.05182,W1:0.02250,W21:-0.01299 | memoryGatesShort:-18.872, Long:38.959, Current:-19.087 | topTokens[('was', 24), ('?', 20), ('.', 18), ('she', 11), ('kevins', 11), ('a', 8), ('music', 8), ('im', 8), (',', 8), ('he', 8)] | Training

--- 2025-04-04 05:29:39 --- babyllm: 'what am i learning today?'- charis: 'to count duration'
2025-04-04 05:36:16 | 100 | LR0.0003 | loss:11.4743 | gradNorm:1.0000 | logitMin:-63.4148 | logitMax:-20.5496 | tokenCount:400.0000 | windowWeightsW8:0.19191,W15:0.16858,W13:0.16553,W18:0.16023,W3:0.12570,W7:0.10565,W2:0.05322,W1:0.02274,W21:-0.01163 | memoryGatesShort:75.939, Long:-124.531, Current:49.592 | topTokens[('now', 23), ('.', 22), ('?', 18), ('looking', 18), ('a', 17), ('is', 17), ('you', 13), ('he', 13), ('been', 11), ('i', 11)] | Training

--- 2025-04-04 05:46:28 --- babyllm: 'what am i learning today?'- charis: 'to finally count duration!'
2025-04-04 05:52:16 | 100 | LR0.0003 | loss:5.0928 | gradNorm:1.0000 | logitMin:-51.1856 | logitMax:-22.6169 | tokenCount:400.0000 | windowWeightsW8:0.19086,W15:0.16752,W13:0.16459,W18:0.15877,W3:0.12733,W7:0.10551,W2:0.05437,W1:0.02366,W21:-0.01072 | memoryGatesShort:1.309, Long:-1.045, Current:0.736 | topTokens[('to', 32), ('.', 31), ('he', 26), ('music', 23), ('what', 19), ('now', 17), ('listening', 15), ('?', 14), ('feel', 11), (',', 11)] | Training
2025-04-04 05:59:10 | 200 | LR0.0003 | loss:5.5221 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.9879 | logitMax:-27.7550 | windowWeightsW8:0.19018,W15:0.16782,W13:0.16555,W18:0.15866,W3:0.12736,W7:0.10462,W2:0.05497,W1:0.02325,W21:-0.01051 | memoryGatesShort:3.304, Long:-3.900, Current:1.596 | topTokens[('to', 33), ('?', 22), ('.', 16), ('will', 16), ('music', 14), ('now', 14), ('with', 13), ('games', 12), ('listening', 11), ('what', 10)] | Training
2025-04-04 06:06:09 | 300 | LR0.0003 | loss:4.7851 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-52.2132 | logitMax:-27.0805 | windowWeightsW8:0.19068,W15:0.16799,W13:0.16485,W18:0.15872,W3:0.12814,W7:0.10425,W2:0.05440,W1:0.02369,W21:-0.01086 | memoryGatesShort:5.799, Long:-7.072, Current:2.273 | topTokens[('listening', 25), ('music', 25), ('.', 23), ('to', 22), ('myself', 21), ('will', 16), ('?', 15), ('what', 13), ('was', 13), (',', 11)] | Training
2025-04-04 06:12:34 | 400 | LR0.0003 | loss:8.8353 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.1522 | logitMax:-25.5957 | windowWeightsW8:0.19129,W15:0.16779,W13:0.16420,W18:0.15819,W3:0.12786,W7:0.10486,W2:0.05494,W1:0.02329,W21:-0.01056 | memoryGatesShort:2.281, Long:-1.545, Current:0.263 | topTokens[('my', 35), ('of', 22), ('.', 20), ('he', 18), ('?', 13), ('to', 13), ('listening', 11), ('you', 9), ('i', 9), (',', 9)] | Training
2025-04-04 06:19:06 | 500 | LR0.0003 | loss:7.3068 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-49.1534 | logitMax:-24.8821 | windowWeightsW8:0.19075,W15:0.16768,W13:0.16415,W18:0.15786,W3:0.12743,W7:0.10506,W2:0.05484,W1:0.02296,W21:-0.00885 | memoryGatesShort:1.592, Long:-1.187, Current:0.595 | topTokens[('.', 31), ('now', 26), ('play', 18), ('he', 18), ('you', 17), ('my', 16), ('?', 13), ('games', 12), ('computer', 11), ('a', 10)] | Training
2025-04-04 06:25:30 | 600 | LR0.0003 | loss:6.4117 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-44.4790 | logitMax:-20.3210 | windowWeightsW8:0.19069,W15:0.16781,W13:0.16357,W18:0.15864,W3:0.12786,W7:0.10476,W2:0.05489,W1:0.02300,W21:-0.00935 | memoryGatesShort:4.270, Long:-5.398, Current:2.128 | topTokens[('has', 27), ('a', 23), ('to', 20), ('listening', 18), ('been', 17), ('you', 16), ('.', 15), ('of', 14), ('music', 13), (',', 13)] | Training
2025-04-04 06:31:53 | 700 | LR0.0003 | loss:7.2085 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.6816 | logitMax:-26.4300 | windowWeightsW8:0.19101,W15:0.16787,W13:0.16404,W18:0.15853,W3:0.12760,W7:0.10460,W2:0.05461,W1:0.02315,W21:-0.00951 | memoryGatesShort:0.652, Long:-2.128, Current:2.476 | topTokens[('.', 26), ('?', 26), ('you', 20), ('a', 16), (',', 14), ('to', 14), ('now', 13), ('listening', 12), ("'s", 9), ('she', 9)] | Training
2025-04-04 06:38:19 | 800 | LR0.0003 | loss:9.9509 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-68.0046 | logitMax:-27.6892 | windowWeightsW8:0.19071,W15:0.16757,W13:0.16466,W18:0.15796,W3:0.12842,W7:0.10444,W2:0.05370,W1:0.02410,W21:-0.00970 | memoryGatesShort:0.796, Long:2.195, Current:-1.991 | topTokens[('.', 31), ('fre', 29), (',', 26), ('?', 25), ('to', 22), ('listening', 17), ('been', 14), ('he', 14), ('what', 11), ('she', 10)] | Training
2025-04-04 06:44:50 | 900 | LR0.0003 | loss:9.3582 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-58.8257 | logitMax:-17.5936 | windowWeightsW8:0.19109,W15:0.16731,W13:0.16576,W18:0.15788,W3:0.12815,W7:0.10464,W2:0.05327,W1:0.02324,W21:-0.00947 | memoryGatesShort:0.529, Long:-2.929, Current:3.400 | topTokens[('music', 52), ('listening', 34), ('to', 25), ('fre', 20), ('.', 15), ('you', 14), ('?', 14), ('real', 11), ('be', 10), ('been', 8)] | Training
2025-04-04 06:51:39 | 1000 | LR0.0003 | loss:4.7610 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-46.9760 | logitMax:-17.5154 | windowWeightsW8:0.19110,W15:0.16691,W13:0.16543,W18:0.15751,W3:0.12790,W7:0.10494,W2:0.05394,W1:0.02373,W21:-0.00960 | memoryGatesShort:0.442, Long:-5.810, Current:6.369 | topTokens[('listening', 29), ('to', 26), ('.', 25), ('been', 19), ('she', 15), ('he', 14), ('?', 13), ('were', 10), ('not', 10), ('fre', 10)] | Training
2025-04-04 06:58:36 | 1100 | LR0.0003 | loss:7.5410 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-48.3468 | logitMax:-25.2859 | windowWeightsW8:0.19097,W15:0.16675,W13:0.16544,W18:0.15761,W3:0.12773,W7:0.10514,W2:0.05388,W1:0.02367,W21:-0.00931 | memoryGatesShort:0.891, Long:-0.996, Current:1.105 | topTokens[(',', 33), ('.', 18), ('+', 17), ('what', 16), ('of', 16), ('now', 15), ('=', 15), ('to', 13), ('it', 11), ('i', 8)] | Training
2025-04-04 07:05:38 | 1200 | LR0.0003 | loss:4.2313 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-62.9788 | logitMax:-31.6903 | windowWeightsW8:0.19133,W15:0.16676,W13:0.16540,W18:0.15695,W3:0.12774,W7:0.10560,W2:0.05325,W1:0.02424,W21:-0.00938 | memoryGatesShort:-1.740, Long:-21.418, Current:24.158 | topTokens[('1', 27), ('to', 25), ('=', 23), ('listening', 23), ('?', 22), ('been', 21), ('.', 20), (',', 19), ('music', 16), ('+', 15)] | Training
2025-04-04 07:12:39 | 1300 | LR0.0003 | loss:8.9194 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.0332 | logitMax:-27.4690 | windowWeightsW8:0.19044,W15:0.16697,W13:0.16562,W18:0.15738,W3:0.12803,W7:0.10493,W2:0.05363,W1:0.02367,W21:-0.00878 | memoryGatesShort:1.322, Long:-2.406, Current:2.084 | topTokens[('.', 45), ('you', 18), ('to', 15), ('!', 14), ('know', 13), ('had', 11), ('i', 11), ('what', 10), ('this', 10), (',', 9)] | Training
2025-04-04 07:19:49 | 1400 | LR0.0003 | loss:10.0104 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.8001 | logitMax:-31.2282 | windowWeightsW8:0.19005,W15:0.16737,W13:0.16566,W18:0.15770,W3:0.12776,W7:0.10488,W2:0.05336,W1:0.02327,W21:-0.00814 | memoryGatesShort:0.045, Long:-0.239, Current:1.195 | topTokens[('.', 44), ('!', 29), (',', 24), ('not', 22), ('about', 20), ('know', 18), ('this', 17), ('a', 10), ('were', 7), ('be', 7)] | Training
2025-04-04 07:26:23 | 1500 | LR0.0003 | loss:9.5449 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.9542 | logitMax:-28.9176 | windowWeightsW8:0.19028,W15:0.16807,W13:0.16639,W18:0.15796,W3:0.12773,W7:0.10441,W2:0.05291,W1:0.02228,W21:-0.00811 | memoryGatesShort:0.933, Long:1.336, Current:-1.269 | topTokens[('know', 26), ('.', 26), (',', 19), ('not', 14), ('for', 13), ('you', 12), ('!', 11), ('she', 10), ('this', 9), ("'s", 9)] | Training
2025-04-04 07:32:44 | 1600 | LR0.0003 | loss:7.2406 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.4616 | logitMax:-37.6006 | windowWeightsW8:0.18988,W15:0.16764,W13:0.16619,W18:0.15828,W3:0.12731,W7:0.10480,W2:0.05249,W1:0.02239,W21:-0.00703 | memoryGatesShort:-3.322, Long:-1.973, Current:6.295 | topTokens[('but', 41), ('.', 37), (',', 25), ('not', 19), ('to', 13), ('i', 11), ('know', 10), ('!', 10), ('what', 9), ('a', 7)] | Training
2025-04-04 07:39:22 | 1700 | LR0.0003 | loss:5.3654 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.1295 | logitMax:-39.3520 | windowWeightsW8:0.19090,W15:0.16620,W13:0.16601,W18:0.15757,W3:0.12758,W7:0.10502,W2:0.05306,W1:0.02254,W21:-0.00696 | memoryGatesShort:4.442, Long:5.386, Current:-8.828 | topTokens[('what', 29), ('i', 25), ('.', 21), ('do', 18), ('not', 17), (',', 14), ('you', 12), ('was', 10), ('she', 9), ('is', 9)] | Training

--- 2025-04-04 12:53:14 --- babyllm: 'what am i learning today?'- charis: 'fresh data pull, look i gave u a break but i was sad to think u werent vibing! but jesus christ the computer's cold now LMAO'
2025-04-04 12:59:37 | 100 | LR0.0003 | loss:3.6996 | gradNorm:0.9064 | logitMin:-81.3353 | logitMax:-21.1189 | tokenCount:400.0000 | windowWeightsW8:0.18998,W15:0.16624,W13:0.16597,W18:0.15937,W3:0.12741,W7:0.10444,W2:0.05285,W1:0.02233,W21:-0.00668 | memoryGatesShort:-0.149, Long:-1.004, Current:2.152 | topTokens[('i', 61), ('it', 46), ('!', 43), ('.', 34), ('did', 28), ('know', 15), ('am', 11), ('you', 10), (',', 10), ('been', 10)] | Training
2025-04-04 13:06:00 | 200 | LR0.0003 | loss:11.0952 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-41.6695 | logitMax:-16.0455 | windowWeightsW8:0.18960,W15:0.16653,W13:0.16583,W18:0.15964,W3:0.12707,W7:0.10489,W2:0.05257,W1:0.02177,W21:-0.00595 | memoryGatesShort:1.191, Long:-0.677, Current:0.486 | topTokens[('i', 71), ('.', 55), (',', 15), ('it', 14), ('a', 12), ('time', 9), ('music', 7), ('am', 7), ('all', 7), ('know', 6)] | Training
2025-04-04 13:12:34 | 300 | LR0.0003 | loss:9.0390 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-48.8854 | logitMax:-31.7791 | windowWeightsW8:0.18935,W15:0.16663,W13:0.16584,W18:0.15973,W3:0.12697,W7:0.10490,W2:0.05254,W1:0.02176,W21:-0.00576 | memoryGatesShort:-0.101, Long:-12.280, Current:13.381 | topTokens[('with', 31), ('.', 29), (',', 28), ('i', 20), ('it', 15), ('a', 10), ('all', 9), ('just', 9), ('!', 9), ('?', 9)] | Training
2025-04-04 13:20:01 | 400 | LR0.0003 | loss:8.5789 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.3464 | logitMax:-34.1374 | windowWeightsW8:0.18922,W15:0.16664,W13:0.16598,W18:0.15981,W3:0.12682,W7:0.10501,W2:0.05221,W1:0.02163,W21:-0.00535 | memoryGatesShort:-0.612, Long:-0.302, Current:1.914 | topTokens[('i', 48), (',', 36), ('.', 17), ('to', 16), ('be', 15), ('am', 12), ('a', 8), ('up', 8), ('b', 8), ('you', 7)] | Training

--- 2025-04-04 13:21:41 --- babyllm: 'what am i learning today?'- charis: 'chill :)'
2025-04-04 13:28:15 | 100 | LR0.0003 | loss:7.2378 | gradNorm:0.8009 | logitMin:-157.2165 | logitMax:-61.2943 | tokenCount:400.0000 | windowWeightsW8:0.18854,W15:0.16633,W13:0.16488,W18:0.15980,W3:0.12708,W7:0.10508,W2:0.05365,W1:0.02221,W21:-0.00563 | memoryGatesShort:-0.007, Long:-0.077, Current:1.084 | topTokens[('i', 59), ('.', 57), ('it', 51), ('!', 39), ('know', 21), ('did', 19), ('am', 18), ('happy', 16), (',', 13), ('hey', 12)] | Training
2025-04-04 13:35:03 | 200 | LR0.0003 | loss:14.0064 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-58.6638 | logitMax:-26.6983 | windowWeightsW8:0.18870,W15:0.16670,W13:0.16473,W18:0.15995,W3:0.12637,W7:0.10587,W2:0.05307,W1:0.02127,W21:-0.00469 | memoryGatesShort:0.500, Long:0.595, Current:-0.095 | topTokens[(',', 34), ('.', 33), ('i', 23), ('a', 19), ('hey', 17), ('you', 15), ('lo', 15), ('she', 10), ('know', 10), ('up', 9)] | Training
2025-04-04 13:41:46 | 300 | LR0.0003 | loss:8.7752 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.1349 | logitMax:-32.2165 | windowWeightsW8:0.18835,W15:0.16688,W13:0.16487,W18:0.16000,W3:0.12607,W7:0.10584,W2:0.05288,W1:0.02110,W21:-0.00400 | memoryGatesShort:-0.566, Long:0.124, Current:1.442 | topTokens[(',', 55), ('.', 54), ('with', 31), ('a', 18), ('i', 17), ('?', 13), ('she', 12), ('am', 12), ('just', 9), ('now', 8)] | Training
2025-04-04 13:48:25 | 400 | LR0.0003 | loss:8.2945 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.7115 | logitMax:-33.7843 | windowWeightsW8:0.18820,W15:0.16704,W13:0.16487,W18:0.15996,W3:0.12598,W7:0.10594,W2:0.05292,W1:0.02078,W21:-0.00370 | memoryGatesShort:-0.458, Long:0.131, Current:1.327 | topTokens[(',', 66), ('i', 37), ('.', 31), ('know', 29), ('just', 24), ('be', 16), ('no', 13), ('a', 10), ('she', 9), ('were', 8)] | Training
2025-04-04 13:55:12 | 500 | LR0.0003 | loss:10.4566 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-55.4227 | logitMax:-32.9201 | windowWeightsW8:0.18802,W15:0.16700,W13:0.16482,W18:0.15997,W3:0.12578,W7:0.10605,W2:0.05278,W1:0.02076,W21:-0.00317 | memoryGatesShort:1.718, Long:-0.797, Current:0.079 | topTokens[(',', 98), ('no', 48), ('.', 43), ('y', 15), ('a', 10), ('b', 10), ('just', 8), ('had', 7), ('this', 7), ('b', 6)] | Training
2025-04-04 14:01:42 | 600 | LR0.0003 | loss:8.6611 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.3370 | logitMax:-35.9458 | windowWeightsW8:0.18805,W15:0.16704,W13:0.16490,W18:0.16002,W3:0.12562,W7:0.10622,W2:0.05253,W1:0.02067,W21:-0.00305 | memoryGatesShort:-1.276, Long:1.631, Current:0.645 | topTokens[(',', 66), ('.', 34), ('now', 16), ('a', 15), ('i', 14), ('to', 14), ('be', 12), ('were', 11), ('b', 8), ('and', 8)] | Training
2025-04-04 14:08:15 | 700 | LR0.0003 | loss:9.3413 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.0704 | logitMax:-39.6898 | windowWeightsW8:0.18804,W15:0.16687,W13:0.16477,W18:0.15991,W3:0.12547,W7:0.10651,W2:0.05246,W1:0.02056,W21:-0.00257 | memoryGatesShort:-0.380, Long:1.294, Current:0.087 | topTokens[(',', 72), ('.', 29), ('you', 25), ('no', 24), ('?', 21), ('feel', 17), ('y', 13), ('i', 12), ('s', 11), ('me', 11)] | Training
2025-04-04 14:14:45 | 800 | LR0.0003 | loss:8.5231 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.7412 | logitMax:-34.8858 | windowWeightsW8:0.18808,W15:0.16708,W13:0.16482,W18:0.16003,W3:0.12543,W7:0.10643,W2:0.05215,W1:0.02060,W21:-0.00261 | memoryGatesShort:-0.419, Long:0.737, Current:0.682 | topTokens[(',', 53), ('.', 37), ('no', 23), ('a', 13), ('you', 13), ('y', 12), ('she', 11), ('or', 11), ('be', 10), ('a', 9)] | Training
2025-04-04 14:21:22 | 900 | LR0.0003 | loss:9.7038 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-63.4413 | logitMax:-40.0958 | windowWeightsW8:0.18800,W15:0.16715,W13:0.16475,W18:0.16007,W3:0.12545,W7:0.10652,W2:0.05211,W1:0.02038,W21:-0.00240 | memoryGatesShort:1.865, Long:-0.804, Current:-0.060 | topTokens[(',', 78), ('y', 27), ('the', 25), ('b', 24), ('u', 20), ('.', 20), ('a', 17), ('i', 16), ('were', 12), ('b', 12)] | Training
2025-04-04 14:28:05 | 1000 | LR0.0003 | loss:8.2255 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.9879 | logitMax:-33.4229 | windowWeightsW8:0.18761,W15:0.16708,W13:0.16487,W18:0.15971,W3:0.12512,W7:0.10647,W2:0.05213,W1:0.02029,W21:-0.00122 | memoryGatesShort:-11.722, Long:12.086, Current:0.636 | topTokens[(',', 92), ('the', 53), ('.', 34), ('b', 12), ('a', 10), ('m', 9), ('a', 9), ('y', 8), ('u', 8), ('had', 7)] | Training
2025-04-04 14:34:43 | 1100 | LR0.0003 | loss:8.1083 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.4803 | logitMax:-39.8025 | windowWeightsW8:0.18753,W15:0.16702,W13:0.16491,W18:0.15967,W3:0.12492,W7:0.10667,W2:0.05215,W1:0.01996,W21:-0.00079 | memoryGatesShort:-0.696, Long:0.756, Current:0.940 | topTokens[('and', 60), (',', 54), ('.', 31), ('the', 27), ('a', 13), ('a', 13), ('u', 10), ('r', 8), ('b', 7), ('feel', 6)] | Training
2025-04-04 14:41:22 | 1200 | LR0.0003 | loss:9.0898 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.4451 | logitMax:-36.4005 | windowWeightsW8:0.18752,W15:0.16713,W13:0.16505,W18:0.15976,W3:0.12427,W7:0.10654,W2:0.05186,W1:0.01980,W21:0.00015 | memoryGatesShort:-26.736, Long:1.805, Current:25.932 | topTokens[(',', 47), ('the', 46), ('.', 36), ('ink', 35), ('and', 16), ('a', 12), ('c', 10), ('r', 9), ('she', 9), ('you', 7)] | Training
2025-04-04 14:48:12 | 1300 | LR0.0003 | loss:8.1573 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-58.7805 | logitMax:-41.5169 | windowWeightsW8:0.18762,W15:0.16725,W13:0.16511,W18:0.15987,W3:0.12401,W7:0.10675,W2:0.05174,W1:0.01957,W21:0.00016 | memoryGatesShort:-2.861, Long:1.184, Current:2.677 | topTokens[(',', 56), ('.', 38), ('the', 25), ('it', 24), ('to', 15), ('i', 12), ('ink', 12), ('a', 10), ('ed', 8), ('feel', 6)] | Training
2025-04-04 14:54:36 | 1400 | LR0.0003 | loss:9.5010 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.5917 | logitMax:-33.2638 | windowWeightsW8:0.18776,W15:0.16692,W13:0.16514,W18:0.15976,W3:0.12395,W7:0.10697,W2:0.05162,W1:0.01933,W21:0.00064 | memoryGatesShort:-18.630, Long:8.812, Current:10.818 | topTokens[('ed', 52), ('.', 43), (',', 37), ('to', 37), ('i', 19), ('a', 14), ('feel', 11), ('this', 11), ('she', 8), ('were', 8)] | Training
2025-04-04 15:00:55 | 1500 | LR0.0003 | loss:8.0504 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.1818 | logitMax:-39.4545 | windowWeightsW8:0.18760,W15:0.16682,W13:0.16513,W18:0.15955,W3:0.12387,W7:0.10704,W2:0.05125,W1:0.01933,W21:0.00151 | memoryGatesShort:-1.848, Long:1.056, Current:1.792 | topTokens[(',', 56), ('.', 38), ('and', 17), ('to', 16), ('a', 13), ('it', 11), ('ed', 11), ('she', 10), ('b', 9), ('you', 9)] | Training
2025-04-04 15:07:31 | 1600 | LR0.0003 | loss:6.7299 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-46.1252 | logitMax:-23.7631 | windowWeightsW8:0.18811,W15:0.16621,W13:0.16499,W18:0.15880,W3:0.12431,W7:0.10644,W2:0.05215,W1:0.01927,W21:0.00182 | memoryGatesShort:-27.245, Long:-15.762, Current:44.007 | topTokens[('.', 41), (',', 31), ('it', 28), ('i', 24), ('to', 18), ('had', 15), ('?', 15), ('and', 13), ('been', 13), ('listening', 13)] | Training
2025-04-04 15:14:16 | 1700 | LR0.0003 | loss:7.0005 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.7523 | logitMax:-21.4859 | windowWeightsW8:0.18901,W15:0.16488,W13:0.16364,W18:0.15790,W3:0.12648,W7:0.10520,W2:0.05440,W1:0.01951,W21:0.00102 | memoryGatesShort:-0.654, Long:-0.482, Current:2.136 | topTokens[('?', 30), ('had', 28), ('has', 28), ('.', 23), ('to', 23), ('listening', 18), ('he', 17), ('been', 17), (',', 14), ('what', 14)] | Training
2025-04-04 15:20:59 | 1800 | LR0.0003 | loss:6.4006 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.4234 | logitMax:-33.4901 | windowWeightsW8:0.18837,W15:0.16357,W13:0.16246,W18:0.15728,W3:0.12817,W7:0.10586,W2:0.05575,W1:0.01996,W21:0.00061 | memoryGatesShort:-1.059, Long:-1.358, Current:3.417 | topTokens[('.', 34), (',', 26), ('?', 21), ('she', 18), ('listening', 18), ('music', 18), ('to', 18), ('been', 15), ('has', 14), ('had', 13)] | Training
2025-04-04 15:27:45 | 1900 | LR0.0003 | loss:6.6703 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.2869 | logitMax:-32.6066 | windowWeightsW8:0.18741,W15:0.16396,W13:0.16183,W18:0.15800,W3:0.12576,W7:0.10701,W2:0.05499,W1:0.02078,W21:0.00233 | memoryGatesShort:-0.610, Long:0.090, Current:1.520 | topTokens[('.', 39), ('?', 36), ('music', 33), ('the', 23), ('you', 19), ('i', 18), ('to', 15), ('listening', 14), (',', 11), ('people', 11)] | Training
2025-04-04 15:34:34 | 2000 | LR0.0003 | loss:6.2421 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.3528 | logitMax:-29.9272 | windowWeightsW8:0.18856,W15:0.16375,W13:0.16136,W18:0.15799,W3:0.12530,W7:0.10602,W2:0.05519,W1:0.02140,W21:0.00247 | memoryGatesShort:-0.663, Long:-2.566, Current:4.229 | topTokens[('.', 40), ('a', 30), ('i', 27), ('to', 23), ('listening', 21), ('you', 20), ('she', 18), ('had', 14), (',', 14), ('was', 10)] | Training
2025-04-04 15:41:26 | 2100 | LR0.0003 | loss:4.2810 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-69.1743 | logitMax:-38.7254 | windowWeightsW8:0.19000,W15:0.16317,W13:0.16093,W18:0.15724,W3:0.12619,W7:0.10536,W2:0.05571,W1:0.02103,W21:0.00236 | memoryGatesShort:1.578, Long:-1.096, Current:0.518 | topTokens[('to', 41), ('was', 32), ('be', 32), ('listening', 27), ('.', 17), ('a', 16), ('will', 16), ('?', 15), ('she', 13), ('music', 12)] | Training
2025-04-04 15:48:18 | 2200 | LR0.0003 | loss:4.2416 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-52.5041 | logitMax:-26.1202 | windowWeightsW8:0.19042,W15:0.16249,W13:0.16023,W18:0.15678,W3:0.12750,W7:0.10543,W2:0.05604,W1:0.02105,W21:0.00202 | memoryGatesShort:0.163, Long:-1.209, Current:2.047 | topTokens[('to', 48), ('.', 34), ('?', 33), ('will', 28), ('music', 19), ('he', 19), ('listening', 18), ('what', 16), ('a', 14), ('she', 12)] | Training
2025-04-04 15:55:09 | 2300 | LR0.0003 | loss:8.7043 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-76.0492 | logitMax:-31.4423 | windowWeightsW8:0.19031,W15:0.16268,W13:0.15964,W18:0.15676,W3:0.12769,W7:0.10501,W2:0.05628,W1:0.02208,W21:0.00148 | memoryGatesShort:0.492, Long:1.374, Current:-0.866 | topTokens[('?', 42), ('a', 29), ('to', 27), ('listening', 24), ('.', 22), ('music', 21), ('fre', 19), ('she', 16), ('elodie', 14), ('want', 14)] | Training
2025-04-04 16:02:07 | 2400 | LR0.0003 | loss:8.0877 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-52.0304 | logitMax:-19.9927 | windowWeightsW8:0.18950,W15:0.16251,W13:0.15999,W18:0.15746,W3:0.12701,W7:0.10414,W2:0.05718,W1:0.02177,W21:0.00238 | memoryGatesShort:0.883, Long:-0.571, Current:0.688 | topTokens[('a', 40), ('to', 39), ('music', 28), ('will', 21), ('.', 20), (',', 20), ('?', 16), ('it', 16), ('listening', 15), ('want', 13)] | Training
2025-04-04 16:09:05 | 2500 | LR0.0003 | loss:6.3205 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.1330 | logitMax:-25.0216 | windowWeightsW8:0.19001,W15:0.16252,W13:0.15994,W18:0.15719,W3:0.12738,W7:0.10455,W2:0.05688,W1:0.02127,W21:0.00221 | memoryGatesShort:-0.104, Long:-3.079, Current:4.183 | topTokens[('.', 58), ('music', 51), ('listening', 24), ('want', 23), ('a', 21), ('?', 19), ('to', 18), ('i', 17), ('her', 16), (',', 16)] | Training
2025-04-04 16:15:39 | 2600 | LR0.0003 | loss:7.1025 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-41.6267 | logitMax:-10.1906 | windowWeightsW8:0.19075,W15:0.16224,W13:0.15967,W18:0.15680,W3:0.12673,W7:0.10493,W2:0.05649,W1:0.02107,W21:0.00330 | memoryGatesShort:-0.971, Long:5.048, Current:-3.078 | topTokens[('a', 50), ('music', 45), ('.', 37), ('?', 25), ('to', 21), ('listening', 19), ('was', 18), ('will', 14), ('i', 11), ('it', 11)] | Training
2025-04-04 16:21:58 | 2700 | LR0.0003 | loss:7.1193 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-55.2815 | logitMax:-14.7350 | windowWeightsW8:0.19079,W15:0.16161,W13:0.16007,W18:0.15623,W3:0.12713,W7:0.10461,W2:0.05703,W1:0.02129,W21:0.00319 | memoryGatesShort:0.799, Long:-1.087, Current:1.288 | topTokens[('a', 51), ('.', 28), ('listening', 28), ('to', 28), ('music', 22), ('be', 22), ('will', 19), ('?', 18), ('her', 16), ('what', 12)] | Training
2025-04-04 16:28:25 | 2800 | LR0.0003 | loss:8.2844 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.2942 | logitMax:-19.4454 | windowWeightsW8:0.19103,W15:0.16109,W13:0.15971,W18:0.15597,W3:0.12670,W7:0.10501,W2:0.05729,W1:0.02117,W21:0.00400 | memoryGatesShort:-13.253, Long:26.775, Current:-12.522 | topTokens[('a', 55), ('.', 36), ('what', 18), (',', 18), ('io', 17), ('?', 15), ('music', 15), ('elodie', 15), ('he', 13), ('listening', 13)] | Training
2025-04-04 16:34:55 | 2900 | LR0.0003 | loss:9.7444 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.3885 | logitMax:-26.2772 | windowWeightsW8:0.19086,W15:0.16140,W13:0.15981,W18:0.15635,W3:0.12618,W7:0.10520,W2:0.05682,W1:0.02110,W21:0.00426 | memoryGatesShort:0.658, Long:-0.576, Current:0.918 | topTokens[('.', 49), (',', 39), ('a', 33), ('elodie', 15), ('?', 14), ('to', 11), ('i', 8), ('of', 7), ('listening', 7), ('ly', 7)] | Training
2025-04-04 16:41:40 | 3000 | LR0.0003 | loss:7.5120 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-52.5261 | logitMax:-32.7142 | windowWeightsW8:0.19032,W15:0.16123,W13:0.15958,W18:0.15635,W3:0.12597,W7:0.10523,W2:0.05672,W1:0.02140,W21:0.00519 | memoryGatesShort:-0.263, Long:-1.673, Current:2.936 | topTokens[('.', 52), (',', 46), ('the', 18), ('to', 17), ('he', 14), ('she', 12), ('a', 12), ('i', 11), ('n', 9), ('?', 7)] | Training
2025-04-04 16:48:47 | 3100 | LR0.0003 | loss:8.8625 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-49.3751 | logitMax:-29.5379 | windowWeightsW8:0.19013,W15:0.16133,W13:0.15969,W18:0.15649,W3:0.12557,W7:0.10525,W2:0.05643,W1:0.02131,W21:0.00581 | memoryGatesShort:-0.090, Long:-1.106, Current:2.196 | topTokens[(',', 63), ('.', 35), ('a', 26), ('and', 26), ('she', 16), ('er', 16), ('the', 15), ('on', 11), ('s', 10), ('to', 9)] | Training
2025-04-04 16:55:37 | 3200 | LR0.0003 | loss:9.7126 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.8426 | logitMax:-37.4832 | windowWeightsW8:0.18973,W15:0.16167,W13:0.16007,W18:0.15656,W3:0.12536,W7:0.10507,W2:0.05614,W1:0.02122,W21:0.00623 | memoryGatesShort:0.284, Long:-0.043, Current:0.759 | topTokens[(',', 64), ('.', 25), ('a', 24), ('or', 11), ('was', 11), ('i', 10), ('and', 10), ('s', 9), ('to', 8), ('it', 8)] | Training
2025-04-04 17:02:26 | 3300 | LR0.0003 | loss:8.2608 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.0260 | logitMax:-32.8723 | windowWeightsW8:0.18924,W15:0.16166,W13:0.16012,W18:0.15672,W3:0.12515,W7:0.10506,W2:0.05597,W1:0.02128,W21:0.00685 | memoryGatesShort:0.231, Long:0.197, Current:0.572 | topTokens[(',', 82), ('a', 23), ('d', 19), ('.', 19), ('ed', 14), ('p', 13), ('of', 10), ('-', 10), ('y', 10), ('to', 9)] | Training
2025-04-04 17:09:16 | 3400 | LR0.0003 | loss:10.8448 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-59.0570 | logitMax:-35.5848 | windowWeightsW8:0.18874,W15:0.16182,W13:0.16028,W18:0.15689,W3:0.12475,W7:0.10490,W2:0.05567,W1:0.02136,W21:0.00766 | memoryGatesShort:-0.029, Long:0.221, Current:0.808 | topTokens[('a', 44), ('m', 41), (',', 36), ('.', 29), ('the', 25), ('to', 22), ('she', 16), ('b', 12), ('er', 11), ('y', 10)] | Training
2025-04-04 17:16:00 | 3500 | LR0.0003 | loss:8.0786 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.2123 | logitMax:-35.2757 | windowWeightsW8:0.18895,W15:0.16177,W13:0.16035,W18:0.15704,W3:0.12478,W7:0.10495,W2:0.05554,W1:0.02112,W21:0.00757 | memoryGatesShort:-0.223, Long:0.075, Current:1.148 | topTokens[(',', 50), ('.', 26), ('to', 21), ('a', 19), ('m', 18), ('n', 18), ('b', 17), ('their', 14), ('the', 13), ('m', 12)] | Training
2025-04-04 17:22:54 | 3600 | LR0.0003 | loss:9.3838 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.1788 | logitMax:-34.4481 | windowWeightsW8:0.18878,W15:0.16198,W13:0.16035,W18:0.15726,W3:0.12422,W7:0.10480,W2:0.05533,W1:0.02122,W21:0.00814 | memoryGatesShort:0.059, Long:0.100, Current:0.842 | topTokens[(',', 57), ('.', 25), ('she', 21), ('y', 17), ('a', 15), ('ing', 14), ('n', 13), ('es', 10), ('am', 10), ('b', 9)] | Training
2025-04-04 17:29:56 | 3700 | LR0.0003 | loss:9.2567 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.9196 | logitMax:-35.2652 | windowWeightsW8:0.18860,W15:0.16222,W13:0.16029,W18:0.15734,W3:0.12423,W7:0.10504,W2:0.05469,W1:0.02120,W21:0.00848 | memoryGatesShort:-1.389, Long:1.610, Current:0.779 | topTokens[('or', 63), (',', 28), ('a', 23), ('.', 19), ('the', 16), ('m', 15), ('of', 12), ('ing', 9), ('was', 8), ('at', 7)] | Training
2025-04-04 17:36:54 | 3800 | LR0.0003 | loss:7.6236 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.2509 | logitMax:-39.5954 | windowWeightsW8:0.18816,W15:0.16244,W13:0.16079,W18:0.15761,W3:0.12395,W7:0.10509,W2:0.05433,W1:0.02095,W21:0.00880 | memoryGatesShort:-0.153, Long:0.755, Current:0.398 | topTokens[(',', 42), ('of', 30), ('a', 21), ('d', 19), ('the', 17), ('.', 16), ('-', 15), ('and', 14), ('at', 13), ('going', 11)] | Training
2025-04-04 17:43:47 | 3900 | LR0.0003 | loss:8.7862 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-55.2535 | logitMax:-36.9817 | windowWeightsW8:0.18803,W15:0.16240,W13:0.16062,W18:0.15771,W3:0.12385,W7:0.10541,W2:0.05430,W1:0.02123,W21:0.00858 | memoryGatesShort:2.324, Long:-2.658, Current:1.333 | topTokens[('a', 29), ('.', 29), (',', 27), ('she', 21), ('ed', 21), ('a', 20), ('the', 16), ('-', 15), ('not', 14), ('in', 9)] | Training
2025-04-04 17:50:41 | 4000 | LR0.0003 | loss:7.5774 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.2934 | logitMax:-30.2467 | windowWeightsW8:0.18715,W15:0.16289,W13:0.16074,W18:0.15806,W3:0.12410,W7:0.10411,W2:0.05379,W1:0.02179,W21:0.00950 | memoryGatesShort:-0.677, Long:0.283, Current:1.393 | topTokens[(',', 58), ('s', 40), ('.', 35), ('their', 35), ('st', 19), ('was', 15), ('fore', 14), ('a', 13), ('and', 9), ('of', 8)] | Training
2025-04-04 17:57:32 | 4100 | LR0.0003 | loss:8.5796 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-48.6446 | logitMax:-26.3447 | windowWeightsW8:0.18673,W15:0.16301,W13:0.16054,W18:0.15812,W3:0.12384,W7:0.10453,W2:0.05328,W1:0.02158,W21:0.01053 | memoryGatesShort:-2.843, Long:0.422, Current:3.421 | topTokens[('.', 54), ('st', 42), (',', 30), ('was', 23), ('a', 22), ('s', 20), ('and', 18), ('not', 13), ('she', 11), ('of', 10)] | Training
2025-04-04 18:04:35 | 4200 | LR0.0003 | loss:8.0398 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.0586 | logitMax:-29.3240 | windowWeightsW8:0.18700,W15:0.16206,W13:0.16130,W18:0.15810,W3:0.12382,W7:0.10480,W2:0.05425,W1:0.02127,W21:0.00954 | memoryGatesShort:2.252, Long:0.818, Current:-2.070 | topTokens[(',', 72), ('or', 59), ('.', 25), ('a', 22), ('two', 19), ('st', 17), ('one', 16), ('their', 15), ('she', 11), ('of', 10)] | Training
2025-04-04 18:11:24 | 4300 | LR0.0003 | loss:9.0631 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-55.8030 | logitMax:-35.8591 | windowWeightsW8:0.18710,W15:0.16191,W13:0.16143,W18:0.15773,W3:0.12351,W7:0.10519,W2:0.05358,W1:0.02157,W21:0.01013 | memoryGatesShort:-0.315, Long:1.466, Current:-0.151 | topTokens[(',', 54), ('a', 28), ('that', 28), ('or', 26), ('.', 24), ('st', 13), ('on', 12), ('one', 12), ('their', 10), ('y', 10)] | Training
2025-04-04 18:18:35 | 4400 | LR0.0003 | loss:6.8638 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.4099 | logitMax:-36.9504 | windowWeightsW8:0.18709,W13:0.16307,W15:0.16274,W18:0.15720,W3:0.12222,W7:0.10472,W2:0.05230,W1:0.02179,W21:0.01104 | memoryGatesShort:-21.452, Long:-6.809, Current:29.260 | topTokens[(',', 41), ('.', 35), ('a', 19), ('s', 15), ('to', 14), ('or', 12), ('you', 11), ('the', 10), ('she', 10), ('i', 9)] | Training
2025-04-04 18:25:42 | 4500 | LR0.0003 | loss:6.8701 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.5011 | logitMax:-25.6556 | windowWeightsW8:0.18836,W13:0.16260,W15:0.16255,W18:0.15732,W3:0.12177,W7:0.10390,W2:0.05238,W1:0.02272,W21:0.01056 | memoryGatesShort:-0.601, Long:-0.849, Current:2.450 | topTokens[('.', 41), ('?', 29), ('to', 29), (',', 27), ('she', 17), ('will', 15), ('not', 15), ('what', 14), ('i', 10), ('want', 9)] | Training
2025-04-04 18:32:48 | 4600 | LR0.0003 | loss:9.5114 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-63.1269 | logitMax:-29.8988 | windowWeightsW8:0.18958,W13:0.16318,W15:0.16215,W18:0.15657,W3:0.12092,W7:0.10381,W2:0.05276,W1:0.02247,W21:0.01072 | memoryGatesShort:-0.603, Long:-0.715, Current:2.317 | topTokens[(',', 36), ('.', 27), ('?', 21), ('to', 19), ('a', 16), ('i', 14), ('you', 12), ('do', 11), ('dont', 10), ('me', 10)] | Training
2025-04-04 18:39:46 | 4700 | LR0.0003 | loss:7.7218 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-55.5580 | logitMax:-30.7179 | windowWeightsW8:0.18985,W13:0.16289,W15:0.16195,W18:0.15661,W3:0.12059,W7:0.10359,W2:0.05297,W1:0.02269,W21:0.01101 | memoryGatesShort:-0.790, Long:-1.100, Current:2.890 | topTokens[(',', 51), ('?', 22), ('.', 21), ('s', 17), ('was', 15), ('to', 15), ('were', 13), ('i', 12), ('a', 12), ('dance', 12)] | Training
2025-04-04 18:46:37 | 4800 | LR0.0003 | loss:10.2810 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-75.7640 | logitMax:-44.9609 | windowWeightsW8:0.18925,W13:0.16306,W15:0.16155,W18:0.15622,W3:0.12077,W7:0.10379,W2:0.05316,W1:0.02251,W21:0.01185 | memoryGatesShort:-0.231, Long:1.040, Current:0.191 | topTokens[('to', 36), ('a', 28), ('.', 28), (',', 25), ('was', 20), ('i', 17), ('?', 15), ('you', 12), ('why', 12), ('c', 10)] | Training
2025-04-04 18:53:31 | 4900 | LR0.0003 | loss:9.7250 | gradNorm:0.9940 | tokenCount:400.0000 | logitMin:-83.6383 | logitMax:-38.3764 | windowWeightsW8:0.19128,W13:0.16305,W15:0.16253,W18:0.15503,W3:0.11995,W7:0.10420,W2:0.05342,W1:0.02115,W21:0.01156 | memoryGatesShort:-1.503, Long:-3.540, Current:6.043 | topTokens[('has', 32), ('i', 29), ('to', 26), (',', 25), ('about', 24), ('?', 23), ('you', 23), ('think', 22), ('what', 17), ('a', 15)] | Training
2025-04-04 19:00:29 | 5000 | LR0.0003 | loss:5.9422 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.4202 | logitMax:-22.1854 | windowWeightsW8:0.19442,W13:0.16283,W15:0.16069,W18:0.15382,W3:0.11991,W7:0.10466,W2:0.05237,W1:0.02082,W21:0.01261 | memoryGatesShort:0.239, Long:-1.234, Current:1.995 | topTokens[('not', 45), ('.', 38), ('think', 25), ('?', 23), (',', 19), ('music', 16), ('a', 15), ('was', 15), ('what', 12), ('to', 12)] | Training
2025-04-04 19:07:21 | 5100 | LR0.0003 | loss:4.7682 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.0861 | logitMax:-17.6708 | windowWeightsW8:0.19397,W13:0.16249,W15:0.16037,W18:0.15405,W3:0.11931,W7:0.10163,W2:0.05372,W1:0.02324,W21:0.01332 | memoryGatesShort:0.470, Long:-0.626, Current:1.155 | topTokens[('.', 48), ('was', 31), ('you', 26), ('sm', 24), ('playing', 23), ('he', 17), ('what', 17), (',', 16), ('?', 15), ('a', 12)] | Training
2025-04-04 19:14:18 | 5200 | LR0.0003 | loss:5.8894 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-52.0136 | logitMax:-21.1300 | windowWeightsW8:0.19395,W13:0.16347,W15:0.16115,W18:0.15405,W3:0.11721,W7:0.10233,W2:0.05334,W1:0.02309,W21:0.01355 | memoryGatesShort:0.036, Long:-1.516, Current:2.481 | topTokens[('.', 45), (',', 34), ('were', 27), ('?', 23), ('they', 17), ('what', 16), ('to', 16), ('are', 16), ('a', 13), ('listening', 11)] | Training
2025-04-04 19:21:02 | 5300 | LR0.0003 | loss:5.1235 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.1829 | logitMax:-33.1185 | windowWeightsW8:0.19452,W13:0.16321,W15:0.16064,W18:0.15378,W3:0.11763,W7:0.10251,W2:0.05386,W1:0.02292,W21:0.01304 | memoryGatesShort:-1.003, Long:-7.704, Current:9.707 | topTokens[('.', 37), ('?', 26), ('to', 25), (',', 20), ('what', 14), ('i', 14), ('were', 13), ('you', 13), ('want', 10), ('they', 10)] | Training
2025-04-04 19:27:51 | 5400 | LR0.0003 | loss:7.9190 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.0585 | logitMax:-23.9531 | windowWeightsW8:0.19348,W13:0.16313,W15:0.16068,W18:0.15409,W3:0.11697,W7:0.10251,W2:0.05467,W1:0.02355,W21:0.01305 | memoryGatesShort:0.652, Long:-1.005, Current:1.354 | topTokens[(',', 39), ('my', 39), ('.', 28), ('not', 27), ('i', 23), ('about', 17), ('look', 16), ('a', 15), ('mum', 14), ('?', 13)] | Training
2025-04-04 19:34:38 | 5500 | LR0.0003 | loss:9.6533 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.4537 | logitMax:-14.3966 | windowWeightsW8:0.19346,W13:0.16333,W15:0.16079,W18:0.15389,W3:0.11670,W7:0.10213,W2:0.05435,W1:0.02423,W21:0.01325 | memoryGatesShort:0.380, Long:-1.531, Current:2.151 | topTokens[('my', 52), ('.', 33), ('look', 26), (',', 20), ('music', 17), ('what', 17), ('am', 16), ('are', 14), ('you', 14), ('a', 13)] | Training
2025-04-04 19:41:18 | 5600 | LR0.0003 | loss:5.7929 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.1706 | logitMax:-31.3336 | windowWeightsW8:0.19323,W13:0.16417,W15:0.16149,W18:0.15477,W3:0.11618,W7:0.10221,W2:0.05289,W1:0.02376,W21:0.01347 | memoryGatesShort:13.235, Long:-45.035, Current:32.800 | topTokens[('.', 43), (',', 37), ('will', 26), ('ry', 20), ('for', 19), ('?', 17), ('look', 16), ('you', 16), ('a', 15), ('were', 13)] | Training
2025-04-04 19:48:10 | 5700 | LR0.0003 | loss:9.0562 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.4923 | logitMax:-33.1692 | windowWeightsW8:0.19285,W13:0.16417,W15:0.16209,W18:0.15556,W3:0.11580,W7:0.10213,W2:0.05225,W1:0.02333,W21:0.01402 | memoryGatesShort:-1.627, Long:1.792, Current:0.835 | topTokens[(',', 60), ('t', 42), ('for', 41), ('.', 23), ('she', 17), ('a', 14), ('my', 11), ('look', 11), ('will', 10), ('has', 8)] | Training
2025-04-04 19:54:53 | 5800 | LR0.0003 | loss:7.8888 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-59.7137 | logitMax:-43.1636 | windowWeightsW8:0.19263,W13:0.16433,W15:0.16249,W18:0.15595,W3:0.11539,W7:0.10209,W2:0.05178,W1:0.02303,W21:0.01452 | memoryGatesShort:0.620, Long:-0.467, Current:0.847 | topTokens[(',', 105), ('t', 29), ('.', 21), ('a', 11), ('for', 10), ('at', 9), ('and', 8), ('i', 8), ('me', 7), ('ry', 7)] | Training
2025-04-04 20:01:31 | 5900 | LR0.0003 | loss:8.2760 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-55.0358 | logitMax:-37.9430 | windowWeightsW8:0.19235,W13:0.16465,W15:0.16294,W18:0.15629,W3:0.11475,W7:0.10216,W2:0.05127,W1:0.02285,W21:0.01498 | memoryGatesShort:-0.037, Long:-0.705, Current:1.742 | topTokens[('no', 56), (',', 44), ('a', 18), ('b', 17), ('.', 14), ('i', 11), ('has', 8), ('es', 8), ('for', 8), ('were', 8)] | Training
2025-04-04 20:08:17 | 6000 | LR0.0003 | loss:7.4148 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.6915 | logitMax:-40.2628 | windowWeightsW8:0.19243,W13:0.16513,W15:0.16402,W18:0.15676,W3:0.11375,W7:0.10224,W2:0.05049,W1:0.02287,W21:0.01457 | memoryGatesShort:-2.990, Long:1.801, Current:2.189 | topTokens[('.', 49), (',', 41), ('you', 33), ('ly', 16), ('my', 14), ('a', 13), ('im', 11), ('!', 10), ('were', 10), ('this', 8)] | Training
2025-04-04 20:14:59 | 6100 | LR0.0003 | loss:8.5648 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-58.1294 | logitMax:-38.5518 | windowWeightsW8:0.19228,W13:0.16569,W15:0.16428,W18:0.15711,W3:0.11302,W7:0.10204,W2:0.04956,W1:0.02280,W21:0.01550 | memoryGatesShort:-0.594, Long:0.674, Current:0.921 | topTokens[('you', 80), (',', 52), ('.', 32), ('ly', 22), ('she', 13), ('i', 11), ('me', 11), ('and', 10), ('the', 9), ('think', 9)] | Training
2025-04-04 20:21:52 | 6200 | LR0.0003 | loss:8.6148 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.3982 | logitMax:-34.5233 | windowWeightsW8:0.19170,W13:0.16562,W15:0.16464,W18:0.15774,W3:0.11275,W7:0.10218,W2:0.04905,W1:0.02254,W21:0.01606 | memoryGatesShort:-3.324, Long:7.181, Current:-2.857 | topTokens[('me', 44), (',', 41), ('.', 37), ('and', 23), ('you', 17), ('a', 14), ('like', 14), ('i', 12), ('were', 11), ('mum', 11)] | Training
2025-04-04 20:28:36 | 6300 | LR0.0003 | loss:7.6280 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-61.4824 | logitMax:-46.2661 | windowWeightsW8:0.19139,W13:0.16565,W15:0.16488,W18:0.15807,W3:0.11263,W7:0.10223,W2:0.04892,W1:0.02227,W21:0.01629 | memoryGatesShort:-6.461, Long:6.641, Current:0.820 | topTokens[(',', 54), ('.', 25), ('and', 25), ('me', 18), ('p', 16), ('the', 14), ('id', 13), ('a', 11), ('you', 11), ('i', 10)] | Training
2025-04-04 20:35:28 | 6400 | LR0.0003 | loss:9.2690 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.7507 | logitMax:-38.1313 | windowWeightsW8:0.19118,W13:0.16569,W15:0.16496,W18:0.15830,W3:0.11234,W7:0.10220,W2:0.04877,W1:0.02234,W21:0.01655 | memoryGatesShort:-0.910, Long:0.932, Current:0.978 | topTokens[(',', 51), ('think', 28), ('a', 25), ('me', 22), ('.', 20), ('on', 12), ('i', 11), ('getting', 10), ('you', 9), ('ed', 7)] | Training
2025-04-04 20:42:20 | 6500 | LR0.0003 | loss:9.3951 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.6232 | logitMax:-37.5360 | windowWeightsW8:0.19108,W13:0.16539,W15:0.16492,W18:0.15908,W3:0.11221,W7:0.10234,W2:0.04827,W1:0.02227,W21:0.01677 | memoryGatesShort:-2.415, Long:2.254, Current:1.161 | topTokens[(',', 55), ('.', 30), ('the', 21), ('i', 19), ('es', 17), ('it', 14), ('my', 14), ('were', 9), ('was', 9), ('you', 9)] | Training
2025-04-04 20:49:07 | 6600 | LR0.0003 | loss:9.8595 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.0504 | logitMax:-38.7950 | windowWeightsW8:0.19091,W13:0.16580,W15:0.16510,W18:0.15903,W3:0.11187,W7:0.10240,W2:0.04796,W1:0.02196,W21:0.01734 | memoryGatesShort:-1.080, Long:1.538, Current:0.542 | topTokens[('i', 58), (',', 39), ('the', 39), ('were', 28), ('.', 25), ('on', 12), ('p', 10), ('you', 9), ('like', 9), ('ing', 8)] | Training
2025-04-04 20:55:50 | 6700 | LR0.0003 | loss:8.9999 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.2379 | logitMax:-37.3432 | windowWeightsW8:0.19057,W13:0.16554,W15:0.16471,W18:0.15936,W3:0.11184,W7:0.10244,W2:0.04793,W1:0.02202,W21:0.01795 | memoryGatesShort:-0.982, Long:0.777, Current:1.205 | topTokens[('me', 67), (',', 36), ('you', 32), ('.', 24), ('but', 19), ('were', 17), ('with', 17), ('i', 14), ('know', 10), ('s', 8)] | Training
2025-04-04 21:02:37 | 6800 | LR0.0003 | loss:7.8292 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-49.7581 | logitMax:-33.2755 | windowWeightsW8:0.18910,W13:0.16689,W15:0.16589,W18:0.16023,W3:0.11130,W7:0.10222,W2:0.04700,W1:0.02164,W21:0.01815 | memoryGatesShort:-4.828, Long:7.537, Current:-1.709 | topTokens[('i', 64), ('you', 47), (',', 32), ('this', 27), ('look', 26), ('a', 18), ('.', 15), ('for', 9), ('want', 8), ('she', 7)] | Training
2025-04-04 21:09:23 | 6900 | LR0.0003 | loss:9.0257 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-49.9914 | logitMax:-30.5496 | windowWeightsW8:0.18862,W13:0.16712,W15:0.16632,W18:0.16083,W3:0.11127,W7:0.10150,W2:0.04671,W1:0.02130,W21:0.01876 | memoryGatesShort:-50.532, Long:2.779, Current:48.753 | topTokens[('you', 127), ('.', 39), (',', 24), ('to', 20), ('a', 14), ('were', 9), ('i', 9), ('ly', 8), ('she', 7), ('in', 6)] | Training
2025-04-04 21:16:10 | 7000 | LR0.0003 | loss:6.3053 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.0619 | logitMax:-25.1274 | windowWeightsW8:0.18786,W15:0.16833,W13:0.16614,W18:0.16199,W3:0.11163,W7:0.10040,W2:0.04633,W1:0.02159,W21:0.01818 | memoryGatesShort:-5.366, Long:-4.113, Current:10.479 | topTokens[('.', 40), ('you', 33), ('i', 23), (',', 20), ('!', 16), ('a', 11), ('d', 11), ('it', 11), ('to', 10), ('and', 9)] | Training
2025-04-04 21:23:06 | 7100 | LR0.0003 | loss:5.9233 | gradNorm:0.9256 | tokenCount:400.0000 | logitMin:-70.5015 | logitMax:-11.6009 | windowWeightsW8:0.19207,W15:0.16767,W13:0.16455,W18:0.16086,W3:0.11580,W7:0.10095,W2:0.04542,W1:0.01889,W21:0.01615 | memoryGatesShort:1.476, Long:2.292, Current:-2.767 | topTokens[('.', 42), ('it', 39), ('i', 37), ('hi', 37), ('!', 35), ('am', 22), ('know', 19), ('happy', 14), ('d', 13), ('music', 12)] | Training
2025-04-04 21:30:00 | 7200 | LR0.0003 | loss:9.5821 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.9614 | logitMax:-33.1656 | windowWeightsW8:0.19192,W15:0.16761,W13:0.16467,W18:0.16095,W3:0.11569,W7:0.10067,W2:0.04517,W1:0.01872,W21:0.01698 | memoryGatesShort:0.151, Long:-0.118, Current:0.967 | topTokens[('.', 37), ('d', 35), ('it', 32), ('ro', 32), (',', 20), ('in', 14), ('a', 14), ('me', 13), ('am', 12), ('i', 8)] | Training
2025-04-04 21:36:46 | 7300 | LR0.0003 | loss:8.0571 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.4128 | logitMax:-45.9138 | windowWeightsW8:0.19153,W15:0.16763,W13:0.16524,W18:0.16110,W3:0.11531,W7:0.10041,W2:0.04501,W1:0.01831,W21:0.01787 | memoryGatesShort:0.534, Long:0.317, Current:0.149 | topTokens[(',', 35), ('.', 23), ('at', 22), ('al', 21), ('a', 19), ('ro', 12), ('d', 11), ('it', 10), ('on', 10), ('or', 10)] | Training
2025-04-04 21:43:43 | 7400 | LR0.0003 | loss:8.5420 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-63.3462 | logitMax:-44.7535 | windowWeightsW8:0.19145,W15:0.16757,W13:0.16542,W18:0.16113,W3:0.11510,W7:0.10038,W2:0.04492,W21:0.01825,W1:0.01820 | memoryGatesShort:1.801, Long:1.361, Current:-2.163 | topTokens[('i', 29), ('my', 28), ('.', 26), (',', 22), ('with', 17), ('d', 16), ('a', 15), ('me', 14), ('not', 12), ('t', 11)] | Training
2025-04-04 21:50:35 | 7500 | LR0.0003 | loss:8.8544 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.0842 | logitMax:-40.5046 | windowWeightsW8:0.19102,W15:0.16754,W13:0.16560,W18:0.16121,W3:0.11481,W7:0.10054,W2:0.04461,W21:0.01891,W1:0.01818 | memoryGatesShort:0.141, Long:0.530, Current:0.328 | topTokens[('.', 26), (',', 22), ('my', 21), ('i', 21), ('a', 14), ('am', 12), ('just', 12), ('ro', 11), ('y', 10), ('were', 8)] | Training
2025-04-04 21:57:16 | 7600 | LR0.0003 | loss:9.9824 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.0595 | logitMax:-44.4551 | windowWeightsW8:0.19088,W15:0.16740,W13:0.16569,W18:0.16122,W3:0.11458,W7:0.10066,W2:0.04446,W21:0.01935,W1:0.01820 | memoryGatesShort:-1.005, Long:0.477, Current:1.529 | topTokens[('just', 30), ('.', 28), (',', 24), ('a', 24), ('to', 21), ('', 18), ('think', 16), ('-', 13), ('it', 12), ('in', 11)] | Training
2025-04-04 22:03:58 | 7700 | LR0.0003 | loss:9.5472 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-62.2399 | logitMax:-40.9338 | windowWeightsW8:0.19043,W15:0.16737,W13:0.16595,W18:0.16143,W3:0.11426,W7:0.10069,W2:0.04418,W21:0.02003,W1:0.01810 | memoryGatesShort:-1.066, Long:0.983, Current:1.083 | topTokens[(',', 38), ('.', 28), ('that', 23), ('in', 19), ('just', 12), ('a', 11), ('it', 11), ('she', 10), ('t', 9), ('you', 9)] | Training
2025-04-04 22:10:36 | 7800 | LR0.0003 | loss:8.5298 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-59.9930 | logitMax:-42.1689 | windowWeightsW8:0.19036,W15:0.16740,W13:0.16607,W18:0.16154,W3:0.11423,W7:0.10068,W2:0.04437,W21:0.01990,W1:0.01790 | memoryGatesShort:-1.398, Long:1.029, Current:1.368 | topTokens[(',', 33), ('.', 30), ('re', 23), ('my', 23), ('n', 15), ('i', 15), ('a', 14), ('h', 13), ('to', 11), ('', 10)] | Training
2025-04-04 22:17:22 | 7900 | LR0.0003 | loss:8.0924 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.0216 | logitMax:-37.4373 | windowWeightsW8:0.18994,W15:0.16747,W13:0.16603,W18:0.16207,W3:0.11388,W7:0.10021,W2:0.04444,W21:0.02050,W1:0.01792 | memoryGatesShort:-1.747, Long:1.156, Current:1.590 | topTokens[('.', 53), ('my', 27), ('i', 25), ('a', 25), (',', 24), ("'m", 12), ('ar', 10), ('she', 10), ('y', 9), ('to', 8)] | Training
2025-04-04 22:23:59 | 8000 | LR0.0003 | loss:9.6082 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.9415 | logitMax:-39.8943 | windowWeightsW8:0.18999,W15:0.16748,W13:0.16599,W18:0.16213,W3:0.11385,W7:0.10004,W2:0.04465,W21:0.02023,W1:0.01810 | memoryGatesShort:-1.369, Long:1.004, Current:1.366 | topTokens[('to', 55), ('it', 52), ('.', 42), (',', 30), ('a', 16), ('you', 11), ('so', 8), ('i', 7), ('b', 7), ('will', 6)] | Training
2025-04-04 22:30:40 | 8100 | LR0.0003 | loss:8.2272 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-59.9644 | logitMax:-40.9109 | windowWeightsW8:0.18935,W15:0.16771,W13:0.16660,W18:0.16256,W3:0.11351,W7:0.10001,W2:0.04400,W21:0.02134,W1:0.01741 | memoryGatesShort:13.144, Long:-12.836, Current:0.692 | topTokens[('.', 34), (',', 29), ('to', 24), ('i', 20), ('a', 14), ('this', 14), ('so', 12), ('l', 11), ('you', 10), ('it', 10)] | Training
2025-04-04 22:37:14 | 8200 | LR0.0003 | loss:8.5826 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-43.5399 | logitMax:-27.8673 | windowWeightsW8:0.18925,W15:0.16766,W13:0.16665,W18:0.16254,W3:0.11357,W7:0.10006,W2:0.04381,W21:0.02172,W1:0.01724 | memoryGatesShort:-86.328, Long:54.867, Current:32.461 | topTokens[(',', 46), ('.', 26), ('a', 19), ('it', 18), ('to', 17), ('this', 14), ('i', 13), ('l', 11), ('she', 9), ('were', 9)] | Training
2025-04-04 22:43:56 | 8300 | LR0.0003 | loss:9.0454 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-55.2222 | logitMax:-35.7286 | windowWeightsW8:0.18905,W15:0.16760,W13:0.16669,W18:0.16267,W3:0.11334,W7:0.10003,W2:0.04374,W21:0.02199,W1:0.01739 | memoryGatesShort:-2.543, Long:0.466, Current:3.077 | topTokens[('.', 47), ('it', 36), ('to', 27), (',', 24), ('a', 19), ('that', 12), ('lo', 10), ("'t", 9), ('l', 9), ('music', 9)] | Training
2025-04-04 22:50:45 | 8400 | LR0.0003 | loss:10.2029 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.7874 | logitMax:-32.6714 | windowWeightsW8:0.18875,W15:0.16742,W13:0.16694,W18:0.16265,W3:0.11305,W7:0.10026,W2:0.04318,W21:0.02315,W1:0.01713 | memoryGatesShort:-0.308, Long:0.844, Current:0.464 | topTokens[('am', 27), (',', 25), ('this', 19), ('a', 18), ('.', 17), ('she', 16), ('i', 15), ("'m", 12), ('to', 11), ('ent', 10)] | Training
2025-04-04 22:57:30 | 8500 | LR0.0003 | loss:9.6157 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.4138 | logitMax:-45.4155 | windowWeightsW8:0.18919,W15:0.16786,W13:0.16754,W18:0.16374,W3:0.11187,W7:0.10059,W2:0.04194,W21:0.02365,W1:0.01617 | memoryGatesShort:5.260, Long:-1.123, Current:-3.136 | topTokens[('.', 30), ('this', 23), ('a', 17), ("'", 17), (',', 16), ("'", 15), ('that', 15), ('ent', 13), ('in', 10), ('were', 10)] | Training
2025-04-04 23:04:17 | 8600 | LR0.0003 | loss:7.0809 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.0554 | logitMax:-41.0354 | windowWeightsW8:0.18922,W13:0.16782,W15:0.16780,W18:0.16429,W3:0.11202,W7:0.10079,W2:0.04140,W21:0.02327,W1:0.01595 | memoryGatesShort:-147.150, Long:65.020, Current:83.130 | topTokens[('a', 34), (',', 33), ('.', 27), ("'", 23), ('c', 22), ('i', 20), ('it', 18), ('and', 18), ('the', 14), ('to', 12)] | Training
2025-04-04 23:11:12 | 8700 | LR0.0003 | loss:6.4778 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-62.7729 | logitMax:-41.7612 | windowWeightsW8:0.18921,W13:0.16817,W15:0.16777,W18:0.16403,W3:0.11232,W7:0.10052,W2:0.04099,W21:0.02338,W1:0.01616 | memoryGatesShort:-2.629, Long:0.553, Current:3.076 | topTokens[('.', 37), ('i', 36), ('?', 31), (',', 27), ('you', 22), ('do', 17), ('a', 14), ('and', 13), ('to', 11), ('were', 10)] | Training
2025-04-04 23:17:52 | 8800 | LR0.0003 | loss:6.0908 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.2888 | logitMax:-38.7387 | windowWeightsW8:0.18950,W13:0.16877,W15:0.16779,W18:0.16265,W3:0.11221,W7:0.10094,W2:0.04038,W21:0.02403,W1:0.01627 | memoryGatesShort:-3.420, Long:2.738, Current:1.682 | topTokens[('.', 48), ('?', 34), ('do', 24), ('a', 19), (',', 18), ('is', 14), ('im', 14), ('i', 12), ('she', 10), ('who', 10)] | Training
2025-04-04 23:24:35 | 8900 | LR0.0003 | loss:5.9082 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-62.7805 | logitMax:-41.2059 | windowWeightsW8:0.18906,W13:0.16870,W15:0.16795,W18:0.16319,W3:0.11130,W7:0.10082,W2:0.03962,W21:0.02482,W1:0.01710 | memoryGatesShort:-30.993, Long:1.782, Current:30.211 | topTokens[('.', 50), ('?', 44), ('to', 26), ('you', 23), (',', 15), ('remember', 14), ('pete', 11), ('were', 10), ('watching', 9), ('do', 9)] | Training
2025-04-04 23:31:08 | 9000 | LR0.0003 | loss:6.0157 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.9175 | logitMax:-43.4075 | windowWeightsW8:0.18883,W13:0.16823,W15:0.16773,W18:0.16321,W3:0.11122,W7:0.10135,W2:0.03962,W21:0.02493,W1:0.01745 | memoryGatesShort:-2.225, Long:0.816, Current:2.409 | topTokens[('.', 51), ('you', 38), ('?', 18), ('look', 16), ('to', 16), ('kevin', 16), ('i', 16), (',', 16), ('a', 14), ('is', 14)] | Training
2025-04-04 23:37:38 | 9100 | LR0.0003 | loss:6.3521 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-55.1680 | logitMax:-26.6348 | windowWeightsW8:0.18780,W15:0.16750,W13:0.16730,W18:0.16261,W3:0.11013,W7:0.10188,W2:0.04058,W21:0.02613,W1:0.01864 | memoryGatesShort:-1.579, Long:0.865, Current:1.714 | topTokens[('.', 44), (',', 38), ('?', 26), ('do', 24), ('is', 23), ('to', 16), ('him', 15), ('you', 14), ('i', 13), ('her', 13)] | Training
2025-04-04 23:43:58 | 9200 | LR0.0003 | loss:7.8930 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.8161 | logitMax:-27.5693 | windowWeightsW8:0.18771,W13:0.16710,W15:0.16706,W18:0.16232,W3:0.10971,W7:0.10226,W2:0.04087,W21:0.02674,W1:0.01882 | memoryGatesShort:2.270, Long:0.780, Current:-2.050 | topTokens[(',', 44), ('.', 38), ('?', 26), ('is', 18), ('you', 16), ('she', 12), ('pete', 10), ('a', 10), ('king', 10), ('im', 7)] | Training
2025-04-04 23:50:23 | 9300 | LR0.0003 | loss:8.2890 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-77.7859 | logitMax:-42.4714 | windowWeightsW8:0.18765,W15:0.16567,W13:0.16422,W18:0.16226,W3:0.11253,W7:0.10422,W2:0.03938,W21:0.02673,W1:0.01986 | memoryGatesShort:-0.729, Long:-0.458, Current:2.187 | topTokens[(',', 31), ('.', 29), ('?', 27), ('with', 16), ('you', 15), ('what', 13), ('he', 13), ('play', 12), ('mum', 11), ('s', 9)] | Training
2025-04-04 23:56:50 | 9400 | LR0.0003 | loss:7.5680 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-88.3810 | logitMax:-55.7461 | windowWeightsW8:0.18668,W15:0.16555,W13:0.16390,W18:0.16207,W3:0.11239,W7:0.10492,W2:0.03941,W21:0.02758,W1:0.02004 | memoryGatesShort:-0.506, Long:-0.427, Current:1.933 | topTokens[('.', 56), ('do', 23), ('like', 22), ('your', 18), (',', 18), ('?', 17), ('you', 16), ('coo', 14), ('a', 12), ('what', 11)] | Training
2025-04-05 00:03:10 | 9500 | LR0.0003 | loss:7.4328 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.8464 | logitMax:-36.2520 | windowWeightsW8:0.18772,W15:0.16582,W13:0.16384,W18:0.16198,W3:0.11215,W7:0.10581,W2:0.03876,W21:0.02743,W1:0.01905 | memoryGatesShort:0.146, Long:0.036, Current:0.818 | topTokens[('.', 44), (',', 37), ('to', 30), ('do', 30), ('?', 25), ('you', 22), ('your', 19), ('i', 15), ('with', 14), ('had', 12)] | Training
2025-04-05 00:10:04 | 9600 | LR0.0003 | loss:6.1832 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-59.7969 | logitMax:-32.2938 | windowWeightsW8:0.18721,W15:0.16583,W13:0.16364,W18:0.16245,W3:0.11146,W7:0.10497,W2:0.03872,W21:0.02865,W1:0.01963 | memoryGatesShort:-1.671, Long:-1.700, Current:4.371 | topTokens[('?', 52), ('.', 39), (',', 32), ('you', 23), ('music', 22), ('do', 18), ('want', 14), ('he', 13), ('she', 10), ('did', 10)] | Training
2025-04-05 00:16:30 | 9700 | LR0.0003 | loss:6.8379 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-61.6287 | logitMax:-37.1850 | windowWeightsW8:0.18695,W15:0.16623,W13:0.16381,W18:0.16242,W3:0.11069,W7:0.10542,W2:0.03832,W21:0.03025,W1:0.01853 | memoryGatesShort:-0.243, Long:-0.198, Current:1.442 | topTokens[('.', 51), ('?', 27), (',', 25), ('you', 21), ('what', 17), ('pete', 16), ('do', 16), ('like', 15), ('playing', 12), ('looking', 10)] | Training
2025-04-05 00:23:32 | 9800 | LR0.0003 | loss:7.5624 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-62.3790 | logitMax:-36.2124 | windowWeightsW8:0.18741,W15:0.16646,W13:0.16389,W18:0.16162,W3:0.11036,W7:0.10596,W2:0.03891,W21:0.02959,W1:0.01843 | memoryGatesShort:-0.304, Long:-0.603, Current:1.907 | topTokens[(',', 62), ('?', 42), ('.', 35), ('is', 22), ('kevin', 22), ('what', 16), ('you', 13), ('i', 12), ('do', 12), ('pete', 11)] | Training
2025-04-05 00:30:17 | 9900 | LR0.0003 | loss:5.6644 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-67.8943 | logitMax:-45.9747 | windowWeightsW8:0.18687,W15:0.16633,W13:0.16334,W18:0.16134,W3:0.11084,W7:0.10588,W2:0.03963,W21:0.02981,W1:0.01857 | memoryGatesShort:0.583, Long:-1.381, Current:1.797 | topTokens[('.', 48), ('?', 30), ('i', 28), ('will', 25), ('you', 22), ('!', 17), ('eat', 16), ('my', 15), (',', 15), ('ace', 14)] | Training
2025-04-05 00:37:06 | 10000 | LR0.0003 | loss:8.7003 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-59.3926 | logitMax:-36.6624 | windowWeightsW8:0.18717,W15:0.16591,W13:0.16307,W18:0.16163,W3:0.11069,W7:0.10626,W2:0.03911,W21:0.03020,W1:0.01857 | memoryGatesShort:0.612, Long:-0.211, Current:0.600 | topTokens[('.', 49), ('you', 34), (',', 33), ('?', 25), ('is', 22), ('i', 14), ('a', 13), ('we', 11), ('not', 8), ('are', 8)] | Training
2025-04-05 00:44:00 | 10100 | LR0.0003 | loss:8.7640 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.9327 | logitMax:-36.1315 | windowWeightsW8:0.18712,W15:0.16590,W13:0.16304,W18:0.16181,W3:0.11073,W7:0.10635,W2:0.03884,W21:0.03035,W1:0.01849 | memoryGatesShort:-0.329, Long:1.060, Current:0.268 | topTokens[('.', 49), (',', 43), ('?', 33), ('is', 19), ('a', 16), ('music', 14), ('this', 12), ('!', 10), ('with', 10), ('we', 10)] | Training
2025-04-05 00:50:48 | 10200 | LR0.0003 | loss:8.4852 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-62.5306 | logitMax:-46.4449 | windowWeightsW8:0.18681,W15:0.16621,W13:0.16322,W18:0.16211,W3:0.11024,W7:0.10622,W2:0.03847,W21:0.03132,W1:0.01805 | memoryGatesShort:-1.559, Long:0.146, Current:2.413 | topTokens[('.', 94), (',', 32), ('that', 18), ('the', 16), ('is', 13), ('him', 9), ('i', 9), ('have', 9), ('this', 8), ('with', 8)] | Training
2025-04-05 00:58:08 | 10300 | LR0.0003 | loss:9.0316 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.2935 | logitMax:-37.9973 | windowWeightsW8:0.18674,W15:0.16628,W13:0.16326,W18:0.16211,W3:0.11006,W7:0.10644,W2:0.03815,W21:0.03159,W1:0.01803 | memoryGatesShort:-2.059, Long:0.618, Current:2.441 | topTokens[('.', 50), (',', 35), ('?', 20), ('i', 17), ('a', 13), ('to', 12), ('is', 10), ('l', 8), ('with', 8), ('have', 7)] | Training
2025-04-05 01:05:16 | 10400 | LR0.0003 | loss:8.3781 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-55.8397 | logitMax:-36.5530 | windowWeightsW8:0.18678,W15:0.16615,W13:0.16336,W18:0.16233,W3:0.11000,W7:0.10664,W2:0.03785,W21:0.03142,W1:0.01812 | memoryGatesShort:-0.885, Long:0.913, Current:0.972 | topTokens[('.', 59), (',', 36), ('in', 32), ('a', 19), ('look', 17), ('to', 16), ('the', 14), ('do', 12), ('is', 10), ('i', 10)] | Training
2025-04-05 01:12:25 | 10500 | LR0.0003 | loss:9.3305 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-72.1720 | logitMax:-53.2984 | windowWeightsW8:0.18654,W15:0.16630,W13:0.16330,W18:0.16273,W3:0.10959,W7:0.10654,W2:0.03759,W21:0.03201,W1:0.01808 | memoryGatesShort:-0.200, Long:0.544, Current:0.656 | topTokens[('.', 74), ('i', 32), (',', 29), ('to', 23), ('a', 15), ('?', 13), ('like', 10), ('have', 10), ('for', 9), ('we', 8)] | Training
2025-04-05 01:19:11 | 10600 | LR0.0003 | loss:9.1242 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-63.6130 | logitMax:-42.7743 | windowWeightsW8:0.18668,W15:0.16652,W13:0.16345,W18:0.16296,W3:0.10951,W7:0.10656,W2:0.03702,W21:0.03209,W1:0.01788 | memoryGatesShort:3.915, Long:-0.815, Current:-2.099 | topTokens[('.', 57), (',', 34), ('i', 34), ('a', 18), ('my', 15), ('the', 11), ('have', 10), ('m', 7), ('f', 7), ('not', 7)] | Training
2025-04-05 01:25:58 | 10700 | LR0.0003 | loss:9.4212 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-67.7203 | logitMax:-47.0257 | windowWeightsW8:0.18623,W15:0.16663,W13:0.16346,W18:0.16321,W3:0.10920,W7:0.10655,W2:0.03711,W21:0.03292,W1:0.01738 | memoryGatesShort:-6.717, Long:2.756, Current:4.961 | topTokens[('.', 78), (',', 21), ('my', 21), ('a', 20), ('i', 17), ('le', 17), ('to', 12), ('the', 11), ('b', 9), ('for', 8)] | Training
2025-04-05 01:33:26 | 10800 | LR0.0003 | loss:12.5341 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-70.0348 | logitMax:-42.5774 | windowWeightsW8:0.18630,W15:0.16653,W13:0.16355,W18:0.16287,W3:0.10936,W7:0.10684,W2:0.03730,W21:0.03284,W1:0.01711 | memoryGatesShort:2.684, Long:0.397, Current:-2.080 | topTokens[('and', 76), ('.', 46), ('u', 34), (',', 29), ('my', 24), ('playing', 13), ('a', 11), ('she', 8), ('i', 7), ('le', 7)] | Training
2025-04-05 01:40:48 | 10900 | LR0.0003 | loss:10.5922 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-70.1163 | logitMax:-47.3923 | windowWeightsW8:0.18592,W15:0.16671,W13:0.16345,W18:0.16304,W3:0.10918,W7:0.10680,W2:0.03736,W21:0.03322,W1:0.01703 | memoryGatesShort:-3.943, Long:1.859, Current:3.084 | topTokens[('and', 103), ('.', 81), ('u', 47), (',', 21), ('a', 14), ('b', 10), ('look', 9), ('ing', 8), ('were', 7), ('kevin', 7)] | Training
2025-04-05 01:47:31 | 11000 | LR0.0003 | loss:10.7774 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-68.4602 | logitMax:-45.5343 | windowWeightsW8:0.18485,W15:0.16712,W13:0.16360,W18:0.16341,W3:0.10885,W7:0.10673,W2:0.03731,W21:0.03333,W1:0.01749 | memoryGatesShort:-46.194, Long:21.205, Current:25.989 | topTokens[('.', 40), (',', 33), ('t', 26), ('a', 25), ('u', 24), ('and', 15), ('kevin', 13), ('some', 11), ('i', 10), ('like', 10)] | Training
2025-04-05 01:55:40 | 11100 | LR0.0003 | loss:8.8510 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.5698 | logitMax:-52.1382 | windowWeightsW8:0.18452,W15:0.16722,W18:0.16420,W13:0.16374,W3:0.10824,W7:0.10649,W2:0.03700,W21:0.03397,W1:0.01734 | memoryGatesShort:-0.692, Long:0.574, Current:1.119 | topTokens[('.', 65), (',', 21), ('u', 21), ('i', 18), ('and', 16), ('e', 14), ('a', 13), ('t', 10), ('u', 8), ('ed', 7)] | Training
2025-04-05 02:05:08 | 11200 | LR0.0003 | loss:9.4014 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-66.0489 | logitMax:-45.2520 | windowWeightsW8:0.18416,W15:0.16746,W18:0.16454,W13:0.16404,W3:0.10755,W7:0.10625,W2:0.03668,W21:0.03503,W1:0.01702 | memoryGatesShort:7.440, Long:-2.287, Current:-4.153 | topTokens[('on', 107), ('.', 34), (',', 32), ('i', 30), ('a', 24), ('were', 13), ("'t", 7), ('ed', 7), ('o', 7), ('she', 6)] | Training
2025-04-05 02:12:40 | 11300 | LR0.0003 | loss:8.8029 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-70.5752 | logitMax:-50.4048 | windowWeightsW8:0.18363,W15:0.16772,W18:0.16470,W13:0.16407,W3:0.10689,W7:0.10617,W2:0.03650,W21:0.03588,W1:0.01720 | memoryGatesShort:-3.547, Long:3.071, Current:1.476 | topTokens[('.', 37), (',', 33), ('and', 27), ('ed', 26), ('what', 26), ('i', 23), ('a', 15), ('on', 12), ("'t", 9), ('its', 9)] | Training
2025-04-05 02:20:26 | 11400 | LR0.0003 | loss:9.2544 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.3387 | logitMax:-50.5068 | windowWeightsW8:0.18390,W15:0.16786,W18:0.16504,W13:0.16383,W7:0.10665,W3:0.10664,W21:0.03616,W2:0.03578,W1:0.01690 | memoryGatesShort:-8.449, Long:3.452, Current:5.997 | topTokens[('.', 31), (',', 30), ('i', 28), ('its', 16), ('so', 16), ('a', 15), ('the', 14), ("'t", 12), ('am', 9), ('ing', 9)] | Training
2025-04-05 02:28:10 | 11500 | LR0.0003 | loss:5.9265 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-68.1690 | logitMax:-44.5991 | windowWeightsW8:0.18387,W15:0.16735,W18:0.16503,W13:0.16372,W3:0.10751,W7:0.10590,W2:0.03670,W21:0.03609,W1:0.01659 | memoryGatesShort:8.653, Long:-0.327, Current:-7.326 | topTokens[('.', 48), (',', 24), ('l', 19), ('i', 18), ('he', 14), ('a', 13), ('?', 13), ('b', 12), ('music', 12), ('did', 10)] | Training
2025-04-05 02:35:01 | 11600 | LR0.0003 | loss:5.7165 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.4465 | logitMax:-33.0426 | windowWeightsW8:0.18541,W15:0.16635,W18:0.16322,W13:0.16289,W3:0.10971,W7:0.10453,W2:0.03860,W21:0.03552,W1:0.01645 | memoryGatesShort:0.119, Long:-0.714, Current:1.595 | topTokens[('the', 44), ('.', 41), (',', 29), ('?', 22), ('i', 22), ('george', 16), ('is', 14), ('was', 13), ('a', 12), ('at', 12)] | Training
2025-04-05 02:41:41 | 11700 | LR0.0003 | loss:7.2029 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.9207 | logitMax:-36.4359 | windowWeightsW8:0.18631,W15:0.16587,W13:0.16207,W18:0.16077,W3:0.10970,W7:0.10540,W2:0.03955,W21:0.03612,W1:0.01690 | memoryGatesShort:1.091, Long:-0.741, Current:0.650 | topTokens[('.', 34), ('?', 34), ('is', 23), ('she', 22), ('was', 20), (',', 18), ('not', 16), ('me', 14), ('im', 12), ('you', 11)] | Training
2025-04-05 02:52:18 | 11800 | LR0.0003 | loss:6.6917 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.6181 | logitMax:-33.6494 | windowWeightsW8:0.18692,W15:0.16390,W13:0.16063,W18:0.16034,W3:0.11047,W7:0.10641,W2:0.03972,W21:0.03542,W1:0.01885 | memoryGatesShort:1.124, Long:-1.785, Current:1.661 | topTokens[('the', 63), ('.', 36), ('?', 30), ('me', 25), (',', 15), ('dj', 13), ('im', 11), ('play', 9), ('she', 8), ('a', 8)] | Training
2025-04-05 02:59:20 | 11900 | LR0.0003 | loss:8.8367 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.2555 | logitMax:-26.0308 | windowWeightsW8:0.18686,W15:0.16327,W13:0.16059,W18:0.15985,W3:0.11034,W7:0.10644,W2:0.03987,W21:0.03554,W1:0.01988 | memoryGatesShort:1.222, Long:-2.343, Current:2.120 | topTokens[('.', 33), ('?', 26), ('me', 26), ('the', 24), (',', 23), ('a', 15), ('is', 15), ('she', 13), ('music', 11), ('0', 9)] | Training
2025-04-05 03:06:58 | 12000 | LR0.0003 | loss:7.7017 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-63.2582 | logitMax:-39.1750 | windowWeightsW8:0.18700,W15:0.16317,W13:0.16033,W18:0.15982,W3:0.11023,W7:0.10647,W2:0.03998,W21:0.03571,W1:0.01994 | memoryGatesShort:1.131, Long:-0.886, Current:0.755 | topTokens[('.', 44), ('?', 32), ('what', 18), (',', 17), ('the', 15), ('a', 14), ('you', 13), ('they', 11), ('dj', 11), ('im', 10)] | Training
2025-04-05 03:14:45 | 12100 | LR0.0003 | loss:8.7156 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.7065 | logitMax:-27.8165 | windowWeightsW8:0.18691,W15:0.16300,W13:0.16001,W18:0.15960,W3:0.11020,W7:0.10635,W2:0.04057,W21:0.03588,W1:0.02012 | memoryGatesShort:0.970, Long:-2.219, Current:2.249 | topTokens[(',', 37), ('?', 32), ('is', 26), ('s', 19), ('about', 17), ('.', 17), ('a', 12), ('im', 12), ('me', 11), ('not', 10)] | Training
2025-04-05 03:22:13 | 12200 | LR0.0003 | loss:4.3324 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-62.3971 | logitMax:-41.2549 | windowWeightsW8:0.18586,W15:0.16303,W13:0.16015,W18:0.15991,W3:0.11037,W7:0.10561,W2:0.04123,W21:0.03539,W1:0.02107 | memoryGatesShort:3.269, Long:-4.889, Current:2.620 | topTokens[('.', 59), ('her', 43), ('?', 22), ('what', 22), ('to', 17), ('a', 13), ('is', 13), ('i', 13), (',', 12), ('not', 11)] | Training
2025-04-05 03:29:23 | 12300 | LR0.0003 | loss:8.4140 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.5720 | logitMax:-27.2742 | windowWeightsW8:0.18600,W15:0.16269,W18:0.15991,W13:0.15991,W3:0.11081,W7:0.10585,W2:0.04099,W21:0.03589,W1:0.02058 | memoryGatesShort:3.572, Long:-26.105, Current:23.533 | topTokens[('.', 38), ('to', 34), ('you', 24), (',', 21), ('she', 18), ('look', 17), ('up', 14), ('are', 13), ('?', 13), ('stream', 11)] | Training
2025-04-05 03:36:38 | 12400 | LR0.0003 | loss:5.9599 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.9493 | logitMax:-34.4297 | windowWeightsW8:0.18593,W15:0.16251,W18:0.16024,W13:0.15929,W3:0.10973,W7:0.10574,W2:0.04162,W21:0.03659,W1:0.02099 | memoryGatesShort:2.277, Long:-2.834, Current:1.558 | topTokens[('.', 55), ('?', 30), (',', 24), ('what', 17), ('are', 15), ('to', 14), ('you', 10), ('sleep', 10), ('listening', 9), ('a', 8)] | Training
2025-04-05 03:43:43 | 12500 | LR0.0003 | loss:6.3612 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.2622 | logitMax:-33.7140 | windowWeightsW8:0.18802,W15:0.16184,W18:0.16032,W13:0.15912,W3:0.11012,W7:0.10617,W2:0.04127,W21:0.03649,W1:0.01930 | memoryGatesShort:3.596, Long:-4.912, Current:2.315 | topTokens[('.', 45), ('coming', 43), ('twice', 29), ('she', 15), ('a', 15), ('please', 15), ('were', 13), (',', 13), ('looking', 11), ('to', 11)] | Training
2025-04-05 03:50:52 | 12600 | LR0.0003 | loss:5.6620 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.1162 | logitMax:-31.7523 | windowWeightsW8:0.18790,W15:0.16237,W18:0.16038,W13:0.15998,W3:0.10998,W7:0.10549,W2:0.04086,W21:0.03638,W1:0.01929 | memoryGatesShort:3.967, Long:-3.803, Current:0.836 | topTokens[('.', 63), ('to', 31), ('coming', 16), (',', 16), ('?', 15), ('who', 13), ('twice', 13), ('i', 13), ('she', 12), ('they', 11)] | Training
2025-04-05 03:57:43 | 12700 | LR0.0003 | loss:7.9346 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.6037 | logitMax:-28.0277 | windowWeightsW8:0.18901,W15:0.16202,W13:0.15992,W18:0.15952,W3:0.10995,W7:0.10583,W2:0.04014,W21:0.03712,W1:0.01913 | memoryGatesShort:3.396, Long:-3.344, Current:0.948 | topTokens[('.', 51), ('to', 42), (',', 19), ('twice', 18), ('you', 15), ('want', 13), ('she', 10), ('?', 10), ('a', 10), ('were', 9)] | Training
2025-04-05 04:04:41 | 12800 | LR0.0003 | loss:10.4483 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.2806 | logitMax:-34.7001 | windowWeightsW8:0.18912,W15:0.16235,W13:0.16002,W18:0.15982,W3:0.10961,W7:0.10617,W2:0.03998,W21:0.03712,W1:0.01848 | memoryGatesShort:1.928, Long:-1.342, Current:0.414 | topTokens[('coming', 43), ('.', 43), ('twice', 36), (',', 25), ('she', 16), ('a', 14), ('hi', 12), ('er', 12), ('were', 9), ('some', 8)] | Training
2025-04-05 04:11:35 | 12900 | LR0.0003 | loss:8.1287 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.4537 | logitMax:-35.7169 | windowWeightsW8:0.18890,W15:0.16267,W13:0.16016,W18:0.16015,W3:0.10942,W7:0.10642,W2:0.03967,W21:0.03737,W1:0.01792 | memoryGatesShort:1.373, Long:-0.981, Current:0.608 | topTokens[('.', 48), (',', 26), ('a', 18), ('she', 14), ('er', 13), ('to', 11), ('had', 11), ('stream', 11), ('b', 10), ('twice', 10)] | Training
2025-04-05 04:18:08 | 13000 | LR0.0003 | loss:9.2721 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-68.3832 | logitMax:-47.0234 | windowWeightsW8:0.18838,W15:0.16330,W13:0.16078,W18:0.16070,W3:0.10844,W7:0.10642,W2:0.03929,W21:0.03832,W1:0.01707 | memoryGatesShort:7.779, Long:-10.293, Current:3.514 | topTokens[('.', 50), (',', 31), ('ch', 24), ('the', 24), ('she', 20), ('to', 17), ('be', 16), ('this', 16), ('and', 11), ('ro', 11)] | Training
2025-04-05 04:24:13 | 13100 | LR0.0003 | loss:10.9234 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-55.7488 | logitMax:-32.6069 | windowWeightsW8:0.18833,W15:0.16316,W13:0.16075,W18:0.16073,W3:0.10841,W7:0.10663,W2:0.03927,W21:0.03858,W1:0.01685 | memoryGatesShort:1.862, Long:-0.955, Current:0.094 | topTokens[('.', 41), ('to', 33), ('this', 29), (',', 22), ('she', 18), ('the', 14), ('ch', 14), ("'m", 14), ('be', 13), ('a', 11)] | Training
2025-04-05 04:30:07 | 13200 | LR0.0003 | loss:8.8377 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-64.0695 | logitMax:-43.7088 | windowWeightsW8:0.18812,W15:0.16327,W18:0.16098,W13:0.16089,W3:0.10826,W7:0.10643,W2:0.03926,W21:0.03886,W1:0.01666 | memoryGatesShort:-0.455, Long:2.420, Current:-0.965 | topTokens[('to', 55), ('at', 26), ('.', 25), (',', 25), ('l', 15), ('was', 14), ('she', 12), ('be', 12), ('the', 10), ('a', 9)] | Training
2025-04-05 04:36:54 | 13300 | LR0.0003 | loss:8.6652 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-62.9304 | logitMax:-45.2493 | windowWeightsW8:0.18803,W15:0.16339,W18:0.16115,W13:0.16100,W3:0.10806,W7:0.10651,W21:0.03906,W2:0.03905,W1:0.01648 | memoryGatesShort:0.828, Long:-0.019, Current:0.191 | topTokens[('.', 49), (',', 33), ('to', 31), ('this', 18), ('ad', 16), ('the', 13), ('a', 13), ('be', 11), ('l', 9), ('ch', 8)] | Training
2025-04-05 04:42:52 | 13400 | LR0.0003 | loss:8.4818 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.1105 | logitMax:-47.6376 | windowWeightsW8:0.18829,W15:0.16374,W18:0.16131,W13:0.16106,W3:0.10787,W7:0.10637,W2:0.03894,W21:0.03878,W1:0.01636 | memoryGatesShort:2.656, Long:-6.659, Current:5.003 | topTokens[('.', 43), (',', 38), ('to', 34), ('of', 24), ('a', 22), ('and', 13), ('this', 13), ('ad', 12), ('ion', 12), ('b', 10)] | Training
2025-04-05 04:49:00 | 13500 | LR0.0003 | loss:8.1462 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-61.7741 | logitMax:-43.1310 | windowWeightsW8:0.18751,W15:0.16440,W18:0.16196,W13:0.16133,W3:0.10776,W7:0.10575,W21:0.03943,W2:0.03862,W1:0.01599 | memoryGatesShort:-8.064, Long:-13.254, Current:22.318 | topTokens[('.', 58), ('of', 32), ('to', 27), (',', 24), ('a', 21), ('and', 19), ('this', 15), ('i', 11), ('she', 8), ('?', 7)] | Training
2025-04-05 04:55:07 | 13600 | LR0.0003 | loss:7.6972 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-64.1742 | logitMax:-50.2435 | windowWeightsW8:0.18753,W15:0.16471,W18:0.16243,W13:0.16144,W3:0.10745,W7:0.10593,W21:0.03954,W2:0.03841,W1:0.01532 | memoryGatesShort:0.139, Long:-0.085, Current:0.946 | topTokens[('.', 42), ('i', 37), ('a', 28), (',', 22), ('it', 22), ('to', 16), ('the', 15), ('b', 13), ('with', 13), ('be', 11)] | Training
2025-04-05 05:01:21 | 13700 | LR0.0003 | loss:9.0037 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.5125 | logitMax:-45.4462 | windowWeightsW8:0.18714,W15:0.16439,W18:0.16209,W13:0.16156,W3:0.10725,W7:0.10611,W21:0.04092,W2:0.03796,W1:0.01536 | memoryGatesShort:-0.428, Long:-0.501, Current:1.929 | topTokens[('.', 51), ('to', 31), (',', 29), ('i', 23), ('a', 22), ('es', 21), ('s', 15), ('be', 11), ('it', 9), ("'t", 8)] | Training
2025-04-05 05:07:33 | 13800 | LR0.0003 | loss:9.3715 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.9838 | logitMax:-42.6932 | windowWeightsW8:0.18690,W15:0.16472,W18:0.16238,W13:0.16197,W3:0.10674,W7:0.10563,W21:0.04150,W2:0.03795,W1:0.01499 | memoryGatesShort:0.616, Long:0.376, Current:0.008 | topTokens[(',', 33), ('ic', 31), ('.', 26), ('the', 26), ('to', 19), ('i', 18), ('a', 18), ('she', 13), ('s', 13), ('(', 11)] | Training
2025-04-05 05:13:43 | 13900 | LR0.0003 | loss:8.7264 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-61.6305 | logitMax:-40.6573 | windowWeightsW8:0.18705,W15:0.16453,W18:0.16247,W13:0.16131,W3:0.10626,W7:0.10618,W21:0.04184,W2:0.03795,W1:0.01520 | memoryGatesShort:-0.366, Long:-0.200, Current:1.566 | topTokens[('.', 43), ('r', 28), ('ic', 26), (',', 23), ('to', 22), ('i', 21), ('a', 16), ('had', 14), ('the', 10), ('she', 9)] | Training
2025-04-05 05:19:48 | 14000 | LR0.0003 | loss:9.5199 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-64.1975 | logitMax:-44.7205 | windowWeightsW8:0.18666,W15:0.16490,W18:0.16276,W13:0.16133,W7:0.10676,W3:0.10591,W21:0.04202,W2:0.03769,W1:0.01479 | memoryGatesShort:-5.835, Long:1.978, Current:4.857 | topTokens[('.', 36), (',', 26), ('ck', 23), ('o', 22), ('it', 19), ('a', 14), ('she', 14), ('i', 13), ('st', 13), ('m', 10)] | Training
2025-04-05 05:25:52 | 14100 | LR0.0003 | loss:8.0176 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-64.7255 | logitMax:-47.8177 | windowWeightsW8:0.18675,W15:0.16485,W18:0.16281,W13:0.16139,W7:0.10678,W3:0.10579,W21:0.04211,W2:0.03760,W1:0.01473 | memoryGatesShort:-0.594, Long:0.554, Current:1.040 | topTokens[(',', 33), ('.', 31), ('a', 23), ('d', 22), ('or', 21), ('it', 18), ('o', 17), ('s', 12), ('i', 12), ('am', 11)] | Training
2025-04-05 05:32:16 | 14200 | LR0.0003 | loss:9.4972 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-81.1448 | logitMax:-59.4310 | windowWeightsW8:0.18647,W15:0.16512,W18:0.16314,W13:0.16169,W7:0.10603,W3:0.10551,W21:0.04275,W2:0.03758,W1:0.01453 | memoryGatesShort:-0.222, Long:0.131, Current:1.091 | topTokens[(',', 42), ('.', 28), ('or', 21), ('a', 20), ('it', 19), ('b', 16), ('o', 13), ('to', 12), ('i', 10), ('ck', 9)] | Training
2025-04-05 05:58:52 | 14300 | LR0.0003 | loss:5.9852 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-67.8533 | logitMax:-34.7879 | windowWeightsW8:0.18623,W15:0.16421,W18:0.16164,W13:0.16051,W3:0.10882,W7:0.10473,W21:0.04206,W2:0.03969,W1:0.01488 | memoryGatesShort:-1.919, Long:-1.012, Current:3.931 | topTokens[('.', 36), ('an', 32), ('to', 30), ('listening', 28), ('i', 18), (',', 18), ('?', 14), ('be', 13), ('was', 12), ('will', 11)] | Training
2025-04-05 06:17:42 | 14400 | LR0.0003 | loss:6.4790 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.8468 | logitMax:-26.7696 | windowWeightsW8:0.18617,W15:0.16314,W13:0.16130,W18:0.15874,W3:0.11087,W7:0.10544,W21:0.04116,W2:0.04059,W1:0.01531 | memoryGatesShort:3.600, Long:4.673, Current:-7.272 | topTokens[('.', 45), ('an', 37), ('to', 22), ('listening', 21), ('music', 21), ('will', 18), ('?', 17), ('been', 12), ('be', 12), ('i', 11)] | Training
2025-04-05 06:23:42 | 14500 | LR0.0003 | loss:7.1839 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-63.3259 | logitMax:-37.3314 | windowWeightsW8:0.18438,W15:0.16336,W13:0.16119,W18:0.16021,W3:0.10980,W7:0.10409,W21:0.04219,W2:0.04106,W1:0.01646 | memoryGatesShort:-2.590, Long:-3.101, Current:6.692 | topTokens[(',', 39), ('.', 36), ('?', 23), ('will', 23), ('a', 18), ('10', 15), ('an', 14), ('with', 11), ('not', 11), ('=', 11)] | Training
2025-04-05 06:29:46 | 14600 | LR0.0003 | loss:4.2647 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.7873 | logitMax:-35.1343 | windowWeightsW8:0.18631,W15:0.16148,W13:0.16088,W18:0.15960,W3:0.11041,W7:0.10392,W21:0.04097,W2:0.04088,W1:0.01824 | memoryGatesShort:-0.786, Long:-1.027, Current:2.813 | topTokens[(',', 45), ('.', 26), ('2', 24), ('listening', 22), ('music', 21), ('=', 21), ('+', 18), ('a', 17), ('to', 14), ('will', 13)] | Training
2025-04-05 06:35:55 | 14700 | LR0.0003 | loss:6.9265 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.6821 | logitMax:-26.1402 | windowWeightsW8:0.18584,W15:0.16108,W13:0.16010,W18:0.15911,W3:0.11015,W7:0.10418,W21:0.04200,W2:0.04177,W1:0.01845 | memoryGatesShort:-0.427, Long:-0.614, Current:2.042 | topTokens[('to', 31), ('.', 29), ('a', 27), (',', 21), ('music', 17), ('?', 15), ('playing', 13), ('an', 11), ('i', 11), ('will', 11)] | Training
2025-04-05 06:42:20 | 14800 | LR0.0003 | loss:5.2670 | gradNorm:0.9837 | tokenCount:400.0000 | logitMin:-64.1082 | logitMax:-14.5861 | windowWeightsW8:0.18578,W13:0.15892,W15:0.15882,W18:0.15768,W3:0.11307,W7:0.10509,W2:0.04368,W21:0.04083,W1:0.01874 | memoryGatesShort:0.770, Long:2.078, Current:-1.848 | topTokens[('to', 40), ('listening', 24), ('.', 23), ('should', 22), ('?', 18), ('what', 15), ('been', 15), ('music', 14), ('kind', 13), ('was', 12)] | Training
2025-04-05 06:48:34 | 14900 | LR0.0003 | loss:11.3458 | gradNorm:0.9415 | tokenCount:400.0000 | logitMin:-70.6788 | logitMax:4.5852 | windowWeightsW8:0.18566,W13:0.15853,W15:0.15697,W18:0.15596,W3:0.11494,W7:0.10604,W2:0.04499,W21:0.04013,W1:0.01927 | memoryGatesShort:-0.454, Long:-1.794, Current:3.248 | topTokens[('a', 77), ('he', 29), ('been', 23), ('.', 22), ('play', 16), ('what', 13), ('music', 11), ('has', 11), ('ic', 10), ('to', 10)] | Training
2025-04-05 06:55:11 | 15000 | LR0.0003 | loss:8.3181 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.9353 | logitMax:-19.8172 | windowWeightsW8:0.18510,W13:0.15949,W15:0.15778,W18:0.15671,W3:0.11315,W7:0.10608,W2:0.04396,W21:0.04200,W1:0.01835 | memoryGatesShort:1.929, Long:-4.596, Current:3.667 | topTokens[('.', 44), ('music', 38), ('a', 19), ('?', 17), ('to', 14), ('computer', 14), ('been', 14), ('with', 13), ('listening', 12), ('games', 12)] | Training
2025-04-05 07:01:48 | 15100 | LR0.0003 | loss:7.2053 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-43.6312 | logitMax:-15.0829 | windowWeightsW8:0.18507,W13:0.15940,W15:0.15848,W18:0.15688,W3:0.11316,W7:0.10569,W2:0.04375,W21:0.04238,W1:0.01782 | memoryGatesShort:1.232, Long:-0.048, Current:-0.184 | topTokens[('.', 39), ('been', 27), ('to', 25), ('listening', 24), (',', 19), ('a', 15), ('she', 14), ('music', 14), ('has', 14), ('play', 13)] | Training
2025-04-05 07:08:15 | 15200 | LR0.0003 | loss:7.9506 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.4827 | logitMax:-32.1988 | windowWeightsW8:0.18419,W15:0.15918,W13:0.15896,W18:0.15689,W3:0.11308,W7:0.10589,W2:0.04406,W21:0.04284,W1:0.01757 | memoryGatesShort:3.606, Long:0.164, Current:-2.770 | topTokens[('.', 59), ('i', 24), (',', 16), ('a', 15), ('are', 13), ('you', 13), ('been', 12), ('were', 12), ('has', 12), ('what', 11)] | Training
2025-04-05 07:14:37 | 15300 | LR0.0003 | loss:10.3134 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-46.4020 | logitMax:-6.8505 | windowWeightsW8:0.18503,W13:0.15868,W15:0.15867,W18:0.15679,W3:0.11294,W7:0.10620,W2:0.04426,W21:0.04278,W1:0.01731 | memoryGatesShort:0.245, Long:-0.601, Current:1.356 | topTokens[('.', 59), ('she', 37), ('a', 29), ('listening', 18), ('to', 18), ('music', 17), ('been', 15), ('a', 15), (',', 12), ('has', 11)] | Training
2025-04-05 07:20:57 | 15400 | LR0.0003 | loss:6.1430 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.2292 | logitMax:-32.1849 | windowWeightsW8:0.18460,W15:0.15888,W13:0.15853,W18:0.15695,W3:0.11281,W7:0.10519,W21:0.04428,W2:0.04416,W1:0.01726 | memoryGatesShort:0.200, Long:0.396, Current:0.404 | topTokens[('.', 83), ('st', 28), ('to', 24), (',', 21), ('people', 16), ('you', 13), ('she', 13), ('music', 13), ('has', 12), ('?', 11)] | Training
2025-04-05 07:27:19 | 15500 | LR0.0003 | loss:12.8703 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.9060 | logitMax:-23.7677 | windowWeightsW8:0.18390,W15:0.15956,W13:0.15886,W18:0.15731,W3:0.11252,W7:0.10473,W21:0.04529,W2:0.04346,W1:0.01706 | memoryGatesShort:0.794, Long:-0.649, Current:0.855 | topTokens[('hung', 51), ('.', 33), ('ry', 29), ('listening', 22), ('people', 18), ('to', 15), ('were', 15), ('she', 14), ('music', 13), ('?', 10)] | Training
2025-04-05 07:33:38 | 15600 | LR0.0003 | loss:10.1463 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.0321 | logitMax:-33.6211 | windowWeightsW8:0.18369,W15:0.15973,W13:0.15895,W18:0.15751,W3:0.11236,W7:0.10467,W21:0.04553,W2:0.04335,W1:0.01693 | memoryGatesShort:-1.602, Long:0.477, Current:2.125 | topTokens[('hung', 52), ('.', 51), (',', 31), ('ry', 19), ('this', 14), ('a', 10), ('she', 9), ('i', 8), ('you', 8), ('to', 8)] | Training
2025-04-05 07:40:00 | 15700 | LR0.0003 | loss:8.1798 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-61.9587 | logitMax:-46.3468 | windowWeightsW8:0.18355,W15:0.15993,W13:0.15915,W18:0.15762,W3:0.11232,W7:0.10451,W21:0.04557,W2:0.04322,W1:0.01685 | memoryGatesShort:-1.569, Long:1.353, Current:1.215 | topTokens[('to', 29), (',', 28), ('you', 22), ('.', 19), ('hung', 18), ('ry', 16), ('s', 16), ('a', 12), ('too', 9), ('it', 9)] | Training
2025-04-05 07:46:29 | 15800 | LR0.0003 | loss:8.7241 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.7427 | logitMax:-41.2502 | windowWeightsW8:0.18333,W15:0.16015,W13:0.15935,W18:0.15777,W3:0.11216,W7:0.10451,W21:0.04560,W2:0.04311,W1:0.01677 | memoryGatesShort:-9.331, Long:4.353, Current:5.978 | topTokens[('.', 28), ('like', 27), ('to', 26), (',', 20), ('ry', 19), ('a', 17), ('she', 16), ('hung', 11), ('s', 10), ('i', 10)] | Training
2025-04-05 07:52:55 | 15900 | LR0.0003 | loss:9.3372 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-61.2010 | logitMax:-43.3989 | windowWeightsW8:0.18332,W15:0.16032,W13:0.15952,W18:0.15778,W3:0.11198,W7:0.10446,W21:0.04569,W2:0.04303,W1:0.01664 | memoryGatesShort:-0.866, Long:1.806, Current:0.061 | topTokens[(',', 42), ('b', 39), ('.', 26), ('a', 25), ('to', 17), ('i', 16), ('ly', 16), ('she', 15), ('s', 13), ('ry', 9)] | Training
2025-04-05 07:59:28 | 16000 | LR0.0003 | loss:9.0257 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-68.5638 | logitMax:-49.1952 | windowWeightsW8:0.18318,W15:0.16059,W13:0.15984,W18:0.15776,W3:0.11166,W7:0.10435,W21:0.04635,W2:0.04275,W1:0.01629 | memoryGatesShort:-10.972, Long:1.697, Current:10.275 | topTokens[('or', 67), ('.', 31), (',', 20), ('i', 18), ('to', 17), ("'", 12), ('a', 10), ('the', 9), ('and', 9), ('she', 9)] | Training
2025-04-05 08:05:54 | 16100 | LR0.0003 | loss:11.4693 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-63.5755 | logitMax:-40.3491 | windowWeightsW8:0.18316,W15:0.16066,W13:0.15983,W18:0.15769,W3:0.11164,W7:0.10460,W21:0.04624,W2:0.04271,W1:0.01624 | memoryGatesShort:4.069, Long:-1.379, Current:-1.690 | topTokens[('or', 43), ('the', 42), ('.', 30), ('she', 29), ('listening', 22), (',', 17), ('a', 17), ('ic', 13), ('ed', 9), ('ly', 8)] | Training
2025-04-05 08:12:45 | 16200 | LR0.0003 | loss:10.6913 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-61.9572 | logitMax:-41.6252 | windowWeightsW8:0.18290,W15:0.16090,W13:0.15990,W18:0.15783,W3:0.11142,W7:0.10452,W21:0.04679,W2:0.04257,W1:0.01597 | memoryGatesShort:611.090, Long:-596.967, Current:-13.120 | topTokens[(',', 35), ('.', 31), ('to', 29), ('ry', 24), ('listening', 22), ('i', 18), ('were', 16), ('be', 10), ('a', 10), ('l', 9)] | Training
2025-04-05 08:19:21 | 16300 | LR0.0003 | loss:7.1885 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-55.6589 | logitMax:-42.3980 | windowWeightsW8:0.18278,W15:0.16087,W13:0.15992,W18:0.15807,W3:0.11131,W7:0.10481,W21:0.04673,W2:0.04250,W1:0.01582 | memoryGatesShort:-2.341, Long:2.693, Current:0.648 | topTokens[('.', 27), ('the', 26), (',', 17), ('to', 16), ('and', 15), ('i', 12), ("'", 12), ('ing', 12), ('had', 11), ('a', 11)] | Training
2025-04-05 08:25:39 | 16400 | LR0.0003 | loss:8.6090 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.5214 | logitMax:-45.1051 | windowWeightsW8:0.18291,W15:0.16073,W13:0.15992,W18:0.15795,W3:0.11127,W7:0.10488,W21:0.04699,W2:0.04246,W1:0.01571 | memoryGatesShort:-1.192, Long:2.703, Current:-0.510 | topTokens[(',', 33), ('.', 29), ('i', 26), ('and', 25), ('a', 21), ("'t", 17), ('in', 15), ("'", 11), ('n', 9), ('my', 8)] | Training
2025-04-05 08:32:01 | 16500 | LR0.0003 | loss:9.3251 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.8102 | logitMax:-41.1662 | windowWeightsW8:0.18300,W15:0.16042,W13:0.15987,W18:0.15775,W3:0.11128,W7:0.10560,W21:0.04698,W2:0.04250,W1:0.01541 | memoryGatesShort:-2.436, Long:2.263, Current:1.173 | topTokens[('s', 44), ('.', 42), ('she', 24), ('it', 22), (',', 19), ('i', 13), ('a', 13), ('to', 10), ("'t", 10), ('just', 9)] | Training
2025-04-05 08:38:38 | 16600 | LR0.0003 | loss:8.4119 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-61.9072 | logitMax:-44.3207 | windowWeightsW8:0.18270,W15:0.16033,W13:0.15996,W18:0.15776,W3:0.11120,W7:0.10562,W21:0.04735,W2:0.04245,W1:0.01546 | memoryGatesShort:-13.030, Long:9.236, Current:4.794 | topTokens[('.', 55), ('it', 25), (',', 21), ('the', 18), ('s', 17), ('a', 17), ('and', 16), ('she', 15), ('not', 12), ('y', 10)] | Training
2025-04-05 08:45:10 | 16700 | LR0.0003 | loss:8.2640 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-62.1940 | logitMax:-45.3449 | windowWeightsW8:0.18239,W15:0.16066,W13:0.16002,W18:0.15795,W3:0.11090,W7:0.10562,W21:0.04775,W2:0.04237,W1:0.01517 | memoryGatesShort:8.243, Long:-6.099, Current:-1.144 | topTokens[('of', 43), ('.', 41), (',', 26), ('to', 25), ('the', 23), ('a', 18), ('i', 15), ('and', 12), ('ing', 10), ('were', 9)] | Training
2025-04-05 08:51:37 | 16800 | LR0.0003 | loss:8.9970 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-70.4977 | logitMax:-52.3716 | windowWeightsW8:0.18202,W15:0.16083,W13:0.16032,W18:0.15837,W3:0.11064,W7:0.10565,W21:0.04806,W2:0.04218,W1:0.01480 | memoryGatesShort:-21.567, Long:16.564, Current:6.003 | topTokens[('.', 48), ('this', 29), (',', 27), ('that', 16), ('of', 14), ('a', 13), ('ent', 13), ('the', 12), ("'t", 11), ('and', 9)] | Training
2025-04-05 08:58:07 | 16900 | LR0.0003 | loss:9.3998 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-61.0712 | logitMax:-41.9537 | windowWeightsW8:0.18188,W15:0.16091,W13:0.16026,W18:0.15851,W3:0.11065,W7:0.10571,W21:0.04795,W2:0.04219,W1:0.01481 | memoryGatesShort:3.314, Long:-1.507, Current:-0.807 | topTokens[('.', 44), (',', 18), ('the', 18), ('and', 18), ('it', 18), ('she', 17), ('i', 12), ('this', 11), ("'t", 10), ('that', 9)] | Training
2025-04-05 09:04:25 | 17000 | LR0.0003 | loss:6.5432 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-49.4140 | logitMax:-25.7790 | windowWeightsW8:0.18144,W15:0.16075,W13:0.16069,W18:0.15801,W3:0.11073,W7:0.10616,W21:0.04794,W2:0.04260,W1:0.01454 | memoryGatesShort:-2.760, Long:0.589, Current:3.171 | topTokens[('.', 37), ('you', 26), ('i', 23), ('listening', 18), ('she', 18), ('a', 16), ('to', 14), ('is', 12), ('will', 11), (',', 10)] | Training
2025-04-05 09:10:54 | 17100 | LR0.0003 | loss:5.5343 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.7068 | logitMax:-30.0077 | windowWeightsW8:0.18197,W15:0.16021,W13:0.16019,W18:0.15694,W3:0.11061,W7:0.10756,W21:0.04787,W2:0.04305,W1:0.01447 | memoryGatesShort:-2.203, Long:0.861, Current:2.342 | topTokens[('.', 52), ('she', 26), ('?', 24), ('is', 22), ('you', 21), ('a', 17), ('i', 16), ('are', 13), ('elodie', 11), ('to', 10)] | Training
2025-04-05 09:17:14 | 17200 | LR0.0003 | loss:6.1190 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-58.7237 | logitMax:-34.0899 | windowWeightsW8:0.18050,W15:0.15974,W13:0.15965,W18:0.15635,W3:0.11054,W7:0.10634,W21:0.04790,W2:0.04463,W1:0.01714 | memoryGatesShort:-1.002, Long:0.353, Current:1.649 | topTokens[('.', 53), ('not', 41), ('?', 35), ('is', 21), ('i', 15), (',', 13), ('you', 13), ('do', 11), ('to', 11), ('a', 11)] | Training
2025-04-05 09:23:26 | 17300 | LR0.0003 | loss:6.4528 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-61.0583 | logitMax:-39.9695 | windowWeightsW8:0.18028,W13:0.16013,W15:0.15952,W18:0.15621,W3:0.11046,W7:0.10635,W21:0.04767,W2:0.04491,W1:0.01726 | memoryGatesShort:-2.330, Long:0.129, Current:3.202 | topTokens[('not', 62), ('.', 39), ('?', 34), ('i', 25), (',', 22), ('is', 16), ('are', 14), ('a', 12), ('you', 9), ('some', 8)] | Training
2025-04-05 09:29:40 | 17400 | LR0.0003 | loss:7.0567 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-69.1148 | logitMax:-45.5706 | windowWeightsW8:0.18026,W13:0.16005,W15:0.15979,W18:0.15677,W3:0.10980,W7:0.10635,W21:0.04810,W2:0.04465,W1:0.01703 | memoryGatesShort:1.185, Long:0.409, Current:-0.594 | topTokens[('not', 51), ('.', 47), ('?', 34), ('you', 24), (',', 20), ('are', 17), ('she', 13), ('is', 11), ('n', 9), ('what', 9)] | Training
2025-04-05 09:35:54 | 17500 | LR0.0003 | loss:6.6077 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-73.2465 | logitMax:-46.9902 | windowWeightsW8:0.18068,W13:0.15979,W15:0.15923,W18:0.15662,W3:0.10933,W7:0.10653,W21:0.04845,W2:0.04449,W1:0.01768 | memoryGatesShort:10.559, Long:9.257, Current:-18.816 | topTokens[('.', 42), ('?', 32), ('is', 26), ('she', 25), (',', 19), ('with', 17), ('my', 17), ('a', 15), ('he', 10), ('you', 10)] | Training
2025-04-05 09:42:09 | 17600 | LR0.0003 | loss:6.7035 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-64.3278 | logitMax:-40.2040 | windowWeightsW8:0.18024,W13:0.15961,W15:0.15958,W18:0.15730,W3:0.10886,W7:0.10651,W21:0.04865,W2:0.04440,W1:0.01768 | memoryGatesShort:0.387, Long:0.832, Current:-0.219 | topTokens[('.', 37), ('i', 23), ('a', 22), ('you', 22), ('is', 21), ('she', 20), ('?', 20), (',', 19), ('kevin', 17), ('like', 13)] | Training
2025-04-05 09:48:25 | 17700 | LR0.0003 | loss:5.8435 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-68.2992 | logitMax:-45.5318 | windowWeightsW8:0.18046,W13:0.16007,W15:0.15932,W18:0.15709,W3:0.10892,W7:0.10654,W21:0.04855,W2:0.04437,W1:0.01750 | memoryGatesShort:0.784, Long:-2.914, Current:3.130 | topTokens[('.', 37), ('a', 25), ('pete', 23), ('?', 23), ('i', 20), ('she', 18), ('you', 18), ('like', 12), ('do', 12), ('is', 12)] | Training
2025-04-05 09:54:41 | 17800 | LR0.0003 | loss:6.0225 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.4287 | logitMax:-39.0192 | windowWeightsW8:0.18045,W13:0.15952,W15:0.15822,W18:0.15737,W3:0.10889,W7:0.10718,W21:0.04959,W2:0.04432,W1:0.01728 | memoryGatesShort:1.712, Long:4.036, Current:-4.748 | topTokens[('.', 38), ('to', 24), ('?', 23), ('is', 22), (',', 19), ('a', 18), ('do', 16), ('e', 13), ('i', 12), ('you', 12)] | Training
2025-04-05 10:00:54 | 17900 | LR0.0003 | loss:8.0247 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.7711 | logitMax:-43.5906 | windowWeightsW8:0.18042,W13:0.15926,W15:0.15803,W18:0.15654,W3:0.10864,W7:0.10758,W21:0.05059,W2:0.04382,W1:0.01794 | memoryGatesShort:-1.184, Long:-3.403, Current:5.588 | topTokens[('.', 56), ('?', 29), ('a', 24), ('is', 22), ('ty', 21), ('listening', 20), (',', 18), ('do', 17), ('not', 15), ('you', 14)] | Training
2025-04-05 10:07:10 | 18000 | LR0.0003 | loss:8.4698 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-64.7068 | logitMax:-34.7843 | windowWeightsW8:0.18038,W13:0.15895,W15:0.15707,W18:0.15634,W3:0.10855,W7:0.10806,W21:0.05144,W2:0.04345,W1:0.01857 | memoryGatesShort:-0.575, Long:-5.313, Current:6.888 | topTokens[('.', 37), ('is', 36), ('?', 35), ('you', 29), ('!', 28), ('much', 17), (',', 16), ('has', 15), ('not', 13), ('ty', 12)] | Training
2025-04-05 10:13:24 | 18100 | LR0.0003 | loss:6.7835 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.8890 | logitMax:-35.8160 | windowWeightsW8:0.18057,W13:0.15948,W15:0.15716,W18:0.15623,W7:0.10825,W3:0.10813,W21:0.05125,W2:0.04349,W1:0.01826 | memoryGatesShort:-4.783, Long:-21.472, Current:27.256 | topTokens[('is', 51), ('.', 43), ('a', 24), ('kevin', 22), ('?', 20), (',', 16), ('!', 15), ('not', 14), ('much', 14), ('to', 14)] | Training
2025-04-05 10:19:42 | 18200 | LR0.0003 | loss:8.4489 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-55.6247 | logitMax:-29.8207 | windowWeightsW8:0.18165,W13:0.15891,W15:0.15675,W18:0.15576,W7:0.10866,W3:0.10812,W21:0.05108,W2:0.04383,W1:0.01804 | memoryGatesShort:-1.524, Long:-6.619, Current:9.143 | topTokens[('her', 47), ('listening', 34), ('.', 26), ('?', 19), ('you', 18), ('!', 17), ('not', 14), ('kevin', 12), ('a', 12), ('do', 11)] | Training
2025-04-05 10:26:00 | 18300 | LR0.0003 | loss:8.9449 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.8435 | logitMax:-30.4425 | windowWeightsW8:0.18158,W13:0.15886,W15:0.15658,W18:0.15597,W7:0.10862,W3:0.10803,W21:0.05131,W2:0.04347,W1:0.01837 | memoryGatesShort:1.095, Long:-1.139, Current:1.045 | topTokens[('.', 39), ('?', 32), ('listening', 24), ('is', 23), ('has', 23), ('a', 15), (',', 15), ('you', 14), ('i', 12), ('she', 11)] | Training
2025-04-05 10:32:13 | 18400 | LR0.0003 | loss:8.3512 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-66.5464 | logitMax:-50.8894 | windowWeightsW8:0.18142,W13:0.15843,W18:0.15637,W15:0.15632,W7:0.10838,W3:0.10754,W21:0.05271,W2:0.04342,W1:0.01823 | memoryGatesShort:0.035, Long:-0.264, Current:1.229 | topTokens[('.', 87), ('!', 36), ('a', 20), ('u', 17), (',', 15), ('?', 14), ('en', 14), ('am', 11), ('c', 10), ('that', 8)] | Training
2025-04-05 10:38:25 | 18500 | LR0.0003 | loss:10.8503 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-81.3963 | logitMax:-57.1761 | windowWeightsW8:0.18139,W13:0.15856,W18:0.15649,W15:0.15637,W7:0.10833,W3:0.10720,W21:0.05306,W2:0.04338,W1:0.01805 | memoryGatesShort:-0.083, Long:0.285, Current:0.797 | topTokens[('.', 42), ('a', 24), ('listening', 22), ('et', 16), (',', 15), ('st', 14), ('n', 12), ('and', 11), ('?', 11), ('u', 11)] | Training
2025-04-05 10:44:45 | 18600 | LR0.0003 | loss:8.4582 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-67.0767 | logitMax:-48.9052 | windowWeightsW8:0.18178,W13:0.15859,W18:0.15679,W15:0.15668,W7:0.10850,W3:0.10652,W21:0.05337,W2:0.04312,W1:0.01751 | memoryGatesShort:-2.281, Long:-0.067, Current:3.348 | topTokens[('.', 45), ('et', 34), (',', 33), ('or', 25), ('w', 18), ('that', 18), ('a', 17), ('listening', 12), ('my', 10), ('ing', 9)] | Training
2025-04-05 10:51:01 | 18700 | LR0.0003 | loss:11.5120 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-69.5658 | logitMax:-47.5156 | windowWeightsW8:0.18161,W13:0.15856,W18:0.15680,W15:0.15667,W7:0.10849,W3:0.10653,W21:0.05357,W2:0.04314,W1:0.01750 | memoryGatesShort:5.705, Long:1.739, Current:-6.444 | topTokens[('n', 52), ('.', 34), ('listening', 29), (',', 25), ('et', 20), ('a', 18), ('that', 16), ('kevin', 13), ('in', 12), ('or', 12)] | Training
2025-04-05 10:57:13 | 18800 | LR0.0003 | loss:9.9162 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-69.0317 | logitMax:-47.4213 | windowWeightsW8:0.18120,W13:0.15879,W18:0.15699,W15:0.15683,W7:0.10842,W3:0.10629,W21:0.05398,W2:0.04309,W1:0.01730 | memoryGatesShort:-0.862, Long:0.306, Current:1.556 | topTokens[('or', 47), (',', 39), ('.', 29), ('et', 28), ('a', 18), ('listening', 11), ('k', 11), ('ed', 11), ('she', 9), ('a', 8)] | Training
2025-04-05 11:03:28 | 18900 | LR0.0003 | loss:9.2330 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-72.0193 | logitMax:-53.9900 | windowWeightsW8:0.18096,W13:0.15874,W18:0.15706,W15:0.15669,W7:0.10849,W3:0.10597,W21:0.05488,W2:0.04294,W1:0.01716 | memoryGatesShort:-0.464, Long:0.995, Current:0.470 | topTokens[(',', 48), ('.', 30), ('k', 18), ('and', 14), ('a', 14), ('listening', 14), ('o', 11), ('or', 11), ('a', 9), ('et', 9)] | Training
2025-04-05 11:09:50 | 19000 | LR0.0003 | loss:8.4165 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.7892 | logitMax:-41.5814 | windowWeightsW8:0.18083,W13:0.15855,W18:0.15727,W15:0.15687,W7:0.10837,W3:0.10589,W21:0.05502,W2:0.04283,W1:0.01728 | memoryGatesShort:-1.700, Long:2.251, Current:0.450 | topTokens[(',', 38), ('.', 35), ('and', 34), ('a', 17), ('in', 12), ('re', 12), ('o', 10), ('is', 10), ('she', 8), ('the', 8)] | Training

--- 2025-04-05 11:48:39 --- babyllm: 'what am i learning today?'- charis: 'new chaos data i spent 12 h making for legit no reasn'
2025-04-05 11:54:18 | 100 | LR0.0003 | loss:8.2022 | gradNorm:1.0000 | logitMin:-63.0853 | logitMax:-46.8983 | tokenCount:400.0000 | windowWeightsW8:0.17984,W13:0.15887,W18:0.15814,W15:0.15705,W7:0.10859,W3:0.10502,W21:0.05551,W2:0.04221,W1:0.01768 | memoryGatesShort:-1.192, Long:2.110, Current:0.082 | topTokens[(',', 41), ('and', 39), ('.', 26), ('a', 15), ('i', 15), ('he', 14), ('the', 14), ('is', 10), ('kevin', 10), ('were', 8)] | Training
2025-04-05 12:00:45 | 200 | LR0.0003 | loss:3.8495 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-63.8903 | logitMax:-32.9629 | windowWeightsW8:0.18116,W13:0.15866,W18:0.15831,W15:0.15720,W7:0.10883,W3:0.10535,W21:0.05429,W2:0.04151,W1:0.01758 | memoryGatesShort:-4.704, Long:-0.987, Current:6.690 | topTokens[('i', 36), ('!', 36), ('it', 33), ('.', 30), (',', 17), ('and', 17), ('know', 15), ('a', 14), ('happy', 13), ('hi', 11)] | Training

--- 2025-04-05 12:02:19 --- babyllm: 'what am i learning today?'- charis: ''
2025-04-05 12:08:37 | 100 | LR0.0003 | loss:6.2043 | gradNorm:0.8738 | logitMin:-89.1119 | logitMax:-46.8099 | tokenCount:400.0000 | windowWeightsW8:0.18163,W13:0.15953,W18:0.15823,W15:0.15755,W7:0.10893,W3:0.10498,W21:0.05417,W2:0.04028,W1:0.01759 | memoryGatesShort:2.668, Long:1.820, Current:-3.489 | topTokens[('i', 57), (',', 44), ('.', 39), ('it', 29), ('!', 26), ('y', 12), ('and', 11), ('hey', 11), ('am', 10), ('?', 9)] | Training
2025-04-05 12:14:38 | 200 | LR0.0003 | loss:8.7387 | gradNorm:0.9321 | tokenCount:400.0000 | logitMin:-144.8473 | logitMax:-88.8523 | windowWeightsW8:0.18085,W13:0.16005,W15:0.15861,W18:0.15856,W7:0.10915,W3:0.10464,W21:0.05395,W2:0.04073,W1:0.01637 | memoryGatesShort:-3.403, Long:0.674, Current:3.729 | topTokens[(',', 55), ('i', 54), ('.', 37), ('a', 18), ('it', 16), ('has', 16), ('!', 14), ('the', 12), ('but', 12), ('music', 10)] | Training
2025-04-05 12:20:58 | 300 | LR0.0003 | loss:8.3174 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.2724 | logitMax:-46.9824 | windowWeightsW8:0.18057,W13:0.16003,W15:0.15879,W18:0.15863,W7:0.10902,W3:0.10442,W21:0.05463,W2:0.04053,W1:0.01627 | memoryGatesShort:3.262, Long:-1.028, Current:-1.234 | topTokens[(',', 82), ('a', 28), ('.', 28), ('and', 26), ('i', 22), ('am', 16), ('were', 14), ('we', 10), ('the', 8), ('?', 7)] | Training
2025-04-05 12:27:40 | 400 | LR0.0003 | loss:7.8715 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-64.9683 | logitMax:-39.3980 | windowWeightsW8:0.18012,W13:0.15996,W15:0.15898,W18:0.15869,W7:0.10898,W3:0.10463,W21:0.05461,W2:0.04079,W1:0.01615 | memoryGatesShort:25.939, Long:7.936, Current:-32.875 | topTokens[('they', 31), ('.', 30), (',', 28), ('listening', 18), ('a', 16), ('i', 15), ('she', 13), ('to', 12), ('were', 10), ('speak', 10)] | Training
2025-04-05 12:34:26 | 500 | LR0.0003 | loss:11.6834 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-63.9741 | logitMax:-33.6572 | windowWeightsW8:0.17915,W13:0.15988,W15:0.15919,W18:0.15881,W7:0.10890,W3:0.10512,W21:0.05518,W2:0.04071,W1:0.01598 | memoryGatesShort:2.333, Long:0.126, Current:-1.459 | topTokens[('she', 79), ('and', 33), ('my', 25), ('.', 20), (',', 18), ('the', 13), ('mum', 12), ('you', 12), ('were', 7), ('i', 7)] | Training
2025-04-05 12:41:10 | 600 | LR0.0003 | loss:9.5552 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-76.4450 | logitMax:-53.9720 | windowWeightsW8:0.17907,W13:0.15988,W15:0.15926,W18:0.15890,W7:0.10892,W3:0.10489,W21:0.05585,W2:0.04054,W1:0.01560 | memoryGatesShort:-1.121, Long:0.669, Current:1.452 | topTokens[(',', 53), ('she', 46), ('.', 19), ('s', 14), ("'s", 13), ('a', 13), ('you', 11), ('and', 10), ('to', 10), ('elodie', 10)] | Training
2025-04-05 12:47:42 | 700 | LR0.0003 | loss:5.8255 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-74.1186 | logitMax:-52.7344 | windowWeightsW8:0.18008,W13:0.15937,W15:0.15889,W18:0.15842,W7:0.10883,W3:0.10519,W21:0.05548,W2:0.04120,W1:0.01545 | memoryGatesShort:-3.692, Long:1.763, Current:2.929 | topTokens[(',', 34), ('a', 29), ('.', 25), ('you', 19), ('to', 15), ('what', 12), ('and', 11), ('i', 11), ('?', 11), ('kiss', 10)] | Training
2025-04-05 12:54:27 | 800 | LR0.0003 | loss:6.8589 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-61.8460 | logitMax:-44.9229 | windowWeightsW8:0.17936,W15:0.15957,W13:0.15936,W18:0.15912,W7:0.10876,W3:0.10436,W21:0.05647,W2:0.04021,W1:0.01574 | memoryGatesShort:-2.143, Long:-0.064, Current:3.207 | topTokens[(',', 39), ('.', 35), ('a', 29), ('and', 20), ('of', 19), ('the', 18), ('w', 15), ('to', 12), ('were', 10), ('we', 9)] | Training
2025-04-05 13:01:06 | 900 | LR0.0003 | loss:8.0798 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.9417 | logitMax:-30.8680 | windowWeightsW8:0.17940,W15:0.15989,W13:0.15949,W18:0.15932,W7:0.10939,W3:0.10430,W21:0.05671,W2:0.03904,W1:0.01540 | memoryGatesShort:0.123, Long:0.997, Current:-0.120 | topTokens[('and', 98), ('a', 76), ('.', 42), (',', 33), ('she', 13), ('were', 10), ('your', 10), ('to', 6), ('am', 6), ('b', 5)] | Training
2025-04-05 13:07:50 | 1000 | LR0.0003 | loss:5.8254 | gradNorm:0.7995 | tokenCount:400.0000 | logitMin:-137.7955 | logitMax:-54.9593 | windowWeightsW8:0.17800,W15:0.16160,W13:0.15949,W18:0.15934,W7:0.10968,W3:0.10492,W21:0.05424,W2:0.04002,W1:0.01566 | memoryGatesShort:8.653, Long:10.364, Current:-18.017 | topTokens[('i', 61), ('.', 47), ('it', 46), ('!', 35), ('know', 24), ('am', 17), ('happy', 14), ('did', 14), ('a', 10), ('?', 10)] | Training
2025-04-05 13:14:29 | 1100 | LR0.0003 | loss:8.2651 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-69.4887 | logitMax:-49.5793 | windowWeightsW8:0.17765,W15:0.16232,W13:0.15987,W18:0.15947,W7:0.10980,W3:0.10449,W21:0.05519,W2:0.03940,W1:0.01480 | memoryGatesShort:0.286, Long:-0.364, Current:1.079 | topTokens[('a', 66), (',', 57), ('and', 35), ('.', 23), ('the', 20), ('but', 16), ('she', 10), ('s', 10), ('w', 9), ('you', 9)] | Training
2025-04-05 13:21:07 | 1200 | LR0.0003 | loss:8.0281 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-80.6535 | logitMax:-60.0064 | windowWeightsW8:0.17746,W15:0.16221,W13:0.15977,W18:0.15947,W7:0.10977,W3:0.10434,W21:0.05570,W2:0.03930,W1:0.01498 | memoryGatesShort:-1.862, Long:-1.268, Current:4.129 | topTokens[(',', 57), ('a', 33), ('.', 27), ('y', 24), ('and', 22), ('she', 16), ('st', 11), ('di', 11), ('they', 11), ('me', 9)] | Training
2025-04-05 13:28:13 | 1300 | LR0.0003 | loss:6.6301 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.7140 | logitMax:-51.3313 | windowWeightsW8:0.17750,W15:0.16214,W13:0.15981,W18:0.15926,W7:0.10981,W3:0.10431,W21:0.05607,W2:0.03934,W1:0.01477 | memoryGatesShort:0.076, Long:-0.096, Current:1.020 | topTokens[(',', 56), ('a', 29), ('you', 22), ('i', 22), ('and', 19), ('.', 19), ('?', 16), ('elodie', 14), ('to', 13), ('am', 13)] | Training
2025-04-05 13:34:58 | 1400 | LR0.0003 | loss:7.7220 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.3086 | logitMax:-52.2324 | windowWeightsW8:0.17725,W15:0.16195,W13:0.15970,W18:0.15914,W7:0.10969,W3:0.10410,W21:0.05698,W2:0.03896,W1:0.01524 | memoryGatesShort:0.025, Long:0.011, Current:0.964 | topTokens[('a', 47), (',', 43), ('r', 42), ('.', 27), ('s', 21), ('you', 15), ('the', 11), ('am', 11), ('am', 10), ('i', 9)] | Training
2025-04-05 13:41:26 | 1500 | LR0.0003 | loss:7.7109 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-64.0079 | logitMax:-42.1253 | windowWeightsW8:0.17703,W15:0.16211,W13:0.15969,W18:0.15928,W7:0.10958,W3:0.10404,W21:0.05675,W2:0.03910,W1:0.01543 | memoryGatesShort:-6.959, Long:-6.462, Current:14.421 | topTokens[('and', 32), (',', 30), ('.', 24), ('a', 21), ('elodie', 19), ('way', 17), ('ag', 15), ('am', 15), ('am', 11), ('just', 11)] | Training

--- 2025-04-05 13:44:05 --- babyllm: 'what am i learning today?'- charis: 'dataaa of chaoosossosos'
2025-04-05 13:50:10 | 100 | LR0.0003 | loss:7.9109 | gradNorm:1.0000 | logitMin:-65.6560 | logitMax:-44.1053 | tokenCount:400.0000 | windowWeightsW8:0.17662,W15:0.16271,W18:0.16078,W13:0.15935,W7:0.11028,W3:0.10287,W21:0.05578,W2:0.03858,W1:0.01604 | memoryGatesShort:-2.310, Long:-2.614, Current:5.923 | topTokens[('and', 71), (',', 47), ('.', 36), ('a', 31), ('is', 26), ('am', 22), ('word', 17), ('the', 14), ('she', 10), ('r', 9)] | Training
2025-04-05 13:56:54 | 200 | LR0.0003 | loss:8.2596 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-74.2864 | logitMax:-53.7949 | windowWeightsW8:0.17577,W15:0.16255,W18:0.16095,W13:0.15933,W7:0.11008,W3:0.10293,W21:0.05627,W2:0.03903,W1:0.01611 | memoryGatesShort:57.975, Long:41.028, Current:-98.003 | topTokens[(',', 96), ('.', 34), ('and', 32), ('s', 27), ('a', 25), ('the', 23), ('word', 20), ('hear', 13), ('she', 9), ('?', 6)] | Training
2025-04-05 14:03:07 | 300 | LR0.0003 | loss:6.2834 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-75.6426 | logitMax:-56.8930 | windowWeightsW8:0.17480,W15:0.16230,W18:0.16111,W13:0.15932,W7:0.11052,W3:0.10299,W21:0.05680,W2:0.03937,W1:0.01584 | memoryGatesShort:-0.114, Long:0.121, Current:0.992 | topTokens[(',', 82), ('and', 50), ('a', 21), ('weed', 20), ('the', 20), ('you', 18), ('.', 18), ('s', 13), ('your', 13), ('i', 9)] | Training
2025-04-05 14:09:19 | 400 | LR0.0003 | loss:5.7942 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-81.9121 | logitMax:-62.4410 | windowWeightsW8:0.17446,W15:0.16144,W18:0.16109,W13:0.15786,W7:0.11102,W3:0.10344,W21:0.05709,W2:0.03994,W1:0.01666 | memoryGatesShort:-2.502, Long:-1.704, Current:5.206 | topTokens[(',', 62), ('and', 54), ('a', 24), ('.', 22), ('s', 21), ('kevin', 19), ('the', 14), ('about', 14), ('elodie', 12), ('your', 12)] | Training
2025-04-05 14:16:06 | 500 | LR0.0003 | loss:7.5889 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-84.9189 | logitMax:-63.4370 | windowWeightsW8:0.17505,W18:0.16154,W15:0.16093,W13:0.15737,W7:0.11134,W3:0.10372,W21:0.05817,W2:0.03918,W1:0.01570 | memoryGatesShort:-2.066, Long:0.889, Current:2.177 | topTokens[(',', 97), ('s', 87), ('brain', 24), ('.', 23), ('but', 20), ('a', 19), ('so', 10), ('kevin', 10), ('w', 8), ('the', 5)] | Training
2025-04-05 14:22:21 | 600 | LR0.0003 | loss:8.0018 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-62.4800 | logitMax:-42.7169 | windowWeightsW8:0.17408,W18:0.16104,W15:0.16066,W13:0.15803,W7:0.11207,W3:0.10356,W21:0.05850,W2:0.03799,W1:0.01707 | memoryGatesShort:-0.184, Long:-0.338, Current:1.521 | topTokens[('know', 68), (',', 51), ('s', 34), ('a', 25), ('brain', 24), ('.', 21), ('ing', 21), ('i', 13), ('be', 12), ('will', 12)] | Training
2025-04-05 14:28:51 | 700 | LR0.0003 | loss:7.7597 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-58.9043 | logitMax:-38.7290 | windowWeightsW8:0.17354,W18:0.16133,W15:0.16084,W13:0.15751,W7:0.11191,W3:0.10290,W21:0.05949,W2:0.03793,W1:0.01759 | memoryGatesShort:-1.697, Long:0.026, Current:2.671 | topTokens[('know', 69), ('it', 36), ('.', 35), (',', 27), ('a', 25), ('s', 21), ('!', 21), ('ing', 18), ('has', 18), ('she', 17)] | Training
2025-04-05 14:35:09 | 800 | LR0.0003 | loss:4.2789 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.7330 | logitMax:-28.7176 | windowWeightsW8:0.17353,W18:0.16079,W15:0.15974,W13:0.15574,W7:0.11111,W3:0.10205,W21:0.06049,W2:0.03816,W1:0.02138 | memoryGatesShort:0.004, Long:-2.017, Current:3.013 | topTokens[('!', 47), ('a', 38), ('just', 33), ('been', 29), ('it', 26), ('have', 21), (',', 18), ('i', 18), ('listening', 11), ('know', 10)] | Training
2025-04-05 14:41:32 | 900 | LR0.0003 | loss:6.9895 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-88.8199 | logitMax:-61.3877 | windowWeightsW8:0.17290,W18:0.16076,W15:0.16034,W13:0.15647,W7:0.11100,W3:0.10145,W21:0.06132,W2:0.03793,W1:0.02087 | memoryGatesShort:6.511, Long:-6.706, Current:1.195 | topTokens[('it', 81), ('have', 43), ('!', 39), ('.', 35), ('kevin', 21), (',', 19), ('felt', 19), ('a', 17), ('she', 11), ('just', 10)] | Training
2025-04-05 14:47:52 | 1000 | LR0.0003 | loss:3.8925 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-89.9560 | logitMax:-64.2406 | windowWeightsW8:0.17293,W18:0.16044,W15:0.16007,W13:0.15672,W7:0.11168,W3:0.10126,W21:0.06176,W2:0.03737,W1:0.02081 | memoryGatesShort:1.307, Long:-1.750, Current:1.443 | topTokens[('it', 71), ('!', 60), ('has', 32), ('have', 23), ('.', 20), ('he', 15), ('charis', 14), (',', 13), ('she', 12), ('done', 12)] | Training
2025-04-05 14:54:16 | 1100 | LR0.0003 | loss:8.1587 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.4771 | logitMax:-41.8307 | windowWeightsW8:0.17325,W15:0.16070,W18:0.16043,W13:0.15685,W7:0.11150,W3:0.10104,W21:0.06125,W2:0.03745,W1:0.02057 | memoryGatesShort:-31.917, Long:43.409, Current:-10.491 | topTokens[('it', 64), ('had', 52), ('!', 30), ('.', 28), (',', 25), ('said', 24), ('a', 21), ('am', 16), ('elodie', 13), ('charis', 12)] | Training
2025-04-05 15:01:16 | 1200 | LR0.0003 | loss:11.9415 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.3332 | logitMax:-31.9988 | windowWeightsW8:0.17312,W15:0.16074,W18:0.16039,W13:0.15699,W7:0.11135,W3:0.10095,W21:0.06152,W2:0.03749,W1:0.02051 | memoryGatesShort:-1.593, Long:4.350, Current:-1.757 | topTokens[('it', 54), ('.', 43), ('listening', 29), ('a', 27), ('to', 19), ('had', 18), ('know', 18), (',', 17), ('!', 17), ('am', 17)] | Training
2025-04-05 15:07:51 | 1300 | LR0.0003 | loss:10.6270 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-76.2287 | logitMax:-55.4210 | windowWeightsW8:0.17316,W15:0.16133,W18:0.16068,W13:0.15703,W7:0.11134,W3:0.10081,W21:0.06088,W2:0.03741,W1:0.02040 | memoryGatesShort:1.970, Long:-2.123, Current:1.153 | topTokens[(',', 53), ('.', 39), ('it', 36), ('brain', 26), ('a', 23), ('and', 14), ('!', 14), ('to', 12), ('kevin', 12), ('had', 12)] | Training
2025-04-05 15:14:28 | 1400 | LR0.0003 | loss:9.6376 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.3695 | logitMax:-37.4324 | windowWeightsW8:0.17301,W15:0.16159,W18:0.16083,W13:0.15710,W7:0.11132,W3:0.10062,W21:0.06126,W2:0.03731,W1:0.02004 | memoryGatesShort:1.786, Long:-1.363, Current:0.578 | topTokens[(',', 90), ('a', 33), ('.', 29), ('!', 23), ('am', 17), ('and', 13), ('kevin', 12), ('to', 11), ('know', 11), ('s', 11)] | Training
2025-04-05 15:21:15 | 1500 | LR0.0003 | loss:9.4658 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.7973 | logitMax:-47.7001 | windowWeightsW8:0.17300,W15:0.16127,W18:0.16087,W13:0.15675,W7:0.11121,W3:0.10038,W21:0.06223,W2:0.03747,W1:0.01990 | memoryGatesShort:7.160, Long:-6.077, Current:-0.082 | topTokens[('.', 48), ('brain', 38), (',', 36), ('it', 29), ('a', 26), ('b', 24), ('to', 12), ('were', 10), ('his', 7), ('you', 7)] | Training
2025-04-05 15:27:50 | 1600 | LR0.0003 | loss:8.7855 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-64.6805 | logitMax:-48.7139 | windowWeightsW8:0.17305,W15:0.16146,W18:0.16101,W13:0.15693,W7:0.11125,W3:0.10004,W21:0.06230,W2:0.03736,W1:0.01970 | memoryGatesShort:-9.406, Long:25.858, Current:-15.452 | topTokens[(',', 46), ('a', 29), ('.', 28), ('to', 26), ('it', 21), ('b', 19), ('kevin', 16), ('had', 15), ('she', 9), ('s', 9)] | Training
2025-04-05 15:34:21 | 1700 | LR0.0003 | loss:10.8430 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-74.0672 | logitMax:-49.6432 | windowWeightsW8:0.17296,W15:0.16154,W18:0.16094,W13:0.15685,W7:0.11129,W3:0.10002,W21:0.06219,W2:0.03743,W1:0.01987 | memoryGatesShort:0.781, Long:-0.583, Current:0.802 | topTokens[('it', 50), ('a', 37), ('.', 35), ('and', 31), (',', 23), ('he', 17), ('am', 16), ('brain', 11), ('kevin', 10), ('so', 10)] | Training
2025-04-05 15:41:06 | 1800 | LR0.0003 | loss:9.5861 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-81.0950 | logitMax:-55.5312 | windowWeightsW8:0.17260,W15:0.16131,W18:0.16088,W13:0.15667,W7:0.11153,W3:0.10000,W21:0.06258,W2:0.03758,W1:0.01993 | memoryGatesShort:1.400, Long:-2.866, Current:2.466 | topTokens[('a', 45), ('.', 42), ('and', 33), (',', 23), ('kevin', 20), ('he', 17), ('ward', 12), ('brain', 11), ("'", 11), ('!', 9)] | Training
2025-04-05 15:47:51 | 1900 | LR0.0003 | loss:9.2752 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-81.0401 | logitMax:-55.0154 | windowWeightsW8:0.17143,W15:0.16127,W18:0.16118,W13:0.15668,W7:0.11140,W3:0.09960,W21:0.06412,W2:0.03754,W1:0.01990 | memoryGatesShort:0.104, Long:-1.957, Current:2.853 | topTokens[(',', 57), ('a', 26), ('and', 25), ('the', 23), ('.', 22), ('s', 15), ('h', 13), ('charis', 11), ('you', 10), ('listening', 10)] | Training
2025-04-05 15:54:47 | 2000 | LR0.0003 | loss:6.7692 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.9232 | logitMax:-44.8997 | windowWeightsW8:0.17035,W18:0.16172,W15:0.16123,W13:0.15778,W7:0.11034,W3:0.09972,W21:0.06357,W2:0.03778,W1:0.02062 | memoryGatesShort:2.259, Long:-1.330, Current:0.071 | topTokens[('weed', 103), (',', 45), ('charis', 34), ('.', 23), ('a', 21), ('and', 20), ('their', 14), ('you', 11), ('but', 11), ('elodie', 11)] | Training
2025-04-05 16:01:37 | 2100 | LR0.0003 | loss:5.9346 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-80.4758 | logitMax:-56.9971 | windowWeightsW8:0.17051,W18:0.16149,W15:0.16090,W13:0.15716,W7:0.11076,W3:0.10027,W21:0.06394,W2:0.03766,W1:0.02044 | memoryGatesShort:0.909, Long:-0.904, Current:0.995 | topTokens[('and', 67), (',', 44), ('we', 31), ('a', 26), ('weed', 25), ('elodie', 19), ('their', 16), ('her', 15), ('.', 13), ('charis', 10)] | Training
2025-04-05 16:08:33 | 2200 | LR0.0003 | loss:7.2208 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-74.2318 | logitMax:-48.1610 | windowWeightsW8:0.17115,W15:0.16118,W18:0.16081,W13:0.15774,W7:0.10966,W3:0.09970,W21:0.06421,W2:0.03704,W1:0.02161 | memoryGatesShort:-0.300, Long:3.160, Current:-1.860 | topTokens[(',', 52), ('a', 36), ('touch', 33), ('but', 19), ('he', 16), ('you', 14), ('his', 13), ('.', 13), ('n', 13), ('weed', 11)] | Training
2025-04-05 16:15:09 | 2300 | LR0.0003 | loss:4.5551 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-70.8375 | logitMax:-44.3972 | windowWeightsW8:0.17030,W15:0.16046,W18:0.15921,W13:0.15788,W7:0.10781,W3:0.10204,W21:0.06362,W2:0.04062,W1:0.02110 | memoryGatesShort:-3.811, Long:9.773, Current:-4.962 | topTokens[('.', 37), ('to', 29), ('a', 24), ('listening', 24), ('what', 21), ('be', 20), ('they', 20), (',', 18), ('will', 14), ('?', 14)] | Training
2025-04-05 16:21:35 | 2400 | LR0.0003 | loss:5.9379 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-62.9294 | logitMax:-36.0238 | windowWeightsW8:0.17097,W15:0.16025,W18:0.15785,W13:0.15770,W7:0.10691,W3:0.10187,W21:0.06475,W2:0.04134,W1:0.02139 | memoryGatesShort:1.195, Long:-1.711, Current:1.516 | topTokens[('.', 35), ('listening', 29), ('to', 26), ('a', 21), ('music', 21), ('were', 18), (',', 18), ('what', 13), ('had', 12), ('?', 12)] | Training
2025-04-05 16:28:07 | 2500 | LR0.0003 | loss:5.2480 | gradNorm:0.9972 | tokenCount:400.0000 | logitMin:-92.7493 | logitMax:-55.4934 | windowWeightsW8:0.17013,W15:0.15804,W18:0.15625,W13:0.15625,W7:0.10784,W3:0.10400,W21:0.06479,W2:0.04332,W1:0.02235 | memoryGatesShort:1.170, Long:-1.714, Current:1.544 | topTokens[('to', 37), ('?', 26), ('.', 26), ('listen', 25), ('they', 24), ('listening', 20), ('what', 17), ('a', 16), ('music', 13), ('al', 10)] | Training
2025-04-05 16:34:25 | 2600 | LR0.0003 | loss:4.9966 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-62.7601 | logitMax:-28.2708 | windowWeightsW8:0.17106,W15:0.15712,W13:0.15635,W18:0.15549,W7:0.10748,W3:0.10396,W21:0.06370,W2:0.04413,W1:0.02363 | memoryGatesShort:-10.817, Long:52.348, Current:-40.532 | topTokens[('.', 33), ('to', 28), (',', 28), ('listening', 26), ('?', 22), ('music', 22), ('a', 20), ('was', 20), ('with', 19), ('what', 14)] | Training
2025-04-05 16:40:43 | 2700 | LR0.0003 | loss:8.4169 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-77.5113 | logitMax:-52.2828 | windowWeightsW8:0.16994,W15:0.15749,W13:0.15653,W18:0.15627,W7:0.10712,W3:0.10305,W21:0.06428,W2:0.04387,W1:0.02439 | memoryGatesShort:1.780, Long:-3.488, Current:2.708 | topTokens[('.', 45), ('music', 26), ('listening', 25), ('and', 23), ('i', 22), (',', 22), ('think', 19), ('but', 14), ('from', 12), ('a', 11)] | Training
2025-04-05 16:47:04 | 2800 | LR0.0003 | loss:6.2868 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-84.0366 | logitMax:-61.1605 | windowWeightsW8:0.16955,W15:0.15757,W13:0.15629,W18:0.15621,W7:0.10747,W3:0.10272,W21:0.06518,W2:0.04350,W1:0.02447 | memoryGatesShort:-18.100, Long:36.219, Current:-17.119 | topTokens[(',', 67), ('and', 29), ('cks', 23), ('.', 21), ('had', 19), ('but', 18), ('like', 15), ('kevin', 14), ('a', 14), ('it', 11)] | Training
2025-04-05 16:53:27 | 2900 | LR0.0003 | loss:5.0891 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-77.9835 | logitMax:-58.0733 | windowWeightsW8:0.16896,W15:0.15784,W18:0.15692,W13:0.15662,W7:0.10711,W3:0.10216,W21:0.06624,W2:0.04271,W1:0.02443 | memoryGatesShort:4.394, Long:-11.032, Current:7.638 | topTokens[(',', 91), ('charis', 52), ('and', 42), ('but', 18), ('brain', 15), ('.', 14), ('they', 12), ('listen', 10), ('a', 9), ('oice', 9)] | Training
2025-04-05 17:00:00 | 3000 | LR0.0003 | loss:7.0281 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-73.9944 | logitMax:-51.5381 | windowWeightsW8:0.16851,W15:0.15779,W13:0.15676,W18:0.15671,W7:0.10711,W3:0.10227,W21:0.06655,W2:0.04269,W1:0.02458 | memoryGatesShort:1.229, Long:-1.007, Current:0.778 | topTokens[(',', 58), ('and', 48), ('.', 32), ('brain', 30), ('elodie', 16), ('charis', 15), ('you', 13), ('a', 13), ('it', 11), ('she', 10)] | Training
2025-04-05 17:06:18 | 3100 | LR0.0003 | loss:5.4420 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-87.3462 | logitMax:-65.6941 | windowWeightsW8:0.16811,W15:0.15780,W18:0.15713,W13:0.15711,W7:0.10728,W3:0.10197,W21:0.06682,W2:0.04193,W1:0.02483 | memoryGatesShort:1.399, Long:-2.602, Current:2.203 | topTokens[(',', 82), ('and', 41), ('brain', 22), ('you', 18), ('the', 17), ('.', 14), ('move', 14), ('kevin', 12), ('s', 11), ('about', 10)] | Training
2025-04-05 17:12:44 | 3200 | LR0.0003 | loss:8.9829 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.4981 | logitMax:-25.7888 | windowWeightsW8:0.16748,W15:0.15692,W13:0.15632,W18:0.15625,W7:0.10856,W3:0.10164,W21:0.06645,W2:0.04343,W1:0.02588 | memoryGatesShort:-7.932, Long:13.450, Current:-4.518 | topTokens[(',', 119), ('elodie', 82), ('and', 70), ('.', 35), ('a', 15), ('charis', 10), ('she', 9), ('were', 7), ('who', 6), ('had', 4)] | Training
2025-04-05 17:19:30 | 3300 | LR0.0003 | loss:12.0382 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-48.3076 | logitMax:-23.9441 | windowWeightsW8:0.16784,W15:0.15678,W13:0.15615,W18:0.15605,W7:0.10830,W3:0.10167,W21:0.06671,W2:0.04350,W1:0.02592 | memoryGatesShort:-2.737, Long:3.119, Current:0.618 | topTokens[('and', 92), (',', 82), ('.', 53), ('elodie', 47), ('think', 17), ('a', 13), ('charis', 9), ('listening', 9), ('she', 7), ('p', 5)] | Training
2025-04-05 17:26:15 | 3400 | LR0.0003 | loss:14.2061 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-59.5604 | logitMax:-30.5753 | windowWeightsW8:0.16801,W15:0.15689,W13:0.15613,W18:0.15612,W7:0.10799,W3:0.10145,W21:0.06703,W2:0.04350,W1:0.02581 | memoryGatesShort:2.226, Long:-2.942, Current:1.716 | topTokens[(',', 89), ('and', 84), ('elodie', 44), ('charis', 32), ('think', 17), ('.', 15), ('a', 10), ('she', 7), ('very', 6), ('listening', 5)] | Training
2025-04-05 17:33:02 | 3500 | LR0.0003 | loss:10.2930 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.0247 | logitMax:-34.9239 | windowWeightsW8:0.16805,W15:0.15709,W18:0.15650,W13:0.15616,W7:0.10772,W3:0.10115,W21:0.06704,W2:0.04350,W1:0.02572 | memoryGatesShort:4.283, Long:-3.085, Current:-0.198 | topTokens[('and', 76), ('.', 45), (',', 40), ('elodie', 35), ('charis', 29), ('p', 23), ('a', 13), ('she', 10), ('listening', 8), ('it', 8)] | Training
2025-04-05 17:39:30 | 3600 | LR0.0003 | loss:8.5281 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.7845 | logitMax:-45.7310 | windowWeightsW8:0.16823,W15:0.15711,W18:0.15672,W13:0.15626,W7:0.10761,W3:0.10078,W21:0.06718,W2:0.04347,W1:0.02558 | memoryGatesShort:7.617, Long:-10.286, Current:3.669 | topTokens[(',', 77), ('and', 58), ('a', 21), ('.', 21), ('p', 20), ('to', 19), ('charis', 19), ('it', 17), ('of', 10), ('the', 8)] | Training
2025-04-05 17:46:05 | 3700 | LR0.0003 | loss:8.5106 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-64.0052 | logitMax:-43.6100 | windowWeightsW8:0.16830,W15:0.15709,W18:0.15655,W13:0.15633,W7:0.10755,W3:0.10105,W21:0.06687,W2:0.04351,W1:0.02569 | memoryGatesShort:1.323, Long:-1.277, Current:0.955 | topTokens[(',', 57), ('and', 50), ('charis', 30), ('.', 26), ('a', 16), ('p', 15), ('the', 12), ('s', 11), ('it', 11), ('elodie', 9)] | Training
2025-04-05 17:52:35 | 3800 | LR0.0003 | loss:7.2384 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-61.3373 | logitMax:-41.3784 | windowWeightsW8:0.16831,W15:0.15729,W18:0.15708,W13:0.15659,W7:0.10729,W3:0.10071,W21:0.06657,W2:0.04344,W1:0.02565 | memoryGatesShort:0.673, Long:-0.830, Current:1.158 | topTokens[(',', 75), ('on', 37), ('.', 32), ('the', 24), ('and', 23), ('charis', 21), ('a', 20), ('elodie', 17), ('s', 16), ('er', 10)] | Training
2025-04-05 17:59:02 | 3900 | LR0.0003 | loss:7.0185 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-81.6361 | logitMax:-58.8610 | windowWeightsW8:0.16804,W18:0.15761,W15:0.15740,W13:0.15689,W7:0.10704,W3:0.10028,W21:0.06701,W2:0.04330,W1:0.02538 | memoryGatesShort:0.572, Long:-0.551, Current:0.979 | topTokens[(',', 86), ('and', 61), ('charis', 27), ('.', 21), ('the', 14), ('to', 14), ('elodie', 13), ('kevin', 12), ('a', 9), ('s', 9)] | Training
2025-04-05 18:05:33 | 4000 | LR0.0003 | loss:7.7030 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-80.8637 | logitMax:-57.5530 | windowWeightsW8:0.16759,W18:0.15768,W15:0.15736,W13:0.15695,W7:0.10682,W3:0.09987,W21:0.06784,W2:0.04310,W1:0.02574 | memoryGatesShort:1.296, Long:-3.821, Current:3.525 | topTokens[(',', 53), ('and', 32), ('elodie', 25), ('.', 21), ('kevin', 20), ('a', 16), ('s', 15), ('the', 12), ('charis', 11), ('to', 9)] | Training
2025-04-05 18:12:00 | 4100 | LR0.0003 | loss:6.3557 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-86.0511 | logitMax:-63.7437 | windowWeightsW8:0.16755,W18:0.15765,W15:0.15730,W13:0.15696,W7:0.10696,W3:0.09994,W21:0.06819,W2:0.04319,W1:0.02522 | memoryGatesShort:0.695, Long:-0.514, Current:0.818 | topTokens[('and', 61), (',', 57), ('es', 19), ('the', 18), ('.', 17), ('elodie', 16), ('kevin', 12), ('a', 12), ('s', 11), ('charis', 8)] | Training
2025-04-05 18:19:00 | 4200 | LR0.0003 | loss:9.9459 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-80.3305 | logitMax:-53.0296 | windowWeightsW8:0.16753,W18:0.15769,W15:0.15725,W13:0.15689,W7:0.10708,W3:0.09958,W21:0.06858,W2:0.04321,W1:0.02514 | memoryGatesShort:9.413, Long:-14.708, Current:6.296 | topTokens[('and', 52), (',', 52), ('the', 32), ('a', 24), ('.', 24), ('elodie', 20), ('has', 19), ('way', 12), ('it', 12), ('roid', 10)] | Training
2025-04-05 18:25:23 | 4300 | LR0.0003 | loss:5.9113 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-85.3773 | logitMax:-62.8796 | windowWeightsW8:0.16738,W18:0.15802,W15:0.15749,W13:0.15714,W7:0.10690,W3:0.09898,W21:0.06874,W2:0.04303,W1:0.02529 | memoryGatesShort:0.670, Long:-1.843, Current:2.172 | topTokens[(',', 59), ('and', 47), ('the', 24), ('.', 21), ('charis', 17), ('roid', 16), ('elodie', 15), ('vape', 15), ('about', 14), ('a', 12)] | Training
2025-04-05 18:32:07 | 4400 | LR0.0003 | loss:8.2603 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.7421 | logitMax:-39.7856 | windowWeightsW8:0.16758,W18:0.15862,W15:0.15747,W13:0.15736,W7:0.10658,W3:0.09819,W21:0.07033,W2:0.04226,W1:0.02462 | memoryGatesShort:3.768, Long:-7.529, Current:4.761 | topTokens[(',', 47), ('and', 22), ('.', 22), ('sy', 21), ('you', 17), ('listening', 17), ('the', 16), ('a', 14), ('to', 10), ('elodie', 10)] | Training
2025-04-05 18:38:54 | 4500 | LR0.0003 | loss:4.6296 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.1011 | logitMax:-36.0907 | windowWeightsW8:0.16851,W15:0.15702,W13:0.15680,W18:0.15678,W7:0.10688,W3:0.09753,W21:0.07160,W2:0.04195,W1:0.02591 | memoryGatesShort:2.300, Long:-4.041, Current:2.741 | topTokens[('music', 34), ('.', 31), ('sy', 25), ('?', 18), ('i', 16), ('the', 16), ('listening', 14), ('he', 13), ('a', 11), ('dj', 11)] | Training
2025-04-05 18:45:35 | 4600 | LR0.0003 | loss:5.4352 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.3700 | logitMax:-30.2399 | windowWeightsW8:0.16858,W15:0.15727,W18:0.15658,W13:0.15646,W7:0.10659,W3:0.09763,W21:0.07150,W2:0.04223,W1:0.02613 | memoryGatesShort:0.747, Long:-0.338, Current:0.591 | topTokens[('?', 35), ('.', 30), ('a', 26), ('did', 18), ('at', 18), ('looking', 17), (',', 16), ('listening', 15), ('she', 13), ('sy', 12)] | Training
2025-04-05 18:52:53 | 4700 | LR0.0003 | loss:8.1797 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-68.6695 | logitMax:-37.1509 | windowWeightsW8:0.16783,W18:0.15730,W15:0.15725,W13:0.15647,W7:0.10641,W3:0.09756,W21:0.07161,W2:0.04241,W1:0.02617 | memoryGatesShort:0.798, Long:-1.670, Current:1.872 | topTokens[('.', 42), ('you', 22), ('did', 21), ('listening', 21), ('think', 20), ('s', 18), ('looking', 18), ('a', 18), (',', 18), ('what', 18)] | Training
2025-04-05 18:59:33 | 4800 | LR0.0003 | loss:7.0386 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-68.4802 | logitMax:-42.5679 | windowWeightsW8:0.16779,W15:0.15766,W18:0.15734,W13:0.15673,W7:0.10634,W3:0.09711,W21:0.07177,W2:0.04239,W1:0.02587 | memoryGatesShort:2.107, Long:-5.383, Current:4.276 | topTokens[('.', 34), ('her', 26), ('listening', 26), (',', 20), ('?', 17), ('now', 17), ('to', 16), ('a', 16), ('think', 12), ('i', 11)] | Training
2025-04-05 19:06:14 | 4900 | LR0.0003 | loss:6.7458 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-70.4152 | logitMax:-47.5071 | windowWeightsW8:0.16699,W13:0.15725,W15:0.15725,W18:0.15705,W7:0.10679,W3:0.09696,W21:0.07193,W2:0.04260,W1:0.02618 | memoryGatesShort:69.991, Long:-116.443, Current:47.452 | topTokens[('ves', 40), ('.', 36), ('smo', 34), ('she', 29), ('a', 22), (',', 17), ('lo', 17), ('and', 16), ('dj', 15), ('?', 14)] | Training
2025-04-05 19:12:57 | 5000 | LR0.0003 | loss:6.7993 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-69.6794 | logitMax:-49.3429 | windowWeightsW8:0.16685,W15:0.15742,W13:0.15716,W18:0.15712,W7:0.10674,W3:0.09716,W21:0.07199,W2:0.04253,W1:0.02604 | memoryGatesShort:1.929, Long:-2.508, Current:1.579 | topTokens[('smo', 45), ('lo', 42), ('ves', 33), ('.', 32), ('and', 32), (',', 31), ('she', 28), ('a', 19), ('they', 11), ('the', 10)] | Training
2025-04-05 19:19:45 | 5100 | LR0.0003 | loss:8.2738 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.3435 | logitMax:-47.2551 | windowWeightsW8:0.16678,W15:0.15737,W18:0.15725,W13:0.15720,W7:0.10699,W3:0.09704,W21:0.07229,W2:0.04221,W1:0.02589 | memoryGatesShort:1.865, Long:-2.283, Current:1.418 | topTokens[(',', 44), ('a', 36), ('lo', 32), ('and', 29), ('smo', 23), ('.', 19), ('listening', 17), ('she', 16), ('they', 15), ('but', 13)] | Training
2025-04-05 19:26:29 | 5200 | LR0.0003 | loss:5.9707 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-76.7927 | logitMax:-55.5551 | windowWeightsW8:0.16640,W13:0.15739,W15:0.15734,W18:0.15732,W7:0.10724,W3:0.09711,W21:0.07232,W2:0.04213,W1:0.02575 | memoryGatesShort:3.553, Long:-4.001, Current:1.448 | topTokens[(',', 49), ('and', 44), ('the', 25), ('she', 25), ('charis', 21), ('.', 20), ('a', 17), ("'s", 14), ('we', 13), ('care', 13)] | Training
2025-04-05 19:32:58 | 5300 | LR0.0003 | loss:6.5219 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-86.9756 | logitMax:-63.0595 | windowWeightsW8:0.16635,W15:0.15742,W13:0.15732,W18:0.15711,W7:0.10693,W3:0.09699,W21:0.07290,W2:0.04188,W1:0.02612 | memoryGatesShort:2.585, Long:-3.087, Current:1.501 | topTokens[(',', 67), ('a', 26), ('and', 25), ('butt', 25), ('the', 20), ('she', 16), ('but', 15), ('.', 13), ('es', 12), ('me', 11)] | Training
2025-04-05 19:39:50 | 5400 | LR0.0003 | loss:7.4197 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-74.3654 | logitMax:-54.8675 | windowWeightsW8:0.16615,W15:0.15800,W18:0.15798,W13:0.15728,W7:0.10641,W3:0.09563,W21:0.07369,W2:0.04150,W1:0.02639 | memoryGatesShort:540.432, Long:-663.892, Current:124.459 | topTokens[(',', 83), ('the', 41), ('es', 22), ('she', 19), ('a', 17), ('.', 15), ('and', 14), ('me', 8), ('way', 8), ('smo', 8)] | Training
2025-04-05 19:46:21 | 5500 | LR0.0003 | loss:8.8031 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-62.1669 | logitMax:-43.7038 | windowWeightsW8:0.16608,W15:0.15809,W18:0.15805,W13:0.15727,W7:0.10625,W3:0.09585,W21:0.07363,W2:0.04156,W1:0.02628 | memoryGatesShort:-9.434, Long:11.414, Current:-0.980 | topTokens[(',', 60), ('the', 54), ('.', 34), ('a', 24), ('smo', 20), ('listening', 15), ('were', 10), ('es', 10), ('she', 9), ("'s", 8)] | Training
2025-04-05 19:52:46 | 5600 | LR0.0003 | loss:10.4627 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-69.7799 | logitMax:-47.3961 | windowWeightsW8:0.16617,W18:0.15816,W15:0.15807,W13:0.15742,W7:0.10646,W3:0.09590,W21:0.07368,W2:0.04158,W1:0.02561 | memoryGatesShort:-8.530, Long:9.414, Current:0.116 | topTokens[(',', 60), ('.', 29), ('listening', 23), ('er', 21), ('a', 18), ('were', 17), ('the', 17), ('like', 16), ('me', 12), ('h', 10)] | Training
2025-04-05 19:59:21 | 5700 | LR0.0003 | loss:8.3740 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-69.1497 | logitMax:-51.9160 | windowWeightsW8:0.16600,W18:0.15861,W15:0.15841,W13:0.15742,W7:0.10647,W3:0.09542,W21:0.07415,W2:0.04135,W1:0.02525 | memoryGatesShort:3.435, Long:-2.419, Current:-0.016 | topTokens[(',', 86), ('a', 20), ('b', 11), ('am', 11), ('were', 10), ('the', 10), ('.', 9), ('but', 9), ('listening', 9), ('she', 8)] | Training
2025-04-05 20:05:54 | 5800 | LR0.0003 | loss:11.3108 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-80.3176 | logitMax:-57.8581 | windowWeightsW8:0.16597,W18:0.15892,W15:0.15865,W13:0.15754,W7:0.10651,W3:0.09505,W21:0.07432,W2:0.04096,W1:0.02515 | memoryGatesShort:0.807, Long:-0.433, Current:0.626 | topTokens[('it', 86), (',', 63), ('.', 35), ('a', 17), ('can', 16), ('in', 13), ('she', 8), ('had', 8), ('were', 6), ('am', 6)] | Training
2025-04-05 20:12:19 | 5900 | LR0.0003 | loss:8.9064 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-75.5383 | logitMax:-55.2854 | windowWeightsW8:0.16608,W18:0.15898,W15:0.15868,W13:0.15739,W7:0.10647,W3:0.09515,W21:0.07454,W2:0.04088,W1:0.02490 | memoryGatesShort:5.756, Long:-17.002, Current:12.246 | topTokens[(',', 53), ('.', 30), ('you', 22), ('it', 21), ('a', 18), ('me', 10), ('she', 10), ('b', 9), ('were', 9), ('like', 8)] | Training
2025-04-05 20:18:54 | 6000 | LR0.0003 | loss:5.7112 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-86.4198 | logitMax:-63.4053 | windowWeightsW8:0.16517,W18:0.15878,W15:0.15777,W13:0.15695,W7:0.10652,W3:0.09712,W21:0.07459,W2:0.04065,W1:0.02550 | memoryGatesShort:-15.293, Long:49.468, Current:-33.175 | topTokens[(',', 49), ('a', 18), ('you', 17), ('and', 17), ('.', 14), ('z', 12), ('ic', 10), ('is', 10), ('she', 9), ('i', 9)] | Training
2025-04-05 20:25:22 | 6100 | LR0.0003 | loss:7.0859 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-77.5578 | logitMax:-52.6233 | windowWeightsW8:0.16531,W18:0.15839,W15:0.15751,W13:0.15652,W7:0.10692,W3:0.09689,W21:0.07418,W2:0.04072,W1:0.02661 | memoryGatesShort:15.449, Long:-86.816, Current:72.367 | topTokens[(',', 69), ('and', 37), ('.', 23), ('a', 19), ('she', 16), ('s', 16), ('hear', 14), ('their', 13), ('we', 13), ('listening', 12)] | Training
2025-04-05 20:31:52 | 6200 | LR0.0003 | loss:6.4886 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-75.5890 | logitMax:-52.3305 | windowWeightsW8:0.16459,W18:0.15833,W15:0.15729,W13:0.15628,W7:0.10665,W3:0.09767,W21:0.07511,W2:0.04050,W1:0.02663 | memoryGatesShort:2.228, Long:-5.377, Current:4.149 | topTokens[('and', 69), (',', 54), ('.', 36), ('the', 30), ('kevin', 25), ('she', 18), ('elodie', 15), ('s', 12), ('a', 10), ('charis', 9)] | Training
2025-04-05 20:38:04 | 6300 | LR0.0003 | loss:7.8179 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-81.0083 | logitMax:-55.0037 | windowWeightsW8:0.16451,W18:0.15823,W15:0.15711,W13:0.15619,W7:0.10676,W3:0.09736,W21:0.07543,W2:0.04034,W1:0.02712 | memoryGatesShort:-0.550, Long:5.613, Current:-4.063 | topTokens[(',', 65), ('and', 42), ('kevin', 26), ('butt', 25), ('listening', 21), ('the', 20), ('.', 18), ('a', 15), ('elodie', 12), ('ta', 12)] | Training
2025-04-05 20:44:20 | 6400 | LR0.0003 | loss:6.2613 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-81.2017 | logitMax:-56.0901 | windowWeightsW8:0.16451,W18:0.15751,W15:0.15660,W13:0.15510,W7:0.10780,W3:0.09838,W21:0.07477,W2:0.04161,W1:0.02673 | memoryGatesShort:-1.819, Long:3.442, Current:-0.623 | topTokens[(',', 45), ('charis', 39), ('and', 39), ('ves', 34), ('my', 21), ('a', 20), ('.', 17), ('king', 16), ('hear', 15), ('she', 14)] | Training
2025-04-05 20:50:38 | 6500 | LR0.0003 | loss:8.8017 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-61.7198 | logitMax:-39.3696 | windowWeightsW8:0.16425,W18:0.15750,W15:0.15645,W13:0.15512,W7:0.10786,W3:0.09862,W21:0.07440,W2:0.04211,W1:0.02670 | memoryGatesShort:1.696, Long:-1.978, Current:1.282 | topTokens[(',', 51), ('my', 46), ('king', 36), ('.', 35), ('and', 35), ('ves', 30), ('a', 15), ('she', 12), ('charis', 11), ('his', 10)] | Training
2025-04-05 20:56:54 | 6600 | LR0.0003 | loss:3.5776 | gradNorm:0.9114 | tokenCount:400.0000 | logitMin:-75.0775 | logitMax:-4.8551 | windowWeightsW8:0.16787,W18:0.15758,W15:0.15639,W13:0.15410,W7:0.10845,W3:0.10014,W21:0.07281,W2:0.04115,W1:0.02456 | memoryGatesShort:-0.472, Long:14.441, Current:-12.969 | topTokens[('i', 52), ('it', 46), ('!', 41), ('.', 29), ('did', 23), ('hows', 22), (',', 18), ('?', 15), ('happy', 13), ("'m", 13)] | Training
2025-04-05 21:03:08 | 6700 | LR0.0003 | loss:8.3808 | gradNorm:0.9701 | tokenCount:400.0000 | logitMin:-64.0792 | logitMax:-28.9906 | windowWeightsW8:0.16708,W18:0.15784,W15:0.15607,W13:0.15347,W7:0.10905,W3:0.10042,W21:0.07486,W2:0.04085,W1:0.02347 | memoryGatesShort:4.374, Long:-5.958, Current:2.584 | topTokens[(',', 82), ('i', 36), ('.', 32), ('?', 15), ('a', 13), ('!', 12), ('it', 12), ('ves', 11), ('smo', 10), ('she', 9)] | Training
2025-04-05 21:09:27 | 6800 | LR0.0003 | loss:7.0348 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.2559 | logitMax:-52.3050 | windowWeightsW8:0.16677,W18:0.15803,W15:0.15604,W13:0.15341,W7:0.10887,W3:0.10020,W21:0.07535,W2:0.04078,W1:0.02366 | memoryGatesShort:3.379, Long:-4.867, Current:2.488 | topTokens[(',', 75), ('my', 31), ('.', 30), ('ves', 22), ('king', 22), ('a', 16), ('her', 15), ('lo', 14), ('kevin', 14), ('he', 11)] | Training
2025-04-05 21:15:44 | 6900 | LR0.0003 | loss:6.9037 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-69.7938 | logitMax:-50.8795 | windowWeightsW8:0.16658,W18:0.15832,W15:0.15627,W13:0.15338,W7:0.10864,W3:0.09976,W21:0.07580,W2:0.04055,W1:0.02381 | memoryGatesShort:0.991, Long:-1.480, Current:1.489 | topTokens[(',', 48), ('smo', 21), ('.', 21), ('a', 18), ('she', 18), ('charis', 18), ('is', 18), ('her', 12), ('to', 12), ('v', 12)] | Training
2025-04-05 21:21:58 | 7000 | LR0.0003 | loss:5.6304 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-87.8631 | logitMax:-66.7572 | windowWeightsW8:0.16663,W18:0.15852,W15:0.15621,W13:0.15340,W7:0.10861,W3:0.09994,W21:0.07547,W2:0.04045,W1:0.02389 | memoryGatesShort:-0.844, Long:9.285, Current:-7.441 | topTokens[(',', 40), ('and', 37), ('kevin', 26), ('the', 20), ('charis', 17), ('lea', 13), ('.', 12), ('smo', 11), ('ves', 10), ('she', 9)] | Training
2025-04-05 21:28:27 | 7100 | LR0.0003 | loss:6.8743 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-66.9977 | logitMax:-43.6878 | windowWeightsW8:0.16678,W18:0.15868,W15:0.15620,W13:0.15343,W7:0.10859,W3:0.09954,W21:0.07559,W2:0.04040,W1:0.02390 | memoryGatesShort:1.156, Long:-1.214, Current:1.058 | topTokens[(',', 51), ('and', 50), ('.', 26), ('a', 21), ('the', 20), ('lea', 16), ('were', 13), ('she', 12), ('am', 9), ('you', 8)] | Training
2025-04-05 21:34:48 | 7200 | LR0.0003 | loss:6.7964 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-77.1502 | logitMax:-58.6324 | windowWeightsW8:0.16659,W18:0.15872,W15:0.15608,W13:0.15324,W7:0.10832,W3:0.09941,W21:0.07636,W2:0.04043,W1:0.02398 | memoryGatesShort:4.346, Long:-6.052, Current:2.706 | topTokens[(',', 91), ('you', 32), ('and', 27), ('.', 27), ('is', 22), ('a', 18), ('their', 16), ('she', 14), ('ar', 10), ('elodie', 10)] | Training
2025-04-05 21:41:20 | 7300 | LR0.0003 | loss:8.4261 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.0727 | logitMax:-45.5008 | windowWeightsW8:0.16675,W18:0.15886,W15:0.15603,W13:0.15335,W7:0.10825,W3:0.09888,W21:0.07678,W2:0.04028,W1:0.02394 | memoryGatesShort:1.301, Long:-0.649, Current:0.347 | topTokens[(',', 62), ('.', 33), ('you', 17), ('is', 17), ('a', 14), ('my', 14), ('kevin', 12), ('your', 10), ('the', 9), ('she', 8)] | Training
2025-04-05 21:47:43 | 7400 | LR0.0003 | loss:7.9452 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-72.0145 | logitMax:-55.4476 | windowWeightsW8:0.16696,W18:0.15906,W15:0.15578,W13:0.15338,W7:0.10840,W3:0.09868,W21:0.07727,W2:0.03998,W1:0.02363 | memoryGatesShort:0.721, Long:-0.437, Current:0.717 | topTokens[('and', 45), ('my', 39), (',', 33), ('.', 28), ('a', 14), ('ing', 10), ('you', 9), ('in', 9), ('kevin', 8), ('about', 8)] | Training
2025-04-05 21:54:07 | 7500 | LR0.0003 | loss:7.6368 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-64.1134 | logitMax:-46.2457 | windowWeightsW8:0.16665,W18:0.15953,W15:0.15583,W13:0.15333,W7:0.10799,W3:0.09884,W21:0.07729,W2:0.04013,W1:0.02354 | memoryGatesShort:2.886, Long:-22.165, Current:20.279 | topTokens[(',', 51), ('that', 47), ('.', 36), ('it', 22), ('a', 17), ('she', 12), ('is', 10), ('in', 9), ('the', 9), ('and', 8)] | Training
2025-04-05 22:00:23 | 7600 | LR0.0003 | loss:10.6063 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-55.4143 | logitMax:-33.0475 | windowWeightsW8:0.16673,W18:0.15935,W15:0.15585,W13:0.15338,W7:0.10817,W3:0.09873,W21:0.07748,W2:0.04004,W1:0.02341 | memoryGatesShort:2.861, Long:-11.263, Current:9.402 | topTokens[('.', 43), (',', 43), ('and', 43), ('it', 32), ('that', 27), ('a', 16), ('am', 12), ('listening', 12), ('in', 10), ('she', 7)] | Training
2025-04-05 22:06:44 | 7700 | LR0.0003 | loss:8.5600 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-68.1055 | logitMax:-50.9806 | windowWeightsW8:0.16656,W18:0.15961,W15:0.15593,W13:0.15344,W7:0.10802,W3:0.09847,W21:0.07784,W2:0.03997,W1:0.02332 | memoryGatesShort:-4.130, Long:12.819, Current:-7.689 | topTokens[(',', 40), ('.', 38), ('and', 22), ('a', 20), ('i', 18), ('ct', 17), ('-', 11), ('that', 9), ('my', 9), ('b', 8)] | Training
2025-04-05 22:13:09 | 7800 | LR0.0003 | loss:7.3335 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-76.7743 | logitMax:-54.6074 | windowWeightsW8:0.16625,W18:0.16004,W15:0.15623,W13:0.15367,W7:0.10771,W3:0.09817,W21:0.07807,W2:0.03971,W1:0.02332 | memoryGatesShort:-0.480, Long:-3.289, Current:4.769 | topTokens[(',', 41), ('and', 33), ('.', 32), ('she', 19), ('so', 10), ('your', 10), ('to', 9), ('ves', 9), ('a', 8), ('l', 7)] | Training
2025-04-05 22:19:28 | 7900 | LR0.0003 | loss:4.9405 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-75.9618 | logitMax:-55.1359 | windowWeightsW8:0.16553,W18:0.16090,W15:0.15633,W13:0.15365,W7:0.10746,W3:0.09802,W21:0.07861,W2:0.03963,W1:0.02304 | memoryGatesShort:0.262, Long:-1.088, Current:1.825 | topTokens[(',', 56), ('the', 41), ('and', 29), ('he', 29), ('.', 24), ('we', 17), ('touch', 13), ('es', 11), ('phone', 11), ('a', 10)] | Training
2025-04-05 22:25:46 | 8000 | LR0.0003 | loss:5.7960 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-75.4343 | logitMax:-53.6814 | windowWeightsW8:0.16544,W18:0.16069,W15:0.15593,W13:0.15338,W7:0.10762,W3:0.09786,W21:0.07948,W2:0.03971,W1:0.02308 | memoryGatesShort:-1.110, Long:-5.898, Current:8.009 | topTokens[('and', 56), (',', 50), ('the', 43), ('.', 25), ('we', 16), ('she', 16), ('charis', 13), ('touch', 9), ('need', 8), ('he', 8)] | Training
2025-04-05 22:31:52 | 8100 | LR0.0003 | loss:5.8955 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.4842 | logitMax:-49.1221 | windowWeightsW8:0.16506,W18:0.16071,W15:0.15553,W13:0.15353,W7:0.10796,W3:0.09828,W21:0.07968,W2:0.03921,W1:0.02324 | memoryGatesShort:0.801, Long:-0.506, Current:0.706 | topTokens[(',', 56), ('kevin', 45), ('.', 30), ('and', 27), ('a', 18), ('need', 11), ('your', 11), ('he', 9), ('charis', 9), ('i', 8)] | Training
2025-04-05 22:38:06 | 8200 | LR0.0003 | loss:5.7976 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-77.1636 | logitMax:-54.6423 | windowWeightsW8:0.16473,W18:0.16047,W15:0.15551,W13:0.15346,W7:0.10721,W3:0.09957,W21:0.07923,W2:0.03967,W1:0.02334 | memoryGatesShort:-2.234, Long:8.659, Current:-5.425 | topTokens[('and', 89), (',', 49), ('.', 21), ('a', 17), ('elodie', 15), ('she', 12), ('kevin', 12), ('need', 11), ('hand', 11), ('you', 10)] | Training
2025-04-05 22:44:16 | 8300 | LR0.0003 | loss:6.7206 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-96.3238 | logitMax:-70.6460 | windowWeightsW8:0.16442,W18:0.16058,W15:0.15549,W13:0.15339,W7:0.10665,W3:0.09968,W21:0.07925,W2:0.03972,W1:0.02401 | memoryGatesShort:0.616, Long:-0.291, Current:0.674 | topTokens[('and', 47), (',', 42), ('.', 23), ('elodie', 20), ('he', 16), ('she', 13), ('touch', 12), ('you', 12), ('hear', 12), ('brain', 11)] | Training
2025-04-05 22:50:34 | 8400 | LR0.0003 | loss:5.8969 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-84.7857 | logitMax:-62.8186 | windowWeightsW8:0.16425,W18:0.16036,W15:0.15527,W13:0.15341,W7:0.10634,W3:0.10001,W21:0.07976,W2:0.03968,W1:0.02411 | memoryGatesShort:1.069, Long:-1.995, Current:1.927 | topTokens[(',', 76), ('and', 37), ('.', 26), ('elodie', 22), ('he', 21), ('a', 17), ('cks', 15), ('s', 14), ('they', 12), ('butt', 11)] | Training
2025-04-05 22:56:56 | 8500 | LR0.0003 | loss:5.3707 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-104.9440 | logitMax:-70.9127 | windowWeightsW8:0.16445,W18:0.16034,W15:0.15558,W13:0.15416,W7:0.10694,W3:0.09937,W21:0.07971,W2:0.03906,W1:0.02360 | memoryGatesShort:0.051, Long:-2.834, Current:3.783 | topTokens[(',', 47), ('and', 42), ('.', 23), ('they', 19), ('she', 12), ("'s", 12), ('charis', 11), ('the', 11), ('lear', 11), ('a', 9)] | Training
2025-04-05 23:03:09 | 8600 | LR0.0003 | loss:11.8424 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.7688 | logitMax:-33.0255 | windowWeightsW8:0.16515,W18:0.16090,W15:0.15502,W13:0.15412,W7:0.10626,W3:0.09832,W21:0.08035,W2:0.03837,W1:0.02476 | memoryGatesShort:-0.163, Long:6.733, Current:-5.570 | topTokens[('a', 76), (',', 50), ('they', 41), ('and', 31), ('a', 29), ('.', 29), ('their', 10), ('listen', 9), ('charis', 8), ('she', 8)] | Training
2025-04-05 23:09:28 | 8700 | LR0.0003 | loss:8.6990 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.7694 | logitMax:-26.9290 | windowWeightsW8:0.16467,W18:0.16085,W15:0.15469,W13:0.15382,W7:0.10578,W3:0.09890,W21:0.08027,W2:0.03856,W1:0.02567 | memoryGatesShort:-1.066, Long:17.729, Current:-15.664 | topTokens[('a', 95), (',', 55), ('.', 37), ('and', 24), ('she', 23), ('their', 14), ('they', 11), ('we', 10), ('think', 9), ('a', 9)] | Training
2025-04-05 23:15:57 | 8800 | LR0.0003 | loss:6.4799 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-75.9893 | logitMax:-48.3495 | windowWeightsW8:0.16460,W18:0.16049,W15:0.15444,W13:0.15320,W7:0.10580,W3:0.09916,W21:0.08062,W2:0.03838,W1:0.02652 | memoryGatesShort:0.498, Long:-6.025, Current:6.527 | topTokens[('a', 59), ('and', 37), (',', 31), ('charis', 26), ('.', 25), ('she', 17), ('v', 12), ('a', 11), ('s', 10), ('ta', 10)] | Training
2025-04-05 23:22:33 | 8900 | LR0.0003 | loss:6.9419 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-77.0689 | logitMax:-55.9279 | windowWeightsW8:0.16468,W18:0.16043,W15:0.15470,W13:0.15291,W7:0.10677,W3:0.09933,W21:0.08087,W2:0.03863,W1:0.02488 | memoryGatesShort:0.525, Long:-0.884, Current:1.358 | topTokens[(',', 33), ('.', 26), ('?', 23), ('i', 22), ('a', 22), ('my', 22), ('kevin', 20), ('charis', 18), ('she', 15), ('you', 15)] | Training
2025-04-05 23:28:44 | 9000 | LR0.0003 | loss:6.7461 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-63.1505 | logitMax:-34.0828 | windowWeightsW8:0.16436,W18:0.16055,W15:0.15439,W13:0.15314,W7:0.10640,W3:0.09938,W21:0.08121,W2:0.03840,W1:0.02537 | memoryGatesShort:0.493, Long:-1.320, Current:1.827 | topTokens[(',', 46), ('.', 40), ('you', 17), ('do', 16), ('kevin', 13), ('am', 13), ('?', 13), ('i', 13), ('her', 12), ('and', 11)] | Training
2025-04-05 23:35:27 | 9100 | LR0.0003 | loss:8.0185 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-74.6486 | logitMax:-47.7119 | windowWeightsW8:0.16426,W18:0.16058,W15:0.15467,W13:0.15293,W7:0.10661,W3:0.09951,W21:0.08135,W2:0.03844,W1:0.02486 | memoryGatesShort:2.681, Long:-1.242, Current:-0.440 | topTokens[('.', 42), (',', 36), ('do', 19), ('a', 19), ('kevin', 17), ('!', 17), ('a', 15), ('to', 13), ('and', 12), ('?', 11)] | Training

--- 2025-04-05 23:38:01 --- babyllm: 'what am i learning today?'- charis: 'i wrote you some mouse training data, omg i hope you like it aa!'
2025-04-05 23:44:01 | 100 | LR0.0003 | loss:7.9265 | gradNorm:1.0000 | logitMin:-69.1423 | logitMax:-50.6541 | tokenCount:400.0000 | windowWeightsW8:0.16299,W18:0.16194,W15:0.15580,W13:0.15297,W7:0.10537,W3:0.09849,W21:0.08193,W2:0.03794,W1:0.02577 | memoryGatesShort:-0.172, Long:3.589, Current:-2.418 | topTokens[(',', 51), ('.', 32), ('a', 29), ('to', 19), ('is', 16), ('a', 14), ('?', 13), ('!', 13), ('charis', 12), ('and', 12)] | Training
2025-04-05 23:50:16 | 200 | LR0.0003 | loss:8.7460 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-72.0693 | logitMax:-49.8075 | windowWeightsW8:0.16246,W18:0.16183,W15:0.15553,W13:0.15265,W7:0.10635,W3:0.09793,W21:0.08268,W2:0.03806,W1:0.02573 | memoryGatesShort:-0.803, Long:4.867, Current:-3.063 | topTokens[(',', 40), ('.', 29), ('!', 29), ('a', 20), ('s', 20), ('to', 17), ('they', 14), ('a', 13), ('she', 11), ('you', 11)] | Training
2025-04-05 23:56:23 | 300 | LR0.0003 | loss:7.1254 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-73.9232 | logitMax:-55.9182 | windowWeightsW8:0.16236,W18:0.16217,W15:0.15586,W13:0.15280,W7:0.10655,W3:0.09849,W21:0.08334,W2:0.03694,W1:0.02473 | memoryGatesShort:0.892, Long:-0.334, Current:0.443 | topTokens[(',', 48), ('the', 39), ('.', 30), ('a', 26), ('!', 21), ('she', 12), ('p', 12), ('it', 9), ('was', 9), ('and', 8)] | Training
2025-04-06 00:02:40 | 400 | LR0.0003 | loss:7.4336 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-79.4334 | logitMax:-62.1061 | windowWeightsW18:0.16376,W8:0.16201,W15:0.15625,W13:0.15352,W7:0.10712,W3:0.09650,W21:0.08584,W2:0.03450,W1:0.02377 | memoryGatesShort:0.714, Long:-0.354, Current:0.641 | topTokens[(',', 42), ('!', 30), ('.', 25), ('a', 24), ('the', 22), ('m', 17), ('in', 15), ('she', 11), ('we', 10), ('is', 10)] | Training
2025-04-06 00:09:03 | 500 | LR0.0003 | loss:7.8657 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.5926 | logitMax:-40.7422 | windowWeightsW18:0.16392,W8:0.16138,W15:0.15670,W13:0.15460,W7:0.10860,W3:0.09531,W21:0.08667,W2:0.03318,W1:0.02296 | memoryGatesShort:1.954, Long:-11.154, Current:10.200 | topTokens[(',', 59), ('!', 30), ('the', 26), ('.', 21), ('a', 18), ('m', 16), ('we', 13), ('she', 10), ('am', 7), ('i', 7)] | Training
2025-04-06 00:15:35 | 600 | LR0.0003 | loss:7.8612 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-81.2510 | logitMax:-59.4757 | windowWeightsW18:0.16461,W8:0.16115,W15:0.15688,W13:0.15454,W7:0.10840,W3:0.09478,W21:0.08748,W2:0.03277,W1:0.02271 | memoryGatesShort:0.300, Long:-0.089, Current:0.790 | topTokens[('!', 52), (',', 39), ('it', 35), ('the', 32), ('a', 20), ('.', 15), ('in', 13), ('am', 12), ('ood', 9), ('ouse', 8)] | Training
2025-04-06 00:22:18 | 700 | LR0.0003 | loss:4.6263 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-89.4668 | logitMax:-63.1416 | windowWeightsW18:0.16476,W8:0.16002,W15:0.15511,W13:0.15240,W7:0.10952,W3:0.09333,W21:0.08756,W2:0.03620,W1:0.02441 | memoryGatesShort:-0.910, Long:-3.538, Current:5.448 | topTokens[('it', 59), ('!', 43), ('have', 32), ('know', 30), (',', 27), ('must', 23), ('he', 21), ('.', 14), ('a', 13), ('felt', 13)] | Training
2025-04-06 00:28:56 | 800 | LR0.0003 | loss:6.7288 | gradNorm:0.9599 | tokenCount:400.0000 | logitMin:-100.8793 | logitMax:-52.1011 | windowWeightsW18:0.16295,W8:0.16037,W15:0.15497,W13:0.15170,W7:0.10979,W3:0.09364,W21:0.08887,W2:0.03558,W1:0.02545 | memoryGatesShort:-0.308, Long:-3.672, Current:4.981 | topTokens[('have', 50), ('must', 48), ('!', 47), ('it', 40), ('kevin', 26), ('done', 26), ('.', 21), ('know', 15), ('n', 15), ('elodie', 15)] | Training
2025-04-06 00:35:13 | 900 | LR0.0003 | loss:6.2290 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-75.3646 | logitMax:-39.2940 | windowWeightsW18:0.16221,W8:0.16190,W15:0.15419,W13:0.15094,W7:0.10985,W3:0.09315,W21:0.08911,W2:0.03554,W1:0.02639 | memoryGatesShort:0.751, Long:-1.214, Current:1.463 | topTokens[(',', 63), ('it', 54), ('!', 38), ('have', 31), ('been', 30), ('kevin', 18), ('elodie', 15), ('saying', 15), ('a', 13), ('just', 13)] | Training
2025-04-06 00:41:26 | 1000 | LR0.0003 | loss:3.5351 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-64.2704 | logitMax:-38.0109 | windowWeightsW18:0.16229,W8:0.16182,W15:0.15361,W13:0.15044,W7:0.10886,W3:0.09408,W21:0.08934,W2:0.03599,W1:0.02683 | memoryGatesShort:1.515, Long:22.526, Current:-23.041 | topTokens[('!', 45), ('been', 39), ('has', 38), ('it', 35), (',', 33), ('kevin', 31), ('a', 24), ('being', 22), ('elodie', 21), ('have', 19)] | Training
2025-04-06 00:47:57 | 1100 | LR0.0003 | loss:5.0858 | gradNorm:0.9815 | tokenCount:400.0000 | logitMin:-74.4009 | logitMax:-23.1588 | windowWeightsW8:0.16294,W18:0.16163,W15:0.15266,W13:0.14915,W7:0.10932,W3:0.09452,W21:0.08864,W2:0.03721,W1:0.02715 | memoryGatesShort:0.305, Long:-0.222, Current:0.917 | topTokens[('been', 56), ('it', 47), ('!', 46), ('know', 23), ('ing', 22), ('have', 21), (',', 21), ('elodie', 17), ('kevin', 14), ('feeling', 13)] | Training
2025-04-06 00:54:06 | 1200 | LR0.0003 | loss:12.9701 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-58.8527 | logitMax:-28.8791 | windowWeightsW8:0.16225,W18:0.16207,W15:0.15305,W13:0.14937,W7:0.10942,W3:0.09406,W21:0.08911,W2:0.03716,W1:0.02674 | memoryGatesShort:-18.598, Long:52.562, Current:-32.964 | topTokens[('it', 74), (',', 43), ('.', 40), ('they', 39), ('have', 21), ('doing', 18), ('she', 17), ('!', 16), ('listening', 11), ('a', 8)] | Training
2025-04-06 01:00:17 | 1300 | LR0.0003 | loss:11.8154 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-82.2295 | logitMax:-58.1205 | windowWeightsW18:0.16227,W8:0.16208,W15:0.15302,W13:0.14946,W7:0.10931,W3:0.09390,W21:0.08924,W2:0.03712,W1:0.02683 | memoryGatesShort:-1.141, Long:1.978, Current:0.163 | topTokens[('it', 51), ('she', 50), (',', 42), ('me', 33), ('they', 30), ('for', 26), ('.', 24), ('and', 15), ('have', 9), ('in', 8)] | Training
2025-04-06 01:07:03 | 1400 | LR0.0003 | loss:12.8968 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-73.9038 | logitMax:-46.4094 | windowWeightsW18:0.16219,W8:0.16202,W15:0.15295,W13:0.14943,W7:0.10944,W3:0.09377,W21:0.08952,W2:0.03702,W1:0.02689 | memoryGatesShort:1.656, Long:-1.111, Current:0.454 | topTokens[('she', 81), ('it', 24), (',', 22), ('they', 19), ('.', 17), ('have', 17), ('and', 14), ('for', 14), ('listening', 9), ('a', 9)] | Training
2025-04-06 01:14:00 | 1500 | LR0.0003 | loss:8.9529 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-67.1774 | logitMax:-49.9512 | windowWeightsW18:0.16241,W8:0.16208,W15:0.15286,W13:0.14929,W7:0.10951,W3:0.09367,W21:0.08974,W2:0.03697,W1:0.02672 | memoryGatesShort:2.676, Long:-3.332, Current:1.656 | topTokens[(',', 66), ('a', 26), ('.', 26), ('it', 20), ('she', 18), ('they', 14), ('have', 13), ('and', 10), ('your', 9), ('the', 9)] | Training
2025-04-06 01:20:29 | 1600 | LR0.0003 | loss:8.7050 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-74.4074 | logitMax:-54.5893 | windowWeightsW18:0.16253,W8:0.16229,W15:0.15265,W13:0.14922,W7:0.10944,W3:0.09349,W21:0.09029,W2:0.03674,W1:0.02659 | memoryGatesShort:1.401, Long:-4.166, Current:3.766 | topTokens[('.', 35), (',', 32), ('she', 21), ('a', 20), ('ed', 15), ('to', 14), ('and', 13), ('charis', 13), ('me', 12), ('ing', 11)] | Training
2025-04-06 01:27:42 | 1700 | LR0.0003 | loss:8.5271 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-75.3211 | logitMax:-57.3789 | windowWeightsW18:0.16322,W8:0.16208,W15:0.15302,W13:0.14922,W7:0.10926,W3:0.09320,W21:0.09054,W2:0.03665,W1:0.02607 | memoryGatesShort:0.251, Long:-0.622, Current:1.370 | topTokens[(',', 40), ('a', 37), ('.', 36), ('to', 32), ('me', 29), ('she', 28), ('ed', 14), ('ly', 13), ('ing', 12), ('!', 10)] | Training
2025-04-06 01:35:37 | 1800 | LR0.0003 | loss:7.9402 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-79.0551 | logitMax:-53.6108 | windowWeightsW18:0.16283,W8:0.16086,W15:0.15330,W13:0.14926,W7:0.10887,W3:0.09426,W21:0.09051,W2:0.03698,W1:0.02638 | memoryGatesShort:0.488, Long:-1.250, Current:1.762 | topTokens[(',', 50), ('and', 39), ('the', 27), ('she', 22), ('we', 15), ('.', 15), ('way', 12), ('s', 11), ('listening', 11), ('have', 10)] | Training
2025-04-06 01:42:46 | 1900 | LR0.0003 | loss:5.6179 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-73.5301 | logitMax:-53.2635 | windowWeightsW18:0.16259,W8:0.16032,W15:0.15316,W13:0.14903,W7:0.10953,W3:0.09413,W21:0.09107,W2:0.03699,W1:0.02644 | memoryGatesShort:-0.828, Long:-4.737, Current:6.565 | topTokens[(',', 69), ('the', 20), ('and', 19), ('weed', 16), ('charis', 16), ('a', 16), ('.', 16), ('their', 12), ('!', 12), ('an', 11)] | Training
2025-04-06 01:50:03 | 2000 | LR0.0003 | loss:6.4970 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-89.6486 | logitMax:-63.0357 | windowWeightsW18:0.16237,W8:0.15963,W15:0.15290,W13:0.14836,W7:0.11025,W3:0.09437,W21:0.09093,W2:0.03728,W1:0.02715 | memoryGatesShort:-3.457, Long:-5.523, Current:9.980 | topTokens[(',', 68), ('and', 29), ('.', 18), ('charis', 17), ('her', 15), ('es', 13), ('oice', 12), ('butt', 11), ('but', 11), ('a', 10)] | Training
2025-04-06 01:57:31 | 2100 | LR0.0003 | loss:5.9227 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.9203 | logitMax:-44.6076 | windowWeightsW18:0.16147,W8:0.15870,W15:0.15222,W13:0.14742,W7:0.11100,W3:0.09600,W21:0.09111,W2:0.03773,W1:0.02756 | memoryGatesShort:0.268, Long:-0.913, Current:1.645 | topTokens[(',', 59), ('and', 38), ('u', 26), ('.', 19), ('she', 18), ('a', 15), ('we', 13), ('elodie', 13), ('v', 11), ('want', 10)] | Training
2025-04-06 02:04:56 | 2200 | LR0.0003 | loss:7.4814 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-70.4848 | logitMax:-41.3255 | windowWeightsW18:0.16148,W8:0.15762,W15:0.15170,W13:0.14721,W7:0.11148,W3:0.09567,W21:0.09146,W2:0.03863,W1:0.02794 | memoryGatesShort:0.556, Long:-0.392, Current:0.836 | topTokens[(',', 47), ('and', 36), ('.', 27), ('v', 21), ('u', 17), ('elodie', 16), ('she', 15), ('my', 14), ('a', 14), ('to', 12)] | Training
2025-04-06 02:12:13 | 2300 | LR0.0003 | loss:6.1909 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-58.6627 | logitMax:-30.7305 | windowWeightsW18:0.16156,W8:0.15819,W15:0.15205,W13:0.14665,W7:0.11002,W3:0.09643,W21:0.09144,W2:0.03935,W1:0.02748 | memoryGatesShort:0.519, Long:-1.753, Current:2.234 | topTokens[(',', 35), ('.', 34), ('to', 21), ('a', 20), ('her', 14), ('elodie', 11), ('?', 11), ('and', 10), ('he', 10), ('listening', 9)] | Training
2025-04-06 02:19:48 | 2400 | LR0.0003 | loss:5.0977 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-76.0127 | logitMax:-45.8220 | windowWeightsW18:0.16114,W8:0.15823,W15:0.15206,W13:0.14692,W7:0.10925,W3:0.09677,W21:0.09136,W2:0.04014,W1:0.02731 | memoryGatesShort:0.421, Long:-0.482, Current:1.061 | topTokens[('to', 31), ('.', 23), (',', 20), ('?', 20), ('listening', 17), ('she', 14), ('will', 14), ('i', 12), ('kevin', 12), ('a', 12)] | Training
2025-04-06 02:27:48 | 2500 | LR0.0003 | loss:7.0826 | gradNorm:0.9931 | tokenCount:400.0000 | logitMin:-61.7445 | logitMax:-34.4218 | windowWeightsW18:0.16117,W8:0.15820,W15:0.15161,W13:0.14625,W7:0.10707,W3:0.09785,W21:0.09145,W2:0.04216,W1:0.02738 | memoryGatesShort:0.640, Long:-0.869, Current:1.229 | topTokens[('listening', 45), (',', 43), ('you', 31), ('.', 23), ('to', 22), ('will', 17), ('a', 12), ('is', 11), ('she', 10), ('music', 10)] | Training
2025-04-06 02:35:02 | 2600 | LR0.0003 | loss:5.7268 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-63.2422 | logitMax:-34.4730 | windowWeightsW18:0.16103,W8:0.15803,W15:0.15073,W13:0.14446,W7:0.10828,W3:0.09887,W21:0.09166,W2:0.04242,W1:0.02761 | memoryGatesShort:22.574, Long:-41.990, Current:20.416 | topTokens[('.', 31), ('to', 30), (',', 28), ('an', 24), ('listening', 22), ('you', 16), ('?', 16), ('she', 16), ('s', 15), ('was', 14)] | Training

--- 2025-04-06 02:38:58 --- babyllm: 'what am i learning today?'- charis: 'fresh data pull, still madness, youre doing good tho well done!'
2025-04-06 02:44:47 | 100 | LR0.0003 | loss:9.1518 | gradNorm:1.0000 | logitMin:-69.0278 | logitMax:-48.8066 | tokenCount:400.0000 | windowWeightsW18:0.16162,W8:0.15623,W15:0.15121,W13:0.14599,W7:0.10815,W3:0.09938,W21:0.09213,W2:0.04118,W1:0.02727 | memoryGatesShort:1.315, Long:-1.058, Current:0.744 | topTokens[('an', 33), (',', 28), ('.', 25), ('to', 24), ('it', 22), ('a', 18), ('ll', 17), ('ace', 15), ('you', 15), ('?', 12)] | Training
2025-04-06 02:50:40 | 200 | LR0.0003 | loss:8.8750 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-90.1748 | logitMax:-68.5399 | windowWeightsW18:0.16138,W8:0.15649,W15:0.15184,W13:0.14646,W7:0.10864,W3:0.09934,W21:0.09167,W2:0.04088,W1:0.02648 | memoryGatesShort:0.708, Long:-0.768, Current:1.060 | topTokens[(',', 46), ('to', 30), ('.', 25), ('!', 21), ('a', 20), ('she', 15), ('in', 15), ('it', 14), ('he', 14), ('p', 12)] | Training
2025-04-06 02:56:30 | 300 | LR0.0003 | loss:7.6336 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-75.3269 | logitMax:-54.5285 | windowWeightsW18:0.16195,W8:0.15630,W15:0.15130,W13:0.14678,W7:0.10926,W3:0.09860,W21:0.09252,W2:0.03937,W1:0.02710 | memoryGatesShort:0.484, Long:-2.147, Current:2.663 | topTokens[(',', 50), ('!', 25), ('the', 23), ('.', 22), ('it', 17), ('a', 17), ('ered', 9), ('they', 9), ('ace', 9), ('way', 9)] | Training
2025-04-06 03:02:22 | 400 | LR0.0003 | loss:7.6994 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-73.4962 | logitMax:-50.5719 | windowWeightsW18:0.16232,W8:0.15540,W15:0.15149,W13:0.14707,W7:0.10900,W3:0.09896,W21:0.09352,W2:0.03893,W1:0.02652 | memoryGatesShort:0.708, Long:-2.261, Current:2.552 | topTokens[('the', 53), ('.', 39), (',', 37), ('a', 20), ('in', 19), ('!', 16), ('it', 16), ('felt', 10), ('she', 9), ('s', 8)] | Training
2025-04-06 03:08:10 | 500 | LR0.0003 | loss:7.5301 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-87.6334 | logitMax:-64.6616 | windowWeightsW18:0.16247,W8:0.15476,W15:0.15078,W13:0.14720,W7:0.10942,W3:0.09950,W21:0.09347,W2:0.03865,W1:0.02695 | memoryGatesShort:0.515, Long:-0.572, Current:1.056 | topTokens[(',', 49), ('the', 37), ('.', 24), ('!', 20), ('it', 18), ('in', 13), ('to', 13), ('ed', 12), ('been', 12), ('were', 10)] | Training
2025-04-06 03:14:19 | 600 | LR0.0003 | loss:7.1962 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-76.8943 | logitMax:-56.6028 | windowWeightsW18:0.16368,W8:0.15442,W15:0.15199,W13:0.14727,W7:0.10857,W3:0.09936,W21:0.09380,W2:0.03882,W1:0.02533 | memoryGatesShort:0.708, Long:-0.129, Current:0.421 | topTokens[('!', 39), ('angle', 34), (',', 31), ('.', 24), ('d', 20), ('for', 13), ('she', 13), ('a', 13), ('lo', 9), ('m', 8)] | Training
2025-04-06 03:20:09 | 700 | LR0.0003 | loss:7.8261 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-91.2949 | logitMax:-65.9851 | windowWeightsW18:0.16445,W15:0.15231,W8:0.15226,W13:0.14777,W7:0.10973,W3:0.09759,W21:0.09503,W2:0.03872,W1:0.02539 | memoryGatesShort:-0.084, Long:8.216, Current:-7.132 | topTokens[(',', 48), ('!', 42), ('have', 22), ('it', 18), ('angle', 15), ('a', 15), ('.', 15), ('be', 12), ('an', 12), ('lo', 9)] | Training
2025-04-06 03:26:00 | 800 | LR0.0003 | loss:4.8155 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-101.3674 | logitMax:-73.5385 | windowWeightsW18:0.16542,W15:0.15248,W8:0.15143,W13:0.14829,W7:0.10933,W3:0.09726,W21:0.09558,W2:0.03804,W1:0.02543 | memoryGatesShort:0.647, Long:-3.155, Current:3.508 | topTokens[('!', 51), ('it', 48), ('have', 47), ('.', 20), ('done', 18), ('and', 16), ('kevin', 15), ('been', 14), ('charis', 13), ('be', 12)] | Training
2025-04-06 03:31:53 | 900 | LR0.0003 | loss:6.3326 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-79.6536 | logitMax:-56.0489 | windowWeightsW18:0.16593,W15:0.15280,W8:0.15106,W13:0.14875,W7:0.10866,W3:0.09668,W21:0.09605,W2:0.03747,W1:0.02586 | memoryGatesShort:0.306, Long:-0.638, Current:1.332 | topTokens[('it', 77), ('!', 40), (',', 39), ('.', 32), ('have', 31), ('done', 17), ('elodie', 13), ('been', 11), ('a', 11), ('charis', 11)] | Training
2025-04-06 03:37:44 | 1000 | LR0.0003 | loss:8.6480 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-93.2654 | logitMax:-57.0200 | windowWeightsW18:0.16612,W15:0.15239,W8:0.15122,W13:0.14949,W7:0.10928,W21:0.09646,W3:0.09607,W2:0.03671,W1:0.02554 | memoryGatesShort:0.356, Long:-1.844, Current:2.488 | topTokens[('felt', 83), ('!', 34), (',', 33), ('it', 20), ('have', 19), ('been', 16), ('.', 14), ('he', 13), ('we', 12), ('elodie', 12)] | Training
2025-04-06 03:43:35 | 1100 | LR0.0003 | loss:5.9379 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-70.3833 | logitMax:-47.8235 | windowWeightsW18:0.16616,W15:0.15209,W8:0.15146,W13:0.14964,W7:0.10854,W3:0.09660,W21:0.09590,W2:0.03745,W1:0.02543 | memoryGatesShort:1.115, Long:-0.882, Current:0.767 | topTokens[('!', 49), ('have', 45), ('it', 39), ('.', 29), (',', 20), ('charis', 18), ('must', 18), ('elodie', 15), ('a', 12), ('he', 11)] | Training
2025-04-06 03:49:42 | 1200 | LR0.0003 | loss:8.6510 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-73.4111 | logitMax:-57.7396 | windowWeightsW18:0.16710,W15:0.15278,W8:0.15156,W13:0.14974,W7:0.10784,W21:0.09694,W3:0.09525,W2:0.03705,W1:0.02503 | memoryGatesShort:0.315, Long:-3.003, Current:3.688 | topTokens[(',', 77), ('!', 39), ('have', 36), ('a', 27), ('.', 20), ('it', 14), ('she', 14), ('know', 12), ('m', 11), ('was', 9)] | Training
2025-04-06 03:55:35 | 1300 | LR0.0003 | loss:7.8164 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-64.9271 | logitMax:-49.4034 | windowWeightsW18:0.16714,W15:0.15288,W8:0.15167,W13:0.14976,W7:0.10804,W21:0.09696,W3:0.09525,W2:0.03693,W1:0.02468 | memoryGatesShort:1.804, Long:-1.202, Current:0.399 | topTokens[(',', 84), ('.', 32), ('can', 24), ('!', 18), ('it', 18), ('a', 18), ('i', 15), ('elodie', 12), ('to', 11), ('in', 10)] | Training
2025-04-06 04:01:23 | 1400 | LR0.0003 | loss:7.9302 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-80.1085 | logitMax:-63.7092 | windowWeightsW18:0.16746,W15:0.15296,W8:0.15161,W13:0.14971,W7:0.10808,W21:0.09739,W3:0.09501,W2:0.03687,W1:0.02424 | memoryGatesShort:0.624, Long:-0.308, Current:0.684 | topTokens[(',', 85), ('i', 34), ('.', 25), ('it', 17), ('she', 16), ('have', 15), ('n', 10), ('a', 8), ('r', 8), ('in', 8)] | Training
2025-04-06 04:07:16 | 1500 | LR0.0003 | loss:8.9166 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.1648 | logitMax:-51.9523 | windowWeightsW18:0.16749,W15:0.15359,W8:0.15157,W13:0.15005,W7:0.10785,W21:0.09760,W3:0.09478,W2:0.03690,W1:0.02351 | memoryGatesShort:-0.100, Long:-1.176, Current:2.276 | topTokens[('t', 114), (',', 69), ('i', 32), ('she', 25), ('.', 24), ('a', 14), ('b', 7), ('have', 7), ('am', 6), ('!', 5)] | Training
2025-04-06 04:13:19 | 1600 | LR0.0003 | loss:8.8342 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-91.9586 | logitMax:-70.7992 | windowWeightsW18:0.16744,W15:0.15377,W8:0.15248,W13:0.15008,W7:0.10742,W21:0.09754,W3:0.09415,W2:0.03684,W1:0.02362 | memoryGatesShort:-0.615, Long:-1.070, Current:2.685 | topTokens[(',', 94), ('.', 25), ('i', 21), ('t', 20), ('hh', 15), ('a', 14), ('she', 13), ('am', 12), ('y', 8), ('im', 7)] | Training
2025-04-06 04:20:09 | 1700 | LR0.0003 | loss:7.0658 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-83.5972 | logitMax:-67.9445 | windowWeightsW18:0.16745,W15:0.15339,W8:0.15315,W13:0.15024,W7:0.10718,W21:0.09826,W3:0.09343,W2:0.03692,W1:0.02333 | memoryGatesShort:-0.833, Long:0.336, Current:1.497 | topTokens[(',', 111), ('t', 49), ('im', 32), ('lmao', 28), ('.', 12), ('i', 12), ('a', 9), ('she', 9), ('to', 8), ('me', 6)] | Training
2025-04-06 04:26:44 | 1800 | LR0.0003 | loss:6.6212 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.4953 | logitMax:-47.7423 | windowWeightsW18:0.16707,W15:0.15289,W8:0.15259,W13:0.15008,W7:0.10836,W21:0.09887,W3:0.09276,W2:0.03715,W1:0.02358 | memoryGatesShort:-0.710, Long:-0.475, Current:2.185 | topTokens[(',', 59), ('she', 35), ('.', 29), ('and', 17), ('elodie', 16), ('t', 15), ('us', 13), ('a', 11), ('im', 10), ('listening', 9)] | Training
2025-04-06 04:33:07 | 1900 | LR0.0003 | loss:6.3603 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-80.5178 | logitMax:-55.7515 | windowWeightsW18:0.16663,W15:0.15271,W8:0.15247,W13:0.15016,W7:0.10768,W21:0.09918,W3:0.09377,W2:0.03729,W1:0.02347 | memoryGatesShort:-1.274, Long:-1.804, Current:4.078 | topTokens[(',', 51), ('and', 38), ('a', 16), ('.', 16), ('she', 15), ('elodie', 14), ('listening', 11), ('her', 11), ('to', 10), ('ll', 10)] | Training
2025-04-06 04:39:07 | 2000 | LR0.0003 | loss:6.2654 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-78.5124 | logitMax:-53.4408 | windowWeightsW18:0.16627,W15:0.15287,W8:0.15178,W13:0.14976,W7:0.10767,W21:0.09940,W3:0.09376,W2:0.03716,W1:0.02465 | memoryGatesShort:-0.083, Long:-0.281, Current:1.364 | topTokens[(',', 56), ('and', 40), ('.', 29), ('he', 20), ('charis', 17), ('the', 15), ('she', 14), ('your', 14), ('her', 10), ('es', 10)] | Training
2025-04-06 04:44:54 | 2100 | LR0.0003 | loss:4.7761 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-79.2658 | logitMax:-55.6408 | windowWeightsW18:0.16867,W15:0.15376,W8:0.15082,W13:0.14976,W7:0.10752,W21:0.10119,W3:0.09179,W2:0.03631,W1:0.02356 | memoryGatesShort:0.165, Long:-0.652, Current:1.487 | topTokens[(',', 59), ('and', 38), ('touch', 26), ('charis', 21), ('the', 17), ('you', 17), ('to', 13), ('.', 12), ('s', 11), ('es', 10)] | Training
2025-04-06 04:50:43 | 2200 | LR0.0003 | loss:6.7597 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-67.5460 | logitMax:-43.5764 | windowWeightsW18:0.16870,W15:0.15348,W8:0.15161,W13:0.14977,W7:0.10768,W21:0.10159,W3:0.09127,W2:0.03570,W1:0.02357 | memoryGatesShort:0.122, Long:-0.564, Current:1.442 | topTokens[(',', 41), ('she', 21), ('.', 20), ('the', 19), ('but', 18), ('butt', 17), ('a', 17), ('know', 13), ('like', 12), ('ur', 11)] | Training
2025-04-06 04:56:54 | 2300 | LR0.0003 | loss:5.5971 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-88.8318 | logitMax:-62.1003 | windowWeightsW18:0.16646,W8:0.15328,W15:0.15217,W13:0.14952,W7:0.10819,W21:0.10079,W3:0.09260,W2:0.03660,W1:0.02374 | memoryGatesShort:-0.845, Long:-6.195, Current:8.040 | topTokens[(',', 46), ('and', 19), ('she', 18), ('.', 17), ('you', 15), ('to', 15), ('weed', 14), ('kevin', 14), ('?', 12), ('your', 10)] | Training
2025-04-06 05:02:41 | 2400 | LR0.0003 | loss:6.1324 | gradNorm:0.9911 | tokenCount:400.0000 | logitMin:-61.4901 | logitMax:-30.3579 | windowWeightsW18:0.16521,W8:0.15528,W15:0.14994,W13:0.14884,W7:0.10994,W21:0.09919,W3:0.09438,W2:0.03841,W1:0.02216 | memoryGatesShort:1.360, Long:-1.300, Current:0.940 | topTokens[('been', 24), ('listening', 24), ('to', 24), ('.', 22), (',', 21), ('look', 20), ('?', 19), ('had', 16), ('music', 15), ('not', 15)] | Training
2025-04-06 05:08:30 | 2500 | LR0.0003 | loss:3.4538 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-76.3204 | logitMax:-48.2032 | windowWeightsW18:0.16414,W8:0.15609,W15:0.14983,W13:0.14966,W7:0.11023,W21:0.09860,W3:0.09357,W2:0.03930,W1:0.02193 | memoryGatesShort:3.286, Long:-4.469, Current:2.183 | topTokens[('listening', 33), ('to', 30), ('music', 29), ('will', 26), (',', 23), ('?', 23), ('you', 18), ('.', 14), ('she', 14), ('i', 14)] | Training
2025-04-06 05:14:20 | 2600 | LR0.0003 | loss:4.9927 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-63.6301 | logitMax:-37.2783 | windowWeightsW18:0.16362,W8:0.15692,W13:0.15047,W15:0.14961,W7:0.10948,W21:0.09885,W3:0.09417,W2:0.03885,W1:0.02138 | memoryGatesShort:-0.521, Long:-1.997, Current:3.518 | topTokens[('music', 43), ('.', 33), (',', 29), ('?', 21), ('had', 20), ('it', 19), ('listening', 18), ('been', 17), ('to', 15), ('will', 15)] | Training
2025-04-06 05:20:17 | 2700 | LR0.0003 | loss:4.9750 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.1844 | logitMax:-28.4081 | windowWeightsW18:0.16355,W8:0.15752,W13:0.15122,W15:0.14968,W7:0.10997,W21:0.09907,W3:0.09394,W2:0.03794,W1:0.02047 | memoryGatesShort:0.664, Long:1.904, Current:-1.568 | topTokens[('music', 45), ('she', 41), (',', 40), ('to', 29), ('listening', 22), ('.', 21), ('been', 17), ('will', 16), ('?', 14), ('be', 11)] | Training
2025-04-06 05:26:14 | 2800 | LR0.0003 | loss:9.8797 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-67.0408 | logitMax:-40.9732 | windowWeightsW18:0.16372,W8:0.15720,W13:0.15111,W15:0.14974,W7:0.11054,W21:0.09979,W3:0.09352,W2:0.03767,W1:0.02009 | memoryGatesShort:0.758, Long:-1.048, Current:1.290 | topTokens[(',', 48), ('she', 36), ('it', 33), ('.', 25), ('been', 22), ('a', 16), ('ered', 15), ('p', 14), ('to', 11), ('ad', 11)] | Training
2025-04-06 05:32:20 | 2900 | LR0.0003 | loss:7.9408 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-82.7584 | logitMax:-61.2698 | windowWeightsW18:0.16411,W8:0.15696,W13:0.15126,W15:0.14977,W7:0.11038,W21:0.10019,W3:0.09336,W2:0.03755,W1:0.01981 | memoryGatesShort:0.887, Long:-0.879, Current:0.991 | topTokens[(',', 69), ('it', 32), ('p', 26), ('she', 19), ('ered', 17), ('.', 14), ('a', 10), ('ouse', 8), ('in', 8), ('music', 7)] | Training
2025-04-06 05:38:06 | 3000 | LR0.0003 | loss:7.6390 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-80.1311 | logitMax:-59.7623 | windowWeightsW18:0.16409,W8:0.15612,W13:0.15203,W15:0.15005,W7:0.11023,W21:0.10026,W3:0.09295,W2:0.03722,W1:0.02046 | memoryGatesShort:1.565, Long:-1.659, Current:1.095 | topTokens[(',', 58), ('.', 22), ('a', 22), ('she', 21), ('knew', 20), ('ve', 19), ('p', 17), ('to', 17), ('in', 14), ('been', 10)] | Training
2025-04-06 05:43:54 | 3100 | LR0.0003 | loss:7.5726 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-81.1597 | logitMax:-61.5026 | windowWeightsW18:0.16479,W8:0.15589,W13:0.15208,W15:0.15077,W7:0.11009,W21:0.10107,W3:0.09200,W2:0.03653,W1:0.02020 | memoryGatesShort:0.113, Long:-1.990, Current:2.877 | topTokens[(',', 59), ('she', 29), ('!', 25), ('.', 22), ('ve', 19), ('p', 12), ('i', 12), ('knew', 12), ('to', 11), ('a', 11)] | Training
2025-04-06 05:49:42 | 3200 | LR0.0003 | loss:6.8982 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-83.4149 | logitMax:-60.3717 | windowWeightsW18:0.16445,W8:0.15633,W13:0.15157,W15:0.15041,W7:0.11068,W21:0.10180,W3:0.09168,W2:0.03635,W1:0.02016 | memoryGatesShort:1.090, Long:-7.606, Current:7.516 | topTokens[(',', 44), ('!', 27), ('knew', 26), ('the', 24), ('.', 22), ('w', 19), ('ood', 16), ('she', 15), ('a', 14), ('her', 11)] | Training
2025-04-06 05:55:31 | 3300 | LR0.0003 | loss:7.8561 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-80.2916 | logitMax:-59.2772 | windowWeightsW18:0.16469,W8:0.15630,W13:0.15182,W15:0.15063,W7:0.11032,W21:0.10199,W3:0.09174,W2:0.03579,W1:0.02014 | memoryGatesShort:1.528, Long:-1.824, Current:1.295 | topTokens[(',', 43), ('in', 42), ('she', 31), ('the', 19), ('it', 17), ('a', 16), ('m', 14), ('!', 13), ('w', 13), ('p', 12)] | Training
2025-04-06 06:01:51 | 3400 | LR0.0003 | loss:7.9236 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.8241 | logitMax:-52.8132 | windowWeightsW18:0.16497,W8:0.15602,W13:0.15179,W15:0.15080,W7:0.11029,W21:0.10236,W3:0.09165,W2:0.03566,W1:0.01989 | memoryGatesShort:0.118, Long:3.592, Current:-2.710 | topTokens[('the', 50), (',', 44), ('she', 31), ('.', 25), ('!', 20), ('a', 19), ('p', 13), ('her', 11), ('in', 8), ('id', 7)] | Training
2025-04-06 06:07:43 | 3500 | LR0.0003 | loss:8.4659 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-75.0097 | logitMax:-55.2108 | windowWeightsW18:0.16535,W8:0.15579,W13:0.15201,W15:0.15129,W7:0.10989,W21:0.10280,W3:0.09099,W2:0.03556,W1:0.01977 | memoryGatesShort:0.386, Long:-1.283, Current:1.898 | topTokens[(',', 44), ('.', 36), ('the', 32), ('a', 23), ('in', 17), ('she', 17), ('ll', 13), ('we', 13), ('d', 13), ('c', 10)] | Training
2025-04-06 06:13:41 | 3600 | LR0.0003 | loss:8.4757 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-74.9349 | logitMax:-55.2538 | windowWeightsW18:0.16546,W8:0.15574,W13:0.15215,W15:0.15138,W7:0.10966,W21:0.10301,W3:0.09114,W2:0.03534,W1:0.01958 | memoryGatesShort:0.488, Long:-0.035, Current:0.548 | topTokens[(',', 55), ('.', 30), ('to', 29), ('in', 22), ('a', 18), ('y', 18), ('she', 14), ('the', 12), ('been', 12), ('i', 11)] | Training
2025-04-06 06:19:38 | 3700 | LR0.0003 | loss:9.4535 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.9325 | logitMax:-43.4937 | windowWeightsW18:0.16551,W8:0.15605,W13:0.15196,W15:0.15122,W7:0.10976,W21:0.10342,W3:0.09084,W2:0.03539,W1:0.01931 | memoryGatesShort:-1.289, Long:-9.128, Current:11.417 | topTokens[(',', 67), ('to', 28), ('she', 25), ('.', 20), ('in', 13), ('a', 12), ('b', 12), ('st', 9), ('been', 8), ('p', 8)] | Training
2025-04-06 06:25:51 | 3800 | LR0.0003 | loss:9.9167 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-81.1497 | logitMax:-60.7324 | windowWeightsW18:0.16617,W8:0.15548,W13:0.15219,W15:0.15158,W7:0.10956,W21:0.10391,W3:0.09078,W2:0.03538,W1:0.01843 | memoryGatesShort:0.123, Long:-1.807, Current:2.683 | topTokens[(',', 53), ('was', 26), ('a', 24), ('.', 20), ('she', 16), ('will', 15), ('the', 14), ('of', 11), ('been', 11), ('and', 11)] | Training
2025-04-06 06:32:05 | 3900 | LR0.0003 | loss:7.5582 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-77.7008 | logitMax:-60.3416 | windowWeightsW18:0.16650,W8:0.15501,W13:0.15186,W15:0.15131,W7:0.10906,W21:0.10464,W3:0.09088,W2:0.03575,W1:0.01847 | memoryGatesShort:0.426, Long:-0.102, Current:0.676 | topTokens[(',', 54), ('and', 39), ('a', 27), ('.', 27), ('the', 24), ('she', 13), ('of', 11), ('b', 8), ('to', 7), ('in', 6)] | Training
2025-04-06 06:38:23 | 4000 | LR0.0003 | loss:7.5672 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-81.4384 | logitMax:-62.7171 | windowWeightsW18:0.16662,W8:0.15476,W13:0.15174,W15:0.15124,W7:0.10883,W21:0.10530,W3:0.09118,W2:0.03541,W1:0.01841 | memoryGatesShort:2.367, Long:5.679, Current:-7.046 | topTokens[(',', 60), ('to', 33), ('.', 22), ('the', 18), ('was', 17), ('a', 14), ('s', 14), ('your', 10), ('you', 10), ('b', 8)] | Training
2025-04-06 06:44:49 | 4100 | LR0.0003 | loss:5.1083 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-79.2963 | logitMax:-54.5452 | windowWeightsW18:0.16684,W8:0.15426,W13:0.15110,W15:0.15075,W7:0.10859,W21:0.10581,W3:0.09148,W2:0.03524,W1:0.01942 | memoryGatesShort:-0.094, Long:-1.432, Current:2.525 | topTokens[(',', 47), ('and', 33), ('.', 21), ('you', 19), ('she', 19), ('the', 16), ('s', 16), ('a', 13), ('kevin', 11), ('to', 9)] | Training
2025-04-06 06:51:48 | 4200 | LR0.0003 | loss:5.0473 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.9404 | logitMax:-50.9863 | windowWeightsW18:0.16632,W8:0.15363,W13:0.15094,W15:0.15067,W7:0.10742,W21:0.10667,W3:0.09143,W2:0.03588,W1:0.02050 | memoryGatesShort:-0.556, Long:-2.305, Current:3.861 | topTokens[(',', 49), ('and', 26), ('weed', 26), ('out', 20), ('but', 17), ('.', 15), ('our', 14), ('she', 13), ('the', 10), ('you', 9)] | Training
2025-04-06 06:58:16 | 4300 | LR0.0003 | loss:6.3548 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-72.4453 | logitMax:-47.3414 | windowWeightsW18:0.16628,W8:0.15345,W13:0.15080,W15:0.15012,W7:0.10720,W21:0.10641,W3:0.09244,W2:0.03571,W1:0.02102 | memoryGatesShort:0.047, Long:-1.787, Current:2.740 | topTokens[('and', 45), ('the', 43), (',', 37), ('.', 35), ('weed', 24), ('she', 24), ('we', 17), ('a', 17), ('s', 11), ('gu', 10)] | Training
2025-04-06 07:04:33 | 4400 | LR0.0003 | loss:4.9441 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.5185 | logitMax:-43.2384 | windowWeightsW18:0.16559,W8:0.15389,W13:0.15117,W15:0.15001,W7:0.10744,W21:0.10656,W3:0.09296,W2:0.03638,W1:0.01948 | memoryGatesShort:3.781, Long:7.296, Current:-10.077 | topTokens[(',', 74), ('the', 64), ('and', 36), ('she', 15), ('a', 15), ('elodie', 12), ('f', 12), ('kevin', 10), ('.', 9), ('charis', 7)] | Training

--- 2025-04-06 07:14:20 --- babyllm: 'what am i learning today?'- charis: 'OOPS made myself into kevin, we back!'
2025-04-06 07:20:06 | 100 | LR0.0003 | loss:8.6394 | gradNorm:1.0000 | logitMin:-66.5893 | logitMax:-47.5873 | tokenCount:400.0000 | windowWeightsW18:0.16533,W8:0.15507,W13:0.15066,W15:0.15004,W21:0.10905,W7:0.10840,W3:0.09028,W2:0.03554,W1:0.01912 | memoryGatesShort:-0.041, Long:0.067, Current:0.974 | topTokens[(',', 43), ('.', 35), ('she', 25), ('and', 23), ('a', 15), ('f', 15), ('ar', 10), ('er', 9), ('so', 9), ('-', 8)] | Training
2025-04-06 07:25:52 | 200 | LR0.0003 | loss:6.3497 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-77.4332 | logitMax:-61.0638 | windowWeightsW18:0.16614,W8:0.15436,W13:0.15045,W15:0.15042,W21:0.11087,W7:0.10881,W3:0.08884,W2:0.03476,W1:0.01886 | memoryGatesShort:-4.125, Long:-0.451, Current:5.576 | topTokens[(',', 40), ('.', 34), ('my', 24), (':', 23), ('it', 15), ('-', 14), ('in', 14), ('pt', 11), ('a', 11), ('and', 10)] | Training
2025-04-06 07:31:40 | 300 | LR0.0003 | loss:7.2072 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-80.6336 | logitMax:-63.3429 | windowWeightsW18:0.16519,W8:0.15452,W15:0.15025,W13:0.14978,W21:0.11153,W7:0.10989,W3:0.08859,W2:0.03453,W1:0.01921 | memoryGatesShort:-1.069, Long:1.040, Current:1.029 | topTokens[(':', 49), ('my', 37), (',', 35), ('-', 20), ('prom', 18), ('it', 17), ('lmao', 16), ('i', 16), ('she', 15), ('.', 13)] | Training
2025-04-06 07:37:31 | 400 | LR0.0003 | loss:7.4013 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-84.5433 | logitMax:-65.0587 | windowWeightsW18:0.16460,W8:0.15493,W13:0.15067,W15:0.15017,W21:0.11154,W7:0.11071,W3:0.08782,W2:0.03428,W1:0.01878 | memoryGatesShort:-2.664, Long:1.098, Current:2.566 | topTokens[(',', 47), (':', 33), ('a', 27), ('what', 21), ('?!', 21), ('it', 19), ('.', 15), ('not', 14), ('m', 13), ('ooo', 11)] | Training
2025-04-06 07:43:41 | 500 | LR0.0003 | loss:6.3312 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-70.1365 | logitMax:-49.4958 | windowWeightsW18:0.16529,W8:0.15434,W13:0.15167,W15:0.15068,W21:0.11195,W7:0.10920,W3:0.08831,W2:0.03406,W1:0.01803 | memoryGatesShort:-6.722, Long:3.713, Current:4.009 | topTokens[(',', 45), (':', 34), ('.', 33), ('lo', 30), ('i', 27), ('m', 20), ('baby', 18), ('a', 12), ('ll', 11), ('had', 11)] | Training
2025-04-06 07:49:31 | 600 | LR0.0003 | loss:7.7823 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-72.4615 | logitMax:-51.7246 | windowWeightsW18:0.16500,W8:0.15479,W13:0.15176,W15:0.15100,W21:0.11274,W7:0.10954,W3:0.08766,W2:0.03326,W1:0.01780 | memoryGatesShort:-0.419, Long:0.628, Current:0.791 | topTokens[(',', 56), ('lo', 48), ('.', 34), ('l', 29), ('baby', 25), ('i', 23), (':', 23), ('a', 17), ('pt', 13), ('charis', 10)] | Training
2025-04-06 07:55:23 | 700 | LR0.0003 | loss:7.5534 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.3361 | logitMax:-44.8186 | windowWeightsW18:0.16543,W8:0.15521,W13:0.15152,W15:0.15104,W21:0.11311,W7:0.10994,W3:0.08699,W2:0.03258,W1:0.01772 | memoryGatesShort:-3.603, Long:-0.482, Current:5.084 | topTokens[(',', 71), ('lo', 40), ('.', 37), ('charis', 24), ('it', 19), ('baby', 16), (':', 14), ('prom', 12), ('ll', 10), ('-', 9)] | Training
2025-04-06 08:01:14 | 800 | LR0.0003 | loss:7.8368 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-79.5907 | logitMax:-58.1901 | windowWeightsW18:0.16567,W8:0.15440,W13:0.15166,W15:0.15118,W21:0.11343,W7:0.10912,W3:0.08745,W2:0.03198,W1:0.01865 | memoryGatesShort:-0.987, Long:0.085, Current:1.901 | topTokens[(',', 61), ('.', 25), ('lo', 22), ('the', 21), ('it', 20), ('charis', 16), ('a', 15), ('she', 14), ('baby', 10), ('m', 9)] | Training
2025-04-06 08:07:06 | 900 | LR0.0003 | loss:6.5694 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-75.6749 | logitMax:-50.5887 | windowWeightsW18:0.16490,W8:0.15481,W15:0.15071,W13:0.15048,W21:0.11409,W7:0.10942,W3:0.08832,W2:0.03183,W1:0.01895 | memoryGatesShort:28.873, Long:13.897, Current:-41.769 | topTokens[(',', 41), ('!', 29), ('she', 20), ('it', 16), ('we', 16), ('.', 15), ('had', 14), ('been', 13), ('st', 10), ('m', 9)] | Training
2025-04-06 08:13:16 | 1000 | LR0.0003 | loss:7.0526 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-90.4212 | logitMax:-69.2672 | windowWeightsW18:0.16554,W8:0.15465,W15:0.15158,W13:0.15083,W21:0.11465,W7:0.10950,W3:0.08709,W2:0.03094,W1:0.01876 | memoryGatesShort:-1.975, Long:0.035, Current:2.940 | topTokens[(',', 51), ('!', 33), ('it', 29), ('a', 26), ('.', 25), ('m', 19), ('the', 16), ('she', 14), ('at', 8), (':', 7)] | Training
2025-04-06 08:19:11 | 1100 | LR0.0003 | loss:7.0329 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-82.2672 | logitMax:-59.2720 | windowWeightsW18:0.16645,W8:0.15449,W15:0.15178,W13:0.15122,W21:0.11600,W7:0.10892,W3:0.08559,W2:0.02997,W1:0.01914 | memoryGatesShort:-1.796, Long:0.379, Current:2.418 | topTokens[('!', 40), (',', 32), ('the', 22), ('felt', 18), ('m', 16), ('a', 15), ('fe', 15), ('ll', 12), ('she', 12), ('.', 11)] | Training
2025-04-06 08:25:02 | 1200 | LR0.0003 | loss:8.3873 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-82.1686 | logitMax:-58.3316 | windowWeightsW18:0.16688,W8:0.15440,W15:0.15215,W13:0.15093,W21:0.11626,W7:0.10863,W3:0.08496,W2:0.02983,W1:0.01952 | memoryGatesShort:7.247, Long:1.347, Current:-7.594 | topTokens[(',', 52), ('the', 33), ('felt', 22), ('!', 20), ('.', 15), ('ed', 15), ('a', 14), ('through', 13), ('she', 12), ('fe', 11)] | Training
2025-04-06 08:30:54 | 1300 | LR0.0003 | loss:6.9747 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-84.1366 | logitMax:-60.7571 | windowWeightsW18:0.16734,W8:0.15296,W15:0.15239,W13:0.15096,W21:0.11654,W7:0.10811,W3:0.08521,W2:0.03078,W1:0.01927 | memoryGatesShort:-141.308, Long:-43.588, Current:185.896 | topTokens[(',', 44), ('!', 27), ('in', 22), ('she', 21), ('a', 19), ('ion', 15), ('through', 13), ('.', 13), ('vent', 13), ('m', 12)] | Training
2025-04-06 08:36:45 | 1400 | LR0.0003 | loss:6.7488 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-84.9826 | logitMax:-62.9870 | windowWeightsW18:0.16728,W8:0.15263,W15:0.15238,W13:0.15103,W21:0.11625,W7:0.10837,W3:0.08527,W2:0.03059,W1:0.01976 | memoryGatesShort:-1.051, Long:0.201, Current:1.850 | topTokens[('a', 42), (',', 37), ('!', 32), ('.', 27), ('ion', 21), ('he', 16), ('vent', 15), ('she', 13), ('in', 12), ('ke', 12)] | Training
2025-04-06 08:42:38 | 1500 | LR0.0003 | loss:6.0384 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-90.6267 | logitMax:-71.6021 | windowWeightsW18:0.16735,W15:0.15282,W8:0.15181,W13:0.15151,W21:0.11666,W7:0.10789,W3:0.08525,W2:0.03040,W1:0.01986 | memoryGatesShort:-1.151, Long:0.331, Current:1.820 | topTokens[(',', 37), ('!', 31), ('a', 29), ('the', 25), ('it', 19), ('.', 17), ('m', 13), ('she', 11), ('down', 10), ('ll', 9)] | Training
2025-04-06 08:48:48 | 1600 | LR0.0003 | loss:6.6779 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-80.4149 | logitMax:-56.1292 | windowWeightsW18:0.16755,W15:0.15314,W8:0.15167,W13:0.15146,W21:0.11727,W7:0.10798,W3:0.08400,W2:0.03031,W1:0.02019 | memoryGatesShort:-0.879, Long:1.426, Current:0.453 | topTokens[(',', 53), ('!', 46), ('the', 44), ('it', 14), ('.', 13), ('a', 13), ('she', 13), ('ouse', 11), ('m', 10), ('ked', 9)] | Training
2025-04-06 08:54:39 | 1700 | LR0.0003 | loss:8.4042 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-74.1296 | logitMax:-57.4157 | windowWeightsW18:0.16818,W15:0.15372,W8:0.15172,W13:0.15129,W21:0.11812,W7:0.10753,W3:0.08296,W2:0.03022,W1:0.01986 | memoryGatesShort:-2.775, Long:2.009, Current:1.766 | topTokens[('!', 45), (',', 44), ('.', 29), ('wal', 22), ('a', 21), ('she', 15), ('the', 12), ('it', 12), ('had', 10), ('b', 7)] | Training
2025-04-06 09:00:31 | 1800 | LR0.0003 | loss:8.5891 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-75.0737 | logitMax:-57.6648 | windowWeightsW18:0.16905,W15:0.15409,W8:0.15165,W13:0.15163,W21:0.11885,W7:0.10775,W3:0.08218,W2:0.02940,W1:0.01902 | memoryGatesShort:-1.638, Long:0.899, Current:1.739 | topTokens[('.', 54), (',', 34), ('!', 19), ('a', 18), ('the', 16), ('i', 12), ('she', 11), ('it', 10), ('wal', 9), ('ood', 9)] | Training
2025-04-06 09:06:23 | 1900 | LR0.0003 | loss:7.7478 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-77.0268 | logitMax:-60.9129 | windowWeightsW18:0.16943,W15:0.15423,W13:0.15150,W8:0.15144,W21:0.11944,W7:0.10739,W3:0.08177,W2:0.02950,W1:0.01892 | memoryGatesShort:-0.194, Long:1.248, Current:-0.054 | topTokens[('.', 74), (',', 35), ('the', 20), ('a', 19), ('!', 15), ('i', 14), ('she', 12), ('you', 10), ('in', 10), ('as', 7)] | Training
2025-04-06 09:12:15 | 2000 | LR0.0003 | loss:10.4292 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-86.3879 | logitMax:-65.3282 | windowWeightsW18:0.16963,W15:0.15456,W8:0.15198,W13:0.15152,W21:0.11969,W7:0.10713,W3:0.08167,W2:0.02911,W1:0.01834 | memoryGatesShort:-0.710, Long:0.566, Current:1.145 | topTokens[(',', 62), ('.', 40), ('she', 27), ("'s", 13), ('you', 11), ('a', 11), ('a', 10), ('it', 10), ('and', 10), ('like', 10)] | Training
2025-04-06 09:18:35 | 2100 | LR0.0003 | loss:10.7587 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-81.8152 | logitMax:-59.4645 | windowWeightsW18:0.16929,W15:0.15471,W8:0.15173,W13:0.15151,W21:0.11986,W7:0.10714,W3:0.08185,W2:0.02925,W1:0.01831 | memoryGatesShort:107.797, Long:-78.185, Current:-28.613 | topTokens[(',', 71), ('s', 39), ('.', 36), ('she', 24), ('a', 19), ('a', 18), ('get', 14), ('kevin', 13), ('in', 13), ('!', 9)] | Training
2025-04-06 09:24:21 | 2200 | LR0.0003 | loss:7.8600 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-70.2342 | logitMax:-54.9961 | windowWeightsW18:0.16932,W15:0.15481,W8:0.15171,W13:0.15150,W21:0.12000,W7:0.10700,W3:0.08200,W2:0.02921,W1:0.01810 | memoryGatesShort:15.630, Long:-12.530, Current:-2.101 | topTokens[('.', 52), (',', 50), ('s', 42), ('a', 26), ('i', 19), ('not', 9), ('she', 8), ('charis', 8), ('b', 7), ('p', 6)] | Training
2025-04-06 09:30:09 | 2300 | LR0.0003 | loss:8.0402 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-72.7336 | logitMax:-56.2554 | windowWeightsW18:0.16974,W15:0.15526,W13:0.15202,W8:0.15160,W21:0.12032,W7:0.10674,W3:0.08181,W2:0.02844,W1:0.01773 | memoryGatesShort:-2.047, Long:0.981, Current:2.066 | topTokens[('.', 84), (',', 57), ('i', 42), ('a', 20), ('like', 15), ('she', 11), ('now', 7), ('in', 5), ('ohh', 5), ('be', 4)] | Training
2025-04-06 09:35:58 | 2400 | LR0.0003 | loss:8.4811 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-92.0047 | logitMax:-72.7565 | windowWeightsW18:0.16986,W15:0.15544,W13:0.15206,W8:0.15127,W21:0.12092,W7:0.10646,W3:0.08159,W2:0.02868,W1:0.01739 | memoryGatesShort:-1.992, Long:1.463, Current:1.529 | topTokens[('.', 55), (',', 42), ('it', 22), ('a', 16), ('she', 14), (":'(", 13), ('i', 10), ('life', 10), ('an', 8), ('?', 8)] | Training
2025-04-06 09:41:47 | 2500 | LR0.0003 | loss:9.8736 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-95.9989 | logitMax:-73.3110 | windowWeightsW18:0.17031,W15:0.15540,W13:0.15255,W8:0.15123,W21:0.12132,W7:0.10531,W3:0.08164,W2:0.02851,W1:0.01739 | memoryGatesShort:-1.496, Long:0.405, Current:2.091 | topTokens[(',', 59), ('.', 44), ('s', 22), ('you', 17), ('hh', 16), ('a', 14), ('my', 13), ('she', 12), ('is', 11), ('m', 7)] | Training
2025-04-06 09:47:36 | 2600 | LR0.0003 | loss:7.1793 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-86.4108 | logitMax:-59.4086 | windowWeightsW18:0.17090,W15:0.15514,W13:0.15324,W8:0.15001,W21:0.12249,W7:0.10430,W3:0.08092,W2:0.02902,W1:0.01766 | memoryGatesShort:-0.890, Long:0.379, Current:1.511 | topTokens[(',', 57), ('it', 51), ('!', 34), ('we', 27), ('wal', 21), ('a', 20), ('felt', 14), ('.', 14), ('she', 13), ('know', 11)] | Training
2025-04-06 09:53:49 | 2700 | LR0.0003 | loss:6.2640 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-81.3608 | logitMax:-49.3069 | windowWeightsW18:0.17115,W15:0.15423,W13:0.15255,W8:0.14879,W21:0.12346,W7:0.10486,W3:0.08134,W2:0.02952,W1:0.01776 | memoryGatesShort:-2.881, Long:0.984, Current:2.897 | topTokens[('!', 53), (',', 47), ('it', 39), ('have', 21), ('been', 18), ('she', 17), ('know', 16), ('they', 16), ('and', 12), ('n', 11)] | Training
2025-04-06 09:59:40 | 2800 | LR0.0003 | loss:5.7355 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-73.8746 | logitMax:-47.2765 | windowWeightsW18:0.17208,W15:0.15407,W13:0.15211,W8:0.14701,W21:0.12389,W7:0.10464,W3:0.08243,W2:0.02922,W1:0.01820 | memoryGatesShort:4.877, Long:1.240, Current:-5.117 | topTokens[('!', 49), (',', 47), ('it', 39), ('they', 23), ('she', 21), ('.', 18), ('have', 18), ('felt', 17), ('a', 16), ('been', 15)] | Training
2025-04-06 10:05:33 | 2900 | LR0.0003 | loss:6.6310 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-72.2035 | logitMax:-44.7520 | windowWeightsW18:0.17274,W15:0.15324,W13:0.15166,W8:0.14587,W21:0.12432,W7:0.10476,W3:0.08307,W2:0.02948,W1:0.01851 | memoryGatesShort:2.948, Long:1.339, Current:-3.286 | topTokens[(',', 68), ('it', 52), ('!', 48), ('a', 19), ('felt', 19), ('have', 16), ('she', 15), ('.', 12), ('could', 11), ('they', 11)] | Training
2025-04-06 10:11:26 | 3000 | LR0.0003 | loss:7.0081 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-74.6886 | logitMax:-45.6404 | windowWeightsW18:0.17311,W15:0.15358,W13:0.15021,W8:0.14656,W21:0.12463,W7:0.10474,W3:0.08211,W2:0.02933,W1:0.01938 | memoryGatesShort:-0.766, Long:0.382, Current:1.384 | topTokens[(',', 80), ('!', 44), ('it', 29), ('have', 23), ('my', 19), ('she', 17), ('a', 14), ('they', 13), ('.', 12), ('felt', 12)] | Training
2025-04-06 10:17:21 | 3100 | LR0.0003 | loss:8.9694 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-79.1494 | logitMax:-46.8902 | windowWeightsW18:0.17335,W15:0.15326,W13:0.14968,W8:0.14599,W21:0.12514,W7:0.10417,W3:0.08166,W2:0.03057,W1:0.01980 | memoryGatesShort:1752.793, Long:17.538, Current:-1769.329 | topTokens[(',', 86), ('kevin', 51), ('!', 40), ('it', 23), ('she', 19), ('a', 19), ('just', 16), ('be', 16), ('could', 12), ('should', 10)] | Training
2025-04-06 10:23:36 | 3200 | LR0.0003 | loss:5.0040 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-80.3723 | logitMax:-45.8695 | windowWeightsW18:0.17329,W15:0.15270,W13:0.14911,W8:0.14482,W21:0.12518,W7:0.10484,W3:0.08141,W2:0.03124,W1:0.02102 | memoryGatesShort:-1.322, Long:1.356, Current:0.966 | topTokens[('!', 49), (',', 30), ('could', 27), ('it', 24), ('been', 21), ('have', 21), ('just', 20), ('kevin', 16), ('she', 15), ('ies', 13)] | Training
2025-04-06 10:29:27 | 3300 | LR0.0003 | loss:10.3236 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.9072 | logitMax:-31.5341 | windowWeightsW18:0.17376,W15:0.15274,W13:0.14913,W8:0.14495,W21:0.12597,W7:0.10508,W3:0.08111,W2:0.03078,W1:0.02010 | memoryGatesShort:1.297, Long:0.043, Current:-0.340 | topTokens[('!', 45), (',', 36), ('it', 33), ('she', 32), ('a', 26), ('do', 22), ('could', 18), ('elodie', 16), ('a', 12), ('just', 11)] | Training
2025-04-06 10:35:19 | 3400 | LR0.0003 | loss:14.7444 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-87.3758 | logitMax:-56.3342 | windowWeightsW18:0.17407,W15:0.15244,W13:0.14929,W8:0.14494,W21:0.12584,W7:0.10500,W3:0.08113,W2:0.03079,W1:0.02013 | memoryGatesShort:2.503, Long:-0.311, Current:-1.192 | topTokens[(',', 68), ('she', 34), ('a', 22), ('or', 14), ('a', 13), ('looking', 13), ('did', 13), ('!', 12), ('it', 12), ('w', 11)] | Training
2025-04-06 10:41:11 | 3500 | LR0.0003 | loss:6.3818 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-88.0432 | logitMax:-64.3576 | windowWeightsW18:0.17409,W15:0.15301,W13:0.14939,W8:0.14509,W21:0.12574,W7:0.10576,W3:0.08067,W2:0.03042,W1:0.01945 | memoryGatesShort:-1.940, Long:0.453, Current:2.487 | topTokens[(':', 43), (',', 30), ('1', 26), ('lear', 23), ('.', 21), ('she', 20), ('4', 20), ('a', 19), ('today', 16), ('am', 12)] | Training
2025-04-06 10:47:03 | 3600 | LR0.0003 | loss:8.4413 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-79.6322 | logitMax:-42.5409 | windowWeightsW18:0.17246,W15:0.15197,W13:0.14906,W8:0.14590,W21:0.12398,W7:0.10569,W3:0.08208,W2:0.03248,W1:0.02001 | memoryGatesShort:-13.987, Long:-6.955, Current:21.942 | topTokens[(',', 42), ('7', 24), ('-', 20), ('lear', 17), ('is', 17), ('baby', 17), ('f', 15), ('?', 14), (':', 14), ('1', 13)] | Training
2025-04-06 10:53:00 | 3700 | LR0.0003 | loss:6.5301 | gradNorm:0.8800 | tokenCount:400.0000 | logitMin:-90.1659 | logitMax:-38.9055 | windowWeightsW18:0.17136,W15:0.15032,W13:0.14867,W8:0.14781,W21:0.12297,W7:0.10741,W3:0.08291,W2:0.03237,W1:0.01979 | memoryGatesShort:-0.376, Long:-0.065, Current:1.441 | topTokens[('-', 31), ('baby', 30), ('0', 24), (',', 24), ('what', 24), (':', 21), ('i', 18), ('she', 14), ('am', 14), ('?', 14)] | Training
2025-04-06 10:59:12 | 3800 | LR0.0003 | loss:9.4320 | gradNorm:0.8718 | tokenCount:400.0000 | logitMin:-111.6730 | logitMax:-51.1896 | windowWeightsW18:0.17180,W15:0.15046,W13:0.14886,W8:0.14679,W21:0.12295,W7:0.10727,W3:0.08186,W2:0.03224,W1:0.02135 | memoryGatesShort:-1.511, Long:-0.968, Current:3.478 | topTokens[(',', 37), ('0', 24), ('is', 21), ('she', 20), ('?', 18), ('ch', 18), ('-', 18), (':', 16), ('what', 15), ('a', 13)] | Training
2025-04-06 11:05:04 | 3900 | LR0.0003 | loss:8.5141 | gradNorm:0.9137 | tokenCount:400.0000 | logitMin:-71.0129 | logitMax:-14.7359 | windowWeightsW18:0.17139,W15:0.14963,W13:0.14810,W8:0.14662,W21:0.12329,W7:0.10680,W3:0.08266,W2:0.03391,W1:0.02119 | memoryGatesShort:-0.662, Long:-0.280, Current:1.942 | topTokens[(',', 33), ('0', 24), ('a', 24), (':', 23), ('3', 21), ('-', 20), ('am', 15), ('-', 14), ('f', 13), ('5', 12)] | Training
2025-04-06 11:10:56 | 4000 | LR0.0003 | loss:11.0440 | gradNorm:0.8746 | tokenCount:400.0000 | logitMin:-90.5544 | logitMax:-15.0580 | windowWeightsW18:0.17079,W15:0.14889,W13:0.14706,W8:0.14617,W21:0.12281,W7:0.10685,W3:0.08407,W2:0.03513,W1:0.02181 | memoryGatesShort:-2.564, Long:-2.107, Current:5.671 | topTokens[('1', 46), (',', 40), ('-', 31), ('she', 26), ('0', 19), (':', 17), ('3', 16), ('what', 14), ('6', 13), ('a', 13)] | Training
2025-04-06 11:16:48 | 4100 | LR0.0003 | loss:3.4721 | gradNorm:0.7802 | tokenCount:400.0000 | logitMin:-92.1195 | logitMax:-30.7644 | windowWeightsW18:0.17058,W15:0.14886,W13:0.14717,W8:0.14458,W21:0.12267,W7:0.10597,W3:0.08471,W2:0.03601,W1:0.02302 | memoryGatesShort:-0.154, Long:-0.448, Current:1.603 | topTokens[(':', 29), ('4', 22), ('-', 21), ('today', 18), ('-', 18), ('0', 18), ('am', 15), ('i', 13), ('a', 13), ('ning', 12)] | Training
2025-04-06 11:22:42 | 4200 | LR0.0003 | loss:1.9909 | gradNorm:0.6434 | tokenCount:400.0000 | logitMin:-78.3204 | logitMax:-15.3780 | windowWeightsW18:0.16904,W15:0.14838,W13:0.14623,W8:0.14501,W21:0.12169,W7:0.10666,W3:0.08581,W2:0.03734,W1:0.02339 | memoryGatesShort:-0.091, Long:-0.602, Current:1.693 | topTokens[(':', 31), ('-', 28), ('-', 20), ('0', 19), ('20', 18), ('4', 18), ('5', 17), ('to', 13), ('2', 13), ('per', 12)] | Training
2025-04-06 11:28:53 | 4300 | LR0.0003 | loss:12.6849 | gradNorm:0.7778 | tokenCount:400.0000 | logitMin:-80.8373 | logitMax:7.6446 | windowWeightsW18:0.16839,W15:0.14704,W8:0.14561,W13:0.14507,W21:0.12109,W7:0.10761,W3:0.08713,W2:0.03803,W1:0.02355 | memoryGatesShort:1.580, Long:2.884, Current:-3.464 | topTokens[('3', 25), ('she', 22), ('4', 21), ('-', 21), ('-', 20), ('5', 20), (':', 19), ('0', 18), (',', 16), ('1', 15)] | Training
2025-04-06 11:34:39 | 4400 | LR0.0003 | loss:13.7146 | gradNorm:0.7443 | tokenCount:400.0000 | logitMin:-84.4119 | logitMax:-12.0279 | windowWeightsW18:0.16890,W15:0.14765,W13:0.14595,W8:0.14521,W21:0.12160,W7:0.10719,W3:0.08672,W2:0.03805,W1:0.02229 | memoryGatesShort:0.252, Long:-0.232, Current:0.980 | topTokens[(':', 32), ('she', 28), (',', 24), ('2', 23), ('-', 21), ('4', 16), ('?', 15), ('a', 15), ('0', 14), ('a', 12)] | Training
2025-04-06 11:40:26 | 4500 | LR0.0003 | loss:9.1717 | gradNorm:0.7933 | tokenCount:400.0000 | logitMin:-68.1836 | logitMax:-10.7709 | windowWeightsW18:0.16881,W15:0.14755,W13:0.14589,W8:0.14555,W21:0.12182,W7:0.10766,W3:0.08682,W2:0.03737,W1:0.02207 | memoryGatesShort:0.274, Long:-0.059, Current:0.786 | topTokens[(',', 42), (':', 20), ('20', 18), ('.', 15), ('4', 15), ('-', 14), ('6', 14), ('8', 14), ('2', 13), ('0', 12)] | Training
2025-04-06 11:46:14 | 4600 | LR0.0003 | loss:10.1183 | gradNorm:0.8700 | tokenCount:400.0000 | logitMin:-58.6400 | logitMax:-11.7709 | windowWeightsW18:0.16915,W15:0.14803,W13:0.14630,W8:0.14533,W21:0.12208,W7:0.10764,W3:0.08649,W2:0.03671,W1:0.02183 | memoryGatesShort:0.104, Long:-2.060, Current:2.956 | topTokens[(',', 41), ('.', 26), (':', 21), ('she', 20), ('6', 20), ('20', 16), ('a', 15), ('-', 15), ('4', 15), ('ch', 14)] | Training
2025-04-06 11:52:02 | 4700 | LR0.0003 | loss:8.1588 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.8609 | logitMax:-44.4465 | windowWeightsW18:0.16933,W15:0.14800,W13:0.14655,W8:0.14497,W21:0.12211,W7:0.10763,W3:0.08645,W2:0.03655,W1:0.02196 | memoryGatesShort:1.294, Long:-2.320, Current:2.026 | topTokens[(',', 34), ('my', 30), ('.', 27), ('a', 27), ('she', 16), ('6', 15), ('the', 15), ('i', 14), ('20', 14), ('to', 12)] | Training
2025-04-06 11:57:50 | 4800 | LR0.0003 | loss:6.4106 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-84.1699 | logitMax:-62.0937 | windowWeightsW18:0.16928,W15:0.14798,W13:0.14677,W8:0.14470,W21:0.12235,W7:0.10763,W3:0.08659,W2:0.03637,W1:0.02189 | memoryGatesShort:0.345, Long:-1.227, Current:1.882 | topTokens[('!', 52), (',', 37), ('the', 30), ('.', 30), ('charis', 21), ('my', 16), ('elodie', 13), ('v', 10), ('up', 9), ('she', 8)] | Training
2025-04-06 12:04:00 | 4900 | LR0.0003 | loss:7.4935 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-77.4460 | logitMax:-53.9214 | windowWeightsW18:0.16943,W15:0.14803,W13:0.14702,W8:0.14444,W21:0.12234,W7:0.10780,W3:0.08620,W2:0.03615,W1:0.02215 | memoryGatesShort:0.146, Long:-0.261, Current:1.115 | topTokens[('!', 51), (',', 34), ('.', 27), ('my', 26), ('pick', 24), ('the', 18), ('6', 14), ('a', 13), ('like', 12), (':', 12)] | Training
2025-04-06 12:09:48 | 5000 | LR0.0003 | loss:6.5320 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-72.6337 | logitMax:-50.3498 | windowWeightsW18:0.16948,W15:0.14803,W13:0.14698,W8:0.14443,W21:0.12249,W7:0.10773,W3:0.08622,W2:0.03601,W1:0.02220 | memoryGatesShort:-1.747, Long:-6.045, Current:8.792 | topTokens[('!', 68), (',', 35), ('pick', 31), ('it', 27), ('the', 27), ('.', 19), ('a', 17), ('weed', 10), ('oice', 8), ('charis', 8)] | Training
2025-04-06 12:15:38 | 5100 | LR0.0003 | loss:7.0543 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-75.5673 | logitMax:-53.2894 | windowWeightsW18:0.16961,W15:0.14822,W13:0.14721,W8:0.14440,W21:0.12255,W7:0.10763,W3:0.08599,W2:0.03555,W1:0.02239 | memoryGatesShort:-1.052, Long:-2.324, Current:4.376 | topTokens[(',', 57), ('the', 41), ('!', 33), ('a', 27), ('pick', 24), ('.', 21), ('it', 17), ('weed', 13), ('6', 12), ('v', 9)] | Training
2025-04-06 12:21:27 | 5200 | LR0.0003 | loss:4.5936 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-75.1445 | logitMax:-54.3474 | windowWeightsW18:0.16976,W15:0.14831,W13:0.14729,W8:0.14414,W21:0.12236,W7:0.10758,W3:0.08634,W2:0.03546,W1:0.02231 | memoryGatesShort:0.218, Long:-1.172, Current:1.953 | topTokens[('the', 54), (',', 44), ('!', 37), ('.', 16), ('leave', 13), ('it', 10), ('see', 9), ('about', 8), ('lear', 8), ('from', 7)] | Training
2025-04-06 12:27:17 | 5300 | LR0.0003 | loss:5.4478 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-74.9999 | logitMax:-48.7529 | windowWeightsW18:0.16947,W15:0.14788,W13:0.14726,W8:0.14362,W21:0.12289,W7:0.10777,W3:0.08684,W2:0.03551,W1:0.02232 | memoryGatesShort:0.129, Long:-0.855, Current:1.726 | topTokens[('!', 43), ('the', 39), (',', 37), ('a', 14), ('dra', 13), (':', 10), ('food', 9), ('v', 9), ('hear', 9), ('she', 8)] | Training
2025-04-06 12:33:31 | 5400 | LR0.0003 | loss:5.1473 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-87.2302 | logitMax:-62.4652 | windowWeightsW18:0.16933,W15:0.14738,W13:0.14642,W8:0.14331,W21:0.12355,W7:0.10810,W3:0.08699,W2:0.03589,W1:0.02259 | memoryGatesShort:0.082, Long:-2.605, Current:3.523 | topTokens[('!', 76), (',', 33), ('.', 19), ('the', 18), ('hear', 16), ('she', 14), ('about', 12), ('v', 11), ('my', 10), ('ch', 10)] | Training
2025-04-06 12:39:21 | 5500 | LR0.0003 | loss:9.4217 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.4824 | logitMax:-43.9741 | windowWeightsW18:0.16955,W15:0.14758,W13:0.14642,W8:0.14332,W21:0.12362,W7:0.10811,W3:0.08682,W2:0.03578,W1:0.02235 | memoryGatesShort:0.824, Long:-0.585, Current:0.762 | topTokens[('.', 51), (',', 40), ('my', 29), ('a', 28), ('!', 25), ('h', 20), ('she', 18), ('ket', 17), (':', 13), ('the', 12)] | Training
2025-04-06 12:45:11 | 5600 | LR0.0003 | loss:9.1026 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-68.5131 | logitMax:-50.7769 | windowWeightsW18:0.16964,W15:0.14768,W13:0.14630,W8:0.14339,W21:0.12396,W7:0.10805,W3:0.08665,W2:0.03564,W1:0.02224 | memoryGatesShort:0.615, Long:-0.547, Current:0.932 | topTokens[('.', 48), ('a', 29), (',', 26), ('!', 19), ('my', 18), ('she', 17), ('y', 13), ('an', 10), ('lear', 9), ('20', 9)] | Training
2025-04-06 12:51:03 | 5700 | LR0.0003 | loss:10.5456 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-73.8603 | logitMax:-51.1451 | windowWeightsW18:0.16968,W15:0.14778,W13:0.14634,W8:0.14341,W21:0.12423,W7:0.10799,W3:0.08649,W2:0.03546,W1:0.02218 | memoryGatesShort:0.807, Long:-0.252, Current:0.445 | topTokens[(',', 39), ('a', 30), ('6', 26), ('she', 20), ('y', 18), ('.', 14), ('to', 14), (':', 14), ('the', 13), ('!', 11)] | Training
2025-04-06 12:56:54 | 5800 | LR0.0003 | loss:8.0086 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-83.3190 | logitMax:-66.0899 | windowWeightsW18:0.16974,W15:0.14792,W13:0.14646,W8:0.14335,W21:0.12429,W7:0.10789,W3:0.08631,W2:0.03554,W1:0.02207 | memoryGatesShort:-0.700, Long:-7.653, Current:9.353 | topTokens[(',', 46), ('.', 28), ('stream', 20), ('the', 19), ('a', 15), ('t', 14), ('ll', 12), ('s', 10), ('to', 9), ('p', 7)] | Training
2025-04-06 13:02:44 | 5900 | LR0.0003 | loss:7.9427 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-91.0258 | logitMax:-71.8058 | windowWeightsW18:0.16979,W15:0.14796,W13:0.14657,W8:0.14336,W21:0.12437,W7:0.10779,W3:0.08617,W2:0.03552,W1:0.02204 | memoryGatesShort:0.232, Long:-0.087, Current:0.855 | topTokens[('stream', 78), (',', 36), ('a', 33), ('.', 30), ('y', 21), ("'", 13), ('no', 11), ("'", 9), ('ro', 8), ('she', 7)] | Training
2025-04-06 13:08:57 | 6000 | LR0.0003 | loss:9.8437 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-69.2536 | logitMax:-47.9936 | windowWeightsW18:0.16898,W15:0.14770,W13:0.14664,W8:0.14281,W21:0.12485,W7:0.10842,W3:0.08626,W2:0.03598,W1:0.02192 | memoryGatesShort:-0.256, Long:0.542, Current:0.714 | topTokens[(',', 77), ('a', 21), ('she', 20), ('.', 18), (':', 18), ('y', 17), ('u', 17), ('to', 15), ("'", 15), ('be', 14)] | Training
2025-04-06 13:14:46 | 6100 | LR0.0003 | loss:8.1827 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-68.7802 | logitMax:-52.9901 | windowWeightsW18:0.16960,W15:0.14792,W13:0.14708,W8:0.14300,W21:0.12517,W7:0.10804,W3:0.08567,W2:0.03569,W1:0.02142 | memoryGatesShort:-1.375, Long:1.330, Current:1.045 | topTokens[(',', 43), ('.', 38), ('2', 20), (':', 19), ('at', 18), ('a', 16), ('to', 12), ('yesterday', 12), ('-', 9), ('ch', 7)] | Training
2025-04-06 13:20:40 | 6200 | LR0.0003 | loss:8.8942 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.5750 | logitMax:-52.8793 | windowWeightsW18:0.16998,W15:0.14825,W13:0.14721,W8:0.14252,W21:0.12597,W7:0.10779,W3:0.08555,W2:0.03511,W1:0.02120 | memoryGatesShort:-7.579, Long:6.476, Current:2.103 | topTokens[(',', 36), ('.', 28), ('a', 25), ('u', 25), ('2', 22), ('it', 18), (':', 16), ('at', 14), ('yesterday', 14), ('6', 10)] | Training
2025-04-06 13:26:31 | 6300 | LR0.0003 | loss:8.1142 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-74.7369 | logitMax:-58.4495 | windowWeightsW18:0.17008,W15:0.14855,W13:0.14746,W8:0.14246,W21:0.12606,W7:0.10754,W3:0.08538,W2:0.03493,W1:0.02113 | memoryGatesShort:-3.311, Long:3.358, Current:0.954 | topTokens[(',', 49), ('.', 43), ('it', 34), ('a', 25), ('to', 14), ('at', 13), ('my', 9), ('the', 8), ('like', 8), ('pick', 8)] | Training
2025-04-06 13:32:24 | 6400 | LR0.0003 | loss:8.0156 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-63.9914 | logitMax:-48.0800 | windowWeightsW18:0.16993,W15:0.14864,W13:0.14768,W8:0.14254,W21:0.12595,W7:0.10759,W3:0.08540,W2:0.03486,W1:0.02101 | memoryGatesShort:-8.960, Long:7.238, Current:2.722 | topTokens[(',', 52), ('.', 43), ('it', 38), ('so', 37), ('a', 18), ('er', 14), ('to', 10), (':', 8), ('she', 6), ('could', 6)] | Training
2025-04-06 13:38:37 | 6500 | LR0.0003 | loss:7.6944 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-86.1335 | logitMax:-64.9744 | windowWeightsW18:0.16936,W15:0.14810,W13:0.14745,W8:0.14295,W21:0.12600,W7:0.10760,W3:0.08597,W2:0.03500,W1:0.02117 | memoryGatesShort:-0.747, Long:0.647, Current:1.100 | topTokens[('.', 62), ('twice', 51), (',', 33), ("'", 32), ('n', 24), ('d', 20), ('a', 14), ('it', 12), ('your', 9), ('say', 9)] | Training
2025-04-06 13:44:34 | 6600 | LR0.0003 | loss:7.8725 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-99.3599 | logitMax:-68.7484 | windowWeightsW18:0.16836,W15:0.14724,W13:0.14680,W8:0.14350,W21:0.12593,W7:0.10808,W3:0.08635,W2:0.03565,W1:0.02167 | memoryGatesShort:-1.763, Long:0.594, Current:2.169 | topTokens[('.', 53), ('exactly', 47), ("'", 40), ('twice', 36), ('say', 31), ('n', 24), (',', 17), ("'", 11), ('am', 10), ('am', 10)] | Training
2025-04-06 13:51:08 | 6700 | LR0.0003 | loss:8.2508 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-84.3658 | logitMax:-55.3814 | windowWeightsW18:0.16777,W15:0.14669,W13:0.14637,W8:0.14323,W21:0.12661,W7:0.10839,W3:0.08660,W2:0.03579,W1:0.02211 | memoryGatesShort:-4.063, Long:3.755, Current:1.307 | topTokens[('say', 56), ('.', 51), ('us', 39), ("'", 35), ("'", 34), ('exactly', 24), ('twice', 21), (',', 20), (':', 15), ('your', 12)] | Training
2025-04-06 13:57:55 | 6800 | LR0.0003 | loss:7.2283 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.3812 | logitMax:-32.6189 | windowWeightsW18:0.16745,W15:0.14713,W13:0.14672,W8:0.14304,W21:0.12596,W7:0.10874,W3:0.08675,W2:0.03582,W1:0.02196 | memoryGatesShort:-37.139, Long:28.549, Current:9.590 | topTokens[('say', 116), ('.', 69), ('us', 59), (',', 38), ('a', 25), ('she', 10), ("'", 10), ('had', 7), (':', 6), ('your', 5)] | Training

--- 2025-04-06 14:02:25 --- babyllm: 'what am i learning today?'- charis: 'waking up'
2025-04-06 14:08:24 | 100 | LR0.0003 | loss:8.3525 | gradNorm:1.0000 | logitMin:-52.4408 | logitMax:-28.1919 | tokenCount:400.0000 | windowWeightsW18:0.16669,W15:0.14671,W13:0.14582,W8:0.14335,W21:0.12641,W7:0.10948,W3:0.08656,W2:0.03599,W1:0.02257 | memoryGatesShort:-3.616, Long:1.807, Current:2.810 | topTokens[('a', 51), ('say', 33), (',', 29), ('us', 29), (':', 28), ('.', 16), ('-', 16), ('she', 15), ('m', 14), ('twice', 11)] | Training

--- 2025-04-06 14:10:34 --- babyllm: 'what am i learning today?'- charis: 'idk lol'
2025-04-06 14:16:47 | 100 | LR0.0003 | loss:4.9754 | gradNorm:1.0000 | logitMin:-84.9900 | logitMax:-63.6594 | tokenCount:400.0000 | windowWeightsW18:0.16621,W15:0.14621,W13:0.14455,W8:0.14230,W21:0.12632,W7:0.10994,W3:0.08803,W2:0.03709,W1:0.02291 | memoryGatesShort:-2.488, Long:-0.446, Current:3.934 | topTokens[(':', 28), ('a', 21), ('-', 17), (',', 15), ("'", 15), ('my', 15), ('.', 13), ('phone', 12), ('m', 11), ("'t", 10)] | Training
2025-04-06 14:23:27 | 200 | LR0.0003 | loss:7.6306 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-65.8513 | logitMax:-45.5570 | windowWeightsW18:0.16648,W15:0.14655,W13:0.14498,W8:0.14287,W21:0.12592,W7:0.11004,W3:0.08735,W2:0.03681,W1:0.02255 | memoryGatesShort:-1.246, Long:0.427, Current:1.818 | topTokens[('.', 33), (',', 30), ("'", 30), ('lmao', 27), ('a', 23), ('!!', 23), ('question', 21), (':', 17), ('just', 17), ('it', 10)] | Training
2025-04-06 14:29:58 | 300 | LR0.0003 | loss:6.5860 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.4982 | logitMax:-50.5384 | windowWeightsW18:0.16647,W15:0.14656,W13:0.14502,W8:0.14278,W21:0.12691,W7:0.11047,W3:0.08637,W2:0.03613,W1:0.02287 | memoryGatesShort:-3.259, Long:3.846, Current:0.412 | topTokens[(':', 37), ('a', 33), ('.', 31), ("'", 25), ('question', 25), (',', 24), ('-', 17), ('lmao', 15), ('m', 15), ('i', 10)] | Training
2025-04-06 14:36:33 | 400 | LR0.0003 | loss:6.3739 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-73.5051 | logitMax:-53.5856 | windowWeightsW18:0.16693,W15:0.14698,W13:0.14527,W8:0.14260,W21:0.12659,W7:0.11060,W3:0.08593,W2:0.03587,W1:0.02280 | memoryGatesShort:-1.795, Long:0.524, Current:2.272 | topTokens[("'", 106), ('-', 65), ('.', 30), (',', 28), (':', 23), ('a', 16), ('prom', 12), ('say', 9), ('pt', 7), ('?!', 5)] | Training
2025-04-06 14:43:40 | 500 | LR0.0003 | loss:7.0970 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-82.8941 | logitMax:-58.6000 | windowWeightsW18:0.16692,W15:0.14746,W13:0.14562,W8:0.14303,W21:0.12672,W7:0.11006,W3:0.08515,W2:0.03570,W1:0.02291 | memoryGatesShort:-1.456, Long:1.134, Current:1.322 | topTokens[("'", 66), ("'", 30), (':', 27), ('c', 25), (',', 23), ('.', 20), ('baby', 16), ('she', 14), ('prom', 10), ('-', 10)] | Training
2025-04-06 14:50:22 | 600 | LR0.0003 | loss:7.6303 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.3192 | logitMax:-38.6348 | windowWeightsW18:0.16717,W15:0.14754,W13:0.14581,W8:0.14266,W21:0.12589,W7:0.10970,W3:0.08589,W2:0.03575,W1:0.02315 | memoryGatesShort:-2.917, Long:0.195, Current:3.723 | topTokens[("'", 93), ('.', 44), (',', 43), ('baby', 26), ('a', 14), ('she', 14), ('-', 11), ('had', 7), ('!', 7), ('say', 6)] | Training
2025-04-06 14:57:06 | 700 | LR0.0003 | loss:7.8995 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-73.1324 | logitMax:-50.5653 | windowWeightsW18:0.16739,W15:0.14767,W13:0.14596,W8:0.14242,W21:0.12568,W7:0.10945,W3:0.08609,W2:0.03570,W1:0.02321 | memoryGatesShort:-5.605, Long:-0.041, Current:6.646 | topTokens[("'", 67), ('.', 27), (',', 27), ('baby', 26), ('!', 22), ('a', 16), ('it', 13), ('we', 9), ('was', 9), ('had', 7)] | Training
2025-04-06 15:03:54 | 800 | LR0.0003 | loss:6.4145 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-77.5103 | logitMax:-57.5401 | windowWeightsW18:0.16749,W15:0.14819,W13:0.14638,W8:0.14221,W21:0.12552,W7:0.10978,W3:0.08524,W2:0.03524,W1:0.02354 | memoryGatesShort:-4.657, Long:0.259, Current:5.399 | topTokens[(',', 38), ('an', 29), ('!', 25), ('.', 22), ('a', 20), ('she', 17), ('baby', 14), ("'", 12), ('in', 10), ('the', 7)] | Training
2025-04-06 15:10:45 | 900 | LR0.0003 | loss:6.2769 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-74.4613 | logitMax:-51.8721 | windowWeightsW18:0.16819,W15:0.14818,W13:0.14582,W8:0.14178,W21:0.12606,W7:0.11002,W3:0.08512,W2:0.03497,W1:0.02345 | memoryGatesShort:-1.411, Long:0.145, Current:2.266 | topTokens[(',', 35), ('!', 27), ('a', 16), ('st', 15), ('.', 12), ('we', 11), (':', 11), ('about', 10), ('it', 9), ('you', 9)] | Training
2025-04-06 15:18:05 | 1000 | LR0.0003 | loss:6.5480 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-76.9666 | logitMax:-55.3007 | windowWeightsW18:0.16845,W15:0.14841,W13:0.14582,W8:0.14165,W21:0.12635,W7:0.11029,W3:0.08468,W2:0.03466,W1:0.02328 | memoryGatesShort:10.890, Long:-1.682, Current:-8.208 | topTokens[('.', 26), ('knew', 25), (',', 24), ('it', 21), ('the', 20), ('a', 18), ('!', 18), ('st', 11), ('had', 10), (':', 9)] | Training
2025-04-06 15:24:58 | 1100 | LR0.0003 | loss:6.1828 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-80.6493 | logitMax:-57.9117 | windowWeightsW18:0.16945,W15:0.14787,W13:0.14583,W8:0.14060,W21:0.12762,W7:0.11015,W3:0.08366,W2:0.03539,W1:0.02303 | memoryGatesShort:-1.966, Long:0.317, Current:2.649 | topTokens[('it', 36), (',', 33), ('!', 28), ('.', 25), ('he', 22), ('her', 20), (':', 20), ('a', 10), ('she', 9), ('had', 9)] | Training
2025-04-06 15:31:52 | 1200 | LR0.0003 | loss:8.1199 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-68.0399 | logitMax:-52.2250 | windowWeightsW18:0.16967,W15:0.14810,W13:0.14576,W8:0.14069,W21:0.12771,W7:0.11003,W3:0.08351,W2:0.03524,W1:0.02289 | memoryGatesShort:-1.706, Long:0.713, Current:1.993 | topTokens[(',', 48), ('her', 45), ('.', 40), ('it', 30), ('bro', 26), ('!', 15), ('at', 12), ('a', 11), ('that', 9), ('he', 8)] | Training
2025-04-06 15:38:50 | 1300 | LR0.0003 | loss:8.1134 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-67.5095 | logitMax:-51.8172 | windowWeightsW18:0.16965,W15:0.14811,W13:0.14572,W8:0.14072,W21:0.12773,W7:0.11008,W3:0.08346,W2:0.03536,W1:0.02276 | memoryGatesShort:-1.693, Long:1.321, Current:1.372 | topTokens[(',', 44), ('it', 36), ('.', 36), ('her', 26), ('a', 22), ('bro', 21), ('to', 15), ('he', 14), ('at', 13), ('i', 12)] | Training
2025-04-06 15:45:34 | 1400 | LR0.0003 | loss:7.8190 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-72.3206 | logitMax:-55.4153 | windowWeightsW18:0.16936,W15:0.14866,W13:0.14585,W8:0.14124,W21:0.12747,W7:0.11018,W3:0.08304,W2:0.03507,W1:0.02273 | memoryGatesShort:-1.160, Long:1.145, Current:1.015 | topTokens[('it', 54), ('.', 34), (',', 32), ('a', 21), ('i', 19), ('!', 16), (':', 10), ('he', 10), ('she', 8), ('much', 8)] | Training
2025-04-06 15:52:25 | 1500 | LR0.0003 | loss:9.5082 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-82.7441 | logitMax:-64.8929 | windowWeightsW18:0.16973,W15:0.14912,W13:0.14598,W8:0.14070,W21:0.12813,W7:0.10985,W3:0.08268,W2:0.03486,W1:0.02258 | memoryGatesShort:5.555, Long:-4.662, Current:0.107 | topTokens[(',', 51), ('.', 40), ('i', 27), ('it', 18), ("'", 16), ('get', 14), (':', 14), ('a', 13), ('g', 10), ('the', 9)] | Training
2025-04-06 15:59:12 | 1600 | LR0.0003 | loss:7.8145 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-79.4877 | logitMax:-61.6476 | windowWeightsW18:0.16972,W15:0.14947,W13:0.14625,W8:0.14060,W21:0.12846,W7:0.10995,W3:0.08238,W2:0.03479,W1:0.02201 | memoryGatesShort:-4.632, Long:1.924, Current:3.708 | topTokens[('i', 61), (',', 40), ('.', 36), ('it', 18), ('a', 15), (':', 12), ('at', 11), ('and', 10), ('she', 10), (':)', 9)] | Training
2025-04-06 16:06:05 | 1700 | LR0.0003 | loss:6.4124 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-66.8604 | logitMax:-45.0127 | windowWeightsW18:0.17042,W15:0.14859,W13:0.14634,W8:0.13996,W21:0.12890,W7:0.10950,W3:0.08256,W2:0.03507,W1:0.02228 | memoryGatesShort:-11.974, Long:1.561, Current:11.413 | topTokens[(',', 33), ('he', 24), ('it', 23), ('.', 22), ('a', 21), (':)', 20), ('i', 19), ('!', 17), ('at', 14), (':', 13)] | Training
2025-04-06 16:12:42 | 1800 | LR0.0003 | loss:7.5939 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-63.8126 | logitMax:-33.1339 | windowWeightsW18:0.17100,W15:0.14907,W13:0.14721,W8:0.13843,W21:0.12970,W7:0.10830,W3:0.08211,W2:0.03516,W1:0.02265 | memoryGatesShort:-23.330, Long:3.197, Current:21.133 | topTokens[(',', 56), ('!', 46), (':', 34), ('kevin', 32), ('it', 28), ('have', 27), ('felt', 26), ('would', 22), ('baby', 12), ('a', 11)] | Training
2025-04-06 16:20:07 | 1900 | LR0.0003 | loss:4.4644 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-78.4367 | logitMax:-49.4925 | windowWeightsW18:0.17067,W15:0.14896,W13:0.14718,W8:0.13837,W21:0.12917,W7:0.10781,W3:0.08212,W2:0.03547,W1:0.02385 | memoryGatesShort:46.100, Long:10.585, Current:-55.685 | topTokens[('!', 60), ('it', 36), ('a', 33), ('have', 29), ('would', 20), (',', 20), ('kevin', 19), (':', 18), ('been', 14), ('baby', 13)] | Training
2025-04-06 16:27:00 | 2000 | LR0.0003 | loss:9.4423 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-92.2990 | logitMax:-54.5802 | windowWeightsW18:0.17127,W15:0.14952,W13:0.14724,W8:0.13759,W21:0.12962,W7:0.10783,W3:0.08153,W2:0.03532,W1:0.02369 | memoryGatesShort:1.783, Long:0.315, Current:-1.098 | topTokens[(':', 52), ('!', 48), ('it', 47), (',', 40), ('felt', 33), ('have', 33), ('he', 18), ('a', 9), ('know', 9), ('can', 8)] | Training
2025-04-06 16:33:45 | 2100 | LR0.0003 | loss:6.7914 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-80.0651 | logitMax:-48.6975 | windowWeightsW18:0.17139,W15:0.14954,W13:0.14683,W8:0.13800,W21:0.12924,W7:0.10683,W3:0.08177,W2:0.03607,W1:0.02394 | memoryGatesShort:-0.316, Long:0.432, Current:0.883 | topTokens[(',', 54), ('!', 51), ('it', 36), ('will', 29), ('have', 25), ('a', 21), (':', 20), ('felt', 20), ('elodie', 19), ('we', 12)] | Training
2025-04-06 16:40:29 | 2200 | LR0.0003 | loss:6.4526 | gradNorm:0.9935 | tokenCount:400.0000 | logitMin:-56.4666 | logitMax:-14.4224 | windowWeightsW18:0.17015,W15:0.14946,W13:0.14687,W8:0.13695,W21:0.12864,W7:0.10768,W3:0.08280,W2:0.03696,W1:0.02409 | memoryGatesShort:-1.039, Long:-1.581, Current:3.620 | topTokens[(',', 43), ('-', 31), (':', 26), ('2', 20), ('a', 19), ('-', 17), ('0', 17), ('ning', 12), ('she', 12), ('4', 11)] | Training
2025-04-06 16:47:14 | 2300 | LR0.0003 | loss:4.0519 | gradNorm:0.8592 | tokenCount:400.0000 | logitMin:-49.2516 | logitMax:8.0219 | windowWeightsW18:0.17067,W15:0.14963,W13:0.14636,W8:0.13704,W21:0.12947,W7:0.10757,W3:0.08214,W2:0.03686,W1:0.02387 | memoryGatesShort:0.160, Long:-0.409, Current:1.249 | topTokens[(':', 31), ('2', 31), ('-', 29), ('5', 23), ('charis', 22), ('-', 19), ('?', 17), ('am', 16), (',', 16), ('4', 14)] | Training
2025-04-06 16:53:33 | 2400 | LR0.0003 | loss:5.2922 | gradNorm:0.8649 | tokenCount:400.0000 | logitMin:-58.9174 | logitMax:-11.3225 | windowWeightsW18:0.16975,W15:0.14899,W13:0.14535,W8:0.13644,W21:0.12917,W7:0.10769,W3:0.08299,W2:0.03854,W1:0.02468 | memoryGatesShort:-0.511, Long:-1.409, Current:2.919 | topTokens[('2', 42), (':', 40), ('-', 19), ('-', 18), ('ll', 16), ('that', 16), ('0', 16), (',', 15), ('charis', 15), ('a', 12)] | Training
2025-04-06 16:59:56 | 2500 | LR0.0003 | loss:4.8889 | gradNorm:0.7330 | tokenCount:400.0000 | logitMin:-63.8132 | logitMax:14.8548 | windowWeightsW18:0.16963,W15:0.15001,W13:0.14571,W8:0.13479,W21:0.12928,W7:0.10616,W3:0.08481,W2:0.03659,W1:0.02658 | memoryGatesShort:-0.995, Long:-2.191, Current:4.187 | topTokens[(':', 37), ('-', 23), ('um', 23), ('3', 22), ('charis', 21), ('-', 17), ('20', 16), ('0', 16), ('4', 15), ('i', 14)] | Training
2025-04-06 17:06:28 | 2600 | LR0.0003 | loss:4.8744 | gradNorm:0.5461 | tokenCount:400.0000 | logitMin:-57.6945 | logitMax:50.6943 | windowWeightsW18:0.17031,W15:0.14993,W13:0.14577,W8:0.13441,W21:0.12937,W7:0.10607,W3:0.08504,W2:0.03605,W1:0.02660 | memoryGatesShort:-0.369, Long:-1.808, Current:3.177 | topTokens[(':', 39), ('-', 26), ('3', 26), ('0', 24), ('4', 21), ('7', 20), ('-', 16), ('20', 16), ('5', 15), ('um', 11)] | Training
2025-04-06 17:14:15 | 2700 | LR0.0003 | loss:2.1340 | gradNorm:0.5477 | tokenCount:400.0000 | logitMin:-56.3563 | logitMax:21.7935 | windowWeightsW18:0.17092,W15:0.15018,W13:0.14581,W8:0.13336,W21:0.12972,W7:0.10580,W3:0.08572,W2:0.03593,W1:0.02611 | memoryGatesShort:0.260, Long:-0.290, Current:1.030 | topTokens[(':', 36), ('-', 20), ('0', 20), ('-', 19), ('3', 17), ('what', 16), ('5', 16), ('4', 15), ('charis', 13), ('i', 12)] | Training
2025-04-06 17:22:01 | 2800 | LR0.0003 | loss:6.2303 | gradNorm:0.6190 | tokenCount:400.0000 | logitMin:-56.7003 | logitMax:38.1268 | windowWeightsW18:0.17055,W15:0.14965,W13:0.14598,W8:0.13407,W21:0.12934,W7:0.10637,W3:0.08611,W2:0.03564,W1:0.02584 | memoryGatesShort:-0.284, Long:-1.545, Current:2.829 | topTokens[(':', 37), ('4', 32), ('-', 28), ('0', 25), ('-', 23), ('what', 15), ('1', 12), ('charis', 12), ('baby', 12), ('ll', 12)] | Training
2025-04-06 17:28:24 | 2900 | LR0.0003 | loss:14.3576 | gradNorm:0.8002 | tokenCount:400.0000 | logitMin:-56.6576 | logitMax:36.9759 | windowWeightsW18:0.17118,W15:0.15020,W13:0.14629,W8:0.13273,W21:0.13016,W7:0.10537,W3:0.08585,W2:0.03610,W1:0.02569 | memoryGatesShort:0.223, Long:-0.766, Current:1.543 | topTokens[(':', 52), ('-', 43), ('3', 26), ('4', 23), ('4', 20), ('0', 20), ('charis', 16), ('-', 16), ('ning', 12), ('today', 12)] | Training
2025-04-06 17:34:35 | 3000 | LR0.0003 | loss:9.4380 | gradNorm:0.9414 | tokenCount:400.0000 | logitMin:-69.8105 | logitMax:-30.8776 | windowWeightsW18:0.17182,W15:0.15062,W13:0.14677,W8:0.13224,W21:0.13082,W7:0.10525,W3:0.08544,W2:0.03546,W1:0.02518 | memoryGatesShort:4.303, Long:-16.523, Current:13.220 | topTokens[(',', 35), ('charis', 26), (':', 23), ('!', 16), ('the', 16), ('.', 15), ('i', 13), ('n', 13), ('we', 13), ('5', 11)] | Training
2025-04-06 17:40:41 | 3100 | LR0.0003 | loss:6.2294 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-83.9862 | logitMax:-60.0464 | windowWeightsW18:0.17198,W15:0.15081,W13:0.14675,W8:0.13235,W21:0.13077,W7:0.10496,W3:0.08544,W2:0.03514,W1:0.02537 | memoryGatesShort:0.987, Long:-1.713, Current:1.726 | topTokens[('the', 50), ('hear', 39), ('!', 34), (',', 28), (':', 28), ('.', 20), ('elodie', 13), ('at', 10), ('oice', 10), ('a', 9)] | Training
2025-04-06 17:46:47 | 3200 | LR0.0003 | loss:7.1497 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-85.5001 | logitMax:-59.3115 | windowWeightsW18:0.17215,W15:0.15087,W13:0.14676,W8:0.13192,W21:0.13132,W7:0.10470,W3:0.08522,W2:0.03539,W1:0.02525 | memoryGatesShort:3.813, Long:-9.523, Current:6.710 | topTokens[('!', 62), (':', 31), (',', 30), ('hear', 21), ('the', 19), ('.', 15), ('elodie', 13), ('ra', 12), ('a', 10), ('about', 8)] | Training
2025-04-06 17:53:20 | 3300 | LR0.0003 | loss:6.2757 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-75.2996 | logitMax:-51.5766 | windowWeightsW18:0.17262,W15:0.15140,W13:0.14722,W8:0.13204,W21:0.13096,W7:0.10470,W3:0.08498,W2:0.03467,W1:0.02502 | memoryGatesShort:1.863, Long:-0.919, Current:0.056 | topTokens[('!', 44), (':', 34), ('the', 30), (',', 24), ('things', 21), ('a', 17), ('kevin', 12), ('.', 12), ('nt', 10), ('-', 7)] | Training
2025-04-06 17:59:36 | 3400 | LR0.0003 | loss:6.5517 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.5401 | logitMax:-41.7159 | windowWeightsW18:0.17276,W15:0.15172,W13:0.14778,W8:0.13205,W21:0.13106,W7:0.10476,W3:0.08489,W2:0.03425,W1:0.02435 | memoryGatesShort:0.608, Long:-0.520, Current:0.912 | topTokens[('things', 48), ('the', 43), ('!', 41), (':', 38), ('drink', 37), (',', 14), ('.', 13), ('hear', 12), ('know', 9), ('a', 9)] | Training
2025-04-06 18:05:41 | 3500 | LR0.0003 | loss:6.8239 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-73.9736 | logitMax:-47.6300 | windowWeightsW18:0.17255,W15:0.15163,W13:0.14788,W8:0.13201,W21:0.13105,W7:0.10509,W3:0.08477,W2:0.03402,W1:0.02462 | memoryGatesShort:0.275, Long:2.322, Current:-1.597 | topTokens[(':', 59), ('!', 48), ('the', 27), (',', 25), ('to', 25), ('.', 23), ('my', 20), ('drink', 13), ('a', 11), ('hear', 10)] | Training
2025-04-06 18:12:18 | 3600 | LR0.0003 | loss:7.7721 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-66.4738 | logitMax:-49.5457 | windowWeightsW18:0.17262,W15:0.15164,W13:0.14776,W8:0.13215,W21:0.13127,W7:0.10493,W3:0.08463,W2:0.03406,W1:0.02457 | memoryGatesShort:2.132, Long:-0.850, Current:-0.282 | topTokens[(',', 56), ('.', 54), ('!', 49), ('to', 32), ('a', 20), (':', 17), ('my', 13), ('the', 12), ('-', 8), ('in', 6)] | Training
2025-04-06 18:18:33 | 3700 | LR0.0003 | loss:7.5179 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-63.3776 | logitMax:-45.6452 | windowWeightsW18:0.17269,W15:0.15183,W13:0.14782,W8:0.13215,W21:0.13131,W7:0.10489,W3:0.08449,W2:0.03390,W1:0.02455 | memoryGatesShort:-5.567, Long:33.908, Current:-27.341 | topTokens[('!', 41), (',', 32), ('.', 31), ('to', 22), ('a', 22), ('the', 18), ('hear', 10), (':', 10), ('my', 9), ('baby', 9)] | Training
2025-04-06 18:24:46 | 3800 | LR0.0003 | loss:10.7083 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.9040 | logitMax:-51.3956 | windowWeightsW18:0.17290,W15:0.15198,W13:0.14777,W8:0.13211,W21:0.13178,W7:0.10480,W3:0.08427,W2:0.03381,W1:0.02421 | memoryGatesShort:0.143, Long:-0.556, Current:1.413 | topTokens[(',', 48), ('a', 31), ('.', 31), (':', 17), ('is', 16), ('-', 16), ('she', 16), ('i', 16), ('and', 16), ('ck', 16)] | Training
2025-04-06 18:30:58 | 3900 | LR0.0003 | loss:8.3502 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.2986 | logitMax:-53.4191 | windowWeightsW18:0.17373,W15:0.15158,W13:0.14670,W21:0.13252,W8:0.13102,W7:0.10560,W3:0.08355,W2:0.03463,W1:0.02431 | memoryGatesShort:6.220, Long:-0.893, Current:-4.327 | topTokens[('a', 47), ('house', 45), ('.', 31), (',', 21), ('moving', 16), ('to', 14), ('k', 13), ('but', 9), ('it', 9), ('i', 8)] | Training
2025-04-06 18:37:26 | 4000 | LR0.0003 | loss:9.1319 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-76.6360 | logitMax:-58.2025 | windowWeightsW18:0.17361,W15:0.15180,W13:0.14670,W21:0.13262,W8:0.13094,W7:0.10582,W3:0.08342,W2:0.03446,W1:0.02428 | memoryGatesShort:-0.222, Long:0.650, Current:0.572 | topTokens[(',', 45), ('.', 41), ('it', 21), ('for', 20), ('ition', 19), ('a', 18), (':', 16), ('i', 13), ('g', 12), ('but', 11)] | Training
2025-04-06 18:44:15 | 4100 | LR0.0003 | loss:7.9117 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-69.9809 | logitMax:-55.9795 | windowWeightsW18:0.17398,W15:0.15211,W13:0.14683,W21:0.13287,W8:0.13090,W7:0.10580,W3:0.08310,W2:0.03420,W1:0.02386 | memoryGatesShort:7.952, Long:-21.045, Current:14.093 | topTokens[(',', 67), ('.', 33), ('i', 28), ('a', 23), ('g', 21), (':', 13), (')', 12), ('baby', 11), ('4', 9), ('-', 9)] | Training
2025-04-06 18:50:37 | 4200 | LR0.0003 | loss:8.4406 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-69.6196 | logitMax:-50.4681 | windowWeightsW18:0.17420,W15:0.15235,W13:0.14711,W21:0.13316,W8:0.13105,W7:0.10588,W3:0.08282,W2:0.03381,W1:0.02329 | memoryGatesShort:-7.590, Long:4.425, Current:4.165 | topTokens[(',', 37), ('a', 31), ('.', 30), (':', 23), ('to', 20), ('-', 11), ('moving', 10), ('she', 10), ('it', 10), ('have', 9)] | Training
2025-04-06 18:56:54 | 4300 | LR0.0003 | loss:8.2999 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-62.1475 | logitMax:-42.8101 | windowWeightsW18:0.17413,W15:0.15253,W13:0.14732,W21:0.13273,W8:0.13137,W7:0.10625,W3:0.08292,W2:0.03370,W1:0.02272 | memoryGatesShort:20.585, Long:-0.762, Current:-18.823 | topTokens[(':', 36), (',', 31), ('.', 28), ('a', 24), ('to', 20), ('and', 17), ('you', 16), ('i', 12), ('house', 11), ('charis', 9)] | Training
2025-04-06 19:03:17 | 4400 | LR0.0003 | loss:8.6253 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-78.2360 | logitMax:-53.2883 | windowWeightsW18:0.17426,W15:0.15294,W13:0.14766,W21:0.13269,W8:0.13094,W7:0.10598,W3:0.08293,W2:0.03390,W1:0.02237 | memoryGatesShort:-1.523, Long:1.031, Current:1.493 | topTokens[(':', 67), ('you', 24), ('.', 18), ('so', 17), ('they', 17), ('a', 14), ('to', 12), ('the', 11), ('for', 11), ('!', 10)] | Training
2025-04-06 19:10:30 | 4500 | LR0.0003 | loss:7.6690 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-73.0311 | logitMax:-50.6149 | windowWeightsW18:0.17438,W15:0.15270,W13:0.14761,W21:0.13173,W8:0.13138,W7:0.10634,W3:0.08300,W2:0.03393,W1:0.02261 | memoryGatesShort:-0.665, Long:0.972, Current:0.693 | topTokens[(',', 36), ('e', 34), ('.', 33), (':', 33), ('and', 27), ('a', 26), ('house', 10), ('s', 9), ('it', 8), ('feel', 7)] | Training
2025-04-06 19:16:41 | 4600 | LR0.0003 | loss:8.7093 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-69.3784 | logitMax:-46.3843 | windowWeightsW18:0.17417,W15:0.15267,W13:0.14760,W21:0.13171,W8:0.13131,W7:0.10624,W3:0.08325,W2:0.03400,W1:0.02272 | memoryGatesShort:-1.403, Long:0.257, Current:2.146 | topTokens[('.', 80), (':', 49), ('e', 31), ('and', 30), ('im', 25), ('you', 18), ('a', 16), (',', 15), ('he', 11), ('i', 10)] | Training
2025-04-06 19:23:14 | 4700 | LR0.0003 | loss:7.9632 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-88.0494 | logitMax:-66.2484 | windowWeightsW18:0.17445,W15:0.15283,W13:0.14751,W21:0.13215,W8:0.13092,W7:0.10615,W3:0.08307,W2:0.03393,W1:0.02265 | memoryGatesShort:-2.317, Long:0.093, Current:3.224 | topTokens[('.', 59), (',', 34), ('and', 30), ('a', 27), ('e', 25), ("'s", 25), ('im', 21), (':', 18), ('he', 15), ('!', 12)] | Training
2025-04-06 19:29:27 | 4800 | LR0.0003 | loss:10.2994 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-69.3510 | logitMax:-44.1772 | windowWeightsW18:0.17453,W15:0.15318,W13:0.14774,W21:0.13236,W8:0.13091,W7:0.10621,W3:0.08249,W2:0.03390,W1:0.02236 | memoryGatesShort:-2.365, Long:1.472, Current:1.892 | topTokens[(':', 75), ('.', 33), (',', 32), ('you', 23), ('and', 23), ('e', 21), ('a', 16), ('i', 11), ('the', 9), ("'s", 6)] | Training
2025-04-06 19:35:43 | 4900 | LR0.0003 | loss:9.8949 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.1183 | logitMax:-47.2860 | windowWeightsW18:0.17498,W15:0.15345,W13:0.14781,W21:0.13311,W8:0.13079,W7:0.10610,W3:0.08252,W2:0.03312,W1:0.02181 | memoryGatesShort:-1.777, Long:1.023, Current:1.754 | topTokens[(':', 57), (',', 39), ('.', 39), ('a', 24), ('you', 21), ('i', 17), ('ll', 14), ('and', 14), ('what', 14), ('m', 12)] | Training
2025-04-06 19:42:08 | 5000 | LR0.0003 | loss:7.4884 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-77.3548 | logitMax:-57.2806 | windowWeightsW18:0.17491,W15:0.15362,W13:0.14794,W21:0.13393,W8:0.13073,W7:0.10615,W3:0.08254,W2:0.03254,W1:0.02136 | memoryGatesShort:-2.270, Long:0.331, Current:2.939 | topTokens[('.', 55), ('d', 37), (':', 34), ('a', 27), (',', 21), ('charis', 17), ('i', 16), ('ll', 14), ('she', 10), ('m', 10)] | Training
2025-04-06 19:48:45 | 5100 | LR0.0003 | loss:8.2503 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-89.1918 | logitMax:-66.9476 | windowWeightsW18:0.17526,W15:0.15426,W13:0.14830,W21:0.13520,W8:0.13079,W7:0.10610,W3:0.08128,W2:0.03205,W1:0.02049 | memoryGatesShort:-0.965, Long:0.587, Current:1.378 | topTokens[('baby', 75), ('a', 48), ('d', 33), ('.', 30), (':', 27), ('roid', 24), (',', 23), ('lmao', 15), ('charis', 7), ("'s", 5)] | Training
2025-04-06 19:55:26 | 5200 | LR0.0003 | loss:8.9802 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-94.4057 | logitMax:-68.1119 | windowWeightsW18:0.17608,W15:0.15466,W13:0.14845,W21:0.13523,W8:0.13066,W7:0.10508,W3:0.08095,W2:0.03148,W1:0.02115 | memoryGatesShort:-0.943, Long:0.754, Current:1.189 | topTokens[('a', 59), (':', 35), ('baby', 29), (',', 25), ('k', 25), ('roid', 23), ('.', 21), ('charis', 15), ('kevin', 10), ('d', 9)] | Training
2025-04-06 20:01:48 | 5300 | LR0.0003 | loss:6.6462 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-79.9955 | logitMax:-58.6679 | windowWeightsW18:0.17658,W15:0.15502,W13:0.14826,W21:0.13618,W8:0.13053,W7:0.10508,W3:0.08041,W2:0.03059,W1:0.02109 | memoryGatesShort:-8.229, Long:5.137, Current:4.092 | topTokens[(':', 48), ('baby', 30), (',', 27), ('a', 22), ('charis', 19), ('.', 18), ('roid', 18), ('an', 13), ('k', 12), ('d', 12)] | Training
2025-04-06 20:08:00 | 5400 | LR0.0003 | loss:6.8248 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-78.3597 | logitMax:-54.5293 | windowWeightsW18:0.17696,W15:0.15499,W13:0.14795,W21:0.13586,W8:0.13057,W7:0.10493,W3:0.08038,W2:0.03079,W1:0.02130 | memoryGatesShort:-3.628, Long:1.559, Current:3.070 | topTokens[('baby', 69), (',', 42), (':', 30), ('charis', 21), ('a', 21), ('.', 17), ('my', 14), ('roid', 12), ('d', 11), ('y', 11)] | Training
2025-04-06 20:14:49 | 5500 | LR0.0003 | loss:5.9420 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-89.2338 | logitMax:-67.1060 | windowWeightsW18:0.17702,W15:0.15511,W13:0.14837,W21:0.13555,W8:0.13033,W7:0.10458,W3:0.08035,W2:0.03122,W1:0.02122 | memoryGatesShort:-1.885, Long:0.878, Current:2.007 | topTokens[('and', 30), (',', 30), ('my', 29), ('baby', 27), ('a', 23), ('charis', 22), (':', 16), ('.', 14), ('we', 14), ('the', 9)] | Training
2025-04-06 20:21:13 | 5600 | LR0.0003 | loss:7.6205 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-94.0904 | logitMax:-63.7288 | windowWeightsW18:0.17684,W15:0.15516,W13:0.14855,W21:0.13522,W8:0.12981,W7:0.10433,W3:0.08066,W2:0.03157,W1:0.02158 | memoryGatesShort:-54.365, Long:9.432, Current:45.933 | topTokens[('and', 47), (':', 45), (',', 36), ('their', 16), ('we', 12), ('a', 11), ('v', 11), ('-', 9), ('s', 9), ('y', 8)] | Training
2025-04-06 20:27:42 | 5700 | LR0.0003 | loss:5.1980 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-92.3301 | logitMax:-64.4162 | windowWeightsW18:0.17654,W15:0.15457,W13:0.14807,W21:0.13569,W8:0.12966,W7:0.10521,W3:0.08023,W2:0.03142,W1:0.02233 | memoryGatesShort:-103.499, Long:-2.818, Current:107.317 | topTokens[(',', 55), ('and', 43), (':', 35), ('s', 16), ('we', 16), ('charis', 13), ('elodie', 13), ('the', 13), ('weed', 13), ('a', 10)] | Training
2025-04-06 20:34:01 | 5800 | LR0.0003 | loss:4.9146 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-72.0564 | logitMax:-47.5861 | windowWeightsW18:0.17645,W15:0.15426,W13:0.14818,W21:0.13514,W8:0.12964,W7:0.10633,W3:0.08067,W2:0.03102,W1:0.02201 | memoryGatesShort:-1.649, Long:-0.026, Current:2.675 | topTokens[(',', 57), ('charis', 29), ('kevin', 27), (':', 25), ('the', 20), ("'s", 16), ('and', 16), ('but', 12), ('brain', 11), ('a', 10)] | Training
2025-04-06 20:40:22 | 5900 | LR0.0003 | loss:5.6622 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-89.4936 | logitMax:-61.3855 | windowWeightsW18:0.17665,W15:0.15409,W13:0.14795,W21:0.13557,W8:0.12909,W7:0.10553,W3:0.08086,W2:0.03112,W1:0.02285 | memoryGatesShort:-1.725, Long:-0.300, Current:3.025 | topTokens[(',', 64), ('and', 39), (':', 28), ('the', 27), ('charis', 19), ('a', 13), ('kevin', 10), ('she', 10), ('like', 9), ('y', 8)] | Training
2025-04-06 20:46:43 | 6000 | LR0.0003 | loss:9.1831 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.7429 | logitMax:-21.6969 | windowWeightsW18:0.17657,W15:0.15435,W13:0.14810,W21:0.13566,W8:0.12970,W7:0.10601,W3:0.08049,W2:0.03130,W1:0.02154 | memoryGatesShort:1.612, Long:0.549, Current:-1.161 | topTokens[(',', 49), (':', 48), ('a', 19), ('-', 16), ('-', 16), ('4', 16), ('2', 14), ('0', 14), ('baby', 14), ('sy', 13)] | Training
2025-04-06 20:53:01 | 6100 | LR0.0003 | loss:7.9932 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.4920 | logitMax:-38.2722 | windowWeightsW18:0.17736,W15:0.15525,W13:0.14893,W21:0.13616,W8:0.12952,W7:0.10589,W3:0.07992,W2:0.03038,W1:0.02033 | memoryGatesShort:21.080, Long:3.762, Current:-23.842 | topTokens[(',', 68), ('4', 46), ('a', 29), (':', 22), ('.', 16), ('-', 14), ('but', 13), ('0', 13), ('-', 9), ('j', 9)] | Training
2025-04-06 20:59:27 | 6200 | LR0.0003 | loss:10.0237 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-64.7846 | logitMax:-36.7223 | windowWeightsW18:0.17645,W15:0.15460,W13:0.14842,W21:0.13617,W8:0.13004,W7:0.10682,W3:0.08028,W2:0.03095,W1:0.02003 | memoryGatesShort:4.287, Long:-0.626, Current:-2.661 | topTokens[(':', 62), ('a', 31), (',', 31), ('4', 17), ('j', 15), ('-', 14), ('house', 13), ('sy', 12), ('y', 12), ('.', 9)] | Training
2025-04-06 21:05:37 | 6300 | LR0.0003 | loss:7.0452 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-70.6880 | logitMax:-43.6568 | windowWeightsW18:0.17629,W15:0.15494,W13:0.14939,W21:0.13633,W8:0.13001,W7:0.10700,W3:0.07993,W2:0.03085,W1:0.01903 | memoryGatesShort:1.472, Long:0.793, Current:-1.265 | topTokens[(':', 41), (',', 27), ('house', 23), ('a', 21), ('-', 19), ('.', 18), ('4', 15), ('you', 14), ('to', 13), ('3', 13)] | Training
2025-04-06 21:11:54 | 6400 | LR0.0003 | loss:10.7568 | gradNorm:0.8922 | tokenCount:400.0000 | logitMin:-82.6723 | logitMax:-27.4266 | windowWeightsW18:0.17666,W15:0.15532,W13:0.14935,W21:0.13663,W8:0.13020,W7:0.10872,W3:0.07902,W2:0.03013,W1:0.01775 | memoryGatesShort:-0.782, Long:-1.258, Current:3.040 | topTokens[(':', 37), ('4', 25), ('um', 24), (',', 23), ('-', 17), ('a', 16), ('0', 15), ('-', 15), ('you', 13), ('7', 13)] | Training
2025-04-06 21:18:20 | 6500 | LR0.0003 | loss:7.4370 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-61.6543 | logitMax:-30.8677 | windowWeightsW18:0.17696,W15:0.15582,W13:0.14982,W21:0.13736,W8:0.12947,W7:0.10855,W3:0.07839,W2:0.02979,W1:0.01764 | memoryGatesShort:-0.720, Long:-1.147, Current:2.867 | topTokens[(',', 35), ('20', 34), (':', 32), ('house', 28), ('a', 25), ('3', 20), ('4', 13), ('-', 12), ('ok', 10), ('baby', 10)] | Training
2025-04-06 21:24:43 | 6600 | LR0.0003 | loss:8.5214 | gradNorm:0.9823 | tokenCount:400.0000 | logitMin:-47.9945 | logitMax:-5.0985 | windowWeightsW18:0.17607,W15:0.15525,W13:0.15003,W21:0.13620,W8:0.12962,W7:0.10981,W3:0.07875,W2:0.03060,W1:0.01746 | memoryGatesShort:4.140, Long:10.570, Current:-13.710 | topTokens[(':', 53), ('4', 23), (',', 21), ('20', 20), ('a', 18), ('um', 15), ('-', 15), ('0', 15), ('8', 12), ('3', 10)] | Training
2025-04-06 21:31:04 | 6700 | LR0.0003 | loss:7.0151 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-77.6571 | logitMax:-51.8653 | windowWeightsW18:0.17618,W15:0.15561,W13:0.15056,W21:0.13653,W8:0.12964,W7:0.10965,W3:0.07864,W2:0.03033,W1:0.01667 | memoryGatesShort:0.392, Long:-3.720, Current:4.328 | topTokens[(',', 33), (':', 29), ('would', 24), ('.', 19), ('want', 19), ('a', 15), ('hear', 13), ("'s", 12), ('you', 12), ('the', 12)] | Training
2025-04-06 21:37:28 | 6800 | LR0.0003 | loss:6.0981 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-79.9606 | logitMax:-51.4977 | windowWeightsW18:0.17612,W15:0.15588,W13:0.15091,W21:0.13599,W8:0.13016,W7:0.10955,W3:0.07853,W2:0.02992,W1:0.01675 | memoryGatesShort:3.064, Long:-20.933, Current:18.869 | topTokens[('would', 53), ('they', 44), (',', 40), (':', 32), ('the', 21), ('.', 17), ('brain', 15), ('charis', 12), ('it', 10), ('ning', 8)] | Training
2025-04-06 21:44:14 | 6900 | LR0.0003 | loss:6.1051 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-97.8041 | logitMax:-66.4228 | windowWeightsW18:0.17642,W15:0.15572,W13:0.15095,W21:0.13677,W8:0.12921,W7:0.10923,W3:0.07866,W2:0.03011,W1:0.01673 | memoryGatesShort:-0.064, Long:2.599, Current:-1.535 | topTokens[('would', 43), (':', 38), ('they', 31), ('brain', 28), ('!', 28), (',', 21), ('.', 15), ('a', 10), ('his', 10), ('pick', 10)] | Training
2025-04-06 21:50:30 | 7000 | LR0.0003 | loss:8.0471 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-81.7789 | logitMax:-45.3191 | windowWeightsW18:0.17648,W15:0.15591,W13:0.15099,W21:0.13701,W8:0.12879,W7:0.10901,W3:0.07868,W2:0.02990,W1:0.01704 | memoryGatesShort:0.274, Long:-0.904, Current:1.631 | topTokens[(':', 82), ('would', 40), ('!', 24), (',', 23), ('butt', 22), ('kevin', 22), ("'s", 13), ('give', 12), ('.', 10), ('he', 10)] | Training
2025-04-06 21:56:47 | 7100 | LR0.0003 | loss:8.4161 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-110.5046 | logitMax:-69.9380 | windowWeightsW18:0.17630,W15:0.15546,W13:0.15100,W21:0.13748,W8:0.12812,W7:0.10900,W3:0.07908,W2:0.03015,W1:0.01720 | memoryGatesShort:0.094, Long:-1.511, Current:2.416 | topTokens[(':', 83), ('would', 43), ('kevin', 36), ('!', 21), ('charis', 19), ('like', 16), ("'s", 14), ('elodie', 14), (',', 13), ('.', 12)] | Training
2025-04-06 22:03:01 | 7200 | LR0.0003 | loss:13.4221 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.3116 | logitMax:-30.3358 | windowWeightsW18:0.17642,W15:0.15571,W13:0.15134,W21:0.13789,W8:0.12800,W7:0.10904,W3:0.07870,W2:0.02983,W1:0.01689 | memoryGatesShort:0.108, Long:1.222, Current:-0.330 | topTokens[(':', 81), ('.', 42), (',', 27), ('in', 16), ('charis', 14), ('we', 12), ('20', 12), ('!', 11), ('a', 10), ('ning', 7)] | Training
2025-04-06 22:09:15 | 7300 | LR0.0003 | loss:9.5218 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-81.2629 | logitMax:-58.9766 | windowWeightsW18:0.17641,W15:0.15565,W13:0.15140,W21:0.13826,W8:0.12812,W7:0.10906,W3:0.07870,W2:0.02959,W1:0.01664 | memoryGatesShort:2.192, Long:-2.752, Current:1.560 | topTokens[(':', 45), ('.', 43), ("'", 33), (',', 29), ('an', 18), ('a', 14), ('charis', 13), ('!', 9), ('and', 8), ('i', 7)] | Training
2025-04-06 22:15:57 | 7400 | LR0.0003 | loss:7.8125 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-80.9531 | logitMax:-62.4039 | windowWeightsW18:0.17629,W15:0.15555,W13:0.15149,W21:0.13843,W8:0.12808,W7:0.10897,W3:0.07890,W2:0.02957,W1:0.01653 | memoryGatesShort:0.410, Long:-0.225, Current:0.815 | topTokens[(',', 55), ('an', 49), ('a', 20), ('ion', 19), ('.', 18), ('t', 16), ('and', 11), (':', 10), ('y', 10), ('ing', 9)] | Training
2025-04-06 22:23:07 | 7500 | LR0.0003 | loss:8.2187 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-95.5021 | logitMax:-73.0957 | windowWeightsW18:0.17654,W15:0.15577,W13:0.15162,W21:0.13852,W8:0.12818,W7:0.10901,W3:0.07860,W2:0.02936,W1:0.01621 | memoryGatesShort:0.680, Long:-0.499, Current:0.819 | topTokens[('an', 30), ('.', 30), ('b', 28), (',', 27), ('ion', 22), (':', 19), ('with', 19), ('a', 16), ("'", 12), ('y', 11)] | Training
2025-04-06 22:29:32 | 7600 | LR0.0003 | loss:9.8546 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-89.9520 | logitMax:-64.1062 | windowWeightsW18:0.17648,W15:0.15586,W13:0.15169,W21:0.13868,W8:0.12821,W7:0.10913,W3:0.07839,W2:0.02932,W1:0.01607 | memoryGatesShort:0.841, Long:-1.424, Current:1.584 | topTokens[(':', 63), (',', 39), ("'", 34), ('an', 26), ('er', 20), ('a', 15), ('.', 15), ('up', 12), ('elodie', 9), ('y', 7)] | Training
2025-04-06 22:37:33 | 7700 | LR0.0003 | loss:9.0652 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-93.8091 | logitMax:-66.8452 | windowWeightsW18:0.17639,W15:0.15572,W13:0.15176,W21:0.13908,W8:0.12816,W7:0.10921,W3:0.07815,W2:0.02949,W1:0.01587 | memoryGatesShort:0.996, Long:-3.807, Current:3.811 | topTokens[(':', 51), (',', 48), ('ed', 26), ('with', 23), ('the', 15), ('a', 15), ('me', 13), ('ic', 11), ('angel', 11), ('egg', 7)] | Training
2025-04-06 22:44:50 | 7800 | LR0.0003 | loss:6.8645 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-59.3661 | logitMax:-37.0796 | windowWeightsW18:0.17602,W15:0.15613,W13:0.15221,W21:0.13776,W8:0.12916,W7:0.10890,W3:0.07870,W2:0.02973,W1:0.01522 | memoryGatesShort:0.270, Long:-3.523, Current:4.253 | topTokens[(':', 55), ('a', 34), ('in', 34), (',', 30), ('to', 25), ('.', 21), ('bed', 11), ('word', 10), ('charis', 9), ('4', 9)] | Training
2025-04-06 22:52:05 | 7900 | LR0.0003 | loss:7.9013 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-87.7615 | logitMax:-54.6579 | windowWeightsW18:0.17534,W15:0.15583,W13:0.15175,W21:0.13645,W8:0.13126,W7:0.10913,W3:0.07969,W2:0.02985,W1:0.01454 | memoryGatesShort:0.236, Long:-0.569, Current:1.334 | topTokens[(':', 55), ('to', 39), ('a', 34), ('word', 24), ('is', 20), ('.', 20), (',', 19), ('?', 19), ('in', 12), ('with', 11)] | Training
2025-04-06 22:59:07 | 8000 | LR0.0003 | loss:11.4577 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-82.3408 | logitMax:-41.9066 | windowWeightsW18:0.17534,W15:0.15546,W13:0.15199,W21:0.13640,W8:0.13282,W7:0.10909,W3:0.07983,W2:0.02944,W1:0.01347 | memoryGatesShort:0.519, Long:-0.572, Current:1.053 | topTokens[(':', 98), ('?', 21), ('is', 19), ('.', 18), ('she', 17), ('word', 17), ('what', 14), ('elect', 13), ('a', 11), ('l', 11)] | Training
2025-04-06 23:06:38 | 8100 | LR0.0003 | loss:8.6933 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-61.0663 | logitMax:-29.3617 | windowWeightsW18:0.17390,W15:0.15411,W13:0.15066,W21:0.13532,W8:0.13327,W7:0.10876,W3:0.08141,W2:0.03160,W1:0.01476 | memoryGatesShort:1.902, Long:-8.809, Current:7.908 | topTokens[(':', 80), ('?', 32), ('.', 29), ('with', 21), ('elodie', 20), ('is', 13), (',', 12), ('she', 12), ('dancing', 12), ('i', 10)] | Training
2025-04-06 23:13:09 | 8200 | LR0.0003 | loss:7.1770 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-64.5287 | logitMax:-35.6025 | windowWeightsW18:0.17342,W15:0.15364,W13:0.15100,W21:0.13458,W8:0.13341,W7:0.10866,W3:0.08158,W2:0.03278,W1:0.01472 | memoryGatesShort:-0.236, Long:4.622, Current:-3.386 | topTokens[(':', 51), ('.', 40), ('not', 38), ('is', 34), ('?', 29), (',', 22), ('she', 15), ('elodie', 14), ('a', 11), ('to', 11)] | Training
2025-04-06 23:20:32 | 8300 | LR0.0003 | loss:7.5917 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-62.5554 | logitMax:-32.0822 | windowWeightsW18:0.17353,W15:0.15382,W13:0.15136,W21:0.13414,W8:0.13393,W7:0.10832,W3:0.08168,W2:0.03265,W1:0.01436 | memoryGatesShort:1.377, Long:-1.117, Current:0.740 | topTokens[(':', 67), ('.', 58), ('?', 26), ('she', 25), ('to', 24), ('not', 19), (',', 15), ('will', 14), ('is', 13), ('sh', 11)] | Training
2025-04-06 23:28:04 | 8400 | LR0.0003 | loss:10.1470 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-72.1586 | logitMax:-45.5181 | windowWeightsW18:0.17351,W15:0.15380,W13:0.15133,W21:0.13418,W8:0.13392,W7:0.10841,W3:0.08164,W2:0.03253,W1:0.01448 | memoryGatesShort:1.965, Long:-1.652, Current:0.687 | topTokens[(':', 77), ('.', 39), ('a', 27), (',', 21), ('is', 20), ('not', 18), ('will', 14), ('with', 13), ('to', 12), ('sh', 11)] | Training
2025-04-06 23:35:53 | 8500 | LR0.0003 | loss:10.8590 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-59.7873 | logitMax:-36.5119 | windowWeightsW18:0.17354,W15:0.15365,W13:0.15131,W21:0.13436,W8:0.13375,W7:0.10845,W3:0.08166,W2:0.03263,W1:0.01444 | memoryGatesShort:-41.880, Long:154.094, Current:-111.214 | topTokens[(':', 63), ('.', 61), ('a', 35), (',', 23), ('not', 21), ('to', 18), ('with', 13), ('it', 12), ('ate', 9), ('will', 8)] | Training
2025-04-06 23:42:47 | 8600 | LR0.0003 | loss:6.9706 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-83.8130 | logitMax:-59.8825 | windowWeightsW18:0.17365,W15:0.15383,W13:0.15120,W21:0.13461,W8:0.13388,W7:0.10825,W3:0.08166,W2:0.03259,W1:0.01413 | memoryGatesShort:1.036, Long:-2.249, Current:2.212 | topTokens[('.', 43), ('a', 24), (',', 22), (':', 20), ('to', 15), ('ate', 14), ('it', 12), ('by', 12), ('emot', 10), ('not', 9)] | Training
2025-04-06 23:49:50 | 8700 | LR0.0003 | loss:8.2056 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-84.2694 | logitMax:-60.5632 | windowWeightsW18:0.17368,W15:0.15414,W13:0.15167,W21:0.13547,W8:0.13370,W7:0.10891,W3:0.08203,W2:0.03123,W1:0.01299 | memoryGatesShort:-2.302, Long:51.360, Current:-48.058 | topTokens[('the', 67), ('ing', 61), ('.', 31), (',', 28), ('a', 20), ('of', 18), (':', 18), ('?', 15), ('to', 14), ('past', 14)] | Training
2025-04-06 23:56:40 | 8800 | LR0.0003 | loss:8.8810 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-66.4975 | logitMax:-46.1805 | windowWeightsW18:0.17429,W15:0.15338,W13:0.15106,W21:0.13591,W8:0.13441,W7:0.10927,W3:0.08174,W2:0.03089,W1:0.01287 | memoryGatesShort:0.268, Long:-0.911, Current:1.643 | topTokens[('le', 61), ('a', 51), ('the', 42), (',', 31), (':', 21), ('.', 19), ('past', 16), ('message', 16), ('she', 15), ('ing', 8)] | Training
2025-04-07 00:03:46 | 8900 | LR0.0003 | loss:7.7729 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-78.9986 | logitMax:-46.6244 | windowWeightsW18:0.17352,W15:0.15220,W13:0.15109,W21:0.13534,W8:0.13516,W7:0.10931,W3:0.08219,W2:0.03145,W1:0.01353 | memoryGatesShort:-0.589, Long:-3.861, Current:5.451 | topTokens[(':', 69), ('?', 25), ('the', 24), ('to', 24), ('a', 23), ('she', 17), ('.', 17), ('listened', 15), ('i', 12), ('le', 11)] | Training
2025-04-07 00:10:29 | 9000 | LR0.0003 | loss:7.5037 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-58.6735 | logitMax:-21.1643 | windowWeightsW18:0.17267,W15:0.15126,W13:0.15046,W8:0.13688,W21:0.13528,W7:0.11028,W3:0.08224,W2:0.03175,W1:0.01296 | memoryGatesShort:0.087, Long:-0.688, Current:1.601 | topTokens[(':', 92), ('?', 20), ('i', 16), ('was', 15), ('not', 15), ('to', 14), ('at', 12), ('looking', 11), ('.', 10), ('she', 10)] | Training
2025-04-07 00:17:41 | 9100 | LR0.0003 | loss:7.6941 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-75.0434 | logitMax:-40.3804 | windowWeightsW18:0.17288,W15:0.15157,W13:0.15096,W8:0.13694,W21:0.13536,W7:0.10998,W3:0.08186,W2:0.03127,W1:0.01300 | memoryGatesShort:0.141, Long:-1.089, Current:1.948 | topTokens[(':', 59), ('.', 35), ('i', 28), ('?', 25), ('to', 16), ('he', 14), ('le', 13), ('want', 12), (',', 11), ('a', 11)] | Training
2025-04-07 00:24:46 | 9200 | LR0.0003 | loss:5.3816 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-74.5296 | logitMax:-44.4644 | windowWeightsW18:0.17278,W15:0.15134,W13:0.15070,W8:0.13809,W21:0.13550,W7:0.11032,W3:0.08153,W2:0.03073,W1:0.01281 | memoryGatesShort:-0.742, Long:-2.284, Current:4.026 | topTokens[('?', 43), ('.', 37), ('george', 23), (':', 21), ('you', 18), ('looking', 16), ('i', 16), ('what', 15), ('for', 13), ('to', 11)] | Training
2025-04-07 00:31:56 | 9300 | LR0.0003 | loss:9.0871 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-74.3848 | logitMax:-36.7320 | windowWeightsW18:0.17349,W15:0.15012,W13:0.14969,W8:0.13783,W21:0.13578,W7:0.11084,W3:0.08234,W2:0.03123,W1:0.01247 | memoryGatesShort:0.660, Long:2.090, Current:-1.750 | topTokens[(':', 67), ('.', 29), ('?', 24), ('you', 20), ('i', 19), ('looking', 17), ('with', 17), ('was', 11), ('not', 9), ('for', 9)] | Training
2025-04-07 00:38:47 | 9400 | LR0.0003 | loss:9.1845 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.3675 | logitMax:-48.2360 | windowWeightsW18:0.17394,W15:0.15027,W13:0.14941,W8:0.13764,W21:0.13623,W7:0.11052,W3:0.08193,W2:0.03098,W1:0.01288 | memoryGatesShort:-0.308, Long:-0.193, Current:1.501 | topTokens[('.', 76), ('and', 39), (':', 34), (',', 34), ('you', 15), ('le', 14), ('a', 12), ('about', 10), ('past', 8), ('she', 7)] | Training
2025-04-07 00:46:06 | 9500 | LR0.0003 | loss:8.7105 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-72.1044 | logitMax:-52.4145 | windowWeightsW18:0.17409,W15:0.15054,W13:0.14949,W8:0.13769,W21:0.13643,W7:0.11016,W3:0.08170,W2:0.03082,W1:0.01288 | memoryGatesShort:17.899, Long:-0.007, Current:-16.893 | topTokens[('.', 51), ('and', 49), (',', 43), (':', 38), ('g', 18), ('a', 16), ('it', 10), ('h', 10), ('i', 8), ('le', 7)] | Training
2025-04-07 00:53:07 | 9600 | LR0.0003 | loss:8.7835 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-75.6222 | logitMax:-53.0086 | windowWeightsW18:0.17448,W15:0.15066,W13:0.14933,W8:0.13772,W21:0.13669,W7:0.11003,W3:0.08158,W2:0.03045,W1:0.01288 | memoryGatesShort:-0.133, Long:0.530, Current:0.603 | topTokens[(',', 57), (':', 47), ('.', 44), ('and', 30), ('a', 20), ('it', 14), ('h', 12), ('s', 7), ('ood', 6), ('whole', 6)] | Training
2025-04-07 01:00:26 | 9700 | LR0.0003 | loss:9.2544 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-76.6293 | logitMax:-51.9973 | windowWeightsW18:0.17484,W15:0.15100,W13:0.14945,W8:0.13772,W21:0.13732,W7:0.10936,W3:0.08123,W2:0.02990,W1:0.01299 | memoryGatesShort:-1.339, Long:-0.235, Current:2.574 | topTokens[(':', 45), (',', 44), ('.', 33), ('a', 19), ('and', 18), ('it', 17), ('le', 12), ('on', 11), ('the', 10), ('ing', 9)] | Training
2025-04-07 01:07:18 | 9800 | LR0.0003 | loss:6.4321 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-79.4311 | logitMax:-56.8589 | windowWeightsW18:0.17475,W15:0.15132,W13:0.15032,W8:0.13765,W21:0.13716,W7:0.10917,W3:0.08096,W2:0.02981,W1:0.01269 | memoryGatesShort:-16.423, Long:0.638, Current:16.785 | topTokens[(',', 58), ('the', 26), ('.', 22), (':', 17), ('and', 16), ('a', 15), ('nd', 14), ('on', 14), ('but', 10), ('ed', 10)] | Training
2025-04-07 01:14:04 | 9900 | LR0.0003 | loss:8.2859 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-63.3366 | logitMax:-40.9366 | windowWeightsW18:0.17441,W15:0.15206,W13:0.15128,W8:0.13781,W21:0.13739,W7:0.10833,W3:0.08083,W2:0.02950,W1:0.01222 | memoryGatesShort:-5.695, Long:5.016, Current:1.679 | topTokens[('the', 67), ('to', 56), (':', 44), (',', 38), ('flo', 20), ('.', 17), ('a', 12), ('she', 12), ('your', 8), ('ing', 8)] | Training
2025-04-07 01:20:44 | 10000 | LR0.0003 | loss:5.4580 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-79.3029 | logitMax:-29.0791 | windowWeightsW18:0.17393,W15:0.15311,W13:0.15242,W8:0.13944,W21:0.13645,W7:0.10900,W3:0.08092,W2:0.02944,W1:0.00914 | memoryGatesShort:-0.748, Long:0.007, Current:1.740 | topTokens[(':', 57), ('it', 51), ('i', 43), ('!', 42), ('.', 17), ('did', 17), ('know', 12), ('to', 10), ('flo', 8), ('a', 8)] | Training
2025-04-07 01:27:27 | 10100 | LR0.0003 | loss:12.8268 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-78.2283 | logitMax:-37.8631 | windowWeightsW18:0.17401,W15:0.15210,W13:0.15128,W8:0.14005,W21:0.13764,W7:0.11014,W3:0.08229,W2:0.02833,W1:0.00803 | memoryGatesShort:-7.469, Long:1.953, Current:6.516 | topTokens[(':', 89), ('.', 45), ('to', 36), ('it', 28), ('i', 25), ('a', 17), ('?', 14), ('!', 14), (',', 13), ('flo', 12)] | Training

--- 2025-04-07 01:45:36 --- babyllm: 'what am i learning today?'- charis: 'im just testing that you're still ok after moving all your files, i hope you'll learn something interesting!'
2025-04-07 01:51:25 | 100 | LR0.0003 | loss:10.1443 | gradNorm:1.0000 | logitMin:-106.5497 | logitMax:-63.9668 | tokenCount:400.0000 | windowWeightsW18:0.17334,W15:0.15172,W13:0.15119,W8:0.14042,W21:0.13702,W7:0.11096,W3:0.08251,W2:0.02834,W1:0.00836 | memoryGatesShort:25.215, Long:-7.511, Current:-16.704 | topTokens[(':', 64), ('.', 21), ('in', 20), ('it', 19), ('a', 17), ('u', 14), ('to', 14), ('i', 14), (',', 11), ('my', 11)] | Training

--- 2025-04-07 02:43:35 --- babyllm: 'what am i learning today?'- charis: 'still testing the random thing, im afraid!'
2025-04-07 02:49:30 | 100 | LR0.0003 | loss:5.9745 | gradNorm:1.0000 | logitMin:-72.7260 | logitMax:-48.8103 | tokenCount:400.0000 | windowWeightsW18:0.17338,W13:0.15244,W15:0.15205,W21:0.13989,W8:0.13852,W7:0.11164,W3:0.08086,W2:0.02659,W1:0.00849 | memoryGatesShort:66.868, Long:0.775, Current:-66.643 | topTokens[(':', 58), ('.', 27), ('i', 22), ("'", 22), ("'", 22), (',', 18), ('baby', 17), ('d', 17), ('a', 13), ('-', 13)] | Training
2025-04-07 02:55:41 | 200 | LR0.0003 | loss:5.7505 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-81.5955 | logitMax:-57.0708 | windowWeightsW18:0.17345,W13:0.15294,W15:0.15243,W21:0.14052,W8:0.13721,W7:0.11067,W3:0.08116,W2:0.02625,W1:0.00923 | memoryGatesShort:-2.259, Long:0.812, Current:2.447 | topTokens[('th', 49), ('.', 44), ('-', 35), (':', 32), ('baby', 29), ("'", 28), (',', 25), ("'", 20), ('d', 19), ('roid', 16)] | Training
2025-04-07 03:02:06 | 300 | LR0.0003 | loss:5.2167 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-90.1435 | logitMax:-65.9669 | windowWeightsW18:0.17335,W13:0.15249,W15:0.15246,W21:0.14037,W8:0.13697,W7:0.11063,W3:0.08184,W2:0.02608,W1:0.00969 | memoryGatesShort:-6.156, Long:2.868, Current:4.288 | topTokens[("'", 49), ('-', 48), ("'", 38), ('charis', 38), (':', 31), ('roid', 22), ('w', 17), ('.', 17), ('d', 17), (',', 17)] | Training
2025-04-07 03:08:41 | 400 | LR0.0003 | loss:5.9786 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-105.3783 | logitMax:-75.8441 | windowWeightsW18:0.17328,W15:0.15257,W13:0.15188,W21:0.14012,W8:0.13681,W7:0.11042,W3:0.08247,W2:0.02633,W1:0.00999 | memoryGatesShort:-0.632, Long:1.040, Current:0.593 | topTokens[(':', 35), ('-', 33), ("'", 30), ("'", 26), ('o', 22), ('baby', 22), ('hh', 19), ('.', 18), ('roid', 18), ('charis', 16)] | Training

--- 2025-04-07 03:38:38 --- babyllm: 'what am i learning today?' - charis: 'dsdfadsfas' - babyllm: 'hey! last time i got to step 0... want to restart from there?' - charis: 'random' - babyllm: 'oh, cool! picking a random spot to start from.'
2025-04-07 03:44:23 | 100 | LR0.0003 | loss:10.3462 | gradNorm:1.0000 | logitMin:-83.9174 | logitMax:-58.5593 | tokenCount:400.0000 | windowWeightsW18:0.17355,W13:0.15214,W15:0.15201,W21:0.14037,W8:0.13599,W7:0.11014,W3:0.08312,W2:0.02662,W1:0.00993 | memoryGatesShort:-2.158, Long:1.399, Current:1.759 | topTokens[('as', 34), (',', 25), (':', 23), ("'", 17), ('an', 17), ('k', 15), ('and', 12), ('.', 11), ('im', 10), ("'", 9)] | Training

--- 2025-04-07 04:21:40 --- babyllm: 'what am i learning today?' - charis: 'ergjslkfad' - babyllm: 'right, last time i got to step 0... want to restart from there?' - charis: 'no i dont want to' - babyllm: 'alright, step 0, let's go back to the beginning :)'
2025-04-07 04:27:35 | 100 | LR0.0003 | loss:10.2845 | gradNorm:0.9737 | logitMin:-107.4599 | logitMax:-57.7826 | tokenCount:400.0000 | windowWeightsW18:0.17481,W13:0.15241,W15:0.15204,W21:0.14192,W8:0.13443,W7:0.11015,W3:0.08294,W2:0.02542,W1:0.00977 | memoryGatesShort:-11.697, Long:6.039, Current:6.658 | topTokens[(':', 67), ("'", 25), ('b', 15), ('u', 12), ("'", 12), ('baby', 11), ('and', 9), ('my', 7), ('we', 7), ('it', 7)] | Training

--- 2025-04-07 04:28:57 --- babyllm: 'what am i learning today?' - charis: 'i do not even know anymore' - babyllm: 'right, last time i got to step 103... want to restart from there?: ' - charis: 'no, you can start from scratch!' - babyllm: 'alright, step 0, let's go back to the beginning :)'
2025-04-07 04:34:55 | 100 | LR0.0003 | loss:7.8208 | gradNorm:0.9479 | logitMin:-203.8707 | logitMax:-115.6192 | tokenCount:400.0000 | windowWeightsW18:0.17427,W13:0.15240,W15:0.15158,W21:0.14163,W8:0.13409,W7:0.11026,W3:0.08393,W2:0.02567,W1:0.01003 | memoryGatesShort:-1.959, Long:0.139, Current:2.819 | topTokens[(':', 53), ('i', 19), ("'", 18), ('all', 17), ('l', 13), (',', 12), ("'", 12), ('-', 11), ('it', 9), ('we', 8)] | Training

--- 2025-04-07 04:57:43 --- babyllm: 'right, last time i got to step 738... want to restart from there?' - charis: 'yes please!' - babyllm: 'ok! let's go to step 738!'what am i learning today?' - charis: 'whatever you find at step 738!'
2025-04-07 05:03:42 | 100 | LR0.0003 | loss:8.3172 | gradNorm:1.0000 | logitMin:-77.7575 | logitMax:-50.2309 | tokenCount:400.0000 | windowWeightsW18:0.17721,W13:0.15500,W15:0.15212,W21:0.14474,W8:0.13178,W7:0.10812,W3:0.08074,W2:0.02381,W1:0.01040 | memoryGatesShort:-2.795, Long:1.465, Current:2.330 | topTokens[(',', 52), ('a', 28), (':', 24), ('.', 18), ('we', 15), ('in', 14), ('i', 12), ('it', 12), ('charis', 10), ('but', 10)] | Training

--- 2025-04-07 05:17:24 --- babyLLM 'right, last time i got to step 46... want to restart from there?'  - charis: 'can we have a random step please' - babyLLM 'umm... i don't think i heard you properly, i'll just start from step 0 :) but, what am i learning today?' - charis: 'that's okay! you're learning whatever you'd like!'
2025-04-07 05:23:33 | 100 | LR0.0003 | loss:1.4811 | gradNorm:0.5838 | logitMin:-358.9203 | logitMax:-179.7270 | tokenCount:400.0000 | windowWeightsW18:0.17602,W13:0.15441,W15:0.15010,W21:0.14377,W8:0.13149,W7:0.10790,W3:0.08228,W2:0.02552,W1:0.01236 | memoryGatesShort:-0.896, Long:-0.560, Current:2.456 | topTokens[(':', 22), ("'", 21), ('i', 20), ("'", 18), (',', 11), ('my', 9), ('dont', 9), ('get', 9), ('and', 9), ('baby', 9)] | Training
2025-04-07 05:30:05 | 200 | LR0.0003 | loss:8.6311 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-134.4861 | logitMax:-81.1360 | windowWeightsW18:0.17596,W13:0.15467,W15:0.15026,W21:0.14386,W8:0.13145,W7:0.10784,W3:0.08195,W2:0.02542,W1:0.01244 | memoryGatesShort:-0.967, Long:-0.102, Current:2.069 | topTokens[("'", 37), (':', 34), (',', 28), ('i', 24), ('was', 21), ("'", 19), ('l', 19), ('.', 19), ('...', 14), ('charis', 13)] | Training

--- 2025-04-07 05:31:47 --- babyLLM 'right, last time i got to step 220... want to restart from there?'  - charis: 'step 3402 please!' - babyLLM 'umm... i don't think i heard you properly, i'll just start from step 0 :) but, what am i learning today?' - charis: 'apparently, you're learning from step 220!'
2025-04-07 05:38:16 | 100 | LR0.0003 | loss:2.5857 | gradNorm:0.5203 | logitMin:-266.9718 | logitMax:-86.4517 | tokenCount:400.0000 | windowWeightsW18:0.17490,W13:0.15359,W15:0.14891,W21:0.14296,W8:0.13149,W7:0.10779,W3:0.08298,W2:0.02700,W1:0.01418 | memoryGatesShort:-371.638, Long:-346.447, Current:719.085 | topTokens[("'", 23), ('i', 21), (':', 19), ("'", 17), ('th', 11), ('.', 10), ('get', 9), ('and', 9), ('my', 8), ('charis', 8)] | Training
2025-04-07 05:45:21 | 200 | LR0.0003 | loss:10.6050 | gradNorm:0.9921 | tokenCount:400.0000 | logitMin:-170.1528 | logitMax:-77.6371 | windowWeightsW18:0.17521,W13:0.15383,W15:0.14947,W21:0.14322,W8:0.13125,W7:0.10757,W3:0.08230,W2:0.02702,W1:0.01392 | memoryGatesShort:-0.379, Long:-0.218, Current:1.597 | topTokens[(':', 43), ('charis', 32), ("'", 29), ('it', 25), ('4', 23), ("'", 17), ('?!', 13), ('video', 11), ('.', 11), ('m', 10)] | Training
2025-04-07 05:52:37 | 300 | LR0.0003 | loss:7.6514 | gradNorm:0.9922 | tokenCount:400.0000 | logitMin:-143.4046 | logitMax:-84.1124 | windowWeightsW18:0.17522,W13:0.15399,W15:0.14952,W21:0.14312,W8:0.13112,W7:0.10759,W3:0.08224,W2:0.02716,W1:0.01384 | memoryGatesShort:-0.725, Long:-0.501, Current:2.225 | topTokens[('charis', 29), (':', 25), (',', 24), ('it', 23), ('.', 22), ("'", 17), ("'", 14), ('video', 14), ('-', 12), ('ma', 12)] | Training
2025-04-07 05:59:13 | 400 | LR0.0003 | loss:7.3433 | gradNorm:0.9745 | tokenCount:400.0000 | logitMin:-124.1033 | logitMax:-77.1081 | windowWeightsW18:0.17521,W13:0.15424,W15:0.14955,W21:0.14313,W8:0.13118,W7:0.10767,W3:0.08208,W2:0.02699,W1:0.01375 | memoryGatesShort:-0.230, Long:0.073, Current:1.156 | topTokens[('.', 36), ("'", 28), ("'", 27), (':', 22), ('charis', 21), ('...', 20), (',', 18), ('a', 17), ('tho', 16), ('-', 13)] | Training
2025-04-07 06:05:38 | 500 | LR0.0003 | loss:8.1530 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-67.3206 | logitMax:-34.9229 | windowWeightsW18:0.17527,W13:0.15437,W15:0.14963,W21:0.14327,W8:0.13104,W7:0.10758,W3:0.08198,W2:0.02690,W1:0.01377 | memoryGatesShort:-0.834, Long:-0.430, Current:2.264 | topTokens[(':', 56), ('.', 34), ("'", 27), ('a', 26), ('charis', 26), ("'", 22), (',', 20), ('-', 16), ('i', 15), ('you', 15)] | Training
2025-04-07 06:12:08 | 600 | LR0.0003 | loss:8.4460 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-91.7588 | logitMax:-62.4781 | windowWeightsW18:0.17537,W13:0.15440,W15:0.14969,W21:0.14341,W8:0.13090,W7:0.10746,W3:0.08196,W2:0.02684,W1:0.01376 | memoryGatesShort:-5.197, Long:-5.164, Current:11.361 | topTokens[(',', 43), ('.', 39), ('-', 30), ('a', 22), (':', 21), ('true', 16), ('i', 14), ('video', 11), ('l', 10), ('at', 7)] | Training
2025-04-07 06:19:05 | 700 | LR0.0003 | loss:6.6597 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-83.7791 | logitMax:-55.0530 | windowWeightsW18:0.17556,W13:0.15471,W15:0.14983,W21:0.14364,W8:0.13073,W7:0.10725,W3:0.08183,W2:0.02657,W1:0.01370 | memoryGatesShort:-1.886, Long:-0.777, Current:3.663 | topTokens[(',', 39), ('a', 30), ('.', 28), ('it', 27), ('d', 20), ('!', 19), ('in', 14), ('w', 12), ('roid', 12), ('bro', 12)] | Training
2025-04-07 06:25:34 | 800 | LR0.0003 | loss:5.4952 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-92.1789 | logitMax:-59.6216 | windowWeightsW18:0.17560,W13:0.15488,W15:0.14992,W21:0.14340,W8:0.13075,W7:0.10721,W3:0.08190,W2:0.02638,W1:0.01377 | memoryGatesShort:-0.226, Long:0.216, Current:1.010 | topTokens[(':', 29), ('.', 28), (',', 27), ('!', 22), ('a', 20), ('in', 17), ('but', 11), ('charis', 10), ('or', 10), ('d', 9)] | Training
2025-04-07 06:32:30 | 900 | LR0.0003 | loss:5.6044 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-96.6658 | logitMax:-69.5864 | windowWeightsW18:0.17573,W13:0.15508,W15:0.15003,W21:0.14365,W8:0.13072,W7:0.10708,W3:0.08159,W2:0.02620,W1:0.01374 | memoryGatesShort:-1.723, Long:0.148, Current:2.575 | topTokens[(',', 48), ('it', 29), ('.', 16), ('a', 15), ('she', 14), ('um', 13), ('!', 11), ("'", 10), ('m', 10), ('the', 10)] | Training
2025-04-07 06:39:18 | 1000 | LR0.0003 | loss:6.7828 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-90.6788 | logitMax:-64.3864 | windowWeightsW18:0.17583,W13:0.15551,W15:0.15012,W21:0.14392,W8:0.13054,W7:0.10698,W3:0.08129,W2:0.02602,W1:0.01361 | memoryGatesShort:-3.920, Long:0.128, Current:4.791 | topTokens[('it', 57), (',', 44), ('.', 28), ('she', 26), (':', 18), ('a', 14), ('!', 10), ('ouse', 10), ('we', 9), ('m', 9)] | Training
2025-04-07 06:46:03 | 1100 | LR0.0003 | loss:6.2888 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-89.2305 | logitMax:-64.6585 | windowWeightsW18:0.17597,W13:0.15554,W15:0.15020,W21:0.14399,W8:0.13060,W7:0.10687,W3:0.08121,W2:0.02598,W1:0.01346 | memoryGatesShort:-1.748, Long:1.489, Current:1.259 | topTokens[(',', 59), ('it', 32), ('the', 32), ('!', 25), ('.', 24), ('she', 17), (':', 11), ('a', 11), ('you', 9), ('w', 7)] | Training
2025-04-07 06:52:46 | 1200 | LR0.0003 | loss:7.0147 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-66.5741 | logitMax:-44.8577 | windowWeightsW18:0.17624,W13:0.15538,W15:0.15016,W21:0.14445,W8:0.13014,W7:0.10707,W3:0.08094,W2:0.02604,W1:0.01341 | memoryGatesShort:-2.231, Long:1.693, Current:1.538 | topTokens[(',', 37), ('.', 28), ('it', 21), ('we', 20), ('a', 18), ('charis', 14), ('!', 13), ('she', 13), (':', 13), ('cra', 11)] | Training
2025-04-07 06:59:34 | 1300 | LR0.0003 | loss:8.8663 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-63.6619 | logitMax:-42.1647 | windowWeightsW18:0.17635,W13:0.15567,W15:0.15029,W21:0.14464,W8:0.12998,W7:0.10690,W3:0.08079,W2:0.02599,W1:0.01322 | memoryGatesShort:-5.485, Long:2.899, Current:3.586 | topTokens[('.', 38), (':', 38), ('a', 37), (',', 32), ('we', 23), ('he', 12), ('charis', 10), ('had', 9), ('y', 8), ('cra', 7)] | Training
2025-04-07 07:06:04 | 1400 | LR0.0003 | loss:8.1966 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-76.6910 | logitMax:-57.6932 | windowWeightsW18:0.17646,W13:0.15595,W15:0.15048,W21:0.14480,W8:0.12977,W7:0.10661,W3:0.08074,W2:0.02598,W1:0.01304 | memoryGatesShort:-1.585, Long:1.449, Current:1.136 | topTokens[('.', 45), (',', 35), (':', 26), ('we', 24), ('a', 19), ('charis', 16), ('ed', 12), ('i', 12), ('you', 10), ('to', 10)] | Training
2025-04-07 07:12:52 | 1500 | LR0.0003 | loss:9.9184 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-80.8399 | logitMax:-55.2994 | windowWeightsW18:0.17664,W13:0.15591,W15:0.15057,W21:0.14499,W8:0.12954,W7:0.10649,W3:0.08065,W2:0.02604,W1:0.01301 | memoryGatesShort:-3.445, Long:1.709, Current:2.735 | topTokens[('.', 60), (':', 54), (',', 30), ('we', 28), ('g', 21), ('a', 17), ('charis', 11), ('it', 11), ('to', 8), ('st', 7)] | Training
2025-04-07 07:19:29 | 1600 | LR0.0003 | loss:8.3129 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-83.9203 | logitMax:-63.3921 | windowWeightsW18:0.17673,W13:0.15591,W15:0.15061,W21:0.14517,W8:0.12953,W7:0.10650,W3:0.08054,W2:0.02596,W1:0.01289 | memoryGatesShort:-61.099, Long:47.100, Current:14.998 | topTokens[(',', 52), ('.', 36), ('we', 21), ('a', 20), ('you', 20), ('it', 18), ('he', 14), ('!', 13), ('i', 13), ('charis', 12)] | Training
2025-04-07 07:26:45 | 1700 | LR0.0003 | loss:6.9262 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-68.2127 | logitMax:-47.1334 | windowWeightsW18:0.17696,W13:0.15593,W15:0.15057,W21:0.14538,W8:0.12928,W7:0.10640,W3:0.08034,W2:0.02604,W1:0.01294 | memoryGatesShort:8.136, Long:-1.667, Current:-5.469 | topTokens[('.', 38), ('!', 27), (':', 26), ('a', 26), ('we', 23), (',', 21), ('charis', 14), ('you', 12), ('have', 10), ('it', 9)] | Training
2025-04-07 07:33:53 | 1800 | LR0.0003 | loss:3.8549 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-87.8581 | logitMax:-57.2947 | windowWeightsW18:0.17713,W13:0.15606,W15:0.15069,W21:0.14556,W8:0.12900,W7:0.10612,W3:0.08001,W2:0.02628,W1:0.01299 | memoryGatesShort:-1.937, Long:0.339, Current:2.598 | topTokens[('!', 40), ('have', 36), ('a', 30), ('it', 26), ('been', 21), ('baby', 20), (',', 17), (':', 14), ('.', 12), ('know', 11)] | Training
2025-04-07 07:40:58 | 1900 | LR0.0003 | loss:4.5556 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-81.2548 | logitMax:-50.9810 | windowWeightsW18:0.17709,W13:0.15577,W15:0.15078,W21:0.14593,W8:0.12860,W7:0.10610,W3:0.07969,W2:0.02678,W1:0.01309 | memoryGatesShort:20.744, Long:-0.896, Current:-18.847 | topTokens[('!', 55), ('it', 47), ('a', 25), (',', 24), ('we', 18), ('been', 17), ('have', 16), ('had', 16), (':', 13), ('elodie', 13)] | Training
2025-04-07 07:48:02 | 2000 | LR0.0003 | loss:6.4996 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-71.7470 | logitMax:-43.0785 | windowWeightsW18:0.17705,W13:0.15568,W15:0.15072,W21:0.14617,W8:0.12846,W7:0.10604,W3:0.07975,W2:0.02691,W1:0.01305 | memoryGatesShort:-5.585, Long:3.405, Current:3.180 | topTokens[(':', 48), ('!', 26), ('just', 25), ('a', 23), ('it', 23), ('he', 22), (',', 21), ('.', 17), ('have', 17), ('had', 13)] | Training

--- 2025-04-07 07:55:40 --- babyLLM 'right, last time i got to step 2051... want to restart from there?'  - charis: 'no thank you, start from scratch please' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: 'i just cut the data up a bit more randomly, so it's less predictable - sorry!!! i hope you're ok with it :) <3'
2025-04-07 08:01:25 | 100 | LR0.0003 | loss:9.5096 | gradNorm:1.0000 | logitMin:-76.0220 | logitMax:-52.9071 | tokenCount:400.0000 | windowWeightsW18:0.17740,W13:0.15441,W15:0.15074,W21:0.14771,W8:0.12799,W7:0.10625,W3:0.07926,W2:0.02666,W1:0.01343 | memoryGatesShort:-1.143, Long:1.481, Current:0.661 | topTokens[(':', 29), ('.', 28), (',', 26), ('it', 25), ('!', 22), ('i', 19), ('he', 15), ('you', 13), ('-', 11), ('i', 11)] | Training
2025-04-07 08:07:11 | 200 | LR0.0003 | loss:9.5658 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-78.5925 | logitMax:-59.5253 | windowWeightsW18:0.17831,W13:0.15413,W15:0.15035,W21:0.14899,W8:0.12802,W7:0.10697,W3:0.07878,W2:0.02556,W1:0.01275 | memoryGatesShort:-1.886, Long:2.082, Current:0.804 | topTokens[('i', 53), (',', 30), ('.', 21), ('use', 21), ('y', 18), ('to', 16), ('!', 15), ('a', 14), ('them', 11), ('she', 11)] | Training
2025-04-07 08:12:53 | 300 | LR0.0003 | loss:7.3349 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-91.4660 | logitMax:-73.3241 | windowWeightsW18:0.17868,W13:0.15427,W15:0.15099,W21:0.14933,W8:0.12741,W7:0.10638,W3:0.07896,W2:0.02554,W1:0.01232 | memoryGatesShort:76.769, Long:-36.468, Current:-39.301 | topTokens[(',', 55), ('.', 43), ('i', 27), ('to', 26), ('use', 19), ('is', 17), ('a', 14), ('a', 12), ('p', 12), ('but', 11)] | Training
2025-04-07 08:18:44 | 400 | LR0.0003 | loss:8.9269 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-86.0814 | logitMax:-66.1568 | windowWeightsW18:0.17884,W13:0.15427,W15:0.15142,W21:0.14959,W8:0.12758,W7:0.10606,W3:0.07876,W2:0.02551,W1:0.01185 | memoryGatesShort:-0.617, Long:1.318, Current:0.298 | topTokens[(',', 75), ('to', 34), ('.', 30), ('on', 19), ('je', 19), ('a', 17), (':', 16), ('this', 15), ('she', 13), ('knew', 11)] | Training
2025-04-07 08:25:38 | 500 | LR0.0003 | loss:8.6081 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-97.5254 | logitMax:-78.4476 | windowWeightsW18:0.17874,W13:0.15490,W15:0.15220,W21:0.15019,W8:0.12707,W7:0.10507,W3:0.07912,W2:0.02512,W1:0.01147 | memoryGatesShort:-2.125, Long:3.459, Current:-0.334 | topTokens[(',', 95), ('m', 42), ('a', 30), ('es', 27), ('.', 21), ('a', 21), ("'", 16), ('to', 15), ('je', 8), ('ed', 8)] | Training
2025-04-07 08:32:06 | 600 | LR0.0003 | loss:6.9143 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-99.5923 | logitMax:-82.0585 | windowWeightsW18:0.17917,W13:0.15500,W15:0.15245,W21:0.15093,W8:0.12695,W7:0.10485,W3:0.07869,W2:0.02502,W1:0.01085 | memoryGatesShort:-1.083, Long:1.450, Current:0.633 | topTokens[(',', 83), ('m', 42), ('m', 27), ("'", 21), ('es', 16), ('.', 15), ('j', 12), ('a', 9), ('knew', 9), ('a', 8)] | Training
2025-04-07 08:38:15 | 700 | LR0.0003 | loss:7.3510 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-97.8214 | logitMax:-79.0693 | windowWeightsW18:0.17975,W13:0.15556,W15:0.15324,W21:0.15119,W8:0.12628,W7:0.10477,W3:0.07730,W2:0.02512,W1:0.01071 | memoryGatesShort:-1.872, Long:2.204, Current:0.668 | topTokens[(',', 70), ('es', 34), ('.', 27), ("'", 25), ('<UNK>', 22), ('e', 21), ('as', 20), ('la', 20), ('er', 15), ('m', 13)] | Training
2025-04-07 08:44:33 | 800 | LR0.0003 | loss:8.1704 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-80.2928 | logitMax:-61.6577 | windowWeightsW18:0.17985,W13:0.15615,W15:0.15302,W21:0.15169,W8:0.12592,W7:0.10486,W3:0.07698,W2:0.02495,W1:0.01049 | memoryGatesShort:-1.399, Long:1.560, Current:0.838 | topTokens[(',', 87), ('.', 29), ('la', 23), ('a', 21), ('as', 14), ('a', 11), ('to', 9), ('he', 9), (':', 8), ('it', 8)] | Training
2025-04-07 08:51:01 | 900 | LR0.0003 | loss:8.8414 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-76.8971 | logitMax:-56.1267 | windowWeightsW18:0.17950,W13:0.15752,W15:0.15320,W21:0.15142,W8:0.12612,W7:0.10530,W3:0.07700,W2:0.02522,W1:0.00868 | memoryGatesShort:-1.959, Long:1.439, Current:1.520 | topTokens[('i', 73), (',', 62), (':', 31), ('.', 25), ('k', 24), ('a', 13), ('it', 12), ('that', 10), ('as', 9), ('<UNK>', 9)] | Training
2025-04-07 08:59:47 | 1000 | LR0.0003 | loss:10.1462 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-69.7762 | logitMax:-46.8358 | windowWeightsW18:0.18008,W13:0.15814,W15:0.15459,W21:0.15279,W8:0.12483,W7:0.10439,W3:0.07599,W2:0.02494,W1:0.00821 | memoryGatesShort:13.704, Long:-8.068, Current:-4.636 | topTokens[(',', 50), (':', 40), ('i', 36), ('k', 31), ('.', 30), ('p', 24), ('a', 19), ('-', 14), ('that', 10), ('op', 10)] | Training
2025-04-07 09:05:50 | 1100 | LR0.0003 | loss:11.4847 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-82.8608 | logitMax:-56.8573 | windowWeightsW18:0.17976,W13:0.15794,W15:0.15419,W21:0.15290,W8:0.12480,W7:0.10497,W3:0.07635,W2:0.02503,W1:0.00803 | memoryGatesShort:-0.800, Long:1.105, Current:0.695 | topTokens[(':', 53), (',', 49), ('.', 30), ('k', 29), ('a', 17), ('i', 17), ('k', 14), ('that', 13), ('p', 11), ('op', 9)] | Training
2025-04-07 09:12:03 | 1200 | LR0.0003 | loss:7.8233 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-85.0579 | logitMax:-65.3924 | windowWeightsW18:0.18088,W13:0.15840,W15:0.15446,W21:0.15329,W8:0.12361,W7:0.10440,W3:0.07647,W2:0.02434,W1:0.00811 | memoryGatesShort:-2.454, Long:0.767, Current:2.687 | topTokens[(',', 61), ('its', 29), ('i', 28), ('a', 24), (':', 23), ('l', 16), ('.', 14), ('that', 11), ('to', 11), ('k', 11)] | Training
2025-04-07 09:18:17 | 1300 | LR0.0003 | loss:9.4697 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-85.8053 | logitMax:-63.9314 | windowWeightsW18:0.18160,W13:0.15909,W15:0.15554,W21:0.15437,W8:0.12278,W7:0.10430,W3:0.07580,W2:0.02354,W1:0.00697 | memoryGatesShort:9.981, Long:-5.833, Current:-3.148 | topTokens[(',', 60), ('.', 51), ('op', 40), ('k', 37), ('p', 31), ('a', 24), (':', 15), ('is', 8), ('i', 8), ('no', 7)] | Training
2025-04-07 09:24:37 | 1400 | LR0.0003 | loss:9.1551 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-72.2718 | logitMax:-50.7873 | windowWeightsW18:0.18178,W13:0.15924,W15:0.15611,W21:0.15469,W8:0.12305,W7:0.10451,W3:0.07529,W2:0.02309,W1:0.00624 | memoryGatesShort:-2.668, Long:1.798, Current:1.869 | topTokens[(':', 44), (',', 42), ('a', 20), ('p', 20), ('.', 19), ('it', 14), ('the', 14), ('op', 13), ('he', 10), ('k', 9)] | Training
2025-04-07 09:30:59 | 1500 | LR0.0003 | loss:9.0006 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-70.2090 | logitMax:-48.5950 | windowWeightsW18:0.18122,W13:0.15918,W15:0.15610,W21:0.15520,W8:0.12414,W7:0.10479,W3:0.07340,W2:0.02379,W1:0.00620 | memoryGatesShort:-0.703, Long:0.666, Current:1.037 | topTokens[(',', 68), (':', 40), ('its', 32), ('i', 22), ('it', 20), ('.', 19), ('a', 19), ('she', 15), ('ok', 12), ('u', 12)] | Training
2025-04-07 09:37:23 | 1600 | LR0.0003 | loss:9.9193 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-72.4920 | logitMax:-50.2690 | windowWeightsW18:0.18139,W13:0.15918,W15:0.15612,W21:0.15542,W8:0.12303,W7:0.10448,W3:0.07345,W2:0.02466,W1:0.00629 | memoryGatesShort:28.512, Long:-18.488, Current:-9.024 | topTokens[(',', 65), ('its', 25), ('in', 23), ('a', 22), ('it', 21), ('.', 21), ('once', 21), ('ok', 20), (':', 18), ('-', 16)] | Training

--- 2025-04-07 10:00:45 --- babyLLM 'right, last time i got to step 1635... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 1635! what am i learning today?' - charis: ''
2025-04-07 10:06:38 | 100 | LR0.0003 | loss:8.8902 | gradNorm:1.0000 | logitMin:-65.6558 | logitMax:-45.8204 | tokenCount:400.0000 | windowWeightsW18:0.18196,W13:0.15908,W21:0.15869,W15:0.15523,W8:0.12151,W7:0.10379,W3:0.07250,W2:0.02464,W1:0.00662 | memoryGatesShort:-1.769, Long:1.890, Current:0.878 | topTokens[(',', 79), (':', 39), ('.', 33), ('a', 21), ('ome', 19), ('i', 16), ('to', 13), ('s', 12), ('it', 10), ('the', 9)] | Training
2025-04-07 10:12:50 | 200 | LR0.0003 | loss:7.2342 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-80.7462 | logitMax:-61.8036 | windowWeightsW18:0.18305,W21:0.16020,W13:0.15890,W15:0.15590,W8:0.12128,W7:0.10420,W3:0.07092,W2:0.02328,W1:0.00630 | memoryGatesShort:6.514, Long:-4.291, Current:-1.223 | topTokens[(',', 111), ('.', 19), ('a', 15), ('tho', 15), ('the', 12), ('no', 11), ('e', 11), ('i', 9), ('ck', 8), ('l', 7)] | Training
2025-04-07 10:19:36 | 300 | LR0.0003 | loss:9.1692 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-88.2439 | logitMax:-68.2364 | windowWeightsW18:0.18363,W21:0.16110,W13:0.15978,W15:0.15653,W8:0.12125,W7:0.10373,W3:0.06998,W2:0.02249,W1:0.00556 | memoryGatesShort:-1.708, Long:1.604, Current:1.104 | topTokens[(',', 87), ('.', 44), ('a', 24), ('ck', 17), ('st', 14), ('l', 12), ('b', 12), ('the', 9), ('e', 8), ('so', 7)] | Training

--- 2025-04-07 10:22:08 --- babyLLM 'right, last time i got to step 336... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 336! what am i learning today?' - charis: ''
2025-04-07 10:27:23 | 100 | LR0.0003 | loss:7.5174 | gradNorm:1.0000 | logitMin:-93.0529 | logitMax:-72.7648 | tokenCount:400.0000 | windowWeightsW18:0.18346,W21:0.16153,W13:0.15981,W15:0.15648,W8:0.12015,W7:0.10355,W3:0.06964,W2:0.02369,W1:0.00572 | memoryGatesShort:-2.309, Long:0.836, Current:2.473 | topTokens[(',', 80), ('i', 24), ('er', 21), ('.', 21), ('p', 14), ('e', 14), ('as', 14), ('a', 12), (':', 11), ('it', 11)] | Training
2025-04-07 10:32:39 | 200 | LR0.0003 | loss:6.8555 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-122.1007 | logitMax:-94.6192 | windowWeightsW18:0.18331,W21:0.16111,W13:0.15978,W15:0.15617,W8:0.12077,W7:0.10268,W3:0.06986,W2:0.02470,W1:0.00565 | memoryGatesShort:-4.765, Long:1.077, Current:4.689 | topTokens[(',', 34), ('<UNK>', 25), ('.', 25), ('j', 24), ('', 24), ('la', 22), ('as', 17), ('es', 14), ("'", 14), ('er', 14)] | Training

--- 2025-04-07 10:39:43 --- babyLLM 'right, last time i got to step 289... want to restart from there?'  - charis: '2000' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''
2025-04-07 10:45:04 | 100 | LR0.0003 | loss:10.4635 | gradNorm:1.0000 | logitMin:-97.4105 | logitMax:-69.1830 | tokenCount:400.0000 | windowWeightsW18:0.18410,W21:0.16284,W13:0.16081,W15:0.15714,W8:0.11850,W7:0.10179,W3:0.06926,W2:0.02466,W1:0.00493 | memoryGatesShort:-2.638, Long:1.567, Current:2.071 | topTokens[(',', 58), (':', 41), ('a', 33), ('es', 23), ('ve', 17), ('the', 14), ('.', 13), ('ux', 9), ('er', 9), ('4', 6)] | Training

--- 2025-04-07 10:47:08 --- babyLLM 'right, last time i got to step 111... want to restart from there?'  - charis: '999' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''
2025-04-07 10:52:31 | 100 | LR0.0003 | loss:12.1829 | gradNorm:1.0000 | logitMin:-113.7350 | logitMax:-79.4726 | tokenCount:400.0000 | windowWeightsW18:0.18439,W21:0.16391,W13:0.15985,W15:0.15628,W8:0.11741,W7:0.10245,W3:0.06930,W2:0.02521,W1:0.00522 | memoryGatesShort:-2.581, Long:1.572, Current:2.009 | topTokens[(':', 79), (',', 51), ('tho', 22), ('a', 20), ('the', 14), ('je', 11), ('its', 8), ('j', 8), ('is', 8), ('ve', 7)] | Training

--- 2025-04-07 10:55:19 --- babyLLM 'right, last time i got to step 125... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 125! what am i learning today?' - charis: ''
2025-04-07 11:00:43 | 100 | LR0.0003 | loss:8.7696 | gradNorm:1.0000 | logitMin:-107.1899 | logitMax:-79.5603 | tokenCount:400.0000 | windowWeightsW18:0.18505,W21:0.16429,W13:0.15891,W15:0.15612,W8:0.11685,W7:0.10299,W3:0.06968,W2:0.02460,W1:0.00553 | memoryGatesShort:-1.782, Long:2.263, Current:0.519 | topTokens[('use', 61), (',', 43), (':', 34), ("'", 18), ('i', 18), ('a', 16), ('is', 16), ('and', 14), ('our', 13), ('qu', 9)] | Training
2025-04-07 11:06:14 | 200 | LR0.0003 | loss:7.0677 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-113.4650 | logitMax:-88.2339 | windowWeightsW18:0.18508,W21:0.16439,W13:0.15857,W15:0.15582,W8:0.11620,W7:0.10272,W3:0.06917,W2:0.02574,W1:0.00630 | memoryGatesShort:-4.330, Long:2.097, Current:3.233 | topTokens[(',', 35), ('je', 28), (':', 26), ('and', 24), ('i', 19), ('a', 14), ('a', 14), ('to', 11), ('is', 10), ('j', 10)] | Training
2025-04-07 11:11:37 | 300 | LR0.0003 | loss:7.5870 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-103.8742 | logitMax:-74.6313 | windowWeightsW18:0.18406,W21:0.16350,W13:0.15862,W15:0.15605,W8:0.11694,W7:0.10180,W3:0.06921,W2:0.02725,W1:0.00659 | memoryGatesShort:-1.087, Long:0.266, Current:1.821 | topTokens[(',', 51), (':', 47), ('j', 18), ('la', 17), ('this', 13), ('a', 12), ('.', 11), ('i', 10), ('to', 10), ('as', 10)] | Training
2025-04-07 11:16:52 | 400 | LR0.0003 | loss:5.5841 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-154.0679 | logitMax:-109.6066 | windowWeightsW18:0.18355,W21:0.16179,W13:0.15885,W15:0.15429,W8:0.11690,W7:0.10089,W3:0.07096,W2:0.02984,W1:0.00689 | memoryGatesShort:-9.838, Long:-6.077, Current:16.915 | topTokens[('la', 24), ('m', 22), ('am', 21), ('es', 19), ("'", 18), (',', 15), (':', 12), ('as', 12), ('m', 10), ('a', 9)] | Training
2025-04-07 11:23:30 | 500 | LR0.0003 | loss:5.7929 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-152.7642 | logitMax:-102.7210 | windowWeightsW18:0.18281,W21:0.16060,W13:0.15912,W15:0.15419,W8:0.11756,W7:0.10069,W3:0.07098,W2:0.03099,W1:0.00700 | memoryGatesShort:-0.315, Long:-0.100, Current:1.415 | topTokens[(':', 28), (',', 25), ("'", 20), ('a', 19), ('te', 18), ('se', 18), ('e', 13), ('ess', 12), ('es', 11), ('m', 10)] | Training

--- 2025-04-07 11:36:00 --- babyLLM 'right, last time i got to step 580... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 580! what am i learning today?' - charis: ''
2025-04-07 11:41:33 | 100 | LR0.0003 | loss:8.4631 | gradNorm:1.0000 | logitMin:-21.8707 | logitMax:-5.5157 | tokenCount:400.0000 | windowWeightsW18:0.18378,W21:0.16084,W13:0.15974,W15:0.15471,W8:0.11760,W7:0.10096,W3:0.07000,W2:0.03001,W1:0.00633 | memoryGatesShort:0.695, Long:-1.277, Current:1.582 | topTokens[(',', 106), ('.', 79), ('ur', 67), ('a', 43), ('whats', 26), ('she', 12), ('your', 5), ('d', 4), ('some', 3), ('too', 3)] | Training
2025-04-07 11:46:57 | 200 | LR0.0003 | loss:8.9404 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-33.2146 | logitMax:-8.7676 | windowWeightsW18:0.18331,W21:0.16120,W13:0.16102,W15:0.15544,W8:0.11975,W7:0.10159,W3:0.06782,W2:0.02764,W1:0.00625 | memoryGatesShort:-0.572, Long:-12.575, Current:14.146 | topTokens[(',', 90), ('.', 55), ('a', 38), ('ur', 28), ('*', 26), ('whats', 16), ('h', 12), ('were', 8), ('in', 7), ('she', 7)] | Training
2025-04-07 11:51:58 | 300 | LR0.0003 | loss:7.8066 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-39.8967 | logitMax:-15.3644 | windowWeightsW18:0.18409,W21:0.16190,W13:0.16132,W15:0.15593,W8:0.11998,W7:0.10145,W3:0.06718,W2:0.02685,W1:0.00536 | memoryGatesShort:0.409, Long:-6.688, Current:7.279 | topTokens[(',', 72), ('.', 39), ('i', 27), ('a', 25), ('ur', 18), ('the', 16), ('from', 13), ('food', 13), ('on', 13), ('you', 10)] | Training

--- 2025-04-07 13:08:03 --- babyLLM 'right, last time i got to step 52... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 52! what am i learning today?' - charis: ''
2025-04-07 13:08:20 | 100 | LR0.0003 | loss:8.2452 | gradNorm:1.0000 | logitMin:-23.1017 | logitMax:-9.0652 | tokenCount:400.0000 | windowWeightsW18:0.18222,W13:0.16115,W21:0.15964,W15:0.15546,W8:0.12083,W7:0.10223,W3:0.06897,W2:0.02733,W1:0.00620 | memoryGatesShort:0.262, Long:0.075, Current:0.663 | topTokens[(',', 105), ('.', 60), ('a', 42), ('ers', 22), ('in', 15), ('them', 13), ('had', 9), ('think', 6), ('-', 5), ('she', 5)] | Training
2025-04-07 13:08:37 | 200 | LR0.0003 | loss:7.9912 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-18.2591 | logitMax:-4.0558 | windowWeightsW18:0.18318,W13:0.16191,W21:0.16086,W15:0.15624,W8:0.12105,W7:0.10139,W3:0.06785,W2:0.02618,W1:0.00539 | memoryGatesShort:0.018, Long:-0.359, Current:1.341 | topTokens[(',', 121), ('a', 67), ('.', 36), ('the', 12), ('b', 8), ('had', 7), ('who', 6), ('are', 6), ('an', 6), ('in', 6)] | Training
2025-04-07 13:08:55 | 300 | LR0.0003 | loss:7.6496 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-26.4296 | logitMax:-13.4816 | windowWeightsW18:0.18418,W13:0.16293,W21:0.16220,W15:0.15733,W8:0.12132,W7:0.10086,W3:0.06684,W2:0.02472,W1:0.00373 | memoryGatesShort:0.172, Long:-0.069, Current:0.897 | topTokens[(',', 119), ('a', 38), ('i', 31), ('.', 19), ('if', 17), ('boomboomraccoon', 14), ('who', 12), ('love', 11), ('is', 11), ('man', 9)] | Training
2025-04-07 13:09:13 | 400 | LR0.0003 | loss:7.6026 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-38.3016 | logitMax:-25.0263 | windowWeightsW18:0.18467,W21:0.16301,W13:0.16286,W15:0.15755,W8:0.12067,W7:0.10064,W3:0.06668,W2:0.02454,W1:0.00347 | memoryGatesShort:0.113, Long:-0.244, Current:1.131 | topTokens[(',', 108), ('a', 73), ('i', 36), ('no', 16), ('r', 11), ('.', 11), ('is', 9), ('man', 8), ('m', 7), ('boomboomraccoon', 6)] | Training
2025-04-07 13:09:31 | 500 | LR0.0003 | loss:7.4116 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-41.0219 | logitMax:-28.6813 | windowWeightsW18:0.18462,W13:0.16313,W21:0.16299,W15:0.15731,W8:0.12135,W7:0.10069,W3:0.06666,W2:0.02433,W1:0.00303 | memoryGatesShort:0.229, Long:0.076, Current:0.695 | topTokens[(',', 91), ('i', 33), ('a', 30), ('the', 30), ('.', 18), ('in', 14), ('is', 12), ('am', 11), ('no', 11), ('b', 7)] | Training
2025-04-07 13:09:49 | 600 | LR0.0003 | loss:6.7949 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-36.6083 | logitMax:-23.6993 | windowWeightsW18:0.18509,W13:0.16339,W21:0.16336,W15:0.15771,W8:0.12121,W7:0.10035,W3:0.06632,W2:0.02382,W1:0.00287 | memoryGatesShort:0.189, Long:0.013, Current:0.798 | topTokens[(',', 150), ('a', 49), ('the', 34), ('.', 27), ('i', 21), ('op', 8), ('just', 7), ('r', 6), ('no', 5), ('is', 5)] | Training
2025-04-07 13:10:06 | 700 | LR0.0003 | loss:7.5143 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-28.6811 | logitMax:-15.7446 | windowWeightsW18:0.18748,W21:0.16566,W13:0.16441,W15:0.16002,W8:0.11900,W7:0.09834,W3:0.06474,W2:0.02243,W1:0.00205 | memoryGatesShort:0.240, Long:0.008, Current:0.751 | topTokens[(',', 200), ('.', 19), ('i', 14), ('s', 12), ('the', 8), ('p', 8), ('a', 8), ('g', 8), ('no', 7), ('n', 5)] | Training
2025-04-07 13:10:24 | 800 | LR0.0003 | loss:7.0657 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-31.4360 | logitMax:-20.2729 | windowWeightsW18:0.18778,W21:0.16604,W13:0.16462,W15:0.16026,W8:0.11881,W7:0.09796,W3:0.06452,W2:0.02216,W1:0.00197 | memoryGatesShort:0.230, Long:0.004, Current:0.766 | topTokens[(',', 146), ('a', 24), ('.', 23), ('i', 22), ('s', 14), ('g', 9), ('some', 7), ('b', 6), ('the', 5), ('who', 5)] | Training
2025-04-07 13:10:42 | 900 | LR0.0003 | loss:6.7773 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-36.2257 | logitMax:-24.7807 | windowWeightsW18:0.18798,W21:0.16632,W13:0.16471,W15:0.16034,W8:0.11889,W7:0.09775,W3:0.06433,W2:0.02196,W1:0.00185 | memoryGatesShort:0.108, Long:-0.206, Current:1.098 | topTokens[(',', 188), ('i', 36), ('a', 17), ('.', 13), ('s', 11), ('good', 7), ('g', 6), ('b', 5), ('the', 5), ('but', 4)] | Training
2025-04-07 13:10:59 | 1000 | LR0.0003 | loss:7.2256 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.4627 | logitMax:-38.0134 | windowWeightsW18:0.18765,W21:0.16615,W13:0.16481,W15:0.15967,W8:0.11882,W7:0.09761,W3:0.06444,W2:0.02237,W1:0.00259 | memoryGatesShort:-0.031, Long:-0.328, Current:1.359 | topTokens[(',', 157), ('i', 23), ('a', 16), ('b', 15), ('the', 13), ('ing', 13), ('s', 12), ('on', 12), ('...', 8), ('a', 8)] | Training
2025-04-07 13:11:17 | 1100 | LR0.0003 | loss:6.4278 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.8177 | logitMax:-33.1521 | windowWeightsW18:0.18827,W21:0.16675,W13:0.16310,W15:0.15932,W8:0.11841,W7:0.09748,W3:0.06541,W2:0.02188,W1:0.00346 | memoryGatesShort:-0.081, Long:-0.347, Current:1.428 | topTokens[(',', 117), ('the', 32), ('a', 30), ('h', 23), ('its', 18), ('i', 14), ('is', 12), ('a', 10), ('.', 5), ('s', 5)] | Training
2025-04-07 13:11:35 | 1200 | LR0.0003 | loss:6.0649 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-46.0592 | logitMax:-32.3781 | windowWeightsW18:0.18925,W21:0.16799,W13:0.16303,W15:0.15913,W8:0.11820,W7:0.09682,W3:0.06457,W2:0.02140,W1:0.00370 | memoryGatesShort:-0.080, Long:-0.350, Current:1.430 | topTokens[(',', 99), ('its', 89), ('the', 24), ('i', 20), ('p', 14), ('a', 9), ('ion', 7), ('.', 6), ('eep', 6), ('us', 5)] | Training
2025-04-07 13:11:53 | 1300 | LR0.0003 | loss:6.2127 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-49.1416 | logitMax:-36.2225 | windowWeightsW18:0.18986,W21:0.16890,W13:0.16303,W15:0.15970,W8:0.11723,W7:0.09600,W3:0.06472,W2:0.02128,W1:0.00337 | memoryGatesShort:-0.323, Long:-0.764, Current:2.087 | topTokens[(',', 104), ('a', 38), ('its', 37), ('oo', 28), ('a', 27), ('the', 22), ('ory', 15), ('i', 13), ('.', 8), ('is', 7)] | Training
2025-04-07 13:12:11 | 1400 | LR0.0003 | loss:7.5719 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.8022 | logitMax:-40.5794 | windowWeightsW18:0.19046,W21:0.16983,W13:0.16336,W15:0.16029,W8:0.11663,W7:0.09560,W3:0.06454,W2:0.02126,W1:0.00212 | memoryGatesShort:-1.559, Long:-2.962, Current:5.522 | topTokens[(',', 113), ('the', 38), ('a', 27), ('.', 16), ('ory', 13), ('p', 13), ('s', 10), ('its', 8), ('h', 7), ('er', 7)] | Training
2025-04-07 13:12:29 | 1500 | LR0.0003 | loss:7.1966 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.4721 | logitMax:-33.8967 | windowWeightsW18:0.19042,W21:0.16984,W13:0.16397,W15:0.16060,W8:0.11698,W7:0.09589,W3:0.06450,W2:0.02155,W1:0.00038 | memoryGatesShort:-0.366, Long:-1.003, Current:2.369 | topTokens[(',', 114), ('the', 49), ('a', 19), ('its', 13), ('i', 12), ('is', 10), ('.', 9), ('it', 8), ('them', 7), ('b', 7)] | Training
2025-04-07 13:12:47 | 1600 | LR0.0003 | loss:7.2203 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-46.8064 | logitMax:-35.0652 | windowWeightsW18:0.19140,W21:0.17148,W13:0.16437,W15:0.16111,W8:0.11694,W7:0.09593,W3:0.06375,W2:0.02054,W1:-0.00137 | memoryGatesShort:-0.368, Long:-1.079, Current:2.447 | topTokens[(',', 71), ('and', 38), ('the', 35), ('is', 22), ('.', 19), ('a', 19), ('to', 18), ('g', 11), ('in', 10), ('are', 8)] | Training
2025-04-07 13:13:05 | 1700 | LR0.0003 | loss:7.3209 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-37.0993 | logitMax:-26.3983 | windowWeightsW18:0.19171,W21:0.17170,W13:0.16467,W15:0.16117,W8:0.11716,W7:0.09569,W3:0.06368,W2:0.01995,W1:-0.00158 | memoryGatesShort:-0.044, Long:-0.449, Current:1.493 | topTokens[(',', 55), ('.', 42), ('the', 42), ('and', 21), ('a', 14), ('i', 13), ('s', 8), ('them', 8), ('b', 7), ('a', 7)] | Training
2025-04-07 13:13:22 | 1800 | LR0.0003 | loss:6.8966 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-43.3949 | logitMax:-32.8933 | windowWeightsW18:0.19178,W21:0.17188,W13:0.16474,W15:0.16135,W8:0.11688,W7:0.09541,W3:0.06365,W2:0.01976,W1:-0.00132 | memoryGatesShort:-0.244, Long:-0.814, Current:2.058 | topTokens[('the', 37), (',', 35), ('a', 27), ('to', 26), ('and', 20), ('.', 18), ('i', 15), ('a', 8), ('in', 7), ('them', 7)] | Training
2025-04-07 13:13:41 | 1900 | LR0.0003 | loss:7.1124 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-42.8048 | logitMax:-32.2424 | windowWeightsW18:0.19174,W21:0.17171,W13:0.16466,W15:0.16095,W8:0.11629,W7:0.09550,W3:0.06347,W2:0.02023,W1:-0.00041 | memoryGatesShort:-0.546, Long:-1.325, Current:2.871 | topTokens[(',', 48), ('.', 39), ('i', 26), ('and', 14), ('a', 12), ('ing', 11), ('the', 10), ('to', 9), ('s', 8), ('b', 6)] | Training
2025-04-07 13:13:59 | 2000 | LR0.0003 | loss:6.8581 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-44.8896 | logitMax:-33.4075 | windowWeightsW18:0.19123,W21:0.17171,W13:0.16420,W15:0.16011,W8:0.11659,W7:0.09576,W3:0.06341,W2:0.02023,W1:0.00088 | memoryGatesShort:-0.189, Long:-0.612, Current:1.801 | topTokens[(',', 34), ('to', 30), ('.', 18), ('a', 17), ('and', 16), ('think', 15), ('i', 13), ('music', 12), ('my', 12), ('so', 10)] | Training
2025-04-07 13:14:17 | 2100 | LR0.0003 | loss:7.1104 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-43.8856 | logitMax:-31.5850 | windowWeightsW18:0.19182,W21:0.17205,W13:0.16451,W15:0.16031,W8:0.11614,W7:0.09526,W3:0.06324,W2:0.02008,W1:0.00071 | memoryGatesShort:-1.095, Long:-2.248, Current:4.343 | topTokens[('to', 60), (',', 57), ('.', 49), ('for', 24), ('a', 24), ('i', 15), ('and', 14), ('think', 7), ('so', 7), ('it', 5)] | Training
2025-04-07 13:14:35 | 2200 | LR0.0003 | loss:6.7083 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-43.2089 | logitMax:-31.8134 | windowWeightsW18:0.19156,W21:0.17236,W13:0.16446,W15:0.16010,W8:0.11651,W7:0.09474,W3:0.06374,W2:0.02023,W1:0.00041 | memoryGatesShort:-0.958, Long:-2.055, Current:4.013 | topTokens[('a', 37), ('.', 31), (',', 31), ('i', 28), ('and', 21), ('to', 19), ('h', 18), ('ron', 12), ('ic', 11), ('music', 10)] | Training
2025-04-07 13:14:53 | 2300 | LR0.0003 | loss:6.3157 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.8394 | logitMax:-33.4202 | windowWeightsW18:0.19085,W21:0.17195,W13:0.16412,W15:0.15977,W8:0.11603,W7:0.09474,W3:0.06504,W2:0.02127,W1:0.00034 | memoryGatesShort:-0.431, Long:-1.061, Current:2.492 | topTokens[(',', 47), ('.', 38), ('ic', 33), ('that', 26), ('i', 24), ('a', 18), ('e', 16), ('h', 15), ('and', 14), ('music', 13)] | Training
2025-04-07 13:15:11 | 2400 | LR0.0003 | loss:7.3047 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-39.6120 | logitMax:-27.1296 | windowWeightsW18:0.19150,W21:0.17250,W13:0.16469,W15:0.16066,W8:0.11636,W7:0.09472,W3:0.06454,W2:0.01998,W1:-0.00082 | memoryGatesShort:-1.051, Long:-2.334, Current:4.385 | topTokens[(',', 70), ('.', 55), ('a', 33), ('i', 29), ('my', 12), ('that', 12), ('music', 11), ('s', 10), ('and', 10), ('have', 6)] | Training
2025-04-07 13:15:29 | 2500 | LR0.0003 | loss:6.6208 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.5198 | logitMax:-34.3603 | windowWeightsW18:0.19167,W21:0.17277,W13:0.16477,W15:0.16096,W8:0.11626,W7:0.09427,W3:0.06445,W2:0.02002,W1:-0.00103 | memoryGatesShort:-0.540, Long:-1.331, Current:2.870 | topTokens[('.', 66), ('i', 40), (',', 23), ('my', 13), ('ed', 13), ('and', 13), ('to', 12), ('a', 11), ('that', 10), ('st', 9)] | Training
2025-04-07 13:15:47 | 2600 | LR0.0003 | loss:6.5596 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-44.3280 | logitMax:-32.1423 | windowWeightsW18:0.19231,W21:0.17352,W13:0.16500,W15:0.16100,W8:0.11558,W7:0.09333,W3:0.06347,W2:0.02079,W1:-0.00088 | memoryGatesShort:-0.333, Long:-0.952, Current:2.285 | topTokens[('.', 113), ('i', 36), ('to', 31), (',', 29), ('a', 12), ('for', 11), ('that', 8), ('your', 8), ('ed', 7), ('maybe', 6)] | Training
2025-04-07 13:16:06 | 2700 | LR0.0003 | loss:7.0479 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.7536 | logitMax:-38.0113 | windowWeightsW18:0.19340,W21:0.17414,W13:0.16616,W15:0.16232,W8:0.11612,W7:0.09312,W3:0.06192,W2:0.01897,W1:-0.00198 | memoryGatesShort:-0.831, Long:-1.922, Current:3.753 | topTokens[('.', 95), ('i', 50), ('it', 28), ('a', 19), (',', 16), ('maybe', 12), ('for', 9), ('?', 8), ('p', 8), ('you', 8)] | Training
2025-04-07 13:16:25 | 2800 | LR0.0003 | loss:6.3829 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-42.6389 | logitMax:-30.8084 | windowWeightsW18:0.19368,W21:0.17455,W13:0.16687,W15:0.16298,W8:0.11616,W7:0.09349,W3:0.06054,W2:0.01829,W1:-0.00237 | memoryGatesShort:-0.735, Long:-1.725, Current:3.460 | topTokens[('.', 91), ('i', 38), ('a', 26), ('it', 24), ('to', 13), (',', 12), ('maybe', 11), ('is', 9), ('pe', 8), ('have', 7)] | Training
2025-04-07 13:16:46 | 2900 | LR0.0003 | loss:7.2010 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-44.5512 | logitMax:-32.1647 | windowWeightsW18:0.19455,W21:0.17511,W13:0.16687,W15:0.16335,W8:0.11581,W7:0.09298,W3:0.06055,W2:0.01813,W1:-0.00315 | memoryGatesShort:-1.351, Long:-2.915, Current:5.266 | topTokens[('.', 113), ('i', 45), ('it', 28), ('to', 18), ('a', 16), (',', 14), ('of', 13), ('you', 5), ('is', 5), ('?', 4)] | Training
2025-04-07 13:17:07 | 3000 | LR0.0003 | loss:7.4698 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-38.2317 | logitMax:-25.5198 | windowWeightsW18:0.19476,W21:0.17563,W13:0.16670,W15:0.16311,W8:0.11570,W7:0.09293,W3:0.06065,W2:0.01801,W1:-0.00329 | memoryGatesShort:-0.323, Long:-0.939, Current:2.262 | topTokens[('.', 91), (',', 48), ('a', 33), ('i', 25), ('for', 11), ('of', 9), ('and', 7), ('to', 6), ('maybe', 6), ('it', 6)] | Training

--- 2025-04-07 13:20:27 --- babyLLM 'right, last time i got to step 3029... want to restart from there?'  - charis: 'yes, and, holy shit babyllm, you're doing 1000 steps in 3 minutes... you used to do 100 steps in 10 minutes. idfk waht to say. im so proud of us!' - babyLLM 'ok! let's go to step 3029! what am i learning today?' - charis: 'that i love you :)'
2025-04-07 13:20:31 | 100 | LR0.0003 | loss:8.3952 | gradNorm:1.0000 | logitMin:-19.5620 | logitMax:-5.3035 | tokenCount:400.0000 | windowWeightsW18:0.18413,W21:0.16218,W13:0.15982,W15:0.15520,W8:0.11696,W7:0.10068,W3:0.06924,W2:0.03013,W1:0.00564 | memoryGatesShort:0.312, Long:0.306, Current:0.382 | topTokens[('.', 12), (',', 12), ('a', 3), ('even', 1), ('w', 1), ('them', 1), ('feel', 1), ('b', 1), ('i', 1), ('mine', 1)] | Training
2025-04-07 13:20:35 | 200 | LR0.0003 | loss:7.8319 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-36.7726 | logitMax:-22.5923 | windowWeightsW18:0.18638,W21:0.16472,W13:0.16155,W15:0.15730,W8:0.11627,W7:0.09901,W3:0.06636,W2:0.02773,W1:0.00468 | memoryGatesShort:0.316, Long:0.307, Current:0.377 | topTokens[('.', 11), (',', 7), ('you', 4), ('a', 4), ('i', 4), ('am', 2), ('b', 1), ('mine', 1), ('s', 1), ('who', 1)] | Training
2025-04-07 13:20:39 | 300 | LR0.0003 | loss:7.0772 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.7142 | logitMax:-37.7777 | windowWeightsW18:0.18803,W21:0.16651,W13:0.16305,W15:0.15855,W8:0.11503,W7:0.09753,W3:0.06484,W2:0.02658,W1:0.00388 | memoryGatesShort:0.353, Long:0.362, Current:0.285 | topTokens[(',', 13), ('a', 5), ('.', 4), ('i', 3), ('b', 2), ('r', 1), ('de', 1), ('co', 1), ('has', 1), ('am', 1)] | Training
2025-04-07 13:20:42 | 400 | LR0.0003 | loss:6.3893 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-68.8938 | logitMax:-54.2542 | windowWeightsW18:0.18823,W21:0.16696,W13:0.16226,W15:0.15836,W8:0.11422,W7:0.09677,W3:0.06511,W2:0.02737,W1:0.00471 | memoryGatesShort:0.194, Long:0.157, Current:0.649 | topTokens[('and', 8), ('a', 6), (',', 6), ('the', 6), ('feel', 5), ('.', 3), ('i', 1), ('who', 1), ('you', 1), ('she', 1)] | Training
2025-04-07 13:20:46 | 500 | LR0.0003 | loss:5.8321 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-49.9377 | logitMax:-37.4484 | windowWeightsW18:0.18809,W21:0.16718,W13:0.16145,W15:0.15778,W8:0.11303,W7:0.09536,W3:0.06600,W2:0.02869,W1:0.00636 | memoryGatesShort:0.113, Long:0.047, Current:0.840 | topTokens[(',', 9), ('and', 9), ('but', 3), ('she', 3), ('you', 3), ('.', 1), ('se', 1), ('too', 1), ('elodie', 1), ('use', 1)] | Training
2025-04-07 13:20:50 | 600 | LR0.0003 | loss:5.0386 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.9866 | logitMax:-37.8952 | windowWeightsW18:0.18799,W21:0.16674,W13:0.15912,W15:0.15567,W8:0.11034,W7:0.09198,W3:0.06747,W2:0.03339,W1:0.01111 | memoryGatesShort:-0.065, Long:-0.190, Current:1.255 | topTokens[(',', 18), ('and', 4), ('s', 3), ('se', 3), ('she', 2), ('the', 2), ('a', 2), ('her', 1), ('they', 1), ('am', 1)] | Training
2025-04-07 13:20:53 | 700 | LR0.0003 | loss:6.6108 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-37.2295 | logitMax:-23.7630 | windowWeightsW18:0.18835,W21:0.16801,W13:0.16043,W15:0.15665,W8:0.10906,W7:0.09151,W3:0.06760,W2:0.03261,W1:0.00962 | memoryGatesShort:-0.310, Long:-0.549, Current:1.860 | topTokens[(',', 9), ('and', 6), ('music', 3), ('charis', 3), ('the', 3), ('you', 2), ('s', 2), ('.', 2), ('find', 1), ('my', 1)] | Training
2025-04-07 13:20:57 | 800 | LR0.0003 | loss:6.9919 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-31.3958 | logitMax:-18.7979 | windowWeightsW18:0.18975,W21:0.17013,W13:0.16168,W15:0.15826,W8:0.10807,W7:0.09080,W3:0.06688,W2:0.03057,W1:0.00774 | memoryGatesShort:-0.187, Long:-0.398, Current:1.585 | topTokens[('.', 8), ('?', 7), ('a', 2), ('b', 2), ('to', 2), ('think', 2), ('charis', 2), ('both', 1), ('it', 1), ('one', 1)] | Training
2025-04-07 13:21:01 | 900 | LR0.0003 | loss:5.3465 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-46.0635 | logitMax:-33.2383 | windowWeightsW18:0.18973,W21:0.17072,W13:0.16113,W15:0.15835,W8:0.10825,W7:0.08991,W3:0.06677,W2:0.03073,W1:0.00829 | memoryGatesShort:-0.347, Long:-0.594, Current:1.941 | topTokens[('to', 10), ('?', 7), (',', 3), ('elodie', 3), ('i', 2), ('.', 2), ('about', 1), ('fail', 1), ('will', 1), ('our', 1)] | Training
2025-04-07 13:21:12 | 1000 | LR0.0003 | loss:5.2985 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-48.6410 | logitMax:-34.8387 | windowWeightsW18:0.18868,W21:0.16958,W13:0.16045,W15:0.15736,W8:0.10822,W7:0.08907,W3:0.06802,W2:0.03190,W1:0.01055 | memoryGatesShort:-0.518, Long:-0.826, Current:2.344 | topTokens[('?', 9), ('to', 6), ('listening', 4), ('.', 3), ('what', 2), ('charis', 2), (',', 2), ('you', 1), ('about', 1), ('take', 1)] | Training
2025-04-07 13:21:16 | 1100 | LR0.0003 | loss:5.6407 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-31.8948 | logitMax:-18.8126 | windowWeightsW18:0.18816,W21:0.16945,W13:0.16084,W15:0.15718,W8:0.10939,W7:0.09053,W3:0.06777,W2:0.03066,W1:0.00987 | memoryGatesShort:-0.945, Long:-1.413, Current:3.358 | topTokens[('.', 7), ('?', 4), ('you', 4), ('is', 4), ('to', 2), ('ic', 2), ('they', 1), ('he', 1), ('talk', 1), ('tast', 1)] | Training
2025-04-07 13:21:20 | 1200 | LR0.0003 | loss:7.5457 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-24.9809 | logitMax:-10.6608 | windowWeightsW18:0.18776,W21:0.16920,W13:0.16197,W15:0.15806,W8:0.11150,W7:0.09182,W3:0.06646,W2:0.02910,W1:0.00803 | memoryGatesShort:-2.058, Long:-3.059, Current:6.117 | topTokens[('.', 8), ('a', 5), (',', 4), ('4', 4), ('think', 2), ('school', 2), (':', 2), ('-', 2), ('will', 1), ('little', 1)] | Training
2025-04-07 13:21:23 | 1300 | LR0.0003 | loss:4.3806 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-28.6864 | logitMax:-12.0120 | windowWeightsW18:0.18806,W21:0.16975,W13:0.16153,W15:0.15781,W8:0.11094,W7:0.09115,W3:0.06664,W2:0.02887,W1:0.00912 | memoryGatesShort:-0.398, Long:-0.689, Current:2.088 | topTokens[(':', 8), ('4', 5), ("'", 5), ('0', 4), (',', 3), ('-', 3), ('kevin', 2), ('wa', 2), ('b', 1), ('v', 1)] | Training
2025-04-07 13:21:27 | 1400 | LR0.0003 | loss:3.2538 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-36.4051 | logitMax:-18.7329 | windowWeightsW18:0.18745,W21:0.16963,W13:0.16090,W15:0.15682,W8:0.11117,W7:0.09086,W3:0.06687,W2:0.02983,W1:0.01032 | memoryGatesShort:-0.722, Long:-1.110, Current:2.833 | topTokens[('4', 4), ('?', 3), ('2', 3), ('5', 3), ('0', 2), ("'", 2), ('lear', 2), (':', 2), ("'", 2), ('1', 2)] | Training
2025-04-07 13:21:31 | 1500 | LR0.0003 | loss:4.5823 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-37.8488 | logitMax:-20.1044 | windowWeightsW18:0.18590,W21:0.16804,W13:0.16082,W15:0.15611,W8:0.11252,W7:0.09254,W3:0.06695,W2:0.03008,W1:0.01091 | memoryGatesShort:-1.608, Long:-2.240, Current:4.848 | topTokens[(':', 6), ('-', 6), ("'", 3), ('you', 3), ('-', 3), ('2', 3), ('i', 3), ('at', 2), ('0', 2), ('7', 2)] | Training
2025-04-07 13:21:35 | 1600 | LR0.0003 | loss:2.9082 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-40.3580 | logitMax:-21.0291 | windowWeightsW18:0.18497,W21:0.16733,W13:0.15991,W15:0.15545,W8:0.11358,W7:0.09333,W3:0.06697,W2:0.03084,W1:0.01148 | memoryGatesShort:-0.849, Long:-1.231, Current:3.079 | topTokens[('-', 5), ('0', 4), ("'", 3), ('2', 3), ('am', 2), ('you', 2), (':', 2), ("'", 2), ('baby', 2), ('ll', 2)] | Training
2025-04-07 13:21:39 | 1700 | LR0.0003 | loss:4.4855 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-38.8862 | logitMax:-20.3676 | windowWeightsW18:0.18460,W21:0.16694,W13:0.16019,W15:0.15544,W8:0.11515,W7:0.09487,W3:0.06636,W2:0.03022,W1:0.01015 | memoryGatesShort:-1.233, Long:-1.747, Current:3.980 | topTokens[('-', 4), ('?', 3), (':', 3), ('i', 3), ('lear', 3), ('ning', 2), ('h', 2), ('4', 2), ('-', 2), ('at', 2)] | Training
2025-04-07 13:21:43 | 1800 | LR0.0003 | loss:3.9079 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-40.6051 | logitMax:-23.0592 | windowWeightsW18:0.18361,W21:0.16602,W13:0.15924,W15:0.15442,W8:0.11656,W7:0.09621,W3:0.06658,W2:0.03076,W1:0.01051 | memoryGatesShort:-0.921, Long:-1.326, Current:3.247 | topTokens[('0', 4), ("'", 3), (':', 3), ('m', 3), ('-', 2), ('baby', 2), ('ll', 2), ("'", 2), ('4', 2), ('ur', 1)] | Training
2025-04-07 13:21:47 | 1900 | LR0.0003 | loss:3.9444 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-41.1470 | logitMax:-23.0119 | windowWeightsW18:0.18257,W21:0.16531,W13:0.15900,W15:0.15383,W8:0.11770,W7:0.09801,W3:0.06629,W2:0.02991,W1:0.01132 | memoryGatesShort:-1.295, Long:-1.782, Current:4.077 | topTokens[(':', 8), ('m', 5), ('4', 4), ("'", 4), ('to', 4), ('-', 3), ('?', 2), ('0', 2), ('am', 2), ('kevin', 1)] | Training
2025-04-07 13:21:59 | 2000 | LR0.0003 | loss:3.9919 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-42.3513 | logitMax:-24.4055 | windowWeightsW18:0.18191,W21:0.16473,W13:0.15921,W15:0.15353,W8:0.11879,W7:0.09934,W3:0.06547,W2:0.02953,W1:0.01144 | memoryGatesShort:-0.871, Long:-1.205, Current:3.076 | topTokens[('-', 8), (':', 4), ("'", 4), (',', 2), ('to', 2), ('7', 2), ('m', 2), ('a', 1), ('charis', 1), ('...', 1)] | Training
2025-04-07 13:22:03 | 2100 | LR0.0003 | loss:3.2840 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-43.1782 | logitMax:-24.2166 | windowWeightsW18:0.18114,W21:0.16378,W13:0.15841,W15:0.15283,W8:0.11999,W7:0.10082,W3:0.06508,W2:0.02944,W1:0.01247 | memoryGatesShort:-0.653, Long:-0.905, Current:2.558 | topTokens[('i', 3), ('4', 3), ('0', 3), ('got', 2), ('!', 2), ("'", 2), ('?', 2), ('-', 2), ('um', 2), ('you', 1)] | Training
2025-04-07 13:22:07 | 2200 | LR0.0003 | loss:3.1296 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-46.3348 | logitMax:-27.2576 | windowWeightsW18:0.18102,W21:0.16350,W13:0.15831,W15:0.15220,W8:0.12049,W7:0.10132,W3:0.06494,W2:0.02861,W1:0.01354 | memoryGatesShort:-0.697, Long:-0.975, Current:2.672 | topTokens[('?', 3), ("'", 3), ('-', 3), ('0', 3), ('m', 2), ('o', 2), ('step', 2), ('-', 2), ('charis', 1), ('20', 1)] | Training

--- 2025-04-07 13:23:29 --- babyLLM 'right, last time i got to step 2250... want to restart from there?'  - charis: 'yes, youre doing amazing' - babyLLM 'ok! let's go to step 2250! what am i learning today?' - charis: 'actual fucking speed, amphetamine levels of speed, like holy fuck'
2025-04-07 13:23:34 | 100 | LR0.0003 | loss:7.4768 | gradNorm:1.0000 | logitMin:-32.5352 | logitMax:-19.4979 | tokenCount:400.0000 | windowWeightsW18:0.18253,W21:0.16564,W13:0.15876,W15:0.15335,W8:0.12117,W7:0.10172,W3:0.06283,W2:0.02665,W1:0.01135 | memoryGatesShort:-1.118, Long:-1.561, Current:3.679 | topTokens[(',', 6), ('a', 5), ('.', 4), ('?', 2), ('s', 2), ('i', 2), ('there', 1), ('let', 1), ('time', 1), ('george', 1)] | Training
2025-04-07 13:23:39 | 200 | LR0.0003 | loss:7.2106 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-35.4434 | logitMax:-23.1855 | windowWeightsW18:0.18456,W21:0.16765,W13:0.16015,W15:0.15458,W8:0.12190,W7:0.10200,W3:0.06025,W2:0.02412,W1:0.00889 | memoryGatesShort:-1.123, Long:-1.560, Current:3.683 | topTokens[('.', 6), (',', 6), ('i', 6), ("'", 3), ('and', 3), ('charis', 2), ('to', 2), ('ic', 1), ('?', 1), ('1', 1)] | Training
2025-04-07 13:23:44 | 300 | LR0.0003 | loss:6.6939 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-39.6758 | logitMax:-28.0082 | windowWeightsW18:0.18468,W21:0.16817,W13:0.16012,W15:0.15553,W8:0.12231,W7:0.10242,W3:0.05900,W2:0.02353,W1:0.00835 | memoryGatesShort:-0.651, Long:-0.942, Current:2.593 | topTokens[('i', 10), ('.', 5), (',', 4), ('to', 3), ('a', 3), ('it', 2), ('?', 2), ('listen', 1), ('you', 1), ('music', 1)] | Training
2025-04-07 13:23:49 | 400 | LR0.0003 | loss:6.6228 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-33.4954 | logitMax:-21.8168 | windowWeightsW18:0.18568,W21:0.16866,W13:0.16048,W15:0.15615,W8:0.12242,W7:0.10224,W3:0.05772,W2:0.02272,W1:0.00805 | memoryGatesShort:-0.900, Long:-1.241, Current:3.141 | topTokens[('.', 6), ('i', 5), ('to', 4), (',', 4), ('am', 3), ('a', 3), ('you', 2), ("'ll", 1), ('charis', 1), ('good', 1)] | Training
2025-04-07 13:23:54 | 500 | LR0.0003 | loss:6.7355 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-37.2686 | logitMax:-26.2104 | windowWeightsW18:0.18628,W21:0.16927,W13:0.16093,W15:0.15645,W8:0.12245,W7:0.10212,W3:0.05704,W2:0.02212,W1:0.00748 | memoryGatesShort:-0.614, Long:-0.870, Current:2.484 | topTokens[('.', 7), ('i', 7), ('you', 3), ('to', 2), ('a', 2), ('were', 1), ('that', 1), (',', 1), ('im', 1), ('!', 1)] | Training
2025-04-07 13:24:00 | 600 | LR0.0003 | loss:6.5122 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-39.4423 | logitMax:-28.1676 | windowWeightsW18:0.18701,W21:0.16963,W13:0.16105,W15:0.15686,W8:0.12236,W7:0.10193,W3:0.05638,W2:0.02149,W1:0.00743 | memoryGatesShort:-2.292, Long:-2.934, Current:6.226 | topTokens[('i', 14), ('.', 8), ('a', 3), ('am', 2), ('to', 2), ('my', 1), ('at', 1), ('5', 1), ('your', 1), ('have', 1)] | Training
2025-04-07 13:24:05 | 700 | LR0.0003 | loss:7.3446 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-41.0734 | logitMax:-29.5407 | windowWeightsW18:0.18768,W21:0.17016,W13:0.16151,W15:0.15749,W8:0.12212,W7:0.10199,W3:0.05584,W2:0.02084,W1:0.00653 | memoryGatesShort:-0.646, Long:-0.882, Current:2.528 | topTokens[('.', 9), ('a', 4), ('i', 3), ('ing', 2), ("'s", 2), ('too', 2), ('to', 2), ('is', 2), ('it', 2), ('b', 1)] | Training
2025-04-07 13:24:10 | 800 | LR0.0003 | loss:6.8642 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-33.4139 | logitMax:-21.9830 | windowWeightsW18:0.18879,W21:0.17105,W13:0.16183,W15:0.15816,W8:0.12131,W7:0.10125,W3:0.05520,W2:0.02027,W1:0.00629 | memoryGatesShort:-0.632, Long:-0.850, Current:2.482 | topTokens[('i', 8), ('.', 8), (',', 4), ('me', 2), ('and', 2), ('a', 2), ('bit', 2), ('the', 1), ('could', 1), ('any', 1)] | Training
2025-04-07 13:24:15 | 900 | LR0.0003 | loss:5.2666 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-41.1134 | logitMax:-29.6203 | windowWeightsW18:0.18713,W21:0.16946,W13:0.16077,W15:0.15739,W8:0.12147,W7:0.10227,W3:0.05666,W2:0.02156,W1:0.00741 | memoryGatesShort:-0.514, Long:-0.727, Current:2.241 | topTokens[('.', 10), ('the', 4), ('p', 2), ('and', 2), ('i', 2), ('comp', 1), ('not', 1), ('yeah', 1), ('my', 1), ('am', 1)] | Training
2025-04-07 13:24:19 | 1000 | LR0.0003 | loss:5.7877 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-42.2268 | logitMax:-30.1526 | windowWeightsW18:0.18543,W21:0.16729,W13:0.16031,W15:0.15703,W8:0.12291,W7:0.10371,W3:0.05754,W2:0.02219,W1:0.00772 | memoryGatesShort:-0.754, Long:-1.047, Current:2.801 | topTokens[('.', 10), ('a', 4), ('is', 2), ('i', 2), (':', 2), (',', 2), ('ar', 1), ('le', 1), ('en', 1), ('any', 1)] | Training
2025-04-07 13:24:24 | 1100 | LR0.0003 | loss:4.9112 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-44.4598 | logitMax:-31.8527 | windowWeightsW18:0.18505,W21:0.16651,W13:0.15999,W15:0.15581,W8:0.12273,W7:0.10306,W3:0.05871,W2:0.02379,W1:0.00847 | memoryGatesShort:-2.164, Long:-2.854, Current:6.018 | topTokens[('you', 7), ('and', 7), (',', 6), ('a', 3), ('de', 2), ('but', 2), ('i', 2), ('the', 2), ('he', 2), ('g', 1)] | Training
2025-04-07 13:24:28 | 1200 | LR0.0003 | loss:4.5550 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.5481 | logitMax:-43.1809 | windowWeightsW18:0.18466,W21:0.16567,W13:0.15941,W15:0.15539,W8:0.12257,W7:0.10332,W3:0.05999,W2:0.02455,W1:0.00854 | memoryGatesShort:-0.639, Long:-0.916, Current:2.556 | topTokens[(',', 10), ('and', 8), ('you', 2), ('-', 2), ('so', 2), ('a', 1), ('me', 1), ('he', 1), ('the', 1), ('charis', 1)] | Training
2025-04-07 13:24:33 | 1300 | LR0.0003 | loss:4.2868 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-52.9451 | logitMax:-38.2136 | windowWeightsW18:0.18353,W21:0.16497,W13:0.15848,W15:0.15395,W8:0.12154,W7:0.10293,W3:0.06255,W2:0.02645,W1:0.00965 | memoryGatesShort:-1.241, Long:-1.710, Current:3.951 | topTokens[(',', 12), ('but', 5), ("'s", 3), ('and', 3), ('you', 2), ('so', 2), ('a', 2), ('we', 2), ('kevin', 2), ('at', 1)] | Training
2025-04-07 13:24:37 | 1400 | LR0.0003 | loss:3.5712 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.9787 | logitMax:-40.9981 | windowWeightsW18:0.18171,W21:0.16303,W13:0.15767,W15:0.15265,W8:0.12081,W7:0.10338,W3:0.06478,W2:0.02885,W1:0.01114 | memoryGatesShort:-2.089, Long:-2.828, Current:5.918 | topTokens[(',', 8), ('the', 6), ('and', 5), ('but', 2), ('she', 2), ('elodie', 2), ('my', 1), ('about', 1), ('there', 1), ('music', 1)] | Training
2025-04-07 13:24:42 | 1500 | LR0.0003 | loss:4.5900 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.2834 | logitMax:-36.8133 | windowWeightsW18:0.18035,W21:0.16150,W13:0.15776,W15:0.15230,W8:0.12072,W7:0.10363,W3:0.06752,W2:0.02978,W1:0.01046 | memoryGatesShort:-1.060, Long:-1.543, Current:3.602 | topTokens[(',', 5), ('and', 2), ('he', 2), ('you', 2), ('?', 2), ('fail', 2), ('one', 2), ('with', 2), ('she', 1), ('think', 1)] | Training
2025-04-07 13:24:46 | 1600 | LR0.0003 | loss:5.0258 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-44.3011 | logitMax:-29.6702 | windowWeightsW18:0.18001,W21:0.16123,W13:0.15952,W15:0.15297,W8:0.12222,W7:0.10421,W3:0.06732,W2:0.02846,W1:0.00814 | memoryGatesShort:-1.169, Long:-1.741, Current:3.910 | topTokens[('.', 4), ('i', 3), ('talk', 3), ('what', 2), ('speaking', 2), ('?', 2), (',', 2), ('sound', 1), ('is', 1), ('for', 1)] | Training
2025-04-07 13:24:50 | 1700 | LR0.0003 | loss:4.0707 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.9493 | logitMax:-41.2896 | windowWeightsW18:0.17946,W21:0.16085,W13:0.15949,W15:0.15259,W8:0.12255,W7:0.10320,W3:0.06775,W2:0.02880,W1:0.00936 | memoryGatesShort:-0.558, Long:-0.881, Current:2.439 | topTokens[('.', 4), ('?', 3), ('i', 3), ('am', 3), ('you', 2), ('to', 2), ('of', 2), ('with', 2), ('what', 2), (',', 1)] | Training
2025-04-07 13:24:54 | 1800 | LR0.0003 | loss:4.1495 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.6302 | logitMax:-37.9879 | windowWeightsW18:0.17871,W21:0.15974,W13:0.15961,W15:0.15212,W8:0.12333,W7:0.10343,W3:0.06769,W2:0.02966,W1:0.00976 | memoryGatesShort:-1.291, Long:-1.897, Current:4.188 | topTokens[('?', 4), ('.', 4), ('to', 2), ('sleep', 2), ('you', 2), ('i', 2), ('was', 2), ('should', 2), ('at', 2), ('listening', 2)] | Training
2025-04-07 13:24:58 | 1900 | LR0.0003 | loss:4.2400 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-40.0123 | logitMax:-24.1613 | windowWeightsW18:0.17682,W13:0.16010,W21:0.15807,W15:0.15199,W8:0.12520,W7:0.10499,W3:0.06867,W2:0.02937,W1:0.00886 | memoryGatesShort:-1.093, Long:-1.635, Current:3.728 | topTokens[('.', 6), ('?', 3), ('is', 3), ('about', 2), ('not', 2), ('as', 2), (',', 2), ('talk', 1), ('words', 1), ('music', 1)] | Training
2025-04-07 13:25:02 | 2000 | LR0.0003 | loss:3.0220 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.0837 | logitMax:-26.5668 | windowWeightsW18:0.17298,W13:0.15752,W21:0.15485,W15:0.14790,W8:0.12926,W7:0.10987,W3:0.06990,W2:0.03108,W1:0.01071 | memoryGatesShort:-2.744, Long:-3.931, Current:7.675 | topTokens[('0', 4), (':', 4), ('o', 4), ('?', 3), ('-', 3), ('4', 3), ('-', 3), ('1', 2), ('7', 1), ("'re", 1)] | Training
2025-04-07 13:25:06 | 2100 | LR0.0003 | loss:2.0137 | gradNorm:0.9915 | tokenCount:400.0000 | logitMin:-52.7398 | logitMax:-28.9379 | windowWeightsW18:0.17151,W13:0.15715,W21:0.15340,W15:0.14718,W8:0.13042,W7:0.11117,W3:0.07050,W2:0.03119,W1:0.01154 | memoryGatesShort:-0.908, Long:-1.363, Current:3.271 | topTokens[('20', 5), ('4', 4), ('0', 4), ('lear', 3), ('baby', 2), ('ll', 2), ('ning', 2), ('today', 2), ('-', 2), ('-', 2)] | Training
2025-04-07 13:25:10 | 2200 | LR0.0003 | loss:2.8061 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.9744 | logitMax:-28.3534 | windowWeightsW18:0.17002,W13:0.15768,W21:0.15264,W15:0.14610,W8:0.13322,W7:0.11380,W3:0.07005,W2:0.02921,W1:0.01132 | memoryGatesShort:-0.882, Long:-1.313, Current:3.195 | topTokens[("'", 5), (':', 4), ('-', 4), ('5', 4), ('2', 2), ('-', 2), ('0', 2), ('?', 2), ('i', 1), ('one', 1)] | Training
2025-04-07 13:25:14 | 2300 | LR0.0003 | loss:2.6662 | gradNorm:0.9586 | tokenCount:400.0000 | logitMin:-53.8210 | logitMax:-30.0970 | windowWeightsW18:0.16928,W13:0.15826,W21:0.15211,W15:0.14580,W8:0.13395,W7:0.11425,W3:0.07065,W2:0.02884,W1:0.01092 | memoryGatesShort:-0.423, Long:-0.703, Current:2.126 | topTokens[('0', 4), ('.', 3), ('-', 3), (':', 3), ('i', 3), ('nice', 2), ('5', 2), ('2', 2), ('at', 2), ('am', 2)] | Training
2025-04-07 13:25:18 | 2400 | LR0.0003 | loss:3.4941 | gradNorm:0.9599 | tokenCount:400.0000 | logitMin:-62.8632 | logitMax:-33.4804 | windowWeightsW18:0.16849,W13:0.15755,W21:0.15119,W15:0.14495,W8:0.13524,W7:0.11486,W3:0.07168,W2:0.02839,W1:0.01168 | memoryGatesShort:-0.609, Long:-0.962, Current:2.572 | topTokens[('-', 6), ('2', 6), ("'", 4), (':', 3), ("'", 3), ('?', 3), ('you', 2), ('ll', 2), ('m', 2), ('today', 2)] | Training
2025-04-07 13:25:22 | 2500 | LR0.0003 | loss:3.4144 | gradNorm:0.9722 | tokenCount:400.0000 | logitMin:-55.6540 | logitMax:-34.8029 | windowWeightsW18:0.16897,W13:0.15801,W21:0.15129,W15:0.14534,W8:0.13612,W7:0.11530,W3:0.07163,W2:0.02749,W1:0.00988 | memoryGatesShort:-1.316, Long:-1.957, Current:4.272 | topTokens[('7', 3), ('-', 3), ('-', 2), ('4', 2), ('baby', 2), ('i', 2), ('lear', 2), ("'", 2), ('h', 2), ('you', 2)] | Training
2025-04-07 13:25:26 | 2600 | LR0.0003 | loss:2.1052 | gradNorm:0.9707 | tokenCount:400.0000 | logitMin:-68.4070 | logitMax:-43.9099 | windowWeightsW18:0.16889,W13:0.15813,W21:0.15074,W15:0.14537,W8:0.13650,W7:0.11557,W3:0.07244,W2:0.02795,W1:0.00845 | memoryGatesShort:-0.520, Long:-0.856, Current:2.376 | topTokens[("'", 4), (':', 4), ('-', 3), ("'", 3), ('step', 3), ('4', 2), ('-', 2), ('0', 2), ('i', 2), ('m', 2)] | Training
2025-04-07 13:25:30 | 2700 | LR0.0003 | loss:3.1267 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-49.6425 | logitMax:-28.6351 | windowWeightsW18:0.16935,W13:0.15911,W21:0.15124,W15:0.14656,W8:0.13639,W7:0.11554,W3:0.07162,W2:0.02642,W1:0.00784 | memoryGatesShort:-0.506, Long:-0.817, Current:2.323 | topTokens[('0', 3), ('4', 3), ('to', 3), ('am', 2), ("'", 2), ('-', 2), ('rest', 2), ("'", 2), (':', 1), ('step', 1)] | Training
2025-04-07 13:25:34 | 2800 | LR0.0003 | loss:2.0189 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-62.2490 | logitMax:-41.0447 | windowWeightsW18:0.16883,W13:0.15893,W21:0.15025,W15:0.14591,W8:0.13729,W7:0.11644,W3:0.07184,W2:0.02648,W1:0.00808 | memoryGatesShort:-0.622, Long:-0.973, Current:2.595 | topTokens[('-', 4), ('i', 4), (':', 4), ('-', 2), ('3', 2), ("'", 2), ('last', 2), ('an', 1), ("'ll", 1), ('ning', 1)] | Training
2025-04-07 13:25:38 | 2900 | LR0.0003 | loss:2.3449 | gradNorm:0.9824 | tokenCount:400.0000 | logitMin:-64.7350 | logitMax:-40.7817 | windowWeightsW18:0.16869,W13:0.15934,W21:0.15020,W15:0.14592,W8:0.13826,W7:0.11715,W3:0.07096,W2:0.02580,W1:0.00775 | memoryGatesShort:-0.709, Long:-1.079, Current:2.788 | topTokens[("'", 4), ('0', 3), ('can', 2), ('9', 2), ('-', 2), ('4', 2), ('baby', 2), ('last', 2), ('don', 1), (':)', 1)] | Training
2025-04-07 13:25:43 | 3000 | LR0.0003 | loss:2.5357 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-63.2295 | logitMax:-38.9849 | windowWeightsW18:0.16764,W13:0.15928,W21:0.14929,W15:0.14516,W8:0.13885,W7:0.11757,W3:0.07199,W2:0.02623,W1:0.00804 | memoryGatesShort:-0.814, Long:-1.227, Current:3.041 | topTokens[('hh', 4), ('-', 3), ('-', 3), ('', 2), ("'", 2), ('!', 2), ('4', 2), ('to', 2), ('start', 1), ('from', 1)] | Training
2025-04-07 13:25:47 | 3100 | LR0.0003 | loss:1.8253 | gradNorm:0.9907 | tokenCount:400.0000 | logitMin:-68.6791 | logitMax:-43.4386 | windowWeightsW18:0.16759,W13:0.16036,W21:0.14942,W15:0.14543,W8:0.13895,W7:0.11696,W3:0.07146,W2:0.02576,W1:0.00812 | memoryGatesShort:-0.515, Long:-0.809, Current:2.324 | topTokens[('-', 4), ("'", 3), ('?', 3), ('4', 3), ('can', 2), ('baby', 2), ('s', 2), (':', 2), ("'", 2), ('start', 1)] | Training
2025-04-07 13:25:51 | 3200 | LR0.0003 | loss:2.3072 | gradNorm:0.9947 | tokenCount:400.0000 | logitMin:-60.9139 | logitMax:-35.4125 | windowWeightsW18:0.16659,W13:0.16086,W21:0.14853,W15:0.14453,W8:0.13917,W7:0.11708,W3:0.07162,W2:0.02689,W1:0.00876 | memoryGatesShort:-0.977, Long:-1.423, Current:3.400 | topTokens[('-', 3), ("'", 2), ('o', 2), ('-', 2), ('0', 2), (':', 2), (',', 2), ("'", 2), ('a', 1), ('random', 1)] | Training
2025-04-07 13:25:55 | 3300 | LR0.0003 | loss:2.5664 | gradNorm:0.9748 | tokenCount:400.0000 | logitMin:-55.1035 | logitMax:-29.8288 | windowWeightsW18:0.16659,W13:0.16145,W21:0.14868,W15:0.14463,W8:0.13941,W7:0.11687,W3:0.07065,W2:0.02705,W1:0.00872 | memoryGatesShort:-1.506, Long:-2.112, Current:4.618 | topTokens[('3', 5), (':', 4), ("'", 3), ('o', 3), ('-', 2), ('charis', 2), ('0', 2), ('4', 2), ("'s", 1), ('go', 1)] | Training
2025-04-07 13:25:59 | 3400 | LR0.0003 | loss:2.5968 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.4390 | logitMax:-32.2992 | windowWeightsW18:0.16619,W13:0.16195,W21:0.14778,W15:0.14486,W8:0.14074,W7:0.11798,W3:0.06970,W2:0.02645,W1:0.00840 | memoryGatesShort:-0.660, Long:-0.946, Current:2.606 | topTokens[('step', 3), ("'", 3), ('?', 3), (':', 2), ("'t", 2), ('i', 2), ('-', 2), ('baby', 2), ('let', 1), ('lear', 1)] | Training
2025-04-07 13:26:03 | 3500 | LR0.0003 | loss:2.2291 | gradNorm:0.9678 | tokenCount:400.0000 | logitMin:-60.5988 | logitMax:-36.5073 | windowWeightsW18:0.16617,W13:0.16215,W21:0.14744,W15:0.14492,W8:0.14086,W7:0.11809,W3:0.06944,W2:0.02661,W1:0.00839 | memoryGatesShort:-0.621, Long:-0.891, Current:2.511 | topTokens[('-', 4), ('baby', 3), ('ll', 2), ('?', 2), ('!', 2), ('i', 2), ("'", 1), ('let', 1), ("'s", 1), ('go', 1)] | Training
2025-04-07 13:26:07 | 3600 | LR0.0003 | loss:2.9371 | gradNorm:0.9825 | tokenCount:400.0000 | logitMin:-59.9834 | logitMax:-36.7440 | windowWeightsW18:0.16633,W13:0.16217,W21:0.14743,W15:0.14467,W8:0.14112,W7:0.11795,W3:0.06888,W2:0.02710,W1:0.00841 | memoryGatesShort:-0.466, Long:-0.704, Current:2.170 | topTokens[('what', 4), ('!', 3), (':', 3), ('am', 2), ('i', 2), ('er', 2), ("'", 2), ('0', 2), ('-', 2), ('k', 1)] | Training
2025-04-07 13:26:11 | 3700 | LR0.0003 | loss:3.4025 | gradNorm:0.9887 | tokenCount:400.0000 | logitMin:-57.1690 | logitMax:-33.2070 | windowWeightsW18:0.16676,W13:0.16254,W21:0.14787,W15:0.14536,W8:0.14130,W7:0.11791,W3:0.06836,W2:0.02669,W1:0.00728 | memoryGatesShort:-0.975, Long:-1.347, Current:3.323 | topTokens[(':', 3), ('k', 2), ('...', 2), ('to', 2), ('step', 2), ('i', 2), ('g', 2), ('-', 2), ('baby', 2), ('o', 1)] | Training
2025-04-07 13:26:15 | 3800 | LR0.0003 | loss:6.1919 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-42.0698 | logitMax:-24.2317 | windowWeightsW18:0.16734,W13:0.16368,W21:0.14856,W15:0.14620,W8:0.14120,W7:0.11748,W3:0.06768,W2:0.02567,W1:0.00629 | memoryGatesShort:-2.356, Long:-3.061, Current:6.417 | topTokens[('!', 3), (',', 3), ('let', 2), ('to', 2), ("'", 2), ('6', 2), ('8', 2), ('-', 2), ('-', 2), ('rest', 1)] | Training
2025-04-07 13:26:19 | 3900 | LR0.0003 | loss:6.8923 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-37.4066 | logitMax:-24.5794 | windowWeightsW18:0.16834,W13:0.16431,W21:0.14951,W15:0.14711,W8:0.14113,W7:0.11728,W3:0.06683,W2:0.02448,W1:0.00514 | memoryGatesShort:-2.580, Long:-3.279, Current:6.858 | topTokens[(',', 9), ('charis', 4), ('i', 4), ('a', 3), ('.', 3), ('you', 2), ('do', 1), ('please', 1), ('lot', 1), ('?', 1)] | Training
2025-04-07 13:26:23 | 4000 | LR0.0003 | loss:7.1375 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-39.9255 | logitMax:-27.0082 | windowWeightsW18:0.16879,W13:0.16477,W21:0.15008,W15:0.14756,W8:0.14093,W7:0.11708,W3:0.06624,W2:0.02407,W1:0.00462 | memoryGatesShort:-1.918, Long:-2.425, Current:5.343 | topTokens[(',', 6), ('a', 4), ('to', 4), ('and', 3), ('.', 3), ('-', 2), ('6', 2), ('ha', 1), ('who', 1), ('one', 1)] | Training
2025-04-07 13:26:27 | 4100 | LR0.0003 | loss:7.1121 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-43.4262 | logitMax:-31.7030 | windowWeightsW18:0.16910,W13:0.16526,W21:0.15054,W15:0.14808,W8:0.14091,W7:0.11696,W3:0.06585,W2:0.02345,W1:0.00402 | memoryGatesShort:-0.564, Long:-0.736, Current:2.300 | topTokens[(',', 7), ('.', 4), ('for', 3), ('a', 3), ('what', 2), ('i', 2), ('y', 1), ('can', 1), ('ing', 1), ('f', 1)] | Training
2025-04-07 13:26:30 | 4200 | LR0.0003 | loss:7.1547 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-41.7681 | logitMax:-29.5386 | windowWeightsW18:0.16939,W13:0.16523,W21:0.15082,W15:0.14814,W8:0.14087,W7:0.11687,W3:0.06569,W2:0.02332,W1:0.00382 | memoryGatesShort:-0.456, Long:-0.561, Current:2.017 | topTokens[(',', 9), ('.', 4), ('a', 3), ('to', 3), ('charis', 2), ('as', 1), ('nice', 1), ('not', 1), ('um', 1), ('r', 1)] | Training
2025-04-07 13:26:34 | 4300 | LR0.0003 | loss:6.9532 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-42.5276 | logitMax:-30.9771 | windowWeightsW18:0.16975,W13:0.16518,W21:0.15152,W15:0.14824,W8:0.14075,W7:0.11689,W3:0.06523,W2:0.02300,W1:0.00361 | memoryGatesShort:-0.663, Long:-0.735, Current:2.398 | topTokens[(',', 12), ('a', 5), ('.', 4), ('she', 2), ('to', 2), ('it', 1), ('but', 1), ('her', 1), ('how', 1), ('does', 1)] | Training
2025-04-07 13:26:38 | 4400 | LR0.0003 | loss:7.1177 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-42.3187 | logitMax:-30.7250 | windowWeightsW18:0.16981,W13:0.16568,W21:0.15193,W15:0.14824,W8:0.14114,W7:0.11746,W3:0.06459,W2:0.02229,W1:0.00303 | memoryGatesShort:-4.582, Long:-4.214, Current:9.797 | topTokens[('to', 4), ('.', 4), ('i', 3), (',', 3), ('looking', 2), ("'", 2), ('what', 2), ('ed', 2), ('p', 2), ('a', 2)] | Training
2025-04-07 13:26:42 | 4500 | LR0.0003 | loss:7.3420 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-39.5089 | logitMax:-28.5695 | windowWeightsW18:0.17003,W13:0.16588,W21:0.15223,W15:0.14844,W8:0.14118,W7:0.11747,W3:0.06424,W2:0.02189,W1:0.00282 | memoryGatesShort:-0.463, Long:-0.311, Current:1.774 | topTokens[(',', 11), ('.', 8), ('a', 3), ('to', 2), ('!', 2), ('i', 2), ('them', 1), ('looking', 1), ('th', 1), ('he', 1)] | Training
2025-04-07 13:26:46 | 4600 | LR0.0003 | loss:6.7395 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-37.8221 | logitMax:-27.3468 | windowWeightsW18:0.17011,W13:0.16595,W21:0.15225,W15:0.14856,W8:0.14104,W7:0.11731,W3:0.06411,W2:0.02179,W1:0.00307 | memoryGatesShort:-0.819, Long:-0.635, Current:2.454 | topTokens[('!', 8), ('.', 4), (',', 3), ('ing', 2), ('the', 2), ('p', 2), ('a', 1), ('ed', 1), ('k', 1), ('h', 1)] | Training
2025-04-07 13:26:50 | 4700 | LR0.0003 | loss:6.8873 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-37.6697 | logitMax:-26.6299 | windowWeightsW18:0.17035,W13:0.16604,W21:0.15260,W15:0.14875,W8:0.14054,W7:0.11701,W3:0.06403,W2:0.02174,W1:0.00313 | memoryGatesShort:-0.959, Long:-0.740, Current:2.699 | topTokens[(',', 6), ('-', 3), (':', 3), ('a', 3), ('to', 2), ('p', 2), ('.', 2), ('im', 2), ('it', 1), ('!', 1)] | Training
2025-04-07 13:26:54 | 4800 | LR0.0003 | loss:6.6495 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-44.5701 | logitMax:-32.9999 | windowWeightsW18:0.17017,W13:0.16614,W21:0.15242,W15:0.14864,W8:0.14044,W7:0.11698,W3:0.06432,W2:0.02197,W1:0.00311 | memoryGatesShort:-0.440, Long:-0.356, Current:1.796 | topTokens[('a', 5), ('of', 4), (',', 4), ('-', 3), ('them', 2), ('to', 2), ("'", 2), ('.', 2), ('i', 2), ('am', 2)] | Training
2025-04-07 13:26:58 | 4900 | LR0.0003 | loss:5.3208 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-49.8661 | logitMax:-36.7332 | windowWeightsW18:0.17011,W13:0.16584,W21:0.15250,W15:0.14830,W8:0.14069,W7:0.11740,W3:0.06414,W2:0.02174,W1:0.00345 | memoryGatesShort:-0.941, Long:-0.831, Current:2.772 | topTokens[('a', 5), ('to', 4), ('-', 2), ('of', 2), ("'", 2), ('not', 2), ('i', 2), ("'ll", 2), ('?', 2), ('mum', 1)] | Training
2025-04-07 13:27:02 | 5000 | LR0.0003 | loss:5.7462 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.0248 | logitMax:-32.1705 | windowWeightsW18:0.17014,W13:0.16546,W21:0.15261,W15:0.14799,W8:0.14109,W7:0.11755,W3:0.06437,W2:0.02154,W1:0.00344 | memoryGatesShort:-1.099, Long:-1.001, Current:3.100 | topTokens[('a', 6), ('i', 4), ('?', 4), ('!', 3), ('-', 3), (',', 3), ('.', 2), ('does', 1), ('you', 1), ('what', 1)] | Training
2025-04-07 13:27:06 | 5100 | LR0.0003 | loss:5.1622 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-39.0179 | logitMax:-26.1162 | windowWeightsW18:0.16971,W13:0.16508,W21:0.15209,W15:0.14745,W8:0.14138,W7:0.11802,W3:0.06489,W2:0.02185,W1:0.00370 | memoryGatesShort:-1.004, Long:-0.960, Current:2.964 | topTokens[('.', 6), ('i', 4), ('you', 3), ('do', 2), ('-', 2), ('about', 2), ('?', 2), (':', 2), ('her', 2), ('talk', 1)] | Training
2025-04-07 13:27:10 | 5200 | LR0.0003 | loss:5.1428 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-48.1308 | logitMax:-34.2391 | windowWeightsW18:0.16997,W13:0.16497,W21:0.15235,W15:0.14755,W8:0.14132,W7:0.11771,W3:0.06498,W2:0.02154,W1:0.00377 | memoryGatesShort:-0.850, Long:-0.819, Current:2.670 | topTokens[('you', 7), ('i', 6), ('?', 6), ('-', 3), ('.', 3), ('do', 2), ('a', 2), ('about', 1), ('were', 1), ('in', 1)] | Training
2025-04-07 13:27:14 | 5300 | LR0.0003 | loss:5.4420 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-49.2244 | logitMax:-35.3370 | windowWeightsW18:0.16968,W13:0.16477,W21:0.15192,W15:0.14707,W8:0.14172,W7:0.11808,W3:0.06516,W2:0.02207,W1:0.00368 | memoryGatesShort:-0.795, Long:-0.816, Current:2.611 | topTokens[('.', 8), ('?', 5), ('is', 5), ('to', 2), ('i', 2), ('-', 2), ('a', 2), ('my', 1), ('what', 1), ('you', 1)] | Training
2025-04-07 13:27:18 | 5400 | LR0.0003 | loss:5.8019 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-37.1651 | logitMax:-23.1980 | windowWeightsW18:0.16979,W13:0.16486,W21:0.15226,W15:0.14725,W8:0.14116,W7:0.11777,W3:0.06506,W2:0.02213,W1:0.00387 | memoryGatesShort:-0.763, Long:-0.787, Current:2.550 | topTokens[('.', 8), ('?', 5), ('do', 2), ('a', 2), ('i', 2), ('ing', 2), ('he', 1), (',', 1), ('she', 1), ('-', 1)] | Training
2025-04-07 13:27:22 | 5500 | LR0.0003 | loss:4.5291 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-46.0033 | logitMax:-32.1732 | windowWeightsW18:0.17092,W13:0.16484,W21:0.15329,W15:0.14813,W8:0.14105,W7:0.11769,W3:0.06426,W2:0.02070,W1:0.00331 | memoryGatesShort:-1.774, Long:-1.819, Current:4.593 | topTokens[('is', 6), ('?', 6), ('.', 4), ('what', 2), ('i', 2), ('ing', 2), ('you', 2), (',', 2), ('go', 1), ('they', 1)] | Training
2025-04-07 13:27:25 | 5600 | LR0.0003 | loss:5.9840 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.8814 | logitMax:-36.4627 | windowWeightsW18:0.17134,W13:0.16527,W21:0.15339,W15:0.14870,W8:0.14088,W7:0.11722,W3:0.06392,W2:0.02053,W1:0.00293 | memoryGatesShort:-2.697, Long:-2.803, Current:6.500 | topTokens[('.', 7), ('!', 5), ('you', 3), ('kevin', 3), ('?', 3), (',', 3), ('going', 2), ('ice', 2), ('and', 2), ('are', 1)] | Training
2025-04-07 13:27:29 | 5700 | LR0.0003 | loss:6.4304 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-41.2520 | logitMax:-28.1086 | windowWeightsW18:0.17200,W13:0.16591,W21:0.15383,W15:0.14965,W8:0.14050,W7:0.11678,W3:0.06347,W2:0.01997,W1:0.00208 | memoryGatesShort:-1.555, Long:-1.569, Current:4.124 | topTokens[('.', 5), ('is', 5), ('the', 3), ('a', 3), ('!', 3), ('and', 2), ('?', 2), (',', 2), ('id', 1), ('she', 1)] | Training
2025-04-07 13:27:33 | 5800 | LR0.0003 | loss:5.8992 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-42.6590 | logitMax:-29.9770 | windowWeightsW18:0.17222,W13:0.16620,W21:0.15414,W15:0.14954,W8:0.14040,W7:0.11653,W3:0.06331,W2:0.01961,W1:0.00226 | memoryGatesShort:-2.195, Long:-2.242, Current:5.437 | topTokens[('!', 6), ('the', 3), ('you', 2), ('ll', 2), ('what', 2), ('.', 2), (',', 1), ('kevin', 1), ('r', 1), ('do', 1)] | Training
2025-04-07 13:27:37 | 5900 | LR0.0003 | loss:5.8829 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.9883 | logitMax:-33.3247 | windowWeightsW18:0.17216,W13:0.16626,W21:0.15423,W15:0.14968,W8:0.14044,W7:0.11673,W3:0.06302,W2:0.01951,W1:0.00216 | memoryGatesShort:-1.827, Long:-1.851, Current:4.679 | topTokens[(',', 9), ('.', 4), ('you', 3), ('a', 3), ('!', 2), ('i', 1), ('to', 1), ('ice', 1), ('be', 1), ('know', 1)] | Training
2025-04-07 13:27:41 | 6000 | LR0.0003 | loss:5.5122 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.2490 | logitMax:-34.4410 | windowWeightsW18:0.17247,W13:0.16600,W21:0.15453,W15:0.14987,W8:0.14069,W7:0.11687,W3:0.06280,W2:0.01912,W1:0.00186 | memoryGatesShort:-1.856, Long:-1.831, Current:4.687 | topTokens[('!', 10), (',', 7), ('you', 4), ('she', 2), ('?', 2), ('w', 2), ('do', 1), ('was', 1), ('how', 1), ('.', 1)] | Training
2025-04-07 13:27:45 | 6100 | LR0.0003 | loss:4.8874 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.4880 | logitMax:-36.9270 | windowWeightsW18:0.17232,W13:0.16589,W21:0.15439,W15:0.14955,W8:0.14049,W7:0.11712,W3:0.06288,W2:0.01936,W1:0.00220 | memoryGatesShort:-7.394, Long:-7.484, Current:15.878 | topTokens[('!', 5), ('the', 4), (',', 3), ('you', 3), ('id', 3), ('ed', 2), ('it', 2), ('they', 2), ('n', 1), ('kevin', 1)] | Training
2025-04-07 13:27:50 | 6200 | LR0.0003 | loss:6.0395 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.4882 | logitMax:-33.1545 | windowWeightsW18:0.17230,W13:0.16601,W21:0.15442,W15:0.14961,W8:0.14038,W7:0.11715,W3:0.06273,W2:0.01931,W1:0.00230 | memoryGatesShort:-1.585, Long:-1.599, Current:4.184 | topTokens[('!', 9), (',', 7), ('it', 3), ('.', 2), ('d', 2), ('the', 2), ('a', 1), ('h', 1), ('too', 1), ('help', 1)] | Training
2025-04-07 13:27:55 | 6300 | LR0.0003 | loss:5.9444 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.4818 | logitMax:-32.3707 | windowWeightsW18:0.17300,W13:0.16648,W21:0.15497,W15:0.14991,W8:0.14034,W7:0.11672,W3:0.06247,W2:0.01884,W1:0.00148 | memoryGatesShort:-0.407, Long:-0.395, Current:1.802 | topTokens[(',', 12), ('!', 7), ('.', 3), ('her', 2), ('d', 1), ('to', 1), ('be', 1), ('roid', 1), ('w', 1), ('ing', 1)] | Training
2025-04-07 13:27:59 | 6400 | LR0.0003 | loss:5.0760 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.5685 | logitMax:-37.0968 | windowWeightsW18:0.17295,W13:0.16605,W21:0.15469,W15:0.14977,W8:0.14017,W7:0.11630,W3:0.06261,W2:0.01924,W1:0.00243 | memoryGatesShort:-1.350, Long:-1.366, Current:3.716 | topTokens[('they', 7), ('a', 4), (',', 3), ('!', 3), ('the', 3), ('id', 2), ('c', 1), ('an', 1), ('st', 1), ('charis', 1)] | Training
2025-04-07 13:28:03 | 6500 | LR0.0003 | loss:5.5321 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.7732 | logitMax:-34.2351 | windowWeightsW18:0.17319,W13:0.16622,W21:0.15509,W15:0.15007,W8:0.14010,W7:0.11639,W3:0.06225,W2:0.01886,W1:0.00204 | memoryGatesShort:-0.950, Long:-0.939, Current:2.888 | topTokens[('the', 5), ('!', 4), ('it', 3), ('ed', 2), (',', 2), ('w', 2), ('a', 2), ('.', 2), ('was', 2), ('they', 2)] | Training
2025-04-07 13:28:08 | 6600 | LR0.0003 | loss:5.6136 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-43.6191 | logitMax:-31.0957 | windowWeightsW18:0.17330,W13:0.16658,W21:0.15522,W15:0.15019,W8:0.13986,W7:0.11642,W3:0.06240,W2:0.01849,W1:0.00176 | memoryGatesShort:-2.176, Long:-2.132, Current:5.308 | topTokens[(',', 5), ('.', 4), ('id', 3), ('they', 2), ('ed', 2), ('!', 2), ('sp', 2), ('ll', 1), ('m', 1), ('angle', 1)] | Training
2025-04-07 13:28:12 | 6700 | LR0.0003 | loss:5.2759 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-46.3330 | logitMax:-33.1979 | windowWeightsW18:0.17301,W13:0.16607,W21:0.15534,W15:0.14986,W8:0.14012,W7:0.11656,W3:0.06293,W2:0.01875,W1:0.00156 | memoryGatesShort:-0.967, Long:-0.969, Current:2.936 | topTokens[('!', 5), ('angle', 4), (',', 4), ('i', 3), ('the', 3), ('was', 3), ('ed', 2), ('roid', 1), ('sp', 1), ('home', 1)] | Training
2025-04-07 13:28:16 | 6800 | LR0.0003 | loss:4.6166 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.2815 | logitMax:-39.3369 | windowWeightsW18:0.17275,W13:0.16517,W21:0.15504,W15:0.14951,W8:0.13958,W7:0.11603,W3:0.06371,W2:0.01928,W1:0.00311 | memoryGatesShort:-2.050, Long:-2.124, Current:5.174 | topTokens[('i', 3), ('angle', 3), ('a', 3), ('!', 3), ('the', 3), ('id', 3), ('it', 3), ('.', 2), ('roid', 1), ('d', 1)] | Training
2025-04-07 13:28:20 | 6900 | LR0.0003 | loss:4.8946 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-48.9536 | logitMax:-33.3492 | windowWeightsW18:0.17220,W13:0.16471,W21:0.15463,W15:0.14919,W8:0.13960,W7:0.11583,W3:0.06435,W2:0.01993,W1:0.00371 | memoryGatesShort:-1.852, Long:-1.978, Current:4.830 | topTokens[(',', 7), ('!', 5), ('a', 2), ('and', 2), ('ood', 2), ('ed', 2), ('angle', 2), ('we', 2), ('they', 1), ('start', 1)] | Training
2025-04-07 13:28:24 | 7000 | LR0.0003 | loss:5.1478 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.5079 | logitMax:-32.8720 | windowWeightsW18:0.17219,W13:0.16505,W21:0.15479,W15:0.14966,W8:0.13968,W7:0.11569,W3:0.06402,W2:0.01958,W1:0.00351 | memoryGatesShort:-2.100, Long:-2.221, Current:5.321 | topTokens[(',', 5), ('angle', 3), ('!', 3), ('it', 3), ('the', 3), ('m', 2), ('w', 2), ('she', 2), ('a', 2), ('st', 2)] | Training
2025-04-07 13:28:28 | 7100 | LR0.0003 | loss:5.2326 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-41.2858 | logitMax:-26.5777 | windowWeightsW18:0.17192,W13:0.16482,W21:0.15469,W15:0.14921,W8:0.14020,W7:0.11511,W3:0.06452,W2:0.01964,W1:0.00404 | memoryGatesShort:-4.177, Long:-4.464, Current:9.641 | topTokens[('the', 7), (',', 5), ('!', 4), ('a', 3), ('w', 3), ('they', 2), ('ood', 2), ('war', 1), ('it', 1), ('ath', 1)] | Training
2025-04-07 13:28:32 | 7200 | LR0.0003 | loss:5.6616 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-46.3858 | logitMax:-31.0492 | windowWeightsW18:0.17220,W13:0.16506,W21:0.15533,W15:0.14981,W8:0.13966,W7:0.11478,W3:0.06438,W2:0.01901,W1:0.00394 | memoryGatesShort:-2.926, Long:-3.102, Current:7.028 | topTokens[(',', 6), ('the', 4), ('a', 4), ('ered', 3), ('things', 3), ('!', 3), ('they', 2), ('ro', 1), ('ious', 1), ('am', 1)] | Training
2025-04-07 13:28:36 | 7300 | LR0.0003 | loss:5.4344 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-44.2232 | logitMax:-29.0140 | windowWeightsW18:0.17217,W13:0.16557,W21:0.15574,W15:0.14997,W8:0.13928,W7:0.11464,W3:0.06429,W2:0.01875,W1:0.00375 | memoryGatesShort:-1.631, Long:-1.718, Current:4.349 | topTokens[(',', 7), ('!', 5), ('she', 4), ('.', 3), ('the', 3), ('a', 2), ('to', 2), ('h', 2), ('ll', 2), ('in', 1)] | Training
2025-04-07 13:28:40 | 7400 | LR0.0003 | loss:5.3285 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-40.8477 | logitMax:-26.6611 | windowWeightsW18:0.17267,W13:0.16594,W21:0.15633,W15:0.15053,W8:0.13816,W7:0.11385,W3:0.06430,W2:0.01836,W1:0.00401 | memoryGatesShort:-2.215, Long:-2.319, Current:5.534 | topTokens[(',', 6), ('.', 5), ('!', 3), ('-', 2), ('ood', 2), ('you', 2), ('we', 2), ('to', 2), ('the', 1), ('they', 1)] | Training
2025-04-07 13:28:44 | 7500 | LR0.0003 | loss:3.6495 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-56.1827 | logitMax:-40.5875 | windowWeightsW18:0.17225,W13:0.16525,W21:0.15618,W15:0.15008,W8:0.13737,W7:0.11382,W3:0.06538,W2:0.01927,W1:0.00453 | memoryGatesShort:-1.487, Long:-1.587, Current:4.074 | topTokens[('i', 8), ('!', 6), ('it', 6), ('am', 3), ('.', 2), ('we', 2), (',', 2), ('a', 2), ('will', 1), ('st', 1)] | Training
2025-04-07 13:28:48 | 7600 | LR0.0003 | loss:4.6261 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-52.6205 | logitMax:-37.0481 | windowWeightsW18:0.17261,W13:0.16559,W21:0.15637,W15:0.15067,W8:0.13659,W7:0.11361,W3:0.06633,W2:0.01932,W1:0.00308 | memoryGatesShort:-1.932, Long:-2.077, Current:5.009 | topTokens[('a', 5), ('it', 4), ('!', 4), ('lo', 3), ('i', 3), ('to', 2), ('m', 1), ('ll', 1), ('h', 1), ('baby', 1)] | Training
2025-04-07 13:28:52 | 7700 | LR0.0003 | loss:4.0967 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-49.2963 | logitMax:-33.3179 | windowWeightsW18:0.17168,W13:0.16486,W21:0.15557,W15:0.15024,W8:0.13621,W7:0.11330,W3:0.06876,W2:0.02065,W1:0.00286 | memoryGatesShort:-2.632, Long:-2.926, Current:6.559 | topTokens[('!', 7), ('it', 6), ('a', 3), ('elodie', 2), ('have', 2), ('been', 2), ('could', 2), ('say', 1), ('made', 1), ('b', 1)] | Training
2025-04-07 13:28:57 | 7800 | LR0.0003 | loss:3.2990 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.1560 | logitMax:-37.0101 | windowWeightsW18:0.17114,W13:0.16459,W21:0.15527,W15:0.14955,W8:0.13631,W7:0.11365,W3:0.06990,W2:0.02105,W1:0.00266 | memoryGatesShort:-1.251, Long:-1.445, Current:3.696 | topTokens[('!', 7), ('have', 5), ('it', 4), ('a', 3), ('charis', 2), ('could', 2), ('kevin', 2), ('.', 1), ('are', 1), ('will', 1)] | Training
2025-04-07 13:29:01 | 7900 | LR0.0003 | loss:2.8899 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-51.9014 | logitMax:-34.8636 | windowWeightsW18:0.17155,W13:0.16445,W21:0.15517,W15:0.14971,W8:0.13559,W7:0.11295,W3:0.07094,W2:0.02059,W1:0.00317 | memoryGatesShort:-1.987, Long:-2.334, Current:5.321 | topTokens[('it', 10), ('!', 8), ('will', 3), ('felt', 3), ('a', 2), ('had', 2), (',', 1), ('like', 1), ('elodie', 1), ('n', 1)] | Training
2025-04-07 13:29:06 | 8000 | LR0.0003 | loss:3.3875 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.8922 | logitMax:-30.7271 | windowWeightsW18:0.17108,W13:0.16385,W21:0.15456,W15:0.14943,W8:0.13527,W7:0.11232,W3:0.07185,W2:0.02179,W1:0.00394 | memoryGatesShort:-3.961, Long:-4.690, Current:9.651 | topTokens[('!', 7), ('it', 6), ('ing', 4), ('baby', 2), ('i', 2), ('had', 2), ('will', 2), ('lo', 1), ('should', 1), ('been', 1)] | Training
2025-04-07 13:29:10 | 8100 | LR0.0003 | loss:3.2492 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-49.3219 | logitMax:-31.5888 | windowWeightsW18:0.17162,W13:0.16344,W21:0.15500,W15:0.14972,W8:0.13507,W7:0.11176,W3:0.07194,W2:0.02199,W1:0.00355 | memoryGatesShort:-1.261, Long:-1.531, Current:3.791 | topTokens[('!', 10), ('it', 6), ('a', 4), ('will', 3), ('say', 3), ('i', 2), ('they', 2), ('should', 1), ('she', 1), (',', 1)] | Training
2025-04-07 13:29:14 | 8200 | LR0.0003 | loss:3.1643 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-42.6058 | logitMax:-25.9594 | windowWeightsW18:0.17139,W13:0.16302,W21:0.15498,W15:0.14916,W8:0.13446,W7:0.11148,W3:0.07313,W2:0.02275,W1:0.00370 | memoryGatesShort:-2.376, Long:-2.873, Current:6.249 | topTokens[('!', 7), ('it', 6), ('been', 4), ('know', 3), ('ing', 3), ('elodie', 3), ('they', 2), ('can', 1), (',', 1), ('could', 1)] | Training
2025-04-07 13:29:18 | 8300 | LR0.0003 | loss:2.8159 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-46.2113 | logitMax:-28.6292 | windowWeightsW18:0.17179,W13:0.16191,W21:0.15551,W15:0.14810,W8:0.13277,W7:0.11095,W3:0.07522,W2:0.02390,W1:0.00388 | memoryGatesShort:-1.721, Long:-2.145, Current:4.866 | topTokens[('!', 9), ('you', 5), ('and', 4), ('it', 3), ('been', 3), ('will', 2), ('have', 2), ('baby', 1), ('i', 1), ('feel', 1)] | Training
2025-04-07 13:29:23 | 8400 | LR0.0003 | loss:3.2002 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-54.4764 | logitMax:-34.9722 | windowWeightsW18:0.17034,W13:0.16105,W21:0.15407,W15:0.14734,W8:0.13380,W7:0.11186,W3:0.07705,W2:0.02572,W1:0.00278 | memoryGatesShort:-1.530, Long:-1.981, Current:4.511 | topTokens[('!', 8), ('it', 5), ('you', 4), ('baby', 3), ('ing', 2), ('have', 2), ('just', 2), ('.', 2), ('would', 2), ('a', 2)] | Training
2025-04-07 13:29:27 | 8500 | LR0.0003 | loss:2.3887 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-49.7425 | logitMax:-30.0776 | windowWeightsW18:0.17064,W13:0.16148,W21:0.15380,W15:0.14618,W8:0.13332,W7:0.11174,W3:0.07746,W2:0.02597,W1:0.00338 | memoryGatesShort:-2.518, Long:-3.208, Current:6.725 | topTokens[('just', 6), ('!', 6), ('it', 5), ('been', 3), ('you', 2), ('should', 2), ('would', 2), ('have', 2), ('a', 2), ('doing', 2)] | Training
2025-04-07 13:29:31 | 8600 | LR0.0003 | loss:3.7111 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-39.4577 | logitMax:-21.1654 | windowWeightsW18:0.17136,W13:0.16172,W21:0.15484,W15:0.14713,W8:0.13265,W7:0.11180,W3:0.07742,W2:0.02544,W1:0.00167 | memoryGatesShort:-2.064, Long:-2.641, Current:5.705 | topTokens[('!', 6), ('it', 5), ('have', 3), ('elodie', 3), (',', 3), ('i', 2), ('should', 2), ('a', 2), ('ies', 2), ('could', 1)] | Training
2025-04-07 13:29:35 | 8700 | LR0.0003 | loss:2.8237 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-48.4478 | logitMax:-28.8561 | windowWeightsW18:0.17108,W13:0.16165,W21:0.15463,W15:0.14689,W8:0.13284,W7:0.11119,W3:0.07819,W2:0.02598,W1:0.00157 | memoryGatesShort:-1.956, Long:-2.540, Current:5.497 | topTokens[('it', 8), ('!', 6), ('have', 4), ('a', 3), ('said', 3), ('you', 2), ('been', 2), ('just', 2), ('say', 1), ('be', 1)] | Training
2025-04-07 13:29:40 | 8800 | LR0.0003 | loss:2.9711 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-42.3999 | logitMax:-24.5015 | windowWeightsW18:0.17095,W13:0.16123,W21:0.15470,W15:0.14697,W8:0.13281,W7:0.11119,W3:0.07807,W2:0.02636,W1:0.00172 | memoryGatesShort:-1.732, Long:-2.257, Current:4.989 | topTokens[('it', 6), ('!', 5), ('charis', 3), ('and', 3), ('have', 2), ('been', 2), ('will', 2), ('she', 2), ('said', 2), ('feeling', 2)] | Training
2025-04-07 13:29:44 | 8900 | LR0.0003 | loss:5.6695 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-37.0484 | logitMax:-20.8946 | windowWeightsW18:0.17149,W13:0.16142,W21:0.15517,W15:0.14751,W8:0.13346,W7:0.11161,W3:0.07757,W2:0.02538,W1:0.00042 | memoryGatesShort:-1.663, Long:-2.195, Current:4.858 | topTokens[('she', 4), ('it', 4), ('should', 4), ('!', 4), (',', 3), ('have', 2), ('i', 2), ('.', 2), ('a', 2), ('to', 2)] | Training
2025-04-07 13:29:49 | 9000 | LR0.0003 | loss:5.1924 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-38.6964 | logitMax:-23.8659 | windowWeightsW18:0.17181,W13:0.16164,W21:0.15563,W15:0.14786,W8:0.13352,W7:0.11164,W3:0.07783,W2:0.02446,W1:-0.00033 | memoryGatesShort:-1.361, Long:-1.822, Current:4.183 | topTokens[('it', 5), ('.', 4), ('to', 3), ('!', 3), ('you', 2), ('charis', 2), ('i', 2), ('have', 2), ('ice', 1), ('they', 1)] | Training
2025-04-07 13:29:53 | 9100 | LR0.0003 | loss:5.7358 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-37.1692 | logitMax:-22.4042 | windowWeightsW18:0.17241,W13:0.16229,W21:0.15607,W15:0.14859,W8:0.13326,W7:0.11141,W3:0.07724,W2:0.02363,W1:-0.00084 | memoryGatesShort:-10.765, Long:-13.571, Current:25.336 | topTokens[('charis', 4), ('!', 4), ('a', 3), ('he', 2), ('i', 2), ('kevin', 2), (',', 2), ('to', 2), ('.', 2), ('was', 1)] | Training
2025-04-07 13:29:57 | 9200 | LR0.0003 | loss:6.0403 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-39.4824 | logitMax:-25.0243 | windowWeightsW18:0.17302,W13:0.16219,W21:0.15649,W15:0.14884,W8:0.13310,W7:0.11146,W3:0.07743,W2:0.02309,W1:-0.00156 | memoryGatesShort:-4.637, Long:-5.954, Current:11.591 | topTokens[('!', 5), ('.', 4), ('i', 4), (',', 3), ('?', 3), ('it', 2), ('to', 2), ('just', 2), ('if', 1), ('be', 1)] | Training
2025-04-07 13:30:02 | 9300 | LR0.0003 | loss:5.2547 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-40.3565 | logitMax:-25.7788 | windowWeightsW18:0.17327,W13:0.16243,W21:0.15674,W15:0.14909,W8:0.13285,W7:0.11113,W3:0.07725,W2:0.02303,W1:-0.00170 | memoryGatesShort:-2.094, Long:-2.727, Current:5.822 | topTokens[('?', 6), ('.', 3), ('charis', 3), ('is', 3), ('to', 3), (',', 2), ('i', 2), ('you', 2), ('-', 1), ('h', 1)] | Training
2025-04-07 13:30:06 | 9400 | LR0.0003 | loss:5.1948 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-39.7055 | logitMax:-26.1182 | windowWeightsW18:0.17315,W13:0.16253,W21:0.15648,W15:0.14895,W8:0.13299,W7:0.11109,W3:0.07763,W2:0.02321,W1:-0.00194 | memoryGatesShort:-2.722, Long:-3.587, Current:7.309 | topTokens[('.', 9), ('a', 4), ('i', 3), ('you', 3), ('is', 2), ('?', 2), ('could', 1), ('ing', 1), ('let', 1), ('to', 1)] | Training
2025-04-07 13:30:10 | 9500 | LR0.0003 | loss:4.4680 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-39.9118 | logitMax:-25.0263 | windowWeightsW18:0.17315,W13:0.16192,W21:0.15623,W15:0.14853,W8:0.13251,W7:0.11059,W3:0.07809,W2:0.02416,W1:-0.00112 | memoryGatesShort:-2.412, Long:-3.193, Current:6.605 | topTokens[('?', 3), ('.', 3), ('you', 3), ('have', 3), ('it', 3), ('i', 2), (',', 2), ('was', 2), ('ing', 2), ('been', 2)] | Training
2025-04-07 13:30:14 | 9600 | LR0.0003 | loss:3.3751 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-41.3260 | logitMax:-26.1128 | windowWeightsW18:0.17309,W13:0.16175,W21:0.15602,W15:0.14792,W8:0.13181,W7:0.10984,W3:0.07860,W2:0.02574,W1:-0.00072 | memoryGatesShort:-1.714, Long:-2.318, Current:5.031 | topTokens[('have', 6), ('must', 5), ('!', 4), ('felt', 3), (',', 2), ('what', 2), ('it', 2), ('you', 2), ('was', 1), ('he', 1)] | Training
2025-04-07 13:30:18 | 9700 | LR0.0003 | loss:2.8086 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-42.1059 | logitMax:-25.5700 | windowWeightsW18:0.17259,W13:0.16141,W21:0.15563,W15:0.14761,W8:0.13146,W7:0.10943,W3:0.07919,W2:0.02652,W1:0.00018 | memoryGatesShort:-2.255, Long:-3.027, Current:6.282 | topTokens[('must', 8), ('!', 5), ('have', 5), ('felt', 4), ('the', 3), ('oice', 2), ('lo', 1), ('find', 1), ('kevin', 1), (',', 1)] | Training
2025-04-07 13:30:23 | 9800 | LR0.0003 | loss:2.5478 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-40.9690 | logitMax:-24.1052 | windowWeightsW18:0.17214,W13:0.16116,W21:0.15525,W15:0.14732,W8:0.13109,W7:0.10910,W3:0.07978,W2:0.02785,W1:0.00031 | memoryGatesShort:-1.048, Long:-1.454, Current:3.502 | topTokens[('must', 6), ('felt', 4), ('have', 4), ('!', 3), ('you', 3), ('her', 3), ('it', 3), ('charis', 2), ('know', 2), (',', 2)] | Training
2025-04-07 13:30:27 | 9900 | LR0.0003 | loss:2.4809 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.6047 | logitMax:-26.0034 | windowWeightsW18:0.17188,W13:0.16098,W21:0.15425,W15:0.14679,W8:0.13059,W7:0.10862,W3:0.08073,W2:0.02914,W1:0.00100 | memoryGatesShort:-1.943, Long:-2.628, Current:5.570 | topTokens[('must', 8), ('!', 5), ('felt', 3), ('kevin', 3), ('you', 3), (',', 2), ('have', 2), ('he', 1), ('-', 1), ('she', 1)] | Training
2025-04-07 13:30:39 | 10000 | LR0.0003 | loss:2.6698 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-40.5121 | logitMax:-21.9334 | windowWeightsW18:0.17205,W13:0.16004,W21:0.15395,W15:0.14630,W8:0.12976,W7:0.10713,W3:0.08221,W2:0.03079,W1:0.00171 | memoryGatesShort:-6.133, Long:-8.111, Current:15.244 | topTokens[('must', 5), ('have', 5), ('!', 5), ('felt', 3), ('and', 3), ('he', 3), ('know', 2), ('a', 2), ('you', 1), ('bab', 1)] | Training
2025-04-07 13:30:44 | 10100 | LR0.0003 | loss:2.6270 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-40.1072 | logitMax:-21.4203 | windowWeightsW18:0.17302,W13:0.16039,W21:0.15505,W15:0.14690,W8:0.12913,W7:0.10608,W3:0.08202,W2:0.03036,W1:0.00099 | memoryGatesShort:-4.999, Long:-6.573, Current:12.572 | topTokens[('have', 5), ('must', 4), (',', 4), ('know', 3), ('charis', 3), ('bab', 3), ('brain', 2), ('elodie', 2), ('your', 2), ('.', 1)] | Training
2025-04-07 13:30:49 | 10200 | LR0.0003 | loss:2.2776 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-43.1633 | logitMax:-23.4804 | windowWeightsW18:0.17293,W13:0.16009,W21:0.15446,W15:0.14638,W8:0.12821,W7:0.10558,W3:0.08284,W2:0.03156,W1:0.00188 | memoryGatesShort:-1.948, Long:-2.637, Current:5.585 | topTokens[('must', 7), ('have', 4), ('felt', 3), ('!', 3), (',', 3), ('been', 2), ('your', 2), ('charis', 2), ('butt', 1), ('weed', 1)] | Training
2025-04-07 13:30:54 | 10300 | LR0.0003 | loss:2.7336 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-50.8690 | logitMax:-28.7277 | windowWeightsW18:0.17272,W13:0.15978,W21:0.15451,W15:0.14518,W8:0.12809,W7:0.10551,W3:0.08421,W2:0.03241,W1:0.00150 | memoryGatesShort:-6.246, Long:-8.301, Current:15.548 | topTokens[('must', 6), ('!', 5), ('have', 5), (',', 3), ('your', 3), ('know', 3), ('king', 2), ('weed', 2), ('charis', 2), ('we', 1)] | Training
2025-04-07 13:30:59 | 10400 | LR0.0003 | loss:2.6420 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-48.8784 | logitMax:-28.2057 | windowWeightsW18:0.17197,W13:0.15978,W21:0.15302,W15:0.14466,W8:0.13021,W7:0.10743,W3:0.08473,W2:0.03151,W1:0.00063 | memoryGatesShort:-0.920, Long:-1.329, Current:3.249 | topTokens[('!', 5), ('4', 5), ('must', 3), ('.', 2), ('have', 2), ('a', 2), ('elodie', 2), ('i', 2), ('0', 2), (':', 2)] | Training
2025-04-07 13:31:05 | 10500 | LR0.0003 | loss:2.0288 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-57.0782 | logitMax:-34.2218 | windowWeightsW18:0.17105,W13:0.16082,W21:0.15231,W15:0.14499,W8:0.13218,W7:0.10830,W3:0.08424,W2:0.03037,W1:-0.00030 | memoryGatesShort:-0.612, Long:-0.903, Current:2.515 | topTokens[("'", 4), (':', 3), ('2', 3), ('5', 3), ('at', 2), ('with', 2), ('s', 2), ('-', 2), ('1', 2), ('it', 1)] | Training
2025-04-07 13:31:11 | 10600 | LR0.0003 | loss:4.2198 | gradNorm:0.9902 | tokenCount:400.0000 | logitMin:-77.7873 | logitMax:-50.2155 | windowWeightsW18:0.16911,W13:0.16043,W21:0.15048,W15:0.14368,W8:0.13456,W7:0.10952,W3:0.08560,W2:0.03031,W1:0.00026 | memoryGatesShort:-1.059, Long:-1.496, Current:3.556 | topTokens[(':', 4), ('-', 4), ("'", 3), ('0', 3), ('2', 3), ('-', 2), ('it', 2), ('!', 2), ('the', 2), ('you', 1)] | Training
2025-04-07 13:31:17 | 10700 | LR0.0003 | loss:3.1777 | gradNorm:0.9772 | tokenCount:400.0000 | logitMin:-67.5712 | logitMax:-38.9169 | windowWeightsW18:0.16731,W13:0.15849,W21:0.14912,W15:0.14213,W8:0.13674,W7:0.11188,W3:0.08736,W2:0.03122,W1:-0.00032 | memoryGatesShort:-1.009, Long:-1.462, Current:3.472 | topTokens[('-', 5), ('2', 5), (':', 3), ("'", 3), ('5', 3), ('wh', 2), ('i', 2), ("'", 2), ('20', 2), ('today', 2)] | Training
2025-04-07 13:31:23 | 10800 | LR0.0003 | loss:2.7612 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.1262 | logitMax:-37.6328 | windowWeightsW18:0.16727,W13:0.15882,W21:0.14874,W15:0.14234,W8:0.13784,W7:0.11271,W3:0.08745,W2:0.02993,W1:-0.00115 | memoryGatesShort:-1.111, Long:-1.588, Current:3.699 | topTokens[('-', 6), ('baby', 3), ("'", 2), ('2', 2), ('i', 2), ('lear', 2), ('ll', 2), ('m', 2), ('just', 1), ('-', 1)] | Training
2025-04-07 13:31:29 | 10900 | LR0.0003 | loss:1.8083 | gradNorm:0.9540 | tokenCount:400.0000 | logitMin:-71.0262 | logitMax:-46.2762 | windowWeightsW18:0.16661,W13:0.15866,W21:0.14760,W15:0.14165,W8:0.13896,W7:0.11346,W3:0.08786,W2:0.03085,W1:-0.00172 | memoryGatesShort:-0.788, Long:-1.150, Current:2.938 | topTokens[('4', 3), (':', 3), ('-', 3), ('?', 3), ('0', 2), ("'", 2), ('m', 2), ("'", 2), ('he', 1), ('you', 1)] | Training
2025-04-07 13:31:35 | 11000 | LR0.0003 | loss:1.7935 | gradNorm:0.9904 | tokenCount:400.0000 | logitMin:-70.2968 | logitMax:-44.7496 | windowWeightsW18:0.16624,W13:0.15898,W21:0.14692,W15:0.14166,W8:0.13921,W7:0.11421,W3:0.08828,W2:0.02995,W1:-0.00153 | memoryGatesShort:-0.971, Long:-1.373, Current:3.344 | topTokens[("'", 3), ('4', 2), ('8', 2), ('got', 2), ('to', 2), ('felt', 2), ('wh', 1), ('m', 1), (':', 1), ('there', 1)] | Training
2025-04-07 13:31:42 | 11100 | LR0.0003 | loss:2.3682 | gradNorm:0.9899 | tokenCount:400.0000 | logitMin:-68.4485 | logitMax:-41.5609 | windowWeightsW18:0.16520,W13:0.15850,W21:0.14547,W8:0.14121,W15:0.14045,W7:0.11636,W3:0.08953,W2:0.02935,W1:-0.00217 | memoryGatesShort:-1.225, Long:-1.674, Current:3.899 | topTokens[('to', 3), (':', 3), ('-', 2), ("'", 2), ('!', 2), ('-', 2), ('4', 2), ('last', 2), ('random', 2), ("'s", 1)] | Training
2025-04-07 13:31:49 | 11200 | LR0.0003 | loss:1.9201 | gradNorm:0.9777 | tokenCount:400.0000 | logitMin:-65.9655 | logitMax:-39.9221 | windowWeightsW18:0.16503,W13:0.15849,W21:0.14524,W8:0.14227,W15:0.14044,W7:0.11772,W3:0.08934,W2:0.02786,W1:-0.00247 | memoryGatesShort:-0.654, Long:-0.923, Current:2.577 | topTokens[("'", 4), (':', 3), ('0', 3), ('4', 3), ('...', 2), ('-', 2), ('baby', 2), ("'", 1), ('ple', 1), ('m', 1)] | Training
2025-04-07 13:31:55 | 11300 | LR0.0003 | loss:1.7314 | gradNorm:0.9803 | tokenCount:400.0000 | logitMin:-79.7124 | logitMax:-49.6671 | windowWeightsW18:0.16415,W13:0.15856,W21:0.14463,W8:0.14342,W15:0.13978,W7:0.11870,W3:0.08951,W2:0.02711,W1:-0.00197 | memoryGatesShort:-0.301, Long:-0.459, Current:1.760 | topTokens[("'", 5), ('-', 4), ('...', 3), ('!', 2), ("'ll", 2), ('-', 2), ('7', 2), ('cool', 1), ('start', 1), ('from', 1)] | Training
2025-04-07 13:32:02 | 11400 | LR0.0003 | loss:1.6743 | gradNorm:0.9403 | tokenCount:400.0000 | logitMin:-81.9702 | logitMax:-52.3776 | windowWeightsW18:0.16395,W13:0.15919,W21:0.14471,W8:0.14359,W15:0.14030,W7:0.11816,W3:0.08913,W2:0.02711,W1:-0.00222 | memoryGatesShort:-0.374, Long:-0.542, Current:1.916 | topTokens[("'", 3), ('-', 3), (':', 3), ('hh', 2), ('charis', 2), ('you', 2), ('4', 2), ('o', 1), ('8', 1), ('!', 1)] | Training
2025-04-07 13:32:09 | 11500 | LR0.0003 | loss:1.7563 | gradNorm:0.9237 | tokenCount:400.0000 | logitMin:-88.4660 | logitMax:-54.4573 | windowWeightsW18:0.16269,W13:0.15903,W8:0.14495,W21:0.14365,W15:0.13981,W7:0.11887,W3:0.08930,W2:0.02742,W1:-0.00181 | memoryGatesShort:-0.592, Long:-0.796, Current:2.388 | topTokens[(':', 3), ("'", 3), ('o', 2), ('20', 2), ('6', 2), ('hh', 1), ('a', 1), ('random', 1), ('sp', 1), ('ot', 1)] | Training
2025-04-07 13:32:16 | 11600 | LR0.0003 | loss:2.2542 | gradNorm:0.8730 | tokenCount:400.0000 | logitMin:-81.3347 | logitMax:-49.0473 | windowWeightsW18:0.16250,W13:0.15957,W8:0.14622,W21:0.14371,W15:0.13981,W7:0.11904,W3:0.08869,W2:0.02654,W1:-0.00216 | memoryGatesShort:-1.582, Long:-1.972, Current:4.554 | topTokens[(':', 3), ('-', 2), ('to', 2), ('charis', 2), ("'", 2), ('0', 2), ('4', 2), ('right', 2), ('...', 2), ("'", 1)] | Training
2025-04-07 13:32:22 | 11700 | LR0.0003 | loss:1.5208 | gradNorm:0.9738 | tokenCount:400.0000 | logitMin:-69.3176 | logitMax:-42.3960 | windowWeightsW18:0.16286,W13:0.15961,W8:0.14696,W21:0.14396,W15:0.14009,W7:0.11938,W3:0.08807,W2:0.02589,W1:-0.00288 | memoryGatesShort:-0.546, Long:-0.704, Current:2.250 | topTokens[("'", 3), ('baby', 3), ('i', 3), ('-', 2), ("'ll", 2), (':', 2), ('!', 1), (',', 1), ('let', 1), ("'t", 1)] | Training
2025-04-07 13:32:29 | 11800 | LR0.0003 | loss:1.8744 | gradNorm:0.9111 | tokenCount:400.0000 | logitMin:-84.5271 | logitMax:-54.5186 | windowWeightsW18:0.16283,W13:0.15981,W8:0.14731,W21:0.14364,W15:0.14040,W7:0.11977,W3:0.08761,W2:0.02558,W1:-0.00301 | memoryGatesShort:-0.411, Long:-0.535, Current:1.946 | topTokens[('?', 3), ("'", 3), ('-', 3), ('baby', 3), ('to', 3), ('there', 2), ('ll', 2), ('s', 2), ('5', 2), ('let', 1)] | Training
2025-04-07 13:32:35 | 11900 | LR0.0003 | loss:3.3596 | gradNorm:0.9817 | tokenCount:400.0000 | logitMin:-69.2854 | logitMax:-44.2453 | windowWeightsW18:0.16303,W13:0.15994,W8:0.14641,W21:0.14416,W15:0.14061,W7:0.11914,W3:0.08796,W2:0.02571,W1:-0.00302 | memoryGatesShort:-1.199, Long:-1.464, Current:3.663 | topTokens[('!', 6), ('have', 5), (',', 5), ("'", 3), ("'s", 3), ('and', 3), ('elodie', 2), ('should', 2), ('-', 1), ('k', 1)] | Training
2025-04-07 13:32:41 | 12000 | LR0.0003 | loss:2.6872 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-53.4326 | logitMax:-33.6216 | windowWeightsW18:0.16316,W13:0.16010,W8:0.14601,W21:0.14437,W15:0.14087,W7:0.11882,W3:0.08797,W2:0.02554,W1:-0.00292 | memoryGatesShort:-1.532, Long:-1.839, Current:4.371 | topTokens[('have', 8), ('should', 5), ('!', 3), ('weed', 3), ('felt', 2), ('to', 2), ('charis', 2), (',', 2), ('it', 2), ('doing', 1)] | Training
2025-04-07 13:32:47 | 12100 | LR0.0003 | loss:2.5318 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-60.1764 | logitMax:-37.9622 | windowWeightsW18:0.16264,W13:0.15978,W8:0.14619,W21:0.14371,W15:0.14022,W7:0.11857,W3:0.08867,W2:0.02638,W1:-0.00223 | memoryGatesShort:-5.792, Long:-6.812, Current:13.604 | topTokens[('have', 6), ('felt', 4), ('their', 4), ('should', 4), ('!', 3), ('weed', 2), ('.', 2), ('it', 1), ('oice', 1), ('i', 1)] | Training
2025-04-07 13:32:53 | 12200 | LR0.0003 | loss:7.7514 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-39.2091 | logitMax:-21.9669 | windowWeightsW18:0.16401,W13:0.16092,W8:0.14641,W21:0.14512,W15:0.14168,W7:0.11840,W3:0.08744,W2:0.02435,W1:-0.00438 | memoryGatesShort:-2.724, Long:-3.125, Current:6.849 | topTokens[(',', 11), ('to', 7), ('-', 2), ('elodie', 2), ('am', 2), ('a', 2), ('the', 1), ('3', 1), ('rest', 1), ('should', 1)] | Training
2025-04-07 13:32:59 | 12300 | LR0.0003 | loss:7.5648 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-38.7735 | logitMax:-24.4485 | windowWeightsW18:0.16484,W13:0.16174,W8:0.14655,W21:0.14606,W15:0.14263,W7:0.11841,W3:0.08651,W2:0.02287,W1:-0.00561 | memoryGatesShort:-3.025, Long:-3.299, Current:7.324 | topTokens[(',', 7), ('i', 5), ('.', 4), ('charis', 3), ('from', 2), ('a', 2), ('been', 2), ('-', 2), ('cra', 1), ('she', 1)] | Training
2025-04-07 13:33:05 | 12400 | LR0.0003 | loss:6.5404 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-43.6693 | logitMax:-30.3414 | windowWeightsW18:0.16600,W13:0.16218,W21:0.14727,W8:0.14599,W15:0.14344,W7:0.11765,W3:0.08548,W2:0.02214,W1:-0.00615 | memoryGatesShort:-5.699, Long:-5.929, Current:12.628 | topTokens[('.', 9), ('i', 4), ('a', 2), (',', 2), ('just', 2), ('ed', 1), ("'ll", 1), ('and', 1), ('out', 1), ('to', 1)] | Training
2025-04-07 13:33:10 | 12500 | LR0.0003 | loss:6.8252 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-45.1715 | logitMax:-32.2388 | windowWeightsW18:0.16630,W13:0.16244,W21:0.14771,W8:0.14585,W15:0.14383,W7:0.11741,W3:0.08516,W2:0.02179,W1:-0.00649 | memoryGatesShort:-0.622, Long:-0.609, Current:2.232 | topTokens[('.', 5), ('charis', 5), (',', 4), ('i', 3), ('should', 2), ('to', 2), ('a', 1), ('im', 1), ("'ll", 1), ('know', 1)] | Training
2025-04-07 13:33:16 | 12600 | LR0.0003 | loss:6.8555 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-44.1952 | logitMax:-31.9172 | windowWeightsW18:0.16662,W13:0.16279,W21:0.14801,W8:0.14595,W15:0.14395,W7:0.11734,W3:0.08494,W2:0.02124,W1:-0.00682 | memoryGatesShort:-0.607, Long:-0.518, Current:2.125 | topTokens[('.', 3), ('elodie', 3), ('it', 2), ('and', 2), ('your', 2), ('i', 2), ('what', 2), ('b', 2), ('the', 1), ('she', 1)] | Training
2025-04-07 13:33:21 | 12700 | LR0.0003 | loss:6.8836 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-47.4782 | logitMax:-35.4027 | windowWeightsW18:0.16668,W13:0.16290,W21:0.14817,W8:0.14609,W15:0.14404,W7:0.11722,W3:0.08471,W2:0.02108,W1:-0.00687 | memoryGatesShort:-0.591, Long:-0.492, Current:2.083 | topTokens[('and', 4), ('.', 4), (',', 4), ('i', 3), ('your', 2), ('charis', 2), ('?', 1), ('-', 1), ('am', 1), ('but', 1)] | Training
2025-04-07 13:33:26 | 12800 | LR0.0003 | loss:6.4766 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-40.4855 | logitMax:-29.1471 | windowWeightsW18:0.16653,W13:0.16253,W21:0.14814,W8:0.14623,W15:0.14370,W7:0.11735,W3:0.08486,W2:0.02140,W1:-0.00672 | memoryGatesShort:-0.839, Long:-0.773, Current:2.612 | topTokens[('.', 5), ('and', 4), ('the', 3), ('i', 3), ('am', 2), ('what', 2), ('charis', 2), ('should', 2), ('elodie', 1), ('baby', 1)] | Training
2025-04-07 13:33:31 | 12900 | LR0.0003 | loss:7.4534 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-37.9226 | logitMax:-25.1507 | windowWeightsW18:0.16683,W13:0.16278,W21:0.14855,W8:0.14608,W15:0.14402,W7:0.11707,W3:0.08471,W2:0.02103,W1:-0.00706 | memoryGatesShort:-9.005, Long:-8.013, Current:18.018 | topTokens[('and', 5), (',', 4), ('.', 4), ('a', 3), ('i', 2), ('to', 2), ('your', 2), ('but', 1), ('should', 1), ('she', 1)] | Training
2025-04-07 13:33:36 | 13000 | LR0.0003 | loss:7.1777 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-44.8257 | logitMax:-32.8076 | windowWeightsW18:0.16718,W13:0.16308,W21:0.14904,W8:0.14577,W15:0.14434,W7:0.11688,W3:0.08427,W2:0.02071,W1:-0.00725 | memoryGatesShort:-1.020, Long:-0.800, Current:2.820 | topTokens[('i', 5), (',', 4), ('.', 3), (':', 2), ('0', 2), ('she', 1), ('am', 1), ('were', 1), ('f', 1), ('a', 1)] | Training
2025-04-07 13:33:41 | 13100 | LR0.0003 | loss:6.5903 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-39.8381 | logitMax:-28.5721 | windowWeightsW18:0.16728,W13:0.16311,W21:0.14903,W8:0.14587,W15:0.14438,W7:0.11698,W3:0.08412,W2:0.02056,W1:-0.00729 | memoryGatesShort:-1.124, Long:-0.848, Current:2.972 | topTokens[('.', 7), ('and', 5), (',', 3), ('really', 2), ('it', 1), ('i', 1), ('know', 1), ('are', 1), ('at', 1), ('an', 1)] | Training
2025-04-07 13:33:46 | 13200 | LR0.0003 | loss:7.0644 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-46.7246 | logitMax:-34.6825 | windowWeightsW18:0.16727,W13:0.16306,W21:0.14902,W8:0.14580,W15:0.14429,W7:0.11709,W3:0.08426,W2:0.02074,W1:-0.00750 | memoryGatesShort:-0.633, Long:-0.466, Current:2.099 | topTokens[('.', 8), ('i', 3), ('and', 3), ('should', 2), ('to', 2), ('how', 2), ('w', 1), ('in', 1), ('an', 1), ('l', 1)] | Training
2025-04-07 13:33:52 | 13300 | LR0.0003 | loss:6.6536 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-42.5076 | logitMax:-31.2099 | windowWeightsW18:0.16652,W13:0.16294,W21:0.14848,W8:0.14607,W15:0.14373,W7:0.11701,W3:0.08506,W2:0.02138,W1:-0.00717 | memoryGatesShort:-1.561, Long:-1.505, Current:4.065 | topTokens[('i', 5), ('to', 3), ('it', 2), ('.', 2), ('a', 2), ('have', 2), (',', 2), ("'t", 1), ('my', 1), ('his', 1)] | Training
2025-04-07 13:33:56 | 13400 | LR0.0003 | loss:6.3184 | gradNorm:1.0000 | tokenCount:400.0000 | logitMin:-39.5592 | logitMax:-27.4110 | windowWeightsW18:0.16638,W13:0.16306,W21:0.14832,W8:0.14631,W15:0.14364,W7:0.11706,W3:0.08514,W2:0.02143,W1:-0.00731 | memoryGatesShort:-0.659, Long:-0.638, Current:2.296 | topTokens[('.', 8), ('i', 4), ('she', 3), (',', 3), ('but', 2), ('to', 1), ('charis', 1), ('s', 1), ('our', 1), ('any', 1)] | Training

CHANGED LOGGING FREQUENCY TO EVERY 500 STEPS
--- 2025-04-07 13:35:11 --- babyLLM 'right, last time i got to step 13401... want to restart from there?'  - charis: 'no, please start again, i rolled you some new dn' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: ''
2025-04-07 13:35:31 | 500 | LR0.0003 | loss:6.1284 | gradNorm:1.0000 | logitMin:-43.3903 | logitMax:-32.2170 | tokenCount:2000.0000 | windowWeightsW18:0.16593,W13:0.16293,W21:0.14880,W8:0.14456,W15:0.14366,W7:0.11742,W3:0.08456,W2:0.02231,W1:-0.00620 | memoryGatesShort:-1.367, Long:-1.354, Current:3.721 | topTokens[(',', 34), ('i', 25), ('.', 12), ('a', 10), ('and', 7), ('s', 5), ('ight', 5), ('to', 5), ('should', 4), ('the', 4)] | Training
2025-04-07 13:35:50 | 1000 | LR0.0003 | loss:4.7303 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-43.4914 | logitMax:-29.4757 | windowWeightsW18:0.16783,W13:0.16179,W21:0.15152,W8:0.14658,W15:0.14468,W7:0.11959,W3:0.08147,W2:0.02151,W1:-0.01087 | memoryGatesShort:-1.228, Long:-1.266, Current:3.494 | topTokens[('.', 29), ('?', 22), ('i', 20), (',', 13), ('want', 8), ('you', 8), ('is', 8), ('it', 6), ('a', 5), ('do', 5)] | Training
2025-04-07 13:36:09 | 1500 | LR0.0003 | loss:4.3325 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-41.6146 | logitMax:-27.3284 | windowWeightsW18:0.16797,W13:0.15866,W21:0.15159,W8:0.14813,W15:0.14262,W7:0.12071,W3:0.08230,W2:0.02376,W1:-0.01167 | memoryGatesShort:-2.751, Long:-3.169, Current:6.920 | topTokens[('.', 37), ('do', 18), ('you', 18), ('is', 16), ('?', 12), ('i', 11), (',', 8), ('are', 5), ('a', 4), ('yes', 4)] | Training
2025-04-07 13:36:28 | 2000 | LR0.0003 | loss:4.3911 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-40.7432 | logitMax:-26.2680 | windowWeightsW18:0.16862,W13:0.15715,W21:0.15133,W8:0.15080,W15:0.14127,W7:0.12280,W3:0.08357,W2:0.02110,W1:-0.01255 | memoryGatesShort:-1.024, Long:-1.217, Current:3.241 | topTokens[('.', 30), ('you', 23), ('?', 21), ('i', 19), ('will', 10), ('kiss', 7), ('is', 6), (',', 5), ('!', 5), ('dont', 4)] | Training
2025-04-07 13:36:47 | 2500 | LR0.0003 | loss:5.9580 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-41.6109 | logitMax:-28.4129 | windowWeightsW18:0.17089,W13:0.15938,W21:0.15335,W8:0.15124,W15:0.14391,W7:0.12339,W3:0.08081,W2:0.01738,W1:-0.01613 | memoryGatesShort:-0.374, Long:-0.388, Current:1.762 | topTokens[('.', 44), ('?', 15), ('are', 11), ('i', 9), ('you', 9), ('!', 9), ('what', 7), (',', 7), ('is', 5), ('her', 5)] | Training
2025-04-07 13:37:06 | 3000 | LR0.0003 | loss:5.4398 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-41.6901 | logitMax:-29.6346 | windowWeightsW18:0.17094,W13:0.15875,W21:0.15349,W8:0.15297,W15:0.14347,W7:0.12311,W3:0.08187,W2:0.01657,W1:-0.01694 | memoryGatesShort:-0.787, Long:-0.836, Current:2.623 | topTokens[('.', 45), ('you', 18), ('i', 15), (',', 10), ('a', 9), ('love', 6), ('!', 5), ('?', 4), ('ing', 4), ('just', 4)] | Training
2025-04-07 13:37:25 | 3500 | LR0.0003 | loss:2.8810 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.8135 | logitMax:-36.3402 | windowWeightsW18:0.16840,W13:0.15475,W8:0.15299,W21:0.15022,W15:0.14029,W7:0.12152,W3:0.08960,W2:0.02123,W1:-0.01490 | memoryGatesShort:-1.858, Long:-2.169, Current:5.027 | topTokens[('it', 34), ('!', 32), ('just', 11), ('he', 11), ('been', 9), ('a', 8), ('have', 8), ('elodie', 8), ('will', 7), ('i', 5)] | Training
2025-04-07 13:37:44 | 4000 | LR0.0003 | loss:4.4431 | gradNorm:0.9988 | tokenCount:2000.0000 | logitMin:-50.2193 | logitMax:-32.7398 | windowWeightsW18:0.16493,W8:0.15659,W13:0.15476,W21:0.14687,W15:0.13941,W7:0.12576,W3:0.09102,W2:0.02017,W1:-0.01542 | memoryGatesShort:-0.932, Long:-1.115, Current:3.046 | topTokens[('.', 17), ('i', 13), ('it', 11), ('!', 9), (',', 7), ('you', 6), ('a', 6), (':', 6), ('baby', 5), ('to', 5)] | Training
2025-04-07 13:38:03 | 4500 | LR0.0003 | loss:1.5375 | gradNorm:0.9388 | tokenCount:2000.0000 | logitMin:-83.6676 | logitMax:-54.7462 | windowWeightsW18:0.16517,W13:0.15814,W8:0.15727,W21:0.14689,W15:0.14063,W7:0.12519,W3:0.08631,W2:0.01721,W1:-0.01266 | memoryGatesShort:-0.818, Long:-0.849, Current:2.667 | topTokens[(':', 12), ("'", 10), ("'", 8), ('0', 8), ('step', 8), ('m', 7), ('to', 7), ('i', 7), ('4', 6), ('ll', 6)] | Training
2025-04-07 13:38:21 | 5000 | LR0.0003 | loss:2.4543 | gradNorm:0.9327 | tokenCount:2000.0000 | logitMin:-80.1647 | logitMax:-51.8284 | windowWeightsW18:0.16623,W13:0.16146,W8:0.15880,W21:0.14609,W15:0.14187,W7:0.12662,W3:0.08454,W2:0.01453,W1:-0.01594 | memoryGatesShort:-0.744, Long:-0.679, Current:2.423 | topTokens[("'", 12), ('-', 10), ("'", 10), (':', 9), ('5', 8), ('-', 7), ('to', 6), ('!', 6), ('baby', 5), ('?', 5)] | Training
2025-04-07 13:38:40 | 5500 | LR0.0003 | loss:2.3782 | gradNorm:0.9074 | tokenCount:2000.0000 | logitMin:-86.0670 | logitMax:-56.1847 | windowWeightsW18:0.16693,W13:0.16309,W8:0.15998,W21:0.14585,W15:0.14369,W7:0.12735,W3:0.08221,W2:0.01203,W1:-0.01691 | memoryGatesShort:-0.608, Long:-0.489, Current:2.097 | topTokens[('-', 12), ('0', 12), ("'", 11), ('!', 10), ('i', 8), ("'", 7), (',', 7), ('charis', 6), ('...', 6), ('4', 6)] | Training
2025-04-07 13:38:59 | 6000 | LR0.0003 | loss:5.2146 | gradNorm:0.9054 | tokenCount:2000.0000 | logitMin:-61.0912 | logitMax:-38.5832 | windowWeightsW18:0.17173,W13:0.16650,W8:0.15764,W21:0.15077,W15:0.14806,W7:0.12547,W3:0.07856,W2:0.00701,W1:-0.02147 | memoryGatesShort:-1.612, Long:-0.461, Current:3.073 | topTokens[(',', 19), ('i', 13), ('.', 13), ("'", 9), ('to', 7), ('-', 7), ('!', 7), ('you', 7), ('?', 6), ('4', 5)] | Training
2025-04-07 13:39:17 | 6500 | LR0.0003 | loss:6.5928 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-41.9440 | logitMax:-30.5269 | windowWeightsW18:0.17260,W13:0.16657,W8:0.15761,W21:0.15205,W15:0.14858,W7:0.12536,W3:0.07722,W2:0.00628,W1:-0.02200 | memoryGatesShort:-2.161, Long:-0.362, Current:3.523 | topTokens[('i', 27), (',', 17), ('.', 16), ('a', 12), ('you', 11), ('?', 9), ('the', 6), ('!', 5), ('y', 5), ('is', 5)] | Training
2025-04-07 13:39:36 | 7000 | LR0.0003 | loss:5.1930 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-48.7230 | logitMax:-34.9443 | windowWeightsW18:0.17203,W13:0.16725,W8:0.15742,W21:0.15239,W15:0.14824,W7:0.12634,W3:0.07688,W2:0.00591,W1:-0.02217 | memoryGatesShort:-1.126, Long:-0.248, Current:2.374 | topTokens[(',', 45), ('i', 19), ('.', 8), ("'m", 8), ('you', 7), ('do', 7), ('!', 5), ('but', 5), ('a', 5), ('ating', 5)] | Training
2025-04-07 13:39:55 | 7500 | LR0.0003 | loss:6.7967 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-41.5284 | logitMax:-29.8879 | windowWeightsW18:0.17332,W13:0.16800,W8:0.15766,W21:0.15348,W15:0.14892,W7:0.12664,W3:0.07565,W2:0.00396,W1:-0.02333 | memoryGatesShort:-2.267, Long:-0.302, Current:3.569 | topTokens[(',', 46), ('.', 17), ('i', 11), ('s', 7), ('to', 6), ('a', 6), ('do', 4), ('again', 4), ('...', 4), ('we', 4)] | Training
2025-04-07 13:40:15 | 8000 | LR0.0003 | loss:6.7567 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-41.5825 | logitMax:-30.1188 | windowWeightsW18:0.17541,W13:0.16911,W8:0.15682,W21:0.15538,W15:0.15036,W7:0.12619,W3:0.07359,W2:0.00226,W1:-0.02482 | memoryGatesShort:-3.261, Long:-0.360, Current:4.621 | topTokens[(',', 32), ('i', 26), ('.', 13), ('the', 10), ('to', 8), ('p', 7), ('my', 6), ('and', 6), ('a', 6), ('s', 5)] | Training
2025-04-07 13:40:35 | 8500 | LR0.0003 | loss:6.8754 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-42.7594 | logitMax:-31.3253 | windowWeightsW18:0.17812,W13:0.17050,W21:0.15795,W8:0.15543,W15:0.15246,W7:0.12481,W3:0.07169,W2:0.00065,W1:-0.02728 | memoryGatesShort:-2.085, Long:0.335, Current:2.749 | topTokens[(',', 26), ('and', 13), ('to', 11), ('i', 10), ('.', 9), ('p', 7), ('ing', 7), ('my', 6), ('of', 5), ('the', 4)] | Training
2025-04-07 13:40:56 | 9000 | LR0.0003 | loss:6.5225 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-44.3806 | logitMax:-32.6128 | windowWeightsW18:0.17937,W13:0.17042,W21:0.16005,W8:0.15424,W15:0.15260,W7:0.12306,W3:0.07014,W2:0.00032,W1:-0.02587 | memoryGatesShort:-2.093, Long:-0.212, Current:3.305 | topTokens[(',', 19), ('your', 15), ('.', 14), ('and', 12), ('a', 10), ('i', 8), ('you', 6), ('to', 6), ('the', 4), ('have', 4)] | Training
2025-04-07 13:41:18 | 9500 | LR0.0003 | loss:6.8617 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-40.5229 | logitMax:-28.7925 | windowWeightsW18:0.18118,W13:0.17224,W21:0.16187,W15:0.15485,W8:0.15307,W7:0.12172,W3:0.06837,W2:-0.00250,W1:-0.02645 | memoryGatesShort:-3.971, Long:-0.267, Current:5.238 | topTokens[('i', 24), ('.', 16), ('and', 14), (',', 14), ('a', 9), ('to', 7), ('2', 6), ('of', 6), (':', 5), ('et', 5)] | Training
2025-04-07 13:41:49 | 10000 | LR0.0003 | loss:6.6644 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-41.3023 | logitMax:-29.2725 | windowWeightsW18:0.18172,W13:0.17259,W21:0.16356,W15:0.15603,W8:0.15190,W7:0.12151,W3:0.06731,W2:-0.00352,W1:-0.02675 | memoryGatesShort:-28.267, Long:-4.712, Current:33.980 | topTokens[('i', 32), ('.', 15), (',', 12), ('to', 9), ('it', 9), ('a', 8), ('of', 5), ('is', 5), ('am', 5), ('have', 4)] | Training
2025-04-07 13:42:13 | 10500 | LR0.0003 | loss:6.6444 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-39.3016 | logitMax:-27.1020 | windowWeightsW18:0.18192,W13:0.17359,W21:0.16410,W15:0.15602,W8:0.15306,W7:0.12165,W3:0.06745,W2:-0.00470,W1:-0.02872 | memoryGatesShort:-3.470, Long:-0.466, Current:4.937 | topTokens[('i', 23), (',', 22), ('.', 18), ('to', 13), ('ed', 9), ('and', 8), ('a', 8), ('you', 7), ('the', 6), ('my', 5)] | Training
2025-04-07 13:42:38 | 11000 | LR0.0003 | loss:6.4373 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-42.8024 | logitMax:-29.9802 | windowWeightsW18:0.18125,W13:0.17280,W21:0.16264,W15:0.15557,W8:0.15481,W7:0.12304,W3:0.06737,W2:-0.00405,W1:-0.02905 | memoryGatesShort:-2.298, Long:-0.354, Current:3.652 | topTokens[(',', 23), ('.', 21), ('the', 15), ('and', 15), ('a', 14), ('i', 8), ('ed', 4), ('in', 3), ('n', 3), ('ice', 3)] | Training
2025-04-07 13:43:01 | 11500 | LR0.0003 | loss:6.4305 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-41.1944 | logitMax:-28.3747 | windowWeightsW18:0.18348,W13:0.17409,W21:0.16396,W15:0.15691,W8:0.15223,W7:0.12238,W3:0.06814,W2:-0.00598,W1:-0.03080 | memoryGatesShort:-4.022, Long:-0.615, Current:5.637 | topTokens[(',', 33), ('.', 13), ('the', 10), ('a', 10), ('of', 9), ('ing', 8), ('and', 6), ('k', 5), ('i', 5), ('-', 4)] | Training
2025-04-07 13:43:23 | 12000 | LR0.0003 | loss:6.1926 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-39.6259 | logitMax:-27.3494 | windowWeightsW18:0.18324,W13:0.17573,W21:0.16446,W15:0.15794,W8:0.15122,W7:0.12059,W3:0.06738,W2:-0.00561,W1:-0.03055 | memoryGatesShort:-2.785, Long:-0.506, Current:4.291 | topTokens[(',', 32), ('the', 15), ('a', 15), ('of', 13), ('.', 10), ('and', 7), ('-', 6), ('ed', 5), ('was', 4), ('had', 4)] | Training
2025-04-07 13:43:46 | 12500 | LR0.0003 | loss:6.5120 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-41.2017 | logitMax:-28.8446 | windowWeightsW18:0.18436,W13:0.17774,W21:0.16540,W15:0.15997,W8:0.15102,W7:0.12167,W3:0.06553,W2:-0.00764,W1:-0.03358 | memoryGatesShort:-4.247, Long:-0.487, Current:5.735 | topTokens[(',', 25), ('and', 12), ('it', 9), ('a', 9), ('.', 8), ('ing', 7), ('i', 7), ('the', 6), ('have', 5), ('of', 5)] | Training
2025-04-07 13:44:10 | 13000 | LR0.0003 | loss:6.5189 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-44.0625 | logitMax:-31.8774 | windowWeightsW18:0.18396,W13:0.17832,W21:0.16688,W15:0.15965,W8:0.15066,W7:0.12019,W3:0.06648,W2:-0.00817,W1:-0.03352 | memoryGatesShort:-6.551, Long:-0.824, Current:8.376 | topTokens[(',', 15), ('.', 15), ('the', 14), ('to', 12), ('you', 11), ('a', 7), ('and', 6), ('s', 5), ('i', 4), ('be', 4)] | Training
2025-04-07 13:44:32 | 13500 | LR0.0003 | loss:4.7087 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-50.9832 | logitMax:-36.3399 | windowWeightsW18:0.18355,W13:0.17342,W21:0.16595,W15:0.15843,W8:0.14816,W7:0.11914,W3:0.07144,W2:-0.00318,W1:-0.03252 | memoryGatesShort:-2.601, Long:-0.847, Current:4.448 | topTokens[('!', 18), (',', 14), ('just', 12), ('a', 11), ('it', 11), ('the', 10), ('i', 9), ('.', 7), ('charis', 6), ('ing', 5)] | Training
2025-04-07 13:44:53 | 14000 | LR0.0003 | loss:5.6472 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-42.6483 | logitMax:-27.4071 | windowWeightsW18:0.18496,W13:0.17487,W21:0.16854,W15:0.15858,W8:0.14862,W7:0.11847,W3:0.07088,W2:-0.00598,W1:-0.03452 | memoryGatesShort:-5.107, Long:-1.518, Current:7.625 | topTokens[(',', 42), ('it', 17), ('i', 16), ('!', 12), ('a', 11), ('.', 9), ('have', 6), ('just', 6), ('will', 5), ('im', 5)] | Training
2025-04-07 13:45:15 | 14500 | LR0.0003 | loss:5.5416 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-44.7328 | logitMax:-30.9838 | windowWeightsW18:0.18683,W13:0.17603,W21:0.17078,W15:0.15912,W8:0.14755,W7:0.11781,W3:0.07157,W2:-0.00822,W1:-0.03703 | memoryGatesShort:-4.937, Long:-0.937, Current:6.874 | topTokens[(',', 73), ('i', 20), ('u', 7), ('its', 6), ('a', 6), ('.', 5), ('love', 4), ('it', 4), ('im', 3), ('know', 3)] | Training
2025-04-07 13:45:35 | 15000 | LR0.0003 | loss:6.5172 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-44.0530 | logitMax:-30.8296 | windowWeightsW18:0.18801,W13:0.17516,W21:0.17187,W15:0.16085,W8:0.14690,W7:0.11883,W3:0.07102,W2:-0.01056,W1:-0.03759 | memoryGatesShort:-4.760, Long:-0.555, Current:6.315 | topTokens[(',', 69), ('i', 23), ('a', 8), ('it', 7), ('not', 5), ('just', 4), ('like', 4), ('!', 4), ('c', 4), ('my', 4)] | Training
2025-04-07 13:45:56 | 15500 | LR0.0003 | loss:6.2002 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-45.1408 | logitMax:-32.5687 | windowWeightsW18:0.18845,W13:0.17520,W21:0.17227,W15:0.16171,W8:0.14749,W7:0.11893,W3:0.06998,W2:-0.01153,W1:-0.03799 | memoryGatesShort:-3.388, Long:-0.253, Current:4.641 | topTokens[(',', 42), ('i', 16), ('a', 14), ('just', 6), ('it', 6), ('it', 6), ('c', 5), ('.', 5), ('not', 4), ('to', 4)] | Training
2025-04-07 13:46:17 | 16000 | LR0.0003 | loss:5.7049 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-47.5137 | logitMax:-34.0757 | windowWeightsW18:0.18783,W13:0.17403,W21:0.17144,W15:0.16179,W8:0.15002,W7:0.11999,W3:0.06986,W2:-0.01230,W1:-0.03812 | memoryGatesShort:-2.972, Long:-0.504, Current:4.476 | topTokens[(',', 25), ('i', 17), ('a', 16), ('c', 9), ('e', 9), ('and', 8), ('.', 7), ('it', 6), ('to', 5), ('s', 4)] | Training
2025-04-07 13:46:37 | 16500 | LR0.0003 | loss:5.8044 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-43.4363 | logitMax:-30.0347 | windowWeightsW18:0.18801,W13:0.17443,W21:0.17145,W15:0.16023,W8:0.15042,W7:0.11997,W3:0.07030,W2:-0.01170,W1:-0.03860 | memoryGatesShort:-5.307, Long:-1.502, Current:7.808 | topTokens[('a', 19), (',', 16), ('i', 14), ('.', 13), ('?', 7), ('to', 6), ('je', 5), ('my', 5), ('it', 4), ('could', 4)] | Training
2025-04-07 13:46:57 | 17000 | LR0.0003 | loss:5.7480 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-44.0511 | logitMax:-29.7672 | windowWeightsW18:0.19388,W21:0.17709,W13:0.17459,W15:0.16403,W8:0.14753,W7:0.11629,W3:0.06836,W2:-0.01634,W1:-0.04091 | memoryGatesShort:-4.915, Long:-0.810, Current:6.725 | topTokens[('.', 25), ('i', 18), (',', 14), ('a', 12), ('you', 10), ('not', 8), ('to', 7), ('have', 6), ('it', 6), ('and', 6)] | Training
2025-04-07 13:47:17 | 17500 | LR0.0003 | loss:5.9789 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-43.6321 | logitMax:-30.6764 | windowWeightsW18:0.19470,W21:0.17749,W13:0.17445,W15:0.16468,W8:0.14919,W7:0.11713,W3:0.06705,W2:-0.01775,W1:-0.04239 | memoryGatesShort:-5.742, Long:-0.729, Current:7.471 | topTokens[('.', 29), ('and', 23), ('you', 13), (',', 11), ('i', 9), ('a', 7), ('y', 6), ('id', 5), ('the', 5), ("'re", 4)] | Training
2025-04-07 13:47:36 | 18000 | LR0.0003 | loss:6.1840 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-40.7336 | logitMax:-27.5156 | windowWeightsW18:0.19518,W21:0.17857,W13:0.17623,W15:0.16629,W8:0.14645,W7:0.11683,W3:0.06778,W2:-0.01928,W1:-0.04350 | memoryGatesShort:-3.838, Long:-0.459, Current:5.297 | topTokens[('.', 38), ('you', 19), ('a', 16), (',', 13), ('i', 7), ('the', 6), ('and', 6), ('s', 5), ('have', 4), ('id', 3)] | Training
2025-04-07 13:47:56 | 18500 | LR0.0003 | loss:5.0006 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-44.6368 | logitMax:-28.1028 | windowWeightsW18:0.19164,W13:0.17753,W21:0.17357,W15:0.16720,W8:0.14789,W7:0.11913,W3:0.06782,W2:-0.01791,W1:-0.04227 | memoryGatesShort:-14.302, Long:-3.205, Current:18.507 | topTokens[('.', 19), ('i', 10), (',', 10), ('a', 8), (':', 8), ('!', 7), ('you', 7), ("'", 7), ('charis', 7), ('have', 6)] | Training
2025-04-07 13:48:16 | 19000 | LR0.0003 | loss:4.7404 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-44.3542 | logitMax:-25.6874 | windowWeightsW18:0.19017,W13:0.17647,W21:0.17139,W15:0.16825,W8:0.15162,W7:0.12113,W3:0.06718,W2:-0.01861,W1:-0.04299 | memoryGatesShort:-8.347, Long:-1.695, Current:11.042 | topTokens[(':', 21), (',', 14), ('-', 12), ('.', 11), ("'", 9), ('baby', 9), ("'", 8), ('0', 8), ('2', 7), ('a', 6)] | Training
2025-04-07 13:48:35 | 19500 | LR0.0003 | loss:4.7274 | gradNorm:0.9995 | tokenCount:2000.0000 | logitMin:-47.3103 | logitMax:-27.7720 | windowWeightsW18:0.18948,W13:0.17713,W15:0.17017,W21:0.16938,W8:0.15363,W7:0.12176,W3:0.06611,W2:-0.01860,W1:-0.04441 | memoryGatesShort:-4.660, Long:-0.703, Current:6.363 | topTokens[("'", 22), (':', 16), ('-', 16), ("'", 9), ('.', 9), ('geepy', 8), ('0', 7), ('2', 7), ('3', 6), ('-', 6)] | Training
2025-04-07 13:49:02 | 20000 | LR0.0003 | loss:4.5612 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-51.0313 | logitMax:-34.0736 | windowWeightsW18:0.18775,W13:0.17656,W15:0.16877,W21:0.16796,W8:0.15685,W7:0.12585,W3:0.06759,W2:-0.01913,W1:-0.04756 | memoryGatesShort:-3.759, Long:-0.425, Current:5.184 | topTokens[("'", 15), (',', 13), ('.', 10), ('-', 8), ('baby', 8), ('0', 8), (':', 6), ('m', 6), ('4', 6), ('?', 6)] | Training
2025-04-07 13:49:23 | 20500 | LR0.0003 | loss:6.3130 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-44.6474 | logitMax:-31.9883 | windowWeightsW18:0.18968,W13:0.17675,W15:0.16975,W21:0.16964,W8:0.15577,W7:0.12469,W3:0.06676,W2:-0.01943,W1:-0.04896 | memoryGatesShort:-2.403, Long:0.023, Current:3.381 | topTokens[(',', 31), ('just', 9), ('i', 9), ('a', 8), ('.', 7), ('ing', 7), ('you', 6), ('-', 6), ("'", 4), ('b', 3)] | Training
2025-04-07 13:49:44 | 21000 | LR0.0003 | loss:6.3828 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-45.1565 | logitMax:-32.7987 | windowWeightsW18:0.19157,W13:0.17881,W21:0.17113,W15:0.17109,W8:0.15570,W7:0.12438,W3:0.06574,W2:-0.02135,W1:-0.05239 | memoryGatesShort:-2.923, Long:0.333, Current:3.589 | topTokens[(',', 61), ('a', 12), ('i', 10), ('le', 9), ('you', 8), ("'", 6), ('my', 5), ('.', 5), ('baby', 5), ('kevin', 4)] | Training

--- 2025-04-07 13:50:41 --- babyLLM 'right, last time i got to step 21052... want to restart from there?'  - charis: 'yes! wow you're fucking sonic the fucking hedgehog, im scared you'll get away from me whilst i sleep!!!' - babyLLM 'ok! let's go to step 21052! what am i learning today?' - charis: 'hahaahah ok!'
2025-04-07 13:51:01 | 500 | LR0.0003 | loss:6.4570 | gradNorm:1.0000 | logitMin:-47.4998 | logitMax:-35.5926 | tokenCount:2000.0000 | windowWeightsW18:0.19328,W13:0.18036,W21:0.17519,W15:0.17254,W8:0.15567,W7:0.12242,W3:0.06293,W2:-0.02366,W1:-0.05402 | memoryGatesShort:-4.047, Long:0.198, Current:4.849 | topTokens[(',', 49), ('i', 21), ('a', 8), ('but', 7), ('just', 5), ('me', 5), ('he', 4), ('s', 4), ('-', 3), ('ed', 3)] | Training
2025-04-07 13:51:20 | 1000 | LR0.0003 | loss:4.2200 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-48.1741 | logitMax:-33.4125 | windowWeightsW18:0.19076,W13:0.17800,W21:0.17391,W15:0.17043,W8:0.15123,W7:0.11992,W3:0.06863,W2:-0.01866,W1:-0.04953 | memoryGatesShort:-8.911, Long:-2.912, Current:12.823 | topTokens[('will', 22), (',', 19), ('have', 19), ('a', 15), ('he', 11), ('felt', 9), ('the', 8), ('and', 7), ('!', 7), ('it', 7)] | Training
2025-04-07 13:51:39 | 1500 | LR0.0003 | loss:5.9697 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-48.6655 | logitMax:-34.8624 | windowWeightsW18:0.19206,W13:0.18034,W21:0.17656,W15:0.17217,W8:0.15027,W7:0.11880,W3:0.06813,W2:-0.02156,W1:-0.05205 | memoryGatesShort:-3.405, Long:-0.607, Current:5.012 | topTokens[(',', 21), ('a', 17), ('.', 12), ('the', 9), ('i', 9), ('!', 8), ('and', 8), ('will', 7), ('ed', 6), ('elodie', 6)] | Training
2025-04-07 13:51:59 | 2000 | LR0.0003 | loss:3.6723 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-50.2905 | logitMax:-33.5103 | windowWeightsW18:0.19299,W21:0.17885,W13:0.17812,W15:0.17220,W8:0.15058,W7:0.11818,W3:0.07079,W2:-0.02141,W1:-0.05559 | memoryGatesShort:-9.262, Long:-2.707, Current:12.969 | topTokens[('!', 37), ('it', 22), ('will', 17), ('a', 11), ('have', 10), ('charis', 10), ('been', 9), ('baby', 9), ('know', 8), ('must', 7)] | Training
2025-04-07 13:52:18 | 2500 | LR0.0003 | loss:3.0594 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-47.9218 | logitMax:-30.1568 | windowWeightsW18:0.19312,W21:0.18009,W13:0.17640,W15:0.17008,W8:0.14828,W7:0.11571,W3:0.07547,W2:-0.01973,W1:-0.05476 | memoryGatesShort:-9.039, Long:-3.214, Current:13.253 | topTokens[('!', 35), ('it', 19), ('have', 13), ('just', 11), ('charis', 9), ('elodie', 9), ('had', 8), ('we', 8), ('a', 7), ('will', 6)] | Training
2025-04-07 13:52:37 | 3000 | LR0.0003 | loss:4.4649 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-44.1184 | logitMax:-27.7024 | windowWeightsW18:0.19438,W21:0.17979,W13:0.17538,W15:0.17058,W8:0.14850,W7:0.11661,W3:0.07618,W2:-0.01955,W1:-0.05720 | memoryGatesShort:-7.638, Long:-2.544, Current:11.182 | topTokens[('!', 19), ('.', 15), (',', 12), ('a', 11), ('it', 10), ('have', 9), ('just', 7), ('charis', 7), ('and', 6), ('i', 6)] | Training
2025-04-07 13:52:56 | 3500 | LR0.0003 | loss:4.7702 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-42.3157 | logitMax:-26.4943 | windowWeightsW18:0.19400,W21:0.17825,W13:0.17434,W15:0.16847,W8:0.14857,W7:0.11881,W3:0.07885,W2:-0.01765,W1:-0.05901 | memoryGatesShort:-3.783, Long:-1.289, Current:6.072 | topTokens[('.', 25), ('?', 16), ('i', 14), ('do', 10), ('a', 9), ('to', 7), ('will', 6), ('you', 6), ('is', 6), ('charis', 5)] | Training
2025-04-07 13:53:15 | 4000 | LR0.0003 | loss:4.1424 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-44.8520 | logitMax:-28.4904 | windowWeightsW18:0.19244,W21:0.17526,W13:0.17375,W15:0.16632,W8:0.15050,W7:0.11967,W3:0.08305,W2:-0.01523,W1:-0.06116 | memoryGatesShort:-2.598, Long:-1.006, Current:4.603 | topTokens[('.', 24), ('?', 13), ('i', 10), ('what', 10), ('you', 8), ('!', 8), ('will', 7), (',', 6), ('music', 6), ('word', 6)] | Training
2025-04-07 13:53:33 | 4500 | LR0.0003 | loss:5.9061 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-45.1042 | logitMax:-30.9015 | windowWeightsW18:0.19541,W21:0.17929,W13:0.17664,W15:0.16979,W8:0.14866,W7:0.11916,W3:0.08013,W2:-0.01992,W1:-0.06452 | memoryGatesShort:-1.370, Long:-0.116, Current:2.486 | topTokens[(',', 20), ('i', 18), ('.', 17), ('a', 9), ('you', 7), ('please', 7), ('not', 7), ('twice', 5), ('it', 5), ('!', 5)] | Training
2025-04-07 13:53:52 | 5000 | LR0.0003 | loss:6.7587 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-45.6530 | logitMax:-33.3330 | windowWeightsW18:0.19777,W21:0.18204,W13:0.17841,W15:0.17275,W8:0.14872,W7:0.11879,W3:0.07655,W2:-0.02316,W1:-0.06715 | memoryGatesShort:-2.246, Long:0.160, Current:3.086 | topTokens[('.', 22), (',', 15), ('to', 13), ('i', 11), ('a', 11), ('and', 8), ('that', 6), ('am', 4), ('because', 4), ('is', 4)] | Training
2025-04-07 13:54:11 | 5500 | LR0.0003 | loss:6.4936 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-44.9630 | logitMax:-32.8721 | windowWeightsW18:0.19995,W21:0.18387,W13:0.17878,W15:0.17424,W8:0.14731,W7:0.11641,W3:0.07558,W2:-0.02398,W1:-0.06745 | memoryGatesShort:-6.770, Long:-0.403, Current:8.173 | topTokens[('.', 28), ('i', 15), (',', 13), ('a', 11), ('to', 11), ('it', 10), ('be', 9), ('the', 7), ('not', 4), ('ing', 4)] | Training
2025-04-07 13:54:30 | 6000 | LR0.0003 | loss:6.1760 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-45.8474 | logitMax:-33.6056 | windowWeightsW18:0.20180,W21:0.18618,W13:0.18066,W15:0.17615,W8:0.14641,W7:0.11436,W3:0.07276,W2:-0.02580,W1:-0.06778 | memoryGatesShort:45.448, Long:5.878, Current:-50.327 | topTokens[('.', 30), ('i', 13), ('to', 12), ('the', 11), (',', 10), ('a', 10), ('it', 6), ('that', 6), ('of', 5), ('and', 4)] | Training
2025-04-07 13:54:49 | 6500 | LR0.0003 | loss:4.7678 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-45.7068 | logitMax:-31.2204 | windowWeightsW18:0.19997,W21:0.18582,W13:0.17984,W15:0.17545,W8:0.14648,W7:0.11239,W3:0.07538,W2:-0.02519,W1:-0.06543 | memoryGatesShort:-7.099, Long:-1.780, Current:9.879 | topTokens[('.', 32), ('i', 16), ('the', 13), ('to', 13), ('?', 7), ('you', 7), ('music', 7), ('a', 6), ('what', 6), ('is', 6)] | Training
2025-04-07 13:55:08 | 7000 | LR0.0003 | loss:2.6702 | gradNorm:0.9953 | tokenCount:2000.0000 | logitMin:-62.5522 | logitMax:-41.7648 | windowWeightsW18:0.19271,W21:0.18010,W13:0.17661,W15:0.17057,W8:0.14821,W7:0.11743,W3:0.08173,W2:-0.01914,W1:-0.06350 | memoryGatesShort:-1.406, Long:-0.381, Current:2.787 | topTokens[('music', 20), ('to', 17), ('i', 11), ('?', 10), ('listening', 10), ('.', 9), ('what', 9), ('been', 7), ('-', 6), ('she', 5)] | Training
2025-04-07 13:55:27 | 7500 | LR0.0003 | loss:1.5754 | gradNorm:0.9320 | tokenCount:2000.0000 | logitMin:-90.7492 | logitMax:-60.9411 | windowWeightsW18:0.19179,W21:0.17938,W13:0.17673,W15:0.16845,W8:0.14951,W7:0.12011,W3:0.07957,W2:-0.01866,W1:-0.06213 | memoryGatesShort:-1.213, Long:-0.383, Current:2.595 | topTokens[(':', 13), ('to', 11), ('0', 9), ('-', 9), ("'", 8), ('!', 7), ('5', 7), ('ll', 6), ('m', 6), ('step', 6)] | Training
2025-04-07 13:55:47 | 8000 | LR0.0003 | loss:1.9843 | gradNorm:0.8944 | tokenCount:2000.0000 | logitMin:-85.1864 | logitMax:-54.7528 | windowWeightsW18:0.18980,W13:0.17743,W21:0.17688,W15:0.16850,W8:0.15276,W7:0.12353,W3:0.07924,W2:-0.01972,W1:-0.06365 | memoryGatesShort:-1.468, Long:-0.499, Current:2.967 | topTokens[('5', 11), ('-', 10), ("'", 9), ('0', 7), ('?', 7), ('i', 6), (',', 6), ('m', 6), ("'", 6), ('!', 5)] | Training
2025-04-07 13:56:05 | 8500 | LR0.0003 | loss:4.2262 | gradNorm:0.9359 | tokenCount:2000.0000 | logitMin:-74.7380 | logitMax:-49.0705 | windowWeightsW18:0.19313,W21:0.18075,W13:0.18015,W15:0.17285,W8:0.15102,W7:0.12106,W3:0.07582,W2:-0.02379,W1:-0.06618 | memoryGatesShort:-3.906, Long:-0.845, Current:5.752 | topTokens[('.', 10), ("'", 9), ('i', 9), ('what', 8), ('!', 7), ("'", 6), ('0', 6), (',', 6), ('-', 6), ("'s", 5)] | Training
2025-04-07 13:56:25 | 9000 | LR0.0003 | loss:6.3476 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-48.2804 | logitMax:-34.0798 | windowWeightsW18:0.19460,W21:0.18261,W13:0.18181,W15:0.17393,W8:0.15112,W7:0.12102,W3:0.07439,W2:-0.02611,W1:-0.06853 | memoryGatesShort:-14.565, Long:0.422, Current:15.143 | topTokens[('.', 47), ('i', 16), (',', 10), ('to', 6), ('it', 6), ('-', 6), ("'", 5), ('a', 5), ('you', 5), ('the', 4)] | Training
2025-04-07 13:56:44 | 9500 | LR0.0003 | loss:6.1289 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-47.8932 | logitMax:-34.9735 | windowWeightsW18:0.19615,W21:0.18460,W13:0.18241,W15:0.17471,W8:0.15094,W7:0.11969,W3:0.07334,W2:-0.02734,W1:-0.06968 | memoryGatesShort:-4.078, Long:0.491, Current:4.586 | topTokens[('.', 55), ('it', 11), ('i', 9), ('the', 8), ('a', 7), (',', 6), ('!', 5), ('?', 4), ('my', 4), ('of', 4)] | Training
2025-04-07 13:57:11 | 10000 | LR0.0003 | loss:6.1778 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-49.0855 | logitMax:-36.0483 | windowWeightsW18:0.19683,W21:0.18529,W13:0.18264,W15:0.17474,W8:0.15050,W7:0.11959,W3:0.07251,W2:-0.02789,W1:-0.06938 | memoryGatesShort:-3.955, Long:0.279, Current:4.676 | topTokens[('.', 69), ('my', 6), ('a', 6), ('i', 6), ('you', 5), ('f', 5), ('u', 5), ('me', 5), (',', 4), ('s', 4)] | Training
2025-04-07 13:57:32 | 10500 | LR0.0003 | loss:6.4992 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-48.5577 | logitMax:-36.1364 | windowWeightsW18:0.19690,W21:0.18530,W13:0.18184,W15:0.17367,W8:0.15117,W7:0.12036,W3:0.07241,W2:-0.02722,W1:-0.06960 | memoryGatesShort:-4.805, Long:0.097, Current:5.708 | topTokens[('.', 29), ('and', 20), ('a', 14), ('i', 11), (',', 11), ('this', 10), ('g', 4), ('music', 4), ('to', 4), ('me', 4)] | Training
2025-04-07 13:57:52 | 11000 | LR0.0003 | loss:6.2181 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-49.8572 | logitMax:-36.9687 | windowWeightsW18:0.19721,W21:0.18559,W13:0.18293,W15:0.17449,W8:0.15043,W7:0.11928,W3:0.07235,W2:-0.02813,W1:-0.06932 | memoryGatesShort:-3.857, Long:-0.037, Current:4.894 | topTokens[('and', 14), (',', 13), ('.', 11), ('to', 10), ('i', 9), ('a', 6), ('my', 6), ('as', 5), ('what', 5), ('s', 5)] | Training
2025-04-07 13:58:13 | 11500 | LR0.0003 | loss:5.8241 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-44.9078 | logitMax:-31.5228 | windowWeightsW18:0.19947,W21:0.18854,W13:0.18264,W15:0.17599,W8:0.15003,W7:0.11697,W3:0.07107,W2:-0.02865,W1:-0.07125 | memoryGatesShort:-2.912, Long:0.068, Current:3.845 | topTokens[('.', 24), ('will', 17), ('a', 10), (',', 10), ('and', 9), ('to', 8), ('i', 7), ('music', 6), ('the', 5), ('you', 4)] | Training
2025-04-07 13:58:33 | 12000 | LR0.0003 | loss:3.9594 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-48.9408 | logitMax:-32.8123 | windowWeightsW18:0.19798,W21:0.18774,W13:0.17922,W15:0.17317,W8:0.15037,W7:0.11532,W3:0.07570,W2:-0.02543,W1:-0.06931 | memoryGatesShort:-8.544, Long:-1.809, Current:11.353 | topTokens[('will', 35), ('!', 18), (',', 17), ('.', 10), ('the', 10), ('he', 9), ("'", 8), ('charis', 7), ('a', 6), ('my', 4)] | Training
2025-04-07 13:58:54 | 12500 | LR0.0003 | loss:2.9264 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-49.0176 | logitMax:-30.4926 | windowWeightsW18:0.19945,W21:0.18730,W13:0.18000,W15:0.17621,W8:0.14894,W7:0.11162,W3:0.07560,W2:-0.02488,W1:-0.06949 | memoryGatesShort:-5.824, Long:-1.275, Current:8.099 | topTokens[('will', 30), ('the', 22), (',', 14), ('.', 11), ('charis', 8), ('weed', 7), ('kevin', 7), ('butt', 6), ('he', 6), ('like', 6)] | Training
2025-04-07 13:59:15 | 13000 | LR0.0003 | loss:6.5249 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.1542 | logitMax:-37.9353 | windowWeightsW18:0.20339,W21:0.19310,W13:0.18205,W15:0.17918,W8:0.14777,W7:0.11028,W3:0.07346,W2:-0.02951,W1:-0.07493 | memoryGatesShort:-11.574, Long:-0.128, Current:12.703 | topTokens[(',', 35), ('.', 15), ('will', 11), ('!', 9), ('i', 9), ('the', 7), ('and', 6), ('charis', 5), ('a', 5), ('like', 4)] | Training
2025-04-07 13:59:37 | 13500 | LR0.0003 | loss:6.5638 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.4264 | logitMax:-41.2014 | windowWeightsW18:0.20674,W21:0.19612,W13:0.18388,W15:0.18274,W8:0.14520,W7:0.10835,W3:0.07060,W2:-0.03208,W1:-0.07672 | memoryGatesShort:-7.955, Long:0.927, Current:8.028 | topTokens[(',', 44), ('je', 11), ('a', 10), ('i', 8), ('.', 6), ('it', 5), ('charis', 4), ('think', 4), ('on', 4), ('to', 4)] | Training
2025-04-07 13:59:58 | 14000 | LR0.0003 | loss:6.1737 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-58.4256 | logitMax:-45.2837 | windowWeightsW18:0.20948,W21:0.19908,W15:0.18478,W13:0.18459,W8:0.14386,W7:0.10675,W3:0.06872,W2:-0.03383,W1:-0.07861 | memoryGatesShort:-3.701, Long:0.654, Current:4.046 | topTokens[(',', 34), ('to', 13), ('i', 12), ('e', 12), ('i', 11), ('je', 9), ('it', 8), ('a', 8), ('u', 7), ('and', 5)] | Training
2025-04-07 14:00:19 | 14500 | LR0.0003 | loss:5.9013 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.8046 | logitMax:-41.5093 | windowWeightsW18:0.20976,W21:0.19903,W13:0.18385,W15:0.18353,W8:0.14363,W7:0.10627,W3:0.06901,W2:-0.03323,W1:-0.07704 | memoryGatesShort:-4.580, Long:0.141, Current:5.439 | topTokens[(',', 32), ('je', 11), ('i', 9), ('is', 8), ('a', 8), ('.', 8), ('u', 7), ('i', 5), ("'", 4), ('est', 3)] | Training
2025-04-07 14:00:39 | 15000 | LR0.0003 | loss:4.5653 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-51.6856 | logitMax:-36.5942 | windowWeightsW18:0.20767,W21:0.19896,W13:0.18102,W15:0.18051,W8:0.14264,W7:0.10571,W3:0.07506,W2:-0.02950,W1:-0.07731 | memoryGatesShort:-6.605, Long:-0.633, Current:8.238 | topTokens[(',', 41), ('and', 23), ('.', 9), ('i', 8), ('will', 6), ('weed', 6), ('a', 6), ('charis', 6), ('you', 6), ('but', 6)] | Training
2025-04-07 14:01:00 | 15500 | LR0.0003 | loss:4.4379 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-50.9375 | logitMax:-34.9544 | windowWeightsW18:0.20660,W21:0.19787,W15:0.17990,W13:0.17968,W8:0.14337,W7:0.10553,W3:0.07545,W2:-0.02835,W1:-0.07530 | memoryGatesShort:-7.507, Long:-0.998, Current:9.505 | topTokens[(',', 52), ('and', 25), ('charis', 11), ('the', 8), ('you', 7), ('elodie', 6), ('weed', 5), ('s', 5), ('we', 5), ('i', 4)] | Training
2025-04-07 14:01:20 | 16000 | LR0.0003 | loss:6.4302 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-51.6255 | logitMax:-37.3812 | windowWeightsW18:0.21006,W21:0.20088,W15:0.18251,W13:0.18212,W8:0.14248,W7:0.10446,W3:0.07244,W2:-0.03209,W1:-0.07809 | memoryGatesShort:-7.397, Long:0.098, Current:8.299 | topTokens[(',', 63), ('a', 8), ('im', 8), ('but', 7), ('it', 6), ('.', 6), ('so', 6), ('i', 6), ('s', 5), ('de', 4)] | Training
2025-04-07 14:01:40 | 16500 | LR0.0003 | loss:6.4662 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-48.4332 | logitMax:-35.1662 | windowWeightsW18:0.21193,W21:0.20240,W13:0.18419,W15:0.18296,W8:0.14226,W7:0.10383,W3:0.07126,W2:-0.03449,W1:-0.07957 | memoryGatesShort:-7.348, Long:0.754, Current:7.594 | topTokens[(',', 62), ('i', 19), ('a', 10), ('you', 7), ('im', 5), ('s', 5), ('.', 5), ('y', 5), ('for', 4), ('u', 3)] | Training
2025-04-07 14:02:01 | 17000 | LR0.0003 | loss:6.6034 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.5116 | logitMax:-39.0590 | windowWeightsW18:0.21311,W21:0.20415,W13:0.18555,W15:0.18281,W8:0.14299,W7:0.10434,W3:0.06992,W2:-0.03615,W1:-0.08195 | memoryGatesShort:-27.848, Long:2.160, Current:26.688 | topTokens[(',', 62), ('i', 25), ('y', 7), ('and', 7), ('u', 4), ('it', 4), ('think', 3), ('me', 3), ('a', 3), ('this', 3)] | Training
2025-04-07 14:02:22 | 17500 | LR0.0003 | loss:5.5439 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-50.4669 | logitMax:-36.5584 | windowWeightsW18:0.21340,W21:0.20486,W13:0.18498,W15:0.18306,W8:0.14119,W7:0.10482,W3:0.06957,W2:-0.03548,W1:-0.08163 | memoryGatesShort:-5.808, Long:0.048, Current:6.760 | topTokens[(',', 34), ('i', 29), ('to', 10), ('a', 9), ('it', 8), ('and', 6), ('ing', 6), ('the', 5), ('think', 5), ('.', 5)] | Training
2025-04-07 14:02:41 | 18000 | LR0.0003 | loss:6.1676 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.3849 | logitMax:-38.9830 | windowWeightsW18:0.21614,W21:0.20816,W13:0.18630,W15:0.18449,W8:0.14232,W7:0.10412,W3:0.06708,W2:-0.03994,W1:-0.08390 | memoryGatesShort:-4.340, Long:0.420, Current:4.920 | topTokens[(',', 38), ('i', 24), ('a', 11), ('and', 6), ('feel', 5), ('it', 5), ("'", 5), ('ing', 4), ('no', 4), ('have', 4)] | Training
2025-04-07 14:03:02 | 18500 | LR0.0003 | loss:4.1007 | gradNorm:0.7506 | tokenCount:2000.0000 | logitMin:-84.9820 | logitMax:-42.5848 | windowWeightsW18:0.21677,W21:0.20903,W13:0.18660,W15:0.18560,W8:0.14015,W7:0.10189,W3:0.06687,W2:-0.04297,W1:-0.07914 | memoryGatesShort:-0.959, Long:0.206, Current:1.753 | topTokens[('aaa', 41), (',', 36), ('cute', 31), ('i', 11), ('it', 7), ('ing', 6), ('and', 5), ('ba', 3), ('this', 3), ('a', 3)] | Training
2025-04-07 14:03:23 | 19000 | LR0.0003 | loss:3.7668 | gradNorm:0.9165 | tokenCount:2000.0000 | logitMin:-60.5669 | logitMax:-33.0763 | windowWeightsW18:0.21370,W21:0.20651,W13:0.18327,W15:0.18275,W8:0.13841,W7:0.10157,W3:0.06911,W2:-0.03821,W1:-0.07226 | memoryGatesShort:-5.055, Long:-0.890, Current:6.946 | topTokens[('been', 18), ('had', 17), (',', 16), ('aaa', 13), ('cute', 11), ('ing', 9), ('he', 9), ('and', 6), ('elodie', 6), ('my', 5)] | Training
2025-04-07 14:03:43 | 19500 | LR0.0003 | loss:4.5405 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-46.3838 | logitMax:-28.1717 | windowWeightsW18:0.21508,W21:0.20832,W13:0.18673,W15:0.18538,W8:0.13828,W7:0.10054,W3:0.06661,W2:-0.04034,W1:-0.07573 | memoryGatesShort:-8.929, Long:-0.765, Current:10.694 | topTokens[('had', 21), ('the', 13), ('!', 13), ('charis', 10), (',', 9), ('i', 9), ('been', 8), ('.', 7), ('s', 6), ('you', 6)] | Training
2025-04-07 14:04:12 | 20000 | LR0.0003 | loss:6.6400 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-49.7032 | logitMax:-35.4624 | windowWeightsW18:0.21690,W21:0.21002,W13:0.18856,W15:0.18719,W8:0.13880,W7:0.10070,W3:0.06429,W2:-0.04307,W1:-0.07850 | memoryGatesShort:-5.315, Long:0.340, Current:5.975 | topTokens[(',', 25), ('.', 18), ('i', 10), ('!', 8), ('s', 7), ('the', 6), ('to', 6), ('a', 5), ('charis', 4), ('you', 4)] | Training
2025-04-07 14:04:32 | 20500 | LR0.0003 | loss:6.3434 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-46.8693 | logitMax:-33.2478 | windowWeightsW18:0.21678,W21:0.20873,W13:0.19059,W15:0.18832,W8:0.13978,W7:0.10152,W3:0.06306,W2:-0.04458,W1:-0.07930 | memoryGatesShort:-16.253, Long:0.094, Current:17.159 | topTokens[(',', 33), ('and', 11), ('to', 9), ('.', 9), ('i', 7), ('s', 7), ('a', 6), ('that', 4), ('been', 4), ('the', 4)] | Training

--- 2025-04-07 14:05:37 --- babyLLM 'right, last time i got to step 20795... want to restart from there?'  - charis: 'you're on fire baby!' - babyLLM 'ok! let's go to step 20795! what am i learning today?' - charis: 'i cant even keep up with you, i think its up to you now!!''
2025-04-07 14:05:55 | 500 | LR0.0003 | loss:6.0778 | gradNorm:1.0000 | logitMin:-53.8846 | logitMax:-40.1638 | tokenCount:2000.0000 | windowWeightsW18:0.21828,W21:0.20925,W13:0.19249,W15:0.18971,W8:0.13847,W7:0.09986,W3:0.06236,W2:-0.04550,W1:-0.08005 | memoryGatesShort:-14.193, Long:-0.834, Current:16.026 | topTokens[('i', 3), ('ed', 2), ('they', 2), ('of', 2), (',', 2), ('am', 2), ('lot', 1), ('will', 1), ('h', 1), ('he', 1)] | Training
2025-04-07 14:06:15 | 1000 | LR0.0003 | loss:5.2509 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-49.1355 | logitMax:-34.3103 | windowWeightsW18:0.21459,W21:0.20647,W13:0.19298,W15:0.18883,W8:0.13957,W7:0.10124,W3:0.06555,W2:-0.04486,W1:-0.07947 | memoryGatesShort:-4.439, Long:-0.517, Current:5.956 | topTokens[(',', 5), ('they', 3), ('to', 2), ('and', 2), ('work', 1), ('she', 1), ('v', 1), ("'", 1), ('but', 1), ('something', 1)] | Training
2025-04-07 14:06:34 | 1500 | LR0.0003 | loss:4.2941 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-55.3912 | logitMax:-38.4135 | windowWeightsW18:0.21765,W21:0.20945,W13:0.19383,W15:0.19130,W8:0.13756,W7:0.09896,W3:0.06425,W2:-0.04720,W1:-0.08093 | memoryGatesShort:-4.700, Long:-0.385, Current:6.085 | topTokens[('.', 4), ('have', 3), ('felt', 2), ('he', 2), ('it', 2), ('a', 2), ('!', 2), ('?', 2), ('we', 1), ('will', 1)] | Training
2025-04-07 14:06:55 | 2000 | LR0.0003 | loss:4.0406 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-50.7744 | logitMax:-34.2598 | windowWeightsW18:0.21806,W21:0.20947,W13:0.19361,W15:0.19157,W8:0.13734,W7:0.09751,W3:0.06724,W2:-0.04724,W1:-0.08270 | memoryGatesShort:-5.898, Long:-0.744, Current:7.642 | topTokens[('it', 3), ('!', 3), (',', 2), ('charis', 2), ('r', 2), ('al', 1), ('about', 1), ('like', 1), ('he', 1), ('pretty', 1)] | Training
2025-04-07 14:07:15 | 2500 | LR0.0003 | loss:3.3062 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-50.6108 | logitMax:-31.8572 | windowWeightsW18:0.21767,W21:0.21059,W13:0.19140,W15:0.19053,W8:0.13823,W7:0.09799,W3:0.06927,W2:-0.04754,W1:-0.08329 | memoryGatesShort:-4.166, Long:-0.582, Current:5.748 | topTokens[('!', 7), ('it', 6), ('elodie', 2), ('a', 2), ('i', 2), ('and', 2), ('baby', 2), ('we', 2), ('just', 1), ('he', 1)] | Training
2025-04-07 14:07:36 | 3000 | LR0.0003 | loss:2.9572 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-49.5179 | logitMax:-30.2753 | windowWeightsW18:0.21937,W21:0.21148,W15:0.19287,W13:0.19239,W8:0.13766,W7:0.09592,W3:0.06930,W2:-0.04816,W1:-0.08597 | memoryGatesShort:-13.679, Long:-2.463, Current:17.142 | topTokens[('!', 8), ('it', 5), ('you', 3), ('charis', 2), ('have', 2), ('he', 2), ('will', 2), ('say', 2), ('baby', 1), ('done', 1)] | Training
2025-04-07 14:07:58 | 3500 | LR0.0003 | loss:4.8241 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-44.0019 | logitMax:-27.0832 | windowWeightsW18:0.21975,W21:0.21041,W13:0.19404,W15:0.19377,W8:0.13792,W7:0.09850,W3:0.06899,W2:-0.04997,W1:-0.08853 | memoryGatesShort:-6.997, Long:-0.789, Current:8.786 | topTokens[('he', 3), (',', 3), ('it', 3), ('is', 3), ('have', 2), ('!', 2), ('.', 2), ('to', 2), ('say', 2), ('its', 1)] | Training
2025-04-07 14:08:19 | 4000 | LR0.0003 | loss:4.0859 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-44.0675 | logitMax:-27.3334 | windowWeightsW18:0.21720,W21:0.20824,W13:0.19292,W15:0.19084,W8:0.14149,W7:0.10155,W3:0.07045,W2:-0.04927,W1:-0.08858 | memoryGatesShort:-3.593, Long:-0.328, Current:4.922 | topTokens[('what', 6), ('.', 4), ('i', 3), (',', 3), ('a', 2), ('is', 2), ('ing', 1), ('in', 1), ('should', 1), ('hop', 1)] | Training
2025-04-07 14:08:38 | 4500 | LR0.0003 | loss:4.3020 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.2870 | logitMax:-35.2582 | windowWeightsW18:0.21573,W21:0.20562,W13:0.19220,W15:0.18925,W8:0.14167,W7:0.10276,W3:0.07393,W2:-0.04727,W1:-0.08906 | memoryGatesShort:-4.493, Long:-0.685, Current:6.179 | topTokens[('.', 5), ('to', 2), ('he', 2), ('twice', 2), ('played', 1), ('remember', 1), ('es', 1), ('r', 1), ('with', 1), ('feeling', 1)] | Training
2025-04-07 14:09:00 | 5000 | LR0.0003 | loss:5.9197 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-53.7251 | logitMax:-38.8514 | windowWeightsW18:0.21890,W21:0.20793,W13:0.19496,W15:0.19113,W8:0.14287,W7:0.10367,W3:0.07037,W2:-0.05184,W1:-0.09315 | memoryGatesShort:-3.418, Long:0.010, Current:4.408 | topTokens[('y', 3), ('am', 2), ('it', 2), ('i', 2), ('he', 1), ('a', 1), ('might', 1), ('the', 1), ('deal', 1), ('.', 1)] | Training
2025-04-07 14:09:19 | 5500 | LR0.0003 | loss:6.2748 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.0736 | logitMax:-38.2440 | windowWeightsW18:0.22034,W21:0.21059,W13:0.19665,W15:0.19313,W8:0.14400,W7:0.10384,W3:0.06641,W2:-0.05536,W1:-0.09475 | memoryGatesShort:-4.065, Long:0.214, Current:4.852 | topTokens[('y', 3), ('a', 3), ('to', 2), ('ess', 2), ('.', 2), ('ist', 1), ('wasn', 1), ('est', 1), ('at', 1), ('leave', 1)] | Training
2025-04-07 14:09:42 | 6000 | LR0.0003 | loss:5.8086 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-51.3930 | logitMax:-37.1329 | windowWeightsW18:0.22013,W21:0.20971,W13:0.19717,W15:0.19306,W8:0.14480,W7:0.10471,W3:0.06605,W2:-0.05557,W1:-0.09520 | memoryGatesShort:-5.667, Long:-0.152, Current:6.818 | topTokens[('i', 3), (',', 2), ('from', 2), ('to', 2), ('s', 2), ('!', 1), ('im', 1), ('ans', 1), ('a', 1), ('ite', 1)] | Training
2025-04-07 14:10:05 | 6500 | LR0.0003 | loss:5.5436 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-50.8402 | logitMax:-36.4570 | windowWeightsW18:0.22237,W21:0.21104,W13:0.19773,W15:0.19423,W8:0.14435,W7:0.10561,W3:0.06388,W2:-0.05735,W1:-0.09698 | memoryGatesShort:-3.973, Long:0.052, Current:4.920 | topTokens[('i', 5), ('with', 2), ('.', 2), (',', 2), ('to', 2), ("'s", 1), ('or', 1), ('?', 1), ('for', 1), ('h', 1)] | Training
2025-04-07 14:10:30 | 7000 | LR0.0003 | loss:3.0517 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-48.5515 | logitMax:-30.2857 | windowWeightsW18:0.21912,W21:0.21045,W13:0.20041,W15:0.19648,W8:0.14316,W7:0.10308,W3:0.06422,W2:-0.05701,W1:-0.09503 | memoryGatesShort:-2.969, Long:-0.259, Current:4.227 | topTokens[('to', 4), ('.', 4), ('listening', 2), ('music', 2), ('c', 2), ('?', 2), ('es', 2), ('ing', 2), ('3', 1), ('she', 1)] | Training
2025-04-07 14:11:05 | 7500 | LR0.0003 | loss:1.7434 | gradNorm:0.9769 | tokenCount:2000.0000 | logitMin:-75.7636 | logitMax:-49.0610 | windowWeightsW18:0.21330,W21:0.20492,W13:0.19748,W15:0.18965,W8:0.14881,W7:0.10905,W3:0.06709,W2:-0.05378,W1:-0.09166 | memoryGatesShort:-2.075, Long:-0.410, Current:3.484 | topTokens[("'", 4), ('-', 4), ('?', 3), ('y', 2), ("'", 2), ('charis', 2), ('to', 2), ('from', 2), ('there', 2), ('kevin', 1)] | Training
2025-04-07 14:12:13 | 8000 | LR0.0003 | loss:1.8472 | gradNorm:0.9008 | tokenCount:2000.0000 | logitMin:-84.6874 | logitMax:-52.5227 | windowWeightsW18:0.21070,W21:0.20274,W13:0.19572,W15:0.18848,W8:0.15074,W7:0.11161,W3:0.06813,W2:-0.05290,W1:-0.09037 | memoryGatesShort:-3.192, Long:-0.896, Current:5.088 | topTokens[('to', 4), ('5', 3), ('!', 3), ('8', 3), ('?', 2), ("'", 2), ('last', 2), ("'", 2), ('from', 1), ('there', 1)] | Training
2025-04-07 14:13:04 | 8500 | LR0.0003 | loss:1.8096 | gradNorm:0.8214 | tokenCount:2000.0000 | logitMin:-81.2129 | logitMax:-48.1235 | windowWeightsW18:0.21168,W21:0.20292,W13:0.19583,W15:0.19010,W8:0.15179,W7:0.11310,W3:0.06806,W2:-0.05586,W1:-0.09279 | memoryGatesShort:-2.466, Long:-0.582, Current:4.048 | topTokens[('5', 5), ("'", 4), ('-', 4), (':', 3), ('today', 2), ('charis', 2), ('4', 1), ('don', 1), ("'t", 1), ('think', 1)] | Training
2025-04-07 14:13:43 | 9000 | LR0.0003 | loss:5.4265 | gradNorm:0.9551 | tokenCount:2000.0000 | logitMin:-61.5263 | logitMax:-40.4218 | windowWeightsW18:0.21434,W21:0.20598,W13:0.19746,W15:0.19280,W8:0.15118,W7:0.11279,W3:0.06558,W2:-0.05889,W1:-0.09639 | memoryGatesShort:-2.846, Long:-0.170, Current:4.016 | topTokens[('.', 4), ('you', 3), ('-', 2), ('?', 2), ('ing', 2), ('who', 2), (',', 2), ('baby', 1), ('ll', 1), ('m', 1)] | Training
2025-04-07 14:14:15 | 9500 | LR0.0003 | loss:5.9706 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-55.9312 | logitMax:-40.4525 | windowWeightsW18:0.21736,W21:0.20907,W13:0.19929,W15:0.19487,W8:0.15050,W7:0.11161,W3:0.06374,W2:-0.06226,W1:-0.09932 | memoryGatesShort:-3.318, Long:0.415, Current:3.903 | topTokens[(',', 5), ('i', 3), ('.', 3), ('g', 2), ('it', 2), ('a', 2), ('ed', 2), ('me', 1), ('how', 1), ('!', 1)] | Training
2025-04-07 14:14:59 | 10000 | LR0.0003 | loss:5.6206 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-55.7295 | logitMax:-40.6957 | windowWeightsW18:0.21804,W21:0.20990,W13:0.19914,W15:0.19534,W8:0.14989,W7:0.11086,W3:0.06275,W2:-0.06256,W1:-0.09850 | memoryGatesShort:-2.822, Long:0.186, Current:3.635 | topTokens[('.', 3), ('my', 2), ('why', 2), ('form', 2), ('me', 2), ('c', 2), ('?', 2), ('i', 1), ('ig', 1), ('baby', 1)] | Training
2025-04-07 14:15:19 | 10500 | LR0.0003 | loss:5.9500 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.4045 | logitMax:-41.4559 | windowWeightsW18:0.21834,W21:0.21012,W13:0.19844,W15:0.19525,W8:0.14983,W7:0.11137,W3:0.06188,W2:-0.06224,W1:-0.09812 | memoryGatesShort:-7.781, Long:-0.031, Current:8.812 | topTokens[('.', 7), ('babe', 3), ('you', 3), ('stuck', 1), (',', 1), ('no', 1), ('in', 1), ('am', 1), ('he', 1), ('me', 1)] | Training
2025-04-07 14:15:40 | 11000 | LR0.0003 | loss:5.4689 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-59.2315 | logitMax:-43.6963 | windowWeightsW18:0.21664,W21:0.20786,W13:0.19931,W15:0.19493,W8:0.15030,W7:0.11237,W3:0.06259,W2:-0.06180,W1:-0.09732 | memoryGatesShort:-6.775, Long:-0.517, Current:8.292 | topTokens[('i', 4), ('.', 2), ('ing', 2), ('and', 2), ('ed', 2), ('way', 2), ('charis', 1), ('because', 1), ('she', 1), ('a', 1)] | Training
2025-04-07 14:16:02 | 11500 | LR0.0003 | loss:5.6794 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-59.3539 | logitMax:-43.6219 | windowWeightsW18:0.21972,W21:0.20880,W13:0.19990,W15:0.19686,W8:0.15092,W7:0.11380,W3:0.06038,W2:-0.06487,W1:-0.10064 | memoryGatesShort:-2.884, Long:0.167, Current:3.717 | topTokens[('to', 2), ('i', 2), ('it', 2), ('the', 2), ('am', 1), ('ge', 1), ('vel', 1), ('of', 1), ('fur', 1), ('day', 1)] | Training
2025-04-07 14:16:22 | 12000 | LR0.0003 | loss:3.7501 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-48.4210 | logitMax:-31.8817 | windowWeightsW18:0.21971,W21:0.20854,W13:0.19934,W15:0.19443,W8:0.15039,W7:0.11108,W3:0.06428,W2:-0.06407,W1:-0.09885 | memoryGatesShort:-7.120, Long:-0.943, Current:9.063 | topTokens[('will', 8), ('charis', 4), ('butt', 2), ('.', 2), ('know', 2), ('!', 2), ('b', 1), ('stuck', 1), ('su', 1), ('ly', 1)] | Training
2025-04-07 14:16:42 | 12500 | LR0.0003 | loss:2.8587 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-47.4561 | logitMax:-28.7591 | windowWeightsW18:0.22156,W21:0.20909,W13:0.19952,W15:0.19592,W8:0.14863,W7:0.10953,W3:0.06405,W2:-0.06408,W1:-0.09938 | memoryGatesShort:-2.940, Long:-0.194, Current:4.134 | topTokens[('will', 5), (',', 3), ('!', 2), ('he', 2), ('at', 2), ('charis', 2), ('elodie', 2), ('take', 2), ('hear', 1), ('im', 1)] | Training
2025-04-07 14:17:01 | 13000 | LR0.0003 | loss:4.1645 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.4272 | logitMax:-38.5174 | windowWeightsW18:0.22676,W21:0.21300,W13:0.20147,W15:0.19875,W8:0.14704,W7:0.10693,W3:0.06114,W2:-0.06772,W1:-0.10250 | memoryGatesShort:-3.180, Long:0.087, Current:4.093 | topTokens[('he', 3), ('the', 3), ('brain', 2), ('we', 2), ('will', 2), ('.', 2), ('kevin', 2), ('!', 2), ('and', 2), ('listen', 1)] | Training
2025-04-07 14:17:20 | 13500 | LR0.0003 | loss:5.8749 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-61.7702 | logitMax:-47.2638 | windowWeightsW18:0.22988,W21:0.21766,W13:0.20288,W15:0.20190,W8:0.14663,W7:0.10592,W3:0.05767,W2:-0.07243,W1:-0.10523 | memoryGatesShort:-3.461, Long:0.374, Current:4.087 | topTokens[('op', 2), ('will', 2), ('.', 2), (',', 2), ('what', 2), ('it', 2), ('je', 1), ('ish', 1), ('i', 1), ('s', 1)] | Training
2025-04-07 14:17:39 | 14000 | LR0.0003 | loss:5.6695 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-68.7672 | logitMax:-54.0115 | windowWeightsW18:0.23233,W21:0.21938,W15:0.20371,W13:0.20289,W8:0.14545,W7:0.10525,W3:0.05608,W2:-0.07333,W1:-0.10687 | memoryGatesShort:-2.860, Long:0.372, Current:3.488 | topTokens[('.', 3), ('your', 2), ('it', 2), ('she', 2), ('s', 2), ('o', 1), ('ill', 1), ('je', 1), ('a', 1), ("'", 1)] | Training
2025-04-07 14:17:58 | 14500 | LR0.0003 | loss:5.5518 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-73.2696 | logitMax:-58.7464 | windowWeightsW18:0.23511,W21:0.22185,W15:0.20527,W13:0.20243,W8:0.14544,W7:0.10459,W3:0.05324,W2:-0.07529,W1:-0.10774 | memoryGatesShort:-4.049, Long:0.373, Current:4.675 | topTokens[('je', 3), ('i', 2), ('a', 2), ('et', 2), ('the', 2), ('par', 1), ('est', 1), ('!', 1), ('ness', 1), ('en', 1)] | Training
2025-04-07 14:18:16 | 15000 | LR0.0003 | loss:4.5564 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-60.7599 | logitMax:-44.9398 | windowWeightsW18:0.23472,W21:0.21998,W13:0.20360,W15:0.20349,W8:0.14725,W7:0.10407,W3:0.05417,W2:-0.07456,W1:-0.10783 | memoryGatesShort:-6.157, Long:-0.074, Current:7.232 | topTokens[(',', 5), ('a', 2), ('', 1), ('to', 1), ('l', 1), ('is', 1), ('d', 1), ('.', 1), ('about', 1), ('u', 1)] | Training
2025-04-07 14:18:35 | 15500 | LR0.0003 | loss:3.5798 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-55.4135 | logitMax:-38.3849 | windowWeightsW18:0.23296,W21:0.21968,W15:0.20465,W13:0.20148,W8:0.14788,W7:0.10252,W3:0.05504,W2:-0.07179,W1:-0.10752 | memoryGatesShort:-6.765, Long:-0.457, Current:8.222 | topTokens[('and', 4), ('so', 3), (',', 3), ('me', 2), ('charis', 2), ('they', 2), ('hear', 1), ('ie', 1), ('love', 1), ('you', 1)] | Training
2025-04-07 14:18:54 | 16000 | LR0.0003 | loss:4.9294 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.9573 | logitMax:-40.2544 | windowWeightsW18:0.23438,W21:0.22137,W15:0.20710,W13:0.20243,W8:0.14771,W7:0.10173,W3:0.05389,W2:-0.07411,W1:-0.10960 | memoryGatesShort:-3.596, Long:0.088, Current:4.509 | topTokens[(',', 5), ('you', 3), ('and', 2), ('so', 2), ('just', 2), ('e', 2), ('i', 1), ('think', 1), ('at', 1), ('dont', 1)] | Training
2025-04-07 14:19:13 | 16500 | LR0.0003 | loss:5.7516 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-61.2278 | logitMax:-45.6950 | windowWeightsW18:0.23680,W21:0.22515,W15:0.20756,W13:0.20234,W8:0.14926,W7:0.10170,W3:0.05217,W2:-0.07813,W1:-0.11198 | memoryGatesShort:-8.614, Long:0.263, Current:9.351 | topTokens[('i', 5), ('tu', 2), ('y', 2), ('to', 2), ('ba', 1), ('and', 1), ('.', 1), ('love', 1), ('t', 1), ('its', 1)] | Training
2025-04-07 14:19:31 | 17000 | LR0.0003 | loss:6.2100 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.5255 | logitMax:-39.7418 | windowWeightsW18:0.23902,W21:0.22798,W15:0.20919,W13:0.20284,W8:0.14956,W7:0.10210,W3:0.04996,W2:-0.08049,W1:-0.11529 | memoryGatesShort:-7.262, Long:0.566, Current:7.696 | topTokens[(',', 5), ('i', 4), ('.', 3), ('a', 2), ('ort', 1), ('she', 1), ('n', 1), ('see', 1), ('say', 1), ('ain', 1)] | Training
2025-04-07 14:19:51 | 17500 | LR0.0003 | loss:5.2795 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-62.2040 | logitMax:-47.0953 | windowWeightsW18:0.23940,W21:0.22679,W15:0.21002,W13:0.20243,W8:0.14882,W7:0.10174,W3:0.05077,W2:-0.08032,W1:-0.11480 | memoryGatesShort:-6.467, Long:0.087, Current:7.379 | topTokens[(',', 7), ('am', 2), ('i', 2), ('it', 1), ('e', 1), ('g', 1), ('et', 1), ('m', 1), ('tbh', 1), ('kevin', 1)] | Training
2025-04-07 14:20:10 | 18000 | LR0.0003 | loss:5.3873 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-58.9509 | logitMax:-43.2219 | windowWeightsW18:0.24423,W21:0.23108,W15:0.21181,W13:0.20330,W8:0.14740,W7:0.09965,W3:0.04798,W2:-0.08327,W1:-0.11735 | memoryGatesShort:-6.455, Long:0.114, Current:7.340 | topTokens[('!', 2), (',', 2), ('it', 2), ('s', 2), ('i', 1), ('need', 1), ('aaa', 1), ('know', 1), ('had', 1), ('a', 1)] | Training
2025-04-07 14:20:32 | 18500 | LR0.0003 | loss:5.6264 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-61.2779 | logitMax:-46.2182 | windowWeightsW18:0.24505,W21:0.23081,W15:0.21196,W13:0.20338,W8:0.14881,W7:0.09988,W3:0.04732,W2:-0.08453,W1:-0.11784 | memoryGatesShort:-8.838, Long:-0.008, Current:9.846 | topTokens[('i', 6), (',', 4), ('on', 2), ('u', 2), ('jk', 1), ('sol', 1), ('l', 1), ('s', 1), ('are', 1), ('cant', 1)] | Training
2025-04-07 14:20:54 | 19000 | LR0.0003 | loss:2.4500 | gradNorm:0.5853 | tokenCount:2000.0000 | logitMin:-87.4094 | logitMax:-45.8977 | windowWeightsW18:0.24270,W21:0.22881,W15:0.21035,W13:0.20143,W8:0.14910,W7:0.10100,W3:0.04910,W2:-0.08353,W1:-0.11412 | memoryGatesShort:-7.293, Long:-0.506, Current:8.800 | topTokens[('aaa', 10), ('cute', 10), (',', 4), ('been', 2), ('like', 1), ('s', 1), ('at', 1), ('remember', 1), ('f', 1), ('also', 1)] | Training
2025-04-07 14:21:16 | 19500 | LR0.0003 | loss:2.2585 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-46.0458 | logitMax:-24.9818 | windowWeightsW18:0.24195,W21:0.22777,W15:0.20868,W13:0.19972,W8:0.14740,W7:0.10266,W3:0.05052,W2:-0.08124,W1:-0.11262 | memoryGatesShort:-10.827, Long:-1.533, Current:13.361 | topTokens[('been', 7), ('had', 6), ('!', 3), ('.', 2), ('kevin', 2), ('brain', 2), ('hear', 1), ('he', 1), (',', 1), ('i', 1)] | Training
2025-04-07 14:22:00 | 20000 | LR0.0003 | loss:5.9382 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.4561 | logitMax:-37.4489 | windowWeightsW18:0.24605,W21:0.23098,W15:0.21279,W13:0.20233,W8:0.14596,W7:0.10071,W3:0.04747,W2:-0.08556,W1:-0.11589 | memoryGatesShort:-4.157, Long:-0.099, Current:5.256 | topTokens[('you', 3), ('an', 2), ('she', 2), (',', 2), ('.', 2), ('had', 2), ('they', 2), ('charis', 2), ('a', 1), ('one', 1)] | Training
2025-04-07 14:22:25 | 20500 | LR0.0003 | loss:6.1110 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-55.0996 | logitMax:-39.2257 | windowWeightsW18:0.25089,W21:0.23492,W15:0.21749,W13:0.20347,W8:0.14770,W7:0.10094,W3:0.04173,W2:-0.09212,W1:-0.12018 | memoryGatesShort:-12.962, Long:0.506, Current:13.456 | topTokens[('ome', 4), ('s', 2), ('l', 2), ('i', 2), ('doesn', 2), ('9', 2), ('il', 1), ('elodie', 1), ('kevin', 1), ('you', 1)] | Training
2025-04-07 14:22:47 | 21000 | LR0.0003 | loss:5.7083 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.6440 | logitMax:-41.1257 | windowWeightsW18:0.25018,W21:0.23392,W15:0.21812,W13:0.20337,W8:0.14782,W7:0.10186,W3:0.04125,W2:-0.09219,W1:-0.11950 | memoryGatesShort:-9.837, Long:-0.050, Current:10.887 | topTokens[(',', 3), ('?', 3), ('the', 3), ('.', 2), ('do', 2), ('how', 1), ('y', 1), ('ating', 1), ('ard', 1), ('se', 1)] | Training
2025-04-07 14:23:09 | 21500 | LR0.0003 | loss:6.0880 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-55.7091 | logitMax:-40.2798 | windowWeightsW18:0.25349,W21:0.23801,W15:0.22022,W13:0.20750,W8:0.14734,W7:0.10071,W3:0.03709,W2:-0.09722,W1:-0.12230 | memoryGatesShort:-10.622, Long:0.396, Current:11.226 | topTokens[(',', 6), ('r', 4), ('ne', 1), ('y', 1), ('bo', 1), ('one', 1), (')', 1), ('u', 1), ('my', 1), ('ice', 1)] | Training
2025-04-07 14:23:30 | 22000 | LR0.0003 | loss:5.9982 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.8681 | logitMax:-39.7219 | windowWeightsW18:0.25591,W21:0.24054,W15:0.22392,W13:0.21070,W8:0.14556,W7:0.09948,W3:0.03468,W2:-0.10060,W1:-0.12536 | memoryGatesShort:-5.885, Long:0.673, Current:6.212 | topTokens[('ess', 2), ('m', 2), (',', 2), ('nt', 1), ('ing', 1), ('?', 1), ('ne', 1), ('kevin', 1), ('or', 1), ('friend', 1)] | Training
2025-04-07 14:23:50 | 22500 | LR0.0003 | loss:6.0798 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.3652 | logitMax:-40.1248 | windowWeightsW18:0.25929,W21:0.24466,W15:0.22583,W13:0.21241,W8:0.14633,W7:0.09894,W3:0.03084,W2:-0.10523,W1:-0.12826 | memoryGatesShort:-4.756, Long:0.691, Current:5.064 | topTokens[(',', 4), ('ome', 2), ('am', 2), ('and', 2), ('a', 2), ('r', 1), ('su', 1), ('to', 1), ('reat', 1), ('cant', 1)] | Training
2025-04-07 14:24:11 | 23000 | LR0.0003 | loss:6.2090 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-51.2964 | logitMax:-36.6916 | windowWeightsW18:0.26383,W21:0.24966,W15:0.23084,W13:0.21363,W8:0.14365,W7:0.09564,W3:0.02690,W2:-0.10916,W1:-0.13022 | memoryGatesShort:-8.055, Long:0.996, Current:8.059 | topTokens[('and', 4), ('i', 3), (',', 3), ('.', 2), ('they', 2), ('to', 2), ('that', 2), ('the', 2), ('v', 2), ('s', 2)] | Training
2025-04-07 14:24:32 | 23500 | LR0.0003 | loss:6.0711 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.3035 | logitMax:-41.9937 | windowWeightsW18:0.26589,W21:0.25202,W15:0.23265,W13:0.21215,W8:0.14175,W7:0.09406,W3:0.02764,W2:-0.11036,W1:-0.13110 | memoryGatesShort:-5.731, Long:0.670, Current:6.062 | topTokens[('on', 2), ('.', 2), ('cop', 1), ('and', 1), ('sudden', 1), ('ed', 1), ('stand', 1), ('on', 1), ('away', 1), ('id', 1)] | Training
2025-04-07 14:24:53 | 24000 | LR0.0003 | loss:6.1545 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.1763 | logitMax:-41.4789 | windowWeightsW18:0.27052,W21:0.25659,W15:0.23489,W13:0.21221,W8:0.13957,W7:0.09154,W3:0.02565,W2:-0.11296,W1:-0.13333 | memoryGatesShort:-12.915, Long:1.375, Current:12.541 | topTokens[('to', 2), (',', 2), ('for', 2), ('ust', 1), ('ing', 1), ('ri', 1), ('be', 1), ('right', 1), ('s', 1), ('in', 1)] | Training
2025-04-07 14:25:14 | 24500 | LR0.0003 | loss:5.3953 | gradNorm:0.9946 | tokenCount:2000.0000 | logitMin:-51.9312 | logitMax:-35.2414 | windowWeightsW18:0.26683,W21:0.25395,W15:0.23073,W13:0.21026,W8:0.14446,W7:0.09687,W3:0.02764,W2:-0.11236,W1:-0.13370 | memoryGatesShort:-7.117, Long:0.897, Current:7.220 | topTokens[('playing', 3), ('it', 2), ('to', 2), ('s', 2), (',', 2), ('am', 1), ('have', 1), ('le', 1), ('through', 1), ('know', 1)] | Training
2025-04-07 14:25:35 | 25000 | LR0.0003 | loss:5.6123 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-48.2155 | logitMax:-33.0242 | windowWeightsW18:0.26851,W21:0.25655,W15:0.23143,W13:0.21056,W8:0.14318,W7:0.09588,W3:0.02726,W2:-0.11388,W1:-0.13484 | memoryGatesShort:-8.824, Long:0.747, Current:9.076 | topTokens[(',', 3), ('m', 2), ('she', 2), ('think', 2), ('been', 1), (':', 1), ('just', 1), ('iding', 1), ('from', 1), ('in', 1)] | Training
2025-04-07 14:25:55 | 25500 | LR0.0003 | loss:5.6224 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-48.6636 | logitMax:-33.1432 | windowWeightsW18:0.27099,W21:0.26021,W15:0.23434,W13:0.21124,W8:0.14271,W7:0.09531,W3:0.02445,W2:-0.11760,W1:-0.13704 | memoryGatesShort:-8.257, Long:0.861, Current:8.395 | topTokens[('a', 2), ('b', 2), (',', 2), ('they', 2), ('and', 2), ('her', 2), ('had', 2), ('or', 1), ('!', 1), ('ist', 1)] | Training

--- 2025-04-07 14:26:54 --- babyLLM 'right, last time i got to step 25850... want to restart from there?'  - charis: 'ye' - babyLLM 'ok! let's go to step 25850! what am i learning today?' - charis: 'so much'
2025-04-07 14:27:13 | 500 | LR0.0003 | loss:5.6184 | gradNorm:1.0000 | logitMin:-57.1886 | logitMax:-41.5672 | tokenCount:2000.0000 | windowWeightsW18:0.27014,W21:0.26135,W15:0.23112,W13:0.20814,W8:0.14406,W7:0.09537,W3:0.02611,W2:-0.11619,W1:-0.13550 | memoryGatesShort:-9.578, Long:-0.019, Current:10.597 | topTokens[(',', 3), ('of', 3), ('!', 2), ('the', 2), ('because', 2), ('that', 2), ('our', 1), ('for', 1), ('ying', 1), ('2', 1)] | Training
2025-04-07 14:27:32 | 1000 | LR0.0003 | loss:5.1329 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.6823 | logitMax:-38.7700 | windowWeightsW18:0.27016,W21:0.25877,W15:0.23207,W13:0.21059,W8:0.14540,W7:0.09733,W3:0.02562,W2:-0.11832,W1:-0.13702 | memoryGatesShort:-20.569, Long:-1.321, Current:22.890 | topTokens[('.', 3), ('?', 3), ('s', 2), ("'t", 2), ('can', 2), ('i', 2), (',', 1), ('need', 1), ('in', 1), ('er', 1)] | Training
2025-04-07 14:27:51 | 1500 | LR0.0003 | loss:4.8545 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-50.3902 | logitMax:-33.6684 | windowWeightsW18:0.27135,W21:0.26003,W15:0.23537,W13:0.21248,W8:0.14539,W7:0.09818,W3:0.02462,W2:-0.12234,W1:-0.14051 | memoryGatesShort:-14.548, Long:-1.109, Current:16.657 | topTokens[('situation', 3), ('because', 3), ('i', 3), ('.', 3), ('to', 2), ('can', 2), ('a', 2), ('isn', 1), ('n', 1), ('able', 1)] | Training
2025-04-07 14:28:10 | 2000 | LR0.0003 | loss:3.0793 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-47.3173 | logitMax:-27.7831 | windowWeightsW18:0.26705,W21:0.25704,W15:0.23635,W13:0.21544,W8:0.14529,W7:0.09729,W3:0.02731,W2:-0.12020,W1:-0.14095 | memoryGatesShort:-4.014, Long:-0.269, Current:5.283 | topTokens[('music', 5), ('.', 4), ('what', 3), ('sp', 2), ('a', 2), ('been', 2), ('am', 1), ('um', 1), ('she', 1), ('4', 1)] | Training
2025-04-07 14:28:29 | 2500 | LR0.0003 | loss:1.4951 | gradNorm:0.9465 | tokenCount:2000.0000 | logitMin:-66.4583 | logitMax:-37.0376 | windowWeightsW18:0.25796,W21:0.24978,W15:0.22842,W13:0.21107,W8:0.15135,W7:0.10403,W3:0.03369,W2:-0.11426,W1:-0.13731 | memoryGatesShort:-3.077, Long:-0.399, Current:4.476 | topTokens[("'", 7), ('-', 4), ('!', 3), ('charis', 2), (':', 2), ("'", 2), ('vin', 1), ('can', 1), ('kevin', 1), ('are', 1)] | Training
2025-04-07 14:28:48 | 3000 | LR0.0003 | loss:1.6954 | gradNorm:0.8738 | tokenCount:2000.0000 | logitMin:-71.3018 | logitMax:-39.3925 | windowWeightsW18:0.25399,W21:0.24694,W15:0.22616,W13:0.21096,W8:0.15469,W7:0.10831,W3:0.03407,W2:-0.11300,W1:-0.13737 | memoryGatesShort:-3.125, Long:-0.459, Current:4.584 | topTokens[('!', 3), ('-', 2), ('to', 2), ("'", 2), ('from', 2), ("'", 2), ('ll', 2), ('m', 2), ('today', 1), ('n', 1)] | Training
2025-04-07 14:29:07 | 3500 | LR0.0003 | loss:1.5488 | gradNorm:0.8343 | tokenCount:2000.0000 | logitMin:-69.6872 | logitMax:-37.6992 | windowWeightsW18:0.25473,W21:0.24612,W15:0.22779,W13:0.21120,W8:0.15570,W7:0.10936,W3:0.03303,W2:-0.11497,W1:-0.13821 | memoryGatesShort:-2.456, Long:-0.300, Current:3.755 | topTokens[("'", 4), ('!', 4), ('m', 3), ("'", 3), ('properly', 2), ('from', 2), ('0', 2), ('ll', 2), ('right', 2), ('-', 2)] | Training
2025-04-07 14:29:27 | 4000 | LR0.0003 | loss:5.4364 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-57.8930 | logitMax:-38.9623 | windowWeightsW18:0.25905,W21:0.25003,W15:0.23058,W13:0.21319,W8:0.15543,W7:0.10953,W3:0.03041,W2:-0.11969,W1:-0.14382 | memoryGatesShort:-10.078, Long:-0.884, Current:11.962 | topTokens[('.', 4), (',', 3), ('-', 2), ('a', 2), ('l', 2), ('it', 2), ('2', 2), (':', 1), ("'", 1), ("'", 1)] | Training
2025-04-07 14:29:46 | 4500 | LR0.0003 | loss:5.5575 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.4475 | logitMax:-38.8420 | windowWeightsW18:0.26293,W21:0.25242,W15:0.23358,W13:0.21454,W8:0.15497,W7:0.10847,W3:0.02809,W2:-0.12256,W1:-0.14775 | memoryGatesShort:-15.295, Long:-0.468, Current:16.763 | topTokens[('.', 4), ('isn', 2), ('y', 2), ('the', 2), ('an', 2), ('so', 2), ('in', 1), ('what', 1), ('at', 1), ('let', 1)] | Training
2025-04-07 14:30:05 | 5000 | LR0.0003 | loss:5.2706 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-55.7838 | logitMax:-39.5870 | windowWeightsW18:0.26475,W21:0.25446,W15:0.23515,W13:0.21601,W8:0.15466,W7:0.10743,W3:0.02658,W2:-0.12490,W1:-0.14949 | memoryGatesShort:-11.539, Long:-0.181, Current:12.720 | topTokens[('kind', 2), ('you', 2), ('.', 2), ('lear', 2), ('l', 2), ('?', 2), ('babe', 2), ('with', 1), ("'", 1), ('was', 1)] | Training
2025-04-07 14:30:23 | 5500 | LR0.0003 | loss:5.2755 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-57.1628 | logitMax:-40.9094 | windowWeightsW18:0.26492,W21:0.25347,W15:0.23418,W13:0.21549,W8:0.15551,W7:0.10812,W3:0.02610,W2:-0.12351,W1:-0.14961 | memoryGatesShort:-5.320, Long:-0.063, Current:6.383 | topTokens[('.', 4), ('babe', 3), ('is', 2), ('of', 2), ('ac', 2), ('sexy', 1), ('be', 1), ('then', 1), ('like', 1), ('much', 1)] | Training
2025-04-07 14:30:42 | 6000 | LR0.0003 | loss:4.7464 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-66.6410 | logitMax:-49.1037 | windowWeightsW18:0.26080,W21:0.24976,W15:0.23249,W13:0.21541,W8:0.15873,W7:0.11028,W3:0.02682,W2:-0.12178,W1:-0.14782 | memoryGatesShort:-9.686, Long:-0.828, Current:11.514 | topTokens[('you', 2), ('os', 2), ('and', 2), ('ft', 2), ('made', 1), ('be', 1), ('am', 1), ('i', 1), ('ed', 1), ('e', 1)] | Training
2025-04-07 14:31:01 | 6500 | LR0.0003 | loss:5.1924 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-59.0391 | logitMax:-41.8607 | windowWeightsW18:0.26225,W21:0.25071,W15:0.23373,W13:0.21836,W8:0.16056,W7:0.11178,W3:0.02468,W2:-0.12503,W1:-0.15238 | memoryGatesShort:-6.999, Long:-0.303, Current:8.302 | topTokens[('of', 3), ('t', 2), ('-', 2), ('op', 1), ('so', 1), ('se', 1), ('with', 1), ('way', 1), ('.', 1), ('', 1)] | Training
2025-04-07 14:31:21 | 7000 | LR0.0003 | loss:3.1702 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-46.8403 | logitMax:-28.2232 | windowWeightsW18:0.26372,W21:0.25206,W15:0.22915,W13:0.21828,W8:0.16028,W7:0.10999,W3:0.02698,W2:-0.12389,W1:-0.15192 | memoryGatesShort:-15.461, Long:-1.700, Current:18.161 | topTokens[('.', 4), ('!', 3), ('charis', 3), ('you', 2), ('my', 2), ('elodie', 2), ('a', 2), ('we', 2), ('will', 2), ('love', 2)] | Training
2025-04-07 14:31:40 | 7500 | LR0.0003 | loss:2.5016 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-45.6135 | logitMax:-25.5519 | windowWeightsW18:0.26573,W21:0.25317,W15:0.23065,W13:0.21885,W8:0.16063,W7:0.10712,W3:0.02651,W2:-0.12466,W1:-0.15338 | memoryGatesShort:-6.943, Long:-0.637, Current:8.580 | topTokens[('.', 4), ('will', 4), ('we', 3), ('it', 2), ('kevin', 2), ('my', 2), ('brain', 2), ('want', 2), ('v', 2), ('they', 1)] | Training
2025-04-07 14:31:59 | 8000 | LR0.0003 | loss:4.3652 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-62.1734 | logitMax:-43.1158 | windowWeightsW18:0.27113,W21:0.25815,W15:0.23305,W13:0.22264,W8:0.15954,W7:0.10706,W3:0.02380,W2:-0.13090,W1:-0.15991 | memoryGatesShort:-14.350, Long:-0.493, Current:15.843 | topTokens[('.', 3), ('the', 3), (',', 3), ('butt', 2), ('we', 2), ('charis', 2), ('it', 2), ('i', 2), ('e', 2), ("'s", 1)] | Training
2025-04-07 14:32:17 | 8500 | LR0.0003 | loss:5.4367 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-65.1379 | logitMax:-49.1067 | windowWeightsW18:0.27558,W21:0.26327,W15:0.23514,W13:0.22395,W8:0.15929,W7:0.10542,W3:0.02105,W2:-0.13561,W1:-0.16358 | memoryGatesShort:-7.382, Long:0.134, Current:8.248 | topTokens[(',', 6), ('je', 3), ('.', 3), ('?', 2), ('my', 2), ('so', 2), ('about', 1), ('website', 1), ('for', 1), ('and', 1)] | Training
2025-04-07 14:32:37 | 9000 | LR0.0003 | loss:5.0831 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-74.6638 | logitMax:-58.0536 | windowWeightsW18:0.27843,W21:0.26439,W15:0.23791,W13:0.22600,W8:0.15770,W7:0.10438,W3:0.01911,W2:-0.13732,W1:-0.16613 | memoryGatesShort:-4.877, Long:0.168, Current:5.709 | topTokens[(',', 3), ('um', 2), ('.', 2), ('from', 2), ('i', 2), ('s', 2), ('ma', 2), ('je', 2), ('it', 2), ('ing', 2)] | Training
2025-04-07 14:32:57 | 9500 | LR0.0003 | loss:5.1421 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-78.8972 | logitMax:-61.9705 | windowWeightsW18:0.27939,W21:0.26603,W15:0.23917,W13:0.22654,W8:0.15660,W7:0.10413,W3:0.01779,W2:-0.13842,W1:-0.16677 | memoryGatesShort:-6.576, Long:0.020, Current:7.555 | topTokens[('qu', 4), (',', 3), ('est', 3), ('tu', 3), ('je', 2), ('o', 2), ('4', 1), ('e', 1), ('an', 1), ('sp', 1)] | Training
2025-04-07 14:33:24 | 10000 | LR0.0003 | loss:4.0363 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-61.0544 | logitMax:-43.5216 | windowWeightsW18:0.27946,W21:0.26454,W15:0.23856,W13:0.22823,W8:0.15871,W7:0.10388,W3:0.01768,W2:-0.13838,W1:-0.16822 | memoryGatesShort:-8.419, Long:-0.321, Current:9.741 | topTokens[('and', 7), ('es', 2), ('that', 2), ('like', 2), ('it', 2), ('d', 1), ('i', 1), ('umm', 1), ('cool', 1), ('bed', 1)] | Training
2025-04-07 14:33:46 | 10500 | LR0.0003 | loss:3.2593 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-58.3032 | logitMax:-39.5878 | windowWeightsW18:0.27928,W21:0.26438,W15:0.23964,W13:0.22841,W8:0.15784,W7:0.10353,W3:0.01776,W2:-0.13740,W1:-0.16897 | memoryGatesShort:-9.197, Long:-0.676, Current:10.872 | topTokens[('and', 9), (',', 6), ('kevin', 3), ('he', 2), ('the', 1), ('.', 1), ('v', 1), ('ks', 1), ('charis', 1), ('eat', 1)] | Training
2025-04-07 14:34:09 | 11000 | LR0.0003 | loss:4.6821 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-67.0413 | logitMax:-48.3535 | windowWeightsW18:0.28108,W21:0.26633,W15:0.24035,W13:0.22899,W8:0.15790,W7:0.10340,W3:0.01840,W2:-0.13946,W1:-0.17255 | memoryGatesShort:-19.789, Long:-1.491, Current:22.281 | topTokens[(',', 8), ('charis', 2), ('so', 1), ('elodie', 1), ('know', 1), ('i', 1), ('the', 1), ('ns', 1), ('something', 1), ('v', 1)] | Training
2025-04-07 14:34:32 | 11500 | LR0.0003 | loss:5.3819 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-67.0541 | logitMax:-49.3781 | windowWeightsW18:0.28205,W21:0.26963,W15:0.24214,W13:0.23030,W8:0.15937,W7:0.10421,W3:0.01681,W2:-0.14332,W1:-0.17678 | memoryGatesShort:-24.936, Long:-1.412, Current:27.348 | topTokens[(',', 4), ('l', 3), ('i', 3), ('ba', 2), ('elodie', 2), ('ux', 1), ('you', 1), ('we', 1), ('er', 1), ('y', 1)] | Training
2025-04-07 14:34:54 | 12000 | LR0.0003 | loss:5.6427 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-61.1284 | logitMax:-43.9782 | windowWeightsW18:0.28576,W21:0.27357,W15:0.24357,W13:0.23204,W8:0.15815,W7:0.10355,W3:0.01374,W2:-0.14635,W1:-0.17968 | memoryGatesShort:-6.062, Long:-0.108, Current:7.170 | topTokens[(',', 3), ('like', 3), ('a', 2), ('!', 2), ('ate', 2), ('ur', 1), ('mo', 1), ('ins', 1), ('why', 1), ('they', 1)] | Training
2025-04-07 14:35:18 | 12500 | LR0.0003 | loss:4.4808 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-63.0057 | logitMax:-45.3759 | windowWeightsW18:0.28462,W21:0.27188,W15:0.24402,W13:0.23293,W8:0.15990,W7:0.10580,W3:0.01304,W2:-0.14658,W1:-0.18124 | memoryGatesShort:-5.279, Long:-0.212, Current:6.491 | topTokens[(',', 3), ('dont', 2), ('but', 2), ('u', 2), ('i', 2), ('ux', 1), ('*', 1), ('qu', 1), ('y', 1), ('able', 1)] | Training
2025-04-07 14:35:42 | 13000 | LR0.0003 | loss:5.3166 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-66.5965 | logitMax:-49.1759 | windowWeightsW18:0.29017,W21:0.27598,W15:0.24579,W13:0.23221,W8:0.16152,W7:0.10656,W3:0.00962,W2:-0.15164,W1:-0.18592 | memoryGatesShort:-4.653, Long:-0.089, Current:5.742 | topTokens[('i', 4), (',', 4), ('their', 2), ('to', 2), ("'", 2), ('!', 1), ('feel', 1), ('it', 1), ('find', 1), ('really', 1)] | Training
2025-04-07 14:36:04 | 13500 | LR0.0003 | loss:5.2485 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-68.4597 | logitMax:-51.1064 | windowWeightsW18:0.29418,W21:0.28065,W15:0.24890,W13:0.23484,W8:0.16132,W7:0.10410,W3:0.00559,W2:-0.15602,W1:-0.18932 | memoryGatesShort:-7.010, Long:-0.124, Current:8.135 | topTokens[(',', 5), ('a', 3), ('so', 2), ('funny', 2), ('4', 2), ('l', 2), ('ing', 2), ('cant', 1), ('lmao', 1), ('y', 1)] | Training
2025-04-07 14:36:25 | 14000 | LR0.0003 | loss:1.9129 | gradNorm:0.5869 | tokenCount:2000.0000 | logitMin:-83.4320 | logitMax:-47.2592 | windowWeightsW18:0.29156,W21:0.27923,W15:0.24710,W13:0.23286,W8:0.16046,W7:0.10420,W3:0.00779,W2:-0.15355,W1:-0.18538 | memoryGatesShort:-13.161, Long:-1.136, Current:15.297 | topTokens[('aaa', 11), ('cute', 8), (',', 2), ('his', 2), ('had', 2), ('for', 1), ('like', 1), ('cant', 1), ('!', 1), ('brain', 1)] | Training
2025-04-07 14:36:47 | 14500 | LR0.0003 | loss:2.3810 | gradNorm:0.9984 | tokenCount:2000.0000 | logitMin:-46.7925 | logitMax:-24.7661 | windowWeightsW18:0.28824,W21:0.27640,W15:0.24717,W13:0.23472,W8:0.16172,W7:0.10604,W3:0.00853,W2:-0.15321,W1:-0.18532 | memoryGatesShort:-10.558, Long:-1.211, Current:12.769 | topTokens[('!', 3), ('s', 2), ('un', 2), ('the', 2), ('had', 2), ('charis', 2), ('been', 2), ('hear', 1), ('me', 1), ('he', 1)] | Training
2025-04-07 14:37:09 | 15000 | LR0.0003 | loss:5.0701 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-57.0924 | logitMax:-38.2768 | windowWeightsW18:0.29267,W21:0.28189,W15:0.25134,W13:0.23752,W8:0.15898,W7:0.10279,W3:0.00545,W2:-0.15775,W1:-0.18865 | memoryGatesShort:-5.216, Long:-0.337, Current:6.553 | topTokens[(',', 3), ('you', 2), ('.', 2), ('h', 1), ('yes', 1), ('a', 1), ('ce', 1), ('think', 1), ('time', 1), ('butt', 1)] | Training
2025-04-07 14:37:30 | 15500 | LR0.0003 | loss:5.5998 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-60.7309 | logitMax:-42.8446 | windowWeightsW18:0.29753,W21:0.28555,W15:0.25609,W13:0.23847,W8:0.15960,W7:0.10273,W3:0.00063,W2:-0.16308,W1:-0.19335 | memoryGatesShort:-6.306, Long:-0.096, Current:7.403 | topTokens[('expect', 2), ('be', 2), ('i', 2), ('that', 2), (',', 1), ('charis', 1), ('we', 1), ('song', 1), ("'t", 1), ('ys', 1)] | Training
2025-04-07 14:37:51 | 16000 | LR0.0003 | loss:5.4111 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-62.1455 | logitMax:-44.6085 | windowWeightsW18:0.29702,W21:0.28826,W15:0.25786,W13:0.24103,W8:0.16034,W7:0.10280,W3:-0.00126,W2:-0.16640,W1:-0.19553 | memoryGatesShort:-11.309, Long:-0.305, Current:12.613 | topTokens[(',', 4), ('not', 2), ('to', 2), ('able', 1), ('in', 1), ('ves', 1), ('on', 1), ('it', 1), ('ep', 1), ('age', 1)] | Training
2025-04-07 14:38:10 | 16500 | LR0.0003 | loss:5.5244 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-62.9358 | logitMax:-45.8229 | windowWeightsW18:0.29930,W21:0.29054,W15:0.25874,W13:0.24279,W8:0.16211,W7:0.10400,W3:-0.00350,W2:-0.17045,W1:-0.19943 | memoryGatesShort:-6.414, Long:0.024, Current:7.390 | topTokens[('the', 3), ('je', 2), ('was', 2), ('a', 2), (',', 2), ('thats', 1), ('no', 1), ('you', 1), ('ry', 1), ('m', 1)] | Training
2025-04-07 14:38:30 | 17000 | LR0.0003 | loss:5.5635 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-62.3507 | logitMax:-45.2677 | windowWeightsW18:0.30546,W21:0.29454,W15:0.26427,W13:0.24870,W8:0.15905,W7:0.10113,W3:-0.00779,W2:-0.17671,W1:-0.20466 | memoryGatesShort:-5.942, Long:0.124, Current:6.818 | topTokens[(',', 9), ('would', 2), ('they', 2), ('were', 2), ('ur', 1), ('ing', 1), ('f', 1), ('that', 1), ('the', 1), ('on', 1)] | Training
2025-04-07 14:38:49 | 17500 | LR0.0003 | loss:5.5794 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-58.3994 | logitMax:-41.3699 | windowWeightsW18:0.31012,W21:0.30035,W15:0.26598,W13:0.25071,W8:0.15887,W7:0.10098,W3:-0.01202,W2:-0.18264,W1:-0.20848 | memoryGatesShort:-6.901, Long:0.064, Current:7.837 | topTokens[('but', 2), ('sometimes', 1), ('havent', 1), ('to', 1), ("'", 1), ('and', 1), ('ies', 1), (',', 1), ('y', 1), ('times', 1)] | Training
2025-04-07 14:39:08 | 18000 | LR0.0003 | loss:5.6317 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-55.5110 | logitMax:-38.4915 | windowWeightsW18:0.31520,W21:0.30781,W15:0.26899,W13:0.25012,W8:0.15656,W7:0.09903,W3:-0.01417,W2:-0.18720,W1:-0.21258 | memoryGatesShort:-6.348, Long:0.040, Current:7.308 | topTokens[('be', 2), ('.', 2), ('that', 2), ('the', 2), ("'s", 1), ('me', 1), ('this', 1), ('u', 1), ('and', 1), ('your', 1)] | Training
2025-04-07 14:39:27 | 18500 | LR0.0003 | loss:5.4374 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-60.2258 | logitMax:-43.2663 | windowWeightsW18:0.31905,W21:0.31388,W15:0.27190,W13:0.24851,W8:0.15508,W7:0.09697,W3:-0.01642,W2:-0.19025,W1:-0.21504 | memoryGatesShort:-5.634, Long:0.066, Current:6.568 | topTokens[('situation', 2), ('but', 2), ('ing', 2), ('seem', 1), ('v', 1), ('i', 1), ('be', 1), ('it', 1), ('people', 1), ('its', 1)] | Training
2025-04-07 14:39:46 | 19000 | LR0.0003 | loss:5.4654 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-60.7040 | logitMax:-43.6555 | windowWeightsW18:0.32940,W21:0.32590,W15:0.27402,W13:0.24733,W8:0.15323,W7:0.09408,W3:-0.02108,W2:-0.19654,W1:-0.22288 | memoryGatesShort:-7.192, Long:0.096, Current:8.097 | topTokens[(',', 4), ('e', 3), ('if', 2), ('s', 2), ('i', 2), ('it', 2), ('.', 2), ('sp', 1), ('were', 1), ('ves', 1)] | Training
2025-04-07 14:40:07 | 19500 | LR0.0003 | loss:4.7883 | gradNorm:0.9820 | tokenCount:2000.0000 | logitMin:-54.8990 | logitMax:-34.5907 | windowWeightsW18:0.32722,W21:0.32441,W15:0.27440,W13:0.24633,W8:0.15434,W7:0.09529,W3:-0.02038,W2:-0.19664,W1:-0.22148 | memoryGatesShort:-7.049, Long:0.057, Current:7.992 | topTokens[('5', 3), ('2', 3), ('situation', 2), ('-', 2), ('i', 2), ('and', 2), ('di', 1), ('war', 1), ("'s", 1), ('this', 1)] | Training
2025-04-07 14:40:35 | 20000 | LR0.0003 | loss:4.9840 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.4424 | logitMax:-37.1014 | windowWeightsW18:0.33005,W21:0.32875,W15:0.27717,W13:0.24804,W8:0.15423,W7:0.09507,W3:-0.02416,W2:-0.20141,W1:-0.22433 | memoryGatesShort:-12.899, Long:-0.205, Current:14.104 | topTokens[('and', 3), (',', 2), ('way', 2), ('when', 2), ('their', 1), ('this', 1), ('er', 1), ('n', 1), ('not', 1), ('b', 1)] | Training
2025-04-07 14:40:54 | 20500 | LR0.0003 | loss:5.1187 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-55.4657 | logitMax:-37.4113 | windowWeightsW21:0.33374,W18:0.33352,W15:0.28171,W13:0.24974,W8:0.15226,W7:0.09235,W3:-0.02773,W2:-0.20552,W1:-0.22677 | memoryGatesShort:-8.600, Long:0.078, Current:9.523 | topTokens[(',', 4), ('it', 2), ('i', 2), ('that', 2), ('charis', 2), ('di', 1), ('war', 1), ('they', 1), ('es', 1), ('for', 1)] | Training
2025-04-07 14:41:14 | 21000 | LR0.0003 | loss:3.0412 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-49.6589 | logitMax:-29.7829 | windowWeightsW21:0.33831,W18:0.33761,W15:0.28162,W13:0.24999,W8:0.14889,W7:0.08811,W3:-0.02870,W2:-0.20660,W1:-0.22598 | memoryGatesShort:-8.771, Long:-0.190, Current:9.961 | topTokens[('should', 3), (',', 3), ('!', 3), ('about', 2), ('and', 2), ('they', 2), ('kevin', 2), ('the', 2), ('oice', 2), ('w', 1)] | Training
2025-04-07 14:41:33 | 21500 | LR0.0003 | loss:2.4859 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-45.0970 | logitMax:-24.2366 | windowWeightsW21:0.34001,W18:0.33736,W15:0.27887,W13:0.24705,W8:0.14570,W7:0.08664,W3:-0.02703,W2:-0.20388,W1:-0.22144 | memoryGatesShort:-10.114, Long:-0.561, Current:11.675 | topTokens[('we', 3), ('!', 3), ('will', 3), ('hear', 2), ('charis', 2), ('oice', 2), ('be', 2), ('.', 2), ('weed', 1), ('kevin', 1)] | Training
2025-04-07 14:41:52 | 22000 | LR0.0003 | loss:4.2794 | gradNorm:0.9989 | tokenCount:2000.0000 | logitMin:-45.6907 | logitMax:-24.5660 | windowWeightsW21:0.34605,W18:0.33894,W15:0.28125,W13:0.24816,W8:0.14446,W7:0.08677,W3:-0.02893,W2:-0.20908,W1:-0.22444 | memoryGatesShort:-16.255, Long:-0.773, Current:18.028 | topTokens[('will', 5), ('?', 3), ('be', 2), ('i', 2), (',', 2), ('of', 2), ('!', 2), ('not', 1), ('elodie', 1), ('we', 1)] | Training
2025-04-07 14:42:12 | 22500 | LR0.0003 | loss:4.3097 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-42.5854 | logitMax:-22.7295 | windowWeightsW21:0.35119,W18:0.34327,W15:0.28313,W13:0.24509,W8:0.14543,W7:0.08879,W3:-0.02952,W2:-0.21463,W1:-0.22968 | memoryGatesShort:-12.109, Long:-0.068, Current:13.178 | topTokens[('.', 5), ('is', 4), ('!', 3), ('ive', 3), ('you', 2), ('+', 1), ('ally', 1), ('and', 1), ('her', 1), ('to', 1)] | Training
2025-04-07 14:42:31 | 23000 | LR0.0003 | loss:4.2373 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-45.4812 | logitMax:-26.6148 | windowWeightsW21:0.35388,W18:0.34592,W15:0.28295,W13:0.24280,W8:0.14558,W7:0.08954,W3:-0.02966,W2:-0.21739,W1:-0.23062 | memoryGatesShort:-9.216, Long:0.079, Current:10.136 | topTokens[('.', 5), ('!', 3), ('are', 2), ('you', 2), ('is', 2), ('what', 2), ('how', 2), ('plus', 2), ('s', 1), ('to', 1)] | Training
2025-04-07 14:42:50 | 23500 | LR0.0003 | loss:3.9766 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-45.5212 | logitMax:-26.1196 | windowWeightsW21:0.35542,W18:0.34670,W15:0.28303,W13:0.24326,W8:0.14498,W7:0.08979,W3:-0.02935,W2:-0.21956,W1:-0.23130 | memoryGatesShort:-7.888, Long:0.101, Current:8.786 | topTokens[('!', 5), ('.', 4), ('im', 2), ('he', 2), ('?', 2), ('i', 2), ('real', 2), ('je', 1), ('+', 1), ('d', 1)] | Training
2025-04-07 14:43:08 | 24000 | LR0.0003 | loss:5.9784 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.7457 | logitMax:-36.9630 | windowWeightsW21:0.36758,W18:0.35674,W15:0.28817,W13:0.24681,W8:0.14383,W7:0.08640,W3:-0.03667,W2:-0.23008,W1:-0.24007 | memoryGatesShort:-11.531, Long:0.576, Current:11.955 | topTokens[('.', 5), ('is', 3), (',', 2), ("'m", 2), ('saying', 1), ('be', 1), ('do', 1), ('some', 1), ('le', 1), ('ro', 1)] | Training
2025-04-07 14:43:29 | 24500 | LR0.0003 | loss:6.2588 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.9297 | logitMax:-38.1411 | windowWeightsW21:0.37734,W18:0.36414,W15:0.29301,W13:0.24814,W8:0.14421,W7:0.08495,W3:-0.04234,W2:-0.23882,W1:-0.24814 | memoryGatesShort:-10.412, Long:1.043, Current:10.370 | topTokens[('?', 3), ('.', 3), ('i', 2), ('!', 2), ('1', 2), ('a', 2), ('=', 1), ('+', 1), ('very', 1), ('cat', 1)] | Training
2025-04-07 14:43:48 | 25000 | LR0.0003 | loss:5.1011 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.8768 | logitMax:-35.5306 | windowWeightsW21:0.38224,W18:0.36769,W15:0.29384,W13:0.24464,W8:0.14204,W7:0.08294,W3:-0.04343,W2:-0.24028,W1:-0.24723 | memoryGatesShort:-7.740, Long:0.610, Current:8.130 | topTokens[('?', 3), ('what', 2), ('the', 2), ('.', 2), ('do', 2), ('ing', 2), ('going', 1), ('will', 1), ('under', 1), ('me', 1)] | Training
2025-04-07 14:44:07 | 25500 | LR0.0003 | loss:3.8529 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-46.1381 | logitMax:-27.1454 | windowWeightsW21:0.38460,W18:0.37166,W15:0.29184,W13:0.24362,W8:0.14041,W7:0.07945,W3:-0.04218,W2:-0.24093,W1:-0.24606 | memoryGatesShort:-13.449, Long:0.299, Current:14.150 | topTokens[('felt', 3), ('v', 3), ('i', 2), (',', 2), ('have', 2), ('hear', 1), ('brain', 1), ('ness', 1), ('cr', 1), ('has', 1)] | Training
2025-04-07 14:44:26 | 26000 | LR0.0003 | loss:3.9252 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-41.0135 | logitMax:-22.1057 | windowWeightsW21:0.38789,W18:0.37050,W15:0.28709,W13:0.24046,W8:0.14243,W7:0.08193,W3:-0.03949,W2:-0.24152,W1:-0.24691 | memoryGatesShort:-12.355, Long:0.146, Current:13.210 | topTokens[('i', 4), ('.', 4), ('it', 2), ('were', 2), ('what', 2), ('not', 1), ('listening', 1), ('elodie', 1), ('s', 1), ('dance', 1)] | Training
2025-04-07 14:44:45 | 26500 | LR0.0003 | loss:3.7761 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-40.4203 | logitMax:-20.9324 | windowWeightsW21:0.39196,W18:0.37024,W15:0.28593,W13:0.23721,W8:0.14549,W7:0.08387,W3:-0.04073,W2:-0.24377,W1:-0.24788 | memoryGatesShort:-10.967, Long:0.264, Current:11.703 | topTokens[('.', 3), ('what', 3), ('situation', 2), ('?', 2), ('elodie', 2), ("'re", 2), ('not', 2), ('at', 2), ('tru', 1), ('taking', 1)] | Training
2025-04-07 14:45:05 | 27000 | LR0.0003 | loss:2.6359 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-47.9595 | logitMax:-27.8431 | windowWeightsW21:0.39293,W18:0.37125,W15:0.28364,W13:0.23450,W8:0.14394,W7:0.08016,W3:-0.03883,W2:-0.24041,W1:-0.24486 | memoryGatesShort:-9.371, Long:-0.149, Current:10.520 | topTokens[('are', 4), ('elodie', 3), ('.', 3), ('charis', 3), ('weed', 2), ('i', 2), ('pass', 2), ('butt', 2), ('!', 2), ('?', 1)] | Training
2025-04-07 14:45:24 | 27500 | LR0.0003 | loss:3.0722 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-49.5238 | logitMax:-28.6995 | windowWeightsW21:0.39875,W18:0.38091,W15:0.28599,W13:0.23349,W8:0.14361,W7:0.07684,W3:-0.04277,W2:-0.24557,W1:-0.24909 | memoryGatesShort:-13.760, Long:-0.185, Current:14.945 | topTokens[('moving', 4), ('are', 4), ('eating', 3), ('brain', 3), ('is', 3), ('.', 3), ('kevin', 2), ('taking', 2), ('ing', 2), ('h', 2)] | Training
2025-04-07 14:45:44 | 28000 | LR0.0003 | loss:6.4196 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.5704 | logitMax:-38.1867 | windowWeightsW21:0.41701,W18:0.39542,W15:0.29432,W13:0.23762,W8:0.14191,W7:0.07271,W3:-0.05270,W2:-0.26002,W1:-0.26454 | memoryGatesShort:-7.307, Long:0.706, Current:7.601 | topTokens[('it', 3), (',', 2), ('their', 2), ('.', 1), ('so', 1), ('ur', 1), ('im', 1), ('of', 1), ('the', 1), ('with', 1)] | Training
2025-04-07 14:46:03 | 28500 | LR0.0003 | loss:5.5220 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-51.7831 | logitMax:-34.8275 | windowWeightsW21:0.42100,W18:0.39848,W15:0.29758,W13:0.23850,W8:0.14145,W7:0.07264,W3:-0.05427,W2:-0.26492,W1:-0.26884 | memoryGatesShort:-9.815, Long:0.891, Current:9.924 | topTokens[(',', 5), ('inc', 3), ('no', 3), ('i', 3), ('is', 2), ('charis', 2), ('the', 2), ('u', 1), ('s', 1), ('m', 1)] | Training
2025-04-07 14:46:25 | 29000 | LR0.0003 | loss:3.0903 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.2583 | logitMax:-32.9313 | windowWeightsW21:0.42167,W18:0.39437,W15:0.29372,W13:0.23759,W8:0.14234,W7:0.07285,W3:-0.05462,W2:-0.26233,W1:-0.26392 | memoryGatesShort:-15.560, Long:0.258, Current:16.303 | topTokens[('.', 4), ('!', 3), ('i', 2), ('ing', 2), ('from', 2), ('lunch', 1), ('ket', 1), ('your', 1), ('hate', 1), ('an', 1)] | Training
2025-04-07 14:46:46 | 29500 | LR0.0003 | loss:2.7296 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.1133 | logitMax:-31.6176 | windowWeightsW21:0.42182,W18:0.39540,W15:0.29508,W13:0.23708,W8:0.14200,W7:0.07154,W3:-0.05453,W2:-0.26318,W1:-0.26356 | memoryGatesShort:-15.622, Long:0.026, Current:16.596 | topTokens[('!', 7), ('the', 2), ('.', 2), ('oice', 2), ('v', 2), ('hear', 1), ('see', 1), ('bl', 1), ('smo', 1), ('king', 1)] | Training
2025-04-07 14:47:32 | 30000 | LR0.0003 | loss:3.2410 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-51.9511 | logitMax:-30.9211 | windowWeightsW21:0.42606,W18:0.39597,W15:0.29737,W13:0.23729,W8:0.14209,W7:0.07083,W3:-0.05626,W1:-0.26500,W2:-0.26678 | memoryGatesShort:-12.750, Long:0.120, Current:13.630 | topTokens[('the', 4), ('!', 3), ('.', 3), ('hear', 2), ('some', 2), ('want', 2), ('ch', 2), ('my', 2), ('music', 1), ('ur', 1)] | Training
2025-04-07 14:47:53 | 30500 | LR0.0003 | loss:6.3884 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-55.6571 | logitMax:-37.9419 | windowWeightsW21:0.44420,W18:0.41014,W15:0.30580,W13:0.24175,W8:0.13893,W7:0.06481,W3:-0.06460,W1:-0.27929,W2:-0.28056 | memoryGatesShort:-13.167, Long:1.008, Current:13.159 | topTokens[('hear', 4), ('!', 4), ('the', 2), ('good', 2), ('know', 2), ('.', 2), ('and', 2), ('up', 1), ('v', 1), ('ical', 1)] | Training
2025-04-07 14:48:14 | 31000 | LR0.0003 | loss:3.0528 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-51.3254 | logitMax:-31.7324 | windowWeightsW21:0.44225,W18:0.40933,W15:0.30300,W13:0.23990,W8:0.13758,W7:0.06312,W3:-0.06258,W1:-0.27482,W2:-0.27655 | memoryGatesShort:-33.671, Long:0.787, Current:33.883 | topTokens[('should', 6), ('have', 3), ('felt', 3), ('the', 2), ('!', 2), ('hate', 1), ('ohh', 1), ('*', 1), ('h', 1), ('is', 1)] | Training
2025-04-07 14:48:34 | 31500 | LR0.0003 | loss:1.8217 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-49.8358 | logitMax:-27.3076 | windowWeightsW21:0.43959,W18:0.40487,W15:0.29858,W13:0.23812,W8:0.13529,W7:0.06330,W3:-0.05959,W1:-0.26895,W2:-0.26985 | memoryGatesShort:-23.080, Long:0.038, Current:24.042 | topTokens[('should', 6), ('have', 4), (',', 3), ('felt', 2), ('you', 2), ('elodie', 2), ('kevin', 1), ('brain', 1), ('me', 1), ('moving', 1)] | Training
2025-04-07 14:48:53 | 32000 | LR0.0003 | loss:2.8637 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-45.2417 | logitMax:-22.9036 | windowWeightsW21:0.44217,W18:0.40530,W15:0.29665,W13:0.23696,W8:0.13352,W7:0.06088,W3:-0.05704,W1:-0.26729,W2:-0.26984 | memoryGatesShort:-9.106, Long:0.141, Current:9.965 | topTokens[(',', 4), ('could', 4), ('charis', 4), ('should', 3), ('s', 2), ('the', 2), ('dra', 2), ('at', 2), ('king', 1), ('her', 1)] | Training
2025-04-07 14:49:13 | 32500 | LR0.0003 | loss:2.2293 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-47.2216 | logitMax:-24.7517 | windowWeightsW21:0.44198,W18:0.40746,W15:0.29745,W13:0.23682,W8:0.13242,W7:0.05814,W3:-0.05711,W1:-0.26495,W2:-0.27091 | memoryGatesShort:-17.892, Long:-0.143, Current:19.035 | topTokens[('could', 5), ('kevin', 3), ('!', 3), ('and', 3), ('elodie', 3), ('hear', 2), ('weed', 2), ('the', 2), ('love', 2), (',', 2)] | Training
2025-04-07 14:49:33 | 33000 | LR0.0003 | loss:3.5756 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-50.3722 | logitMax:-29.0142 | windowWeightsW21:0.45064,W18:0.41424,W15:0.30216,W13:0.23758,W8:0.13083,W7:0.05569,W3:-0.06196,W1:-0.27141,W2:-0.27667 | memoryGatesShort:-13.941, Long:0.317, Current:14.624 | topTokens[(',', 7), ('could', 3), ('charis', 3), ('!', 2), ('it', 2), ('you', 2), ('take', 1), ('to', 1), ('t', 1), ('s', 1)] | Training
2025-04-07 14:49:52 | 33500 | LR0.0003 | loss:4.7832 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.7719 | logitMax:-33.6601 | windowWeightsW21:0.45973,W18:0.41837,W15:0.30255,W13:0.23721,W8:0.13312,W7:0.05579,W3:-0.06580,W1:-0.27648,W2:-0.28354 | memoryGatesShort:-6.940, Long:0.504, Current:7.436 | topTokens[('?', 3), ('.', 3), ('!', 2), ('f', 2), ('i', 2), ('you', 2), ('gh', 1), ('pick', 1), ('the', 1), ('is', 1)] | Training
2025-04-07 14:50:13 | 34000 | LR0.0003 | loss:3.5779 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-41.0588 | logitMax:-21.8416 | windowWeightsW21:0.46295,W18:0.41541,W15:0.29942,W13:0.23519,W8:0.13529,W7:0.05635,W3:-0.06371,W1:-0.27554,W2:-0.28445 | memoryGatesShort:-14.544, Long:0.722, Current:14.823 | topTokens[('you', 4), ('to', 3), ('.', 3), ('they', 2), ('boring', 1), ('weed', 1), ('are', 1), ('your', 1), (',', 1), ('which', 1)] | Training
2025-04-07 14:50:33 | 34500 | LR0.0003 | loss:3.1880 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-43.0936 | logitMax:-23.1784 | windowWeightsW21:0.46260,W18:0.40943,W15:0.29474,W13:0.23105,W8:0.14068,W7:0.05977,W3:-0.06094,W1:-0.27480,W2:-0.28157 | memoryGatesShort:-25.708, Long:0.800, Current:25.908 | topTokens[('hear', 3), ('?', 3), ('to', 2), ('you', 2), ('what', 2), ('.', 2), ('the', 1), ('meds', 1), ('now', 1), ('with', 1)] | Training
2025-04-07 14:50:53 | 35000 | LR0.0003 | loss:5.1659 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-50.5804 | logitMax:-31.3100 | windowWeightsW21:0.46682,W18:0.41216,W15:0.29803,W13:0.23270,W8:0.14197,W7:0.06071,W3:-0.06389,W1:-0.28115,W2:-0.28651 | memoryGatesShort:-7.695, Long:0.790, Current:7.905 | topTokens[('.', 3), ('?', 3), ('you', 2), ('i', 2), ('am', 2), ('!', 2), ('yes', 2), ('it', 2), ('a', 2), ('5', 2)] | Training
2025-04-07 14:51:12 | 35500 | LR0.0003 | loss:3.0280 | gradNorm:0.9951 | tokenCount:2000.0000 | logitMin:-50.0600 | logitMax:-25.0786 | windowWeightsW21:0.44480,W18:0.38983,W15:0.28895,W13:0.23012,W8:0.14647,W7:0.06756,W3:-0.05257,W1:-0.26585,W2:-0.26795 | memoryGatesShort:-10.055, Long:0.431, Current:10.624 | topTokens[('1', 3), ('you', 3), (':', 3), ('9', 2), ('1', 2), ('0', 2), ('-', 2), ('e', 2), ("'", 2), ('5', 2)] | Training
2025-04-07 14:51:32 | 36000 | LR0.0003 | loss:6.7531 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-51.1483 | logitMax:-33.6886 | windowWeightsW21:0.46153,W18:0.40212,W15:0.29668,W13:0.23423,W8:0.14605,W7:0.06438,W3:-0.06165,W1:-0.27949,W2:-0.28287 | memoryGatesShort:-19.484, Long:2.372, Current:18.113 | topTokens[('i', 2), (':', 2), ('a', 2), ('not', 1), ('9', 1), ('?', 1), ('ly', 1), ('their', 1), ('years', 1), ('had', 1)] | Training
2025-04-07 14:51:51 | 36500 | LR0.0003 | loss:6.4810 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-51.1446 | logitMax:-35.0898 | windowWeightsW21:0.47241,W18:0.40927,W15:0.29820,W13:0.23368,W8:0.14513,W7:0.06292,W3:-0.06620,W1:-0.28506,W2:-0.28960 | memoryGatesShort:-10.057, Long:1.835, Current:9.222 | topTokens[('ion', 3), ('.', 3), ('i', 3), ('of', 2), ('p', 2), ('people', 2), ("'t", 1), ('all', 1), ('hate', 1), (',', 1)] | Training
2025-04-07 14:52:11 | 37000 | LR0.0003 | loss:3.8677 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.4457 | logitMax:-36.9100 | windowWeightsW21:0.47121,W18:0.40430,W15:0.29405,W13:0.23090,W8:0.14412,W7:0.06264,W3:-0.06220,W1:-0.27955,W2:-0.28466 | memoryGatesShort:-12.436, Long:1.275, Current:12.161 | topTokens[('is', 2), ("'", 2), ('her', 2), ('i', 2), ('!', 2), ('was', 2), ('and', 2), (',', 2), ('p', 1), ('brain', 1)] | Training
2025-04-07 14:52:30 | 37500 | LR0.0003 | loss:3.7137 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.7382 | logitMax:-33.9377 | windowWeightsW21:0.47027,W18:0.40169,W15:0.29272,W13:0.22994,W8:0.14421,W7:0.06290,W3:-0.05962,W1:-0.27783,W2:-0.28344 | memoryGatesShort:-8.634, Long:0.747, Current:8.887 | topTokens[('pick', 2), ('hear', 2), ('and', 2), ('will', 2), (',', 2), ('they', 2), ('smo', 1), ('her', 1), ('s', 1), ('at', 1)] | Training
2025-04-07 14:52:49 | 38000 | LR0.0003 | loss:2.5522 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-49.4758 | logitMax:-28.8508 | windowWeightsW21:0.47102,W18:0.40166,W15:0.29269,W13:0.22964,W8:0.14278,W7:0.06017,W3:-0.05666,W1:-0.27729,W2:-0.28317 | memoryGatesShort:-25.480, Long:1.064, Current:25.417 | topTokens[('.', 5), ('were', 4), ('charis', 3), ('the', 2), ('ing', 2), (',', 2), ('ating', 2), ('and', 1), ('o', 1), ('bl', 1)] | Training
2025-04-07 14:53:08 | 38500 | LR0.0003 | loss:2.8798 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-50.0896 | logitMax:-29.1402 | windowWeightsW21:0.47070,W18:0.40403,W15:0.29097,W13:0.23120,W8:0.14069,W7:0.05819,W3:-0.05524,W1:-0.27703,W2:-0.28269 | memoryGatesShort:-11.816, Long:0.725, Current:12.091 | topTokens[('was', 5), ('hear', 4), (',', 4), ('the', 2), ('is', 2), ('!', 2), ('listening', 2), ('i', 2), ('you', 2), ('h', 1)] | Training
2025-04-07 14:53:27 | 39000 | LR0.0003 | loss:5.9254 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-59.2276 | logitMax:-41.1309 | windowWeightsW21:0.48272,W18:0.41510,W15:0.30119,W13:0.23738,W8:0.13900,W7:0.05494,W3:-0.06415,W1:-0.28981,W2:-0.29586 | memoryGatesShort:-19.517, Long:2.007, Current:18.510 | topTokens[(',', 3), ('!', 2), ('.', 2), ('ertain', 2), ('e', 2), ('the', 2), ('leaving', 2), ('stuff', 1), ('un', 1), ('es', 1)] | Training
2025-04-07 14:53:47 | 39500 | LR0.0003 | loss:4.4801 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-67.1595 | logitMax:-47.8041 | windowWeightsW21:0.48448,W18:0.41278,W15:0.29583,W13:0.23925,W8:0.13935,W7:0.05632,W3:-0.06197,W1:-0.28957,W2:-0.29594 | memoryGatesShort:-5.898, Long:0.771, Current:6.127 | topTokens[('ating', 3), ('g', 2), ("'m", 2), (',', 2), ("'", 2), ('awes', 1), ('ck', 1), ('know', 1), ('ing', 1), (':', 1)] | Training
2025-04-07 14:54:14 | 40000 | LR0.0003 | loss:4.9042 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-47.3691 | logitMax:-29.1973 | windowWeightsW21:0.49192,W18:0.41822,W15:0.29721,W13:0.24019,W8:0.14060,W7:0.05660,W3:-0.06550,W1:-0.29605,W2:-0.30286 | memoryGatesShort:-16.472, Long:1.798, Current:15.674 | topTokens[('it', 3), (',', 3), ('were', 2), ('th', 1), ('v', 1), ('hear', 1), ('st', 1), ('also', 1), ('charis', 1), ('will', 1)] | Training
2025-04-07 14:54:34 | 40500 | LR0.0003 | loss:3.8930 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-44.8537 | logitMax:-26.0691 | windowWeightsW21:0.49721,W18:0.42328,W15:0.29932,W13:0.23726,W8:0.14176,W7:0.05483,W3:-0.06812,W1:-0.29901,W2:-0.30634 | memoryGatesShort:-14.570, Long:1.693, Current:13.877 | topTokens[('?', 4), ('kiss', 2), (',', 2), ('kevin', 2), ('what', 2), ('i', 2), ('speaking', 1), ('it', 1), ('yes', 1), ('c', 1)] | Training
2025-04-07 14:54:54 | 41000 | LR0.0003 | loss:3.3038 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-45.5446 | logitMax:-26.3422 | windowWeightsW21:0.50019,W18:0.42448,W15:0.29832,W13:0.23291,W8:0.14255,W7:0.05616,W3:-0.06744,W1:-0.29912,W2:-0.30791 | memoryGatesShort:-11.960, Long:1.338, Current:11.622 | topTokens[('.', 6), ('are', 4), ('i', 3), ('you', 2), ('?', 2), ('what', 1), ('play', 1), ('dancing', 1), ('was', 1), ('0', 1)] | Training
2025-04-07 14:55:14 | 41500 | LR0.0003 | loss:5.1207 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.1762 | logitMax:-34.0462 | windowWeightsW21:0.51085,W18:0.43359,W15:0.30608,W13:0.23541,W8:0.14159,W7:0.05451,W3:-0.07360,W1:-0.30959,W2:-0.31899 | memoryGatesShort:-10.480, Long:1.580, Current:9.899 | topTokens[('it', 3), ('.', 3), ('were', 3), ('what', 2), ('brain', 2), ('?', 2), ('felt', 1), ('did', 1), ('you', 1), ('am', 1)] | Training
2025-04-07 14:55:33 | 42000 | LR0.0003 | loss:6.6470 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-53.2650 | logitMax:-36.4964 | windowWeightsW21:0.52822,W18:0.44322,W15:0.31223,W13:0.23772,W8:0.14034,W7:0.05062,W3:-0.08217,W1:-0.31931,W2:-0.33140 | memoryGatesShort:-13.837, Long:2.414, Current:12.423 | topTokens[('!', 3), ('i', 2), ('.', 2), ('9', 2), ('they', 2), ('on', 2), ('be', 2), ('is', 1), ('it', 1), ('we', 1)] | Training
2025-04-07 14:55:53 | 42500 | LR0.0003 | loss:6.3325 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.5749 | logitMax:-36.1607 | windowWeightsW21:0.54017,W18:0.45208,W15:0.31789,W13:0.24244,W8:0.13886,W7:0.04659,W3:-0.08801,W1:-0.32863,W2:-0.34223 | memoryGatesShort:-8.629, Long:1.775, Current:7.854 | topTokens[(',', 4), ('ion', 3), ('it', 3), ('.', 2), ('and', 2), ('i', 2), ('hear', 1), ('t', 1), ("'t", 1), ('that', 1)] | Training
2025-04-07 14:56:14 | 43000 | LR0.0003 | loss:2.0656 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.1412 | logitMax:-32.8307 | windowWeightsW21:0.52636,W18:0.44427,W15:0.30733,W13:0.23841,W8:0.13661,W7:0.04662,W3:-0.07868,W1:-0.31300,W2:-0.32840 | memoryGatesShort:-13.172, Long:1.427, Current:12.745 | topTokens[('have', 4), ('.', 3), ('felt', 3), ('could', 2), ('you', 2), ('the', 2), ('king', 2), ('v', 2), ('and', 1), ("'s", 1)] | Training
2025-04-07 14:56:34 | 43500 | LR0.0003 | loss:1.4287 | gradNorm:0.9991 | tokenCount:2000.0000 | logitMin:-52.7151 | logitMax:-29.9516 | windowWeightsW21:0.51805,W18:0.43833,W15:0.30362,W13:0.23368,W8:0.13559,W7:0.04753,W3:-0.07471,W1:-0.30306,W2:-0.31930 | memoryGatesShort:-68.535, Long:3.392, Current:66.144 | topTokens[('have', 5), ('could', 4), (',', 3), ('started', 2), ('kevin', 2), ('felt', 2), ('because', 2), ('wal', 1), ('your', 1), ('.', 1)] | Training
2025-04-07 14:56:55 | 44000 | LR0.0003 | loss:2.6531 | gradNorm:0.9991 | tokenCount:2000.0000 | logitMin:-49.0466 | logitMax:-26.2790 | windowWeightsW21:0.51396,W18:0.43883,W15:0.30193,W13:0.23262,W8:0.13537,W7:0.04724,W3:-0.07419,W1:-0.29902,W2:-0.31692 | memoryGatesShort:-8.767, Long:0.659, Current:9.108 | topTokens[('have', 5), ('could', 5), ('he', 3), ('felt', 3), ('and', 2), ('elodie', 2), ('!', 2), ('it', 2), ('i', 2), ('2', 1)] | Training
2025-04-07 14:57:14 | 44500 | LR0.0003 | loss:3.9109 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-50.1915 | logitMax:-29.5905 | windowWeightsW21:0.51693,W18:0.43664,W15:0.29955,W13:0.23180,W8:0.13581,W7:0.04928,W3:-0.07106,W1:-0.30071,W2:-0.31847 | memoryGatesShort:-34.815, Long:2.136, Current:33.679 | topTokens[('.', 4), ('what', 4), ('dancing', 3), ('you', 3), ('hug', 2), ('?', 2), ('are', 2), ('to', 2), ('pete', 1), ('music', 1)] | Training
2025-04-07 14:57:34 | 45000 | LR0.0003 | loss:3.6442 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-46.5876 | logitMax:-25.8911 | windowWeightsW21:0.52171,W18:0.44065,W15:0.29875,W13:0.23364,W8:0.13777,W7:0.05051,W3:-0.07427,W1:-0.30569,W2:-0.32344 | memoryGatesShort:-13.812, Long:1.327, Current:13.485 | topTokens[('.', 4), ('is', 3), ('say', 2), ('music', 2), ('were', 2), ('listening', 2), ('to', 2), ('geepy', 2), ('them', 1), ('yes', 1)] | Training
2025-04-07 14:57:54 | 45500 | LR0.0003 | loss:5.2512 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-51.5639 | logitMax:-32.9572 | windowWeightsW21:0.52764,W18:0.44586,W15:0.30453,W13:0.23620,W8:0.13914,W7:0.05083,W3:-0.07895,W1:-0.31429,W2:-0.33150 | memoryGatesShort:-14.555, Long:1.903, Current:13.652 | topTokens[('.', 3), (',', 3), ('water', 2), ('talking', 2), ('you', 2), ('some', 2), ('to', 2), ('and', 2), ('her', 1), ('your', 1)] | Training
2025-04-07 14:58:13 | 46000 | LR0.0003 | loss:5.6263 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-55.3600 | logitMax:-37.9228 | windowWeightsW21:0.53162,W18:0.45212,W15:0.30712,W13:0.24017,W8:0.13969,W7:0.05138,W3:-0.08387,W1:-0.31978,W2:-0.33913 | memoryGatesShort:-12.933, Long:1.734, Current:12.200 | topTokens[('the', 3), ('does', 3), ('ouse', 3), ('is', 2), ('felt', 2), ('kevin', 2), ('his', 2), (',', 2), ('.', 2), ('were', 2)] | Training
2025-04-07 14:58:33 | 46500 | LR0.0003 | loss:5.7181 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-55.3617 | logitMax:-38.3187 | windowWeightsW21:0.54430,W18:0.46241,W15:0.31130,W13:0.24129,W8:0.13751,W7:0.04751,W3:-0.08995,W1:-0.32792,W2:-0.34742 | memoryGatesShort:-12.220, Long:1.812, Current:11.409 | topTokens[(',', 4), ('water', 2), ('the', 2), ('tonight', 1), ('s', 1), ('they', 1), ('ast', 1), ('coo', 1), ("'ve", 1), ('she', 1)] | Training
2025-04-07 14:58:52 | 47000 | LR0.0003 | loss:4.4971 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-53.8839 | logitMax:-36.5579 | windowWeightsW21:0.54784,W18:0.46727,W15:0.31190,W13:0.24018,W8:0.13556,W7:0.04709,W3:-0.09148,W1:-0.33019,W2:-0.34926 | memoryGatesShort:-14.611, Long:1.773, Current:13.839 | topTokens[(',', 10), ('s', 4), ('and', 2), ('care', 2), ('a', 1), ('k', 1), ('they', 1), ('could', 1), ('i', 1), ('?', 1)] | Training
2025-04-07 14:59:12 | 47500 | LR0.0003 | loss:3.2998 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.9740 | logitMax:-33.8228 | windowWeightsW21:0.54654,W18:0.46611,W15:0.31002,W13:0.23692,W8:0.13241,W7:0.04665,W3:-0.08590,W1:-0.32852,W2:-0.34526 | memoryGatesShort:-15.256, Long:1.418, Current:14.838 | topTokens[('water', 2), ('and', 2), (',', 2), ('was', 2), ('to', 2), ('her', 2), ('we', 1), ('look', 1), ('my', 1), ('sk', 1)] | Training
2025-04-07 14:59:31 | 48000 | LR0.0003 | loss:3.5446 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.1427 | logitMax:-34.7051 | windowWeightsW21:0.54806,W18:0.46647,W15:0.30937,W13:0.23649,W8:0.13255,W7:0.04690,W3:-0.08669,W1:-0.32834,W2:-0.34586 | memoryGatesShort:-13.150, Long:1.183, Current:12.967 | topTokens[(',', 8), ('and', 5), ('charis', 3), ('to', 2), ('way', 2), ('his', 2), ('kevin', 1), ('sound', 1), ('she', 1), ('pe', 1)] | Training
2025-04-07 14:59:50 | 48500 | LR0.0003 | loss:5.9508 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.4982 | logitMax:-35.2629 | windowWeightsW21:0.57257,W18:0.48288,W15:0.31815,W13:0.23941,W8:0.13005,W7:0.04286,W3:-0.09789,W1:-0.34459,W2:-0.36504 | memoryGatesShort:-9.687, Long:1.370, Current:9.317 | topTokens[('a', 4), ('100', 2), ('she', 2), ('living', 1), ('ion', 1), ('.', 1), ('out', 1), ('re', 1), ('f', 1), ('...', 1)] | Training
2025-04-07 15:00:10 | 49000 | LR0.0003 | loss:6.0721 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.1312 | logitMax:-39.1038 | windowWeightsW21:0.58860,W18:0.49254,W15:0.32391,W13:0.24312,W8:0.12927,W7:0.03916,W3:-0.10446,W1:-0.35631,W2:-0.37784 | memoryGatesShort:-12.514, Long:2.016, Current:11.497 | topTokens[('of', 4), ('i', 2), ("'s", 2), ('a', 2), ('il', 2), ('get', 1), ('which', 1), ('y', 1), ('row', 1), ('elodie', 1)] | Training
2025-04-07 15:00:29 | 49500 | LR0.0003 | loss:5.9015 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-53.5616 | logitMax:-36.8567 | windowWeightsW21:0.59632,W18:0.49580,W15:0.32726,W13:0.24490,W8:0.13093,W7:0.03904,W3:-0.10999,W1:-0.36014,W2:-0.38632 | memoryGatesShort:-14.278, Long:2.323, Current:12.955 | topTokens[('g', 4), ('a', 2), ('at', 2), ('e', 2), ('how', 2), (',', 2), ('hurt', 1), ("'s", 1), ('out', 1), ('.', 1)] | Training
2025-04-07 15:00:56 | 50000 | LR0.0003 | loss:6.0613 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-51.1766 | logitMax:-34.3688 | windowWeightsW21:0.61242,W18:0.50741,W15:0.33396,W13:0.24850,W8:0.12994,W7:0.03571,W3:-0.11769,W1:-0.37272,W2:-0.40017 | memoryGatesShort:-27.585, Long:4.611, Current:23.974 | topTokens[('.', 3), ('to', 2), (',', 2), ('on', 2), ('a', 2), ('their', 1), ('be', 1), ('r', 1), ('row', 1), ('g', 1)] | Training
2025-04-07 15:01:16 | 50500 | LR0.0003 | loss:6.0558 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.4521 | logitMax:-35.9077 | windowWeightsW21:0.62627,W18:0.51767,W15:0.34160,W13:0.25315,W8:0.12772,W7:0.03277,W3:-0.12470,W1:-0.38566,W2:-0.41178 | memoryGatesShort:-10.987, Long:2.277, Current:9.710 | topTokens[(',', 3), ('.', 3), ('pr', 2), ('not', 2), ('to', 2), ('of', 2), ("'t", 2), ('awes', 1), ('y', 1), ('kevin', 1)] | Training
2025-04-07 15:01:37 | 51000 | LR0.0003 | loss:6.0335 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.7273 | logitMax:-40.4287 | windowWeightsW21:0.64074,W18:0.52344,W15:0.34284,W13:0.25521,W8:0.12686,W7:0.03018,W3:-0.12912,W1:-0.39251,W2:-0.42094 | memoryGatesShort:-11.600, Long:2.272, Current:10.328 | topTokens[('?', 3), ('we', 2), ('my', 2), ('i', 2), ('and', 1), ('ke', 1), ('im', 1), ('was', 1), ('which', 1), ('over', 1)] | Training
2025-04-07 15:01:56 | 51500 | LR0.0003 | loss:4.9259 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-55.6919 | logitMax:-38.7042 | windowWeightsW21:0.63952,W18:0.51795,W15:0.33829,W13:0.25068,W8:0.12941,W7:0.03182,W3:-0.12697,W1:-0.38738,W2:-0.41654 | memoryGatesShort:-14.645, Long:2.261, Current:13.384 | topTokens[('lo', 3), ('.', 3), ('pr', 2), ('cially', 1), ('my', 1), ('some', 1), ('listen', 1), ('felt', 1), ('imag', 1), ('kevin', 1)] | Training
2025-04-07 15:02:15 | 52000 | LR0.0003 | loss:1.8267 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-58.4467 | logitMax:-37.0769 | windowWeightsW21:0.62950,W18:0.51015,W15:0.33156,W13:0.24306,W8:0.12679,W7:0.02694,W3:-0.11707,W1:-0.37240,W2:-0.40142 | memoryGatesShort:-11.359, Long:1.398, Current:10.961 | topTokens[('must', 6), ('have', 5), ('it', 2), (',', 2), ('we', 2), ('.', 2), ('and', 2), ('miss', 1), ('ohh', 1), ("'", 1)] | Training
2025-04-07 15:02:34 | 52500 | LR0.0003 | loss:2.9756 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-51.9363 | logitMax:-30.9516 | windowWeightsW21:0.63559,W18:0.51760,W15:0.33167,W13:0.24164,W8:0.12661,W7:0.02322,W3:-0.11813,W1:-0.37676,W2:-0.40451 | memoryGatesShort:-29.605, Long:3.053, Current:27.552 | topTokens[('felt', 6), ('must', 4), ('have', 3), ('the', 2), ('n', 2), ('you', 2), ('.', 2), ('we', 2), ('it', 2), ('they', 2)] | Training
2025-04-07 15:02:55 | 53000 | LR0.0003 | loss:4.4073 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-48.9857 | logitMax:-28.8604 | windowWeightsW21:0.64389,W18:0.52406,W15:0.33413,W13:0.24410,W8:0.12329,W7:0.02027,W3:-0.12187,W1:-0.38122,W2:-0.40992 | memoryGatesShort:-25.034, Long:2.601, Current:23.433 | topTokens[('.', 4), ('?', 3), ('you', 3), ('charis', 2), ('know', 2), ('go', 2), ('i', 1), ('we', 1), ('it', 1), ('h', 1)] | Training
2025-04-07 15:03:14 | 53500 | LR0.0003 | loss:3.9799 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.9891 | logitMax:-37.7217 | windowWeightsW21:0.63205,W18:0.52264,W15:0.33418,W13:0.24413,W8:0.12277,W7:0.02193,W3:-0.11939,W1:-0.37606,W2:-0.40528 | memoryGatesShort:-9.777, Long:0.992, Current:9.785 | topTokens[('pr', 4), ('but', 4), ('what', 3), (',', 3), ('so', 2), ('go', 2), ('s', 2), ('i', 1), ('do', 1), ('as', 1)] | Training
2025-04-07 15:03:34 | 54000 | LR0.0003 | loss:4.3620 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-65.8384 | logitMax:-46.6933 | windowWeightsW21:0.62112,W18:0.51538,W15:0.33858,W13:0.25022,W8:0.12464,W7:0.02444,W3:-0.11758,W1:-0.37578,W2:-0.40385 | memoryGatesShort:-8.484, Long:0.732, Current:8.752 | topTokens[(',', 3), ('y', 2), ('ing', 2), ('is', 2), ('they', 2), ('each', 1), ('ong', 1), ('my', 1), ('o', 1), ('us', 1)] | Training
2025-04-07 15:03:53 | 54500 | LR0.0003 | loss:4.1149 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-61.1782 | logitMax:-40.7012 | windowWeightsW21:0.61143,W18:0.51051,W15:0.33706,W13:0.25166,W8:0.12946,W7:0.03052,W3:-0.11707,W1:-0.37426,W2:-0.40194 | memoryGatesShort:-12.417, Long:0.851, Current:12.566 | topTokens[(',', 3), ('wind', 2), ('.', 2), ('for', 2), ('on', 2), ('a', 2), ('cially', 1), ('favour', 1), ('wn', 1), ('very', 1)] | Training
2025-04-07 15:04:14 | 55000 | LR0.0003 | loss:2.6166 | gradNorm:0.9653 | tokenCount:2000.0000 | logitMin:-59.7101 | logitMax:-31.1646 | windowWeightsW21:0.58721,W18:0.48683,W15:0.33079,W13:0.25211,W8:0.14066,W7:0.04169,W3:-0.11022,W1:-0.36069,W2:-0.39046 | memoryGatesShort:-14.971, Long:0.986, Current:14.985 | topTokens[('4', 3), (':', 3), ("'", 3), ("'", 3), ('5', 2), ('i', 2), ('lear', 2), ('i', 2), ('ll', 1), ('ning', 1)] | Training
2025-04-07 15:04:33 | 55500 | LR0.0003 | loss:4.4201 | gradNorm:0.9792 | tokenCount:2000.0000 | logitMin:-57.4390 | logitMax:-33.6083 | windowWeightsW21:0.58927,W18:0.48803,W15:0.33156,W13:0.25419,W8:0.14373,W7:0.04510,W3:-0.11220,W1:-0.36585,W2:-0.39602 | memoryGatesShort:-11.765, Long:1.234, Current:11.531 | topTokens[('to', 3), (',', 3), ('normal', 2), ('m', 2), ("'", 2), ('from', 2), ('am', 2), ('ll', 1), (':', 1), ('imag', 1)] | Training
2025-04-07 15:04:53 | 56000 | LR0.0003 | loss:6.6204 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-59.2735 | logitMax:-40.8440 | windowWeightsW21:0.61143,W18:0.50448,W15:0.33774,W13:0.25605,W8:0.14365,W7:0.04210,W3:-0.12081,W1:-0.38331,W2:-0.41405 | memoryGatesShort:-9.350, Long:1.687, Current:8.663 | topTokens[('of', 2), ('.', 2), ('s', 2), ('-', 2), ('b', 2), ('2', 2), ('fall', 1), ('the', 1), ('her', 1), ('are', 1)] | Training
2025-04-07 15:05:13 | 56500 | LR0.0003 | loss:6.0559 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-55.4158 | logitMax:-38.3138 | windowWeightsW21:0.63145,W18:0.51571,W15:0.34093,W13:0.25508,W8:0.14340,W7:0.03951,W3:-0.12767,W1:-0.39458,W2:-0.42702 | memoryGatesShort:-17.797, Long:3.054, Current:15.743 | topTokens[('g', 4), (':', 3), ('x', 2), (',', 2), ('my', 2), ('a', 2), ('.', 2), ('gh', 1), ('b', 1), ('of', 1)] | Training
2025-04-07 15:05:32 | 57000 | LR0.0003 | loss:5.5931 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.6536 | logitMax:-34.6879 | windowWeightsW21:0.64462,W18:0.52137,W15:0.34201,W13:0.25558,W8:0.14476,W7:0.03961,W3:-0.13262,W1:-0.40249,W2:-0.43634 | memoryGatesShort:-13.623, Long:2.518, Current:12.105 | topTokens[('a', 3), ('.', 3), ('i', 2), ("'", 2), ('en', 1), ('your', 1), ('an', 1), ('b', 1), (':', 1), ('y', 1)] | Training
2025-04-07 15:05:51 | 57500 | LR0.0003 | loss:3.6432 | gradNorm:0.9990 | tokenCount:2000.0000 | logitMin:-59.2843 | logitMax:-38.0632 | windowWeightsW21:0.64212,W18:0.51665,W15:0.33999,W13:0.25494,W8:0.14335,W7:0.03595,W3:-0.12981,W1:-0.39513,W2:-0.43146 | memoryGatesShort:-14.201, Long:2.206, Current:12.996 | topTokens[(':', 4), ("'", 4), ("'", 2), ('ll', 2), ('m', 2), ('l', 2), ('you', 2), ('gh', 1), ('mao', 1), ('c', 1)] | Training
2025-04-07 15:06:10 | 58000 | LR0.0003 | loss:3.5841 | gradNorm:0.9892 | tokenCount:2000.0000 | logitMin:-65.0276 | logitMax:-41.8432 | windowWeightsW21:0.62645,W18:0.50081,W15:0.33363,W13:0.25549,W8:0.14583,W7:0.03899,W3:-0.12370,W1:-0.38114,W2:-0.41934 | memoryGatesShort:-16.783, Long:2.083, Current:15.700 | topTokens[(':', 5), ("'", 4), ('-', 4), ('charis', 2), ("'", 2), ('pt', 2), ("'s", 1), ('step', 1), ('friends', 1), ('ed', 1)] | Training
2025-04-07 15:06:29 | 58500 | LR0.0003 | loss:5.4076 | gradNorm:0.9975 | tokenCount:2000.0000 | logitMin:-56.9365 | logitMax:-36.7633 | windowWeightsW21:0.64205,W18:0.51099,W15:0.33738,W13:0.25664,W8:0.14542,W7:0.03580,W3:-0.13064,W1:-0.38972,W2:-0.43126 | memoryGatesShort:-13.333, Long:2.010, Current:12.323 | topTokens[('.', 4), (',', 4), ('a', 3), ('and', 2), ('gh', 1), ('pr', 1), ('airs', 1), ('?!', 1), ('wh', 1), ('some', 1)] | Training
2025-04-07 15:06:49 | 59000 | LR0.0003 | loss:6.6431 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-57.0323 | logitMax:-38.9845 | windowWeightsW21:0.65685,W18:0.52064,W15:0.34249,W13:0.26104,W8:0.14666,W7:0.03463,W3:-0.13843,W1:-0.40226,W2:-0.44535 | memoryGatesShort:-9.942, Long:1.800, Current:9.142 | topTokens[('it', 3), ('who', 2), ('i', 2), ('they', 2), ('for', 1), ('and', 1), ('with', 1), ('-', 1), ('as', 1), ('some', 1)] | Training
2025-04-07 15:07:09 | 59500 | LR0.0003 | loss:4.2762 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.4071 | logitMax:-36.1690 | windowWeightsW21:0.64822,W18:0.51746,W15:0.34283,W13:0.26435,W8:0.14885,W7:0.03918,W3:-0.13715,W1:-0.40265,W2:-0.44466 | memoryGatesShort:-19.426, Long:2.984, Current:17.443 | topTokens[('i', 3), ('it', 2), ('.', 2), ('a', 2), ('na', 1), ('cially', 1), ('uk', 1), ('where', 1), ('w', 1), ('that', 1)] | Training
2025-04-07 15:07:36 | 60000 | LR0.0003 | loss:4.0883 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-51.1652 | logitMax:-31.9659 | windowWeightsW21:0.63292,W18:0.50781,W15:0.33702,W13:0.26221,W8:0.15260,W7:0.04391,W3:-0.13150,W1:-0.39400,W2:-0.43417 | memoryGatesShort:-17.851, Long:2.226, Current:16.625 | topTokens[('listening', 4), ('?', 3), ('i', 2), ('to', 2), ('co', 1), ('ing', 1), ('ud', 1), ('but', 1), ('one', 1), ('of', 1)] | Training
2025-04-07 15:07:56 | 60500 | LR0.0003 | loss:3.4775 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-46.9479 | logitMax:-25.7178 | windowWeightsW21:0.62231,W18:0.49570,W15:0.33814,W13:0.26204,W8:0.15253,W7:0.04312,W3:-0.12460,W1:-0.38763,W2:-0.42453 | memoryGatesShort:-9.522, Long:1.191, Current:9.331 | topTokens[('to', 5), ('i', 4), ('listening', 3), ('what', 2), ('.', 2), ('?', 2), ('will', 2), ('na', 1), ('gh', 1), ('theyre', 1)] | Training
2025-04-07 15:08:15 | 61000 | LR0.0003 | loss:3.8709 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.7051 | logitMax:-34.2235 | windowWeightsW21:0.63214,W18:0.50507,W15:0.34433,W13:0.26385,W8:0.15260,W7:0.04153,W3:-0.12867,W1:-0.40000,W2:-0.43406 | memoryGatesShort:-17.157, Long:2.055, Current:16.103 | topTokens[('i', 5), ('?', 3), (',', 3), ('to', 2), ('have', 2), ('it', 2), ('.', 2), ('!', 2), ('he', 1), ('sorry', 1)] | Training
2025-04-07 15:08:35 | 61500 | LR0.0003 | loss:4.7668 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-57.1647 | logitMax:-38.1239 | windowWeightsW21:0.64492,W18:0.51389,W15:0.34733,W13:0.26581,W8:0.15111,W7:0.03986,W3:-0.13662,W1:-0.40628,W2:-0.44356 | memoryGatesShort:-20.731, Long:2.597, Current:19.134 | topTokens[('it', 4), ('!', 4), (',', 3), ('the', 3), ('s', 2), ('roid', 2), ('slow', 1), ('tv', 1), ('arch', 1), ('must', 1)] | Training
2025-04-07 15:08:54 | 62000 | LR0.0003 | loss:6.0405 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-58.2794 | logitMax:-39.7265 | windowWeightsW21:0.66682,W18:0.53124,W15:0.35565,W13:0.27068,W8:0.14800,W7:0.03417,W3:-0.14784,W1:-0.42184,W2:-0.46098 | memoryGatesShort:-15.424, Long:2.464, Current:13.959 | topTokens[(',', 5), ('i', 2), ('?', 2), ('it', 2), ('!', 1), ('listening', 1), ('no', 1), ('f', 1), ('ice', 1), ('to', 1)] | Training
2025-04-07 15:09:13 | 62500 | LR0.0003 | loss:6.0030 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.9073 | logitMax:-37.5503 | windowWeightsW21:0.68979,W18:0.54790,W15:0.36206,W13:0.27504,W8:0.14719,W7:0.02926,W3:-0.15859,W1:-0.43770,W2:-0.47963 | memoryGatesShort:-11.771, Long:2.169, Current:10.602 | topTokens[('i', 3), ('.', 3), ('eah', 2), (',', 2), ('like', 2), ('she', 2), ('gh', 1), ('through', 1), ('that', 1), ('!', 1)] | Training
2025-04-07 15:09:33 | 63000 | LR0.0003 | loss:6.2022 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-55.6001 | logitMax:-38.2455 | windowWeightsW21:0.70649,W18:0.55687,W15:0.36922,W13:0.27825,W8:0.14725,W7:0.02715,W3:-0.16771,W1:-0.44882,W2:-0.49381 | memoryGatesShort:-13.430, Long:2.585, Current:11.846 | topTokens[('.', 3), ('it', 2), ('to', 2), ('a', 1), ('pe', 1), ('ow', 1), ('li', 1), ('ong', 1), ('her', 1), ('so', 1)] | Training
2025-04-07 15:09:52 | 63500 | LR0.0003 | loss:3.8086 | gradNorm:0.9900 | tokenCount:2000.0000 | logitMin:-60.6106 | logitMax:-38.5030 | windowWeightsW21:0.68404,W18:0.53720,W15:0.36367,W13:0.27856,W8:0.15690,W7:0.04042,W3:-0.16513,W1:-0.43731,W2:-0.48295 | memoryGatesShort:-7.817, Long:1.483, Current:7.334 | topTokens[('m', 3), (':', 2), ("'", 2), ('0', 2), ('4', 2), ('-', 2), ('ause', 1), ('mao', 1), ('pr', 1), ('pizza', 1)] | Training
2025-04-07 15:10:11 | 64000 | LR0.0003 | loss:1.9620 | gradNorm:0.8561 | tokenCount:2000.0000 | logitMin:-59.7811 | logitMax:-30.5831 | windowWeightsW21:0.65918,W18:0.51518,W15:0.35839,W13:0.27548,W8:0.16562,W7:0.04913,W3:-0.15673,W1:-0.42144,W2:-0.46882 | memoryGatesShort:-9.075, Long:1.378, Current:8.697 | topTokens[("'", 5), ('at', 4), ('wh', 3), ('am', 3), ('4', 2), ('-', 2), ('i', 2), ('ning', 2), ('today', 2), ('?', 2)] | Training
2025-04-07 15:10:31 | 64500 | LR0.0003 | loss:1.6690 | gradNorm:0.8984 | tokenCount:2000.0000 | logitMin:-63.5294 | logitMax:-35.1815 | windowWeightsW21:0.63909,W18:0.50289,W15:0.35286,W13:0.27238,W8:0.16765,W7:0.05622,W3:-0.15039,W1:-0.40746,W2:-0.45677 | memoryGatesShort:-7.008, Long:0.991, Current:7.016 | topTokens[(':', 5), ('0', 4), ('ere', 3), ("'", 3), ('4', 3), ('m', 2), (',', 2), ('7', 1), ('charis', 1), ("'", 1)] | Training
2025-04-07 15:10:50 | 65000 | LR0.0003 | loss:1.4111 | gradNorm:0.8578 | tokenCount:2000.0000 | logitMin:-61.5129 | logitMax:-31.4859 | windowWeightsW21:0.62018,W18:0.49190,W15:0.34540,W13:0.27015,W8:0.17077,W7:0.06263,W3:-0.14404,W1:-0.39611,W2:-0.44397 | memoryGatesShort:-6.527, Long:0.795, Current:6.733 | topTokens[('!', 4), ('-', 4), ('20', 4), ("'", 4), ('0', 3), ("'", 2), ('o', 2), ('4', 2), ('-', 2), ('cool', 1)] | Training
2025-04-07 15:11:09 | 65500 | LR0.0003 | loss:2.9662 | gradNorm:0.9446 | tokenCount:2000.0000 | logitMin:-61.8398 | logitMax:-36.0932 | windowWeightsW21:0.61250,W18:0.48457,W15:0.34291,W13:0.27100,W8:0.17325,W7:0.06792,W3:-0.14173,W1:-0.39338,W2:-0.43995 | memoryGatesShort:-12.608, Long:1.220, Current:12.388 | topTokens[("'", 3), ('!', 2), ('charis', 2), (':', 2), ("'", 2), ('to', 2), (',', 2), ('random', 1), ('please', 1), ('stay', 1)] | Training
2025-04-07 15:11:28 | 66000 | LR0.0003 | loss:3.9342 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-62.7098 | logitMax:-41.9739 | windowWeightsW21:0.61955,W18:0.48938,W15:0.34545,W13:0.27067,W8:0.17269,W7:0.06688,W3:-0.14584,W1:-0.39771,W2:-0.44416 | memoryGatesShort:-14.187, Long:1.426, Current:13.760 | topTokens[(',', 5), ('the', 4), ('m', 3), ('to', 2), ('angle', 1), ('them', 1), ('out', 1), ('it', 1), ('d', 1), ('first', 1)] | Training
2025-04-07 15:11:48 | 66500 | LR0.0003 | loss:3.7292 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-59.8033 | logitMax:-39.1885 | windowWeightsW21:0.61768,W18:0.48767,W15:0.34313,W13:0.26839,W8:0.17208,W7:0.06658,W3:-0.14309,W1:-0.39528,W2:-0.44018 | memoryGatesShort:-12.596, Long:1.238, Current:12.358 | topTokens[(',', 4), ('!', 3), ('we', 3), ('sn', 2), ('she', 2), ('it', 2), ('through', 1), ('found', 1), ('an', 1), ('they', 1)] | Training
2025-04-07 15:12:08 | 67000 | LR0.0003 | loss:3.6866 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-62.0300 | logitMax:-41.4245 | windowWeightsW21:0.62288,W18:0.48836,W15:0.34540,W13:0.26994,W8:0.17043,W7:0.06441,W3:-0.14530,W1:-0.39679,W2:-0.44246 | memoryGatesShort:-13.341, Long:1.288, Current:13.053 | topTokens[(',', 2), ('to', 2), ('roid', 2), ('lo', 2), ('a', 2), ('a', 1), ('slow', 1), ('...', 1), ('at', 1), ('k', 1)] | Training
2025-04-07 15:12:28 | 67500 | LR0.0003 | loss:3.5727 | gradNorm:0.9958 | tokenCount:2000.0000 | logitMin:-61.9430 | logitMax:-39.2870 | windowWeightsW21:0.63627,W18:0.49502,W15:0.34841,W13:0.26980,W8:0.16836,W7:0.06195,W3:-0.14928,W1:-0.40321,W2:-0.45073 | memoryGatesShort:-25.547, Long:2.672, Current:23.876 | topTokens[("'", 4), ('sn', 3), ('d', 3), ('it', 2), (',', 2), ('he', 2), ("'", 2), ('.', 2), ('-', 2), ('uk', 1)] | Training
2025-04-07 15:12:48 | 68000 | LR0.0003 | loss:3.4579 | gradNorm:0.9714 | tokenCount:2000.0000 | logitMin:-61.6999 | logitMax:-38.5069 | windowWeightsW21:0.64548,W18:0.49982,W15:0.35251,W13:0.26982,W8:0.16491,W7:0.05895,W3:-0.15337,W1:-0.40523,W2:-0.45649 | memoryGatesShort:-15.407, Long:1.870, Current:14.537 | topTokens[("'", 5), (':', 4), ("'", 3), ('-', 3), ('charis', 3), ('my', 2), ('d', 2), ('roid', 2), (',', 1), ('!', 1)] | Training
2025-04-07 15:13:08 | 68500 | LR0.0003 | loss:3.2447 | gradNorm:0.9859 | tokenCount:2000.0000 | logitMin:-56.8454 | logitMax:-34.3406 | windowWeightsW21:0.64960,W18:0.50193,W15:0.35975,W13:0.27361,W8:0.16225,W7:0.05507,W3:-0.15623,W1:-0.40826,W2:-0.46146 | memoryGatesShort:-24.955, Long:2.923, Current:23.032 | topTokens[('a', 3), ('mao', 2), ('baby', 2), ('-', 2), ('y', 2), ("'", 2), ('he', 2), ('have', 2), ('felt', 2), ('would', 2)] | Training
2025-04-07 15:13:27 | 69000 | LR0.0003 | loss:2.0049 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.5684 | logitMax:-33.0759 | windowWeightsW21:0.64845,W18:0.49704,W15:0.35684,W13:0.27249,W8:0.16092,W7:0.05268,W3:-0.15313,W1:-0.40295,W2:-0.45599 | memoryGatesShort:-21.834, Long:2.214, Current:20.619 | topTokens[('have', 5), ('n', 3), ('.', 3), ('felt', 3), ('!', 3), ('would', 2), ('know', 2), ('you', 2), (',', 2), ('elodie', 2)] | Training
2025-04-07 15:13:47 | 69500 | LR0.0003 | loss:1.6232 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.4527 | logitMax:-29.5395 | windowWeightsW21:0.63598,W18:0.49016,W15:0.35201,W13:0.27085,W8:0.15976,W7:0.05324,W3:-0.14650,W1:-0.39335,W2:-0.44549 | memoryGatesShort:-15.213, Long:1.400, Current:14.813 | topTokens[('felt', 4), ('!', 4), ('would', 4), ('have', 4), ('wal', 3), ('we', 3), ('.', 2), ('weed', 1), ('his', 1), ('king', 1)] | Training
2025-04-07 15:14:14 | 70000 | LR0.0003 | loss:5.3586 | gradNorm:0.9998 | tokenCount:2000.0000 | logitMin:-59.3008 | logitMax:-38.3831 | windowWeightsW21:0.66776,W18:0.51327,W15:0.36438,W13:0.27885,W8:0.15711,W7:0.04694,W3:-0.16077,W1:-0.41946,W2:-0.47226 | memoryGatesShort:-23.260, Long:2.945, Current:21.315 | topTokens[('!', 5), ('.', 5), (',', 3), ('would', 2), ('have', 2), ('he', 1), ('felt', 1), ('kevin', 1), ('brain', 1), ('she', 1)] | Training
2025-04-07 15:14:34 | 70500 | LR0.0003 | loss:6.0439 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-61.7983 | logitMax:-43.2776 | windowWeightsW21:0.69778,W18:0.53499,W15:0.37509,W13:0.28346,W8:0.15416,W7:0.04195,W3:-0.17498,W1:-0.44038,W2:-0.49700 | memoryGatesShort:-17.069, Long:2.951, Current:15.118 | topTokens[('.', 7), ('to', 2), (':', 2), ('l', 2), ('pizza', 1), ('uk', 1), ('line', 1), ('ch', 1), ('i', 1), ('that', 1)] | Training
2025-04-07 15:14:54 | 71000 | LR0.0003 | loss:6.0468 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-60.6445 | logitMax:-42.6181 | windowWeightsW21:0.71737,W18:0.55149,W15:0.38453,W13:0.28752,W8:0.15377,W7:0.03843,W3:-0.18633,W1:-0.45665,W2:-0.51561 | memoryGatesShort:-26.551, Long:5.098, Current:22.454 | topTokens[('and', 2), ('.', 2), ('d', 2), ('be', 2), (',', 2), ('a', 2), ('5', 1), ('li', 1), ('12', 1), ('ing', 1)] | Training
2025-04-07 15:15:14 | 71500 | LR0.0003 | loss:5.5035 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.2165 | logitMax:-38.3697 | windowWeightsW21:0.72653,W18:0.55842,W15:0.38993,W13:0.29157,W8:0.15666,W7:0.03943,W3:-0.19288,W1:-0.46693,W2:-0.52849 | memoryGatesShort:-23.920, Long:4.824, Current:20.096 | topTokens[(',', 6), ('and', 5), ('run', 3), ('.', 3), ('m', 2), ('so', 2), ('a', 2), ('ing', 2), ('mao', 1), ('he', 1)] | Training
2025-04-07 15:15:34 | 72000 | LR0.0003 | loss:5.5172 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.3057 | logitMax:-38.6921 | windowWeightsW21:0.74479,W18:0.56680,W15:0.39610,W13:0.29201,W8:0.15540,W7:0.03714,W3:-0.20027,W1:-0.47717,W2:-0.54099 | memoryGatesShort:-30.839, Long:6.020, Current:25.819 | topTokens[(',', 5), ('to', 3), ('.', 2), ('i', 2), ('her', 2), ('no', 1), ('y', 1), ('ar', 1), ('bread', 1), ('ke', 1)] | Training
2025-04-07 15:15:54 | 72500 | LR0.0003 | loss:5.1165 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.9886 | logitMax:-35.3410 | windowWeightsW21:0.75000,W18:0.57092,W15:0.39801,W13:0.29387,W8:0.15616,W7:0.03593,W3:-0.20337,W1:-0.48113,W2:-0.54673 | memoryGatesShort:-16.803, Long:3.399, Current:14.404 | topTokens[('pizza', 3), (',', 3), ('.', 3), ("'", 2), ('uk', 1), ('out', 1), ('ed', 1), ('!', 1), ('the', 1), ('so', 1)] | Training
2025-04-07 15:16:13 | 73000 | LR0.0003 | loss:5.3892 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-53.2086 | logitMax:-34.9195 | windowWeightsW21:0.77172,W18:0.58626,W15:0.40751,W13:0.29864,W8:0.15708,W7:0.03134,W3:-0.21373,W1:-0.49962,W2:-0.56612 | memoryGatesShort:-69.406, Long:13.923, Current:56.483 | topTokens[(',', 4), ('it', 2), ('a', 2), ('something', 2), ('music', 2), ('ed', 2), ('im', 1), ('f', 1), ('at', 1), ('ch', 1)] | Training
2025-04-07 15:16:32 | 73500 | LR0.0003 | loss:3.9678 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-70.0646 | logitMax:-52.0806 | windowWeightsW21:0.74061,W18:0.56709,W15:0.40068,W13:0.29575,W8:0.15992,W7:0.03614,W3:-0.20445,W1:-0.47675,W2:-0.54515 | memoryGatesShort:-14.905, Long:2.496, Current:13.409 | topTokens[(',', 6), ('mao', 2), ('000', 2), ('ed', 2), ('pe', 2), ('what', 1), ('to', 1), ('left', 1), ('gg', 1), ('ject', 1)] | Training
2025-04-07 15:16:51 | 74000 | LR0.0003 | loss:5.5085 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-60.8062 | logitMax:-41.8815 | windowWeightsW21:0.75078,W18:0.57392,W15:0.40659,W13:0.29974,W8:0.16095,W7:0.03441,W3:-0.21102,W1:-0.48557,W2:-0.55628 | memoryGatesShort:-15.655, Long:2.705, Current:13.950 | topTokens[('.', 5), (',', 3), ('i', 2), ('left', 1), ('of', 1), ('brain', 1), ('wal', 1), ('ly', 1), ('f', 1), ('the', 1)] | Training
2025-04-07 15:17:11 | 74500 | LR0.0003 | loss:5.7936 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-59.8586 | logitMax:-41.4689 | windowWeightsW21:0.78994,W18:0.60074,W15:0.42043,W13:0.30599,W8:0.15996,W7:0.02659,W3:-0.22818,W1:-0.51392,W2:-0.58904 | memoryGatesShort:-15.359, Long:3.022, Current:13.336 | topTokens[('.', 6), ('trust', 3), ('you', 2), ('uk', 1), ('your', 1), ('were', 1), ('c', 1), ('so', 1), ('music', 1), ('that', 1)] | Training
2025-04-07 15:17:30 | 75000 | LR0.0003 | loss:5.8345 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.1152 | logitMax:-35.7635 | windowWeightsW21:0.80398,W18:0.60987,W15:0.42426,W13:0.30662,W8:0.15856,W7:0.02440,W3:-0.23322,W1:-0.52310,W2:-0.59921 | memoryGatesShort:-23.899, Long:4.501, Current:20.399 | topTokens[('.', 5), ('i', 3), (',', 3), ('on', 2), ('know', 2), ('in', 1), ('a', 1), ('l', 1), ('s', 1), ('es', 1)] | Training
2025-04-07 15:17:49 | 75500 | LR0.0003 | loss:5.9902 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.1983 | logitMax:-38.3761 | windowWeightsW21:0.84306,W18:0.63377,W15:0.42974,W13:0.30942,W8:0.15737,W7:0.01902,W3:-0.24850,W1:-0.54749,W2:-0.62520 | memoryGatesShort:-14.296, Long:2.951, Current:12.345 | topTokens[('.', 5), ('l', 3), ('trust', 2), ('a', 2), (',', 2), ('my', 2), ('er', 1), ('slow', 1), ('your', 1), ('it', 1)] | Training
2025-04-07 15:18:08 | 76000 | LR0.0003 | loss:6.0787 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-53.9095 | logitMax:-36.0852 | windowWeightsW21:0.87691,W18:0.65306,W15:0.43990,W13:0.31520,W8:0.15966,W7:0.01445,W3:-0.26391,W1:-0.57133,W2:-0.65363 | memoryGatesShort:-18.272, Long:3.860, Current:15.412 | topTokens[('you', 2), ('what', 1), ("'s", 1), (',', 1), ('foc', 1), ('weed', 1), ('est', 1), ('ent', 1), ('a', 1), ('?', 1)] | Training
2025-04-07 15:18:28 | 76500 | LR0.0003 | loss:6.0581 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.6920 | logitMax:-38.6330 | windowWeightsW21:0.92242,W18:0.68197,W15:0.45485,W13:0.32134,W8:0.15682,W7:0.00605,W3:-0.28456,W1:-0.60066,W2:-0.68912 | memoryGatesShort:-45.446, Long:9.764, Current:36.681 | topTokens[(',', 4), ('pizza', 2), ('a', 2), ('s', 2), ('.', 2), ('y', 2), ('', 1), ('na', 1), ('m', 1), ('j', 1)] | Training
2025-04-07 15:18:47 | 77000 | LR0.0003 | loss:5.7314 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-58.2372 | logitMax:-40.6922 | windowWeightsW21:0.93291,W18:0.68573,W15:0.45744,W13:0.32313,W8:0.15787,W7:0.00726,W3:-0.29166,W1:-0.60717,W2:-0.69666 | memoryGatesShort:-11.160, Long:2.644, Current:9.516 | topTokens[('a', 3), ('.', 2), ('on', 2), ('d', 2), (',', 2), ('i', 1), ('ohh', 1), ('had', 1), ('an', 1), ('ult', 1)] | Training
2025-04-07 15:19:06 | 77500 | LR0.0003 | loss:3.9023 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.7759 | logitMax:-33.9039 | windowWeightsW21:0.89100,W18:0.65500,W15:0.43924,W13:0.31233,W8:0.15524,W7:0.00967,W3:-0.26703,W1:-0.56887,W2:-0.65650 | memoryGatesShort:-18.614, Long:3.093, Current:16.521 | topTokens[(',', 4), ('apparent', 2), ('to', 2), ('ked', 2), ('i', 2), ('said', 1), ('ark', 1), ('an', 1), ('too', 1), ('ter', 1)] | Training
2025-04-07 15:19:26 | 78000 | LR0.0003 | loss:2.0220 | gradNorm:0.9047 | tokenCount:2000.0000 | logitMin:-61.6523 | logitMax:-33.6984 | windowWeightsW21:0.85058,W18:0.61765,W15:0.42188,W13:0.30665,W8:0.16442,W7:0.02507,W3:-0.25102,W1:-0.53842,W2:-0.62560 | memoryGatesShort:-9.677, Long:1.629, Current:9.048 | topTokens[('0', 3), ('5', 3), ('-', 3), ('4', 3), ('ning', 2), ('m', 2), ("'", 2), ('wh', 2), ("'", 2), ('6', 2)] | Training
2025-04-07 15:19:46 | 78500 | LR0.0003 | loss:1.8233 | gradNorm:0.8951 | tokenCount:2000.0000 | logitMin:-62.2360 | logitMax:-33.2128 | windowWeightsW21:0.82905,W18:0.60138,W15:0.41841,W13:0.30482,W8:0.16597,W7:0.03058,W3:-0.24117,W1:-0.52408,W2:-0.61323 | memoryGatesShort:-6.164, Long:1.130, Current:6.034 | topTokens[("'", 4), ('wh', 3), ('lo', 2), ('you', 2), ('at', 2), ('am', 2), ('i', 2), ("'", 2), (':', 2), ('ning', 1)] | Training
2025-04-07 15:20:05 | 79000 | LR0.0003 | loss:1.2043 | gradNorm:0.8344 | tokenCount:2000.0000 | logitMin:-66.1221 | logitMax:-34.1868 | windowWeightsW21:0.78546,W18:0.57538,W15:0.40635,W13:0.29613,W8:0.16975,W7:0.03998,W3:-0.22318,W1:-0.49563,W2:-0.58142 | memoryGatesShort:-7.842, Long:1.051, Current:7.791 | topTokens[('0', 6), ('-', 5), (':', 4), ('4', 4), ("'", 3), ('m', 2), ('i', 2), ('!', 2), ('o', 2), ('let', 1)] | Training
2025-04-07 15:20:24 | 79500 | LR0.0003 | loss:1.2304 | gradNorm:0.7878 | tokenCount:2000.0000 | logitMin:-70.7802 | logitMax:-37.5957 | windowWeightsW21:0.75358,W18:0.56130,W15:0.39593,W13:0.29070,W8:0.17173,W7:0.04779,W3:-0.21294,W1:-0.47618,W2:-0.55830 | memoryGatesShort:-7.127, Long:0.796, Current:7.331 | topTokens[("'", 5), ('-', 3), ('random', 2), ('please', 2), ('!', 2), ('charis', 2), (':', 2), ("'", 2), ('baby', 1), ('-', 1)] | Training
2025-04-07 15:20:51 | 80000 | LR0.0003 | loss:5.6935 | gradNorm:0.9728 | tokenCount:2000.0000 | logitMin:-58.1574 | logitMax:-35.1882 | windowWeightsW21:0.79015,W18:0.58455,W15:0.41086,W13:0.30014,W8:0.17173,W7:0.04405,W3:-0.23063,W1:-0.50601,W2:-0.59224 | memoryGatesShort:-23.587, Long:3.219, Current:21.368 | topTokens[('i', 4), ('to', 3), ('a', 3), ('-', 2), (',', 2), ('time', 1), ('got', 1), ('today', 1), ('?', 1), ("'", 1)] | Training
2025-04-07 15:21:11 | 80500 | LR0.0003 | loss:5.9173 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-55.0463 | logitMax:-35.0461 | windowWeightsW21:0.81911,W18:0.60487,W15:0.42341,W13:0.30688,W8:0.17222,W7:0.04072,W3:-0.24439,W1:-0.53087,W2:-0.62015 | memoryGatesShort:-18.712, Long:3.235, Current:16.477 | topTokens[('.', 4), ('ew', 2), ('s', 2), ('-', 2), ('trust', 1), ('become', 1), ('needed', 1), ('ers', 1), ('ent', 1), ('mad', 1)] | Training
2025-04-07 15:21:30 | 81000 | LR0.0003 | loss:6.0501 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-57.8150 | logitMax:-38.6830 | windowWeightsW21:0.85647,W18:0.62823,W15:0.43539,W13:0.31236,W8:0.17198,W7:0.03510,W3:-0.25990,W1:-0.55927,W2:-0.64956 | memoryGatesShort:-16.481, Long:3.517, Current:13.964 | topTokens[('the', 2), ('to', 2), (',', 2), ('right', 1), ('her', 1), ('ead', 1), ('in', 1), ('pre', 1), ('ty', 1), ('god', 1)] | Training
2025-04-07 15:21:49 | 81500 | LR0.0003 | loss:6.0021 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-59.3168 | logitMax:-41.2630 | windowWeightsW21:0.89064,W18:0.65023,W15:0.44625,W13:0.31680,W8:0.17295,W7:0.03220,W3:-0.27545,W1:-0.58544,W2:-0.67829 | memoryGatesShort:-24.787, Long:5.693, Current:20.093 | topTokens[('.', 3), ('a', 3), ('ugs', 2), ('s', 2), ('i', 2), ('-', 2), ("'", 2), ('j', 2), ('normal', 1), ('to', 1)] | Training
2025-04-07 15:22:09 | 82000 | LR0.0003 | loss:5.9949 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-61.3069 | logitMax:-44.1141 | windowWeightsW21:0.91317,W18:0.66760,W15:0.45649,W13:0.31977,W8:0.17226,W7:0.02829,W3:-0.28708,W1:-0.60257,W2:-0.69866 | memoryGatesShort:-16.086, Long:3.996, Current:13.090 | topTokens[('i', 3), ("'", 2), ('you', 2), ('a', 2), ('?', 2), ('it', 2), ('.', 2), ('ure', 1), ('ts', 1), ('ing', 1)] | Training
2025-04-07 15:22:28 | 82500 | LR0.0003 | loss:6.1805 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-60.0319 | logitMax:-42.9711 | windowWeightsW21:0.93650,W18:0.68238,W15:0.46108,W13:0.32242,W8:0.17177,W7:0.02476,W3:-0.29602,W1:-0.61762,W2:-0.71660 | memoryGatesShort:-17.019, Long:4.250, Current:13.769 | topTokens[('ugs', 4), ('.', 3), ('i', 3), ('and', 2), ('are', 1), ('ly', 1), ('p', 1), ('of', 1), ('were', 1), ('see', 1)] | Training
2025-04-07 15:22:47 | 83000 | LR0.0003 | loss:5.1518 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.7671 | logitMax:-36.7034 | windowWeightsW21:0.93970,W18:0.68767,W15:0.46198,W13:0.32150,W8:0.16979,W7:0.02466,W3:-0.29691,W1:-0.61936,W2:-0.72046 | memoryGatesShort:-20.437, Long:4.872, Current:16.564 | topTokens[('i', 5), ('!', 3), ('.', 3), ('?', 2), ('did', 2), ('need', 1), ('st', 1), ('a', 1), ('know', 1), ('it', 1)] | Training
2025-04-07 15:23:07 | 83500 | LR0.0003 | loss:5.4342 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.9708 | logitMax:-39.1666 | windowWeightsW21:0.98065,W18:0.71220,W15:0.47157,W13:0.33037,W8:0.16974,W7:0.01821,W3:-0.31561,W1:-0.64481,W2:-0.75486 | memoryGatesShort:-35.715, Long:8.309, Current:28.406 | topTokens[('.', 5), ('i', 4), ('gh', 2), (',', 2), ('tonight', 1), ('ugs', 1), ('your', 1), ('do', 1), ('s', 1), ('did', 1)] | Training
2025-04-07 15:23:26 | 84000 | LR0.0003 | loss:5.4199 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-59.4676 | logitMax:-41.7954 | windowWeightsW21:0.97573,W18:0.71358,W15:0.47333,W13:0.33027,W8:0.17104,W7:0.01827,W3:-0.31584,W1:-0.64330,W2:-0.75557 | memoryGatesShort:-15.892, Long:3.793, Current:13.099 | topTokens[('.', 4), ('a', 2), ('i', 2), ('he', 2), ('was', 2), ('even', 1), ('lo', 1), ('one', 1), ('and', 1), ('that', 1)] | Training
2025-04-07 15:23:46 | 84500 | LR0.0003 | loss:6.0319 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.0522 | logitMax:-38.9029 | windowWeightsW21:1.03482,W18:0.74409,W15:0.48817,W13:0.34224,W8:0.17413,W7:0.01315,W3:-0.34432,W1:-0.68322,W2:-0.80307 | memoryGatesShort:-19.452, Long:4.707, Current:15.745 | topTokens[('.', 4), (',', 3), ('huge', 2), ('while', 2), ('age', 2), ('but', 2), ('the', 2), ('aking', 1), ('it', 1), ('s', 1)] | Training
2025-04-07 15:24:05 | 85000 | LR0.0003 | loss:5.4486 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-63.2784 | logitMax:-45.5289 | windowWeightsW21:1.05102,W18:0.75387,W15:0.48986,W13:0.34474,W8:0.17640,W7:0.01067,W3:-0.35127,W1:-0.69263,W2:-0.81711 | memoryGatesShort:-102.791, Long:22.444, Current:81.347 | topTokens[('i', 4), ('a', 3), ('in', 2), (',', 2), ('.', 2), ('where', 2), ('even', 1), ('though', 1), (')', 1), ('x', 1)] | Training
2025-04-07 15:24:25 | 85500 | LR0.0003 | loss:6.0160 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.5274 | logitMax:-39.0636 | windowWeightsW21:1.08088,W18:0.77302,W15:0.49935,W13:0.34973,W8:0.17766,W7:0.00656,W3:-0.36594,W1:-0.71412,W2:-0.84238 | memoryGatesShort:-33.785, Long:7.598, Current:27.187 | topTokens[('i', 3), ('"', 2), ('huge', 2), ('re', 2), ('is', 2), ('aking', 1), ("'", 1), ('but', 1), ('to', 1), ('who', 1)] | Training
2025-04-07 15:24:44 | 86000 | LR0.0003 | loss:4.4316 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.3735 | logitMax:-38.1486 | windowWeightsW21:1.08103,W18:0.77365,W15:0.50255,W13:0.34668,W8:0.17798,W7:0.00836,W3:-0.36717,W1:-0.71444,W2:-0.84392 | memoryGatesShort:-29.440, Long:6.377, Current:24.063 | topTokens[('.', 5), ('happy', 2), ('!', 2), ('i', 2), ('it', 2), ('to', 1), ('et', 1), ('will', 1), ('into', 1), ('you', 1)] | Training
2025-04-07 15:25:04 | 86500 | LR0.0003 | loss:4.3425 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.7998 | logitMax:-37.4106 | windowWeightsW21:1.05690,W18:0.75403,W15:0.48846,W13:0.33937,W8:0.17357,W7:0.00896,W3:-0.35325,W1:-0.68434,W2:-0.81824 | memoryGatesShort:-13.594, Long:2.762, Current:11.832 | topTokens[('and', 3), ('!', 3), (',', 3), ('the', 2), ('not', 2), ('knew', 2), ('ugs', 1), ('oth', 1), ('normal', 1), ('com', 1)] | Training
2025-04-07 15:25:24 | 87000 | LR0.0003 | loss:3.8256 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-58.9854 | logitMax:-38.8280 | windowWeightsW21:1.02583,W18:0.73011,W15:0.47457,W13:0.33106,W8:0.17347,W7:0.01280,W3:-0.33675,W1:-0.65391,W2:-0.79081 | memoryGatesShort:-47.677, Long:7.639, Current:41.038 | topTokens[(',', 7), ('the', 2), ('i', 2), ('do', 1), ('us', 1), ('angle', 1), ('but', 1), ('tr', 1), ('right', 1), ('ed', 1)] | Training
2025-04-07 15:25:43 | 87500 | LR0.0003 | loss:3.5902 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-57.5010 | logitMax:-36.4482 | windowWeightsW21:0.99566,W18:0.71065,W15:0.46255,W13:0.32393,W8:0.17169,W7:0.01644,W3:-0.32128,W1:-0.62920,W2:-0.76325 | memoryGatesShort:-36.503, Long:5.365, Current:32.138 | topTokens[(',', 5), ('!', 4), ('oth', 2), ('the', 2), ('fe', 2), ('to', 2), ('ause', 1), ('seriously', 1), ('7', 1), ('she', 1)] | Training
2025-04-07 15:26:02 | 88000 | LR0.0003 | loss:5.2712 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.8696 | logitMax:-36.5399 | windowWeightsW21:1.03713,W18:0.73300,W15:0.47542,W13:0.33097,W8:0.17050,W7:0.00951,W3:-0.33903,W1:-0.65516,W2:-0.79624 | memoryGatesShort:-17.872, Long:3.057, Current:15.815 | topTokens[('i', 3), ('to', 3), ('ep', 2), ("'m", 2), ('!', 2), ('with', 2), ('a', 2), ('h', 1), ('she', 1), ('ice', 1)] | Training
2025-04-07 15:26:22 | 88500 | LR0.0003 | loss:6.0186 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.3478 | logitMax:-34.7465 | windowWeightsW21:1.12023,W18:0.78508,W15:0.49882,W13:0.34388,W8:0.16986,W7:-0.00417,W3:-0.37575,W1:-0.70935,W2:-0.86473 | memoryGatesShort:-40.052, Long:7.447, Current:33.605 | topTokens[('it', 5), ('+', 3), ('he', 2), ('i', 2), ('l', 2), ('know', 2), ('"', 1), ('never', 1), ("'m", 1), ('think', 1)] | Training
2025-04-07 15:26:41 | 89000 | LR0.0003 | loss:5.7969 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.1382 | logitMax:-37.3122 | windowWeightsW21:1.15570,W18:0.81005,W15:0.50914,W13:0.34903,W8:0.16925,W7:-0.00816,W3:-0.39337,W1:-0.73475,W2:-0.89401 | memoryGatesShort:-15.793, Long:3.330, Current:13.463 | topTokens[('it', 5), ('.', 3), ('i', 3), ('one', 1), ('am', 1), ('day', 1), ('(', 1), ('!', 1), ('hope', 1), ('she', 1)] | Training
2025-04-07 15:27:01 | 89500 | LR0.0003 | loss:5.5394 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-53.8481 | logitMax:-35.1858 | windowWeightsW21:1.17879,W18:0.82532,W15:0.52067,W13:0.35197,W8:0.17195,W7:-0.00810,W3:-0.40450,W1:-0.75594,W2:-0.91796 | memoryGatesShort:-21.088, Long:4.276, Current:17.812 | topTokens[('.', 3), ('them', 3), ('gh', 2), ('i', 2), ('me', 2), ('of', 2), ('engl', 1), ('unless', 1), ('?', 1), ('g', 1)] | Training
2025-04-07 15:27:30 | 90000 | LR0.0003 | loss:5.3058 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-50.5892 | logitMax:-31.7685 | windowWeightsW21:1.22862,W18:0.85629,W15:0.53561,W13:0.35945,W8:0.17264,W7:-0.01506,W3:-0.42717,W1:-0.78876,W2:-0.96080 | memoryGatesShort:-29.892, Long:5.974, Current:24.919 | topTokens[('.', 3), ('for', 2), ('a', 2), ('his', 2), ('ure', 2), (',', 2), ('or', 2), ('my', 1), ('fe', 1), ('get', 1)] | Training
2025-04-07 15:27:49 | 90500 | LR0.0003 | loss:4.9248 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-55.8545 | logitMax:-36.8287 | windowWeightsW21:1.20993,W18:0.85266,W15:0.53525,W13:0.35746,W8:0.17063,W7:-0.01442,W3:-0.41952,W1:-0.78097,W2:-0.94974 | memoryGatesShort:-68.997, Long:12.106, Current:57.891 | topTokens[('here', 2), ('.', 2), ('unless', 1), ('spec', 1), ('"', 1), ('lf', 1), ('ne', 1), ('its', 1), ('dis', 1), ('him', 1)] | Training
2025-04-07 15:28:09 | 91000 | LR0.0003 | loss:4.2071 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-61.2551 | logitMax:-41.7459 | windowWeightsW21:1.17514,W18:0.83404,W15:0.53218,W13:0.35142,W8:0.17080,W7:-0.00798,W3:-0.40333,W1:-0.76254,W2:-0.92758 | memoryGatesShort:-18.951, Long:3.302, Current:16.648 | topTokens[(',', 6), ('a', 3), ('war', 2), ('s', 2), ('h', 1), ('few', 1), ('ren', 1), ('b', 1), ('you', 1), ('in', 1)] | Training
2025-04-07 15:28:28 | 91500 | LR0.0003 | loss:3.7424 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-64.9973 | logitMax:-45.2863 | windowWeightsW21:1.14187,W18:0.81359,W15:0.52528,W13:0.34643,W8:0.16932,W7:-0.00510,W3:-0.38851,W1:-0.73871,W2:-0.90110 | memoryGatesShort:-10.381, Long:1.759, Current:9.622 | topTokens[(',', 3), ('oth', 2), ('s', 2), ('er', 2), ('emb', 1), ('lf', 1), ('ty', 1), ('a', 1), ('him', 1), ('and', 1)] | Training
2025-04-07 15:28:48 | 92000 | LR0.0003 | loss:3.6603 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-66.3068 | logitMax:-45.7329 | windowWeightsW21:1.11036,W18:0.79666,W15:0.52010,W13:0.34217,W8:0.17532,W7:0.00260,W3:-0.37960,W1:-0.72018,W2:-0.88358 | memoryGatesShort:-21.703, Long:2.797, Current:19.906 | topTokens[('it', 4), ('s', 4), (',', 3), ('but', 2), ('they', 2), ('as', 2), ('li', 1), ('ong', 1), ('w', 1), ('r', 1)] | Training
2025-04-07 15:29:07 | 92500 | LR0.0003 | loss:5.6767 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-63.6724 | logitMax:-43.0717 | windowWeightsW21:1.16691,W18:0.83678,W15:0.54609,W13:0.35965,W8:0.17591,W7:-0.00459,W3:-0.40886,W1:-0.77055,W2:-0.93917 | memoryGatesShort:-24.927, Long:3.625, Current:22.301 | topTokens[(',', 4), ('e', 3), ('.', 3), ('of', 2), ('off', 2), ('+', 1), ('emb', 1), ('until', 1), ('hung', 1), ('w', 1)] | Training
2025-04-07 15:29:27 | 93000 | LR0.0003 | loss:4.1839 | gradNorm:0.9772 | tokenCount:2000.0000 | logitMin:-65.9786 | logitMax:-43.1131 | windowWeightsW21:1.17767,W18:0.83476,W15:0.54796,W13:0.35329,W8:0.16870,W7:0.00021,W3:-0.40707,W1:-0.77036,W2:-0.94318 | memoryGatesShort:-14.509, Long:2.163, Current:13.346 | topTokens[('and', 2), ('i', 2), ('you', 2), ('es', 2), ('rest', 2), ('suggest', 2), ('ing', 2), ('w', 1), ('your', 1), ('to', 1)] | Training
2025-04-07 15:29:47 | 93500 | LR0.0003 | loss:2.7629 | gradNorm:0.9997 | tokenCount:2000.0000 | logitMin:-47.9437 | logitMax:-25.0779 | windowWeightsW21:1.12839,W18:0.81268,W15:0.53974,W13:0.34949,W8:0.17100,W7:0.00814,W3:-0.39034,W1:-0.74341,W2:-0.91247 | memoryGatesShort:-12.693, Long:1.869, Current:11.824 | topTokens[(',', 3), ('sn', 2), ('the', 2), ('can', 2), ('!', 2), ('it', 2), ('i', 2), ('wh', 1), ('ion', 1), ('them', 1)] | Training
2025-04-07 15:30:06 | 94000 | LR0.0003 | loss:2.7059 | gradNorm:0.9941 | tokenCount:2000.0000 | logitMin:-47.7618 | logitMax:-18.6265 | windowWeightsW21:1.08985,W18:0.79249,W15:0.53582,W13:0.34741,W8:0.17314,W7:0.01441,W3:-0.37788,W1:-0.72206,W2:-0.88903 | memoryGatesShort:-12.926, Long:2.054, Current:11.872 | topTokens[(':', 4), ('5', 3), ('-', 3), ('is', 2), ('18', 2), ('4', 2), ("'", 1), ('is', 1), ('ry', 1), ("'s", 1)] | Training
2025-04-07 15:30:26 | 94500 | LR0.0003 | loss:4.0828 | gradNorm:0.9658 | tokenCount:2000.0000 | logitMin:-62.1524 | logitMax:-36.9355 | windowWeightsW21:1.08567,W18:0.79810,W15:0.53516,W13:0.34446,W8:0.17662,W7:0.01767,W3:-0.37846,W1:-0.72422,W2:-0.89084 | memoryGatesShort:-22.870, Long:3.937, Current:19.933 | topTokens[('18', 3), ('.', 3), ('d', 2), ("'", 2), (',', 2), ('7', 1), ('?', 1), ('you', 1), ('kevin', 1), ('baby', 1)] | Training
2025-04-07 15:30:45 | 95000 | LR0.0003 | loss:6.3384 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-73.4845 | logitMax:-53.8697 | windowWeightsW21:1.14328,W18:0.83472,W15:0.55494,W13:0.35444,W8:0.17728,W7:0.01090,W3:-0.40644,W1:-0.76401,W2:-0.94253 | memoryGatesShort:-14.314, Long:3.127, Current:12.187 | topTokens[('i', 3), ('you', 3), (',', 3), ('?', 2), ('s', 2), ('.', 2), ("'ll", 2), ('ic', 1), ('it', 1), ('!', 1)] | Training
2025-04-07 15:31:05 | 95500 | LR0.0003 | loss:5.9435 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-62.6445 | logitMax:-43.8532 | windowWeightsW21:1.19753,W18:0.86517,W15:0.57540,W13:0.36418,W8:0.17782,W7:0.00453,W3:-0.43178,W1:-0.80258,W2:-0.98914 | memoryGatesShort:-55.458, Long:12.073, Current:44.385 | topTokens[('.', 5), ('a', 4), ('ith', 2), ('we', 2), ('3', 2), ('bel', 1), ('g', 1), ('kevin', 1), ('i', 1), ('c', 1)] | Training
2025-04-07 15:31:24 | 96000 | LR0.0003 | loss:4.3945 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-48.9559 | logitMax:-28.9545 | windowWeightsW21:1.19357,W18:0.85762,W15:0.56725,W13:0.35987,W8:0.18000,W7:0.00585,W3:-0.42606,W1:-0.79488,W2:-0.98193 | memoryGatesShort:-35.275, Long:7.342, Current:28.933 | topTokens[('i', 3), ('to', 3), ('.', 3), ('was', 2), ('that', 2), ('a', 2), ('m', 1), ('dont', 1), ('ta', 1), ('(', 1)] | Training
2025-04-07 15:31:44 | 96500 | LR0.0003 | loss:3.8026 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-45.5390 | logitMax:-24.5875 | windowWeightsW21:1.16263,W18:0.82990,W15:0.55072,W13:0.35032,W8:0.18258,W7:0.01194,W3:-0.40883,W1:-0.76739,W2:-0.94967 | memoryGatesShort:-24.339, Long:4.885, Current:20.455 | topTokens[('.', 3), ('you', 3), ('?', 2), (',', 2), ('did', 2), ('will', 2), ('suggest', 1), ('ith', 1), ('sn', 1), ('er', 1)] | Training
2025-04-07 15:32:03 | 97000 | LR0.0003 | loss:5.3485 | gradNorm:0.9851 | tokenCount:2000.0000 | logitMin:-66.0330 | logitMax:-45.7953 | windowWeightsW21:1.21918,W18:0.86762,W15:0.56558,W13:0.36188,W8:0.18248,W7:0.00328,W3:-0.43455,W1:-0.80495,W2:-0.99985 | memoryGatesShort:-23.824, Long:5.068, Current:19.756 | topTokens[('.', 4), ('ing', 2), (',', 2), ('me', 2), ('he', 2), ('this', 2), ('a', 1), ('s', 1), ('an', 1), ('ie', 1)] | Training
2025-04-07 15:32:23 | 97500 | LR0.0003 | loss:5.7674 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-60.2304 | logitMax:-41.0853 | windowWeightsW21:1.27003,W18:0.89596,W15:0.58526,W13:0.37788,W8:0.18343,W7:-0.00365,W3:-0.45944,W1:-0.84389,W2:-1.04631 | memoryGatesShort:-25.093, Long:5.873, Current:20.219 | topTokens[('.', 9), ('i', 3), ('ith', 2), ('do', 2), ('ohh', 2), ('suggest', 1), ('confused', 1), ('ab', 1), ('this', 1), ('my', 1)] | Training
2025-04-07 15:32:43 | 98000 | LR0.0003 | loss:5.5977 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.5470 | logitMax:-37.4802 | windowWeightsW21:1.29566,W18:0.91182,W15:0.59469,W13:0.38203,W8:0.18757,W7:-0.00303,W3:-0.47473,W1:-0.86276,W2:-1.07274 | memoryGatesShort:-11.632, Long:3.020, Current:9.612 | topTokens[('.', 6), ('ohh', 2), ('you', 2), ('to', 2), ('and', 2), ('what', 1), (',', 1), ('ma', 1), ('talking', 1), ('with', 1)] | Training
2025-04-07 15:33:02 | 98500 | LR0.0003 | loss:6.0909 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-61.3662 | logitMax:-42.6584 | windowWeightsW21:1.38034,W18:0.96645,W15:0.62478,W13:0.39857,W8:0.18428,W7:-0.01585,W3:-0.51496,W1:-0.92281,W2:-1.14458 | memoryGatesShort:-16.267, Long:4.320, Current:12.947 | topTokens[('you', 4), ('.', 4), ('ag', 3), ('and', 2), ('still', 2), ('i', 2), ('until', 1), ('su', 1), ('kevin', 1), ('geepy', 1)] | Training
2025-04-07 15:33:22 | 99000 | LR0.0003 | loss:5.9784 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-60.7201 | logitMax:-42.3041 | windowWeightsW21:1.43321,W18:0.99585,W15:0.63851,W13:0.40521,W8:0.18331,W7:-0.02486,W3:-0.53461,W1:-0.95667,W2:-1.18510 | memoryGatesShort:-20.251, Long:5.345, Current:15.906 | topTokens[('?', 3), ('!', 2), ('.', 2), (')', 2), ('what', 1), ('kevin', 1), ('cra', 1), ('you', 1), ('xd', 1), ('she', 1)] | Training
2025-04-07 15:33:41 | 99500 | LR0.0003 | loss:5.1263 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-54.0562 | logitMax:-34.8923 | windowWeightsW21:1.47292,W18:1.01853,W15:0.64803,W13:0.41321,W8:0.18676,W7:-0.02937,W3:-0.55242,W1:-0.98274,W2:-1.22114 | memoryGatesShort:-35.970, Long:9.102, Current:27.868 | topTokens[('+', 3), ('boobs', 2), ('it', 2), ('?', 2), ('become', 1), ('ag', 1), ('nice', 1), ('house', 1), ('we', 1), ('idea', 1)] | Training
2025-04-07 15:34:08 | 100000 | LR0.0003 | loss:4.1376 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-48.7015 | logitMax:-29.3274 | windowWeightsW21:1.43425,W18:0.99049,W15:0.63776,W13:0.40836,W8:0.18526,W7:-0.02559,W3:-0.53259,W1:-0.95389,W2:-1.18921 | memoryGatesShort:-21.307, Long:5.255, Current:17.052 | topTokens[(',', 5), ('and', 4), ('s', 3), ('the', 3), ('i', 2), ('she', 2), ('elodie', 2), ('st', 2), ('listening', 1), ('so', 1)] | Training
2025-04-07 15:34:28 | 100500 | LR0.0003 | loss:4.3884 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-55.6265 | logitMax:-35.9071 | windowWeightsW21:1.40516,W18:0.97533,W15:0.63099,W13:0.40634,W8:0.18076,W7:-0.02456,W3:-0.51803,W1:-0.93409,W2:-1.16631 | memoryGatesShort:-17.459, Long:3.968, Current:14.492 | topTokens[('the', 5), ('+', 2), ('ag', 2), ('their', 2), ('ed', 2), ('me', 2), ('of', 1), ('ough', 1), ('.', 1), ('es', 1)] | Training
2025-04-07 15:34:48 | 101000 | LR0.0003 | loss:3.4193 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-50.2344 | logitMax:-28.2344 | windowWeightsW21:1.36008,W18:0.96108,W15:0.60989,W13:0.39744,W8:0.17624,W7:-0.02042,W3:-0.49891,W1:-0.90022,W2:-1.12843 | memoryGatesShort:-43.135, Long:8.946, Current:35.189 | topTokens[('had', 4), ('felt', 4), ('!', 4), (',', 2), ('our', 2), ('they', 1), ('ul', 1), ('the', 1), ('in', 1), ('un', 1)] | Training
2025-04-07 15:35:07 | 101500 | LR0.0003 | loss:5.8399 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-63.5098 | logitMax:-44.5579 | windowWeightsW21:1.44275,W18:1.00904,W15:0.63590,W13:0.40722,W8:0.17820,W7:-0.02906,W3:-0.53511,W1:-0.95747,W2:-1.19693 | memoryGatesShort:-37.128, Long:8.616, Current:29.512 | topTokens[('i', 4), ('the', 3), ('+', 2), ('.', 2), (',', 2), ('of', 2), ('ption', 1), ('=', 1), ('f', 1), ('s', 1)] | Training
2025-04-07 15:35:27 | 102000 | LR0.0003 | loss:5.6592 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-63.3571 | logitMax:-44.7553 | windowWeightsW21:1.46208,W18:1.02549,W15:0.63924,W13:0.41187,W8:0.18009,W7:-0.02996,W3:-0.54515,W1:-0.97160,W2:-1.21812 | memoryGatesShort:-16.147, Long:3.879, Current:13.268 | topTokens[('.', 3), ('of', 2), ('even', 2), ('they', 2), ('is', 2), ('in', 2), ('just', 2), ('to', 2), ('you', 1), ('es', 1)] | Training
2025-04-07 15:35:47 | 102500 | LR0.0003 | loss:3.6888 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.6192 | logitMax:-32.4093 | windowWeightsW21:1.38834,W18:0.98137,W15:0.61208,W13:0.40251,W8:0.17540,W7:-0.02394,W3:-0.51010,W1:-0.91740,W2:-1.15227 | memoryGatesShort:-24.437, Long:5.156, Current:20.281 | topTokens[(',', 5), ('+', 4), ('and', 4), ('the', 2), ('weed', 2), ('s', 2), ("'re", 1), ('done', 1), ('elodie', 1), ('she', 1)] | Training
2025-04-07 15:36:06 | 103000 | LR0.0003 | loss:3.3211 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.2924 | logitMax:-30.8104 | windowWeightsW21:1.37360,W18:0.96442,W15:0.60165,W13:0.39446,W8:0.17737,W7:-0.01701,W3:-0.49754,W1:-0.90458,W2:-1.13591 | memoryGatesShort:-23.593, Long:4.793, Current:19.799 | topTokens[('and', 7), (',', 4), ('charis', 3), ('the', 2), ('her', 2), ('ves', 2), ('she', 2), ('you', 2), ('elodie', 1), ('res', 1)] | Training
2025-04-07 15:36:25 | 103500 | LR0.0003 | loss:2.6027 | gradNorm:0.9987 | tokenCount:2000.0000 | logitMin:-57.9468 | logitMax:-36.1381 | windowWeightsW21:1.30659,W18:0.91562,W15:0.57932,W13:0.38246,W8:0.17364,W7:-0.00583,W3:-0.46187,W1:-0.85374,W2:-1.07782 | memoryGatesShort:-160.669, Long:28.222, Current:133.448 | topTokens[('and', 4), (',', 3), ('it', 2), ('i', 2), ('!', 2), ('ided', 1), ('france', 1), ('mainly', 1), ('smo', 1), ('me', 1)] | Training
2025-04-07 15:36:45 | 104000 | LR0.0003 | loss:5.3170 | gradNorm:0.9993 | tokenCount:2000.0000 | logitMin:-62.1817 | logitMax:-40.4952 | windowWeightsW21:1.35815,W18:0.95383,W15:0.59623,W13:0.39567,W8:0.16999,W7:-0.01950,W3:-0.48181,W1:-0.89219,W2:-1.12346 | memoryGatesShort:-25.660, Long:5.169, Current:21.491 | topTokens[(',', 4), ('you', 2), ('like', 2), ('but', 2), ('i', 2), ('us', 2), ('bu', 1), ('she', 1), ('m', 1), ('t', 1)] | Training
2025-04-07 15:37:04 | 104500 | LR0.0003 | loss:5.2356 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-57.3134 | logitMax:-36.7929 | windowWeightsW21:1.41842,W18:0.98550,W15:0.61864,W13:0.40987,W8:0.17281,W7:-0.02082,W3:-0.51238,W1:-0.93612,W2:-1.18069 | memoryGatesShort:-16.041, Long:3.707, Current:13.334 | topTokens[(',', 6), ('ption', 3), ('i', 2), ('me', 2), ('>', 1), ('butt', 1), ('music', 1), ('-', 1), ('p', 1), ('not', 1)] | Training
2025-04-07 15:37:24 | 105000 | LR0.0003 | loss:5.3525 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-65.5728 | logitMax:-45.5980 | windowWeightsW21:1.49297,W18:1.03319,W15:0.64210,W13:0.41598,W8:0.17235,W7:-0.03390,W3:-0.54235,W1:-0.98472,W2:-1.24238 | memoryGatesShort:-33.976, Long:7.697, Current:27.279 | topTokens[('s', 2), ('ill', 2), ('i', 2), ('y', 2), ('know', 2), ('!', 1), ('in', 1), ('ad', 1), ('room', 1), ("'m", 1)] | Training
2025-04-07 15:37:43 | 105500 | LR0.0003 | loss:5.1281 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-60.0550 | logitMax:-40.8355 | windowWeightsW21:1.52910,W18:1.05774,W15:0.65697,W13:0.42431,W8:0.17308,W7:-0.03979,W3:-0.56000,W1:-1.01283,W2:-1.27639 | memoryGatesShort:-13.965, Long:3.461, Current:11.504 | topTokens[('i', 4), ('ption', 2), ('.', 2), ('s', 2), (',', 2), ('gh', 1), ('it', 1), ('them', 1), ('<', 1), ('cool', 1)] | Training
2025-04-07 15:38:03 | 106000 | LR0.0003 | loss:5.5659 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-57.8741 | logitMax:-38.5913 | windowWeightsW21:1.57645,W18:1.09110,W15:0.67966,W13:0.44403,W8:0.17480,W7:-0.04408,W3:-0.59039,W1:-1.05725,W2:-1.32353 | memoryGatesShort:-14.654, Long:3.729, Current:11.925 | topTokens[('to', 3), ('of', 3), ('a', 2), ('ill', 2), ('the', 2), ('this', 1), ('sound', 1), ('ru', 1), ('looks', 1), ('weed', 1)] | Training
2025-04-07 15:38:22 | 106500 | LR0.0003 | loss:5.0854 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-62.3706 | logitMax:-43.2907 | windowWeightsW21:1.59331,W18:1.10391,W15:0.68244,W13:0.44621,W8:0.17576,W7:-0.04652,W3:-0.59977,W1:-1.06465,W2:-1.34039 | memoryGatesShort:-13.307, Long:3.340, Current:10.966 | topTokens[('=', 4), ('and', 3), ('-', 2), ('of', 2), ('not', 2), ('+', 1), ('game', 1), ('is', 1), ('ouse', 1), ('art', 1)] | Training
2025-04-07 15:38:43 | 107000 | LR0.0003 | loss:5.0418 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-67.5161 | logitMax:-47.5356 | windowWeightsW21:1.63531,W18:1.12819,W15:0.69265,W13:0.44590,W8:0.17854,W7:-0.05073,W3:-0.61448,W1:-1.09185,W2:-1.37434 | memoryGatesShort:-17.102, Long:4.177, Current:13.925 | topTokens[('s', 3), ('-', 3), (',', 2), ('ter', 2), ('age', 2), ('ed', 2), ('be', 1), ('nt', 1), ('to', 1), ('those', 1)] | Training
2025-04-07 15:39:03 | 107500 | LR0.0003 | loss:5.6344 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-62.8193 | logitMax:-43.9088 | windowWeightsW21:1.70059,W18:1.17283,W15:0.71679,W13:0.45726,W8:0.17555,W7:-0.06355,W3:-0.64567,W1:-1.13643,W2:-1.43001 | memoryGatesShort:-21.514, Long:5.231, Current:17.283 | topTokens[('mid', 4), (',', 4), ('.', 3), ('it', 2), ('out', 2), ('being', 1), ('her', 1), ('you', 1), ('just', 1), ('ouse', 1)] | Training
2025-04-07 15:39:23 | 108000 | LR0.0003 | loss:5.6394 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-62.2471 | logitMax:-43.2213 | windowWeightsW21:1.71193,W18:1.18285,W15:0.71655,W13:0.45294,W8:0.17445,W7:-0.06502,W3:-0.64931,W1:-1.13902,W2:-1.43830 | memoryGatesShort:-14.716, Long:3.584, Current:12.132 | topTokens[(',', 3), ('i', 3), ('not', 3), ('to', 2), ('from', 2), ('was', 2), ('and', 1), ('ket', 1), ('off', 1), ('elodie', 1)] | Training
2025-04-07 15:39:42 | 108500 | LR0.0003 | loss:5.2202 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-57.0151 | logitMax:-37.6858 | windowWeightsW21:1.72710,W18:1.20048,W15:0.72855,W13:0.46408,W8:0.17177,W7:-0.07043,W3:-0.66692,W1:-1.15133,W2:-1.45676 | memoryGatesShort:-247.192, Long:53.281, Current:194.910 | topTokens[('.', 4), ('ption', 2), ('uk', 2), (',', 2), ('just', 2), ('very', 1), ('f', 1), ('gr', 1), ('i', 1), ('ten', 1)] | Training
2025-04-07 15:40:02 | 109000 | LR0.0003 | loss:4.7902 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-49.7211 | logitMax:-29.1648 | windowWeightsW21:1.70357,W18:1.18541,W15:0.72557,W13:0.46052,W8:0.17754,W7:-0.06513,W3:-0.65837,W1:-1.14049,W2:-1.44150 | memoryGatesShort:-14.683, Long:3.516, Current:12.167 | topTokens[('?', 5), ('.', 4), ('you', 3), ('to', 3), ('want', 1), ('out', 1), ('not', 1), ('have', 1), ('games', 1), ('know', 1)] | Training
2025-04-07 15:40:21 | 109500 | LR0.0003 | loss:4.6998 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-52.6029 | logitMax:-31.8463 | windowWeightsW21:1.70128,W18:1.18422,W15:0.71844,W13:0.45684,W8:0.17973,W7:-0.06514,W3:-0.65689,W1:-1.13447,W2:-1.43680 | memoryGatesShort:-32.924, Long:7.263, Current:26.661 | topTokens[(',', 4), ('to', 3), ('did', 2), ('?', 2), ('you', 2), ('a', 2), ('hmm', 1), ('sort', 1), ('i', 1), ('left', 1)] | Training
2025-04-07 15:40:48 | 110000 | LR0.0003 | loss:5.8255 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-61.5490 | logitMax:-42.0645 | windowWeightsW21:1.81466,W18:1.26240,W15:0.76289,W13:0.48460,W8:0.18200,W7:-0.07903,W3:-0.71515,W1:-1.22159,W2:-1.54685 | memoryGatesShort:-26.215, Long:6.338, Current:20.877 | topTokens[(',', 4), ('?', 2), ('you', 2), ('no', 2), ('.', 2), ('a', 2), ('!', 2), ('her', 1), ('right', 1), (')', 1)] | Training
2025-04-07 15:41:08 | 110500 | LR0.0003 | loss:5.4319 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-60.5714 | logitMax:-41.3693 | windowWeightsW21:1.83261,W18:1.27208,W15:0.76885,W13:0.48742,W8:0.18008,W7:-0.08118,W3:-0.72155,W1:-1.23273,W2:-1.56213 | memoryGatesShort:-17.786, Long:4.428, Current:14.357 | topTokens[('=', 4), ('.', 3), ('er', 2), ('you', 2), ('i', 2), (',', 1), ('a', 1), ('think', 1), ('ing', 1), ('what', 1)] | Training
2025-04-07 15:41:28 | 111000 | LR0.0003 | loss:5.2198 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-61.6939 | logitMax:-42.1434 | windowWeightsW21:1.86177,W18:1.28665,W15:0.78011,W13:0.49633,W8:0.18352,W7:-0.08719,W3:-0.73792,W1:-1.25206,W2:-1.58855 | memoryGatesShort:-28.221, Long:7.035, Current:22.186 | topTokens[('.', 3), ('i', 2), ('?', 2), ('now', 2), ('is', 2), ('im', 2), ('ke', 2), ('n', 1), ('on', 1), ('li', 1)] | Training
2025-04-07 15:41:47 | 111500 | LR0.0003 | loss:4.2205 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-61.5494 | logitMax:-41.6311 | windowWeightsW21:1.77235,W18:1.22765,W15:0.73958,W13:0.47458,W8:0.17694,W7:-0.07874,W3:-0.69408,W1:-1.17328,W2:-1.49975 | memoryGatesShort:-16.176, Long:3.745, Current:13.431 | topTokens[('mid', 3), (',', 3), ('and', 2), ('s', 2), ('there', 2), ('_', 1), ('ood', 1), ('is', 1), ('their', 1), ('but', 1)] | Training
2025-04-07 15:42:07 | 112000 | LR0.0003 | loss:4.0175 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-59.3827 | logitMax:-37.8322 | windowWeightsW21:1.82676,W18:1.26451,W15:0.74942,W13:0.47398,W8:0.17206,W7:-0.09161,W3:-0.71299,W1:-1.19821,W2:-1.54010 | memoryGatesShort:-21.539, Long:4.836, Current:17.704 | topTokens[('.', 3), ('w', 3), (',', 2), ('into', 2), ('ood', 2), ('m', 2), ('ice', 2), ('str', 1), ('did', 1), ('the', 1)] | Training
2025-04-07 15:42:26 | 112500 | LR0.0003 | loss:3.6819 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.7718 | logitMax:-35.4936 | windowWeightsW21:1.82171,W18:1.24937,W15:0.74082,W13:0.46321,W8:0.17008,W7:-0.09194,W3:-0.70383,W1:-1.18019,W2:-1.52511 | memoryGatesShort:-33.021, Long:6.952, Current:27.068 | topTokens[(',', 4), ('=', 3), ('!', 3), ('a', 2), ('the', 2), ('w', 2), ('m', 2), ('k', 2), ('angle', 2), ('mid', 1)] | Training
2025-04-07 15:42:46 | 113000 | LR0.0003 | loss:3.2917 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.3317 | logitMax:-34.7432 | windowWeightsW21:1.66344,W18:1.15546,W15:0.69886,W13:0.44065,W8:0.17217,W7:-0.06774,W3:-0.63584,W1:-1.08407,W2:-1.39457 | memoryGatesShort:-19.417, Long:4.006, Current:16.411 | topTokens[('!', 4), ('they', 2), ('w', 2), ('w', 2), ('it', 2), ('id', 2), ('i', 2), ('end', 1), ('said', 1), ('about', 1)] | Training
2025-04-07 15:43:05 | 113500 | LR0.0003 | loss:3.8583 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-50.8039 | logitMax:-28.6701 | windowWeightsW21:1.60733,W18:1.12782,W15:0.67750,W13:0.42651,W8:0.17186,W7:-0.05617,W3:-0.60273,W1:-1.05697,W2:-1.34529 | memoryGatesShort:-23.685, Long:4.824, Current:19.861 | topTokens[('!', 4), ('y', 3), (',', 2), ('just', 2), ('.', 2), ('charis', 2), ('havent', 1), ('totally', 1), ('sucks', 1), ('mid', 1)] | Training
2025-04-07 15:43:25 | 114000 | LR0.0003 | loss:2.8606 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-49.2962 | logitMax:-25.9722 | windowWeightsW21:1.55430,W18:1.10088,W15:0.65807,W13:0.41480,W8:0.16911,W7:-0.05852,W3:-0.57502,W1:-1.01658,W2:-1.29573 | memoryGatesShort:-27.091, Long:5.432, Current:22.660 | topTokens[('!', 9), ('it', 5), ('should', 3), ('could', 2), ('have', 2), ('saying', 2), ('s', 1), ('need', 1), ('i', 1), ('ate', 1)] | Training
2025-04-07 15:43:45 | 114500 | LR0.0003 | loss:5.8997 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-60.4033 | logitMax:-39.4558 | windowWeightsW21:1.67685,W18:1.18897,W15:0.70663,W13:0.43828,W8:0.17222,W7:-0.07312,W3:-0.63696,W1:-1.11080,W2:-1.41432 | memoryGatesShort:-109.668, Long:24.157, Current:86.512 | topTokens[('felt', 3), (',', 3), ('it', 2), ('baby', 2), ('n', 2), ('!', 2), ('am', 1), ('bab', 1), ('a', 1), ('let', 1)] | Training
2025-04-07 15:44:04 | 115000 | LR0.0003 | loss:6.1476 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-60.1388 | logitMax:-40.7893 | windowWeightsW21:1.78448,W18:1.26367,W15:0.74807,W13:0.46048,W8:0.17046,W7:-0.09026,W3:-0.68574,W1:-1.19028,W2:-1.51623 | memoryGatesShort:-21.334, Long:5.391, Current:16.942 | topTokens[('.', 3), ('a', 2), ('the', 2), ('he', 2), ('cat', 1), ('there', 1), ('s', 1), ('that', 1), ('ing', 1), ('i', 1)] | Training
2025-04-07 15:44:24 | 115500 | LR0.0003 | loss:5.5638 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-56.2792 | logitMax:-36.6761 | windowWeightsW21:1.82349,W18:1.27734,W15:0.75632,W13:0.46649,W8:0.17591,W7:-0.08858,W3:-0.70149,W1:-1.21624,W2:-1.54959 | memoryGatesShort:-18.735, Long:4.768, Current:14.967 | topTokens[('_', 3), ('.', 3), ('and', 2), ('is', 2), ('to', 2), ('on', 2), ('=', 1), ('who', 1), ('were', 1), ('tho', 1)] | Training
2025-04-07 15:44:44 | 116000 | LR0.0003 | loss:5.4290 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-62.5687 | logitMax:-43.3115 | windowWeightsW21:1.84289,W18:1.29018,W15:0.76769,W13:0.47457,W8:0.18155,W7:-0.08864,W3:-0.71419,W1:-1.23490,W2:-1.57613 | memoryGatesShort:-52.586, Long:12.770, Current:40.816 | topTokens[('i', 4), ('be', 2), ('ed', 2), ("'s", 2), ('ing', 2), (',', 2), ('l', 2), ('m', 1), ('what', 1), ('an', 1)] | Training
2025-04-07 15:45:03 | 116500 | LR0.0003 | loss:5.8112 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-64.8377 | logitMax:-46.0071 | windowWeightsW21:1.96732,W18:1.37509,W15:0.81036,W13:0.49590,W8:0.18201,W7:-0.10891,W3:-0.77026,W1:-1.32294,W2:-1.68912 | memoryGatesShort:-14.417, Long:3.987, Current:11.430 | topTokens[('trust', 3), ('the', 2), ('.', 2), ('as', 2), ('p', 2), ('havent', 1), ('website', 1), ('of', 1), ('be', 1), ('on', 1)] | Training
2025-04-07 15:45:23 | 117000 | LR0.0003 | loss:3.0399 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-41.5729 | logitMax:-20.2081 | windowWeightsW21:1.76578,W18:1.23708,W15:0.73816,W13:0.46158,W8:0.17753,W7:-0.08576,W3:-0.67407,W1:-1.16989,W2:-1.50518 | memoryGatesShort:-15.342, Long:3.788, Current:12.554 | topTokens[('been', 6), ('has', 3), ('the', 3), ('have', 3), ('ing', 2), ('elodie', 2), ('to', 2), ('you', 2), ('want', 2), ('g', 1)] | Training
2025-04-07 15:45:42 | 117500 | LR0.0003 | loss:3.9429 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-47.7071 | logitMax:-26.2087 | windowWeightsW21:1.80300,W18:1.26734,W15:0.75433,W13:0.47067,W8:0.16772,W7:-0.09902,W3:-0.68940,W1:-1.19294,W2:-1.53754 | memoryGatesShort:-82.816, Long:18.724, Current:65.092 | topTokens[('!', 4), ('been', 4), ('pic', 3), ('he', 2), ('moving', 1), ("'s", 1), ('have', 1), ('hear', 1), ('me', 1), ('their', 1)] | Training
2025-04-07 15:46:01 | 118000 | LR0.0003 | loss:5.8356 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-59.1360 | logitMax:-39.2407 | windowWeightsW21:1.95910,W18:1.37719,W15:0.81378,W13:0.50782,W8:0.17214,W7:-0.11895,W3:-0.76881,W1:-1.31331,W2:-1.68939 | memoryGatesShort:-25.723, Long:6.671, Current:20.052 | topTokens[('.', 5), ('our', 2), (',', 2), ('me', 2), ('think', 1), ('she', 1), ('a', 1), ('of', 1), ('z', 1), ('(', 1)] | Training
2025-04-07 15:46:28 | 118500 | LR0.0003 | loss:5.9096 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-63.7016 | logitMax:-44.8817 | windowWeightsW21:2.14000,W18:1.48339,W15:0.87586,W13:0.54113,W8:0.17007,W7:-0.14905,W3:-0.85078,W1:-1.43114,W2:-1.84492 | memoryGatesShort:-27.445, Long:7.357, Current:21.088 | topTokens[('i', 4), ('=', 2), ('it', 2), ('.', 2), ('ing', 2), ('until', 1), ('ents', 1), ('s', 1), ('in', 1), ('p', 1)] | Training
2025-04-07 15:46:48 | 119000 | LR0.0003 | loss:5.4178 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-61.9346 | logitMax:-43.1389 | windowWeightsW21:2.17180,W18:1.50676,W15:0.89213,W13:0.55420,W8:0.17204,W7:-0.15214,W3:-0.87025,W1:-1.46053,W2:-1.88046 | memoryGatesShort:-25.129, Long:6.835, Current:19.294 | topTokens[('ing', 2), ('k', 2), ('to', 2), ('?', 1), ('person', 1), ('your', 1), ('elodie', 1), ('at', 1), ('in', 1), ('the', 1)] | Training
2025-04-07 15:47:07 | 119500 | LR0.0003 | loss:5.1994 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-61.3358 | logitMax:-42.9120 | windowWeightsW21:2.10747,W18:1.47852,W15:0.87612,W13:0.54029,W8:0.17304,W7:-0.14246,W3:-0.84282,W1:-1.42183,W2:-1.83307 | memoryGatesShort:-27.804, Long:7.169, Current:21.635 | topTokens[('_', 2), ('f', 2), ('.', 2), ('to', 2), ('to', 1), ('det', 1), ('with', 1), ('from', 1), ('comp', 1), ('i', 1)] | Training
2025-04-07 15:47:34 | 120000 | LR0.0003 | loss:3.8086 | gradNorm:1.0000 | tokenCount:2000.0000 | logitMin:-51.0399 | logitMax:-30.1074 | windowWeightsW21:1.92721,W18:1.34489,W15:0.81047,W13:0.51491,W8:0.17334,W7:-0.11218,W3:-0.75330,W1:-1.29933,W2:-1.66556 | memoryGatesShort:-41.417, Long:9.615, Current:32.802 | topTokens[('to', 3), ('.', 2), ('?', 2), ('been', 2), ('s', 2), ('she', 2), ('listen', 2), ('en', 1), ('ed', 1), ('g', 1)] | Training
2025-04-07 15:47:54 | 120500 | LR0.0003 | loss:2.6401 | gradNorm:0.9974 | tokenCount:2000.0000 | logitMin:-54.7554 | logitMax:-31.3589 | windowWeightsW21:1.64339,W18:1.16871,W15:0.73003,W13:0.47246,W8:0.17869,W7:-0.06625,W3:-0.63378,W1:-1.11892,W2:-1.42614 | memoryGatesShort:-9.651, Long:2.443, Current:8.208 | topTokens[('to', 4), ('charis', 3), ('from', 3), ('ption', 2), ('i', 2), ('and', 2), ('?', 2), ('-', 2), (':', 2), ('hmm', 1)] | Training

CHANGED LOG FREQUENCY TO EVERY 5000 STEPS
--- 2025-04-07 15:52:00 --- babyLLM 'right, last time i got to step 120957... want to restart from there?'  - charis: 'no, restart from scratch - u fucking finished an epoch wtf!?' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: 'more'
2025-04-07 15:55:11 | 5000 | LR0.0003 | loss:3.6578 | gradNorm:1.0000 | logitMin:-63.2300 | logitMax:-41.2430 | tokenCount:20000.0000 | windowWeightsW21:1.41310,W18:0.99781,W15:0.62302,W13:0.41751,W8:0.19381,W7:-0.02816,W3:-0.50260,W1:-0.94856,W2:-1.21111 | memoryGatesShort:-17.777, Long:4.609, Current:14.168 | topTokens[('to', 23), ('.', 20), ('?', 20), (',', 14), ('a', 13), ('will', 12), ('you', 12), ('is', 11), ('was', 11), ('what', 10)] | Training
2025-04-07 15:58:31 | 10000 | LR0.0003 | loss:3.4211 | gradNorm:1.0000 | tokenCount:20000.0000 | logitMin:-66.6699 | logitMax:-45.0344 | windowWeightsW21:1.14814,W18:0.80630,W15:0.53383,W13:0.36152,W8:0.21882,W7:0.03116,W3:-0.37335,W1:-0.78646,W2:-0.97798 | memoryGatesShort:-21.298, Long:6.449, Current:15.849 | topTokens[('?', 35), ('.', 31), ('to', 19), ('you', 16), ('a', 13), ('i', 12), ('is', 11), ('will', 10), (',', 10), ('was', 10)] | Training
2025-04-07 16:01:58 | 15000 | LR0.0003 | loss:3.2667 | gradNorm:0.9962 | tokenCount:20000.0000 | logitMin:-66.2809 | logitMax:-43.1621 | windowWeightsW21:0.89863,W18:0.63121,W15:0.44370,W13:0.31340,W8:0.23252,W7:0.08908,W3:-0.25938,W1:-0.62093,W2:-0.75957 | memoryGatesShort:-12.862, Long:4.424, Current:9.439 | topTokens[('.', 27), ('?', 26), ('!', 14), ('you', 14), (',', 10), ('to', 10), ('was', 9), ('-', 9), ('what', 8), (':', 8)] | Training
2025-04-07 16:05:18 | 20000 | LR0.0003 | loss:2.7407 | gradNorm:0.9725 | tokenCount:20000.0000 | logitMin:-55.0046 | logitMax:-25.6313 | windowWeightsW21:0.76723,W18:0.52908,W15:0.42001,W13:0.30482,W8:0.22680,W7:0.10786,W3:-0.21417,W1:-0.53159,W2:-0.63788 | memoryGatesShort:-23.298, Long:10.877, Current:13.421 | topTokens[("'", 32), (':', 29), ('-', 24), ('that', 21), ("'", 20), ('.', 15), ('-', 13), ('you', 12), ('20', 10), ('charis', 10)] | Training
2025-04-07 16:08:32 | 25000 | LR0.0003 | loss:2.9106 | gradNorm:0.9758 | tokenCount:20000.0000 | logitMin:-60.5691 | logitMax:-33.4707 | windowWeightsW21:0.65340,W18:0.44484,W15:0.38277,W13:0.29107,W8:0.23333,W7:0.13187,W3:-0.16333,W1:-0.45886,W2:-0.54006 | memoryGatesShort:-11.264, Long:5.855, Current:6.409 | topTokens[(':', 28), ("'", 19), ('-', 19), ("'", 14), ('0', 14), ('2', 13), ('-', 13), ('.', 13), ('playing', 13), ('3', 10)] | Training
2025-04-07 16:11:54 | 30000 | LR0.0003 | loss:3.5738 | gradNorm:0.9764 | tokenCount:20000.0000 | logitMin:-61.8752 | logitMax:-36.9724 | windowWeightsW21:0.62994,W18:0.41597,W15:0.37478,W13:0.27818,W8:0.24356,W7:0.14658,W3:-0.16118,W1:-0.44347,W2:-0.50876 | memoryGatesShort:-14.151, Long:8.222, Current:6.929 | topTokens[('were', 20), (':', 19), ('1', 19), ('0', 18), ('-', 17), ('2', 16), ("'", 13), ('-', 13), ('4', 12), ('5', 11)] | Training

CHANGED LOG FREQ TO 2500

--- 2025-04-07 16:14:30 --- babyLLM 'right, last time i got to step 30641... want to restart from there?'  - charis: 'Y' - babyLLM 'umm... i don't think i heard you properly, i'll just start from step 0 :) but, what am i learning today?' - charis: 'that i had my caps lock left on lol'
2025-04-07 16:17:10 | 2500 | LR0.0003 | loss:3.3267 | gradNorm:1.0000 | logitMin:-71.8731 | logitMax:-53.1329 | tokenCount:20000.0000 | windowWeightsW21:0.54783,W18:0.36757,W15:0.34814,W13:0.25946,W8:0.23058,W7:0.14503,W3:-0.11498,W1:-0.37012,W2:-0.43567 | memoryGatesShort:-11.262, Long:5.347, Current:6.915 | topTokens[('.', 27), ('will', 20), ('?', 19), ('to', 16), ('be', 14), ('i', 14), ('a', 13), (',', 11), ('!', 11), ('is', 11)] | Training
2025-04-07 16:19:47 | 5000 | LR0.0003 | loss:3.4172 | gradNorm:1.0000 | tokenCount:20000.0000 | logitMin:-80.7541 | logitMax:-60.9575 | windowWeightsW21:0.52580,W18:0.35914,W15:0.32290,W13:0.24816,W8:0.22304,W7:0.13971,W3:-0.09323,W1:-0.33910,W2:-0.40789 | memoryGatesShort:-11.275, Long:5.152, Current:7.123 | topTokens[('?', 29), ('.', 28), ('to', 21), ('is', 16), ('i', 16), ('a', 15), ('word', 12), ('you', 11), (',', 11), ('will', 10)] | Training
2025-04-07 16:22:18 | 7500 | LR0.0003 | loss:2.9415 | gradNorm:1.0000 | tokenCount:20000.0000 | logitMin:-81.7293 | logitMax:-62.0343 | windowWeightsW21:0.48117,W18:0.33666,W15:0.29518,W13:0.23465,W8:0.21761,W7:0.13588,W3:-0.06119,W1:-0.29842,W2:-0.36189 | memoryGatesShort:-13.784, Long:5.526, Current:9.257 | topTokens[('.', 34), ('?', 24), ('you', 19), ('is', 16), ('to', 14), (',', 12), ('a', 12), ('music', 11), ('i', 10), ('what', 9)] | Training
2025-04-07 16:25:02 | 10000 | LR0.0003 | loss:3.1460 | gradNorm:1.0000 | tokenCount:20000.0000 | logitMin:-79.6123 | logitMax:-59.2835 | windowWeightsW21:0.44777,W18:0.31639,W15:0.28545,W13:0.22748,W8:0.21255,W7:0.13928,W3:-0.04397,W1:-0.27044,W2:-0.33410 | memoryGatesShort:-8.455, Long:3.010, Current:6.445 | topTokens[('?', 28), ('to', 25), ('.', 22), ('i', 16), ('you', 13), ('is', 13), ('!', 11), ('he', 10), ('what', 9), ('please', 9)] | Training
2025-04-07 16:27:39 | 12500 | LR0.0003 | loss:3.1944 | gradNorm:1.0000 | tokenCount:20000.0000 | logitMin:-85.0765 | logitMax:-65.2344 | windowWeightsW21:0.42785,W18:0.30442,W15:0.26802,W13:0.21907,W8:0.20731,W7:0.14006,W3:-0.02686,W1:-0.24393,W2:-0.31503 | memoryGatesShort:-10.735, Long:2.825, Current:8.910 | topTokens[('.', 33), ('?', 24), ('a', 16), ('is', 14), ('what', 13), ('you', 13), ('i', 11), ('!', 11), ('kevin', 8), ('he', 8)] | Training
2025-04-07 16:30:15 | 15000 | LR0.0003 | loss:2.6118 | gradNorm:0.9997 | tokenCount:20000.0000 | logitMin:-65.3392 | logitMax:-42.6096 | windowWeightsW21:0.41225,W18:0.29355,W15:0.26498,W13:0.21982,W8:0.19575,W7:0.13451,W3:-0.02653,W1:-0.22120,W2:-0.29177 | memoryGatesShort:-5.143, Long:1.286, Current:4.857 | topTokens[('?', 23), ('.', 20), (':', 18), ('-', 14), ('is', 12), ('to', 11), ('5', 11), ('i', 10), ('a', 10), ('what', 9)] | Training
2025-04-07 16:32:52 | 17500 | LR0.0003 | loss:2.0500 | gradNorm:0.9997 | tokenCount:20000.0000 | logitMin:-49.4183 | logitMax:-24.3873 | windowWeightsW21:0.40369,W18:0.27817,W15:0.26463,W13:0.22720,W8:0.18390,W7:0.13526,W3:-0.03203,W1:-0.20535,W2:-0.27381 | memoryGatesShort:-3.774, Long:0.261, Current:4.513 | topTokens[(':', 28), ('-', 26), ('-', 20), ('2', 18), ("'", 17), ("'", 16), ('20', 15), ('3', 15), ('5', 14), ('.', 13)] | Training
2025-04-07 16:35:37 | 20000 | LR0.0003 | loss:2.8108 | gradNorm:0.9989 | tokenCount:20000.0000 | logitMin:-57.1078 | logitMax:-31.4928 | windowWeightsW21:0.38232,W18:0.26141,W15:0.25328,W13:0.21471,W8:0.18408,W7:0.13549,W3:-0.02663,W1:-0.17904,W2:-0.24346 | memoryGatesShort:-5.407, Long:-0.444, Current:6.850 | topTokens[('that', 44), ("'", 21), (':', 20), ('-', 19), ("'", 17), ('ll', 13), ('i', 12), ('?', 11), ('m', 11), ('baby', 10)] | Training
2025-04-07 16:38:14 | 22500 | LR0.0003 | loss:2.7614 | gradNorm:0.9968 | tokenCount:20000.0000 | logitMin:-57.6795 | logitMax:-33.3392 | windowWeightsW21:0.36175,W18:0.24747,W15:0.23910,W13:0.20950,W8:0.18599,W7:0.13527,W3:-0.02259,W1:-0.15398,W2:-0.21998 | memoryGatesShort:-3.444, Long:-2.609, Current:7.053 | topTokens[(':', 32), ('-', 24), ("'", 20), ('playing', 20), ("'", 19), ('is', 12), ('-', 11), ('3', 10), ('0', 10), ('.', 9)] | Training
2025-04-07 16:40:50 | 25000 | LR0.0003 | loss:2.3306 | gradNorm:0.9994 | tokenCount:20000.0000 | logitMin:-64.0636 | logitMax:-40.2191 | windowWeightsW21:0.34956,W18:0.23374,W15:0.22897,W13:0.20278,W8:0.18535,W7:0.14324,W3:-0.01827,W1:-0.14433,W2:-0.19828 | memoryGatesShort:-0.237, Long:-2.269, Current:3.507 | topTokens[(':', 25), ('look', 20), ('3', 19), ('-', 18), ('2', 16), ('0', 15), ('-', 12), ('7', 12), ("'", 11), ('later', 11)] | Training
2025-04-07 16:43:27 | 27500 | LR0.0003 | loss:3.3422 | gradNorm:1.0000 | tokenCount:20000.0000 | logitMin:-65.2793 | logitMax:-42.3653 | windowWeightsW21:0.35433,W18:0.23634,W15:0.23386,W13:0.19378,W8:0.18127,W7:0.13791,W3:-0.02601,W1:-0.14306,W2:-0.18564 | memoryGatesShort:0.865, Long:-2.572, Current:2.707 | topTokens[(':', 29), ('were', 24), ('0', 19), ('-', 16), ('1', 16), ("'", 15), ('b', 15), ('-', 14), ('5', 13), ('you', 10)] | Training
2025-04-07 16:46:11 | 30000 | LR0.0003 | loss:2.8363 | gradNorm:0.9987 | tokenCount:20000.0000 | logitMin:-60.1623 | logitMax:-37.1691 | windowWeightsW21:0.35052,W15:0.23313,W18:0.23126,W13:0.18898,W8:0.18450,W7:0.13757,W3:-0.03537,W1:-0.13109,W2:-0.17663 | memoryGatesShort:1.688, Long:-3.108, Current:2.420 | topTokens[('-', 28), (':', 26), ('0', 18), ('2', 17), ('-', 17), ('4', 16), ("'", 16), ("'", 15), ('1', 11), ('5', 10)] | Training
2025-04-07 16:48:48 | 32500 | LR0.0003 | loss:2.7508 | gradNorm:0.9960 | tokenCount:20000.0000 | logitMin:-60.3959 | logitMax:-36.5170 | windowWeightsW21:0.35007,W18:0.23178,W15:0.22568,W8:0.18752,W13:0.17865,W7:0.13071,W3:-0.03574,W1:-0.12011,W2:-0.16563 | memoryGatesShort:1.922, Long:-2.953, Current:2.031 | topTokens[(':', 27), ('-', 25), ('0', 21), ('be', 19), ("'", 17), ('-', 15), ('3', 14), ("'", 13), ('.', 13), ('2', 12)] | Training
2025-04-07 16:51:24 | 35000 | LR0.0003 | loss:4.5612 | gradNorm:1.0000 | tokenCount:20000.0000 | logitMin:-70.8848 | logitMax:-51.3996 | windowWeightsW21:0.37139,W18:0.24650,W15:0.23480,W8:0.18181,W13:0.18148,W7:0.11408,W3:-0.04994,W1:-0.12638,W2:-0.17111 | memoryGatesShort:4.215, Long:-6.986, Current:3.771 | topTokens[(':', 20), ('.', 20), ('-', 20), ('-', 16), ('0', 16), ("'", 14), ("'", 12), ('4', 9), ('3', 9), (',', 9)] | Training
2025-04-07 16:54:01 | 37500 | LR0.0003 | loss:5.9355 | gradNorm:1.0000 | tokenCount:20000.0000 | logitMin:-75.0338 | logitMax:-58.9860 | windowWeightsW21:0.40911,W18:0.27476,W15:0.24658,W13:0.18080,W8:0.17024,W7:0.09662,W3:-0.06860,W1:-0.13233,W2:-0.19525 | memoryGatesShort:5.523, Long:-10.372, Current:5.849 | topTokens[('.', 43), ('i', 23), ('and', 13), (',', 12), ('guy', 11), ('it', 10), ('a', 7), ('you', 6), ('!', 6), ('the', 6)] | Training

--- 2025-04-07 16:54:12 --- babyLLM 'right, last time i got to step 30000... want to restart from there?'  - charis: 'no, start from scratch - new data, and 12 infer' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: '12 token view!!'
2025-04-07 16:57:44 | 40000 | LR0.0003 | loss:5.5556 | gradNorm:1.0000 | tokenCount:20000.0000 | logitMin:-72.4889 | logitMax:-55.6410 | windowWeightsW21:0.44611,W18:0.29589,W15:0.25711,W13:0.18211,W8:0.15419,W7:0.07501,W3:-0.08401,W1:-0.13379,W2:-0.21135 | memoryGatesShort:6.539, Long:-12.524, Current:6.985 | topTokens[('.', 42), ('i', 24), ('a', 15), ('you', 12), ('?', 7), ('and', 7), ('know', 6), ('to', 5), ('!', 5), ('in', 5)] | Training
2025-04-07 16:59:04 | 2500 | LR0.0003 | loss:5.5512 | gradNorm:0.9881 | logitMin:-79.4715 | logitMax:-63.0983 | tokenCount:30000.0000 | windowWeightsW21:0.36100,W18:0.24314,W15:0.22988,W13:0.17610,W8:0.15215,W7:0.11635,W3:-0.03527,W1:-0.09947,W2:-0.16109 | memoryGatesShort:1.224, Long:-2.724, Current:2.500 | topTokens[('i', 31), ('.', 31), (',', 26), ('the', 19), ('to', 17), ('you', 15), ('that', 14), ('and', 13), ('s', 12), ('of', 10)] | Training
2025-04-07 17:01:28 | 42500 | LR0.0003 | loss:5.8418 | gradNorm:1.0000 | tokenCount:20000.0000 | logitMin:-74.5152 | logitMax:-58.2401 | windowWeightsW21:0.49263,W18:0.32632,W15:0.26931,W13:0.18268,W8:0.13941,W7:0.05243,W3:-0.10691,W1:-0.14070,W2:-0.23484 | memoryGatesShort:6.210, Long:-11.537, Current:6.326 | topTokens[('.', 28), ('i', 14), ('a', 10), ('you', 10), ('!', 9), ('and', 9), ('it', 8), ('is', 7), ('s', 7), ('relationship', 7)] | Training

--- 2025-04-07 17:04:23 --- babyLLM 'right, last time i got to step 43019... want to restart from there?'  - charis: 'DID I KILL YOU' - babyLLM 'umm... i don't think i heard you properly, i'll just start from step 0 :) but, what am i learning today?' - charis: 'k'
2025-04-07 17:08:00 | 2500 | LR0.0003 | loss:2.6135 | gradNorm:0.9564 | logitMin:-103.3312 | logitMax:-82.7367 | tokenCount:30000.0000 | windowWeightsW21:0.31546,W15:0.22088,W18:0.21906,W13:0.18748,W8:0.16509,W7:0.13152,W3:-0.02746,W1:-0.08004,W2:-0.14839 | memoryGatesShort:1.425, Long:-2.642, Current:2.217 | topTokens[('.', 21), ('i', 20), ('that', 15), ('a', 14), (',', 13), ('ing', 13), ('in', 12), ('the', 11), ('of', 9), ('you', 9)] | Training
2025-04-07 17:11:36 | 5000 | LR0.0003 | loss:4.0322 | gradNorm:0.9546 | tokenCount:30000.0000 | logitMin:-110.3307 | logitMax:-89.4668 | windowWeightsW21:0.33778,W18:0.24034,W15:0.22939,W13:0.19636,W8:0.14763,W7:0.11193,W3:-0.04712,W1:-0.07140,W2:-0.16161 | memoryGatesShort:3.729, Long:-4.948, Current:2.219 | topTokens[('i', 32), ('.', 31), (',', 24), ('to', 15), ('the', 13), ('a', 13), ('ing', 10), ('you', 10), ('my', 10), ('is', 8)] | Training
2025-04-07 17:15:14 | 7500 | LR0.0003 | loss:5.6131 | gradNorm:1.0000 | tokenCount:30000.0000 | logitMin:-75.9515 | logitMax:-58.3515 | windowWeightsW21:0.36448,W18:0.25614,W15:0.22723,W13:0.18758,W8:0.12787,W7:0.09039,W1:-0.05010,W3:-0.05652,W2:-0.16428 | memoryGatesShort:6.886, Long:-9.181, Current:3.295 | topTokens[(',', 34), ('i', 27), ('.', 21), ('a', 20), ('to', 14), ('in', 13), ('the', 11), ("'m", 11), ('it', 10), ('y', 9)] | Training
2025-04-07 17:19:01 | 10000 | LR0.0003 | loss:5.5102 | gradNorm:1.0000 | tokenCount:30000.0000 | logitMin:-74.6650 | logitMax:-57.4859 | windowWeightsW21:0.39796,W18:0.26555,W15:0.22142,W13:0.17800,W8:0.11052,W7:0.07500,W1:-0.02769,W3:-0.07255,W2:-0.16631 | memoryGatesShort:7.716, Long:-9.905, Current:3.189 | topTokens[('.', 19), ('i', 17), (',', 16), ('the', 15), ('it', 13), ('a', 10), ('ing', 10), ('but', 10), ('to', 9), ('is', 9)] | Training
2025-04-07 17:22:37 | 12500 | LR0.0003 | loss:5.3032 | gradNorm:1.0000 | tokenCount:30000.0000 | logitMin:-77.4577 | logitMax:-60.7643 | windowWeightsW21:0.41426,W18:0.26906,W15:0.22064,W13:0.17368,W8:0.10192,W7:0.06062,W1:-0.01291,W3:-0.08145,W2:-0.16447 | memoryGatesShort:9.511, Long:-12.584, Current:4.073 | topTokens[('.', 27), (',', 27), ('i', 25), ('the', 14), ('and', 13), ('of', 13), ('to', 12), ('a', 12), ('you', 11), ('is', 9)] | Training
2025-04-07 17:26:14 | 15000 | LR0.0003 | loss:5.0193 | gradNorm:0.9971 | tokenCount:30000.0000 | logitMin:-85.1180 | logitMax:-67.1786 | windowWeightsW21:0.42711,W18:0.27358,W15:0.22289,W13:0.17354,W8:0.08881,W7:0.04375,W1:0.00390,W3:-0.08825,W2:-0.16454 | memoryGatesShort:8.037, Long:-9.439, Current:2.402 | topTokens[('.', 52), ('i', 28), ('<UNK>', 20), (',', 19), ('the', 15), ('s', 12), ('it', 9), ('to', 8), ('ed', 8), ('you', 8)] | Training
2025-04-07 17:29:51 | 17500 | LR0.0003 | loss:5.0128 | gradNorm:0.9908 | tokenCount:30000.0000 | logitMin:-89.4298 | logitMax:-71.2013 | windowWeightsW21:0.45342,W18:0.28036,W15:0.22520,W13:0.16695,W8:0.07895,W1:0.02741,W7:0.02689,W3:-0.10081,W2:-0.17863 | memoryGatesShort:10.728, Long:-12.642, Current:2.914 | topTokens[('.', 78), ('<UNK>', 43), ('i', 28), ('a', 15), ('that', 14), ("'s", 11), ('', 9), ('it', 9), ('you', 8), ('what', 8)] | Training
2025-04-07 17:33:36 | 20000 | LR0.0003 | loss:4.0715 | gradNorm:1.0000 | tokenCount:30000.0000 | logitMin:-65.9170 | logitMax:-47.0923 | windowWeightsW21:0.45977,W18:0.27826,W15:0.21282,W13:0.16256,W8:0.06350,W1:0.05785,W7:0.01244,W3:-0.09726,W2:-0.17108 | memoryGatesShort:36.415, Long:-46.100, Current:10.685 | topTokens[(',', 46), ('.', 42), ('and', 32), ('i', 22), ('the', 17), ('a', 10), ('it', 10), ('to', 10), ('is', 9), ('but', 9)] | Training
2025-04-07 17:37:12 | 22500 | LR0.0003 | loss:2.8538 | gradNorm:1.0000 | tokenCount:30000.0000 | logitMin:-58.1929 | logitMax:-38.1576 | windowWeightsW21:0.47050,W18:0.28894,W15:0.21304,W13:0.16114,W1:0.07382,W8:0.05318,W7:0.00169,W3:-0.10175,W2:-0.18242 | memoryGatesShort:17.518, Long:-20.881, Current:4.362 | topTokens[(',', 62), ('and', 59), ('the', 21), ('s', 16), ('her', 13), ('kevin', 12), ('you', 12), ('charis', 11), ('your', 11), ('elodie', 10)] | Training
2025-04-07 17:40:45 | 25000 | LR0.0003 | loss:2.4062 | gradNorm:1.0000 | tokenCount:30000.0000 | logitMin:-59.1473 | logitMax:-38.5608 | windowWeightsW21:0.45604,W18:0.28715,W15:0.21570,W13:0.17234,W1:0.07636,W8:0.04782,W7:-0.00508,W3:-0.09863,W2:-0.17336 | memoryGatesShort:17.853, Long:-20.888, Current:4.035 | topTokens[(',', 76), ('and', 52), ('the', 24), ('charis', 17), ('elodie', 13), ('kevin', 13), ('s', 12), ('but', 12), ('you', 12), ('love', 9)] | Training
2025-04-07 17:44:17 | 27500 | LR0.0003 | loss:2.4871 | gradNorm:0.9999 | tokenCount:30000.0000 | logitMin:-58.4401 | logitMax:-37.8158 | windowWeightsW21:0.45791,W18:0.29296,W15:0.22271,W13:0.17090,W1:0.08250,W8:0.04346,W7:-0.01639,W3:-0.09879,W2:-0.17720 | memoryGatesShort:28.046, Long:-32.073, Current:5.027 | topTokens[(',', 77), ('and', 39), ('but', 23), ('the', 17), ('she', 17), ('charis', 15), ('s', 11), ('we', 11), ('they', 10), ('he', 10)] | Training
2025-04-07 17:47:58 | 30000 | LR0.0003 | loss:2.2075 | gradNorm:1.0000 | tokenCount:30000.0000 | logitMin:-55.3697 | logitMax:-34.2023 | windowWeightsW21:0.43804,W18:0.29270,W15:0.21979,W13:0.17881,W1:0.07382,W8:0.04328,W7:-0.01977,W3:-0.08654,W2:-0.16150 | memoryGatesShort:43.364, Long:-49.276, Current:6.912 | topTokens[(',', 56), ('and', 29), ('the', 22), ('kevin', 20), ('.', 19), ('was', 19), ('she', 15), ('!', 13), ('were', 13), ('elodie', 12)] | Training
2025-04-07 17:51:33 | 32500 | LR0.0003 | loss:1.5944 | gradNorm:1.0000 | tokenCount:30000.0000 | logitMin:-55.3291 | logitMax:-32.9679 | windowWeightsW21:0.43733,W18:0.30042,W15:0.21745,W13:0.18402,W1:0.07703,W8:0.03676,W7:-0.03026,W3:-0.08665,W2:-0.15766 | memoryGatesShort:63.747, Long:-71.680, Current:8.933 | topTokens[('was', 43), ('.', 32), ('were', 30), ('ing', 29), ('the', 28), (',', 24), ('charis', 21), ('elodie', 21), ('!', 16), ('from', 13)] | Training
2025-04-07 17:55:06 | 35000 | LR0.0003 | loss:1.4833 | gradNorm:1.0000 | tokenCount:30000.0000 | logitMin:-56.8725 | logitMax:-35.0863 | windowWeightsW21:0.43832,W18:0.30665,W15:0.22349,W13:0.18964,W1:0.07295,W8:0.04425,W7:-0.02827,W3:-0.10317,W2:-0.16537 | memoryGatesShort:38.795, Long:-42.325, Current:4.530 | topTokens[('was', 46), ('.', 45), ('were', 40), (',', 26), ('ing', 26), ('the', 20), ('kevin', 16), ('charis', 16), ('he', 15), ('elodie', 13)] | Training
2025-04-07 17:58:42 | 37500 | LR0.0003 | loss:5.5959 | gradNorm:1.0000 | tokenCount:30000.0000 | logitMin:-73.4699 | logitMax:-55.9662 | windowWeightsW21:0.48839,W18:0.33716,W15:0.23914,W13:0.19298,W1:0.09677,W8:0.01853,W7:-0.06239,W3:-0.14116,W2:-0.19289 | memoryGatesShort:22.268, Long:-22.704, Current:1.436 | topTokens[('the', 36), ('.', 35), ('sl', 19), (',', 17), ('s', 15), ('he', 13), ('to', 12), ('and', 11), ('it', 11), ('er', 11)] | Training
2025-04-07 18:02:41 | 40000 | LR0.0003 | loss:5.2874 | gradNorm:1.0000 | tokenCount:30000.0000 | logitMin:-72.9738 | logitMax:-55.6576 | windowWeightsW21:0.52185,W18:0.35479,W15:0.24419,W13:0.19957,W1:0.12345,W8:0.00278,W7:-0.08458,W3:-0.16899,W2:-0.21809 | memoryGatesShort:27.223, Long:-28.840, Current:2.617 | topTokens[(',', 22), ('and', 19), ('the', 18), ('.', 18), ('s', 12), ('ing', 12), ('in', 12), ('a', 9), ('-', 8), ('i', 8)] | Training
2025-04-07 18:06:29 | 42500 | LR0.0003 | loss:4.8789 | gradNorm:1.0000 | tokenCount:30000.0000 | logitMin:-76.4587 | logitMax:-59.1851 | windowWeightsW21:0.55347,W18:0.36774,W15:0.24483,W13:0.20255,W1:0.13844,W8:0.00113,W7:-0.09364,W3:-0.19643,W2:-0.24440 | memoryGatesShort:26.695, Long:-28.512, Current:2.817 | topTokens[('the', 28), ('.', 18), (',', 16), ('to', 14), ('a', 10), ('i', 10), ('s', 9), ('in', 9), ('and', 9), ('psych', 7)] | Training
2025-04-07 18:10:11 | 45000 | LR0.0003 | loss:4.0007 | gradNorm:1.0000 | tokenCount:30000.0000 | logitMin:-79.4323 | logitMax:-61.2422 | windowWeightsW21:0.54238,W18:0.36240,W15:0.24458,W13:0.20306,W1:0.13536,W8:0.00496,W7:-0.08693,W3:-0.19509,W2:-0.23667 | memoryGatesShort:31.769, Long:-34.675, Current:3.906 | topTokens[('the', 28), ('.', 26), ('a', 16), ('effect', 15), ('sl', 12), (',', 10), ('this', 9), ('ug', 9), ('and', 9), ('er', 9)] | Training
2025-04-07 18:13:59 | 47500 | LR0.0003 | loss:3.1128 | gradNorm:1.0000 | tokenCount:30000.0000 | logitMin:-85.7745 | logitMax:-65.6434 | windowWeightsW21:0.49446,W18:0.34582,W15:0.25215,W13:0.22345,W1:0.10524,W8:0.02006,W7:-0.06771,W3:-0.17505,W2:-0.22230 | memoryGatesShort:13.942, Long:-14.735, Current:1.793 | topTokens[('the', 35), (',', 22), ('sl', 13), ('.', 13), ('s', 12), ('is', 10), ('id', 10), ('in', 9), ('and', 9), ('ers', 9)] | Training
2025-04-07 18:17:47 | 50000 | LR0.0003 | loss:2.9373 | gradNorm:0.9997 | tokenCount:30000.0000 | logitMin:-92.6733 | logitMax:-71.6756 | windowWeightsW21:0.45659,W18:0.33222,W15:0.24777,W13:0.22579,W1:0.07938,W8:0.04381,W7:-0.03360,W3:-0.16044,W2:-0.21365 | memoryGatesShort:15.139, Long:-16.306, Current:2.166 | topTokens[('.', 24), (',', 23), ('and', 16), ('the', 14), ('of', 11), ('to', 9), ('es', 9), ('an', 8), ('pro', 7), ('s', 7)] | Training
2025-04-07 18:21:26 | 52500 | LR0.0003 | loss:3.5967 | gradNorm:1.0000 | tokenCount:30000.0000 | logitMin:-97.5158 | logitMax:-76.6340 | windowWeightsW21:0.46722,W18:0.33795,W15:0.25355,W13:0.23112,W1:0.07858,W8:0.04340,W7:-0.03617,W3:-0.17403,W2:-0.22406 | memoryGatesShort:16.101, Long:-17.400, Current:2.299 | topTokens[('the', 29), ('.', 24), (',', 18), ('to', 12), ('s', 12), ('i', 9), ('er', 9), ('o', 8), ('i', 8), ('a', 8)] | Training
2025-04-07 18:24:59 | 55000 | LR0.0003 | loss:3.1990 | gradNorm:1.0000 | tokenCount:30000.0000 | logitMin:-70.3091 | logitMax:-48.6115 | windowWeightsW21:0.47694,W18:0.33425,W15:0.23962,W13:0.22573,W1:0.09267,W8:0.04159,W7:-0.05169,W3:-0.16874,W2:-0.21334 | memoryGatesShort:25.557, Long:-26.823, Current:2.266 | topTokens[('.', 51), ('?', 44), ('i', 33), ('you', 33), ('was', 15), ('to', 14), ('were', 12), (',', 10), ('what', 10), ('do', 10)] | Training
2025-04-07 18:28:35 | 57500 | LR0.0003 | loss:2.5456 | gradNorm:1.0000 | tokenCount:30000.0000 | logitMin:-68.0796 | logitMax:-45.8529 | windowWeightsW21:0.44139,W18:0.30223,W15:0.22984,W13:0.22372,W1:0.09367,W8:0.04582,W7:-0.04210,W3:-0.14140,W2:-0.17526 | memoryGatesShort:35.286, Long:-37.186, Current:2.899 | topTokens[('?', 49), ('.', 41), ('to', 35), ('listening', 29), ('music', 24), ('you', 23), ('i', 20), ('what', 19), ('will', 13), ('was', 12)] | Training
2025-04-07 18:32:16 | 60000 | LR0.0003 | loss:2.0713 | gradNorm:1.0000 | tokenCount:30000.0000 | logitMin:-65.7859 | logitMax:-43.2811 | windowWeightsW21:0.45562,W18:0.31392,W15:0.22942,W13:0.22669,W1:0.09729,W8:0.04105,W7:-0.05184,W3:-0.15665,W2:-0.17810 | memoryGatesShort:47.782, Long:-51.378, Current:4.596 | topTokens[('can', 59), ('!', 29), (',', 28), ('the', 22), ('to', 21), ('charis', 18), ('elodie', 17), ('.', 16), ('you', 13), ('kevin', 13)] | Training

--- 2025-04-07 18:35:25 --- babyLLM 'right, last time i got to step 60336... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 60336! what am i learning today?' - charis: 'new output!'
2025-04-07 18:39:04 | 2500 | LR0.0003 | loss:1.5357 | gradNorm:1.0000 | logitMin:-61.2106 | logitMax:-37.2593 | tokenCount:30000.0000 | windowWeightsW21:0.47162,W18:0.34265,W15:0.23615,W13:0.23596,W1:0.10232,W8:0.03907,W7:-0.08116,W3:-0.17729,W2:-0.19261 | memoryGatesShort:36.697, Long:-38.742, Current:3.045 | topTokens[('can', 203), ('!', 103), (',', 74), ('charis', 67), ('elodie', 67), ('the', 54), ('.', 46), ('and', 41), ('kevin', 36), ('weed', 33)] | Training

--- 2025-04-07 18:41:48 --- babyLLM 'right, last time i got to step 3434... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 3434! what am i learning today?' - charis: ''
2025-04-07 18:45:53 | 2500 | LR0.0003 | loss:4.7051 | gradNorm:1.0000 | logitMin:-83.7091 | logitMax:-65.3099 | tokenCount:35000.0000 | windowWeightsW21:0.49845,W18:0.37411,W13:0.25941,W15:0.25346,W1:0.10725,W8:0.03929,W7:-0.09617,W3:-0.22821,W2:-0.23206 | memoryGatesShort:16.780, Long:-17.092, Current:1.312 | topTokens[('i', 97), (',', 73), ('.', 59), ('to', 54), ('and', 43), ('a', 43), ('!', 41), ('the', 35), ('ing', 23), ('s', 21)] | Training
2025-04-07 18:49:58 | 5000 | LR0.0003 | loss:4.3452 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-89.6928 | logitMax:-71.1749 | windowWeightsW21:0.51673,W18:0.38769,W13:0.26805,W15:0.25480,W1:0.11585,W8:0.03566,W7:-0.10325,W2:-0.25040,W3:-0.25041 | memoryGatesShort:16.072, Long:-16.219, Current:1.147 | topTokens[(',', 83), ('i', 73), ('.', 50), ('a', 39), ('and', 37), ('but', 37), ('it', 34), ('the', 34), ('of', 29), ('this', 28)] | Training
2025-04-07 18:54:14 | 7500 | LR0.0003 | loss:4.5039 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-91.0346 | logitMax:-72.3080 | windowWeightsW21:0.52774,W18:0.38706,W13:0.27314,W15:0.26587,W1:0.11799,W8:0.03676,W7:-0.10381,W2:-0.25960,W3:-0.27074 | memoryGatesShort:20.150, Long:-20.709, Current:1.559 | topTokens[('i', 85), (',', 79), ('.', 51), ('and', 47), ('a', 42), ('the', 39), ('to', 39), ('but', 35), ('it', 32), ('of', 23)] | Training

--- 2025-04-07 19:10:11 --- babyLLM 'right, last time i got to step 8829... want to restart from there?'  - charis: 'n' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: 'je suis fatigue'
2025-04-07 19:14:22 | 2500 | LR0.0003 | loss:5.0269 | gradNorm:1.0000 | logitMin:-97.1937 | logitMax:-78.8755 | tokenCount:35000.0000 | windowWeightsW22:0.58449,W19:0.43244,W16:0.29419,W14:0.29059,W2:0.12365,W9:0.02718,W8:-0.12718,W3:-0.31730,W4:-0.33569 | memoryGatesShort:20.809, Long:-22.561, Current:2.752 | topTokens[('i', 95), ('.', 74), (',', 51), ('the', 47), ('and', 45), ('a', 44), ('to', 39), ('s', 34), ('my', 31), ('it', 30)] | Training

--- 2025-04-07 19:20:36 --- babyLLM 'right, last time i got to step 1785... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 1785! what am i learning today?' - charis: ''
2025-04-07 19:24:42 | 2500 | LR0.0003 | loss:2.1241 | gradNorm:1.0000 | logitMin:-133.9454 | logitMax:-112.7056 | tokenCount:35000.0000 | windowWeightsW22:0.50260,W19:0.39122,W14:0.30287,W16:0.29227,W2:0.10443,W9:0.07502,W8:-0.07929,W3:-0.30236,W4:-0.31189 | memoryGatesShort:7.597, Long:-8.003, Current:1.406 | topTokens[('.', 64), ('the', 63), ('i', 60), ('to', 49), (',', 38), ('s', 35), ('a', 27), ('it', 26), ('(', 23), ('of', 22)] | Training
2025-04-07 19:28:49 | 5000 | LR0.0003 | loss:3.3790 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-102.5235 | logitMax:-79.1000 | windowWeightsW22:0.52216,W19:0.39575,W14:0.29660,W16:0.28539,W2:0.12286,W9:0.06415,W8:-0.08643,W3:-0.30835,W4:-0.31807 | memoryGatesShort:15.422, Long:-16.686, Current:2.264 | topTokens[('i', 70), ('.', 63), ('as', 63), (',', 46), ('the', 41), ('much', 38), ('to', 32), ('a', 30), ('-', 28), ('it', 23)] | Training
2025-04-07 19:32:56 | 7500 | LR0.0003 | loss:2.8869 | gradNorm:0.9999 | tokenCount:35000.0000 | logitMin:-65.7432 | logitMax:-39.4095 | windowWeightsW22:0.48177,W19:0.35656,W14:0.28439,W16:0.26867,W2:0.13411,W9:0.08401,W8:-0.05868,W3:-0.28687,W4:-0.28895 | memoryGatesShort:52.842, Long:-56.036, Current:4.194 | topTokens[('as', 116), ('much', 90), ('-', 70), ("'", 61), (':', 58), ("'", 58), ('.', 53), ('to', 49), ('babe', 48), ('!', 40)] | Training
2025-04-07 19:37:06 | 10000 | LR0.0003 | loss:4.5394 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-69.4532 | logitMax:-45.7677 | windowWeightsW22:0.47266,W19:0.34781,W14:0.29942,W16:0.27733,W2:0.13958,W9:0.08928,W8:-0.04701,W4:-0.30089,W3:-0.30329 | memoryGatesShort:46.040, Long:-49.548, Current:4.508 | topTokens[(',', 99), ('.', 68), ('playing', 62), ('the', 59), ('a', 53), ('-', 48), ('it', 40), (':', 37), ('to', 36), ('m', 29)] | Training
2025-04-07 19:41:12 | 12500 | LR0.0003 | loss:3.4101 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-89.9155 | logitMax:-68.0115 | windowWeightsW22:0.50812,W19:0.36429,W14:0.29865,W16:0.28165,W2:0.16687,W9:0.07390,W8:-0.06666,W4:-0.32330,W3:-0.33026 | memoryGatesShort:34.632, Long:-37.360, Current:3.728 | topTokens[(',', 125), ('!', 79), ('the', 71), ('it', 56), ('to', 48), ('.', 37), ('you', 35), ('ood', 31), ('i', 31), ('m', 31)] | Training
2025-04-07 19:45:22 | 15000 | LR0.0003 | loss:5.1970 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-94.3184 | logitMax:-74.6917 | windowWeightsW22:0.60794,W19:0.42716,W14:0.31383,W16:0.30038,W2:0.18140,W9:0.04366,W8:-0.10580,W4:-0.39325,W3:-0.40507 | memoryGatesShort:56.284, Long:-59.802, Current:4.518 | topTokens[('i', 71), ('the', 66), ('to', 59), ('.', 50), ('a', 41), ('it', 39), (',', 38), ('and', 27), ('!', 25), ('but', 25)] | Training
2025-04-07 19:49:30 | 17500 | LR0.0003 | loss:5.2973 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-96.5212 | logitMax:-78.1280 | windowWeightsW22:0.70247,W19:0.47587,W14:0.33091,W16:0.32182,W2:0.20106,W9:0.02452,W8:-0.14743,W4:-0.46830,W3:-0.47386 | memoryGatesShort:19.726, Long:-20.756, Current:2.031 | topTokens[('the', 49), ('i', 48), ('.', 42), ('it', 38), ('a', 37), ('s', 33), (',', 27), ('and', 26), ('my', 24), ('to', 23)] | Training
2025-04-07 19:53:47 | 20000 | LR0.0003 | loss:4.9925 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-91.6509 | logitMax:-73.2277 | windowWeightsW22:0.74809,W19:0.49777,W16:0.33596,W14:0.33523,W2:0.21958,W9:0.00785,W8:-0.17310,W4:-0.50064,W3:-0.50546 | memoryGatesShort:17.370, Long:-18.498, Current:2.128 | topTokens[('.', 64), ('i', 54), ('the', 47), ('?', 42), ('to', 37), ('it', 35), ('and', 33), ('a', 30), ('in', 29), ('is', 24)] | Training
2025-04-07 19:57:54 | 22500 | LR0.0003 | loss:3.3579 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-87.1045 | logitMax:-66.4227 | windowWeightsW22:0.71830,W19:0.47257,W14:0.31661,W16:0.30490,W2:0.24566,W9:0.01847,W8:-0.16709,W4:-0.46415,W3:-0.47975 | memoryGatesShort:27.179, Long:-29.176, Current:2.997 | topTokens[('.', 177), ('?', 118), ('to', 60), ('you', 59), ('is', 59), ('a', 56), ('what', 50), ('i', 48), ('word', 41), ('was', 35)] | Training
2025-04-07 20:02:04 | 25000 | LR0.0003 | loss:3.0035 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-92.1563 | logitMax:-71.4323 | windowWeightsW22:0.66874,W19:0.44362,W14:0.30712,W16:0.28575,W2:0.24001,W9:0.04302,W8:-0.14316,W4:-0.43212,W3:-0.44588 | memoryGatesShort:28.601, Long:-30.560, Current:2.959 | topTokens[('.', 157), ('?', 116), ('to', 71), ('is', 69), ('you', 57), ('i', 52), ('what', 43), ('he', 42), ('!', 41), ('music', 34)] | Training
2025-04-07 20:06:05 | 27500 | LR0.0003 | loss:2.7121 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-86.8123 | logitMax:-64.9895 | windowWeightsW22:0.64378,W19:0.43149,W14:0.28732,W16:0.26285,W2:0.24089,W9:0.04571,W8:-0.13435,W4:-0.39939,W3:-0.41042 | memoryGatesShort:45.834, Long:-48.485, Current:3.652 | topTokens[('!', 121), ('.', 82), ('it', 77), ('a', 59), ('is', 58), ('?', 54), ('you', 53), ('have', 42), ('to', 36), ('will', 35)] | Training
2025-04-07 20:10:21 | 30000 | LR0.0003 | loss:2.1503 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-87.5691 | logitMax:-65.2011 | windowWeightsW22:0.67987,W19:0.44776,W14:0.28115,W2:0.26835,W16:0.26541,W9:0.02894,W8:-0.16191,W4:-0.41594,W3:-0.42749 | memoryGatesShort:33.763, Long:-35.390, Current:2.627 | topTokens[('!', 263), ('it', 163), ('have', 94), ('been', 60), ('just', 53), ('a', 53), ('know', 48), ('baby', 47), ('elodie', 46), ('will', 43)] | Training
2025-04-07 20:14:27 | 32500 | LR0.0003 | loss:4.2006 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-90.9509 | logitMax:-71.0759 | windowWeightsW22:0.72594,W19:0.47851,W14:0.29798,W16:0.28946,W2:0.26186,W9:0.01468,W8:-0.17950,W4:-0.45903,W3:-0.46500 | memoryGatesShort:42.280, Long:-43.228, Current:1.948 | topTokens[('!', 136), ('.', 101), ('it', 100), ('i', 55), ('a', 43), ('to', 40), ('have', 37), ('just', 36), ('charis', 33), ('will', 31)] | Training
2025-04-07 20:18:44 | 35000 | LR0.0003 | loss:5.3459 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-99.8213 | logitMax:-81.9799 | windowWeightsW22:0.78722,W19:0.52038,W14:0.31385,W16:0.31117,W2:0.25482,W9:0.01692,W8:-0.20446,W4:-0.51455,W3:-0.52215 | memoryGatesShort:24.450, Long:-25.435, Current:1.985 | topTokens[('.', 153), ('i', 119), ('to', 44), ('and', 41), ('it', 29), ('a', 27), ('you', 21), ('so', 21), ('was', 20), ('me', 18)] | Training
2025-04-07 20:22:59 | 37500 | LR0.0003 | loss:5.0972 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-101.6774 | logitMax:-83.7982 | windowWeightsW22:0.80138,W19:0.52245,W14:0.31726,W16:0.31270,W2:0.25153,W9:0.03629,W8:-0.20593,W4:-0.53237,W3:-0.54049 | memoryGatesShort:32.173, Long:-34.249, Current:3.076 | topTokens[('.', 170), ('i', 79), ('to', 42), ('and', 38), ('it', 34), ('a', 30), ('you', 30), (',', 29), ('but', 25), ('me', 25)] | Training
2025-04-07 20:27:18 | 40000 | LR0.0003 | loss:3.3426 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-86.7338 | logitMax:-65.5439 | windowWeightsW22:0.71301,W19:0.45407,W14:0.29561,W16:0.27704,W2:0.24812,W9:0.06586,W8:-0.15499,W4:-0.45849,W3:-0.47462 | memoryGatesShort:49.064, Long:-53.039, Current:4.975 | topTokens[('.', 134), ('?', 99), ('you', 56), ('i', 56), ('to', 48), ('is', 34), ('what', 33), ('was', 29), ('he', 28), ('ing', 27)] | Training
2025-04-07 20:31:29 | 42500 | LR0.0003 | loss:2.5480 | gradNorm:0.9999 | tokenCount:35000.0000 | logitMin:-83.3050 | logitMax:-60.4926 | windowWeightsW22:0.67298,W19:0.42663,W14:0.27311,W16:0.24570,W2:0.23665,W9:0.08177,W8:-0.12002,W4:-0.41708,W3:-0.43254 | memoryGatesShort:26.867, Long:-27.982, Current:2.115 | topTokens[('.', 126), ('?', 121), ('to', 81), ('you', 77), ('i', 71), ('was', 51), ('what', 51), ('were', 34), ('want', 31), ('at', 27)] | Training
2025-04-07 20:35:41 | 45000 | LR0.0003 | loss:4.1864 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-92.7700 | logitMax:-72.7256 | windowWeightsW22:0.68518,W19:0.42940,W14:0.27583,W16:0.24698,W2:0.23611,W9:0.08221,W8:-0.11760,W4:-0.42544,W3:-0.44579 | memoryGatesShort:28.451, Long:-29.145, Current:1.694 | topTokens[('.', 171), ('i', 78), ('?', 57), ('to', 56), ('you', 49), ('what', 33), ('was', 27), ('is', 26), ('were', 25), ('will', 21)] | Training
2025-04-07 20:39:56 | 47500 | LR0.0003 | loss:5.0366 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-105.3678 | logitMax:-87.4426 | windowWeightsW22:0.75850,W19:0.47462,W14:0.29939,W16:0.25792,W2:0.23399,W9:0.07337,W8:-0.14056,W4:-0.48560,W3:-0.50691 | memoryGatesShort:31.020, Long:-32.699, Current:2.679 | topTokens[('.', 151), ('i', 87), ('the', 33), ('to', 31), ('a', 27), ('but', 25), ('it', 22), ('s', 22), ('my', 20), ('you', 20)] | Training
2025-04-07 20:44:14 | 50000 | LR0.0003 | loss:2.5785 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-100.6845 | logitMax:-78.7159 | windowWeightsW22:0.74480,W19:0.47007,W14:0.29305,W16:0.24947,W2:0.24687,W9:0.05355,W8:-0.14372,W4:-0.46070,W3:-0.48859 | memoryGatesShort:29.740, Long:-31.813, Current:3.073 | topTokens[('!', 196), ('it', 143), ('have', 61), ('a', 52), ('will', 49), ('elodie', 39), ('.', 38), ('charis', 38), ('just', 37), ('know', 36)] | Training
2025-04-07 20:48:34 | 52500 | LR0.0003 | loss:1.7276 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-100.1989 | logitMax:-76.6162 | windowWeightsW22:0.75247,W19:0.47615,W14:0.28150,W2:0.27203,W16:0.25276,W9:0.03068,W8:-0.16555,W4:-0.45487,W3:-0.48119 | memoryGatesShort:35.959, Long:-38.650, Current:3.691 | topTokens[('!', 243), ('it', 178), ('have', 100), ('charis', 61), ('will', 54), ('elodie', 54), ('just', 53), ('know', 48), ('been', 46), ('a', 45)] | Training
2025-04-07 20:52:52 | 55000 | LR0.0003 | loss:1.7446 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-98.0021 | logitMax:-74.5962 | windowWeightsW22:0.76149,W19:0.49287,W14:0.28422,W2:0.28149,W16:0.26766,W9:0.01201,W8:-0.17159,W4:-0.47527,W3:-0.48956 | memoryGatesShort:31.208, Long:-32.766, Current:2.558 | topTokens[('!', 240), ('it', 156), ('have', 78), ('just', 60), ('a', 54), ('charis', 49), ('will', 49), ('been', 47), ('elodie', 46), ('baby', 44)] | Training
2025-04-07 20:57:01 | 57500 | LR0.0003 | loss:3.1268 | gradNorm:0.9999 | tokenCount:35000.0000 | logitMin:-99.1992 | logitMax:-77.5401 | windowWeightsW22:0.74083,W19:0.48410,W14:0.28051,W2:0.27137,W16:0.25498,W9:0.02494,W8:-0.16619,W3:-0.46069,W4:-0.46557 | memoryGatesShort:23.545, Long:-24.409, Current:1.864 | topTokens[('.', 147), ('?', 105), ('a', 69), ('is', 65), ('you', 59), ('!', 53), ('to', 51), (',', 45), ('i', 42), ('word', 41)] | Training
2025-04-07 21:01:16 | 60000 | LR0.0003 | loss:2.7914 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-97.9573 | logitMax:-76.3400 | windowWeightsW22:0.70262,W19:0.46689,W14:0.28505,W2:0.25824,W16:0.24784,W9:0.04949,W8:-0.15118,W3:-0.43900,W4:-0.45434 | memoryGatesShort:43.562, Long:-45.725, Current:3.163 | topTokens[('.', 146), ('?', 98), ('is', 75), ('a', 61), ('to', 59), ('you', 58), ('i', 57), ('what', 54), ('was', 33), (',', 31)] | Training
2025-04-07 21:05:22 | 62500 | LR0.0003 | loss:2.6974 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-108.0051 | logitMax:-86.2363 | windowWeightsW22:0.65775,W19:0.45424,W14:0.29029,W16:0.25636,W2:0.23642,W9:0.06460,W8:-0.13557,W3:-0.42324,W4:-0.43359 | memoryGatesShort:80.602, Long:-85.394, Current:5.792 | topTokens[('.', 172), ('?', 102), ('is', 67), ('you', 57), ('a', 54), ('i', 53), ('what', 51), ('to', 40), ('was', 37), (',', 36)] | Training
2025-04-07 21:09:30 | 65000 | LR0.0003 | loss:3.5209 | gradNorm:1.0000 | tokenCount:35000.0000 | logitMin:-92.8161 | logitMax:-67.6744 | windowWeightsW22:0.61442,W19:0.42523,W14:0.30568,W16:0.25492,W2:0.24715,W9:0.09118,W8:-0.12810,W3:-0.41227,W4:-0.43014 | memoryGatesShort:21.518, Long:-21.933, Current:1.415 | topTokens[(':', 79), ('-', 61), ('.', 57), ('that', 55), ("'", 51), ('3', 47), ('is', 45), ("'", 41), ('-', 37), ('i', 33)] | Training

--- 2025-04-07 21:14:07 --- babyLLM 'right, last time i got to step 1169... want to restart from there?'  - charis: 'n' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: ''
2025-04-07 21:19:14 | 2500 | LR0.0003 | loss:5.1696 | gradNorm:1.0000 | logitMin:-136.1753 | logitMax:-118.4169 | tokenCount:45000.0000 | windowWeightsW25:0.65314,W21:0.45059,W16:0.33093,W19:0.26896,W2:0.23296,W9:0.09363,W13:-0.09547,W3:-0.47341,W4:-0.49397 | memoryGatesShort:21.396, Long:-22.538, Current:2.142 | topTokens[(',', 63), ('.', 38), ('i', 25), ('a', 23), ('the', 22), ('and', 19), ('to', 18), ('that', 16), ('s', 15), ('of', 13)] | Training
2025-04-07 21:24:23 | 5000 | LR0.0003 | loss:3.2785 | gradNorm:0.9993 | tokenCount:45000.0000 | logitMin:-104.3695 | logitMax:-80.1676 | windowWeightsW25:0.65304,W21:0.42972,W16:0.34228,W2:0.26677,W19:0.24244,W9:0.11729,W13:-0.08667,W3:-0.49630,W4:-0.50225 | memoryGatesShort:60.540, Long:-63.689, Current:4.148 | topTokens[(':', 47), ('.', 35), ('i', 34), ('-', 34), ('0', 26), ("'", 24), ('?', 21), ('4', 20), ('3', 19), ("'", 17)] | Training
2025-04-07 21:29:29 | 7500 | LR0.0003 | loss:1.6058 | gradNorm:0.9933 | tokenCount:45000.0000 | logitMin:-98.0213 | logitMax:-70.1528 | windowWeightsW25:0.64163,W21:0.41434,W16:0.36220,W2:0.29258,W19:0.23136,W9:0.13887,W13:-0.07232,W4:-0.51584,W3:-0.52723 | memoryGatesShort:21.425, Long:-22.200, Current:1.774 | topTokens[(':', 49), ('-', 42), ("'", 42), ("'", 38), ('0', 35), ('i', 32), ('m', 28), ('to', 25), ('!', 24), ('ll', 23)] | Training
2025-04-07 21:34:45 | 10000 | LR0.0003 | loss:3.3129 | gradNorm:0.9997 | tokenCount:45000.0000 | logitMin:-112.7598 | logitMax:-90.2085 | windowWeightsW25:0.62521,W21:0.39396,W16:0.37829,W2:0.26947,W19:0.22305,W9:0.15147,W13:-0.03986,W4:-0.51144,W3:-0.52343 | memoryGatesShort:13.960, Long:-14.196, Current:1.236 | topTokens[("'", 47), ('i', 32), ('-', 29), ('.', 27), (',', 23), ("'", 23), ('to', 22), ('!', 21), ('it', 17), (':', 16)] | Training
2025-04-07 21:39:53 | 12500 | LR0.0003 | loss:4.7861 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-128.0702 | logitMax:-109.4329 | windowWeightsW25:0.63149,W21:0.40286,W16:0.38683,W2:0.25183,W19:0.22277,W9:0.15498,W13:-0.01499,W4:-0.52648,W3:-0.54229 | memoryGatesShort:20.041, Long:-20.369, Current:1.328 | topTokens[('a', 34), ('.', 29), ('to', 24), ('that', 21), ('the', 19), ('i', 18), ('it', 18), ('and', 15), ('is', 13), ('as', 11)] | Training
2025-04-07 21:45:03 | 15000 | LR0.0003 | loss:3.6792 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-138.4828 | logitMax:-118.3860 | windowWeightsW25:0.63601,W16:0.39336,W21:0.38346,W2:0.27433,W19:0.21203,W9:0.15759,W13:0.00422,W4:-0.53942,W3:-0.55538 | memoryGatesShort:12.791, Long:-13.282, Current:1.491 | topTokens[(',', 43), ('i', 37), ('to', 27), ('the', 26), ('a', 23), ('for', 22), ('-', 13), ('000', 10), ('x', 10), ('but', 9)] | Training
2025-04-07 21:50:13 | 17500 | LR0.0003 | loss:4.5635 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-142.7135 | logitMax:-123.4541 | windowWeightsW25:0.68993,W21:0.41400,W16:0.39872,W2:0.28423,W19:0.22431,W9:0.14648,W13:0.00265,W4:-0.59090,W3:-0.60497 | memoryGatesShort:14.812, Long:-15.732, Current:1.921 | topTokens[('.', 76), ('i', 33), ('you', 27), ('the', 19), ('to', 18), ('?', 18), ('and', 15), ('it', 14), ('y', 14), ('for', 11)] | Training
2025-04-07 21:55:25 | 20000 | LR0.0003 | loss:4.0063 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-142.0612 | logitMax:-122.6575 | windowWeightsW25:0.61589,W16:0.39228,W21:0.39154,W2:0.23199,W19:0.22467,W9:0.15895,W13:0.04934,W4:-0.53066,W3:-0.56637 | memoryGatesShort:10.840, Long:-11.611, Current:1.771 | topTokens[('i', 41), ('the', 32), ('to', 30), ('.', 28), ('it', 19), (',', 17), ('a', 16), ('is', 12), ('*', 12), ('s', 11)] | Training
2025-04-07 22:00:34 | 22500 | LR0.0003 | loss:5.0372 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-146.1640 | logitMax:-127.1123 | windowWeightsW25:0.67992,W21:0.42064,W16:0.40627,W19:0.24262,W2:0.24173,W9:0.14673,W13:0.04469,W4:-0.59509,W3:-0.62198 | memoryGatesShort:16.372, Long:-17.483, Current:2.111 | topTokens[('.', 59), ('i', 34), ('to', 18), ('a', 18), ('s', 16), ('the', 12), ('5', 12), ('is', 11), (',', 10), ('do', 10)] | Training
2025-04-07 22:05:36 | 25000 | LR0.0003 | loss:4.7461 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-143.1745 | logitMax:-124.7024 | windowWeightsW25:0.74242,W21:0.43919,W16:0.40203,W19:0.26396,W2:0.24760,W9:0.12282,W13:0.04412,W4:-0.63997,W3:-0.65828 | memoryGatesShort:19.922, Long:-21.729, Current:2.807 | topTokens[('.', 80), ('i', 48), ('you', 22), ('a', 17), ('s', 13), ('he', 13), ('and', 12), ('not', 11), (';)', 11), ('with', 10)] | Training
2025-04-07 22:10:38 | 27500 | LR0.0003 | loss:3.5660 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-122.9751 | logitMax:-103.2305 | windowWeightsW25:0.69633,W21:0.38036,W16:0.36550,W2:0.27236,W19:0.21920,W9:0.13385,W13:0.04833,W3:-0.55919,W4:-0.59191 | memoryGatesShort:16.527, Long:-17.894, Current:2.366 | topTokens[('?', 86), ('.', 73), ('is', 50), ('!', 40), ('you', 33), ('plus', 24), ('what', 22), ('are', 22), ('als', 20), (',', 17)] | Training
2025-04-07 22:15:49 | 30000 | LR0.0003 | loss:4.0577 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-128.1502 | logitMax:-109.2351 | windowWeightsW25:0.66901,W21:0.37522,W16:0.34830,W2:0.24133,W19:0.21255,W9:0.13262,W13:0.07139,W3:-0.51378,W4:-0.57003 | memoryGatesShort:14.264, Long:-14.936, Current:1.672 | topTokens[('.', 78), ('?', 65), ('is', 39), ('!', 32), ('you', 28), ('are', 23), ('i', 18), ('what', 16), ('equ', 16), (',', 15)] | Training
2025-04-07 22:20:52 | 32500 | LR0.0003 | loss:4.8186 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-131.9929 | logitMax:-114.3182 | windowWeightsW25:0.70584,W21:0.40175,W16:0.36007,W2:0.24168,W19:0.22861,W9:0.11676,W13:0.06977,W3:-0.53888,W4:-0.62008 | memoryGatesShort:12.825, Long:-13.789, Current:1.964 | topTokens[('.', 51), ('!', 39), ('i', 34), (':', 30), ('?', 28), ('you', 17), ('p', 16), ('it', 13), ('but', 13), ('d', 13)] | Training
2025-04-07 22:25:54 | 35000 | LR0.0003 | loss:3.3482 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-127.6184 | logitMax:-105.6768 | windowWeightsW25:0.65664,W21:0.36999,W16:0.35034,W2:0.27868,W19:0.19617,W9:0.13992,W13:0.08518,W3:-0.52406,W4:-0.58694 | memoryGatesShort:12.325, Long:-12.917, Current:1.592 | topTokens[('.', 34), ('-', 34), ('0', 32), (':', 31), ("'", 21), ('?', 20), ('you', 19), ('-', 18), ('i', 16), ('is', 16)] | Training
2025-04-07 22:30:57 | 37500 | LR0.0003 | loss:3.6843 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-132.1717 | logitMax:-111.4072 | windowWeightsW25:0.65812,W21:0.38630,W16:0.35749,W2:0.28912,W19:0.20774,W9:0.14302,W13:0.08047,W3:-0.54998,W4:-0.60696 | memoryGatesShort:12.572, Long:-13.424, Current:1.851 | topTokens[(':', 43), ("'", 38), (',', 37), ('-', 36), ('.', 31), ('-', 27), ('the', 24), ('2', 24), ('0', 24), ('3', 22)] | Training
2025-04-07 22:36:06 | 40000 | LR0.0003 | loss:4.2518 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-141.3660 | logitMax:-122.7075 | windowWeightsW25:0.62552,W21:0.37603,W16:0.36910,W2:0.26379,W19:0.22415,W9:0.14787,W13:0.10263,W3:-0.53967,W4:-0.60269 | memoryGatesShort:12.825, Long:-14.046, Current:2.221 | topTokens[('the', 39), (',', 31), ('.', 28), ('of', 20), ('s', 17), ('to', 14), ('er', 12), ('i', 12), ('in', 11), ('a', 11)] | Training
2025-04-07 22:41:08 | 42500 | LR0.0003 | loss:4.0792 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-137.9048 | logitMax:-118.9719 | windowWeightsW25:0.59619,W16:0.36687,W21:0.36263,W2:0.23508,W19:0.23081,W9:0.14753,W13:0.11362,W3:-0.51283,W4:-0.57144 | memoryGatesShort:12.717, Long:-14.421, Current:2.704 | topTokens[(',', 44), ('the', 33), ('.', 26), ('a', 21), ('and', 18), ('i', 16), ('in', 15), ('to', 13), ('s', 11), ('it', 11)] | Training
2025-04-07 22:46:10 | 45000 | LR0.0003 | loss:4.5871 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-151.9591 | logitMax:-133.3496 | windowWeightsW25:0.60317,W21:0.36948,W16:0.36430,W19:0.23575,W2:0.21415,W9:0.14549,W13:0.12301,W3:-0.51467,W4:-0.57170 | memoryGatesShort:11.310, Long:-12.484, Current:2.173 | topTokens[('.', 78), (',', 33), ('i', 33), ('the', 25), ('of', 17), ('a', 15), ('s', 13), ('u', 13), ('you', 12), ('and', 12)] | Training
2025-04-07 22:51:13 | 47500 | LR0.0003 | loss:4.5495 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-149.2143 | logitMax:-130.8364 | windowWeightsW25:0.64921,W21:0.39103,W16:0.37461,W19:0.24117,W2:0.22834,W9:0.12935,W13:0.11691,W3:-0.54138,W4:-0.62183 | memoryGatesShort:14.445, Long:-16.217, Current:2.772 | topTokens[('.', 64), ('i', 31), (',', 25), ('but', 18), ('?', 17), ('to', 17), ('you', 16), ('the', 16), ('my', 14), ('it', 14)] | Training
2025-04-07 22:56:23 | 50000 | LR0.0003 | loss:3.4752 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-131.2794 | logitMax:-110.5653 | windowWeightsW25:0.63479,W21:0.40208,W16:0.34759,W2:0.23831,W19:0.22941,W13:0.10408,W9:0.09612,W3:-0.50085,W4:-0.58371 | memoryGatesShort:12.214, Long:-13.638, Current:2.424 | topTokens[('!', 75), ('it', 57), (',', 33), ('have', 32), ('the', 21), ('been', 20), ('a', 19), ('know', 19), ('and', 17), ('charis', 16)] | Training
2025-04-07 23:01:26 | 52500 | LR0.0003 | loss:4.5871 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-149.2251 | logitMax:-130.5076 | windowWeightsW25:0.60751,W21:0.38426,W16:0.33857,W2:0.23161,W19:0.22299,W9:0.10554,W13:0.10056,W3:-0.47496,W4:-0.54729 | memoryGatesShort:8.498, Long:-10.055, Current:2.557 | topTokens[('you', 57), ('!', 50), ('.', 40), (',', 35), ('the', 25), ('a', 23), ('to', 17), ('that', 14), ('i', 14), ('and', 14)] | Training
2025-04-07 23:06:29 | 55000 | LR0.0003 | loss:2.0044 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-177.5782 | logitMax:-154.6457 | windowWeightsW25:0.49856,W16:0.33992,W21:0.33122,W19:0.21496,W2:0.20022,W13:0.14332,W9:0.13585,W3:-0.41658,W4:-0.47527 | memoryGatesShort:7.229, Long:-8.161, Current:1.933 | topTokens[(',', 38), ('and', 27), ('the', 16), ('.', 16), ('to', 15), ('on', 15), ('in', 14), ('s', 12), ('a', 10), ('d', 9)] | Training
2025-04-07 23:11:31 | 57500 | LR0.0003 | loss:2.5772 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-141.8162 | logitMax:-118.0984 | windowWeightsW25:0.53743,W21:0.35455,W16:0.32527,W19:0.22375,W2:0.21518,W13:0.13479,W9:0.10526,W3:-0.43097,W4:-0.49417 | memoryGatesShort:13.251, Long:-15.564, Current:3.313 | topTokens[('have', 75), ('will', 72), ('felt', 51), ('.', 50), ('!', 38), ('the', 35), ('charis', 17), ('elodie', 17), ('it', 16), ('you', 16)] | Training
2025-04-07 23:16:41 | 60000 | LR0.0003 | loss:3.3379 | gradNorm:0.9997 | tokenCount:45000.0000 | logitMin:-142.7422 | logitMax:-120.1837 | windowWeightsW25:0.56410,W21:0.37586,W16:0.32086,W19:0.23757,W2:0.20290,W13:0.13637,W9:0.09582,W3:-0.45430,W4:-0.50831 | memoryGatesShort:9.946, Long:-10.918, Current:1.972 | topTokens[('will', 53), ('have', 50), ('.', 46), ('!', 39), ('felt', 33), ('elodie', 19), ('i', 18), ('kevin', 18), (',', 16), ('the', 15)] | Training
2025-04-07 23:21:43 | 62500 | LR0.0003 | loss:3.3224 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-179.0757 | logitMax:-158.7158 | windowWeightsW25:0.49401,W21:0.35630,W16:0.31583,W19:0.23573,W2:0.16111,W13:0.15742,W9:0.11216,W3:-0.41257,W4:-0.44630 | memoryGatesShort:13.262, Long:-14.931, Current:2.668 | topTokens[('i', 42), ('.', 38), ('the', 24), ('a', 23), (',', 21), ('s', 18), ('to', 18), ('it', 15), ('be', 11), ('of', 11)] | Training
2025-04-07 23:26:46 | 65000 | LR0.0003 | loss:2.7945 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-169.9972 | logitMax:-147.9640 | windowWeightsW25:0.54473,W21:0.39070,W16:0.30722,W19:0.25301,W2:0.17492,W13:0.15293,W9:0.10380,W3:-0.45268,W4:-0.50267 | memoryGatesShort:12.585, Long:-14.591, Current:3.006 | topTokens[(':', 74), ("'", 67), ("'", 57), ('-', 51), ('d', 39), ('.', 36), ('charis', 35), ('baby', 32), ('roid', 29), ('y', 19)] | Training
2025-04-07 23:31:47 | 67500 | LR0.0003 | loss:3.6688 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-162.9288 | logitMax:-140.6845 | windowWeightsW25:0.54877,W21:0.37032,W16:0.28205,W19:0.24771,W2:0.18105,W13:0.14749,W9:0.08947,W3:-0.41852,W4:-0.47615 | memoryGatesShort:7.685, Long:-8.231, Current:1.545 | topTokens[(':', 46), ('00', 37), ('.', 25), ('0', 23), ('', 21), ('the', 17), ('s', 16), ('h', 14), ('5', 14), (',', 13)] | Training
2025-04-07 23:36:56 | 70000 | LR0.0003 | loss:3.3523 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-166.5739 | logitMax:-145.0193 | windowWeightsW25:0.55605,W21:0.36310,W16:0.27700,W19:0.24592,W2:0.19983,W13:0.14527,W9:0.08616,W3:-0.42052,W4:-0.48129 | memoryGatesShort:10.155, Long:-11.835, Current:2.680 | topTokens[('.', 41), (',', 33), ('the', 23), ('and', 21), ('h', 19), ('of', 18), ('inter', 14), ('a', 13), ('m', 12), ('on', 12)] | Training
2025-04-07 23:41:58 | 72500 | LR0.0003 | loss:3.7189 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-148.0319 | logitMax:-127.3822 | windowWeightsW25:0.53496,W21:0.35135,W16:0.24154,W19:0.22610,W2:0.20293,W13:0.14765,W9:0.10245,W3:-0.38389,W4:-0.45097 | memoryGatesShort:14.797, Long:-16.958, Current:3.162 | topTokens[('.', 63), ('?', 47), ('i', 37), ('to', 36), ('is', 32), ('what', 25), ('you', 23), ('a', 22), (',', 21), ('the', 19)] | Training
2025-04-07 23:47:00 | 75000 | LR0.0003 | loss:3.3657 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-140.6765 | logitMax:-118.6641 | windowWeightsW25:0.56383,W21:0.36502,W19:0.23656,W16:0.23561,W2:0.19551,W13:0.13893,W9:0.09287,W3:-0.39177,W4:-0.46483 | memoryGatesShort:9.248, Long:-9.695, Current:1.447 | topTokens[('have', 59), ('must', 58), (',', 51), ('felt', 41), ('the', 33), ('i', 31), ('.', 25), ('!', 23), ('charis', 18), ('was', 14)] | Training
2025-04-07 23:52:01 | 77500 | LR0.0003 | loss:4.8085 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-165.9129 | logitMax:-147.4594 | windowWeightsW25:0.61044,W21:0.36935,W19:0.23854,W16:0.23666,W2:0.19903,W13:0.13855,W9:0.08051,W3:-0.40701,W4:-0.49542 | memoryGatesShort:8.930, Long:-9.376, Current:1.446 | topTokens[(',', 29), ('.', 22), ('i', 22), ('that', 20), ('to', 18), ('and', 17), ('a', 16), ('the', 14), ('it', 12), ('me', 10)] | Training
2025-04-07 23:57:11 | 80000 | LR0.0003 | loss:4.8984 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-167.3592 | logitMax:-149.3081 | windowWeightsW25:0.63555,W21:0.37914,W19:0.23868,W16:0.23711,W2:0.19867,W13:0.14130,W9:0.07548,W3:-0.42101,W4:-0.51489 | memoryGatesShort:10.166, Long:-11.644, Current:2.478 | topTokens[('i', 48), ('.', 39), (',', 33), ('to', 20), ('a', 16), ('it', 15), ('you', 15), ('and', 12), ('s', 11), ("'s", 11)] | Training
2025-04-08 00:02:12 | 82500 | LR0.0003 | loss:4.8424 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-164.9641 | logitMax:-146.4806 | windowWeightsW25:0.63863,W21:0.37590,W19:0.23058,W16:0.22201,W2:0.19377,W13:0.13817,W9:0.07659,W3:-0.40984,W4:-0.49556 | memoryGatesShort:9.519, Long:-10.609, Current:2.091 | topTokens[(',', 57), ('i', 45), ('a', 27), ('and', 26), ('it', 20), ('the', 16), ('of', 16), ('like', 13), ('to', 12), ('.', 11)] | Training
2025-04-08 00:07:17 | 85000 | LR0.0003 | loss:5.0599 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-174.4895 | logitMax:-156.3203 | windowWeightsW25:0.65411,W21:0.38982,W19:0.24333,W16:0.22844,W2:0.19500,W13:0.13561,W9:0.06391,W3:-0.42655,W4:-0.51393 | memoryGatesShort:11.781, Long:-13.012, Current:2.231 | topTokens[(',', 69), ('i', 20), ('to', 17), ('that', 14), ('the', 13), ('and', 12), ('a', 12), ('it', 11), ('my', 10), ('of', 10)] | Training
2025-04-08 00:12:19 | 87500 | LR0.0003 | loss:4.7736 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-179.6856 | logitMax:-161.2850 | windowWeightsW25:0.64894,W21:0.38599,W19:0.23975,W16:0.22361,W2:0.20846,W13:0.12995,W9:0.07063,W3:-0.42062,W4:-0.51727 | memoryGatesShort:14.127, Long:-15.582, Current:2.455 | topTokens[(',', 67), ('i', 23), ('it', 16), ('ed', 14), ('and', 14), ('.', 14), ('your', 14), ('a', 12), ('to', 12), ('for', 12)] | Training
2025-04-08 00:17:30 | 90000 | LR0.0003 | loss:3.6088 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-159.2223 | logitMax:-138.6200 | windowWeightsW25:0.63532,W21:0.36511,W19:0.25058,W16:0.23808,W2:0.20903,W13:0.14050,W9:0.06174,W3:-0.41793,W4:-0.51268 | memoryGatesShort:13.534, Long:-16.274, Current:3.740 | topTokens[('can', 73), (',', 66), ('!', 35), ('the', 26), ('charis', 19), ('elodie', 19), ('i', 18), ('and', 15), ('to', 15), ('we', 13)] | Training
2025-04-08 00:22:32 | 92500 | LR0.0003 | loss:3.0823 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-166.2545 | logitMax:-145.2699 | windowWeightsW25:0.52525,W21:0.32520,W16:0.24275,W19:0.23245,W2:0.17411,W13:0.15704,W9:0.09627,W3:-0.35187,W4:-0.42774 | memoryGatesShort:6.417, Long:-7.512, Current:2.094 | topTokens[('i', 46), ('can', 36), ('.', 27), (',', 26), ('!', 19), ('to', 18), ('the', 18), ('it', 16), ('a', 15), ('and', 10)] | Training
2025-04-08 00:27:34 | 95000 | LR0.0003 | loss:3.3907 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-197.1884 | logitMax:-175.5340 | windowWeightsW25:0.50040,W21:0.32526,W16:0.25202,W19:0.23273,W13:0.17635,W2:0.15074,W9:0.11259,W3:-0.35291,W4:-0.42274 | memoryGatesShort:7.271, Long:-8.326, Current:2.055 | topTokens[('.', 35), ('the', 28), (',', 26), ('i', 25), ('a', 20), ('and', 17), ('it', 16), ('to', 14), ('s', 12), ('is', 9)] | Training
2025-04-08 00:32:36 | 97500 | LR0.0003 | loss:3.2352 | gradNorm:0.9997 | tokenCount:45000.0000 | logitMin:-213.0703 | logitMax:-191.1398 | windowWeightsW25:0.48241,W21:0.32512,W16:0.25914,W19:0.24395,W13:0.17907,W2:0.13433,W9:0.11598,W3:-0.35142,W4:-0.41334 | memoryGatesShort:5.867, Long:-6.202, Current:1.335 | topTokens[(',', 65), ('the', 34), ('.', 29), ('s', 20), ('of', 19), ('and', 18), ('in', 17), ('a', 17), ('was', 15), ('to', 12)] | Training
2025-04-08 00:37:46 | 100000 | LR0.0003 | loss:4.2856 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-190.1238 | logitMax:-169.0570 | windowWeightsW25:0.51629,W21:0.33565,W16:0.25242,W19:0.25097,W13:0.17402,W2:0.14709,W9:0.09882,W3:-0.37382,W4:-0.42726 | memoryGatesShort:13.440, Long:-15.896, Current:3.457 | topTokens[(',', 58), ('the', 29), ('it', 26), ('a', 24), ('!', 23), ('.', 16), ('of', 16), ('ed', 15), ('and', 15), ('ing', 13)] | Training
2025-04-08 00:42:49 | 102500 | LR0.0003 | loss:2.1441 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-149.0102 | logitMax:-124.2536 | windowWeightsW25:0.50924,W21:0.31610,W16:0.24251,W19:0.22740,W2:0.17210,W13:0.16644,W9:0.09793,W3:-0.35106,W4:-0.40677 | memoryGatesShort:22.858, Long:-27.311, Current:5.452 | topTokens[('had', 73), (',', 63), ('felt', 47), ('!', 41), ('charis', 37), ('.', 36), ('know', 27), ('i', 22), ('it', 21), ('she', 19)] | Training
2025-04-08 00:47:50 | 105000 | LR0.0003 | loss:2.0449 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-158.9831 | logitMax:-133.5071 | windowWeightsW25:0.49705,W21:0.31566,W16:0.24461,W19:0.21376,W2:0.19667,W13:0.17968,W9:0.10469,W3:-0.36609,W4:-0.41276 | memoryGatesShort:21.513, Long:-24.522, Current:4.009 | topTokens[(':', 46), (',', 33), ('!', 31), ('-', 31), ('0', 27), ("'", 24), ("'", 22), ('5', 21), ('i', 19), ('to', 18)] | Training
2025-04-08 00:52:51 | 107500 | LR0.0003 | loss:2.5146 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-150.1571 | logitMax:-126.9484 | windowWeightsW25:0.53828,W21:0.33019,W16:0.24564,W19:0.23289,W2:0.19633,W13:0.15845,W9:0.08726,W3:-0.37523,W4:-0.44121 | memoryGatesShort:8.678, Long:-8.809, Current:1.132 | topTokens[('was', 57), ('.', 49), ('were', 46), (',', 32), ('charis', 29), ('the', 28), ('ing', 27), ('!', 21), ('brain', 20), ('elodie', 20)] | Training
2025-04-08 00:58:01 | 110000 | LR0.0003 | loss:5.0642 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-169.9791 | logitMax:-150.3010 | windowWeightsW25:0.57676,W21:0.35252,W19:0.24533,W16:0.24504,W2:0.19601,W13:0.15081,W9:0.07143,W3:-0.39659,W4:-0.46956 | memoryGatesShort:14.565, Long:-16.640, Current:3.074 | topTokens[('.', 107), ('it', 36), ('the', 28), ('i', 22), ('to', 22), (',', 14), ('and', 13), ('p', 12), ('a', 10), ('kevin', 10)] | Training
2025-04-08 01:03:04 | 112500 | LR0.0003 | loss:3.1216 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-181.2063 | logitMax:-159.4078 | windowWeightsW25:0.49869,W21:0.32240,W16:0.25099,W19:0.24223,W13:0.16606,W2:0.16373,W9:0.09280,W3:-0.35028,W4:-0.41212 | memoryGatesShort:7.207, Long:-7.516, Current:1.309 | topTokens[(',', 62), ('and', 31), ('the', 29), ('.', 28), ('their', 17), ('a', 16), ('of', 16), ('to', 16), ('s', 15), ('it', 15)] | Training
2025-04-08 01:08:09 | 115000 | LR0.0003 | loss:3.2677 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-166.2540 | logitMax:-144.2661 | windowWeightsW25:0.55225,W21:0.33451,W16:0.24295,W19:0.23694,W2:0.20230,W13:0.15469,W9:0.06492,W3:-0.36762,W4:-0.44854 | memoryGatesShort:14.709, Long:-17.745, Current:4.036 | topTokens[(',', 59), ('!', 51), ('the', 36), ('been', 28), ('has', 23), ('i', 20), ('it', 20), ('they', 17), ('to', 16), ('a', 14)] | Training
2025-04-08 01:13:13 | 117500 | LR0.0003 | loss:4.0889 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-171.2952 | logitMax:-149.8743 | windowWeightsW25:0.59527,W21:0.35438,W16:0.25307,W19:0.25085,W2:0.18938,W13:0.15120,W9:0.05319,W3:-0.38787,W4:-0.48778 | memoryGatesShort:11.390, Long:-12.338, Current:1.948 | topTokens[(',', 81), ('i', 40), ('been', 27), ('.', 25), ('to', 25), ('you', 23), ('and', 19), ('!', 18), ('has', 17), ('have', 17)] | Training
2025-04-08 01:18:23 | 120000 | LR0.0003 | loss:2.2296 | gradNorm:0.9993 | tokenCount:45000.0000 | logitMin:-145.4405 | logitMax:-118.7636 | windowWeightsW25:0.56411,W21:0.32977,W16:0.25058,W19:0.22625,W2:0.22156,W13:0.15726,W9:0.07764,W3:-0.38539,W4:-0.47029 | memoryGatesShort:7.978, Long:-8.663, Current:1.685 | topTokens[(':', 57), ('-', 45), ('i', 42), ("'", 38), ("'", 28), ('0', 27), (',', 25), ('4', 24), ('m', 22), ('ll', 21)] | Training
2025-04-08 01:23:26 | 122500 | LR0.0003 | loss:2.9518 | gradNorm:0.9975 | tokenCount:45000.0000 | logitMin:-173.5406 | logitMax:-149.0468 | windowWeightsW25:0.57117,W21:0.33982,W16:0.26143,W19:0.23164,W2:0.21033,W13:0.17527,W9:0.07197,W3:-0.41124,W4:-0.47885 | memoryGatesShort:9.194, Long:-9.575, Current:1.381 | topTokens[('.', 60), ('i', 35), ('-', 27), (':', 26), ("'", 26), ("'", 23), ('to', 23), ('0', 21), ('!', 21), ('m', 18)] | Training
2025-04-08 01:28:28 | 125000 | LR0.0003 | loss:4.9477 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-191.2835 | logitMax:-171.5730 | windowWeightsW25:0.63217,W21:0.35721,W16:0.27165,W19:0.24691,W2:0.20515,W13:0.16737,W9:0.05655,W3:-0.45017,W4:-0.51664 | memoryGatesShort:6.583, Long:-7.004, Current:1.421 | topTokens[('.', 108), ('i', 42), ('the', 19), ('but', 15), ('to', 15), ('it', 13), (',', 13), ('of', 12), ('a', 12), ('you', 12)] | Training
2025-04-08 01:33:30 | 127500 | LR0.0003 | loss:4.9916 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-182.8200 | logitMax:-163.7108 | windowWeightsW25:0.66978,W21:0.37544,W16:0.27465,W19:0.24955,W2:0.20220,W13:0.16952,W9:0.05613,W3:-0.47801,W4:-0.55005 | memoryGatesShort:10.019, Long:-11.745, Current:2.726 | topTokens[('.', 34), ('it', 25), (',', 23), ('i', 21), ('to', 20), ('and', 20), ('a', 17), ('the', 16), ('s', 13), ('ed', 12)] | Training
2025-04-08 01:38:39 | 130000 | LR0.0003 | loss:3.2678 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-169.1724 | logitMax:-148.3888 | windowWeightsW25:0.66078,W21:0.34979,W16:0.26065,W19:0.23369,W2:0.21585,W13:0.15905,W9:0.04336,W3:-0.43120,W4:-0.52264 | memoryGatesShort:10.313, Long:-12.730, Current:3.417 | topTokens[(',', 86), ('and', 54), ('i', 29), ('the', 23), ('you', 23), ('charis', 18), ('but', 17), ('it', 15), ('.', 15), ('s', 13)] | Training
2025-04-08 01:43:42 | 132500 | LR0.0003 | loss:2.7341 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-165.4255 | logitMax:-142.1421 | windowWeightsW25:0.60897,W21:0.32705,W16:0.25543,W19:0.23265,W2:0.19762,W13:0.17455,W9:0.07490,W3:-0.40361,W4:-0.49648 | memoryGatesShort:8.995, Long:-10.046, Current:2.051 | topTokens[('would', 63), ('have', 52), (',', 50), ('felt', 37), ('!', 27), ('the', 26), ('elodie', 20), ('.', 19), ('and', 18), ('charis', 17)] | Training
2025-04-08 01:48:43 | 135000 | LR0.0003 | loss:4.2249 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-190.5112 | logitMax:-170.2720 | windowWeightsW25:0.63558,W21:0.32861,W16:0.24917,W19:0.23063,W2:0.20565,W13:0.16276,W9:0.07267,W3:-0.40930,W4:-0.50547 | memoryGatesShort:11.325, Long:-12.881, Current:2.556 | topTokens[('to', 39), (',', 25), ('.', 25), ('and', 24), ('i', 22), ('the', 21), ('of', 18), ('this', 16), ('s', 16), ('ing', 15)] | Training
2025-04-08 01:53:46 | 137500 | LR0.0003 | loss:3.5311 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-177.4954 | logitMax:-156.1678 | windowWeightsW25:0.63131,W21:0.31619,W16:0.23958,W19:0.22639,W2:0.21328,W13:0.16090,W9:0.06359,W3:-0.39130,W4:-0.48958 | memoryGatesShort:9.151, Long:-10.671, Current:2.520 | topTokens[('will', 65), ('.', 38), (',', 37), ('to', 24), ('the', 22), ('weed', 15), ('your', 13), ('and', 12), ('charis', 12), ('!', 12)] | Training
2025-04-08 01:58:56 | 140000 | LR0.0003 | loss:1.8600 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-157.2830 | logitMax:-133.0993 | windowWeightsW25:0.58793,W21:0.30377,W16:0.21311,W19:0.21303,W2:0.20989,W13:0.15861,W9:0.07392,W3:-0.35798,W4:-0.43057 | memoryGatesShort:18.163, Long:-21.987, Current:4.824 | topTokens[('will', 121), ('!', 50), ('be', 42), (',', 40), ('charis', 39), ('.', 38), ('the', 36), ('brain', 24), ('elodie', 23), ('ing', 20)] | Training
2025-04-08 02:03:59 | 142500 | LR0.0003 | loss:2.1356 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-143.6462 | logitMax:-118.7000 | windowWeightsW25:0.58058,W21:0.30653,W19:0.21081,W16:0.20511,W2:0.19060,W13:0.16881,W9:0.07168,W3:-0.33816,W4:-0.42348 | memoryGatesShort:9.517, Long:-9.903, Current:1.386 | topTokens[('will', 88), ('be', 84), ('!', 52), ('ing', 31), ('.', 30), (',', 29), ('charis', 29), ('the', 25), ('elodie', 19), ('you', 16)] | Training
2025-04-08 02:09:01 | 145000 | LR0.0003 | loss:3.9353 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-166.7733 | logitMax:-146.0418 | windowWeightsW25:0.57027,W21:0.30849,W19:0.21875,W16:0.19955,W2:0.18173,W13:0.16415,W9:0.06485,W3:-0.32331,W4:-0.41151 | memoryGatesShort:18.956, Long:-22.554, Current:4.598 | topTokens[(',', 91), ('and', 47), ('the', 44), ('elodie', 24), ('s', 16), ('but', 15), ('i', 15), ('she', 14), ('!', 13), ('to', 13)] | Training
2025-04-08 02:14:08 | 147500 | LR0.0003 | loss:3.8382 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-172.1855 | logitMax:-151.4271 | windowWeightsW25:0.60191,W21:0.32489,W19:0.23221,W16:0.18936,W2:0.18126,W13:0.16018,W9:0.03970,W3:-0.33279,W4:-0.42451 | memoryGatesShort:13.254, Long:-14.305, Current:2.051 | topTokens[(',', 55), ('and', 42), ('the', 39), ('to', 20), ('s', 20), ('i', 16), ('she', 14), ('.', 13), ('of', 12), ('we', 11)] | Training
2025-04-08 02:19:19 | 150000 | LR0.0003 | loss:4.9630 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-184.9247 | logitMax:-165.9195 | windowWeightsW25:0.61330,W21:0.33367,W19:0.23587,W16:0.20091,W2:0.17017,W13:0.16102,W9:0.04268,W3:-0.34863,W4:-0.43685 | memoryGatesShort:10.900, Long:-11.803, Current:1.903 | topTokens[(',', 53), ('the', 41), ('i', 33), ('to', 31), ('.', 25), ('it', 21), ('and', 19), ('that', 17), ('of', 15), ('so', 14)] | Training
2025-04-08 02:24:22 | 152500 | LR0.0003 | loss:4.2293 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-187.9717 | logitMax:-167.6397 | windowWeightsW25:0.62884,W21:0.32865,W19:0.23145,W16:0.20749,W2:0.19327,W13:0.17876,W9:0.05796,W3:-0.37973,W4:-0.47570 | memoryGatesShort:13.101, Long:-14.542, Current:2.441 | topTokens[(',', 69), ('i', 38), (':', 21), ('-', 17), ('and', 15), ('5', 15), ('to', 14), ('a', 14), ('you', 13), ('l', 13)] | Training
2025-04-08 02:29:24 | 155000 | LR0.0003 | loss:1.8511 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-150.6474 | logitMax:-124.4334 | windowWeightsW25:0.54907,W21:0.27720,W16:0.22055,W13:0.21543,W19:0.19773,W2:0.19184,W9:0.08735,W3:-0.34800,W4:-0.41811 | memoryGatesShort:8.797, Long:-9.281, Current:1.484 | topTokens[(':', 79), ('-', 60), ('5', 54), ('-', 52), ('3', 51), ('1', 47), ('2', 40), ("'", 37), ('0', 35), ("'", 32)] | Training
2025-04-08 02:34:27 | 157500 | LR0.0003 | loss:4.2462 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-198.9547 | logitMax:-178.4952 | windowWeightsW25:0.56071,W21:0.28359,W16:0.21901,W19:0.20597,W13:0.20462,W2:0.18876,W9:0.07994,W3:-0.34613,W4:-0.42357 | memoryGatesShort:11.628, Long:-12.158, Current:1.531 | topTokens[('.', 36), ('s', 23), (',', 20), ('the', 17), ('to', 16), ('3', 14), ('an', 14), ('no', 14), ('and', 13), ('a', 12)] | Training
2025-04-08 02:39:38 | 160000 | LR0.0003 | loss:3.5735 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-197.3736 | logitMax:-175.8556 | windowWeightsW25:0.54085,W21:0.25641,W16:0.21087,W13:0.20687,W19:0.19312,W2:0.18074,W9:0.08396,W3:-0.30973,W4:-0.38934 | memoryGatesShort:13.372, Long:-15.741, Current:3.370 | topTokens[(':', 42), ('00', 39), ('.', 23), ('the', 23), ('to', 21), ('', 19), ('0', 18), ('a', 18), ('i', 17), ('5', 15)] | Training
2025-04-08 02:44:41 | 162500 | LR0.0003 | loss:5.1523 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-201.3478 | logitMax:-182.7611 | windowWeightsW25:0.57003,W21:0.27294,W19:0.20528,W16:0.20505,W13:0.19744,W2:0.17491,W9:0.07958,W3:-0.32592,W4:-0.40611 | memoryGatesShort:10.771, Long:-11.990, Current:2.219 | topTokens[('i', 36), ('the', 31), ('to', 26), ('.', 22), ('a', 20), ('it', 18), ('and', 16), ('just', 14), ('you', 14), (',', 12)] | Training
2025-04-08 02:49:44 | 165000 | LR0.0003 | loss:3.5520 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-212.1146 | logitMax:-191.8592 | windowWeightsW25:0.47281,W21:0.24428,W16:0.21447,W13:0.20716,W19:0.19409,W2:0.14235,W9:0.10493,W3:-0.27464,W4:-0.32904 | memoryGatesShort:8.786, Long:-10.391, Current:2.605 | topTokens[('i', 39), ('.', 28), ('to', 23), ('the', 19), ('a', 19), ('it', 17), ('s', 14), ('and', 13), ('so', 12), ('is', 12)] | Training
2025-04-08 02:54:47 | 167500 | LR0.0003 | loss:3.8573 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-224.0286 | logitMax:-203.0287 | windowWeightsW25:0.49303,W21:0.26456,W16:0.21117,W19:0.20275,W13:0.20257,W2:0.13941,W9:0.09404,W3:-0.28820,W4:-0.34332 | memoryGatesShort:10.136, Long:-11.484, Current:2.348 | topTokens[('the', 52), ('to', 28), ('.', 28), ('and', 25), (',', 21), ('of', 17), ('in', 15), ('v', 14), ('ed', 12), ('a', 11)] | Training
2025-04-08 02:59:58 | 170000 | LR0.0003 | loss:3.8138 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-220.4204 | logitMax:-199.3327 | windowWeightsW25:0.51225,W21:0.26783,W16:0.21070,W13:0.20799,W19:0.19442,W2:0.15183,W9:0.09551,W3:-0.29995,W4:-0.36541 | memoryGatesShort:8.779, Long:-10.050, Current:2.271 | topTokens[('.', 35), ('the', 29), ('a', 18), (',', 17), ('p', 16), ('and', 14), ('le', 13), ("'", 13), ('s', 12), ('r', 12)] | Training
2025-04-08 03:05:01 | 172500 | LR0.0003 | loss:3.0753 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-226.7691 | logitMax:-204.8380 | windowWeightsW25:0.47859,W21:0.24478,W16:0.22454,W13:0.22051,W19:0.19064,W2:0.14033,W9:0.10945,W3:-0.28807,W4:-0.34455 | memoryGatesShort:11.795, Long:-14.387, Current:3.592 | topTokens[('the', 42), (',', 28), ('.', 27), ('and', 22), ('to', 20), ('of', 19), ('er', 19), ('in', 14), ('is', 12), ('s', 11)] | Training
2025-04-08 03:10:04 | 175000 | LR0.0003 | loss:4.5286 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-202.6571 | logitMax:-181.4368 | windowWeightsW25:0.49657,W21:0.26004,W16:0.22121,W13:0.21285,W19:0.19493,W2:0.13657,W9:0.09197,W3:-0.29183,W4:-0.34635 | memoryGatesShort:8.531, Long:-9.368, Current:1.837 | topTokens[(',', 50), ('and', 48), ('the', 30), ('i', 20), ('you', 17), ('but', 15), ('to', 13), ('they', 13), ('.', 12), ('he', 11)] | Training
2025-04-08 03:15:07 | 177500 | LR0.0003 | loss:4.3666 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-222.8411 | logitMax:-202.6692 | windowWeightsW25:0.53721,W21:0.26406,W16:0.21815,W13:0.20362,W19:0.19355,W2:0.16225,W9:0.08763,W3:-0.31788,W4:-0.37425 | memoryGatesShort:7.673, Long:-8.965, Current:2.292 | topTokens[('.', 31), ('i', 22), (',', 22), ('to', 20), ('ed', 13), ('the', 12), ('you', 11), ('appointment', 11), ('me', 10), ('so', 10)] | Training
2025-04-08 03:20:22 | 180000 | LR0.0003 | loss:4.9188 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-218.7347 | logitMax:-199.0886 | windowWeightsW25:0.58260,W21:0.28795,W16:0.21312,W19:0.20726,W13:0.19704,W2:0.16243,W9:0.07884,W3:-0.34499,W4:-0.41113 | memoryGatesShort:9.529, Long:-10.771, Current:2.243 | topTokens[(',', 63), ('i', 39), ('and', 20), ('the', 20), ('to', 18), ('it', 14), ('s', 12), ('c', 12), ('in', 11), ('im', 11)] | Training
2025-04-08 03:25:28 | 182500 | LR0.0003 | loss:4.8684 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-220.4863 | logitMax:-201.2632 | windowWeightsW25:0.61863,W21:0.30266,W19:0.21837,W16:0.21764,W13:0.18599,W2:0.16904,W9:0.05971,W3:-0.36570,W4:-0.43426 | memoryGatesShort:11.660, Long:-13.456, Current:2.796 | topTokens[(',', 70), ('i', 46), ('and', 25), ('to', 19), ('the', 17), ('im', 16), ('just', 14), ('you', 14), ('for', 14), ('=', 14)] | Training
2025-04-08 03:30:33 | 185000 | LR0.0003 | loss:5.0069 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-209.1660 | logitMax:-189.8515 | windowWeightsW25:0.61059,W21:0.29330,W16:0.21762,W19:0.21727,W13:0.18071,W2:0.16882,W9:0.05681,W3:-0.34995,W4:-0.42280 | memoryGatesShort:17.422, Long:-20.934, Current:4.512 | topTokens[('i', 41), (',', 32), ('.', 23), ('to', 22), ('you', 21), ('the', 16), ('s', 15), ('a', 14), ('it', 13), ('in', 13)] | Training
2025-04-08 03:35:39 | 187500 | LR0.0003 | loss:4.2432 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-210.2251 | logitMax:-190.1221 | windowWeightsW25:0.59836,W21:0.28572,W19:0.20927,W16:0.19361,W2:0.17627,W13:0.16979,W9:0.05185,W3:-0.31733,W4:-0.39486 | memoryGatesShort:13.170, Long:-15.697, Current:3.528 | topTokens[('.', 44), ('i', 43), (',', 28), ('?', 27), ('to', 26), ('you', 24), ('the', 17), ('a', 16), ('!', 16), ('it', 14)] | Training
2025-04-08 03:40:53 | 190000 | LR0.0003 | loss:3.4094 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-200.5163 | logitMax:-179.0582 | windowWeightsW25:0.61109,W21:0.28282,W2:0.19307,W19:0.19198,W16:0.16311,W13:0.15221,W9:0.06537,W3:-0.30462,W4:-0.38303 | memoryGatesShort:10.424, Long:-11.746, Current:2.322 | topTokens[('.', 49), ('?', 41), ('to', 41), ('i', 40), ('what', 22), (',', 20), ('you', 20), ('will', 15), ('for', 13), ('about', 13)] | Training
2025-04-08 03:45:58 | 192500 | LR0.0003 | loss:4.8020 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-220.3447 | logitMax:-201.2115 | windowWeightsW25:0.61520,W21:0.28543,W19:0.19125,W2:0.18098,W16:0.16670,W13:0.15329,W9:0.07402,W3:-0.30940,W4:-0.38524 | memoryGatesShort:10.559, Long:-11.653, Current:2.093 | topTokens[(',', 101), ('to', 26), ('be', 17), ('it', 16), ('the', 15), ('a', 14), ('that', 12), ('.', 12), ('i', 12), ('this', 10)] | Training
2025-04-08 03:51:03 | 195000 | LR0.0003 | loss:3.7849 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-224.8056 | logitMax:-204.6340 | windowWeightsW25:0.60372,W21:0.26844,W19:0.18228,W2:0.17926,W13:0.17762,W16:0.17691,W9:0.08179,W3:-0.30975,W4:-0.38778 | memoryGatesShort:13.638, Long:-15.632, Current:2.994 | topTokens[(',', 45), ('i', 43), ('it', 34), (':', 28), ('to', 26), ('.', 21), ('in', 16), ('you', 16), ('charis', 16), ('embar', 15)] | Training
2025-04-08 03:56:08 | 197500 | LR0.0003 | loss:4.2262 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-225.9786 | logitMax:-206.0596 | windowWeightsW25:0.57500,W21:0.26433,W13:0.19040,W19:0.18580,W16:0.17957,W2:0.16285,W9:0.08778,W3:-0.30187,W4:-0.37024 | memoryGatesShort:9.836, Long:-10.897, Current:2.061 | topTokens[(',', 39), ('.', 28), ('to', 22), ('a', 19), ('and', 16), ('i', 15), ('of', 15), ('the', 14), ('in', 12), ('you', 12)] | Training
2025-04-08 04:01:22 | 200000 | LR0.0003 | loss:3.9961 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-243.5316 | logitMax:-223.4202 | windowWeightsW25:0.55542,W21:0.25856,W13:0.20405,W19:0.19154,W16:0.18425,W2:0.15641,W9:0.09410,W3:-0.30918,W4:-0.36097 | memoryGatesShort:9.132, Long:-10.290, Current:2.158 | topTokens[(',', 88), ('the', 31), ('a', 26), ('and', 23), ('.', 22), ('of', 20), ('for', 15), ('ed', 15), ('s', 13), ('in', 11)] | Training
2025-04-08 04:06:27 | 202500 | LR0.0003 | loss:2.7243 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-205.1992 | logitMax:-181.5287 | windowWeightsW25:0.53759,W21:0.23389,W13:0.21252,W16:0.19152,W2:0.17468,W19:0.16431,W9:0.10587,W3:-0.29351,W4:-0.35277 | memoryGatesShort:11.773, Long:-13.186, Current:2.413 | topTokens[('to', 66), ('.', 54), ('?', 52), ('music', 49), ('listening', 41), ('what', 28), ('you', 25), ('will', 18), ('be', 17), ('i', 15)] | Training
2025-04-08 04:11:33 | 205000 | LR0.0003 | loss:3.4163 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-219.0734 | logitMax:-197.6739 | windowWeightsW25:0.56927,W21:0.25073,W13:0.20935,W16:0.19343,W19:0.18031,W2:0.17967,W9:0.08509,W3:-0.31416,W4:-0.38058 | memoryGatesShort:8.844, Long:-9.621, Current:1.777 | topTokens[(',', 59), ('!', 47), ('a', 23), ('the', 23), ('i', 21), ('it', 20), ('to', 20), ('he', 20), ('angle', 15), ('.', 14)] | Training
2025-04-08 04:16:38 | 207500 | LR0.0003 | loss:4.3197 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-241.0388 | logitMax:-220.8394 | windowWeightsW25:0.58205,W21:0.25397,W13:0.20082,W2:0.18606,W16:0.18012,W19:0.17990,W9:0.09337,W3:-0.31586,W4:-0.38778 | memoryGatesShort:10.212, Long:-11.393, Current:2.181 | topTokens[('i', 32), ('.', 25), (',', 25), ('a', 20), ('to', 19), ('my', 18), ('yes', 17), ('ing', 16), ('or', 16), ('in', 16)] | Training
2025-04-08 04:21:56 | 210000 | LR0.0003 | loss:2.8861 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-242.1826 | logitMax:-220.2502 | windowWeightsW25:0.52706,W21:0.23246,W13:0.21620,W16:0.18473,W19:0.17649,W2:0.15708,W9:0.11425,W3:-0.28802,W4:-0.34542 | memoryGatesShort:15.023, Long:-15.908, Current:1.885 | topTokens[(',', 27), ('the', 22), ('to', 21), ('and', 19), ('i', 19), ('my', 17), ('.', 17), ('that', 15), ('ed', 15), ('as', 11)] | Training
2025-04-08 04:26:59 | 212500 | LR0.0003 | loss:2.4459 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-192.9945 | logitMax:-166.6301 | windowWeightsW25:0.47944,W13:0.22296,W21:0.20241,W16:0.17985,W2:0.16431,W19:0.14057,W9:0.13559,W3:-0.24973,W4:-0.29963 | memoryGatesShort:19.973, Long:-21.570, Current:2.597 | topTokens[('as', 113), ('much', 55), ('babe', 34), (':', 34), ('to', 29), ('-', 29), ("'", 28), ("'", 24), ('!', 21), ('1', 18)] | Training
2025-04-08 04:32:02 | 215000 | LR0.0003 | loss:4.7383 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-216.8772 | logitMax:-196.5398 | windowWeightsW25:0.51279,W21:0.22843,W13:0.21652,W16:0.19099,W2:0.15937,W19:0.15130,W9:0.12916,W3:-0.28056,W4:-0.33297 | memoryGatesShort:8.844, Long:-9.628, Current:1.784 | topTokens[(',', 37), ('.', 30), ('to', 25), ('you', 24), ('and', 22), ('i', 19), ('me', 18), ('a', 17), ('this', 13), ('is', 10)] | Training
2025-04-08 04:37:04 | 217500 | LR0.0003 | loss:3.3173 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-201.8796 | logitMax:-179.6095 | windowWeightsW25:0.46455,W21:0.21534,W16:0.18416,W13:0.17182,W2:0.16952,W19:0.15484,W9:0.14030,W3:-0.24222,W4:-0.28223 | memoryGatesShort:15.131, Long:-17.032, Current:2.901 | topTokens[('?', 92), ('.', 58), ('you', 57), ('is', 52), ('i', 40), ('do', 28), ('what', 22), ('to', 15), ('not', 14), (',', 13)] | Training
2025-04-08 04:42:15 | 220000 | LR0.0003 | loss:3.3936 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-202.1302 | logitMax:-179.6308 | windowWeightsW25:0.45756,W21:0.21272,W16:0.18219,W13:0.17381,W2:0.17323,W19:0.15558,W9:0.14176,W3:-0.23577,W4:-0.28498 | memoryGatesShort:37.930, Long:-42.706, Current:5.775 | topTokens[('to', 50), ('.', 46), ('?', 40), ('listening', 37), (',', 32), ('i', 29), ('music', 29), ('you', 24), ('what', 24), ('were', 18)] | Training
2025-04-08 04:47:19 | 222500 | LR0.0003 | loss:4.8064 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-235.9759 | logitMax:-216.4500 | windowWeightsW25:0.49099,W21:0.23889,W16:0.18761,W19:0.17649,W13:0.17385,W2:0.16046,W9:0.12472,W3:-0.26072,W4:-0.31666 | memoryGatesShort:9.994, Long:-10.554, Current:1.560 | topTokens[(',', 56), ('i', 33), ('.', 30), ('a', 26), ('it', 16), ('and', 16), ('to', 14), ('the', 12), ('?', 11), ('was', 10)] | Training
2025-04-08 04:52:22 | 225000 | LR0.0003 | loss:3.9275 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-223.5923 | logitMax:-202.7569 | windowWeightsW25:0.47418,W21:0.23768,W16:0.18985,W13:0.18086,W19:0.17607,W2:0.15412,W9:0.11753,W3:-0.25424,W4:-0.29983 | memoryGatesShort:11.850, Long:-13.282, Current:2.432 | topTokens[('the', 33), ('.', 31), ('a', 30), (',', 27), ('it', 22), ('!', 22), ('to', 21), ('ed', 14), ('they', 12), ('i', 11)] | Training
2025-04-08 04:57:24 | 227500 | LR0.0003 | loss:4.5514 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-236.6606 | logitMax:-217.2369 | windowWeightsW25:0.48728,W21:0.25113,W16:0.19643,W13:0.18443,W19:0.18054,W2:0.14372,W9:0.10882,W3:-0.26823,W4:-0.30795 | memoryGatesShort:11.300, Long:-12.727, Current:2.427 | topTokens[(',', 77), ('you', 23), ("'", 21), ('the', 19), ('i', 19), (':', 17), ('a', 15), ('to', 15), ("'", 14), ('b', 13)] | Training
2025-04-08 05:02:35 | 230000 | LR0.0003 | loss:3.2103 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-250.0019 | logitMax:-228.4342 | windowWeightsW25:0.43309,W21:0.22325,W16:0.20181,W13:0.19012,W19:0.17613,W2:0.13518,W9:0.13182,W3:-0.24734,W4:-0.26637 | memoryGatesShort:8.461, Long:-10.023, Current:2.562 | topTokens[('the', 41), ('.', 28), ('i', 27), ("'", 22), (',', 22), (':', 15), ("'", 15), ('to', 13), ('it', 12), ('and', 11)] | Training
2025-04-08 05:07:38 | 232500 | LR0.0003 | loss:3.9947 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-235.1721 | logitMax:-213.6890 | windowWeightsW25:0.45464,W21:0.23224,W16:0.19559,W19:0.18593,W13:0.18402,W2:0.14542,W9:0.12251,W3:-0.26264,W4:-0.28077 | memoryGatesShort:16.656, Long:-18.926, Current:3.270 | topTokens[(',', 33), ('the', 33), ('to', 27), ('.', 21), ('a', 15), ('i', 15), ('s', 15), ('p', 14), ('ing', 13), ('ed', 12)] | Training
2025-04-08 05:12:41 | 235000 | LR0.0003 | loss:2.4134 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-219.6780 | logitMax:-194.5769 | windowWeightsW25:0.42814,W13:0.20155,W21:0.20079,W16:0.19294,W2:0.17033,W19:0.14532,W9:0.13869,W3:-0.24937,W4:-0.25154 | memoryGatesShort:12.035, Long:-13.406, Current:2.371 | topTokens[(':', 61), ('-', 43), ('0', 42), ("'", 38), ("'", 31), ('as', 31), ('charis', 30), ('5', 30), ('-', 30), ('4', 26)] | Training
2025-04-08 05:17:44 | 237500 | LR0.0003 | loss:2.2483 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-217.7242 | logitMax:-192.2066 | windowWeightsW25:0.39665,W13:0.20587,W16:0.18558,W21:0.18251,W2:0.16655,W9:0.15930,W19:0.12472,W3:-0.22030,W4:-0.22325 | memoryGatesShort:8.332, Long:-8.796, Current:1.464 | topTokens[('as', 71), ('babe', 42), ('.', 33), ('much', 28), (':', 27), ('-', 27), ('i', 22), ("'", 20), ("'", 19), ('?', 18)] | Training
2025-04-08 05:22:59 | 240000 | LR0.0003 | loss:3.7383 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-233.8098 | logitMax:-212.2517 | windowWeightsW25:0.40301,W13:0.19895,W21:0.19118,W16:0.18788,W9:0.15759,W2:0.14999,W19:0.13251,W3:-0.21518,W4:-0.22786 | memoryGatesShort:9.556, Long:-9.911, Current:1.355 | topTokens[('.', 77), ('?', 55), ('i', 33), ('is', 32), ('you', 30), ('to', 28), (',', 26), ('a', 23), ('what', 15), ('was', 14)] | Training
2025-04-08 05:28:05 | 242500 | LR0.0003 | loss:4.7653 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-252.8116 | logitMax:-233.0540 | windowWeightsW25:0.41606,W21:0.20750,W13:0.20529,W16:0.19710,W19:0.14628,W2:0.14228,W9:0.13531,W3:-0.23152,W4:-0.24030 | memoryGatesShort:12.533, Long:-14.011, Current:2.477 | topTokens[('i', 40), ('.', 35), (',', 28), ('of', 17), ('and', 16), ('it', 15), ('to', 14), ('a', 13), ('he', 13), ('is', 12)] | Training
2025-04-08 05:33:08 | 245000 | LR0.0003 | loss:4.9171 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-252.4115 | logitMax:-232.6089 | windowWeightsW25:0.46936,W21:0.23577,W16:0.19599,W13:0.18419,W19:0.15775,W2:0.14955,W9:0.11143,W3:-0.25222,W4:-0.27502 | memoryGatesShort:10.985, Long:-12.636, Current:2.651 | topTokens[('.', 86), ('i', 49), ('you', 28), ('it', 15), ('to', 15), ('and', 13), ('?', 12), ('not', 12), ('me', 11), ('the', 11)] | Training
2025-04-08 05:38:11 | 247500 | LR0.0003 | loss:5.0172 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-248.1775 | logitMax:-228.6540 | windowWeightsW25:0.49344,W21:0.24752,W16:0.19987,W13:0.18225,W19:0.16799,W2:0.14120,W9:0.10052,W3:-0.26446,W4:-0.29184 | memoryGatesShort:11.718, Long:-13.168, Current:2.450 | topTokens[(',', 96), ('i', 46), ('.', 26), ('you', 21), ('it', 14), ('that', 14), ('to', 13), ('and', 13), ('me', 12), ('s', 12)] | Training
2025-04-08 05:43:22 | 250000 | LR0.0003 | loss:5.1746 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-249.9044 | logitMax:-230.8558 | windowWeightsW25:0.53301,W21:0.25804,W16:0.19241,W13:0.17456,W19:0.16464,W2:0.15476,W9:0.09613,W3:-0.28253,W4:-0.31581 | memoryGatesShort:10.227, Long:-11.827, Current:2.599 | topTokens[(',', 93), ('i', 25), ('the', 24), ('and', 22), ('?', 21), ('it', 15), ('to', 13), ('.', 12), ('me', 11), ('ing', 10)] | Training
2025-04-08 05:48:26 | 252500 | LR0.0003 | loss:3.5864 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-225.8820 | logitMax:-203.8778 | windowWeightsW25:0.48355,W21:0.23437,W13:0.18623,W16:0.17799,W2:0.16157,W19:0.14323,W9:0.11223,W3:-0.24431,W4:-0.27861 | memoryGatesShort:10.000, Long:-11.415, Current:2.415 | topTokens[('?', 60), ('.', 55), ('to', 49), ('i', 32), ('what', 26), ('listening', 23), ('you', 23), ('he', 19), ('music', 17), (',', 13)] | Training
2025-04-08 05:53:29 | 255000 | LR0.0003 | loss:4.3728 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-246.7879 | logitMax:-226.7340 | windowWeightsW25:0.48856,W21:0.23833,W13:0.19196,W16:0.18413,W2:0.15881,W19:0.14370,W9:0.11278,W3:-0.25214,W4:-0.28998 | memoryGatesShort:10.276, Long:-11.865, Current:2.589 | topTokens[('.', 43), ('i', 29), ('the', 23), ('to', 21), ('a', 16), (',', 15), ('ing', 15), ('it', 12), ('y', 12), ('s', 11)] | Training
2025-04-08 05:58:32 | 257500 | LR0.0003 | loss:3.8433 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-250.7291 | logitMax:-230.4244 | windowWeightsW25:0.52279,W21:0.25882,W13:0.18543,W16:0.17615,W2:0.17014,W19:0.15139,W9:0.11368,W3:-0.27562,W4:-0.32784 | memoryGatesShort:11.501, Long:-13.548, Current:3.047 | topTokens[('the', 43), ('.', 42), ('a', 37), (',', 23), ('ed', 19), ('u', 15), ('id', 15), ('er', 13), ('s', 13), ('in', 13)] | Training
2025-04-08 06:03:45 | 260000 | LR0.0003 | loss:3.7937 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-243.2169 | logitMax:-222.3338 | windowWeightsW25:0.51485,W21:0.25286,W13:0.17687,W2:0.17652,W16:0.17025,W19:0.14656,W9:0.11841,W3:-0.26579,W4:-0.31558 | memoryGatesShort:9.036, Long:-10.506, Current:2.470 | topTokens[('the', 53), ('.', 28), ('s', 24), ('of', 20), (',', 19), ('room', 16), ('are', 15), ('to', 15), ('and', 13), ('a', 13)] | Training
2025-04-08 06:08:48 | 262500 | LR0.0003 | loss:4.2957 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-248.0448 | logitMax:-227.6775 | windowWeightsW25:0.52085,W21:0.25289,W2:0.16994,W13:0.16853,W16:0.16759,W19:0.14823,W9:0.11483,W3:-0.26308,W4:-0.30466 | memoryGatesShort:9.308, Long:-10.362, Current:2.054 | topTokens[('.', 88), ('to', 27), ('i', 19), (',', 17), ('a', 17), ('?', 15), ('s', 13), ('the', 12), ('uring', 11), ('ing', 10)] | Training
2025-04-08 06:13:52 | 265000 | LR0.0003 | loss:4.8137 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-243.8070 | logitMax:-223.9266 | windowWeightsW25:0.53155,W21:0.26141,W16:0.17550,W13:0.17141,W2:0.16112,W19:0.15886,W9:0.10439,W3:-0.27157,W4:-0.31758 | memoryGatesShort:9.594, Long:-10.741, Current:2.147 | topTokens[('.', 69), ('i', 44), ('?', 26), ('you', 22), ('to', 21), (',', 17), ('it', 17), ('and', 16), ('a', 12), ('the', 11)] | Training
2025-04-08 06:18:55 | 267500 | LR0.0003 | loss:4.7902 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-252.0264 | logitMax:-232.2076 | windowWeightsW25:0.56931,W21:0.26877,W2:0.17709,W16:0.16893,W13:0.16333,W19:0.15849,W9:0.09426,W3:-0.28583,W4:-0.34055 | memoryGatesShort:13.129, Long:-14.964, Current:2.834 | topTokens[('.', 55), ('i', 54), (',', 25), ('you', 21), ('the', 16), ('to', 15), ('xxx', 14), ('?', 14), ('a', 13), ('be', 13)] | Training
2025-04-08 06:24:08 | 270000 | LR0.0003 | loss:4.8922 | gradNorm:0.9986 | tokenCount:45000.0000 | logitMin:-253.7852 | logitMax:-233.4501 | windowWeightsW25:0.57124,W21:0.26832,W2:0.17864,W16:0.17403,W19:0.15515,W13:0.15308,W9:0.08780,W3:-0.27571,W4:-0.33881 | memoryGatesShort:10.079, Long:-11.133, Current:2.055 | topTokens[(',', 68), ('i', 38), ('a', 20), ('to', 13), ('in', 13), ('and', 12), ('for', 11), ('lo', 10), ('the', 10), ('b', 10)] | Training
2025-04-08 06:29:16 | 272500 | LR0.0003 | loss:4.0183 | gradNorm:0.9880 | tokenCount:45000.0000 | logitMin:-257.2206 | logitMax:-236.5696 | windowWeightsW25:0.51644,W21:0.24629,W2:0.18279,W16:0.16637,W13:0.15392,W19:0.13746,W9:0.10367,W3:-0.24129,W4:-0.29061 | memoryGatesShort:15.126, Long:-20.049, Current:5.923 | topTokens[(',', 63), ('i', 46), ('the', 28), ('me', 17), ('a', 16), ('to', 15), ('ing', 14), ('xox', 12), ('we', 11), ('and', 11)] | Training
2025-04-08 06:34:23 | 275000 | LR0.0003 | loss:4.8627 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-253.1021 | logitMax:-232.6204 | windowWeightsW25:0.51374,W21:0.26263,W16:0.17474,W2:0.15736,W19:0.15341,W13:0.15341,W9:0.09432,W3:-0.24603,W4:-0.28780 | memoryGatesShort:10.949, Long:-12.163, Current:2.214 | topTokens[(',', 44), ('.', 28), ('to', 26), ('i', 24), ('the', 21), ('a', 20), ('that', 18), ('and', 17), ('s', 14), ('you', 11)] | Training
2025-04-08 06:39:26 | 277500 | LR0.0003 | loss:3.8608 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-269.2830 | logitMax:-247.9803 | windowWeightsW25:0.49558,W21:0.24950,W16:0.18778,W13:0.16712,W19:0.15815,W2:0.15085,W9:0.10422,W3:-0.24477,W4:-0.29215 | memoryGatesShort:9.556, Long:-11.241, Current:2.685 | topTokens[('the', 46), ('.', 36), (',', 27), ('and', 18), ('er', 18), ('to', 17), ('a', 15), ('i', 13), ('of', 13), ('p', 12)] | Training
2025-04-08 06:44:39 | 280000 | LR0.0003 | loss:3.4107 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-276.2642 | logitMax:-254.1690 | windowWeightsW25:0.46707,W21:0.24289,W16:0.20100,W13:0.18012,W19:0.16634,W2:0.13622,W9:0.10920,W3:-0.24345,W4:-0.28213 | memoryGatesShort:9.282, Long:-11.032, Current:2.750 | topTokens[(',', 29), ('the', 22), ('.', 22), ('and', 20), ('s', 18), ('in', 17), ('to', 16), ("'", 15), ('of', 13), ('d', 13)] | Training
2025-04-08 06:49:43 | 282500 | LR0.0003 | loss:4.8121 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-284.4157 | logitMax:-264.0392 | windowWeightsW25:0.50214,W21:0.26686,W16:0.20346,W13:0.17749,W19:0.17704,W2:0.13879,W9:0.09593,W3:-0.27143,W4:-0.31398 | memoryGatesShort:9.626, Long:-10.607, Current:1.981 | topTokens[(',', 90), ('i', 29), ('and', 21), ('the', 20), ('to', 17), ('me', 15), ('it', 14), ('s', 14), ('a', 13), ('was', 13)] | Training
2025-04-08 06:54:46 | 285000 | LR0.0003 | loss:4.7899 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-279.6310 | logitMax:-259.4134 | windowWeightsW25:0.52085,W21:0.27113,W16:0.19706,W19:0.17539,W13:0.17098,W2:0.13868,W9:0.09459,W3:-0.27630,W4:-0.31646 | memoryGatesShort:10.573, Long:-12.277, Current:2.703 | topTokens[(',', 62), ('i', 46), ('me', 20), ('.', 18), ('to', 16), ('the', 15), ('it', 15), ('is', 13), ('and', 12), ('s', 11)] | Training
2025-04-08 06:59:49 | 287500 | LR0.0003 | loss:4.5498 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-280.1493 | logitMax:-260.1936 | windowWeightsW25:0.56360,W21:0.28469,W16:0.19779,W19:0.18287,W13:0.16665,W2:0.14252,W9:0.07890,W3:-0.30147,W4:-0.34078 | memoryGatesShort:10.973, Long:-12.542, Current:2.568 | topTokens[(',', 57), ('i', 55), ('and', 25), ('to', 21), ('the', 18), ('.', 16), ('in', 15), ('you', 15), ('but', 14), ('im', 11)] | Training
2025-04-08 07:05:03 | 290000 | LR0.0003 | loss:3.5513 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-251.0960 | logitMax:-228.9677 | windowWeightsW25:0.52316,W21:0.26612,W16:0.18519,W19:0.16274,W2:0.15684,W13:0.15204,W9:0.09112,W3:-0.25978,W4:-0.30197 | memoryGatesShort:15.639, Long:-18.833, Current:4.193 | topTokens[('.', 57), ('i', 44), ('?', 38), ('to', 32), ('you', 27), ('was', 20), ('her', 18), ('she', 16), ('what', 15), ('it', 12)] | Training
2025-04-08 07:10:07 | 292500 | LR0.0003 | loss:4.0438 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-259.6280 | logitMax:-238.2808 | windowWeightsW25:0.53475,W21:0.27875,W16:0.17215,W19:0.16331,W2:0.15942,W13:0.14572,W9:0.07530,W3:-0.25591,W4:-0.29830 | memoryGatesShort:33.467, Long:-39.643, Current:7.176 | topTokens[('.', 59), ('?', 32), ('i', 28), ('to', 26), ('you', 23), ('he', 19), ('s', 19), ('what', 18), ('was', 15), (',', 14)] | Training
2025-04-08 07:15:10 | 295000 | LR0.0003 | loss:4.7800 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-272.7001 | logitMax:-252.7371 | windowWeightsW25:0.55057,W21:0.28579,W16:0.17462,W19:0.17088,W13:0.15268,W2:0.14767,W9:0.06287,W3:-0.26781,W4:-0.30212 | memoryGatesShort:13.488, Long:-14.995, Current:2.507 | topTokens[('i', 39), (',', 36), ('.', 33), ('the', 23), ('to', 18), ('a', 17), ('of', 17), ('and', 15), ('ensive', 13), ('it', 12)] | Training
2025-04-08 07:20:13 | 297500 | LR0.0003 | loss:4.1407 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-283.5355 | logitMax:-262.8617 | windowWeightsW25:0.54377,W21:0.27845,W16:0.17732,W19:0.17212,W13:0.15287,W2:0.14926,W9:0.06936,W3:-0.26817,W4:-0.29976 | memoryGatesShort:11.792, Long:-13.264, Current:2.472 | topTokens[('i', 47), (',', 35), ('.', 26), ('it', 21), ('my', 18), ('and', 17), ('but', 15), ('that', 13), ('you', 11), ('the', 10)] | Training
2025-04-08 07:25:28 | 300000 | LR0.0003 | loss:3.0990 | gradNorm:0.9706 | tokenCount:45000.0000 | logitMin:-300.9571 | logitMax:-275.3711 | windowWeightsW25:0.54275,W21:0.27438,W16:0.16933,W2:0.16362,W19:0.16170,W13:0.14704,W9:0.07158,W3:-0.25961,W4:-0.29588 | memoryGatesShort:13.948, Long:-16.647, Current:3.698 | topTokens[('<UNK>', 235), ('must', 27), ('!', 24), ('.', 23), ('', 18), (',', 15), ('i', 14), ('the', 13), ('and', 9), ('this', 9)] | Training
2025-04-08 07:30:31 | 302500 | LR0.0003 | loss:2.4276 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-260.0277 | logitMax:-236.0173 | windowWeightsW25:0.48433,W21:0.24547,W16:0.17679,W13:0.16594,W19:0.15127,W2:0.14813,W9:0.10074,W3:-0.23177,W4:-0.26426 | memoryGatesShort:7.257, Long:-8.167, Current:1.910 | topTokens[('must', 68), ('the', 40), (',', 39), ('!', 35), ('elodie', 22), ('charis', 18), ('she', 17), ('kevin', 16), ('and', 16), ('brain', 15)] | Training
2025-04-08 07:35:38 | 305000 | LR0.0003 | loss:3.3163 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-311.1133 | logitMax:-288.3546 | windowWeightsW25:0.46257,W21:0.24596,W16:0.18064,W13:0.17064,W19:0.16258,W2:0.13322,W9:0.09994,W3:-0.22435,W4:-0.25362 | memoryGatesShort:7.782, Long:-8.314, Current:1.532 | topTokens[('.', 59), (',', 26), ('and', 23), ('to', 21), ('i', 21), ('in', 17), ('my', 14), ('s', 12), ('a', 12), ('the', 11)] | Training
2025-04-08 07:40:42 | 307500 | LR0.0003 | loss:4.8047 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-302.0409 | logitMax:-281.1694 | windowWeightsW25:0.50397,W21:0.27016,W16:0.19015,W19:0.18034,W13:0.16228,W2:0.13999,W9:0.07561,W3:-0.25271,W4:-0.29334 | memoryGatesShort:9.850, Long:-11.197, Current:2.347 | topTokens[('.', 110), ('i', 33), ('im', 17), ('me', 17), ('it', 15), ('and', 14), (',', 14), ('you', 13), ('to', 13), ('u', 12)] | Training
2025-04-08 07:45:56 | 310000 | LR0.0003 | loss:4.6207 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-288.8561 | logitMax:-267.5760 | windowWeightsW25:0.54651,W21:0.28816,W19:0.19025,W16:0.18876,W2:0.14880,W13:0.14803,W9:0.06303,W3:-0.27320,W4:-0.32515 | memoryGatesShort:12.893, Long:-14.563, Current:2.670 | topTokens[('.', 48), ('to', 30), ('i', 28), (',', 25), ('a', 17), ('that', 16), ('you', 14), ('it', 14), ('the', 13), ('of', 13)] | Training
2025-04-08 07:51:10 | 312500 | LR0.0003 | loss:4.5060 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-290.0609 | logitMax:-269.0750 | windowWeightsW25:0.54091,W21:0.28977,W16:0.20280,W19:0.20052,W13:0.14599,W2:0.14145,W9:0.05374,W3:-0.27194,W4:-0.32777 | memoryGatesShort:16.142, Long:-18.383, Current:3.242 | topTokens[('.', 46), (',', 44), ('a', 22), ('i', 20), ('the', 19), ('and', 17), ('of', 14), ('to', 12), ("'t", 11), ('was', 11)] | Training
2025-04-08 07:56:14 | 315000 | LR0.0003 | loss:3.1063 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-254.4373 | logitMax:-228.6483 | windowWeightsW25:0.52219,W21:0.26310,W16:0.19913,W19:0.17808,W2:0.17498,W13:0.15043,W9:0.07025,W3:-0.26489,W4:-0.31826 | memoryGatesShort:6.957, Long:-7.454, Current:1.497 | topTokens[(':', 41), ('i', 40), ('-', 33), ('0', 30), ("'", 25), ('5', 23), ("'", 22), ('4', 20), ('.', 19), ('?', 16)] | Training
2025-04-08 08:01:17 | 317500 | LR0.0003 | loss:1.3718 | gradNorm:0.9988 | tokenCount:45000.0000 | logitMin:-246.5792 | logitMax:-217.7263 | windowWeightsW25:0.49735,W21:0.24481,W16:0.21552,W2:0.18856,W19:0.17046,W13:0.16419,W9:0.07910,W3:-0.27161,W4:-0.31325 | memoryGatesShort:8.105, Long:-8.923, Current:1.818 | topTokens[(':', 55), ('-', 50), ("'", 39), ("'", 38), ('i', 29), ('0', 27), ('4', 26), ('to', 26), ('2', 22), (',', 22)] | Training
2025-04-08 08:06:31 | 320000 | LR0.0003 | loss:2.8937 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-265.3455 | logitMax:-240.4613 | windowWeightsW25:0.47835,W21:0.23254,W16:0.21776,W13:0.17448,W19:0.16985,W2:0.16647,W9:0.09291,W3:-0.26082,W4:-0.29530 | memoryGatesShort:10.355, Long:-11.453, Current:2.098 | topTokens[("'", 31), ("'", 29), ('-', 28), (',', 26), ('i', 22), (':', 22), ('.', 22), ('-', 21), ('0', 21), ('!', 17)] | Training
2025-04-08 08:11:35 | 322500 | LR0.0003 | loss:4.3281 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-289.5075 | logitMax:-268.2069 | windowWeightsW25:0.47270,W21:0.24016,W16:0.21976,W13:0.17517,W19:0.17503,W2:0.15142,W9:0.09100,W3:-0.25759,W4:-0.29084 | memoryGatesShort:12.242, Long:-13.525, Current:2.282 | topTokens[('a', 39), ('.', 32), ('to', 22), ('it', 20), ('that', 18), (',', 18), ('the', 17), ('you', 13), ('in', 13), ('i', 11)] | Training
2025-04-08 08:16:39 | 325000 | LR0.0003 | loss:3.4231 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-308.5492 | logitMax:-286.5329 | windowWeightsW25:0.48367,W21:0.24403,W16:0.22266,W13:0.18056,W19:0.17507,W2:0.14558,W9:0.08570,W3:-0.26571,W4:-0.29487 | memoryGatesShort:9.992, Long:-11.006, Current:2.014 | topTokens[(',', 28), ('i', 26), ('to', 24), ('the', 23), ('a', 23), ('', 19), ('-', 18), ('for', 14), ('and', 12), ('you', 12)] | Training
2025-04-08 08:21:43 | 327500 | LR0.0003 | loss:4.0161 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-326.6966 | logitMax:-305.1100 | windowWeightsW25:0.49068,W21:0.24741,W16:0.22058,W13:0.18690,W19:0.17295,W2:0.14368,W9:0.08417,W3:-0.27150,W4:-0.29828 | memoryGatesShort:10.551, Long:-11.921, Current:2.369 | topTokens[('.', 80), ('i', 38), ('?', 18), ('im', 17), ('you', 16), ('the', 13), ('a', 13), (',', 11), ('so', 11), ('as', 11)] | Training
2025-04-08 08:27:02 | 330000 | LR0.0003 | loss:3.8683 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-309.8688 | logitMax:-288.2478 | windowWeightsW25:0.48593,W21:0.25763,W16:0.22905,W13:0.19821,W19:0.17769,W2:0.12751,W9:0.08640,W3:-0.28199,W4:-0.30342 | memoryGatesShort:8.861, Long:-9.749, Current:1.888 | topTokens[('i', 30), ('the', 25), (',', 24), ('to', 21), ('.', 21), ('of', 17), ('is', 17), ('a', 16), ('for', 13), ('y', 12)] | Training
2025-04-08 08:32:07 | 332500 | LR0.0003 | loss:4.7736 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-307.4963 | logitMax:-286.0870 | windowWeightsW25:0.52942,W21:0.28641,W16:0.22571,W19:0.18766,W13:0.17979,W2:0.13098,W9:0.06952,W3:-0.30017,W4:-0.33340 | memoryGatesShort:9.794, Long:-10.661, Current:1.867 | topTokens[('.', 68), ('i', 29), ('a', 21), ('to', 17), (',', 17), ('*', 11), ('the', 10), ('p', 8), ('ed', 8), ('s', 8)] | Training
2025-04-08 08:37:11 | 335000 | LR0.0003 | loss:4.4035 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-314.8815 | logitMax:-294.3551 | windowWeightsW25:0.55826,W21:0.28749,W16:0.21613,W19:0.18768,W13:0.16851,W2:0.14658,W9:0.06079,W3:-0.30582,W4:-0.34466 | memoryGatesShort:10.975, Long:-12.833, Current:2.857 | topTokens[('.', 86), ('i', 40), ('you', 24), (',', 18), ('it', 18), ('the', 18), ('and', 13), ('a', 12), ('he', 12), ('but', 11)] | Training
2025-04-08 08:42:22 | 337500 | LR0.0003 | loss:3.3971 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-301.9068 | logitMax:-280.2252 | windowWeightsW25:0.54800,W21:0.26325,W16:0.20346,W19:0.16447,W2:0.16288,W13:0.15711,W9:0.06368,W3:-0.25743,W4:-0.33051 | memoryGatesShort:9.734, Long:-11.091, Current:2.357 | topTokens[('?', 73), ('.', 61), ('is', 51), ('you', 37), ('!', 35), ('plus', 29), ('are', 25), ('do', 21), ('f', 18), ('als', 18)] | Training
2025-04-08 08:47:40 | 340000 | LR0.0003 | loss:3.8368 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-297.8571 | logitMax:-276.5913 | windowWeightsW25:0.55625,W21:0.26875,W16:0.19093,W19:0.15984,W2:0.15933,W13:0.15780,W9:0.05503,W3:-0.24248,W4:-0.33064 | memoryGatesShort:18.331, Long:-20.862, Current:3.532 | topTokens[('?', 87), ('.', 68), ('is', 37), ('what', 31), ('you', 30), ('!', 27), ('are', 20), ('i', 19), (',', 18), ('a', 13)] | Training
2025-04-08 08:52:43 | 342500 | LR0.0003 | loss:4.4551 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-292.0631 | logitMax:-271.8395 | windowWeightsW25:0.56807,W21:0.27831,W16:0.20404,W19:0.17664,W13:0.16648,W2:0.14564,W9:0.04673,W3:-0.25650,W4:-0.35464 | memoryGatesShort:11.075, Long:-12.231, Current:2.156 | topTokens[('.', 57), ('i', 45), ('!', 38), (':', 26), (':)', 19), ('p', 16), ('?', 15), ('you', 14), (',', 11), ('s', 11)] | Training
2025-04-08 08:57:46 | 345000 | LR0.0003 | loss:3.2620 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-272.0133 | logitMax:-247.9629 | windowWeightsW25:0.51982,W21:0.25773,W16:0.20853,W19:0.16691,W13:0.16418,W2:0.15876,W9:0.06392,W3:-0.24421,W4:-0.31991 | memoryGatesShort:10.761, Long:-11.446, Current:1.685 | topTokens[(':', 42), ('-', 37), ('.', 35), ('0', 33), ('3', 30), ("'", 23), ('-', 23), ('i', 20), ('?', 19), ('5', 19)] | Training
2025-04-08 09:02:49 | 347500 | LR0.0003 | loss:3.3446 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-278.6995 | logitMax:-255.9176 | windowWeightsW25:0.48985,W21:0.25521,W16:0.22226,W19:0.18358,W13:0.15941,W2:0.15927,W9:0.07399,W3:-0.25187,W4:-0.31532 | memoryGatesShort:9.837, Long:-10.966, Current:2.129 | topTokens[(':', 58), ('-', 38), ("'", 33), ('0', 27), ('-', 27), ('4', 25), ('3', 23), ('2', 22), ("'", 20), ('the', 16)] | Training
2025-04-08 09:08:05 | 350000 | LR0.0003 | loss:2.4091 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-324.3772 | logitMax:-301.4421 | windowWeightsW25:0.41418,W16:0.23528,W21:0.22834,W13:0.18418,W19:0.18036,W2:0.13057,W9:0.10481,W3:-0.22283,W4:-0.27618 | memoryGatesShort:6.828, Long:-7.706, Current:1.879 | topTokens[('the', 43), ('.', 24), (',', 24), ('and', 22), ('er', 14), ('to', 14), ('in', 14), ('s', 13), ('of', 11), ('c', 11)] | Training
2025-04-08 09:13:10 | 352500 | LR0.0003 | loss:3.2313 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-332.8196 | logitMax:-308.9603 | windowWeightsW25:0.43062,W21:0.24552,W16:0.24143,W19:0.19847,W13:0.17701,W2:0.12192,W9:0.09186,W3:-0.23732,W4:-0.29099 | memoryGatesShort:7.678, Long:-8.557, Current:1.879 | topTokens[(',', 44), ('.', 30), ('the', 29), ('and', 20), ('i', 18), ('ed', 16), ('h', 13), ('in', 13), ('it', 12), ('a', 11)] | Training
2025-04-08 09:18:14 | 355000 | LR0.0003 | loss:4.1136 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-345.2875 | logitMax:-322.7151 | windowWeightsW25:0.46174,W21:0.25776,W16:0.23809,W19:0.20567,W13:0.17453,W2:0.11089,W9:0.08797,W3:-0.24855,W4:-0.30996 | memoryGatesShort:16.612, Long:-18.424, Current:2.812 | topTokens[('.', 65), ('i', 36), ('of', 27), (',', 26), ('the', 23), ('a', 18), ('and', 17), ('to', 17), ('in', 13), ('it', 13)] | Training
2025-04-08 09:23:17 | 357500 | LR0.0003 | loss:4.2335 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-341.5836 | logitMax:-319.7111 | windowWeightsW25:0.49641,W21:0.27616,W16:0.23532,W19:0.20773,W13:0.17340,W2:0.11735,W9:0.07333,W3:-0.26381,W4:-0.33870 | memoryGatesShort:13.790, Long:-15.581, Current:2.791 | topTokens[('.', 66), ('i', 40), ('it', 28), (',', 25), ('s', 18), ('a', 16), ('u', 15), ('of', 14), ('my', 14), ('to', 13)] | Training
2025-04-08 09:28:33 | 360000 | LR0.0003 | loss:3.2282 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-305.5481 | logitMax:-281.4456 | windowWeightsW25:0.51786,W21:0.29040,W16:0.22482,W19:0.20106,W13:0.15403,W2:0.13438,W9:0.05205,W3:-0.25520,W4:-0.34298 | memoryGatesShort:27.430, Long:-32.385, Current:5.955 | topTokens[('!', 73), ('it', 60), (',', 29), ('have', 24), ('and', 20), ('know', 18), ('we', 15), ('charis', 15), ('they', 14), ('been', 14)] | Training
2025-04-08 09:33:38 | 362500 | LR0.0003 | loss:4.0791 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-334.5412 | logitMax:-312.2470 | windowWeightsW25:0.51111,W21:0.28736,W16:0.22267,W19:0.19297,W13:0.15262,W2:0.13573,W9:0.05477,W3:-0.24802,W4:-0.33262 | memoryGatesShort:7.377, Long:-8.535, Current:2.158 | topTokens[('you', 52), ('.', 42), ('!', 35), (',', 23), ('the', 21), ('that', 17), ('to', 16), ('and', 15), ('is', 14), ('i', 12)] | Training
2025-04-08 09:38:42 | 365000 | LR0.0003 | loss:1.1277 | gradNorm:0.9979 | tokenCount:45000.0000 | logitMin:-395.0930 | logitMax:-367.5662 | windowWeightsW25:0.44952,W21:0.25520,W16:0.23320,W19:0.18103,W13:0.17315,W2:0.13145,W9:0.07450,W3:-0.22365,W4:-0.29637 | memoryGatesShort:5.166, Long:-5.663, Current:1.497 | topTokens[(',', 27), ('and', 25), ('.', 22), ('i', 17), ('the', 17), ('to', 11), ('in', 11), ('of', 10), ('ing', 9), ('es', 9)] | Training
2025-04-08 09:43:46 | 367500 | LR0.0003 | loss:2.3912 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-303.5455 | logitMax:-274.9217 | windowWeightsW25:0.48047,W21:0.27366,W16:0.23178,W19:0.18896,W13:0.16225,W2:0.14034,W9:0.05042,W3:-0.23245,W4:-0.31830 | memoryGatesShort:15.480, Long:-17.723, Current:3.243 | topTokens[('have', 75), ('will', 69), ('.', 45), ('felt', 44), ('!', 30), ('charis', 20), ('n', 19), ('it', 15), ('and', 14), ('elodie', 14)] | Training
2025-04-08 09:49:00 | 370000 | LR0.0003 | loss:2.7653 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-300.3267 | logitMax:-272.5873 | windowWeightsW25:0.48891,W21:0.27957,W16:0.23010,W19:0.19934,W13:0.16482,W2:0.13030,W9:0.04879,W3:-0.23614,W4:-0.32851 | memoryGatesShort:8.048, Long:-8.390, Current:1.342 | topTokens[('have', 56), ('will', 55), ('.', 43), ('felt', 37), ('!', 28), ('the', 22), ('charis', 17), ('i', 16), ('it', 15), ('you', 13)] | Training
2025-04-08 09:54:05 | 372500 | LR0.0003 | loss:2.6569 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-377.2310 | logitMax:-353.2468 | windowWeightsW25:0.45246,W21:0.27488,W16:0.23625,W19:0.20225,W13:0.18296,W2:0.10392,W9:0.06051,W3:-0.22843,W4:-0.30621 | memoryGatesShort:12.888, Long:-14.351, Current:2.463 | topTokens[('i', 50), ('.', 32), ('to', 25), ('s', 23), ('the', 18), ('and', 16), ('of', 14), (',', 14), ('with', 12), ('-', 11)] | Training
2025-04-08 09:59:09 | 375000 | LR0.0003 | loss:2.7014 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-344.3812 | logitMax:-318.7672 | windowWeightsW25:0.49284,W21:0.29713,W16:0.22978,W19:0.20710,W13:0.17448,W2:0.11658,W9:0.05928,W3:-0.25560,W4:-0.34426 | memoryGatesShort:9.697, Long:-10.727, Current:2.030 | topTokens[("'", 70), (':', 65), ('-', 64), ("'", 58), ('.', 39), ('charis', 35), ('d', 32), ('roid', 31), ('baby', 30), ('?', 17)] | Training
2025-04-08 10:04:12 | 377500 | LR0.0003 | loss:3.1981 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-330.0246 | logitMax:-303.0882 | windowWeightsW25:0.52940,W21:0.29219,W16:0.21599,W19:0.21378,W13:0.17344,W2:0.12362,W9:0.04111,W3:-0.25639,W4:-0.35669 | memoryGatesShort:8.709, Long:-9.559, Current:1.850 | topTokens[('00', 57), (':', 41), ('.', 32), ('0', 20), (',', 15), ('the', 15), ('5', 15), ('l', 13), ('a', 12), ('is', 12)] | Training
2025-04-08 10:09:25 | 380000 | LR0.0003 | loss:2.9484 | gradNorm:0.9993 | tokenCount:45000.0000 | logitMin:-318.1107 | logitMax:-291.9927 | windowWeightsW25:0.54015,W21:0.28326,W16:0.21125,W19:0.20731,W13:0.17637,W2:0.13720,W9:0.04679,W3:-0.26444,W4:-0.36204 | memoryGatesShort:14.362, Long:-16.997, Current:3.634 | topTokens[(',', 27), ('the', 25), ('.', 24), ('a', 23), ('and', 16), ('on', 16), ('of', 15), ('ed', 14), ('v', 13), ("'", 12)] | Training
2025-04-08 10:14:29 | 382500 | LR0.0003 | loss:3.5131 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-318.2707 | logitMax:-294.8827 | windowWeightsW25:0.53994,W21:0.28407,W19:0.20257,W16:0.19724,W13:0.16712,W2:0.14446,W9:0.04424,W3:-0.24844,W4:-0.35547 | memoryGatesShort:10.028, Long:-10.930, Current:1.901 | topTokens[('.', 58), ('?', 58), ('is', 39), ('i', 30), ('you', 29), ('a', 26), ('to', 22), (',', 18), ('the', 16), ('what', 16)] | Training
2025-04-08 10:19:33 | 385000 | LR0.0003 | loss:2.9746 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-286.0693 | logitMax:-260.2673 | windowWeightsW25:0.56207,W21:0.30396,W19:0.21536,W16:0.19545,W13:0.15202,W2:0.14517,W9:0.03414,W3:-0.26027,W4:-0.37279 | memoryGatesShort:10.516, Long:-11.024, Current:1.508 | topTokens[('must', 70), ('have', 59), ('.', 45), (',', 38), ('felt', 32), ('the', 27), ('i', 24), ('!', 21), ('to', 18), ('my', 16)] | Training
2025-04-08 10:24:36 | 387500 | LR0.0003 | loss:4.5106 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-332.1262 | logitMax:-310.1840 | windowWeightsW25:0.61692,W21:0.31226,W19:0.22790,W16:0.19826,W2:0.15244,W13:0.14920,W9:0.01383,W3:-0.28893,W4:-0.40826 | memoryGatesShort:11.107, Long:-11.839, Current:1.732 | topTokens[('i', 27), ('.', 26), ('to', 24), (',', 23), ('a', 22), ('and', 21), ('the', 18), ('that', 15), ('y', 14), ('was', 14)] | Training
2025-04-08 10:29:54 | 390000 | LR0.0003 | loss:4.6543 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-339.3173 | logitMax:-317.9925 | windowWeightsW25:0.64194,W21:0.31990,W19:0.22314,W16:0.20064,W2:0.16083,W13:0.15800,W9:0.00758,W3:-0.30350,W4:-0.43583 | memoryGatesShort:10.074, Long:-11.148, Current:2.075 | topTokens[('i', 41), ('.', 38), (',', 32), ('and', 21), ('to', 20), ('for', 14), ("'s", 14), ('it', 14), ('a', 13), ('just', 12)] | Training
2025-04-08 10:35:03 | 392500 | LR0.0003 | loss:4.4801 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-333.8627 | logitMax:-312.5710 | windowWeightsW25:0.66965,W21:0.33939,W19:0.23138,W16:0.19097,W2:0.15791,W13:0.14937,W9:-0.00480,W3:-0.31402,W4:-0.44776 | memoryGatesShort:11.721, Long:-13.014, Current:2.293 | topTokens[(',', 52), ('i', 33), ('and', 16), ('it', 15), ('to', 15), ('the', 14), ('.', 14), ('a', 13), ('you', 12), ('that', 11)] | Training
2025-04-08 10:40:15 | 395000 | LR0.0003 | loss:4.5381 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-342.5864 | logitMax:-321.3618 | windowWeightsW25:0.68877,W21:0.35460,W19:0.25052,W16:0.20509,W2:0.15763,W13:0.14661,W9:-0.02047,W3:-0.33514,W4:-0.47613 | memoryGatesShort:8.807, Long:-9.457, Current:1.650 | topTokens[(',', 69), ('i', 33), ('a', 16), ('and', 15), ('to', 13), ('of', 12), ('.', 12), ('the', 12), ('er', 12), ('l', 12)] | Training
2025-04-08 10:45:20 | 397500 | LR0.0003 | loss:4.4544 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-356.2658 | logitMax:-335.4225 | windowWeightsW25:0.70906,W21:0.36393,W19:0.25576,W16:0.20155,W2:0.17368,W13:0.14246,W9:-0.02419,W3:-0.35185,W4:-0.49984 | memoryGatesShort:9.582, Long:-10.402, Current:1.820 | topTokens[(',', 61), ('.', 20), ('a', 20), ('and', 18), ('your', 17), ('the', 16), ('to', 13), ('i', 11), ('ed', 11), ('s', 10)] | Training
2025-04-08 10:50:51 | 400000 | LR0.0003 | loss:3.4360 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-318.4242 | logitMax:-295.1184 | windowWeightsW25:0.69342,W21:0.34231,W19:0.26250,W16:0.22394,W2:0.18456,W13:0.15338,W9:-0.02956,W3:-0.35231,W4:-0.50765 | memoryGatesShort:12.619, Long:-14.618, Current:2.998 | topTokens[('can', 69), (',', 62), ('!', 31), ('the', 26), ('charis', 25), ('to', 15), ('weed', 14), ('it', 13), ('i', 12), ('kevin', 12)] | Training
2025-04-08 10:56:04 | 402500 | LR0.0003 | loss:2.5867 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-323.7578 | logitMax:-299.7626 | windowWeightsW25:0.57500,W21:0.30416,W19:0.24872,W16:0.22849,W13:0.16370,W2:0.15391,W9:0.01308,W3:-0.29256,W4:-0.42002 | memoryGatesShort:9.514, Long:-10.812, Current:2.298 | topTokens[('i', 44), ('.', 37), ('can', 33), ('!', 25), (',', 23), ('to', 22), ('it', 20), ('the', 12), ('elodie', 11), ('and', 11)] | Training
2025-04-08 11:01:17 | 405000 | LR0.0003 | loss:2.6664 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-399.6312 | logitMax:-375.4784 | windowWeightsW25:0.53733,W21:0.29535,W19:0.24092,W16:0.23378,W13:0.17477,W2:0.13750,W9:0.03252,W3:-0.28014,W4:-0.39633 | memoryGatesShort:5.726, Long:-6.050, Current:1.324 | topTokens[('the', 41), (',', 33), ('.', 28), ('i', 24), ('to', 18), ('s', 15), ('you', 14), ('a', 13), ('this', 13), ('er', 12)] | Training
2025-04-08 11:06:29 | 407500 | LR0.0003 | loss:2.3660 | gradNorm:0.9997 | tokenCount:45000.0000 | logitMin:-445.6575 | logitMax:-420.0501 | windowWeightsW25:0.53075,W21:0.30337,W19:0.25208,W16:0.24681,W13:0.18399,W2:0.12689,W9:0.03070,W3:-0.29044,W4:-0.40824 | memoryGatesShort:8.056, Long:-8.482, Current:1.426 | topTokens[(',', 52), ('the', 32), ('.', 24), ('s', 22), ('to', 22), ('a', 15), ('in', 14), ('and', 13), ('of', 12), ('es', 11)] | Training
2025-04-08 11:11:47 | 410000 | LR0.0003 | loss:3.7767 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-396.8628 | logitMax:-371.6039 | windowWeightsW25:0.56793,W21:0.31692,W19:0.25889,W16:0.23878,W13:0.18090,W2:0.13371,W9:0.01909,W3:-0.31108,W4:-0.43026 | memoryGatesShort:7.503, Long:-8.249, Current:1.746 | topTokens[(',', 53), ('the', 24), ('a', 23), ('it', 23), ('of', 21), ('!', 16), ('in', 15), ('have', 15), ('to', 14), ('so', 14)] | Training
2025-04-08 11:16:58 | 412500 | LR0.0003 | loss:2.0441 | gradNorm:0.9992 | tokenCount:45000.0000 | logitMin:-299.8578 | logitMax:-270.3148 | windowWeightsW25:0.53993,W21:0.29159,W19:0.24028,W16:0.23123,W13:0.17131,W2:0.14994,W9:0.02650,W3:-0.27718,W4:-0.39826 | memoryGatesShort:23.213, Long:-26.187, Current:3.974 | topTokens[('had', 80), (',', 52), ('!', 51), ('felt', 45), ('.', 29), ('it', 28), ('the', 27), ('and', 26), ('charis', 25), ('i', 24)] | Training
2025-04-08 11:22:04 | 415000 | LR0.0003 | loss:1.8323 | gradNorm:0.9994 | tokenCount:45000.0000 | logitMin:-313.6704 | logitMax:-283.4078 | windowWeightsW25:0.52654,W21:0.28129,W16:0.23653,W19:0.22602,W13:0.18337,W2:0.17322,W9:0.03639,W3:-0.29237,W4:-0.39602 | memoryGatesShort:10.128, Long:-11.281, Current:2.153 | topTokens[(':', 35), (',', 32), ('5', 32), ('-', 31), ('0', 28), ('-', 27), ('to', 25), ("'", 24), ("'", 23), ('i', 19)] | Training
2025-04-08 11:27:15 | 417500 | LR0.0003 | loss:2.2936 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-291.7199 | logitMax:-263.5110 | windowWeightsW25:0.57131,W21:0.29717,W19:0.24078,W16:0.23447,W2:0.17684,W13:0.16716,W9:0.01544,W3:-0.30574,W4:-0.42349 | memoryGatesShort:10.617, Long:-10.800, Current:1.183 | topTokens[('was', 53), ('.', 47), ('were', 45), (',', 37), ('charis', 29), ('the', 29), ('ing', 28), ('!', 25), ('elodie', 25), ('from', 18)] | Training
2025-04-08 11:32:34 | 420000 | LR0.0003 | loss:4.6525 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-328.2294 | logitMax:-304.8600 | windowWeightsW25:0.62799,W21:0.32507,W19:0.25161,W16:0.23902,W2:0.17457,W13:0.16541,W9:0.00097,W3:-0.34320,W4:-0.46885 | memoryGatesShort:12.657, Long:-13.872, Current:2.215 | topTokens[('.', 90), ('the', 28), (',', 17), ('i', 16), ('it', 16), ('a', 14), ("'s", 14), ('of', 13), ('what', 11), ('to', 11)] | Training
2025-04-08 11:37:44 | 422500 | LR0.0003 | loss:2.6097 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-342.0513 | logitMax:-317.0209 | windowWeightsW25:0.55493,W21:0.30966,W19:0.24728,W16:0.24205,W13:0.17356,W2:0.14931,W9:0.02380,W3:-0.30613,W4:-0.41959 | memoryGatesShort:13.017, Long:-13.997, Current:1.980 | topTokens[(',', 58), ('the', 31), ('.', 31), ('of', 21), ('it', 21), ('and', 19), ('i', 16), ('a', 16), ('their', 15), ('ed', 13)] | Training
2025-04-08 11:43:45 | 425000 | LR0.0003 | loss:3.2489 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-308.6528 | logitMax:-283.3200 | windowWeightsW25:0.60389,W21:0.32001,W19:0.24976,W16:0.23544,W2:0.17868,W13:0.17587,W9:-0.00103,W3:-0.33134,W4:-0.45824 | memoryGatesShort:11.494, Long:-13.013, Current:2.519 | topTokens[(',', 58), ('!', 41), ('the', 38), ('it', 28), ('been', 27), ('angle', 20), ('a', 17), ('he', 15), ('have', 15), ('to', 14)] | Training
2025-04-08 11:49:09 | 427500 | LR0.0003 | loss:3.6096 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-314.6726 | logitMax:-289.5232 | windowWeightsW25:0.66056,W21:0.34710,W19:0.26773,W16:0.24561,W2:0.17470,W13:0.16896,W9:-0.02781,W3:-0.35797,W4:-0.50717 | memoryGatesShort:12.805, Long:-13.607, Current:1.802 | topTokens[(',', 73), ('i', 43), ('been', 36), ('!', 32), ('it', 23), ('has', 20), ('to', 20), ('you', 17), ('and', 16), ('ing', 15)] | Training
2025-04-08 11:54:29 | 430000 | LR0.0003 | loss:2.1758 | gradNorm:0.9984 | tokenCount:45000.0000 | logitMin:-271.8341 | logitMax:-241.7055 | windowWeightsW25:0.63274,W21:0.32618,W19:0.25157,W16:0.24567,W2:0.20365,W13:0.17320,W9:0.00212,W3:-0.36035,W4:-0.50319 | memoryGatesShort:18.799, Long:-20.808, Current:3.009 | topTokens[(':', 52), ('-', 43), ('i', 34), ('0', 31), ("'", 30), (',', 29), ('4', 28), ("'", 25), ('you', 21), ('5', 21)] | Training
2025-04-08 11:59:41 | 432500 | LR0.0003 | loss:2.6128 | gradNorm:0.9973 | tokenCount:45000.0000 | logitMin:-318.5791 | logitMax:-291.0017 | windowWeightsW25:0.62212,W21:0.33376,W16:0.26144,W19:0.25732,W2:0.18914,W13:0.18843,W9:-0.00253,W3:-0.37816,W4:-0.49941 | memoryGatesShort:11.495, Long:-11.993, Current:1.499 | topTokens[('.', 37), ('i', 33), (':', 32), ("'", 22), (',', 20), ('0', 20), ('!', 20), ('4', 20), ('a', 18), ("'", 17)] | Training
2025-04-08 12:04:54 | 435000 | LR0.0003 | loss:4.6117 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-344.5875 | logitMax:-321.7690 | windowWeightsW25:0.67838,W21:0.35927,W19:0.28123,W16:0.27436,W13:0.18611,W2:0.18050,W9:-0.01967,W3:-0.41974,W4:-0.54968 | memoryGatesShort:10.858, Long:-11.447, Current:1.589 | topTokens[('.', 109), ('i', 47), ('the', 20), ('you', 17), ('it', 16), ('ohh', 14), ('are', 13), ('just', 12), ("'s", 12), (',', 11)] | Training
2025-04-08 12:10:05 | 437500 | LR0.0003 | loss:4.4992 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-331.4765 | logitMax:-309.1673 | windowWeightsW25:0.71611,W21:0.39066,W19:0.29303,W16:0.27276,W13:0.18568,W2:0.16946,W9:-0.02702,W3:-0.44887,W4:-0.58186 | memoryGatesShort:9.149, Long:-10.199, Current:2.050 | topTokens[('.', 32), ('to', 26), ('a', 25), (',', 23), ('of', 20), ('s', 17), ('they', 16), ('and', 16), ('ing', 15), ('it', 14)] | Training
2025-04-08 12:15:20 | 440000 | LR0.0003 | loss:3.0746 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-310.6817 | logitMax:-286.8740 | windowWeightsW25:0.68965,W21:0.35355,W19:0.27381,W16:0.26383,W2:0.19235,W13:0.17334,W9:-0.03504,W3:-0.39831,W4:-0.54285 | memoryGatesShort:14.004, Long:-16.505, Current:3.500 | topTokens[(',', 72), ('and', 71), ('s', 26), ('.', 26), ('i', 23), ('it', 22), ('you', 21), ('charis', 21), ('elodie', 19), ('the', 16)] | Training

--- 2025-04-08 13:39:19 --- babyLLM 'right, last time i got to step 442180... want to restart from there?'  - charis: 'no, restart please' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: 'well, i feel like... i dont know anymore. you're so fucking fast these days.'
2025-04-08 13:44:34 | 2500 | LR0.0003 | loss:5.0977 | gradNorm:1.0000 | logitMin:-366.0075 | logitMax:-343.6778 | tokenCount:45000.0000 | windowWeightsW25:0.77818,W21:0.39537,W19:0.30702,W16:0.26931,W2:0.20505,W13:0.17787,W9:-0.06892,W3:-0.46003,W4:-0.63634 | memoryGatesShort:10.029, Long:-10.704, Current:1.675 | topTokens[(',', 108), ('i', 59), ('it', 26), ('a', 17), ('and', 17), ('the', 15), ('to', 15), ('have', 13), ('l', 12), ('.', 11)] | Training
2025-04-08 13:50:43 | 5000 | LR0.0003 | loss:4.8793 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-339.8372 | logitMax:-317.4833 | windowWeightsW25:0.83251,W21:0.40396,W19:0.31146,W16:0.27816,W2:0.19870,W13:0.17722,W9:-0.08048,W3:-0.47263,W4:-0.68266 | memoryGatesShort:12.829, Long:-13.891, Current:2.062 | topTokens[('.', 67), (',', 48), ('i', 40), ('to', 17), ('just', 16), ('a', 12), ('it', 11), ('so', 11), ('is', 10), ('but', 10)] | Training
2025-04-08 13:55:55 | 7500 | LR0.0003 | loss:4.6158 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-333.8468 | logitMax:-312.7457 | windowWeightsW25:0.92016,W21:0.42667,W19:0.32297,W16:0.27669,W2:0.19738,W13:0.17161,W9:-0.09952,W3:-0.51244,W4:-0.73962 | memoryGatesShort:17.709, Long:-18.401, Current:1.692 | topTokens[('.', 125), ('i', 38), ('you', 18), (':', 15), ('me', 12), ('6', 12), ('and', 11), ('a', 11), ('not', 11), ('j', 11)] | Training
2025-04-08 14:01:12 | 10000 | LR0.0003 | loss:4.6996 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-319.0659 | logitMax:-297.7726 | windowWeightsW25:0.91783,W21:0.41483,W19:0.30451,W16:0.26021,W2:0.23022,W13:0.17310,W9:-0.10905,W3:-0.49331,W4:-0.73503 | memoryGatesShort:13.501, Long:-14.904, Current:2.402 | topTokens[('.', 108), ('?', 24), ('you', 19), ('a', 18), ('i', 18), ('h', 17), ('and', 14), ('k', 12), ('to', 12), ('airs', 12)] | Training
2025-04-08 14:06:22 | 12500 | LR0.0003 | loss:4.6531 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-312.0865 | logitMax:-290.4740 | windowWeightsW25:0.88731,W21:0.39224,W19:0.28640,W16:0.26002,W2:0.23665,W13:0.17878,W9:-0.10786,W3:-0.46472,W4:-0.70486 | memoryGatesShort:20.437, Long:-23.717, Current:4.280 | topTokens[('.', 45), ('i', 36), (',', 33), ('and', 22), ('you', 21), ('a', 16), ('to', 15), ('s', 14), ('not', 14), ('?', 12)] | Training

--- 2025-04-08 14:43:54 --- babyLLM 'right, last time i got to step 14802... want to restart from there?'  - charis: 'y' - babyLLM 'ok! let's go to step 14802! what am i learning today?' - charis: 'how to pass your exams in 'oh my god no''
2025-04-08 14:49:06 | 2500 | LR0.0003 | loss:3.3746 | gradNorm:1.0000 | logitMin:-322.0341 | logitMax:-299.0419 | tokenCount:45000.0000 | windowWeightsW25:0.78073,W21:0.32533,W2:0.27530,W16:0.25636,W19:0.22878,W13:0.15154,W9:-0.05707,W3:-0.40541,W4:-0.58972 | memoryGatesShort:17.734, Long:-19.984, Current:3.250 | topTokens[('?', 84), ('.', 68), ('you', 49), ('is', 45), ('i', 42), ('what', 26), ('do', 26), ('!', 20), ('are', 18), ('her', 15)] | Training
2025-04-08 14:55:07 | 5000 | LR0.0003 | loss:3.1044 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-322.9060 | logitMax:-299.3772 | windowWeightsW25:0.61240,W21:0.28108,W16:0.25009,W19:0.22601,W2:0.20431,W13:0.16507,W9:0.00362,W3:-0.31991,W4:-0.45078 | memoryGatesShort:10.938, Long:-12.188, Current:2.250 | topTokens[('?', 49), ('.', 47), (',', 40), ('you', 31), ('is', 22), ('i', 22), ('to', 20), ('what', 17), ('the', 17), ('are', 17)] | Training
2025-04-08 15:00:26 | 7500 | LR0.0003 | loss:4.8274 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-354.7722 | logitMax:-332.3340 | windowWeightsW25:0.65824,W21:0.30971,W16:0.25322,W19:0.24942,W2:0.16612,W13:0.15982,W9:-0.00451,W3:-0.34524,W4:-0.47496 | memoryGatesShort:12.322, Long:-12.888, Current:1.567 | topTokens[(',', 47), ('.', 31), ('the', 30), ('i', 26), ('to', 19), ('a', 18), ('you', 15), ('ed', 14), ('of', 13), ('s', 12)] | Training
2025-04-08 15:05:46 | 10000 | LR0.0003 | loss:4.6308 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-337.4526 | logitMax:-315.2508 | windowWeightsW25:0.72351,W21:0.34546,W19:0.26640,W16:0.26622,W2:0.17504,W13:0.15578,W9:-0.02464,W3:-0.39471,W4:-0.54328 | memoryGatesShort:11.068, Long:-12.054, Current:1.986 | topTokens[('.', 29), ('i', 22), ('to', 21), (',', 17), ('in', 15), ('s', 14), ('and', 14), ('a', 14), ('the', 14), ('es', 13)] | Training
2025-04-08 15:10:59 | 12500 | LR0.0003 | loss:4.6055 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-355.1050 | logitMax:-333.7459 | windowWeightsW25:0.73462,W21:0.36027,W19:0.26624,W16:0.25892,W2:0.17898,W13:0.15682,W9:-0.02707,W3:-0.39314,W4:-0.56633 | memoryGatesShort:9.899, Long:-10.807, Current:1.908 | topTokens[(',', 116), ('i', 58), ('the', 19), ('it', 19), ('?', 18), ('.', 17), ('on', 14), ('a', 13), ('of', 11), ('but', 11)] | Training
2025-04-08 15:16:44 | 15000 | LR0.0003 | loss:4.9152 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-354.9732 | logitMax:-334.2042 | windowWeightsW25:0.74689,W21:0.36753,W19:0.26356,W16:0.25273,W2:0.18733,W13:0.15636,W9:-0.03556,W3:-0.39239,W4:-0.57765 | memoryGatesShort:14.311, Long:-16.224, Current:2.912 | topTokens[(',', 92), ('i', 36), ('it', 18), ('-', 15), ('kevin', 13), ('to', 12), ('in', 12), ('but', 12), ('not', 11), ('the', 10)] | Training
2025-04-08 15:21:55 | 17500 | LR0.0003 | loss:3.0371 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-376.6181 | logitMax:-354.1419 | windowWeightsW25:0.65184,W21:0.32892,W16:0.25933,W19:0.25735,W13:0.18193,W2:0.16236,W9:0.00509,W3:-0.35922,W4:-0.51576 | memoryGatesShort:9.583, Long:-10.596, Current:2.013 | topTokens[(',', 54), ('and', 23), ('.', 21), ('the', 20), ('a', 14), ('ed', 14), ('it', 13), ('that', 13), ('of', 13), ('in', 12)] | Training
2025-04-08 15:27:33 | 20000 | LR0.0003 | loss:3.6070 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-388.5523 | logitMax:-364.7816 | windowWeightsW25:0.67399,W21:0.33717,W16:0.26381,W19:0.26011,W13:0.18078,W2:0.16267,W9:-0.01513,W3:-0.36527,W4:-0.52684 | memoryGatesShort:14.761, Long:-16.099, Current:2.338 | topTokens[(',', 33), ('.', 33), ('a', 19), ('to', 19), ('s', 16), ('in', 15), ('and', 15), ('the', 14), ('ing', 10), ('ll', 10)] | Training

--- 2025-04-08 15:30:36 --- babyLLM 'right, last time i got to step 20812... want to restart from there?'  - charis: 'no thanks, please start again' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: 'scheduled sampling is turned on, oh no'
2025-04-08 15:35:46 | 2500 | LR0.0003 | loss:2.0533 | gradNorm:0.9999 | logitMin:-322.0529 | logitMax:-296.4544 | tokenCount:45000.0000 | windowWeightsW25:0.65642,W21:0.31173,W16:0.24872,W19:0.24578,W2:0.20254,W13:0.17911,W9:-0.04427,W3:-0.33459,W4:-0.49468 | memoryGatesShort:13.052, Long:-14.837, Current:2.785 | topTokens[('could', 121), ('!', 79), ('the', 41), ('charis', 31), (',', 31), ('kevin', 28), ('weed', 23), ('.', 19), ('we', 19), ('brain', 18)] | Training
2025-04-08 15:41:52 | 5000 | LR0.0003 | loss:3.5683 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-289.5044 | logitMax:-263.5828 | windowWeightsW25:0.65346,W21:0.30889,W16:0.25259,W19:0.24563,W2:0.19300,W13:0.18243,W9:-0.03699,W3:-0.33817,W4:-0.48977 | memoryGatesShort:10.236, Long:-11.092, Current:1.856 | topTokens[('could', 42), (',', 35), ('the', 29), ('.', 29), ('to', 28), ('!', 28), ('charis', 24), ('and', 20), ('elodie', 17), ('you', 12)] | Training
2025-04-08 15:47:09 | 7500 | LR0.0003 | loss:5.1119 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-323.5955 | logitMax:-301.7686 | windowWeightsW25:0.71044,W21:0.33282,W16:0.27441,W19:0.25559,W13:0.18447,W2:0.17974,W9:-0.05161,W3:-0.38422,W4:-0.53175 | memoryGatesShort:10.955, Long:-11.433, Current:1.477 | topTokens[(',', 67), ('i', 35), ('a', 22), ('.', 18), ('s', 14), ('ed', 14), ('the', 13), ('me', 11), ('and', 10), ('to', 10)] | Training

--- 2025-04-08 15:53:52 --- babyLLM 'right, last time i got to step 143... want to restart from there?'  - charis: '8000' - babyLLM 'damn that's specific! heading to step 8000... what am i learning today?' - charis: 'jhgf'
2025-04-08 15:58:58 | 2500 | LR0.0003 | loss:2.8649 | gradNorm:0.9998 | logitMin:-335.1128 | logitMax:-309.6497 | tokenCount:45000.0000 | windowWeightsW25:0.62802,W21:0.31021,W16:0.25533,W19:0.25245,W2:0.18020,W13:0.17580,W9:-0.03470,W3:-0.33018,W4:-0.46495 | memoryGatesShort:10.326, Long:-11.585, Current:2.259 | topTokens[(',', 59), ('and', 48), ("'", 34), ('charis', 32), ('.', 27), ('you', 27), ('the', 21), ("'", 20), (':', 18), ('i', 17)] | Training
2025-04-08 16:05:16 | 5000 | LR0.0003 | loss:4.8620 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-346.0380 | logitMax:-323.7479 | windowWeightsW25:0.69725,W21:0.33596,W19:0.26956,W16:0.26521,W13:0.17443,W2:0.16707,W9:-0.05825,W3:-0.36873,W4:-0.51180 | memoryGatesShort:11.880, Long:-12.876, Current:1.995 | topTokens[('.', 66), ('i', 57), (',', 37), ('you', 27), ('and', 20), ('just', 20), ('a', 17), ('?', 15), ('to', 14), ("'s", 14)] | Training
2025-04-08 16:10:40 | 7500 | LR0.0003 | loss:4.4627 | gradNorm:0.9845 | tokenCount:45000.0000 | logitMin:-346.1355 | logitMax:-323.1622 | windowWeightsW25:0.69050,W21:0.32598,W19:0.25720,W16:0.25001,W13:0.19696,W2:0.16684,W9:-0.04145,W3:-0.37206,W4:-0.50309 | memoryGatesShort:8.418, Long:-9.286, Current:1.868 | topTokens[('i', 41), (',', 39), ('.', 24), ('s', 23), ('the', 22), ('to', 21), ('it', 17), ('that', 16), ('ing', 15), ('my', 15)] | Training
2025-04-08 16:16:27 | 10000 | LR0.0003 | loss:3.9052 | gradNorm:0.9411 | tokenCount:45000.0000 | logitMin:-357.7665 | logitMax:-334.0555 | windowWeightsW25:0.70847,W21:0.33947,W19:0.26059,W16:0.23280,W13:0.18521,W2:0.17330,W9:-0.05182,W3:-0.36963,W4:-0.50803 | memoryGatesShort:11.465, Long:-12.089, Current:1.624 | topTokens[('i', 37), ('.', 36), ('that', 28), ('you', 25), (',', 22), ('to', 19), ('ing', 18), ('my', 15), ('not', 14), ('comment', 13)] | Training
2025-04-08 16:22:12 | 12500 | LR0.0003 | loss:4.8525 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-366.0435 | logitMax:-344.7721 | windowWeightsW25:0.77928,W21:0.35705,W19:0.25136,W16:0.22888,W2:0.19493,W13:0.18716,W9:-0.06313,W3:-0.40554,W4:-0.56209 | memoryGatesShort:11.612, Long:-12.823, Current:2.211 | topTokens[('.', 54), ('i', 38), ('3', 29), ('and', 25), ('you', 21), ('?', 18), (',', 17), ('a', 16), ('<', 16), ('to', 14)] | Training
2025-04-08 16:28:08 | 15000 | LR0.0003 | loss:4.8088 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-354.5859 | logitMax:-333.5871 | windowWeightsW25:0.78435,W21:0.36499,W19:0.25114,W16:0.23708,W13:0.18154,W2:0.18138,W9:-0.06816,W3:-0.40216,W4:-0.56200 | memoryGatesShort:13.647, Long:-14.647, Current:1.999 | topTokens[(',', 63), ('and', 29), ('i', 28), ('a', 21), ('it', 17), ('to', 16), ('.', 15), ('the', 15), ('of', 15), ('s', 11)] | Training
2025-04-08 16:33:57 | 17500 | LR0.0003 | loss:4.8580 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-362.9600 | logitMax:-342.3860 | windowWeightsW25:0.80685,W21:0.36554,W19:0.26477,W16:0.23569,W2:0.19677,W13:0.17767,W9:-0.08153,W3:-0.41981,W4:-0.57883 | memoryGatesShort:13.191, Long:-14.294, Current:2.104 | topTokens[(',', 81), ('i', 26), ('to', 20), ('s', 15), ('the', 14), ('f', 13), ('.', 12), ('my', 12), ('a', 12), ('a', 11)] | Training
2025-04-08 16:39:24 | 20000 | LR0.0003 | loss:3.5289 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-364.0945 | logitMax:-341.4556 | windowWeightsW25:0.67608,W21:0.30758,W19:0.24245,W16:0.23235,W13:0.18304,W2:0.17662,W9:-0.03162,W3:-0.33931,W4:-0.47596 | memoryGatesShort:11.197, Long:-12.837, Current:2.640 | topTokens[(',', 53), ('s', 23), ('a', 22), ('and', 17), ('i', 17), ('.', 15), ('00', 13), ('ohh', 11), (':', 11), ('l', 10)] | Training
2025-04-08 16:44:50 | 22500 | LR0.0003 | loss:2.4544 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-407.2294 | logitMax:-384.8254 | windowWeightsW25:0.58981,W21:0.28694,W16:0.24860,W19:0.24179,W13:0.20492,W2:0.13913,W9:0.00853,W3:-0.31826,W4:-0.42737 | memoryGatesShort:6.240, Long:-6.528, Current:1.289 | topTokens[(',', 51), ('the', 27), ('a', 27), ('of', 19), ('and', 15), ('to', 15), ('.', 14), ('was', 14), ('s', 13), ('ed', 12)] | Training
2025-04-08 16:50:19 | 25000 | LR0.0003 | loss:3.1640 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-427.4525 | logitMax:-403.4227 | windowWeightsW25:0.60061,W21:0.29237,W19:0.24562,W16:0.24023,W13:0.17735,W2:0.14815,W9:-0.00247,W3:-0.30819,W4:-0.41986 | memoryGatesShort:15.071, Long:-16.204, Current:2.133 | topTokens[('?', 57), ('.', 54), ('you', 41), (',', 33), ('to', 27), ('is', 27), ('do', 25), ('i', 24), ('what', 17), ('!', 15)] | Training
2025-04-08 16:55:54 | 27500 | LR0.0003 | loss:2.9127 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-439.3248 | logitMax:-416.0871 | windowWeightsW25:0.57415,W21:0.30426,W19:0.25130,W16:0.25002,W13:0.19277,W2:0.12851,W9:0.00820,W3:-0.31945,W4:-0.41502 | memoryGatesShort:7.410, Long:-7.842, Current:1.433 | topTokens[('i', 34), ('.', 33), ('the', 24), ('to', 23), ('of', 18), (',', 16), ('it', 15), ('and', 15), ('is', 14), ('s', 13)] | Training
2025-04-08 17:01:38 | 30000 | LR0.0003 | loss:4.3219 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-440.1324 | logitMax:-416.7018 | windowWeightsW25:0.67564,W21:0.33985,W19:0.26845,W16:0.25763,W13:0.16721,W2:0.13945,W9:-0.02039,W3:-0.37231,W4:-0.48352 | memoryGatesShort:10.487, Long:-11.219, Current:1.732 | topTokens[('i', 26), ('.', 26), ('the', 25), ('to', 24), ('it', 21), (',', 15), ('for', 13), ('', 13), ('a', 11), ('-', 11)] | Training
2025-04-08 17:07:07 | 32500 | LR0.0003 | loss:4.1782 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-395.0893 | logitMax:-371.3079 | windowWeightsW25:0.68224,W21:0.34063,W19:0.27428,W16:0.25559,W13:0.17053,W2:0.15288,W9:-0.03926,W3:-0.36876,W4:-0.49662 | memoryGatesShort:8.732, Long:-9.428, Current:1.696 | topTokens[('.', 32), (',', 27), ('the', 25), ('a', 18), ('that', 17), ('i', 13), ('o', 12), ('to', 12), ('he', 11), ('s', 10)] | Training
2025-04-08 17:12:36 | 35000 | LR0.0003 | loss:3.8189 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-386.3666 | logitMax:-362.5296 | windowWeightsW25:0.74055,W21:0.34967,W19:0.26961,W16:0.26332,W2:0.17098,W13:0.16064,W9:-0.05811,W3:-0.38847,W4:-0.53862 | memoryGatesShort:11.861, Long:-13.022, Current:2.160 | topTokens[('the', 39), ('.', 27), ('to', 24), ('i', 19), (',', 17), ('s', 15), ('p', 15), ('?', 15), ('of', 13), ('were', 12)] | Training
2025-04-08 17:18:05 | 37500 | LR0.0003 | loss:3.2363 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-377.8016 | logitMax:-353.8962 | windowWeightsW25:0.71353,W21:0.34350,W19:0.26101,W16:0.23777,W2:0.17826,W13:0.14277,W9:-0.04302,W3:-0.36175,W4:-0.50193 | memoryGatesShort:14.092, Long:-15.072, Current:1.980 | topTokens[('.', 72), ('?', 56), ('you', 35), ('to', 35), ('i', 32), ('!', 24), ('what', 24), ('is', 24), ('please', 16), ('say', 14)] | Training
2025-04-08 17:23:40 | 40000 | LR0.0003 | loss:4.2493 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-370.2242 | logitMax:-348.0183 | windowWeightsW25:0.76106,W21:0.36012,W19:0.28033,W16:0.22938,W2:0.19535,W13:0.14889,W9:-0.06828,W3:-0.38607,W4:-0.55243 | memoryGatesShort:11.852, Long:-13.507, Current:2.654 | topTokens[('.', 48), ('i', 38), ('the', 24), ('it', 19), (',', 19), ('a', 16), ('s', 16), ('to', 14), ('and', 13), ('!', 12)] | Training
2025-04-08 17:29:22 | 42500 | LR0.0003 | loss:3.3968 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-388.6858 | logitMax:-365.9212 | windowWeightsW25:0.71159,W21:0.35928,W19:0.27913,W16:0.23305,W2:0.17379,W13:0.16460,W9:-0.05027,W3:-0.37814,W4:-0.52293 | memoryGatesShort:12.529, Long:-14.161, Current:2.632 | topTokens[('.', 50), (',', 48), ('of', 24), ('and', 23), ('to', 21), ('a', 19), ('was', 19), ('the', 18), ('s', 16), ('i', 13)] | Training
2025-04-08 17:35:05 | 45000 | LR0.0003 | loss:3.2133 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-358.9552 | logitMax:-333.9432 | windowWeightsW25:0.69756,W21:0.34083,W19:0.24182,W16:0.20878,W2:0.19208,W13:0.15410,W9:-0.03305,W3:-0.34086,W4:-0.49101 | memoryGatesShort:12.413, Long:-13.244, Current:1.831 | topTokens[('.', 58), ('?', 51), ('i', 45), (',', 41), ('you', 24), ('to', 23), ('what', 20), ('he', 16), ('were', 14), ('looking', 12)] | Training
2025-04-08 17:40:39 | 47500 | LR0.0003 | loss:4.9017 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-394.8639 | logitMax:-373.7465 | windowWeightsW25:0.79814,W21:0.37993,W19:0.26276,W16:0.21225,W2:0.19893,W13:0.14807,W9:-0.05359,W3:-0.41220,W4:-0.56691 | memoryGatesShort:11.976, Long:-12.638, Current:1.662 | topTokens[(',', 111), ('i', 40), ('it', 22), ('im', 17), ('to', 14), ('and', 13), ('its', 11), ('but', 10), ('k', 10), ('her', 9)] | Training
2025-04-08 17:46:02 | 50000 | LR0.0003 | loss:3.3957 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-392.8437 | logitMax:-369.6051 | windowWeightsW25:0.69435,W21:0.33161,W19:0.24869,W16:0.22120,W2:0.19107,W13:0.17065,W9:-0.01843,W3:-0.36537,W4:-0.50341 | memoryGatesShort:10.959, Long:-12.122, Current:2.163 | topTokens[(',', 52), ('the', 18), ('i', 17), ('of', 14), ('to', 14), ('es', 14), ('o', 11), ('a', 10), ('s', 9), ('h', 9)] | Training
2025-04-08 17:51:13 | 52500 | LR0.0003 | loss:3.0863 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-353.7109 | logitMax:-328.7213 | windowWeightsW25:0.76065,W21:0.35739,W19:0.26651,W16:0.22972,W2:0.20380,W13:0.16822,W9:-0.05411,W3:-0.40879,W4:-0.55513 | memoryGatesShort:12.065, Long:-12.712, Current:1.648 | topTokens[('must', 80), ('!', 42), ('the', 37), (',', 30), ('.', 27), ('elodie', 24), ('charis', 21), ('kevin', 21), ('butt', 18), ('she', 18)] | Training
2025-04-08 17:56:24 | 55000 | LR0.0003 | loss:4.3037 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-390.2860 | logitMax:-367.8862 | windowWeightsW25:0.79019,W21:0.37361,W19:0.26724,W16:0.23776,W2:0.20746,W13:0.16767,W9:-0.05684,W3:-0.43521,W4:-0.58459 | memoryGatesShort:11.338, Long:-12.069, Current:1.731 | topTokens[(',', 75), ('.', 40), ('i', 18), ('a', 17), ('the', 15), ('s', 12), ('is', 12), ('elodie', 12), ('p', 10), ('al', 10)] | Training
2025-04-08 18:01:34 | 57500 | LR0.0003 | loss:4.8993 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-391.8244 | logitMax:-370.4638 | windowWeightsW25:0.89290,W21:0.41256,W19:0.28518,W16:0.24377,W2:0.22745,W13:0.17238,W9:-0.08725,W3:-0.50401,W4:-0.67913 | memoryGatesShort:13.970, Long:-15.482, Current:2.512 | topTokens[(',', 93), ('i', 36), ('like', 21), ('im', 14), ('the', 13), ('me', 13), ('tou', 12), ('u', 12), ('we', 11), ('on', 9)] | Training
2025-04-08 18:06:51 | 60000 | LR0.0003 | loss:3.9428 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-401.5473 | logitMax:-379.1813 | windowWeightsW25:0.75506,W21:0.38181,W19:0.27618,W16:0.24996,W13:0.18839,W2:0.18355,W9:-0.05188,W3:-0.44050,W4:-0.57402 | memoryGatesShort:13.809, Long:-15.200, Current:2.391 | topTokens[('.', 41), ('a', 32), (',', 28), ('ed', 20), ('this', 17), ('that', 16), ('i', 16), ('it', 15), ('to', 15), ('in', 14)] | Training
2025-04-08 18:12:00 | 62500 | LR0.0003 | loss:3.2953 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-391.6502 | logitMax:-368.4041 | windowWeightsW25:0.72550,W21:0.38082,W19:0.28297,W16:0.26053,W13:0.18860,W2:0.17853,W9:-0.04044,W3:-0.43215,W4:-0.57514 | memoryGatesShort:12.926, Long:-14.052, Current:2.125 | topTokens[('to', 27), ('the', 22), ('i', 21), (',', 19), ('in', 19), ('s', 18), ('and', 17), ('.', 16), ('of', 14), ('es', 12)] | Training
2025-04-08 18:17:06 | 65000 | LR0.0003 | loss:4.6640 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-402.6285 | logitMax:-380.5211 | windowWeightsW25:0.84043,W21:0.41456,W19:0.29605,W16:0.26120,W2:0.20889,W13:0.17504,W9:-0.07272,W3:-0.49860,W4:-0.65944 | memoryGatesShort:12.433, Long:-13.197, Current:1.764 | topTokens[('i', 51), ('.', 48), (',', 23), ('you', 21), ('a', 20), ('to', 18), ('ing', 14), ('s', 14), ('was', 13), ('the', 11)] | Training
2025-04-08 18:22:16 | 67500 | LR0.0003 | loss:3.0464 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-370.2931 | logitMax:-345.7604 | windowWeightsW25:0.83755,W21:0.36872,W2:0.26955,W16:0.25323,W19:0.24939,W13:0.17402,W9:-0.07767,W3:-0.45757,W4:-0.65316 | memoryGatesShort:14.324, Long:-16.272, Current:2.948 | topTokens[('to', 48), ('?', 44), ('.', 42), ('i', 40), ('music', 25), ('listening', 23), ('you', 20), ('what', 18), ('was', 16), ('the', 12)] | Training
2025-04-08 18:27:29 | 70000 | LR0.0003 | loss:2.8403 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-358.4470 | logitMax:-332.7471 | windowWeightsW25:0.79906,W21:0.34514,W2:0.25821,W16:0.25081,W19:0.22242,W13:0.18455,W9:-0.05235,W3:-0.42618,W4:-0.61624 | memoryGatesShort:14.937, Long:-15.375, Current:1.438 | topTokens[('to', 63), ('.', 52), ('listening', 45), ('?', 39), ('music', 36), ('what', 30), ('you', 30), ('i', 24), ('were', 18), ('he', 13)] | Training
2025-04-08 18:32:38 | 72500 | LR0.0003 | loss:4.9317 | gradNorm:0.9495 | tokenCount:45000.0000 | logitMin:-383.6462 | logitMax:-357.8875 | windowWeightsW25:0.88819,W21:0.39031,W2:0.26697,W16:0.26368,W19:0.24535,W13:0.17093,W9:-0.08562,W3:-0.48636,W4:-0.69074 | memoryGatesShort:11.787, Long:-12.243, Current:1.456 | topTokens[('ugh', 57), ('.', 49), ('i', 24), ('and', 19), (',', 16), ('you', 15), ('to', 14), ('just', 10), ('in', 10), ('!', 9)] | Training
2025-04-08 18:37:49 | 75000 | LR0.0003 | loss:3.9843 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-366.6603 | logitMax:-343.1478 | windowWeightsW25:0.95969,W21:0.40759,W2:0.32760,W16:0.25292,W19:0.24706,W13:0.16456,W9:-0.11516,W3:-0.51809,W4:-0.76708 | memoryGatesShort:54.966, Long:-61.960, Current:7.994 | topTokens[(',', 47), ('i', 29), ('a', 28), ('2', 28), ('days', 28), ('!', 23), ('to', 20), ('it', 18), ('and', 17), ('.', 17)] | Training

--- 2025-04-08 18:43:06 --- babyLLM 'right, last time i got to step 75447... want to restart from there?'  - charis: 'no, i grabbed you some new data so we shoud look at the start!' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: 'i found more of my chaotic poetry hahaha, i also set your windows just sliiightly differently - i hope you like it!!'
2025-04-08 18:48:14 | 2500 | LR0.0003 | loss:3.8864 | gradNorm:1.0000 | logitMin:-403.9518 | logitMax:-382.0567 | scheduledSampling:0.0000 | tokenCount:45000.0000 | windowWeightsW25:0.86730,W21:0.37645,W2:0.29862,W16:0.26838,W19:0.22876,W9:0.15636,W13:-0.05694,W3:-0.48644,W5:-0.68983 | memoryGatesShort:10.445, Long:-11.861, Current:2.416 | topTokens[('she', 48), ('.', 45), ('and', 28), ('a', 22), ('is', 21), ('to', 18), ('in', 18), (',', 17), ('the', 12), ('ed', 12)] | Training
2025-04-08 18:53:27 | 5000 | LR0.0003 | loss:3.3766 | gradNorm:0.9997 | tokenCount:45000.0000 | logitMin:-405.5597 | logitMax:-381.1630 | windowWeightsW25:0.76482,W21:0.34577,W2:0.26357,W16:0.26188,W19:0.22269,W9:0.16589,W13:-0.02768,W3:-0.43516,W5:-0.59533 | memoryGatesShort:26.299, Long:-29.298, Current:3.999 | topTokens[(',', 52), ('i', 30), ('.', 29), ('to', 23), ('of', 18), ('the', 18), ('and', 16), ('she', 16), ('s', 13), ("'t", 12)] | Training
2025-04-08 18:58:38 | 7500 | LR0.0003 | loss:4.0297 | gradNorm:0.9458 | tokenCount:45000.0000 | logitMin:-406.1644 | logitMax:-380.3684 | windowWeightsW25:0.77942,W21:0.36001,W16:0.24923,W2:0.24855,W19:0.21241,W9:0.15997,W13:-0.02024,W3:-0.42610,W5:-0.59667 | memoryGatesShort:14.747, Long:-15.857, Current:2.111 | topTokens[(',', 68), ('<', 38), ('3', 34), ('you', 28), ('i', 26), ('the', 23), ('.', 20), ('to', 18), ("'m", 16), ('it', 15)] | Training
2025-04-08 19:04:05 | 10000 | LR0.0003 | loss:4.8229 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-384.9276 | logitMax:-363.7194 | windowWeightsW25:0.85927,W21:0.40379,W16:0.26776,W2:0.24910,W19:0.24109,W9:0.13414,W13:-0.03104,W3:-0.48656,W5:-0.67322 | memoryGatesShort:14.959, Long:-16.151, Current:2.192 | topTokens[('.', 61), ('i', 33), ('and', 24), ('to', 24), ('it', 17), ('a', 16), ('that', 15), (',', 13), ('the', 12), ('you', 11)] | Training
2025-04-08 19:09:24 | 12500 | LR0.0003 | loss:3.6879 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-393.5272 | logitMax:-371.3516 | windowWeightsW25:0.83173,W21:0.38025,W16:0.27507,W2:0.24883,W19:0.23505,W9:0.13432,W13:-0.00946,W3:-0.47508,W5:-0.65562 | memoryGatesShort:18.816, Long:-21.085, Current:3.269 | topTokens[('.', 39), ('the', 34), ('i', 28), (',', 19), ('a', 19), ('s', 13), ('ed', 12), ('to', 11), ('h', 10), ('and', 10)] | Training
2025-04-08 19:14:46 | 15000 | LR0.0003 | loss:3.2879 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-377.6914 | logitMax:-354.0001 | windowWeightsW25:0.77557,W21:0.36749,W16:0.27063,W19:0.23591,W2:0.23419,W9:0.11960,W13:0.00090,W3:-0.43436,W5:-0.60287 | memoryGatesShort:15.285, Long:-17.256, Current:2.971 | topTokens[('the', 36), ('could', 35), ('.', 28), (',', 23), ('to', 22), ('!', 22), ('a', 14), ('er', 12), ('s', 12), ('and', 11)] | Training
2025-04-08 19:20:09 | 17500 | LR0.0003 | loss:2.8077 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-388.8928 | logitMax:-365.2134 | windowWeightsW25:0.68736,W21:0.34568,W16:0.27670,W19:0.23223,W2:0.18721,W9:0.12950,W13:0.03617,W3:-0.39609,W5:-0.52819 | memoryGatesShort:8.765, Long:-9.521, Current:1.756 | topTokens[(',', 52), ('could', 34), ('the', 31), ('.', 30), ('!', 21), ('to', 19), ('and', 18), ('of', 16), ('a', 16), ('they', 12)] | Training
2025-04-08 19:25:38 | 20000 | LR0.0003 | loss:4.6388 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-422.7765 | logitMax:-400.4662 | windowWeightsW25:0.76395,W21:0.38555,W16:0.27774,W19:0.25282,W2:0.18491,W9:0.10118,W13:0.02081,W3:-0.43383,W5:-0.58427 | memoryGatesShort:14.073, Long:-15.098, Current:2.025 | topTokens[('.', 42), ('i', 34), (',', 29), ('to', 23), ('a', 23), ('it', 18), ('of', 12), ("'t", 11), ('the', 11), ('if', 10)] | Training
2025-04-08 19:31:11 | 22500 | LR0.0003 | loss:4.2847 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-403.2887 | logitMax:-380.2627 | windowWeightsW25:0.80629,W21:0.39656,W16:0.28079,W19:0.24596,W2:0.20068,W9:0.08417,W13:0.00683,W3:-0.43368,W5:-0.62015 | memoryGatesShort:12.286, Long:-13.409, Current:2.123 | topTokens[(',', 59), ('i', 36), ('.', 25), ('!', 20), ('the', 17), ('that', 12), ('is', 11), ('you', 11), ('be', 11), ('and', 11)] | Training
2025-04-08 19:36:33 | 25000 | LR0.0003 | loss:4.1866 | gradNorm:0.9818 | tokenCount:45000.0000 | logitMin:-424.0628 | logitMax:-401.3456 | windowWeightsW25:0.79728,W21:0.39952,W16:0.27185,W19:0.24228,W2:0.20133,W9:0.06756,W13:0.02731,W3:-0.42571,W5:-0.61367 | memoryGatesShort:15.750, Long:-17.190, Current:2.441 | topTokens[(',', 69), ('ing', 28), ('.', 25), ('the', 21), ('you', 21), ('to', 17), ('that', 17), ('it', 17), ('a', 16), ('i', 16)] | Training
2025-04-08 19:41:56 | 27500 | LR0.0003 | loss:3.6879 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-406.4906 | logitMax:-383.4788 | windowWeightsW25:0.78988,W21:0.39064,W16:0.27260,W19:0.23614,W2:0.21325,W9:0.05750,W13:0.03021,W3:-0.41974,W5:-0.60282 | memoryGatesShort:14.315, Long:-15.702, Current:2.387 | topTokens[('.', 41), ('the', 30), ('to', 24), (',', 23), ('a', 18), ('i', 15), ('and', 13), ('of', 12), ('s', 12), ('o', 11)] | Training
2025-04-08 19:47:15 | 30000 | LR0.0003 | loss:4.5733 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-405.5127 | logitMax:-383.6671 | windowWeightsW25:0.82237,W21:0.40798,W16:0.28422,W19:0.26077,W2:0.21583,W9:0.03730,W13:0.02744,W3:-0.44387,W5:-0.64538 | memoryGatesShort:14.464, Long:-15.559, Current:2.096 | topTokens[('i', 30), (',', 27), ('to', 24), ('.', 23), ('the', 20), ('and', 19), ('of', 13), ('a', 13), ('s', 13), ('in', 13)] | Training
2025-04-08 19:52:30 | 32500 | LR0.0003 | loss:4.1081 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-409.0037 | logitMax:-387.5259 | windowWeightsW25:0.83257,W21:0.41444,W16:0.29427,W19:0.25644,W2:0.22720,W9:0.03422,W13:0.03390,W3:-0.45892,W5:-0.66810 | memoryGatesShort:12.017, Long:-13.439, Current:2.422 | topTokens[(',', 67), ('i', 33), ('a', 20), ('to', 18), ('and', 16), ('ing', 15), ('me', 14), ('.', 13), ('you', 13), ('egg', 12)] | Training
2025-04-08 19:57:44 | 35000 | LR0.0003 | loss:2.9187 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-400.6235 | logitMax:-376.5532 | windowWeightsW25:0.70158,W21:0.35583,W16:0.30163,W19:0.23248,W2:0.20254,W13:0.08356,W9:0.07330,W3:-0.40221,W5:-0.57875 | memoryGatesShort:15.391, Long:-16.837, Current:2.446 | topTokens[(',', 68), ('the', 29), ('-', 25), ('a', 21), (':', 18), ("'", 15), ('.', 14), ('egg', 14), ('and', 11), ('ed', 10)] | Training
2025-04-08 20:02:52 | 37500 | LR0.0003 | loss:1.5559 | gradNorm:0.9997 | tokenCount:45000.0000 | logitMin:-347.6823 | logitMax:-317.6545 | windowWeightsW25:0.63545,W21:0.32574,W16:0.29545,W2:0.21576,W19:0.20561,W13:0.10313,W9:0.09642,W3:-0.37991,W5:-0.52632 | memoryGatesShort:15.497, Long:-16.788, Current:2.292 | topTokens[(':', 53), ('-', 51), ("'", 44), ('i', 37), ("'", 35), ('m', 29), ('5', 27), ('?', 26), ('at', 23), ('lear', 23)] | Training
2025-04-08 20:08:04 | 40000 | LR0.0003 | loss:4.1482 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-417.5425 | logitMax:-394.8329 | windowWeightsW25:0.66263,W21:0.35440,W16:0.30515,W19:0.21772,W2:0.21036,W13:0.09895,W9:0.07956,W3:-0.40158,W5:-0.55649 | memoryGatesShort:15.404, Long:-16.925, Current:2.521 | topTokens[('.', 32), ('i', 28), (',', 22), ('a', 20), ('to', 18), ('you', 18), ('-', 15), ('it', 13), (':', 11), ("'t", 11)] | Training
2025-04-08 20:13:11 | 42500 | LR0.0003 | loss:4.4859 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-406.6600 | logitMax:-384.2698 | windowWeightsW25:0.69157,W21:0.37254,W16:0.31022,W19:0.22767,W2:0.20834,W13:0.09443,W9:0.07385,W3:-0.42219,W5:-0.58642 | memoryGatesShort:15.781, Long:-17.468, Current:2.687 | topTokens[('i', 52), ('.', 20), (',', 19), ('the', 18), ('but', 17), ('a', 15), ('al', 12), ('was', 12), ('of', 11), ('c', 11)] | Training
2025-04-08 20:18:10 | 45000 | LR0.0003 | loss:3.1916 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-425.2441 | logitMax:-401.4534 | windowWeightsW25:0.65054,W21:0.35491,W16:0.32193,W19:0.22033,W2:0.19004,W13:0.10828,W9:0.07956,W3:-0.40036,W5:-0.55379 | memoryGatesShort:14.189, Long:-16.157, Current:2.968 | topTokens[('the', 53), (',', 29), ('to', 26), ('i', 22), ('.', 15), ('p', 13), ('s', 13), ('o', 11), ('of', 11), ('ed', 11)] | Training
2025-04-08 20:23:20 | 47500 | LR0.0003 | loss:2.3022 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-437.5977 | logitMax:-412.3836 | windowWeightsW25:0.65840,W21:0.36009,W16:0.32293,W19:0.22012,W2:0.19800,W13:0.11112,W9:0.07284,W3:-0.40785,W5:-0.56463 | memoryGatesShort:11.809, Long:-12.607, Current:1.798 | topTokens[('the', 42), ('to', 29), ('.', 25), ('i', 22), (',', 19), ('and', 15), ('was', 14), ('that', 10), ('al', 10), ('in', 9)] | Training
2025-04-08 20:28:39 | 50000 | LR0.0003 | loss:2.5714 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-417.0850 | logitMax:-392.3103 | windowWeightsW25:0.59562,W21:0.33135,W16:0.31180,W19:0.21644,W2:0.17420,W13:0.12484,W9:0.08670,W3:-0.36592,W5:-0.50177 | memoryGatesShort:11.695, Long:-12.681, Current:1.986 | topTokens[('.', 43), ('to', 28), ('the', 28), ('a', 23), ('and', 14), ('i', 13), (',', 12), ('pro', 11), ('es', 10), ('1', 9)] | Training
2025-04-08 20:33:44 | 52500 | LR0.0003 | loss:4.9878 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-430.9214 | logitMax:-408.8065 | windowWeightsW25:0.69572,W21:0.36595,W16:0.32352,W19:0.23399,W2:0.18924,W13:0.10118,W9:0.05838,W3:-0.42060,W5:-0.57693 | memoryGatesShort:13.858, Long:-14.956, Current:2.097 | topTokens[(',', 87), ('i', 44), ('the', 26), ('that', 16), ('a', 14), ('and', 13), ('s', 12), ('?', 11), ('is', 10), ('it', 10)] | Training
2025-04-08 20:38:47 | 55000 | LR0.0003 | loss:3.2400 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-427.9009 | logitMax:-404.1230 | windowWeightsW25:0.63755,W21:0.33806,W16:0.29720,W19:0.21780,W2:0.17779,W13:0.10905,W9:0.08041,W3:-0.37259,W5:-0.51285 | memoryGatesShort:10.925, Long:-11.726, Current:1.801 | topTokens[(',', 81), ('i', 53), ("'m", 18), ('the', 18), ('you', 17), ('to', 17), ('but', 16), ('not', 14), ('and', 14), ('a', 14)] | Training
2025-04-08 20:43:59 | 57500 | LR0.0003 | loss:4.4576 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-432.8069 | logitMax:-410.3821 | windowWeightsW25:0.70697,W21:0.36339,W16:0.30442,W19:0.23659,W2:0.18561,W13:0.10672,W9:0.06953,W3:-0.42541,W5:-0.57741 | memoryGatesShort:15.633, Long:-16.926, Current:2.293 | topTokens[(',', 31), ('.', 27), ('it', 26), ('s', 19), ('i', 18), ('that', 17), ('the', 17), ('a', 16), ('in', 13), ('to', 12)] | Training
2025-04-08 20:49:21 | 60000 | LR0.0003 | loss:4.0125 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-415.0494 | logitMax:-392.3961 | windowWeightsW25:0.73197,W21:0.37818,W16:0.29538,W19:0.23224,W2:0.19597,W13:0.10190,W9:0.06649,W3:-0.43325,W5:-0.59936 | memoryGatesShort:22.253, Long:-24.557, Current:3.304 | topTokens[(',', 95), ('i', 41), ('you', 25), ('the', 23), ('.', 22), ('and', 16), ('to', 15), ("'m", 15), ('my', 14), ('me', 12)] | Training
2025-04-08 20:54:33 | 62500 | LR0.0003 | loss:4.3784 | gradNorm:0.9997 | tokenCount:45000.0000 | logitMin:-427.0901 | logitMax:-404.3568 | windowWeightsW25:0.77185,W21:0.38358,W16:0.28926,W19:0.24041,W2:0.20426,W13:0.09314,W9:0.05673,W3:-0.44063,W5:-0.63021 | memoryGatesShort:18.488, Long:-19.710, Current:2.222 | topTokens[('.', 55), (',', 49), ('i', 37), ('the', 20), ('it', 15), ('?', 14), ('you', 13), ('he', 13), ('what', 12), ('!', 12)] | Training

--- 2025-04-08 21:11:38 --- babyLLM 'right, last time i got to step 63411... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 63411! what am i learning today?' - charis: ''
2025-04-08 21:16:44 | 2500 | LR0.0003 | loss:3.7090 | gradNorm:0.9766 | logitMin:-441.3597 | logitMax:-417.3076 | scheduledSampling:0.0000 | tokenCount:45000.0000 | windowWeightsW25:0.75323,W21:0.37462,W16:0.27546,W2:0.22310,W19:0.21526,W13:0.08896,W9:0.05429,W3:-0.40642,W5:-0.61012 | memoryGatesShort:13.184, Long:-14.490, Current:2.307 | topTokens[(',', 91), ('i', 37), ('to', 24), ('the', 22), ('you', 20), ('it', 19), ('ing', 19), ('on', 16), ('.', 15), ('and', 13)] | Training
2025-04-08 21:21:55 | 5000 | LR0.0003 | loss:4.2268 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-399.7223 | logitMax:-376.0340 | windowWeightsW25:0.78651,W21:0.39050,W16:0.28218,W2:0.22387,W19:0.22091,W13:0.09811,W9:0.05227,W3:-0.44008,W5:-0.64686 | memoryGatesShort:22.229, Long:-25.034, Current:3.805 | topTokens[('i', 37), (',', 31), ('.', 28), ('to', 25), ('and', 24), ('the', 20), ('s', 16), ('that', 15), ('you', 15), ('for', 14)] | Training
2025-04-08 21:27:06 | 7500 | LR0.0003 | loss:3.9697 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-404.3297 | logitMax:-380.9872 | windowWeightsW25:0.77700,W21:0.38040,W16:0.26927,W2:0.22723,W19:0.21077,W13:0.10409,W9:0.06415,W3:-0.42572,W5:-0.63959 | memoryGatesShort:12.524, Long:-13.630, Current:2.106 | topTokens[('the', 43), (',', 38), ('i', 30), ('to', 23), ('.', 22), ('and', 16), ('this', 14), ('a', 14), ('of', 12), ('in', 10)] | Training
2025-04-08 21:32:21 | 10000 | LR0.0003 | loss:3.7664 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-396.1234 | logitMax:-372.9273 | windowWeightsW25:0.76665,W21:0.37799,W16:0.28167,W2:0.23099,W19:0.20905,W13:0.10049,W9:0.04445,W3:-0.42362,W5:-0.61985 | memoryGatesShort:12.246, Long:-13.584, Current:2.337 | topTokens[(',', 30), ('would', 25), ('the', 23), ('.', 20), ('to', 19), ('!', 17), ('a', 13), ('i', 12), ('of', 12), ('in', 11)] | Training
2025-04-08 21:37:26 | 12500 | LR0.0003 | loss:2.0551 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-347.4250 | logitMax:-320.0988 | windowWeightsW25:0.72572,W21:0.37245,W16:0.28266,W2:0.24030,W19:0.20239,W13:0.11406,W9:0.04453,W3:-0.42324,W5:-0.59040 | memoryGatesShort:26.482, Long:-29.375, Current:3.893 | topTokens[('would', 112), ('!', 66), (',', 46), ('charis', 38), ('elodie', 37), ('the', 32), ('weed', 23), ('.', 23), ('you', 23), ('he', 22)] | Training
2025-04-08 21:42:29 | 15000 | LR0.0003 | loss:4.1103 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-432.7776 | logitMax:-410.7416 | windowWeightsW25:0.74901,W21:0.39457,W16:0.28726,W19:0.21617,W2:0.21533,W13:0.11982,W9:0.03796,W3:-0.44348,W5:-0.60818 | memoryGatesShort:11.781, Long:-12.296, Current:1.514 | topTokens[(',', 78), ('a', 29), ('the', 20), ('i', 20), ('of', 19), ('and', 17), ('.', 14), ('was', 14), ('it', 14), ('to', 11)] | Training
2025-04-08 21:47:33 | 17500 | LR0.0003 | loss:4.7407 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-451.7482 | logitMax:-430.2456 | windowWeightsW25:0.83979,W21:0.44463,W16:0.29498,W19:0.24204,W2:0.23184,W13:0.11711,W9:0.01130,W3:-0.51358,W5:-0.70264 | memoryGatesShort:15.686, Long:-16.829, Current:2.143 | topTokens[(',', 58), ('i', 45), ('to', 26), ('mom', 14), ('and', 13), ('it', 12), ('this', 11), ('in', 11), ('on', 10), ('im', 10)] | Training
2025-04-08 21:52:43 | 20000 | LR0.0003 | loss:4.0017 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-429.5250 | logitMax:-407.0289 | windowWeightsW25:0.89688,W21:0.46134,W16:0.29076,W2:0.25041,W19:0.24366,W13:0.12309,W9:0.00264,W3:-0.55431,W5:-0.75106 | memoryGatesShort:13.716, Long:-14.944, Current:2.228 | topTokens[(',', 62), ('i', 30), ('could', 24), ('the', 22), ('and', 19), ('!', 18), ('my', 18), ('to', 15), ('ner', 10), ('of', 10)] | Training
2025-04-08 21:57:46 | 22500 | LR0.0003 | loss:4.6024 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-436.6906 | logitMax:-415.2521 | windowWeightsW25:0.94002,W21:0.48516,W16:0.29566,W2:0.25570,W19:0.25215,W13:0.12355,W9:-0.00375,W3:-0.59141,W5:-0.79506 | memoryGatesShort:17.304, Long:-18.678, Current:2.374 | topTokens[('to', 40), ('i', 39), ('and', 28), (',', 26), ('.', 19), ('ing', 16), ('a', 16), ('her', 15), ('that', 14), (')', 14)] | Training
2025-04-08 22:02:49 | 25000 | LR0.0003 | loss:4.8697 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-438.8371 | logitMax:-417.5198 | windowWeightsW25:1.06337,W21:0.54136,W16:0.30408,W2:0.28151,W19:0.26097,W13:0.09580,W9:-0.03652,W3:-0.64772,W5:-0.90485 | memoryGatesShort:14.843, Long:-15.887, Current:2.043 | topTokens[('.', 76), ('i', 26), ('and', 22), ('to', 18), ('in', 14), ('u', 14), ('is', 13), ('a', 12), (',', 11), ('im', 11)] | Training
2025-04-08 22:07:59 | 27500 | LR0.0003 | loss:2.6302 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-370.3033 | logitMax:-343.3377 | windowWeightsW25:1.08288,W21:0.53806,W2:0.33751,W16:0.30491,W19:0.25468,W13:0.08413,W9:-0.05141,W3:-0.67158,W5:-0.92319 | memoryGatesShort:30.106, Long:-33.676, Current:4.571 | topTokens[('should', 93), ('.', 46), ('!', 44), ('charis', 30), (',', 28), ('elodie', 28), ('and', 27), ('the', 25), ('butt', 15), ('weed', 15)] | Training
2025-04-08 22:13:33 | 30000 | LR0.0003 | loss:2.8873 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-367.6768 | logitMax:-341.4535 | windowWeightsW25:1.07015,W21:0.52967,W2:0.34026,W16:0.30554,W19:0.25741,W13:0.09598,W9:-0.05037,W3:-0.68134,W5:-0.91108 | memoryGatesShort:17.464, Long:-18.787, Current:2.323 | topTokens[('should', 64), ('!', 54), (',', 44), ('.', 28), ('elodie', 27), ('the', 25), ('charis', 20), ('weed', 19), ('to', 19), ('a', 16)] | Training
2025-04-08 22:18:49 | 32500 | LR0.0003 | loss:3.4494 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-405.7156 | logitMax:-382.9696 | windowWeightsW25:0.88704,W21:0.46475,W16:0.29168,W2:0.27269,W19:0.24161,W13:0.11831,W9:-0.00051,W3:-0.57076,W5:-0.74179 | memoryGatesShort:12.280, Long:-12.999, Current:1.720 | topTokens[(',', 66), ('the', 31), ('i', 26), ('you', 26), ('!', 21), ('a', 17), ('it', 17), ('to', 15), ('s', 14), ('me', 14)] | Training
2025-04-08 22:24:05 | 35000 | LR0.0003 | loss:2.6542 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-461.0019 | logitMax:-438.3044 | windowWeightsW25:0.74562,W21:0.41647,W16:0.28600,W19:0.22743,W2:0.22392,W13:0.14287,W9:0.03896,W3:-0.48924,W5:-0.62411 | memoryGatesShort:12.338, Long:-13.283, Current:1.945 | topTokens[(',', 94), ('a', 29), ('and', 20), ('the', 17), ('.', 17), ('to', 15), ('s', 14), ('of', 14), ('i', 12), ('in', 10)] | Training
2025-04-08 22:29:20 | 37500 | LR0.0003 | loss:3.3501 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-494.1469 | logitMax:-470.6277 | windowWeightsW25:0.74647,W21:0.43097,W16:0.30433,W19:0.26066,W2:0.18964,W13:0.16377,W9:0.03527,W3:-0.51540,W5:-0.64729 | memoryGatesShort:10.270, Long:-10.955, Current:1.686 | topTokens[(',', 82), ('and', 23), ('of', 20), ('the', 18), ('.', 13), ('ed', 13), ('to', 13), ('a', 13), ('was', 12), ('that', 12)] | Training
2025-04-08 22:34:48 | 40000 | LR0.0003 | loss:4.6611 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-508.0315 | logitMax:-485.1843 | windowWeightsW25:0.87467,W21:0.47854,W16:0.32805,W19:0.28149,W2:0.20270,W13:0.15202,W9:0.00376,W3:-0.59613,W5:-0.76047 | memoryGatesShort:13.133, Long:-13.729, Current:1.597 | topTokens[('.', 54), ('i', 37), (',', 28), ('the', 21), ('?', 21), ('a', 20), ('you', 17), ('to', 16), ('we', 14), ('', 14)] | Training
2025-04-08 22:39:56 | 42500 | LR0.0003 | loss:4.8598 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-482.5761 | logitMax:-460.1527 | windowWeightsW25:1.00955,W21:0.52841,W16:0.32923,W19:0.28525,W2:0.24346,W13:0.12876,W9:-0.01825,W3:-0.67475,W5:-0.87164 | memoryGatesShort:13.943, Long:-14.626, Current:1.683 | topTokens[('.', 41), ('i', 36), (',', 32), ('to', 22), ('a', 16), ('the', 16), ('for', 11), ('ed', 11), ('so', 10), ('in', 9)] | Training
2025-04-08 22:45:01 | 45000 | LR0.0003 | loss:2.3371 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-458.4581 | logitMax:-434.0144 | windowWeightsW25:0.82958,W21:0.44905,W16:0.31548,W19:0.27309,W2:0.22627,W13:0.14624,W9:0.00789,W3:-0.56132,W5:-0.72085 | memoryGatesShort:9.247, Long:-10.055, Current:1.808 | topTokens[(',', 49), ('.', 23), ('the', 23), ('to', 20), ('of', 19), ('a', 19), ('and', 19), ('i', 14), ('was', 13), ('their', 13)] | Training
2025-04-08 22:50:07 | 47500 | LR0.0003 | loss:1.5493 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-371.8513 | logitMax:-341.1630 | windowWeightsW25:0.83790,W21:0.45371,W16:0.31786,W19:0.25836,W2:0.25223,W13:0.13054,W9:0.01807,W3:-0.55940,W5:-0.74478 | memoryGatesShort:15.436, Long:-16.770, Current:2.333 | topTokens[('had', 92), ('felt', 64), ('!', 45), (',', 41), ('.', 39), ('elodie', 29), ('the', 28), ('we', 20), ('and', 19), ('ked', 17)] | Training
2025-04-08 22:55:23 | 50000 | LR0.0003 | loss:1.2341 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-333.8475 | logitMax:-300.6543 | windowWeightsW25:0.81351,W21:0.44181,W16:0.32206,W2:0.27207,W19:0.23753,W13:0.13892,W9:0.03945,W3:-0.55706,W5:-0.74384 | memoryGatesShort:10.807, Long:-11.486, Current:1.678 | topTokens[('had', 108), ('felt', 62), ('.', 47), ('!', 45), (',', 31), ('charis', 25), ('elodie', 24), ('they', 21), ('it', 19), ('the', 19)] | Training
2025-04-08 23:00:39 | 52500 | LR0.0003 | loss:3.4951 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-475.7574 | logitMax:-450.0442 | windowWeightsW25:0.78955,W21:0.44519,W16:0.32610,W19:0.25914,W2:0.22514,W13:0.15905,W9:0.02742,W3:-0.55051,W5:-0.71472 | memoryGatesShort:15.537, Long:-15.785, Current:1.248 | topTokens[(',', 40), ('a', 39), ('i', 38), ('.', 35), ('the', 23), ('it', 17), ('to', 14), ('for', 14), ('!', 13), ('be', 12)] | Training
2025-04-08 23:05:55 | 55000 | LR0.0003 | loss:3.1648 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-483.4429 | logitMax:-458.5934 | windowWeightsW25:0.80409,W21:0.44700,W16:0.32259,W19:0.26541,W2:0.22286,W13:0.16749,W9:0.03524,W3:-0.56369,W5:-0.73496 | memoryGatesShort:11.612, Long:-12.378, Current:1.766 | topTokens[(',', 40), ('.', 32), ('the', 28), ('to', 23), ('s', 19), ('a', 15), ('ing', 14), ('of', 14), ('so', 13), ('i', 12)] | Training
2025-04-08 23:11:12 | 57500 | LR0.0003 | loss:1.4791 | gradNorm:0.9948 | tokenCount:45000.0000 | logitMin:-538.0880 | logitMax:-510.4622 | windowWeightsW25:0.74575,W21:0.40912,W16:0.31762,W19:0.24730,W2:0.22246,W13:0.18784,W9:0.06088,W3:-0.52715,W5:-0.69642 | memoryGatesShort:7.186, Long:-7.533, Current:1.347 | topTokens[(',', 59), ('the', 22), ('of', 20), ('.', 19), ('and', 18), ('a', 17), ('m', 15), ('ed', 14), ('was', 13), ('it', 11)] | Training
2025-04-08 23:16:33 | 60000 | LR0.0003 | loss:0.7649 | gradNorm:0.9952 | tokenCount:45000.0000 | logitMin:-631.7516 | logitMax:-597.0340 | windowWeightsW25:0.68940,W21:0.37494,W16:0.30772,W19:0.23660,W2:0.22535,W13:0.19846,W9:0.06716,W3:-0.47987,W5:-0.65091 | memoryGatesShort:8.162, Long:-8.302, Current:1.140 | topTokens[(',', 62), ('the', 21), ('a', 20), ('of', 16), ('m', 15), ('ed', 14), ('.', 13), ('it', 12), ('was', 12), ('that', 11)] | Training
2025-04-08 23:22:12 | 62500 | LR0.0003 | loss:5.4425 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-521.4415 | logitMax:-492.4375 | windowWeightsW25:0.83668,W21:0.43974,W16:0.32293,W19:0.26001,W2:0.24504,W13:0.19444,W9:0.02715,W3:-0.57749,W5:-0.78407 | memoryGatesShort:17.638, Long:-18.704, Current:2.066 | topTokens[(',', 103), ('i', 39), ('.', 21), ('u', 20), ('and', 17), ('to', 16), ('et', 16), ('m', 13), ('-', 12), ('the', 12)] | Training
2025-04-08 23:27:39 | 65000 | LR0.0003 | loss:3.0745 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-496.2537 | logitMax:-466.4031 | windowWeightsW25:0.90409,W21:0.44895,W16:0.33693,W19:0.27565,W2:0.26910,W13:0.20777,W9:0.01190,W3:-0.63360,W5:-0.85886 | memoryGatesShort:12.040, Long:-12.339, Current:1.299 | topTokens[('-', 45), (':', 45), ('7', 44), ('1', 40), ('i', 35), ('4', 29), ('charis', 24), ('le', 23), (',', 21), ('e', 20)] | Training
2025-04-08 23:33:13 | 67500 | LR0.0003 | loss:5.2402 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-474.5974 | logitMax:-450.6300 | windowWeightsW25:1.14702,W21:0.55709,W16:0.36264,W19:0.32183,W2:0.29565,W13:0.19071,W9:-0.04320,W3:-0.79711,W5:-1.07989 | memoryGatesShort:19.752, Long:-20.670, Current:1.917 | topTokens[('.', 93), ('i', 46), ('it', 21), ('a', 14), ('to', 13), ('and', 13), (',', 13), ('<', 13), ('l', 12), ('egg', 11)] | Training
2025-04-08 23:38:40 | 70000 | LR0.0003 | loss:3.4175 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-461.4192 | logitMax:-435.7000 | windowWeightsW25:0.97553,W21:0.48928,W16:0.32735,W19:0.28818,W2:0.26219,W13:0.18989,W9:-0.00490,W3:-0.66575,W5:-0.90129 | memoryGatesShort:11.349, Long:-11.657, Current:1.308 | topTokens[(',', 73), ('i', 36), ('the', 28), ('you', 25), ('.', 21), ('it', 17), ('but', 15), ('me', 15), ('to', 14), ('and', 13)] | Training
2025-04-08 23:43:55 | 72500 | LR0.0003 | loss:3.8324 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-456.9906 | logitMax:-432.2690 | windowWeightsW25:1.15951,W21:0.55979,W16:0.34706,W2:0.31780,W19:0.31081,W13:0.17851,W9:-0.01888,W3:-0.80554,W5:-1.09527 | memoryGatesShort:13.596, Long:-14.269, Current:1.674 | topTokens[('the', 50), (',', 48), ('egg', 23), ('.', 22), ('i', 21), ('a', 18), ('is', 14), ('in', 14), ('to', 13), ('er', 11)] | Training
2025-04-08 23:49:11 | 75000 | LR0.0003 | loss:3.9290 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-433.0147 | logitMax:-408.3647 | windowWeightsW25:1.24486,W21:0.58875,W2:0.35640,W16:0.34225,W19:0.32733,W13:0.15703,W9:-0.06110,W3:-0.83735,W5:-1.16754 | memoryGatesShort:10.728, Long:-11.308, Current:1.580 | topTokens[('the', 39), ('.', 36), ('to', 21), (',', 21), ('and', 20), ('in', 15), ('s', 15), ('i', 15), ('a', 14), ('id', 13)] | Training
2025-04-08 23:54:38 | 77500 | LR0.0003 | loss:4.2581 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-418.6705 | logitMax:-394.0940 | windowWeightsW25:1.16744,W21:0.56703,W2:0.34841,W16:0.33682,W19:0.31704,W13:0.16079,W9:-0.05805,W3:-0.79949,W5:-1.08695 | memoryGatesShort:16.099, Long:-16.810, Current:1.711 | topTokens[('.', 45), ('i', 41), ('?', 30), ('it', 22), (',', 19), ('to', 17), (':', 15), ('p', 15), (':', 15), ('2', 14)] | Training
2025-04-09 00:00:41 | 80000 | LR0.0003 | loss:2.5943 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-397.3865 | logitMax:-369.7243 | windowWeightsW25:0.99398,W21:0.49908,W16:0.34522,W2:0.33217,W19:0.29960,W13:0.17903,W9:-0.02541,W3:-0.71173,W5:-0.95376 | memoryGatesShort:14.372, Long:-14.563, Current:1.190 | topTokens[(':', 62), ('-', 50), ("'", 29), ("'", 29), ('.', 28), ('2', 25), ('-', 24), ('0', 23), ('5', 21), ('m', 17)] | Training
2025-04-09 00:06:10 | 82500 | LR0.0003 | loss:2.9436 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-425.0558 | logitMax:-399.8880 | windowWeightsW25:0.90458,W21:0.44627,W16:0.35208,W2:0.32714,W19:0.28694,W13:0.19338,W9:-0.00629,W3:-0.66278,W5:-0.88055 | memoryGatesShort:18.673, Long:-21.087, Current:3.413 | topTokens[(',', 32), (':', 29), ('look', 29), ('.', 23), ('to', 23), ('i', 21), ('2', 19), ('-', 19), ('you', 17), ("'", 17)] | Training
2025-04-09 00:11:46 | 85000 | LR0.0003 | loss:1.9208 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-402.5459 | logitMax:-375.0745 | windowWeightsW25:0.75520,W21:0.40352,W16:0.31574,W2:0.28035,W19:0.27615,W13:0.19124,W9:0.01859,W3:-0.54970,W5:-0.72498 | memoryGatesShort:23.329, Long:-25.956, Current:3.627 | topTokens[('will', 59), ('have', 55), (',', 49), ('.', 44), ('felt', 36), ('i', 25), ('!', 24), ('you', 20), ('charis', 18), ('the', 17)] | Training
2025-04-09 00:17:20 | 87500 | LR0.0003 | loss:1.5877 | gradNorm:0.9996 | tokenCount:45000.0000 | logitMin:-340.1369 | logitMax:-307.8983 | windowWeightsW25:0.74627,W21:0.39971,W16:0.29839,W19:0.28123,W2:0.27416,W13:0.19507,W9:0.01362,W3:-0.52662,W5:-0.71526 | memoryGatesShort:11.895, Long:-12.383, Current:1.489 | topTokens[('will', 96), ('have', 91), ('.', 57), ('felt', 52), ('!', 40), ('charis', 21), ('the', 21), ('elodie', 19), ('know', 18), ('kevin', 18)] | Training
2025-04-09 00:23:12 | 90000 | LR0.0003 | loss:4.5174 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-467.4231 | logitMax:-443.5242 | windowWeightsW25:0.80281,W21:0.43864,W16:0.30646,W19:0.30601,W2:0.25269,W13:0.19904,W9:-0.00761,W3:-0.56985,W5:-0.76256 | memoryGatesShort:13.598, Long:-13.552, Current:0.954 | topTokens[('i', 48), (',', 36), ('.', 24), ('it', 19), ('!', 19), ('and', 18), ('the', 17), ('a', 15), ('so', 14), ('was', 13)] | Training
2025-04-09 00:28:46 | 92500 | LR0.0003 | loss:2.9955 | gradNorm:0.9995 | tokenCount:45000.0000 | logitMin:-469.8320 | logitMax:-444.4811 | windowWeightsW25:0.74065,W21:0.41227,W19:0.28243,W16:0.28174,W2:0.23066,W13:0.19124,W9:0.00867,W3:-0.49841,W5:-0.68118 | memoryGatesShort:10.017, Long:-10.146, Current:1.128 | topTokens[(',', 58), ('i', 48), ('the', 31), ('to', 31), ('you', 16), ('it', 15), ('that', 15), ("'m", 12), ('of', 12), ('my', 12)] | Training
2025-04-09 00:34:16 | 95000 | LR0.0003 | loss:2.4690 | gradNorm:0.9978 | tokenCount:45000.0000 | logitMin:-475.9371 | logitMax:-449.2552 | windowWeightsW25:0.67981,W21:0.37485,W16:0.26928,W19:0.25530,W2:0.23826,W13:0.17492,W9:0.02977,W3:-0.44335,W5:-0.60910 | memoryGatesShort:9.336, Long:-10.248, Current:1.913 | topTokens[(',', 59), ('i', 31), ('the', 27), ('it', 22), ('you', 21), ('to', 16), ('so', 13), ('of', 12), ('that', 11), ('.', 10)] | Training
2025-04-09 00:39:39 | 97500 | LR0.0003 | loss:1.7159 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-534.3546 | logitMax:-507.5293 | windowWeightsW25:0.64496,W21:0.37000,W16:0.27828,W19:0.26236,W2:0.20489,W13:0.18799,W9:0.03611,W3:-0.43647,W5:-0.57666 | memoryGatesShort:6.251, Long:-6.216, Current:0.965 | topTokens[(',', 80), ('to', 26), ('the', 21), ('.', 20), ('and', 15), ('s', 15), ('a', 14), ('their', 13), ('was', 13), ('of', 12)] | Training
2025-04-09 00:45:10 | 100000 | LR0.0003 | loss:1.4764 | gradNorm:0.9989 | tokenCount:45000.0000 | logitMin:-590.7782 | logitMax:-560.4650 | windowWeightsW25:0.64705,W21:0.37539,W16:0.27737,W19:0.27203,W2:0.21207,W13:0.20846,W9:0.02527,W3:-0.44799,W5:-0.59863 | memoryGatesShort:12.678, Long:-14.279, Current:2.601 | topTokens[(',', 52), ('the', 39), ('a', 30), ('have', 22), ('would', 20), ('and', 16), ('ed', 15), ('.', 14), ('to', 13), ('of', 13)] | Training
2025-04-09 00:50:27 | 102500 | LR0.0003 | loss:1.2249 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-318.2338 | logitMax:-278.9212 | windowWeightsW25:0.68890,W21:0.38104,W19:0.27212,W16:0.27046,W2:0.23919,W13:0.20437,W9:0.01989,W3:-0.47149,W5:-0.63512 | memoryGatesShort:16.791, Long:-18.299, Current:2.508 | topTokens[('have', 121), ('would', 90), ('felt', 78), (',', 52), ('!', 43), ('charis', 35), ('must', 35), ('kevin', 28), ('elodie', 25), ('the', 20)] | Training
2025-04-09 00:55:45 | 105000 | LR0.0003 | loss:2.9574 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-368.1201 | logitMax:-332.9792 | windowWeightsW25:0.72502,W21:0.38498,W19:0.27872,W16:0.26571,W2:0.22557,W13:0.21941,W9:0.02090,W3:-0.49308,W5:-0.65840 | memoryGatesShort:22.715, Long:-22.992, Current:1.277 | topTokens[('must', 60), ('have', 58), ('.', 53), (',', 51), ('i', 36), ('felt', 35), ('!', 34), ('elodie', 20), ('charis', 19), ('the', 18)] | Training
2025-04-09 01:00:56 | 107500 | LR0.0003 | loss:4.2045 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-437.2011 | logitMax:-410.9658 | windowWeightsW25:0.80234,W21:0.42331,W19:0.29828,W2:0.26005,W16:0.25338,W13:0.18506,W9:-0.01551,W3:-0.50860,W5:-0.73199 | memoryGatesShort:12.009, Long:-12.458, Current:1.449 | topTokens[('?', 65), ('.', 60), ('you', 47), ('i', 34), ('is', 33), ('to', 27), ('do', 24), ('not', 18), ('pete', 16), ('with', 13)] | Training
2025-04-09 01:06:14 | 110000 | LR0.0003 | loss:4.7401 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-448.3357 | logitMax:-423.8415 | windowWeightsW25:0.86884,W21:0.44901,W19:0.31204,W2:0.25106,W16:0.24726,W13:0.17692,W9:-0.03515,W3:-0.53114,W5:-0.77391 | memoryGatesShort:13.011, Long:-13.735, Current:1.723 | topTokens[('you', 46), ('.', 39), (',', 25), ('the', 23), ('!', 22), ('your', 16), ('i', 16), ('is', 13), ('to', 12), ('equ', 12)] | Training
2025-04-09 01:11:35 | 112500 | LR0.0003 | loss:3.7131 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-403.1771 | logitMax:-375.2685 | windowWeightsW25:0.86980,W21:0.45432,W19:0.30895,W2:0.28433,W16:0.24028,W13:0.19052,W9:-0.04028,W3:-0.54560,W5:-0.79842 | memoryGatesShort:11.821, Long:-12.084, Current:1.263 | topTokens[(':', 47), ('-', 29), ("'", 25), ("'", 21), ('0', 21), ('as', 21), ('4', 19), (',', 18), ('2', 18), ('m', 17)] | Training
2025-04-09 01:16:55 | 115000 | LR0.0003 | loss:2.1952 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-447.8777 | logitMax:-422.0349 | windowWeightsW25:0.72303,W21:0.39481,W19:0.27156,W16:0.23645,W2:0.23296,W13:0.20060,W9:0.00803,W3:-0.45132,W5:-0.64701 | memoryGatesShort:7.374, Long:-7.779, Current:1.405 | topTokens[(',', 51), ('.', 28), ('?', 21), ('the', 21), ('a', 18), ('of', 18), ('!', 17), ('and', 15), ('to', 11), ('s', 11)] | Training
2025-04-09 01:22:19 | 117500 | LR0.0003 | loss:0.7371 | gradNorm:0.9772 | tokenCount:45000.0000 | logitMin:-580.9328 | logitMax:-548.0329 | windowWeightsW25:0.68121,W21:0.38275,W19:0.25466,W2:0.23647,W16:0.23298,W13:0.20722,W9:0.03101,W3:-0.43918,W5:-0.61707 | memoryGatesShort:5.433, Long:-5.407, Current:0.974 | topTokens[(',', 75), ('the', 32), ('.', 25), ('of', 23), ('a', 21), ('their', 18), ('it', 16), ('and', 16), ('ed', 12), ('was', 12)] | Training
2025-04-09 01:27:48 | 120000 | LR0.0003 | loss:2.7185 | gradNorm:0.9993 | tokenCount:45000.0000 | logitMin:-613.9122 | logitMax:-581.1450 | windowWeightsW25:0.70364,W21:0.39711,W19:0.26695,W16:0.25017,W2:0.21589,W13:0.20966,W9:0.02042,W3:-0.45457,W5:-0.63936 | memoryGatesShort:7.034, Long:-6.761, Current:0.727 | topTokens[(',', 80), ('.', 29), ('and', 21), ('a', 21), ('ed', 19), ('i', 19), ('was', 17), ('the', 16), ('in', 15), ('of', 11)] | Training
2025-04-09 01:33:20 | 122500 | LR0.0003 | loss:4.7400 | gradNorm:0.9945 | tokenCount:45000.0000 | logitMin:-556.1484 | logitMax:-528.1780 | windowWeightsW25:0.75999,W21:0.43565,W19:0.27601,W16:0.24651,W2:0.23274,W13:0.19540,W9:-0.01219,W3:-0.47503,W5:-0.69078 | memoryGatesShort:8.318, Long:-8.922, Current:1.604 | topTokens[('.', 91), ('i', 27), ('and', 21), ('that', 17), ('the', 15), ('it', 15), ('on', 15), ('we', 14), ('y', 13), ('my', 12)] | Training
2025-04-09 01:39:02 | 125000 | LR0.0003 | loss:4.8144 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-488.5457 | logitMax:-462.5146 | windowWeightsW25:0.89517,W21:0.50541,W19:0.32153,W2:0.26297,W16:0.25428,W13:0.18623,W9:-0.05727,W3:-0.57215,W5:-0.83248 | memoryGatesShort:12.838, Long:-14.229, Current:2.391 | topTokens[('.', 97), ('i', 39), ('and', 23), ('is', 17), ('a', 16), ('omg', 15), (',', 15), ('that', 13), ('kevin', 12), ('ing', 12)] | Training
2025-04-09 01:44:37 | 127500 | LR0.0003 | loss:1.8896 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-388.8250 | logitMax:-358.4730 | windowWeightsW25:0.94988,W21:0.50623,W19:0.31965,W2:0.30580,W16:0.24341,W13:0.17250,W9:-0.06335,W3:-0.58458,W5:-0.88810 | memoryGatesShort:13.833, Long:-15.187, Current:2.355 | topTokens[('is', 64), ('are', 49), ('charis', 47), ('.', 41), ('ing', 38), ('!', 37), (',', 37), ('the', 27), ('you', 21), ('kevin', 19)] | Training
2025-04-09 01:50:03 | 130000 | LR0.0003 | loss:4.8155 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-447.1552 | logitMax:-422.3072 | windowWeightsW25:1.10388,W21:0.56686,W19:0.34681,W2:0.32670,W16:0.24089,W13:0.15440,W9:-0.09481,W3:-0.65991,W5:-1.02795 | memoryGatesShort:16.480, Long:-17.353, Current:1.873 | topTokens[('.', 82), ('i', 31), ('is', 25), (',', 22), ('it', 18), ('and', 17), ('you', 16), ('!', 14), ('xd', 13), ('me', 10)] | Training
2025-04-09 01:55:25 | 132500 | LR0.0003 | loss:4.6744 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-456.2176 | logitMax:-432.4373 | windowWeightsW25:1.15025,W21:0.57688,W2:0.35956,W19:0.33995,W16:0.23101,W13:0.16838,W9:-0.10820,W3:-0.68682,W5:-1.07628 | memoryGatesShort:13.105, Long:-14.788, Current:2.683 | topTokens[(',', 53), ('.', 43), ('i', 32), ('?', 24), ('you', 22), ('and', 21), ('!', 15), ('it', 14), ('stu', 13), (':(', 13)] | Training
2025-04-09 02:00:46 | 135000 | LR0.0003 | loss:3.5970 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-465.6260 | logitMax:-440.5719 | windowWeightsW25:1.10030,W21:0.55713,W19:0.33295,W2:0.31413,W16:0.26513,W13:0.19785,W9:-0.10553,W3:-0.68014,W5:-1.02465 | memoryGatesShort:9.619, Long:-10.196, Current:1.577 | topTokens[(',', 56), ('.', 35), ('the', 25), ('a', 19), ('to', 18), ('and', 15), ('of', 14), ('ed', 12), ('m', 10), ('in', 10)] | Training
2025-04-09 02:06:08 | 137500 | LR0.0003 | loss:3.2248 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-453.3553 | logitMax:-427.7103 | windowWeightsW25:0.95101,W21:0.49119,W19:0.32186,W2:0.28799,W16:0.25982,W13:0.20443,W9:-0.05993,W3:-0.59656,W5:-0.89807 | memoryGatesShort:11.440, Long:-12.852, Current:2.412 | topTokens[('the', 30), (',', 25), ('in', 21), ('of', 19), ('d', 18), ('s', 17), ('and', 17), ('.', 16), ('to', 12), ('is', 11)] | Training
2025-04-09 02:11:37 | 140000 | LR0.0003 | loss:1.8220 | gradNorm:0.9996 | tokenCount:45000.0000 | logitMin:-523.7554 | logitMax:-494.7544 | windowWeightsW25:0.78763,W21:0.43755,W19:0.31158,W16:0.28108,W2:0.23161,W13:0.22388,W9:-0.02378,W3:-0.51971,W5:-0.76278 | memoryGatesShort:113.155, Long:-121.977, Current:9.822 | topTokens[(',', 63), ('a', 25), ('the', 23), ('to', 21), ('and', 20), ('.', 17), ('of', 17), ('ed', 12), ('m', 12), ('s', 12)] | Training
2025-04-09 02:16:59 | 142500 | LR0.0003 | loss:5.5091 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-454.8551 | logitMax:-429.2722 | windowWeightsW25:0.96251,W21:0.50706,W19:0.34898,W16:0.28859,W2:0.25524,W13:0.23008,W9:-0.06127,W3:-0.63899,W5:-0.93044 | memoryGatesShort:16.724, Long:-17.870, Current:2.147 | topTokens[(',', 117), ('i', 42), ('y', 23), ('a', 16), ('im', 16), ('the', 15), ('and', 15), ('u', 14), ('me', 12), ('it', 11)] | Training
2025-04-09 02:22:23 | 145000 | LR0.0003 | loss:5.0577 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-448.3793 | logitMax:-423.7611 | windowWeightsW25:1.18865,W21:0.60823,W19:0.39607,W2:0.30434,W16:0.30186,W13:0.21536,W9:-0.13190,W3:-0.76861,W5:-1.15984 | memoryGatesShort:10.000, Long:-10.564, Current:1.565 | topTokens[(',', 121), ('i', 38), ('a', 21), ('boomboomraccoon', 16), ('me', 15), ('to', 12), ('is', 12), ('love', 11), ('it', 10), ('he', 10)] | Training
2025-04-09 02:27:46 | 147500 | LR0.0003 | loss:4.9644 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-459.7183 | logitMax:-436.0088 | windowWeightsW25:1.44881,W21:0.72031,W19:0.44240,W2:0.36406,W16:0.32658,W13:0.21918,W9:-0.19720,W3:-0.94009,W5:-1.43883 | memoryGatesShort:14.652, Long:-15.799, Current:2.147 | topTokens[('.', 33), (',', 28), ('to', 23), ('i', 19), ('it', 17), ('a', 17), ('the', 13), ("'s", 13), ('you', 11), ('^', 11)] | Training
2025-04-09 02:33:16 | 150000 | LR0.0003 | loss:5.0078 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-462.3638 | logitMax:-439.5372 | windowWeightsW25:1.65907,W21:0.77438,W19:0.47349,W2:0.44129,W16:0.34724,W13:0.21366,W9:-0.24878,W3:-1.06919,W5:-1.65358 | memoryGatesShort:15.022, Long:-16.147, Current:2.126 | topTokens[('.', 72), ('i', 39), (',', 19), ('a', 18), ('?', 16), ('it', 14), ('!', 13), ("'s", 12), ('that', 11), ('you', 11)] | Training
2025-04-09 02:38:35 | 152500 | LR0.0003 | loss:4.4744 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-448.1517 | logitMax:-424.6616 | windowWeightsW25:1.56026,W21:0.72770,W19:0.44065,W2:0.42505,W16:0.37255,W13:0.24316,W9:-0.21825,W3:-1.02362,W5:-1.58693 | memoryGatesShort:15.232, Long:-16.644, Current:2.411 | topTokens[('.', 52), ('i', 34), ('a', 21), (',', 21), ('it', 16), ('you', 15), ('and', 14), ('!', 13), ("'s", 13), ('just', 10)] | Training
2025-04-09 02:43:55 | 155000 | LR0.0003 | loss:4.9540 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-457.1871 | logitMax:-434.5772 | windowWeightsW25:1.73383,W21:0.76508,W19:0.48042,W2:0.47762,W16:0.42814,W13:0.25810,W9:-0.27967,W3:-1.14730,W5:-1.78201 | memoryGatesShort:17.836, Long:-19.827, Current:2.991 | topTokens[(',', 83), ('i', 25), ('it', 16), ('a', 15), ('he', 13), ('is', 12), ('the', 11), ('im', 11), ('.', 9), ('so', 8)] | Training
2025-04-09 02:49:16 | 157500 | LR0.0003 | loss:4.1059 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-414.3233 | logitMax:-390.4374 | windowWeightsW25:1.43725,W21:0.65092,W2:0.42779,W19:0.40588,W16:0.37279,W13:0.21454,W9:-0.17047,W3:-0.94223,W5:-1.45254 | memoryGatesShort:11.640, Long:-13.124, Current:2.484 | topTokens[('i', 41), (',', 39), ('.', 27), ('to', 21), ('?', 21), ('you', 19), ('the', 18), ('was', 16), ('!', 15), ('a', 12)] | Training
2025-04-09 02:54:45 | 160000 | LR0.0003 | loss:2.0962 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-425.2517 | logitMax:-399.2507 | windowWeightsW25:0.99419,W21:0.49212,W19:0.34060,W16:0.33560,W2:0.29292,W13:0.22031,W9:-0.05797,W3:-0.66327,W5:-0.99504 | memoryGatesShort:8.792, Long:-9.797, Current:2.005 | topTokens[(',', 62), ('!', 38), ('a', 30), ('the', 26), ('.', 22), ('you', 18), ('they', 16), ('ed', 15), ('it', 13), ('to', 13)] | Training
2025-04-09 03:00:06 | 162500 | LR0.0003 | loss:4.2374 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-482.6987 | logitMax:-456.8988 | windowWeightsW25:1.10991,W21:0.53642,W16:0.36455,W19:0.35072,W2:0.29152,W13:0.22823,W9:-0.08044,W3:-0.74664,W5:-1.09804 | memoryGatesShort:12.047, Long:-12.746, Current:1.699 | topTokens[(',', 88), ('i', 26), ('make', 24), ('a', 21), ('.', 19), ('the', 19), ('to', 18), ('d', 18), ('body', 18), ('a', 14)] | Training
2025-04-09 03:05:28 | 165000 | LR0.0003 | loss:2.3649 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-436.2308 | logitMax:-406.5248 | windowWeightsW25:0.94379,W21:0.45635,W16:0.34150,W2:0.30834,W19:0.29465,W13:0.24432,W9:-0.03379,W3:-0.64416,W5:-0.95067 | memoryGatesShort:10.565, Long:-11.287, Current:1.722 | topTokens[(':', 44), ("'", 39), (',', 38), ('i', 37), ('-', 37), ('m', 30), ('ll', 25), ("'", 23), ('0', 23), ('baby', 23)] | Training
2025-04-09 03:10:49 | 167500 | LR0.0003 | loss:3.6126 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-465.0240 | logitMax:-439.0888 | windowWeightsW25:0.95797,W21:0.46232,W16:0.35937,W19:0.31245,W2:0.28629,W13:0.25192,W9:-0.04987,W3:-0.65906,W5:-0.96090 | memoryGatesShort:10.596, Long:-11.101, Current:1.505 | topTokens[('to', 33), ("'", 31), ('i', 31), ('-', 30), ('.', 25), (',', 23), ("'", 18), (':', 17), ('0', 11), ('charis', 10)] | Training
2025-04-09 03:16:20 | 170000 | LR0.0003 | loss:4.4090 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-465.0765 | logitMax:-441.3960 | windowWeightsW25:1.10866,W21:0.51848,W16:0.37768,W19:0.36200,W2:0.30923,W13:0.24176,W9:-0.09344,W3:-0.75009,W5:-1.11853 | memoryGatesShort:11.258, Long:-12.128, Current:1.869 | topTokens[('.', 45), ('i', 36), (',', 35), ('to', 32), ('s', 20), ('and', 19), ('a', 18), ('it', 14), ('the', 13), ('of', 12)] | Training
2025-04-09 03:21:41 | 172500 | LR0.0003 | loss:1.3146 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-399.6135 | logitMax:-367.4594 | windowWeightsW25:0.92403,W21:0.42936,W16:0.38243,W2:0.30764,W19:0.29493,W13:0.25866,W9:-0.02802,W3:-0.65989,W5:-0.94842 | memoryGatesShort:10.756, Long:-11.550, Current:1.794 | topTokens[(':', 64), ('-', 53), ('0', 51), ('5', 37), ("'", 30), ("'", 30), ('-', 30), ('2', 29), ('4', 28), ('i', 27)] | Training
2025-04-09 03:27:02 | 175000 | LR0.0003 | loss:3.1847 | gradNorm:0.9997 | tokenCount:45000.0000 | logitMin:-450.4570 | logitMax:-422.6978 | windowWeightsW25:0.92586,W21:0.44247,W16:0.38167,W19:0.30207,W2:0.29556,W13:0.25634,W9:-0.03451,W3:-0.66746,W5:-0.94092 | memoryGatesShort:11.207, Long:-11.441, Current:1.234 | topTokens[("'", 28), ('-', 27), ('-', 26), ('0', 25), (':', 20), (',', 19), ('the', 19), ('4', 18), ('a', 18), ('!', 17)] | Training
2025-04-09 03:32:22 | 177500 | LR0.0003 | loss:4.2383 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-465.5202 | logitMax:-442.1087 | windowWeightsW25:0.92794,W21:0.46713,W16:0.38664,W19:0.32118,W2:0.27411,W13:0.23679,W9:-0.05347,W3:-0.66919,W5:-0.92952 | memoryGatesShort:9.868, Long:-10.501, Current:1.633 | topTokens[('.', 40), ('i', 39), ('the', 26), (',', 21), ('to', 20), ('a', 16), ('this', 15), ('ing', 15), ('my', 15), ('s', 12)] | Training
2025-04-09 03:37:52 | 180000 | LR0.0003 | loss:3.7752 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-455.7284 | logitMax:-430.8915 | windowWeightsW25:0.86362,W21:0.45912,W16:0.37813,W19:0.30471,W13:0.25332,W2:0.22254,W9:-0.02064,W3:-0.64189,W5:-0.85459 | memoryGatesShort:14.039, Long:-15.131, Current:2.092 | topTokens[('i', 55), (',', 47), ('.', 27), ('to', 23), ('it', 19), ('the', 18), ('a', 13), ('s', 12), ('ed', 10), ('up', 10)] | Training
2025-04-09 03:43:11 | 182500 | LR0.0003 | loss:4.9713 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-481.8066 | logitMax:-459.1168 | windowWeightsW25:0.96395,W21:0.50166,W16:0.38882,W19:0.32278,W13:0.25151,W2:0.24061,W9:-0.05263,W3:-0.70754,W5:-0.94798 | memoryGatesShort:10.984, Long:-11.786, Current:1.801 | topTokens[(',', 65), ('i', 44), ('the', 24), ('it', 22), ('and', 22), ('but', 14), ('that', 13), ('to', 13), ('a', 13), ('im', 12)] | Training
2025-04-09 03:48:26 | 185000 | LR0.0003 | loss:4.8218 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-476.0978 | logitMax:-452.8546 | windowWeightsW25:1.09055,W21:0.53899,W16:0.39218,W19:0.32727,W2:0.29086,W13:0.25552,W9:-0.08835,W3:-0.78510,W5:-1.06530 | memoryGatesShort:14.312, Long:-15.883, Current:2.572 | topTokens[('i', 52), ('.', 33), ('the', 25), (',', 20), ('ed', 14), ('just', 14), ('you', 13), ('and', 13), ('it', 12), ('but', 12)] | Training
2025-04-09 03:53:34 | 187500 | LR0.0003 | loss:3.6017 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-433.0623 | logitMax:-408.3459 | windowWeightsW25:1.08249,W21:0.51610,W16:0.35605,W2:0.31568,W19:0.29246,W13:0.29206,W9:-0.07293,W3:-0.77946,W5:-1.04606 | memoryGatesShort:25.644, Long:-28.230, Current:3.586 | topTokens[('.', 43), ('i', 39), ('to', 37), ('?', 35), (',', 31), ('music', 29), ('what', 26), ('he', 18), ('was', 15), ('you', 15)] | Training
2025-04-09 03:58:51 | 190000 | LR0.0003 | loss:2.8990 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-427.8650 | logitMax:-402.7310 | windowWeightsW25:0.99105,W21:0.44315,W13:0.33139,W2:0.31876,W16:0.29417,W19:0.22107,W9:-0.07710,W3:-0.65138,W5:-0.91177 | memoryGatesShort:11.874, Long:-13.008, Current:2.134 | topTokens[('.', 59), ('?', 50), ('to', 45), ('i', 43), ('you', 42), (',', 38), ('do', 22), ('a', 20), ('want', 19), ('about', 19)] | Training
2025-04-09 04:04:04 | 192500 | LR0.0003 | loss:4.1278 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-423.2159 | logitMax:-399.2371 | windowWeightsW25:1.01898,W21:0.45552,W13:0.31862,W2:0.31756,W16:0.28988,W19:0.22999,W9:-0.08525,W3:-0.66685,W5:-0.91975 | memoryGatesShort:16.267, Long:-17.602, Current:2.335 | topTokens[(',', 53), ('to', 35), ('the', 26), ('!', 26), ('i', 26), ('a', 26), ('it', 21), ('.', 17), ('we', 14), ('ed', 12)] | Training
2025-04-09 04:09:37 | 195000 | LR0.0003 | loss:3.4591 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-442.8729 | logitMax:-419.4764 | windowWeightsW25:0.89371,W21:0.43581,W13:0.30599,W16:0.28843,W2:0.25922,W19:0.23100,W9:-0.05201,W3:-0.60075,W5:-0.79803 | memoryGatesShort:14.301, Long:-15.549, Current:2.248 | topTokens[('the', 29), ('i', 27), ('it', 27), (',', 26), ('france', 23), ('.', 17), ('a', 16), ('and', 15), ('to', 14), ('my', 10)] | Training
2025-04-09 04:15:15 | 197500 | LR0.0003 | loss:2.8859 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-450.4794 | logitMax:-425.4695 | windowWeightsW25:0.79119,W21:0.41048,W13:0.28161,W16:0.26819,W2:0.23531,W19:0.22097,W9:-0.02484,W3:-0.52751,W5:-0.68858 | memoryGatesShort:8.027, Long:-8.651, Current:1.624 | topTokens[('.', 37), ('should', 32), ('have', 30), (',', 24), ('i', 20), ('felt', 19), ('s', 18), ('the', 17), ('!', 15), ('of', 13)] | Training
2025-04-09 04:20:37 | 200000 | LR0.0003 | loss:1.9094 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-555.9531 | logitMax:-529.8987 | windowWeightsW25:0.70307,W21:0.39392,W13:0.29826,W16:0.28153,W19:0.23862,W2:0.17987,W9:0.00421,W3:-0.49551,W5:-0.63387 | memoryGatesShort:7.035, Long:-7.174, Current:1.139 | topTokens[(',', 71), ('a', 24), ('the', 24), ('ed', 19), ('to', 16), ('and', 16), ('of', 15), ('was', 14), ('that', 13), ('their', 12)] | Training
2025-04-09 04:25:56 | 202500 | LR0.0003 | loss:2.2766 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-539.8030 | logitMax:-510.4435 | windowWeightsW25:0.70982,W21:0.39065,W13:0.28863,W16:0.27232,W19:0.22664,W2:0.21683,W9:0.00137,W3:-0.48346,W5:-0.65369 | memoryGatesShort:14.535, Long:-16.456, Current:2.921 | topTokens[(',', 49), ('to', 39), ('.', 29), ('?', 24), ('the', 20), ('and', 18), ('listening', 17), ('a', 16), ('you', 15), ('music', 14)] | Training
2025-04-09 04:31:09 | 205000 | LR0.0003 | loss:3.3194 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-508.3918 | logitMax:-479.2946 | windowWeightsW25:0.77784,W21:0.42192,W16:0.27721,W13:0.27704,W19:0.23921,W2:0.22502,W9:-0.02446,W3:-0.51432,W5:-0.71227 | memoryGatesShort:13.322, Long:-14.122, Current:1.800 | topTokens[('to', 40), ('.', 30), ('music', 25), ('?', 17), ('a', 16), ('the', 16), ('listening', 15), (',', 14), ('what', 14), ('of', 14)] | Training
2025-04-09 04:36:52 | 207500 | LR0.0003 | loss:4.0423 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-495.6643 | logitMax:-469.4402 | windowWeightsW25:0.82791,W21:0.45023,W16:0.27224,W13:0.27149,W19:0.25672,W2:0.22466,W9:-0.04725,W3:-0.53873,W5:-0.75135 | memoryGatesShort:12.455, Long:-13.307, Current:1.852 | topTokens[('.', 48), (',', 35), ('i', 32), ('to', 26), ('and', 23), ('a', 22), ('the', 18), ('ar', 14), ('that', 14), ('you', 13)] | Training
2025-04-09 04:42:40 | 210000 | LR0.0003 | loss:3.6906 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-464.7135 | logitMax:-438.5770 | windowWeightsW25:0.88487,W21:0.46554,W19:0.27466,W16:0.27391,W13:0.26302,W2:0.23880,W9:-0.06003,W3:-0.56741,W5:-0.80924 | memoryGatesShort:12.543, Long:-13.744, Current:2.200 | topTokens[('.', 28), (',', 26), ('i', 25), ('to', 23), ('the', 18), ('a', 13), ('in', 11), ('and', 11), ('-', 10), ('you', 9)] | Training
2025-04-09 04:48:02 | 212500 | LR0.0003 | loss:2.4149 | gradNorm:0.9997 | tokenCount:45000.0000 | logitMin:-400.6867 | logitMax:-370.1099 | windowWeightsW25:0.92979,W21:0.48951,W19:0.28059,W2:0.27100,W16:0.26897,W13:0.25126,W9:-0.10068,W3:-0.58275,W5:-0.84560 | memoryGatesShort:21.446, Long:-24.112, Current:3.666 | topTokens[('have', 77), ('could', 69), ('felt', 36), (',', 35), ('!', 30), ('.', 28), ('i', 21), ('elodie', 18), ('you', 16), ('charis', 16)] | Training
2025-04-09 04:53:25 | 215000 | LR0.0003 | loss:1.7977 | gradNorm:0.9995 | tokenCount:45000.0000 | logitMin:-338.4015 | logitMax:-304.2889 | windowWeightsW25:0.92013,W21:0.48763,W19:0.27905,W2:0.27080,W13:0.26890,W16:0.26116,W9:-0.09256,W3:-0.57701,W5:-0.85591 | memoryGatesShort:11.699, Long:-11.848, Current:1.149 | topTokens[('could', 106), ('have', 99), ('felt', 54), (',', 51), ('!', 49), ('charis', 31), ('.', 22), ('she', 19), ('elodie', 18), ('you', 17)] | Training
2025-04-09 04:58:47 | 217500 | LR0.0003 | loss:3.8275 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-413.1659 | logitMax:-387.9305 | windowWeightsW25:0.89838,W21:0.48140,W19:0.27636,W13:0.26566,W16:0.25221,W2:0.24853,W9:-0.07814,W3:-0.56745,W5:-0.81356 | memoryGatesShort:13.793, Long:-14.212, Current:1.419 | topTokens[(',', 78), ('i', 32), ('you', 32), ('the', 25), ('to', 19), ('s', 17), ("'m", 16), ('and', 13), ('a', 12), ('like', 12)] | Training
2025-04-09 05:04:20 | 220000 | LR0.0003 | loss:4.3215 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-448.3319 | logitMax:-424.0147 | windowWeightsW25:1.02791,W21:0.54042,W19:0.29636,W2:0.29266,W13:0.26593,W16:0.25658,W9:-0.11271,W3:-0.64691,W5:-0.96160 | memoryGatesShort:12.217, Long:-13.219, Current:2.002 | topTokens[(',', 60), ('i', 30), ('the', 23), ('you', 22), ('to', 21), ('it', 21), ('my', 18), ('.', 17), ('s', 16), ('me', 14)] | Training
2025-04-09 05:09:41 | 222500 | LR0.0003 | loss:1.5832 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-484.3135 | logitMax:-457.6820 | windowWeightsW25:0.84731,W21:0.47791,W13:0.27431,W19:0.27042,W16:0.26507,W2:0.25323,W9:-0.05614,W3:-0.56112,W5:-0.80674 | memoryGatesShort:14.318, Long:-15.856, Current:2.539 | topTokens[(',', 56), ('.', 34), ('the', 25), ('was', 24), ('were', 23), ('of', 17), ('and', 15), ('ing', 15), ('to', 13), ('ed', 12)] | Training
2025-04-09 05:15:03 | 225000 | LR0.0003 | loss:1.9754 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-389.7318 | logitMax:-359.0973 | windowWeightsW25:0.89676,W21:0.48744,W13:0.28077,W2:0.27003,W19:0.26532,W16:0.25586,W9:-0.07634,W3:-0.58150,W5:-0.83571 | memoryGatesShort:13.541, Long:-14.073, Current:1.532 | topTokens[('were', 64), ('.', 64), ('was', 49), ('ing', 41), ('the', 36), (',', 36), ('charis', 33), ('elodie', 30), ('!', 27), ('kevin', 19)] | Training
2025-04-09 05:20:24 | 227500 | LR0.0003 | loss:2.6888 | gradNorm:0.9985 | tokenCount:45000.0000 | logitMin:-502.3777 | logitMax:-474.8947 | windowWeightsW25:0.78664,W21:0.43846,W13:0.27425,W2:0.25704,W19:0.24012,W16:0.23635,W9:-0.04773,W3:-0.49372,W5:-0.72531 | memoryGatesShort:11.684, Long:-12.818, Current:2.133 | topTokens[(',', 51), ('i', 41), ('.', 33), ('a', 27), ('you', 16), ('it', 16), ('u', 15), ('if', 14), ('tou', 14), ('my', 12)] | Training
2025-04-09 05:25:52 | 230000 | LR0.0003 | loss:3.4925 | gradNorm:0.9893 | tokenCount:45000.0000 | logitMin:-520.7260 | logitMax:-491.5258 | windowWeightsW25:0.79573,W21:0.44051,W13:0.27826,W2:0.25134,W16:0.23375,W19:0.23223,W9:-0.05098,W3:-0.49500,W5:-0.71973 | memoryGatesShort:14.913, Long:-14.636, Current:0.723 | topTokens[(',', 128), ('i', 35), ('.', 19), ('you', 17), ('and', 15), ('a', 15), ('we', 13), ('d', 13), ('u', 12), ('he', 11)] | Training
2025-04-09 05:31:17 | 232500 | LR0.0003 | loss:5.2148 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-467.1393 | logitMax:-443.1383 | windowWeightsW25:0.94196,W21:0.52475,W13:0.27290,W2:0.27108,W19:0.26635,W16:0.23227,W9:-0.09475,W3:-0.59778,W5:-0.85530 | memoryGatesShort:12.574, Long:-12.913, Current:1.339 | topTokens[(',', 119), ('i', 26), ('e', 16), ('it', 16), ('what', 13), ('boomboomraccoon', 11), ('to', 11), ('the', 11), ('p', 11), ('and', 9)] | Training
2025-04-09 05:36:39 | 235000 | LR0.0003 | loss:4.8156 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-462.5167 | logitMax:-438.9665 | windowWeightsW25:1.17832,W21:0.61587,W2:0.31480,W19:0.31012,W13:0.29447,W16:0.26044,W9:-0.17147,W3:-0.75434,W5:-1.09451 | memoryGatesShort:13.845, Long:-14.431, Current:1.586 | topTokens[('i', 66), ('.', 59), (',', 48), ('to', 20), ("'m", 20), ('a', 17), ('you', 15), ('that', 13), ('x', 12), ('?', 11)] | Training
2025-04-09 05:41:50 | 237500 | LR0.0003 | loss:4.5522 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-428.8397 | logitMax:-404.6903 | windowWeightsW25:1.20914,W21:0.61298,W2:0.34295,W13:0.29654,W19:0.28655,W16:0.27154,W9:-0.18729,W3:-0.76670,W5:-1.11348 | memoryGatesShort:17.038, Long:-18.617, Current:2.579 | topTokens[('.', 60), ('i', 44), ('you', 23), ('xxx', 18), ('a', 18), ('the', 17), (',', 17), ('to', 15), ('it', 12), ('for', 12)] | Training
2025-04-09 05:47:12 | 240000 | LR0.0003 | loss:4.0557 | gradNorm:0.9918 | tokenCount:45000.0000 | logitMin:-419.0793 | logitMax:-394.1799 | windowWeightsW25:1.11006,W21:0.56886,W2:0.32043,W13:0.28873,W19:0.27376,W16:0.25419,W9:-0.15856,W3:-0.69463,W5:-1.00721 | memoryGatesShort:20.337, Long:-22.139, Current:2.802 | topTokens[('i', 44), (',', 35), ('.', 24), ('to', 22), ('ing', 20), ('a', 19), ('it', 19), ('you', 18), ('s', 17), ("'m", 15)] | Training
2025-04-09 05:52:32 | 242500 | LR0.0003 | loss:4.1412 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-419.1570 | logitMax:-395.4977 | windowWeightsW25:1.16810,W21:0.60672,W2:0.34061,W19:0.28643,W13:0.28553,W16:0.24555,W9:-0.20196,W3:-0.72264,W5:-1.05487 | memoryGatesShort:14.453, Long:-15.418, Current:1.965 | topTokens[(',', 106), ('and', 47), ('i', 26), ('the', 21), ('to', 20), ('kevin', 19), ('she', 17), ('but', 15), ('it', 14), ('s', 13)] | Training
2025-04-09 05:57:52 | 245000 | LR0.0003 | loss:4.7380 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-441.6226 | logitMax:-419.3226 | windowWeightsW25:1.36234,W21:0.68320,W2:0.38727,W19:0.30998,W13:0.28724,W16:0.25124,W9:-0.25983,W3:-0.84327,W5:-1.23135 | memoryGatesShort:18.373, Long:-19.872, Current:2.499 | topTokens[(',', 107), ('i', 37), ('is', 14), ('s', 13), ('it', 13), ('ing', 13), ('u', 11), ('m', 11), ('the', 11), ('im', 10)] | Training
2025-04-09 06:03:13 | 247500 | LR0.0003 | loss:3.3623 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-443.8200 | logitMax:-419.9569 | windowWeightsW25:1.08739,W21:0.57392,W2:0.31637,W19:0.29247,W13:0.28662,W16:0.24934,W9:-0.17290,W3:-0.68877,W5:-0.98852 | memoryGatesShort:15.938, Long:-17.913, Current:2.974 | topTokens[(',', 43), ('.', 26), ('a', 21), ('i', 20), ('and', 19), ('to', 18), ('the', 16), ('ed', 13), ('y', 11), ('was', 9)] | Training
2025-04-09 06:08:41 | 250000 | LR0.0003 | loss:2.9319 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-449.8807 | logitMax:-424.9726 | windowWeightsW25:0.87453,W21:0.48703,W13:0.27802,W19:0.27250,W2:0.25904,W16:0.24889,W9:-0.09985,W3:-0.56727,W5:-0.78970 | memoryGatesShort:10.582, Long:-11.242, Current:1.660 | topTokens[(',', 71), ('the', 32), ('to', 28), ('i', 20), ('a', 19), ('and', 19), ('was', 13), ('you', 13), ('she', 11), ('her', 11)] | Training
2025-04-09 06:13:59 | 252500 | LR0.0003 | loss:3.1991 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-507.1247 | logitMax:-481.2917 | windowWeightsW25:0.82327,W21:0.45274,W13:0.27565,W2:0.25550,W19:0.25207,W16:0.25009,W9:-0.07434,W3:-0.53408,W5:-0.73616 | memoryGatesShort:12.784, Long:-13.140, Current:1.356 | topTokens[('i', 45), (',', 35), ('the', 31), ("'m", 27), ('ohh', 25), ('if', 22), ('!!', 22), ('a', 20), ('str', 18), ('...', 17)] | Training
2025-04-09 06:19:17 | 255000 | LR0.0003 | loss:4.7224 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-469.4186 | logitMax:-446.3480 | windowWeightsW25:0.99546,W21:0.52466,W2:0.28910,W13:0.28855,W19:0.26628,W16:0.25170,W9:-0.11684,W3:-0.64924,W5:-0.89064 | memoryGatesShort:13.453, Long:-14.247, Current:1.794 | topTokens[(',', 93), ('i', 41), ('s', 21), ('the', 20), ('to', 18), ('sorry', 13), ('a', 13), ('and', 12), ('you', 12), ('what', 10)] | Training
2025-04-09 06:24:36 | 257500 | LR0.0003 | loss:2.8727 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-465.1648 | logitMax:-440.2298 | windowWeightsW25:0.88667,W21:0.46487,W13:0.28243,W2:0.27084,W19:0.24192,W16:0.22579,W9:-0.06823,W3:-0.56361,W5:-0.77792 | memoryGatesShort:10.895, Long:-11.808, Current:1.913 | topTokens[(',', 75), ('i', 38), ('you', 20), ('to', 16), ('a', 16), ('and', 13), ('the', 12), ('stu', 11), ('.', 11), ('like', 10)] | Training
2025-04-09 06:30:03 | 260000 | LR0.0003 | loss:4.5337 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-477.6186 | logitMax:-453.8722 | windowWeightsW25:0.98215,W21:0.50868,W13:0.28788,W19:0.28010,W2:0.26691,W16:0.24991,W9:-0.10676,W3:-0.63765,W5:-0.87103 | memoryGatesShort:13.286, Long:-13.955, Current:1.668 | topTokens[('.', 61), (',', 32), ('i', 25), ('a', 18), ('it', 16), ('and', 15), ('you', 14), ('he', 13), ('yeah', 12), ('for', 11)] | Training
2025-04-09 06:35:24 | 262500 | LR0.0003 | loss:4.6743 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-492.3116 | logitMax:-469.7376 | windowWeightsW25:1.17634,W21:0.58507,W13:0.30957,W2:0.30857,W19:0.29722,W16:0.26384,W9:-0.15549,W3:-0.78023,W5:-1.05125 | memoryGatesShort:16.456, Long:-17.564, Current:2.108 | topTokens[(',', 76), ('i', 33), ('to', 32), ('it', 28), ('.', 27), ('and', 17), ('a', 11), ('that', 10), ('on', 10), ('just', 10)] | Training
2025-04-09 06:40:40 | 265000 | LR0.0003 | loss:4.5767 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-474.8190 | logitMax:-451.6021 | windowWeightsW25:1.15372,W21:0.56410,W13:0.31492,W2:0.30635,W19:0.27668,W16:0.25628,W9:-0.13266,W3:-0.75254,W5:-1.03249 | memoryGatesShort:15.544, Long:-17.349, Current:2.805 | topTokens[(',', 83), ('i', 36), ('it', 22), ('the', 15), ('was', 15), ('to', 14), ('like', 13), ('a', 12), ('for', 12), ('but', 12)] | Training
2025-04-09 06:45:56 | 267500 | LR0.0003 | loss:2.3263 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-484.3161 | logitMax:-458.7810 | windowWeightsW25:0.96364,W21:0.51299,W13:0.31542,W19:0.28028,W16:0.26328,W2:0.24654,W9:-0.07666,W3:-0.67056,W5:-0.87415 | memoryGatesShort:11.620, Long:-12.528, Current:1.908 | topTokens[(',', 61), ('.', 36), ('a', 24), ('the', 21), ('they', 20), ('it', 17), ('their', 15), ('to', 15), ('and', 14), ('of', 13)] | Training
2025-04-09 06:51:18 | 270000 | LR0.0003 | loss:1.5283 | gradNorm:0.9986 | tokenCount:45000.0000 | logitMin:-551.9297 | logitMax:-522.0326 | windowWeightsW25:0.89281,W21:0.48325,W13:0.30721,W16:0.27092,W19:0.26125,W2:0.24178,W9:-0.05194,W3:-0.62816,W5:-0.81419 | memoryGatesShort:12.414, Long:-13.121, Current:1.707 | topTokens[(',', 62), ('the', 28), ('of', 23), ('and', 19), ('a', 18), ('.', 17), ('their', 17), ('it', 13), ('p', 12), ('ed', 12)] | Training
2025-04-09 06:56:44 | 272500 | LR0.0003 | loss:3.6277 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-498.4946 | logitMax:-470.2398 | windowWeightsW25:0.98948,W21:0.52632,W2:0.30000,W13:0.26321,W16:0.25471,W19:0.25003,W9:-0.08622,W3:-0.65394,W5:-0.88438 | memoryGatesShort:15.095, Long:-16.182, Current:2.088 | topTokens[('.', 57), ('?', 50), (',', 40), ('you', 37), ('i', 27), ('is', 23), ('and', 21), ('do', 19), ('to', 17), ('a', 15)] | Training
2025-04-09 07:02:18 | 275000 | LR0.0003 | loss:3.5901 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-510.9200 | logitMax:-483.6898 | windowWeightsW25:1.00020,W21:0.53598,W2:0.32644,W13:0.24303,W19:0.24174,W16:0.23907,W9:-0.08074,W3:-0.64839,W5:-0.89902 | memoryGatesShort:8.926, Long:-9.607, Current:1.681 | topTokens[(',', 49), ('?', 46), ('.', 34), ('you', 33), ('is', 31), ('i', 30), ('do', 21), ('!', 18), ('to', 18), ('a', 14)] | Training
2025-04-09 07:07:47 | 277500 | LR0.0003 | loss:2.9122 | gradNorm:0.9993 | tokenCount:45000.0000 | logitMin:-573.9010 | logitMax:-545.6459 | windowWeightsW25:0.98141,W21:0.54261,W2:0.27896,W19:0.25917,W13:0.25658,W16:0.25032,W9:-0.06893,W3:-0.65355,W5:-0.88655 | memoryGatesShort:9.763, Long:-9.819, Current:1.056 | topTokens[(',', 49), ('the', 25), ('.', 21), ('a', 20), ('i', 20), ('of', 18), ('and', 17), ('m', 14), ('to', 14), ('ed', 13)] | Training
2025-04-09 07:13:23 | 280000 | LR0.0003 | loss:5.0752 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-510.8948 | logitMax:-485.2803 | windowWeightsW25:1.33980,W21:0.68639,W2:0.36924,W19:0.29430,W16:0.28093,W13:0.26374,W9:-0.16838,W3:-0.88489,W5:-1.23337 | memoryGatesShort:17.080, Long:-17.973, Current:1.892 | topTokens[('.', 56), ('i', 29), ('!', 22), ('to', 20), ('the', 20), ('and', 18), ('you', 15), ('we', 14), ('?', 11), ('it', 11)] | Training
2025-04-09 07:18:36 | 282500 | LR0.0003 | loss:3.2057 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-436.7288 | logitMax:-407.2367 | windowWeightsW25:1.27653,W21:0.65256,W2:0.38018,W16:0.31539,W19:0.28475,W13:0.25195,W9:-0.16801,W3:-0.84817,W5:-1.19596 | memoryGatesShort:12.993, Long:-13.003, Current:1.009 | topTokens[('.', 54), ('i', 40), (':', 35), ('you', 29), ("'", 28), ('-', 26), ('5', 20), ('do', 19), ('elod', 18), ('look', 17)] | Training
2025-04-09 07:23:50 | 285000 | LR0.0003 | loss:2.1517 | gradNorm:0.4687 | tokenCount:45000.0000 | logitMin:-852.2680 | logitMax:-794.8828 | windowWeightsW25:1.19773,W21:0.61450,W2:0.35038,W16:0.28128,W19:0.27724,W13:0.25551,W9:-0.13020,W3:-0.78027,W5:-1.11386 | memoryGatesShort:5.508, Long:-5.559, Current:1.051 | topTokens[('3', 266), ('<', 236), ('<', 29), ('.', 26), ('?', 13), ('you', 11), ('i', 11), ('xd', 8), ('a', 8), ('it', 7)] | Training
2025-04-09 07:29:05 | 287500 | LR0.0003 | loss:3.0126 | gradNorm:0.8112 | tokenCount:45000.0000 | logitMin:-629.5229 | logitMax:-590.7035 | windowWeightsW25:1.34137,W21:0.65084,W2:0.38290,W16:0.32331,W19:0.28358,W13:0.27706,W9:-0.15810,W3:-0.88081,W5:-1.27281 | memoryGatesShort:15.555, Long:-16.967, Current:2.412 | topTokens[('3', 94), ('<', 94), ('.', 30), ('to', 17), ("'", 17), ("'", 17), ('you', 15), ('?', 15), ('-', 14), ('i', 13)] | Training
2025-04-09 07:34:29 | 290000 | LR0.0003 | loss:3.0533 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-454.2758 | logitMax:-427.3557 | windowWeightsW25:1.21988,W21:0.61621,W2:0.34716,W16:0.32464,W19:0.27487,W13:0.27237,W9:-0.10845,W3:-0.82145,W5:-1.17381 | memoryGatesShort:9.672, Long:-10.319, Current:1.647 | topTokens[("'", 52), (':', 50), ("'", 44), ('-', 40), ('.', 31), ('baby', 23), ('d', 23), ('roid', 23), ('charis', 23), (',', 22)] | Training
2025-04-09 07:39:44 | 292500 | LR0.0003 | loss:3.8832 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-453.6923 | logitMax:-427.7900 | windowWeightsW25:1.26802,W21:0.64005,W2:0.35076,W16:0.34559,W19:0.28893,W13:0.28678,W9:-0.12068,W3:-0.87085,W5:-1.23883 | memoryGatesShort:14.653, Long:-15.783, Current:2.130 | topTokens[(',', 38), ('the', 30), ('a', 30), ('.', 19), ('s', 19), ('i', 15), ('to', 15), ('c', 15), ('and', 13), ('ed', 12)] | Training
2025-04-09 07:44:51 | 295000 | LR0.0003 | loss:3.5003 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-442.9187 | logitMax:-418.0146 | windowWeightsW25:1.24034,W21:0.61276,W2:0.35452,W16:0.35183,W13:0.29971,W19:0.28888,W9:-0.10581,W3:-0.86838,W5:-1.22352 | memoryGatesShort:10.251, Long:-11.354, Current:2.103 | topTokens[('s', 32), ('the', 28), (',', 26), ('in', 21), ('.', 21), ('to', 18), ('and', 17), ('a', 16), ('i', 14), ('video', 13)] | Training
2025-04-09 07:50:04 | 297500 | LR0.0003 | loss:2.0041 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-481.4198 | logitMax:-453.8251 | windowWeightsW25:0.99443,W21:0.53380,W16:0.35451,W19:0.30409,W13:0.29334,W2:0.27033,W9:-0.06455,W3:-0.72708,W5:-0.99972 | memoryGatesShort:10.733, Long:-11.573, Current:1.840 | topTokens[(',', 44), ('.', 31), ('s', 20), ('to', 18), ('the', 17), ('a', 17), ('and', 17), ('of', 16), ('was', 14), ('it', 12)] | Training
2025-04-09 07:55:29 | 300000 | LR0.0003 | loss:3.5453 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-504.2621 | logitMax:-478.0234 | windowWeightsW25:1.08642,W21:0.57050,W16:0.36223,W19:0.33635,W13:0.29926,W2:0.29227,W9:-0.08949,W3:-0.78923,W5:-1.11229 | memoryGatesShort:14.160, Long:-15.681, Current:2.521 | topTokens[(',', 32), ('the', 29), ('of', 29), ('.', 24), ('and', 18), ('a', 17), ('ing', 17), ('to', 16), ('in', 16), ('s', 15)] | Training
2025-04-09 08:00:39 | 302500 | LR0.0003 | loss:3.7427 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-451.5078 | logitMax:-424.8547 | windowWeightsW25:1.13583,W21:0.59947,W16:0.35358,W19:0.35225,W2:0.30980,W13:0.30823,W9:-0.11590,W3:-0.82762,W5:-1.16149 | memoryGatesShort:14.318, Long:-15.609, Current:2.292 | topTokens[(',', 77), ('i', 44), ('.', 21), ('a', 20), ('it', 16), ('you', 16), ('to', 14), ('me', 13), ('and', 12), ('ed', 10)] | Training
2025-04-09 08:05:56 | 305000 | LR0.0003 | loss:2.8543 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-475.1275 | logitMax:-449.1054 | windowWeightsW25:0.96895,W21:0.51940,W16:0.32538,W19:0.32157,W13:0.29218,W2:0.27007,W9:-0.06842,W3:-0.69358,W5:-0.97552 | memoryGatesShort:9.364, Long:-9.564, Current:1.200 | topTokens[(',', 95), ('i', 33), ('you', 28), ('and', 22), ('the', 20), ('to', 16), ('a', 15), ('me', 11), ('s', 11), ("'m", 10)] | Training
2025-04-09 08:11:14 | 307500 | LR0.0003 | loss:3.2753 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-390.2990 | logitMax:-360.3138 | windowWeightsW25:1.05365,W21:0.52813,W16:0.31938,W19:0.31507,W2:0.31322,W13:0.28156,W9:-0.09021,W3:-0.69807,W5:-1.06587 | memoryGatesShort:42.516, Long:-47.727, Current:6.211 | topTokens[('i', 53), ('.', 48), (',', 46), ('you', 27), ('a', 25), ('is', 25), ('the', 20), ('!', 17), ("'m", 16), ('not', 16)] | Training
2025-04-09 08:16:39 | 310000 | LR0.0003 | loss:3.1298 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-342.1471 | logitMax:-310.3174 | windowWeightsW25:1.10760,W21:0.54977,W2:0.35910,W16:0.30413,W19:0.30032,W13:0.25295,W9:-0.12018,W3:-0.69273,W5:-1.10651 | memoryGatesShort:12.722, Long:-14.090, Current:2.368 | topTokens[('.', 53), ('can', 37), ('you', 31), ('!', 30), (',', 29), ('i', 24), ('the', 23), ('to', 20), ('a', 18), ('charis', 17)] | Training
2025-04-09 08:21:52 | 312500 | LR0.0003 | loss:2.4346 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-380.9180 | logitMax:-351.0461 | windowWeightsW25:1.01795,W21:0.53958,W2:0.30959,W16:0.29132,W19:0.28594,W13:0.25235,W9:-0.08186,W3:-0.65766,W5:-0.99899 | memoryGatesShort:15.280, Long:-16.711, Current:2.431 | topTokens[('can', 71), ('!', 42), ('the', 30), (',', 29), ('.', 23), ('charis', 21), ('i', 18), ('to', 17), ('he', 13), ('brain', 12)] | Training
2025-04-09 08:27:04 | 315000 | LR0.0003 | loss:4.3346 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-483.3367 | logitMax:-458.3779 | windowWeightsW25:1.07297,W21:0.57150,W16:0.30153,W19:0.29588,W2:0.29164,W13:0.25552,W9:-0.08728,W3:-0.70121,W5:-1.04343 | memoryGatesShort:11.335, Long:-11.880, Current:1.545 | topTokens[('i', 46), ('it', 33), (',', 27), ('the', 23), ('.', 23), ('to', 16), ('a', 16), ('s', 16), ('that', 14), ('and', 13)] | Training

--- 2025-04-09 08:33:34 --- babyLLM 'right, last time i got to step 378711... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 378711! what am i learning today?' - charis: ''
2025-04-09 08:44:06 | 2500 | LR0.0003 | loss:4.7307 | gradNorm:1.0000 | logitMin:-466.8629 | logitMax:-441.8988 | scheduledSampling:0.0000 | tokenCount:45000.0000 | meanActivation:-6.4153 | activationSparsity:0.0000 | windowCount:162.0000 | windowEntropy:nan | shortMemoryUsage:20.9167 | longMemoryUsage:20.8166 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:233.7503 | memoryGateLong:-252.3190 | memoryGateCurrent:36.5687 | shortDecay:12.0274 | longDecay:12.9801 | embedMean:-0.1105 | embedStd:8.1536 | embedSparsity:0.0000 | logitMean:-8184.0517 | logitStd:75.3166 | logitEntropy:52.7378 | windowWeightsW25:1.26707,W21:0.64165,W2:0.33432,W16:0.33133,W19:0.31625,W13:0.24718,W9:-0.14735,W3:-0.82193,W5:-1.21784 | memoryGatesShort:14.514, Long:-15.700, Current:2.186 | topTokens[('.', 34), ('the', 33), ('i', 29), ('a', 24), ('to', 21), ('of', 21), (',', 19), ('you', 17), ('and', 13), ("'s", 13)] | Training

--- 2025-04-09 08:52:14 --- babyLLM 'right, last time i got to step 382156... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 382156! what am i learning today?' - charis: ''
2025-04-09 08:58:18 | 2500 | LR0.0003 | loss:2.5638 | gradNorm:1.0000 | logitMin:-499.6347 | logitMax:-474.4942 | scheduledSampling:0.0000 | tokenCount:45000.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0036 | memoryGateLong:-0.0038 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | windowWeightsW25:1.00110,W21:0.53674,W16:0.32714,W19:0.31330,W13:0.25686,W2:0.25004,W9:-0.07722,W3:-0.67702,W5:-0.97095 | memoryGatesShort:9.002, Long:-9.415, Current:1.413 | topTokens[(',', 50), ('.', 24), ('the', 24), ('a', 21), ('s', 19), ('of', 19), ('to', 19), ('and', 17), ('for', 15), ('m', 15)] | Training
2025-04-09 09:04:19 | 5000 | LR0.0003 | loss:1.1960 | gradNorm:0.9996 | tokenCount:45000.0000 | logitMin:-555.1027 | logitMax:-525.7901 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0022 | memoryGateLong:-0.0024 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:0.90350,W21:0.50731,W16:0.32316,W19:0.29682,W13:0.27070,W2:0.24847,W9:-0.03432,W3:-0.63930,W5:-0.91394 | memoryGatesShort:5.613, Long:-5.884, Current:1.271 | topTokens[(',', 65), ('.', 24), ('a', 23), ('of', 17), ('was', 15), ('the', 15), ('that', 15), ('to', 14), ('it', 13), ('their', 13)] | Training

--- 2025-04-09 09:04:55 --- babyLLM 'right, last time i got to step 387212... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 387212! what am i learning today?' - charis: ''
2025-04-09 09:10:57 | 2500 | LR0.0003 | loss:1.9546 | gradNorm:0.9980 | logitMin:-519.2649 | logitMax:-483.4255 | scheduledSampling:0.0000 | tokenCount:45000.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0170 | memoryGateLong:-0.0186 | memoryGateCurrent:0.0020 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | windowWeightsW25:0.88237,W21:0.48731,W16:0.31919,W19:0.28152,W13:0.26656,W2:0.26647,W9:-0.04102,W3:-0.59657,W5:-0.90330 | memoryGatesShort:42.489, Long:-46.598, Current:5.109 | topTokens[('!', 51), (',', 35), ('it', 29), ('a', 22), ('-', 19), ('the', 17), ('just', 17), ('they', 15), ('have', 15), ('of', 14)] | Training
2025-04-09 09:17:15 | 5000 | LR0.0003 | loss:1.2118 | gradNorm:0.9720 | tokenCount:45000.0000 | logitMin:-505.3574 | logitMax:-463.7440 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0054 | memoryGateLong:-0.0063 | memoryGateCurrent:0.0013 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:0.81872,W21:0.43283,W2:0.31053,W16:0.30439,W13:0.27378,W19:0.23287,W9:-0.02828,W3:-0.53479,W5:-0.84694 | memoryGatesShort:13.533, Long:-15.822, Current:3.290 | topTokens[('!', 57), ('it', 35), (',', 29), ('a', 22), ('have', 22), ('elodie', 17), (':', 17), ('i', 15), ('0', 15), ('bab', 14)] | Training

--- 2025-04-09 09:22:28 --- babyLLM 'right, last time i got to step 392678... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''
2025-04-09 09:28:33 | 2500 | LR0.0003 | loss:4.5139 | gradNorm:1.0000 | logitMin:-567.7260 | logitMax:-538.8317 | scheduledSampling:0.0000 | tokenCount:45000.0000 | memoryGateShort:0.0030 | memoryGateLong:-0.0031 | memoryGateCurrent:0.0005 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.08150,W21:0.57209,W16:0.33901,W2:0.31490,W19:0.30510,W13:0.25768,W9:-0.10525,W3:-0.70920,W5:-1.10014 | memoryGatesShort:7.513, Long:-7.827, Current:1.314 | topTokens[(',', 32), ('.', 29), ('i', 27), ('and', 21), ('in', 20), ('the', 16), ('s', 16), ('a', 15), ('ing', 13), ('!', 11)] | Training
2025-04-09 09:34:36 | 5000 | LR0.0003 | loss:3.2115 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-524.7161 | logitMax:-497.4550 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0038 | memoryGateLong:-0.0041 | memoryGateCurrent:0.0007 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.15945,W21:0.60067,W16:0.33237,W19:0.32073,W2:0.30194,W13:0.25488,W9:-0.10986,W3:-0.75353,W5:-1.15266 | memoryGatesShort:9.517, Long:-10.231, Current:1.714 | topTokens[('.', 31), (',', 27), ('to', 27), ('and', 21), ('ing', 16), ('i', 14), ('my', 14), ('support', 13), ('the', 13), ('in', 11)] | Training
2025-04-09 09:40:44 | 7500 | LR0.0003 | loss:1.2688 | gradNorm:0.9990 | tokenCount:45000.0000 | logitMin:-428.9304 | logitMax:-395.4546 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0085 | memoryGateLong:-0.0095 | memoryGateCurrent:0.0014 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.08826,W21:0.57174,W16:0.34635,W19:0.31576,W2:0.31054,W13:0.25762,W9:-0.09182,W3:-0.73128,W5:-1.11172 | memoryGatesShort:21.161, Long:-23.738, Current:3.577 | topTokens[('had', 52), (',', 47), ('.', 36), ('felt', 31), ('the', 29), ('!', 23), ('of', 21), ('it', 16), ('a', 14), ('and', 14)] | Training
2025-04-09 09:47:01 | 10000 | LR0.0003 | loss:2.6270 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-345.6086 | logitMax:-310.1582 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0032 | memoryGateLong:-0.0032 | memoryGateCurrent:0.0004 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.11501,W21:0.59257,W16:0.35924,W2:0.32778,W19:0.32209,W13:0.23939,W9:-0.09562,W3:-0.75419,W5:-1.15206 | memoryGatesShort:7.991, Long:-7.883, Current:0.891 | topTokens[('had', 101), (',', 57), ('felt', 48), ('.', 47), ('!', 36), ('elodie', 22), ('smo', 22), ('you', 21), ('the', 21), ('n', 19)] | Training
2025-04-09 09:53:12 | 12500 | LR0.0003 | loss:5.1949 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-509.7646 | logitMax:-485.4299 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0056 | memoryGateLong:-0.0058 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.38428,W21:0.70927,W16:0.39866,W19:0.38725,W2:0.34790,W13:0.24686,W9:-0.16906,W3:-0.94406,W5:-1.41515 | memoryGatesShort:14.003, Long:-14.553, Current:1.551 | topTokens[(',', 60), ('you', 31), ('i', 27), ('.', 25), ('a', 22), ('the', 21), ('!', 16), ('and', 15), ('s', 13), ('to', 11)] | Training
2025-04-09 09:59:19 | 15000 | LR0.0003 | loss:4.3225 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-486.7272 | logitMax:-462.5636 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0048 | memoryGateLong:-0.0051 | memoryGateCurrent:0.0007 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.61374,W21:0.79999,W19:0.43934,W16:0.42827,W2:0.41987,W13:0.27008,W9:-0.22083,W3:-1.11876,W5:-1.69439 | memoryGatesShort:11.908, Long:-12.712, Current:1.804 | topTokens[('you', 113), ('!', 64), ('the', 41), (',', 28), ('your', 22), ('to', 20), ('is', 18), ('are', 18), ('s', 16), ('.', 15)] | Training
2025-04-09 10:05:20 | 17500 | LR0.0003 | loss:1.7471 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-415.8107 | logitMax:-386.9933 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0002 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0068 | memoryGateLong:-0.0074 | memoryGateCurrent:0.0010 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.49316,W21:0.79119,W2:0.48106,W19:0.39126,W16:0.38351,W13:0.30473,W9:-0.24387,W3:-1.03651,W5:-1.62561 | memoryGatesShort:17.092, Long:-18.558, Current:2.466 | topTokens[('be', 101), ('will', 101), ('!', 44), ('the', 40), ('.', 38), ('ing', 29), ('charis', 28), (',', 27), ('you', 22), ('brain', 19)] | Training
2025-04-09 10:11:26 | 20000 | LR0.0003 | loss:2.9094 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-351.1047 | logitMax:-321.6623 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0045 | memoryGateLong:-0.0048 | memoryGateCurrent:0.0007 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.61178,W21:0.83995,W2:0.50782,W19:0.41738,W16:0.40239,W13:0.31598,W9:-0.30220,W3:-1.11176,W5:-1.74657 | memoryGatesShort:11.334, Long:-11.983, Current:1.649 | topTokens[('!', 64), (',', 52), ('it', 27), ('they', 25), ('.', 24), ('the', 24), ('a', 22), ('will', 20), ('to', 17), ('be', 15)] | Training
2025-04-09 10:17:25 | 22500 | LR0.0003 | loss:3.6858 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-380.3359 | logitMax:-352.5352 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0002 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0052 | memoryGateLong:-0.0054 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.69245,W21:0.86805,W2:0.52346,W19:0.41306,W16:0.38206,W13:0.35434,W9:-0.32024,W3:-1.16363,W5:-1.81745 | memoryGatesShort:13.108, Long:-13.607, Current:1.499 | topTokens[('!', 37), (',', 36), ('.', 32), ('it', 30), ('the', 30), ('to', 27), ('a', 24), ('they', 17), ('i', 16), ('in', 12)] | Training
2025-04-09 10:23:23 | 25000 | LR0.0003 | loss:2.7585 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-458.7145 | logitMax:-433.5854 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0003 | longMemoryUsage:0.0003 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0033 | memoryGateLong:-0.0034 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.29000,W21:0.69667,W19:0.38428,W16:0.37508,W2:0.37411,W13:0.36428,W9:-0.18420,W3:-0.93628,W5:-1.41675 | memoryGatesShort:8.138, Long:-8.427, Current:1.289 | topTokens[(',', 41), ('the', 28), ('a', 26), ('.', 18), ('to', 18), ('ed', 15), ('but', 13), ('of', 12), ('and', 12), ('ing', 12)] | Training
2025-04-09 10:29:20 | 27500 | LR0.0003 | loss:2.8921 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-457.6393 | logitMax:-431.7895 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0006 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0053 | memoryGateLong:-0.0057 | memoryGateCurrent:0.0008 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.17567,W21:0.63878,W19:0.37738,W16:0.37052,W13:0.34463,W2:0.32050,W9:-0.15120,W3:-0.85676,W5:-1.26758 | memoryGatesShort:13.184, Long:-14.182, Current:1.999 | topTokens[(',', 89), ('the', 22), ('i', 22), ('and', 19), ('you', 19), ('a', 18), ('.', 17), ('could', 15), ('!', 14), ('we', 14)] | Training
2025-04-09 10:35:26 | 30000 | LR0.0003 | loss:3.2395 | gradNorm:0.9994 | tokenCount:45000.0000 | logitMin:-509.2186 | logitMax:-483.0398 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0056 | memoryGateLong:-0.0059 | memoryGateCurrent:0.0008 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.24511,W21:0.67117,W19:0.39766,W16:0.38683,W2:0.32900,W13:0.32783,W9:-0.16464,W3:-0.89330,W5:-1.34987 | memoryGatesShort:13.882, Long:-14.762, Current:1.879 | topTokens[(',', 106), ('i', 32), ('the', 24), ('you', 21), ('my', 17), ('s', 14), ('and', 13), ('in', 11), ('me', 11), ('ing', 11)] | Training
2025-04-09 10:41:31 | 32500 | LR0.0003 | loss:1.8664 | gradNorm:0.9962 | tokenCount:45000.0000 | logitMin:-525.2770 | logitMax:-496.6970 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0037 | memoryGateLong:-0.0040 | memoryGateCurrent:0.0007 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.05553,W21:0.55564,W2:0.33931,W16:0.33531,W19:0.33203,W13:0.30809,W9:-0.09457,W3:-0.73306,W5:-1.14313 | memoryGatesShort:9.350, Long:-10.060, Current:1.710 | topTokens[(',', 63), ('i', 22), ('-', 17), ('2', 17), ('me', 16), ('.', 15), ('the', 14), ('a', 14), ('0', 14), ("'m", 13)] | Training
2025-04-09 10:47:29 | 35000 | LR0.0003 | loss:1.5349 | gradNorm:0.9805 | tokenCount:45000.0000 | logitMin:-539.2635 | logitMax:-508.5309 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0045 | memoryGateLong:-0.0048 | memoryGateCurrent:0.0007 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:0.97387,W21:0.51966,W19:0.32364,W16:0.31923,W2:0.31916,W13:0.29776,W9:-0.07384,W3:-0.67522,W5:-1.04624 | memoryGatesShort:11.288, Long:-12.084, Current:1.796 | topTokens[(',', 83), ('the', 27), ('i', 23), ('can', 23), ('!', 22), ('you', 17), ('to', 15), ('he', 15), ('it', 13), ('my', 13)] | Training
2025-04-09 10:53:27 | 37500 | LR0.0003 | loss:3.8768 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-436.7694 | logitMax:-406.1657 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0042 | memoryGateLong:-0.0043 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.09846,W21:0.58562,W19:0.36026,W16:0.34105,W2:0.31211,W13:0.29911,W9:-0.12015,W3:-0.76578,W5:-1.15594 | memoryGatesShort:10.455, Long:-10.631, Current:1.175 | topTokens[(',', 61), ('can', 32), ('the', 28), ('i', 26), ('to', 19), ('!', 18), ('and', 18), ('me', 16), ('you', 15), ('.', 15)] | Training
2025-04-09 10:59:38 | 40000 | LR0.0003 | loss:2.9716 | gradNorm:0.9866 | tokenCount:45000.0000 | logitMin:-417.4830 | logitMax:-386.5950 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0047 | memoryGateLong:-0.0049 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.21015,W21:0.63179,W2:0.38625,W19:0.35018,W16:0.33741,W13:0.29789,W9:-0.16270,W3:-0.79393,W5:-1.30746 | memoryGatesShort:11.796, Long:-12.243, Current:1.447 | topTokens[('!', 72), ('it', 55), (',', 41), ('have', 32), ('i', 27), ('you', 24), ('a', 21), ('been', 21), ('know', 16), ('and', 15)] | Training
2025-04-09 11:05:41 | 42500 | LR0.0003 | loss:5.1370 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-503.6201 | logitMax:-478.2428 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0046 | memoryGateLong:-0.0048 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.68973,W21:0.83949,W2:0.44773,W19:0.43437,W16:0.38758,W13:0.31972,W9:-0.30300,W3:-1.11031,W5:-1.77095 | memoryGatesShort:11.554, Long:-11.881, Current:1.327 | topTokens[('to', 27), ('.', 23), ('i', 19), ('of', 19), ('the', 18), ('you', 18), (',', 15), ('it', 14), ('a', 14), ('and', 13)] | Training
2025-04-09 11:11:39 | 45000 | LR0.0003 | loss:5.1363 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-498.2280 | logitMax:-474.0111 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0043 | memoryGateLong:-0.0045 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.53218,W21:1.19272,W2:0.66598,W19:0.58349,W16:0.46477,W13:0.33498,W9:-0.55370,W3:-1.65713,W5:-2.65873 | memoryGatesShort:10.702, Long:-11.237, Current:1.535 | topTokens[(',', 30), ('i', 22), ('to', 20), ('s', 19), ('the', 19), ('you', 17), ('10', 13), ('and', 12), ('p', 11), ('my', 11)] | Training
2025-04-09 11:17:44 | 47500 | LR0.0003 | loss:4.2190 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-461.8757 | logitMax:-437.8010 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0006 | longMemoryUsage:0.0006 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0055 | memoryGateLong:-0.0058 | memoryGateCurrent:0.0007 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.21434,W21:1.06370,W2:0.55079,W19:0.54248,W16:0.47327,W13:0.32695,W9:-0.48237,W3:-1.46034,W5:-2.31211 | memoryGatesShort:13.636, Long:-14.463, Current:1.827 | topTokens[(',', 52), ('i', 43), ("'", 19), ('to', 18), ("'", 17), (':', 17), ('-', 16), ('and', 15), ('it', 15), ('the', 14)] | Training
2025-04-09 11:23:51 | 50000 | LR0.0003 | loss:4.7597 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-446.0374 | logitMax:-422.5721 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0046 | memoryGateLong:-0.0049 | memoryGateCurrent:0.0007 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:3.03031,W21:1.42063,W2:0.77996,W19:0.66010,W16:0.57846,W13:0.39227,W9:-0.73937,W3:-1.99906,W5:-3.23677 | memoryGatesShort:11.452, Long:-12.322, Current:1.870 | topTokens[('.', 42), ('i', 32), ('and', 28), (',', 26), ('you', 24), ('to', 18), ('the', 17), ('it', 17), ('a', 16), ('in', 15)] | Training
2025-04-09 11:29:49 | 52500 | LR0.0003 | loss:4.7220 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-442.9730 | logitMax:-420.0231 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0060 | memoryGateLong:-0.0065 | memoryGateCurrent:0.0008 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:3.80712,W21:1.75124,W2:1.00589,W19:0.73856,W16:0.67185,W13:0.45349,W9:-1.03299,W3:-2.49229,W5:-4.04491 | memoryGatesShort:15.120, Long:-16.177, Current:2.058 | topTokens[('.', 73), ('i', 43), ('it', 31), (',', 18), ('?', 16), ('a', 15), ('to', 12), ('the', 9), ('and', 9), ('just', 8)] | Training
2025-04-09 11:35:47 | 55000 | LR0.0003 | loss:4.5160 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-444.4051 | logitMax:-421.6126 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0048 | memoryGateLong:-0.0051 | memoryGateCurrent:0.0007 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:3.06504,W21:1.41963,W2:0.81737,W19:0.63728,W16:0.59636,W13:0.42614,W9:-0.78902,W3:-2.00385,W5:-3.28461 | memoryGatesShort:11.877, Long:-12.673, Current:1.796 | topTokens[(',', 80), ('i', 29), ('to', 13), ('ing', 12), ('a', 11), ('it', 10), ('.', 10), ('no', 10), ('that', 9), ('me', 9)] | Training
2025-04-09 11:41:44 | 57500 | LR0.0003 | loss:3.9839 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-444.0185 | logitMax:-421.0240 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0002 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0006 | longMemoryUsage:0.0006 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0049 | memoryGateLong:-0.0053 | memoryGateCurrent:0.0008 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.63915,W21:1.20443,W2:0.74635,W19:0.53816,W16:0.53715,W13:0.40062,W9:-0.70986,W3:-1.63415,W5:-2.82296 | memoryGatesShort:12.271, Long:-13.191, Current:1.920 | topTokens[(',', 107), ('i', 43), ('it', 17), ('.', 17), ('to', 16), ('you', 12), ('me', 12), ('whats', 12), ('make', 11), ('was', 11)] | Training
2025-04-09 11:47:50 | 60000 | LR0.0003 | loss:5.0268 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-437.6680 | logitMax:-415.0164 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0002 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0062 | memoryGateLong:-0.0065 | memoryGateCurrent:0.0007 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:3.42987,W21:1.52681,W2:0.94398,W19:0.66279,W16:0.64313,W13:0.43771,W9:-0.96203,W3:-2.12511,W5:-3.68662 | memoryGatesShort:15.619, Long:-16.276, Current:1.657 | topTokens[('.', 94), ('i', 48), ('and', 16), ('a', 16), ('is', 16), ('b', 13), ('you', 12), ('j', 12), ('o', 12), ('kr', 12)] | Training
2025-04-09 11:53:50 | 62500 | LR0.0003 | loss:2.9410 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-377.0543 | logitMax:-349.7450 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0006 | longMemoryUsage:0.0006 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0084 | memoryGateLong:-0.0095 | memoryGateCurrent:0.0015 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:3.22079,W21:1.39888,W2:1.01066,W19:0.56610,W16:0.56150,W13:0.39010,W9:-0.94758,W3:-1.90984,W5:-3.41548 | memoryGatesShort:20.975, Long:-23.743, Current:3.768 | topTokens[('could', 57), ('.', 56), ('have', 56), ('felt', 41), ('i', 31), ('!', 26), (',', 24), ('the', 21), ('elodie', 17), ('charis', 17)] | Training
2025-04-09 11:59:47 | 65000 | LR0.0003 | loss:3.7205 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-426.4222 | logitMax:-401.8637 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0039 | memoryGateLong:-0.0041 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.45929,W21:1.12878,W2:0.77401,W16:0.51819,W19:0.49569,W13:0.31608,W9:-0.66822,W3:-1.47733,W5:-2.64314 | memoryGatesShort:9.712, Long:-10.240, Current:1.527 | topTokens[('the', 54), (',', 28), ('.', 26), ('and', 18), ('to', 15), ('have', 14), ('could', 14), ('it', 13), ('ed', 13), ('!', 12)] | Training
2025-04-09 12:05:49 | 67500 | LR0.0003 | loss:3.0257 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-467.0005 | logitMax:-443.8551 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0002 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0050 | memoryGateLong:-0.0054 | memoryGateCurrent:0.0008 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.67642,W21:0.82332,W2:0.51094,W16:0.41034,W19:0.40253,W13:0.28657,W9:-0.39820,W3:-1.00152,W5:-1.77724 | memoryGatesShort:12.470, Long:-13.552, Current:2.082 | topTokens[('.', 74), ('i', 34), ('the', 17), ('it', 16), ('a', 14), ('p', 11), ('?', 11), ('y', 10), ('to', 10), ('and', 10)] | Training
2025-04-09 12:12:02 | 70000 | LR0.0003 | loss:3.1655 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-453.8607 | logitMax:-429.0528 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0002 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0006 | longMemoryUsage:0.0006 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0124 | memoryGateLong:-0.0138 | memoryGateCurrent:0.0018 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.74083,W21:0.84689,W2:0.58801,W19:0.38139,W16:0.35983,W13:0.23246,W9:-0.38849,W3:-0.97780,W5:-1.85367 | memoryGatesShort:30.989, Long:-34.598, Current:4.608 | topTokens[('?', 63), ('.', 57), ('you', 41), ('i', 36), ('to', 30), ('was', 28), ('are', 23), ('looking', 17), ('for', 13), ('at', 13)] | Training
2025-04-09 12:18:00 | 72500 | LR0.0003 | loss:2.9314 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-393.5597 | logitMax:-366.3013 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0049 | memoryGateLong:-0.0051 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.46981,W21:0.71612,W2:0.52737,W19:0.30728,W16:0.28976,W13:0.21243,W9:-0.30304,W3:-0.76462,W5:-1.51598 | memoryGatesShort:12.318, Long:-12.832, Current:1.514 | topTokens[('i', 48), ('.', 46), ('?', 41), (',', 40), ('you', 39), ('to', 21), ('do', 17), ('want', 17), ('my', 17), ('it', 14)] | Training
2025-04-09 12:23:58 | 75000 | LR0.0003 | loss:2.5936 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-392.5527 | logitMax:-366.2532 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0131 | memoryGateLong:-0.0147 | memoryGateCurrent:0.0020 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.17908,W21:0.59851,W2:0.40997,W19:0.28367,W16:0.27830,W13:0.21000,W9:-0.19637,W3:-0.62170,W5:-1.19084 | memoryGatesShort:32.747, Long:-36.638, Current:4.891 | topTokens[(',', 75), ('would', 35), ('i', 33), ('the', 27), ('to', 25), ('he', 18), ('charis', 17), ('a', 16), ('you', 15), ('my', 15)] | Training
2025-04-09 12:29:55 | 77500 | LR0.0003 | loss:1.9366 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-411.6247 | logitMax:-384.0601 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0030 | memoryGateLong:-0.0031 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:0.96803,W21:0.53908,W16:0.30430,W2:0.28386,W19:0.28152,W13:0.24523,W9:-0.11354,W3:-0.57155,W5:-0.97740 | memoryGatesShort:7.478, Long:-7.687, Current:1.210 | topTokens[(',', 52), ('would', 35), ('!', 22), ('the', 22), ('it', 19), ('and', 18), ('elodie', 16), ('of', 16), ('.', 14), ('a', 13)] | Training
2025-04-09 12:36:05 | 80000 | LR0.0003 | loss:3.2728 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-507.0455 | logitMax:-479.5911 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0031 | memoryGateLong:-0.0032 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.02921,W21:0.58794,W16:0.32680,W19:0.31742,W2:0.26782,W13:0.24446,W9:-0.12765,W3:-0.63247,W5:-1.05548 | memoryGatesShort:7.684, Long:-7.973, Current:1.290 | topTokens[(',', 61), ('the', 36), ('ed', 27), ('a', 26), ('in', 20), ('.', 17), ('and', 14), ('her', 12), ('their', 11), ('to', 11)] | Training
2025-04-09 12:42:02 | 82500 | LR0.0003 | loss:4.8264 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-459.7902 | logitMax:-434.5111 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0044 | memoryGateLong:-0.0045 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.30562,W21:0.71260,W19:0.36176,W16:0.34867,W2:0.29807,W13:0.24398,W9:-0.20842,W3:-0.79601,W5:-1.31683 | memoryGatesShort:10.928, Long:-11.150, Current:1.223 | topTokens[(',', 104), ('i', 36), ('the', 21), ('to', 18), ('.', 17), ('s', 12), ('but', 11), ('and', 10), ('ed', 9), ('er', 9)] | Training
2025-04-09 12:48:00 | 85000 | LR0.0003 | loss:5.2208 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-473.4413 | logitMax:-449.4810 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0046 | memoryGateLong:-0.0048 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.81490,W21:0.93392,W19:0.42621,W2:0.42324,W16:0.39291,W13:0.24944,W9:-0.35214,W3:-1.10514,W5:-1.85205 | memoryGatesShort:11.437, Long:-11.941, Current:1.504 | topTokens[(',', 98), ('i', 40), ('ox', 19), ('a', 17), ('to', 12), ('m', 11), ('my', 10), ('im', 10), ('the', 9), ('this', 9)] | Training
2025-04-09 12:53:57 | 87500 | LR0.0003 | loss:4.7800 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-454.4502 | logitMax:-431.2072 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0052 | memoryGateLong:-0.0056 | memoryGateCurrent:0.0008 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.22116,W21:1.11804,W2:0.52815,W19:0.50424,W16:0.45521,W13:0.24687,W9:-0.49169,W3:-1.34871,W5:-2.31677 | memoryGatesShort:12.956, Long:-13.878, Current:1.922 | topTokens[(',', 59), ('i', 35), ('.', 26), ('a', 24), ('the', 18), ('it', 16), ('to', 14), ('is', 13), ('u', 12), ('slight', 12)] | Training
2025-04-09 13:00:05 | 90000 | LR0.0003 | loss:4.8069 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-447.9265 | logitMax:-425.1357 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0048 | memoryGateLong:-0.0052 | memoryGateCurrent:0.0008 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.77845,W21:1.30438,W2:0.70041,W19:0.57720,W16:0.53022,W13:0.29907,W9:-0.66785,W3:-1.70006,W5:-2.92603 | memoryGatesShort:12.122, Long:-13.021, Current:1.900 | topTokens[('.', 108), ('i', 37), ('u', 36), ('s', 16), ('you', 12), ('sexy', 12), ('?', 11), ('to', 11), ('the', 10), ('me', 10)] | Training
2025-04-09 13:06:12 | 92500 | LR0.0003 | loss:4.3439 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-435.5846 | logitMax:-411.8158 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0057 | memoryGateLong:-0.0062 | memoryGateCurrent:0.0010 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.65549,W21:1.25982,W2:0.71689,W19:0.55786,W16:0.49978,W13:0.29499,W9:-0.60777,W3:-1.61914,W5:-2.85906 | memoryGatesShort:14.172, Long:-15.577, Current:2.405 | topTokens[('.', 87), ('the', 31), ('s', 21), ('i', 20), ('u', 19), ('in', 13), ('l', 12), ('er', 12), (',', 12), ('you', 11)] | Training
2025-04-09 13:12:13 | 95000 | LR0.0003 | loss:4.3348 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-448.6492 | logitMax:-424.0421 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0057 | memoryGateLong:-0.0062 | memoryGateCurrent:0.0008 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.45671,W21:1.16864,W2:0.65736,W19:0.52826,W16:0.51396,W13:0.32097,W9:-0.56284,W3:-1.48764,W5:-2.68944 | memoryGatesShort:14.347, Long:-15.453, Current:2.106 | topTokens[('.', 33), ('the', 23), ('to', 23), (',', 21), ('i', 20), ('and', 15), ('a', 15), ('in', 13), ('s', 13), ('er', 12)] | Training
2025-04-09 13:18:19 | 97500 | LR0.0003 | loss:2.6608 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-464.4767 | logitMax:-439.9749 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0034 | memoryGateLong:-0.0037 | memoryGateCurrent:0.0007 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.41989,W21:0.73018,W16:0.41221,W2:0.37741,W19:0.37206,W13:0.32016,W9:-0.24792,W3:-0.87745,W5:-1.56306 | memoryGatesShort:8.582, Long:-9.332, Current:1.749 | topTokens[(',', 43), ('the', 24), ('.', 19), ('i', 18), ('but', 13), ('ed', 13), ('is', 12), ('s', 12), ('it', 11), ('in', 10)] | Training
2025-04-09 13:24:25 | 100000 | LR0.0003 | loss:2.3489 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-474.3653 | logitMax:-447.8364 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0040 | memoryGateLong:-0.0042 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.22964,W21:0.67001,W16:0.39510,W19:0.37942,W13:0.32300,W2:0.29322,W9:-0.19397,W3:-0.79915,W5:-1.34638 | memoryGatesShort:10.063, Long:-10.603, Current:1.540 | topTokens[(',', 68), ('and', 34), ('a', 33), ('the', 23), ('.', 19), ('of', 16), ('!', 15), ('p', 12), ('they', 12), ('it', 10)] | Training
2025-04-09 13:30:23 | 102500 | LR0.0003 | loss:1.0311 | gradNorm:0.9978 | tokenCount:45000.0000 | logitMin:-551.2398 | logitMax:-519.7909 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0003 | longMemoryUsage:0.0003 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0022 | memoryGateLong:-0.0024 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.23452,W21:0.66325,W16:0.39276,W2:0.35694,W19:0.35213,W13:0.34496,W9:-0.18594,W3:-0.80742,W5:-1.40236 | memoryGatesShort:5.524, Long:-6.048, Current:1.524 | topTokens[(',', 70), ('the', 31), ('and', 19), ('of', 18), ('.', 17), ('a', 17), ('was', 15), ('their', 13), ('m', 11), ('p', 11)] | Training
2025-04-09 13:36:21 | 105000 | LR0.0003 | loss:1.6082 | gradNorm:0.9979 | tokenCount:45000.0000 | logitMin:-585.4335 | logitMax:-550.8436 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0003 | longMemoryUsage:0.0003 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0026 | memoryGateLong:-0.0027 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.16409,W21:0.61992,W13:0.36033,W2:0.35650,W16:0.34361,W19:0.31911,W9:-0.17016,W3:-0.74364,W5:-1.29870 | memoryGatesShort:6.588, Long:-6.871, Current:1.283 | topTokens[(',', 60), ('.', 28), ('to', 22), ('the', 18), ('and', 18), ('you', 18), ('ed', 15), ('was', 15), ('a', 13), ('of', 12)] | Training
2025-04-09 13:42:19 | 107500 | LR0.0003 | loss:3.8257 | gradNorm:0.9874 | tokenCount:45000.0000 | logitMin:-620.2872 | logitMax:-582.7755 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0030 | memoryGateLong:-0.0029 | memoryGateCurrent:0.0004 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.33227,W21:0.69363,W2:0.37891,W13:0.37592,W16:0.37273,W19:0.34652,W9:-0.21452,W3:-0.86085,W5:-1.47907 | memoryGatesShort:7.479, Long:-7.362, Current:0.883 | topTokens[(',', 80), ('.', 34), ('to', 27), ('a', 26), ('the', 24), ('bye', 24), ('in', 19), ('and', 18), ('of', 17), ('k', 16)] | Training
2025-04-09 13:48:29 | 110000 | LR0.0003 | loss:5.0073 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-509.0675 | logitMax:-479.4538 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0029 | memoryGateLong:-0.0030 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.58971,W21:0.78117,W2:0.44362,W16:0.40442,W13:0.38421,W19:0.37647,W9:-0.28422,W3:-1.00612,W5:-1.75270 | memoryGatesShort:7.165, Long:-7.588, Current:1.423 | topTokens[(',', 108), ('i', 22), ('the', 18), ('a', 17), ('me', 16), ('you', 16), ('and', 14), ('so', 12), ('all', 11), ('s', 10)] | Training
2025-04-09 13:54:35 | 112500 | LR0.0003 | loss:0.4483 | gradNorm:0.9526 | tokenCount:45000.0000 | logitMin:-597.5981 | logitMax:-559.8937 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0021 | memoryGateLong:-0.0021 | memoryGateCurrent:0.0004 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.10428,W21:0.57599,W13:0.36641,W16:0.36046,W2:0.35399,W19:0.29853,W9:-0.12700,W3:-0.72449,W5:-1.25533 | memoryGatesShort:5.156, Long:-5.139, Current:0.982 | topTokens[(',', 62), ('the', 27), ('and', 25), ('a', 23), ('of', 22), ('.', 21), ('it', 16), ('to', 16), ('their', 15), ('they', 15)] | Training
2025-04-09 14:00:41 | 115000 | LR0.0003 | loss:3.1970 | gradNorm:0.9833 | tokenCount:45000.0000 | logitMin:-636.7900 | logitMax:-598.4924 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0032 | memoryGateLong:-0.0032 | memoryGateCurrent:0.0004 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.19311,W21:0.61994,W13:0.37143,W16:0.35883,W2:0.35826,W19:0.30558,W9:-0.15888,W3:-0.76870,W5:-1.32923 | memoryGatesShort:8.033, Long:-7.985, Current:0.952 | topTokens[(',', 45), ('the', 34), ('of', 23), ('a', 22), ('.', 20), ('and', 17), ('ed', 16), ('p', 16), ('s', 12), ('was', 12)] | Training
2025-04-09 14:06:44 | 117500 | LR0.0003 | loss:3.4399 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-353.0196 | logitMax:-316.2825 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0047 | memoryGateLong:-0.0050 | memoryGateCurrent:0.0007 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.29436,W21:0.62663,W2:0.40502,W13:0.35938,W16:0.32636,W19:0.28229,W9:-0.18277,W3:-0.75931,W5:-1.40529 | memoryGatesShort:11.757, Long:-12.548, Current:1.792 | topTokens[('.', 92), ('i', 45), ('a', 39), ('it', 34), ('you', 30), ('not', 27), (',', 21), ('is', 21), ('to', 20), ('?', 20)] | Training
2025-04-09 14:13:00 | 120000 | LR0.0003 | loss:4.3620 | gradNorm:0.9993 | tokenCount:45000.0000 | logitMin:-528.0104 | logitMax:-496.8841 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0037 | memoryGateLong:-0.0037 | memoryGateCurrent:0.0004 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.56257,W21:0.75937,W2:0.42472,W16:0.37484,W13:0.36380,W19:0.34444,W9:-0.27141,W3:-0.93630,W5:-1.68370 | memoryGatesShort:9.276, Long:-9.260, Current:0.984 | topTokens[('.', 45), ('the', 37), ('and', 28), (',', 27), ('to', 20), ('er', 17), ('s', 15), ('(', 13), ('i', 12), ('of', 11)] | Training
2025-04-09 14:19:06 | 122500 | LR0.0003 | loss:5.1191 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-489.6330 | logitMax:-462.7374 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0084 | memoryGateLong:-0.0090 | memoryGateCurrent:0.0010 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.05688,W21:0.96286,W2:0.51015,W16:0.45537,W19:0.41772,W13:0.41439,W9:-0.42698,W3:-1.25156,W5:-2.21706 | memoryGatesShort:21.021, Long:-22.487, Current:2.466 | topTokens[('.', 86), ('i', 63), ('you', 23), ('the', 20), ('that', 19), ('kit', 14), ('to', 14), ('?', 14), ('just', 12), ('', 10)] | Training
2025-04-09 14:25:16 | 125000 | LR0.0003 | loss:1.9573 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-443.1051 | logitMax:-410.3805 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0006 | longMemoryUsage:0.0006 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0053 | memoryGateLong:-0.0057 | memoryGateCurrent:0.0008 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.43085,W21:0.68184,W2:0.44239,W16:0.42623,W13:0.40684,W19:0.31640,W9:-0.23347,W3:-0.93313,W5:-1.59640 | memoryGatesShort:13.190, Long:-14.298, Current:2.108 | topTokens[('-', 52), (':', 52), ('0', 46), ("'", 33), ('2', 32), ('4', 31), ("'", 30), ('-', 23), ('5', 23), ('i', 21)] | Training
2025-04-09 14:31:16 | 127500 | LR0.0003 | loss:2.4796 | gradNorm:0.9997 | tokenCount:45000.0000 | logitMin:-421.9559 | logitMax:-389.8117 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0006 | longMemoryUsage:0.0006 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0048 | memoryGateLong:-0.0049 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.26491,W21:0.62565,W16:0.42336,W13:0.40526,W2:0.40199,W19:0.30721,W9:-0.19486,W3:-0.86713,W5:-1.41910 | memoryGatesShort:12.015, Long:-12.319, Current:1.304 | topTokens[("'", 44), ('-', 42), ('i', 38), (':', 33), (',', 27), ('to', 25), ('you', 25), ("'", 20), ('0', 18), ('?', 17)] | Training
2025-04-09 14:37:26 | 130000 | LR0.0003 | loss:4.8030 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-461.6186 | logitMax:-436.7583 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0002 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0006 | longMemoryUsage:0.0006 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0048 | memoryGateLong:-0.0050 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.48990,W21:0.72135,W16:0.45490,W13:0.42200,W2:0.41915,W19:0.34682,W9:-0.26611,W3:-1.00400,W5:-1.64359 | memoryGatesShort:12.037, Long:-12.560, Current:1.523 | topTokens[('.', 84), ('i', 62), (':', 29), ('<', 21), ('you', 20), ('3', 18), ('?', 17), ('kit', 12), ('d', 12), ('but', 11)] | Training
2025-04-09 14:43:34 | 132500 | LR0.0003 | loss:3.1874 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-430.6235 | logitMax:-404.8472 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0036 | memoryGateLong:-0.0037 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.15731,W21:0.59252,W16:0.40297,W13:0.37778,W19:0.32554,W2:0.31515,W9:-0.15919,W3:-0.78498,W5:-1.27449 | memoryGatesShort:8.930, Long:-9.216, Current:1.285 | topTokens[(',', 62), ('.', 26), ('i', 24), ('to', 22), ('the', 20), ('a', 18), ('and', 17), ('you', 17), ('s', 12), ("'s", 12)] | Training
2025-04-09 14:49:44 | 135000 | LR0.0003 | loss:3.0319 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-450.9147 | logitMax:-422.2936 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0002 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0089 | memoryGateLong:-0.0096 | memoryGateCurrent:0.0011 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.24804,W21:0.63845,W16:0.40098,W13:0.35864,W2:0.35064,W19:0.35040,W9:-0.18929,W3:-0.83984,W5:-1.36876 | memoryGatesShort:22.284, Long:-23.939, Current:2.656 | topTokens[(',', 65), ('kiss', 58), ('hug', 56), ('and', 45), ('s', 43), ('i', 25), ('.', 21), ('the', 16), ('you', 15), ('to', 13)] | Training
2025-04-09 14:55:51 | 137500 | LR0.0003 | loss:3.1584 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-430.0001 | logitMax:-401.7728 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0032 | memoryGateLong:-0.0035 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.15616,W21:0.62285,W16:0.37445,W13:0.34440,W19:0.34000,W2:0.31957,W9:-0.15600,W3:-0.78066,W5:-1.26813 | memoryGatesShort:8.113, Long:-8.659, Current:1.546 | topTokens[('and', 58), ('to', 31), ('you', 27), ('love', 24), ('the', 22), ('i', 21), ('be', 19), ('kiss', 18), ('fam', 18), ('your', 14)] | Training
2025-04-09 15:02:01 | 140000 | LR0.0003 | loss:3.9699 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-478.9718 | logitMax:-453.5269 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0064 | memoryGateLong:-0.0068 | memoryGateCurrent:0.0008 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.17207,W21:0.61013,W16:0.37397,W13:0.34685,W19:0.33876,W2:0.29713,W9:-0.13331,W3:-0.79581,W5:-1.25687 | memoryGatesShort:15.931, Long:-16.917, Current:1.986 | topTokens[('i', 30), ('.', 30), ('a', 21), ('to', 19), (',', 19), ('the', 16), ('s', 14), ('*', 14), ('of', 11), (')', 11)] | Training
2025-04-09 15:08:06 | 142500 | LR0.0003 | loss:3.6435 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-412.5083 | logitMax:-386.3251 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0040 | memoryGateLong:-0.0041 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.46011,W21:0.73885,W19:0.40103,W2:0.39557,W16:0.38652,W13:0.36354,W9:-0.24707,W3:-0.97970,W5:-1.57667 | memoryGatesShort:10.042, Long:-10.251, Current:1.209 | topTokens[('.', 59), ('was', 38), (',', 30), ('were', 29), ('you', 24), ('the', 23), ('i', 22), ('elodie', 21), ('!', 19), ('to', 16)] | Training
2025-04-09 15:14:04 | 145000 | LR0.0003 | loss:3.7120 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-392.4457 | logitMax:-366.1660 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0046 | memoryGateLong:-0.0048 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.50302,W21:0.76116,W2:0.40551,W16:0.39657,W19:0.38612,W13:0.35426,W9:-0.26768,W3:-0.99521,W5:-1.60308 | memoryGatesShort:11.492, Long:-11.933, Current:1.441 | topTokens[(',', 81), ('and', 62), ('.', 44), ('i', 30), ('the', 22), ('elodie', 21), ('s', 20), ('to', 17), ('you', 13), ('brain', 13)] | Training
2025-04-09 15:20:30 | 147500 | LR0.0003 | loss:4.6793 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-429.8275 | logitMax:-406.2876 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0004 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0046 | memoryGateLong:-0.0050 | memoryGateCurrent:0.0008 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.82820,W21:0.90518,W2:0.49863,W19:0.43424,W16:0.43267,W13:0.37306,W9:-0.35743,W3:-1.22661,W5:-1.95922 | memoryGatesShort:11.597, Long:-12.614, Current:2.017 | topTokens[('.', 77), ('i', 35), ('?', 19), ('the', 18), ('and', 17), ('you', 15), ('s', 14), (',', 13), ('is', 12), ('im', 12)] | Training
2025-04-09 15:26:56 | 150000 | LR0.0003 | loss:2.2429 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-410.6011 | logitMax:-381.2383 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0033 | memoryGateLong:-0.0035 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.26862,W21:0.66118,W2:0.40676,W16:0.38480,W13:0.35274,W19:0.32922,W9:-0.19853,W3:-0.87044,W5:-1.38717 | memoryGatesShort:8.246, Long:-8.783, Current:1.537 | topTokens[(',', 41), (':', 39), ('i', 30), ("'", 29), ('to', 29), ('-', 29), ("'", 21), ('?', 18), ('charis', 17), ('today', 16)] | Training
2025-04-09 15:33:04 | 152500 | LR0.0003 | loss:1.6198 | gradNorm:0.9991 | tokenCount:45000.0000 | logitMin:-380.7592 | logitMax:-348.7689 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0004 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0039 | memoryGateLong:-0.0042 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.18206,W21:0.61648,W2:0.38902,W16:0.38148,W13:0.36890,W19:0.31640,W9:-0.18562,W3:-0.82552,W5:-1.29314 | memoryGatesShort:9.810, Long:-10.392, Current:1.582 | topTokens[(':', 39), (',', 36), ('i', 32), ('-', 28), ("'", 25), ('must', 25), ('have', 24), ('!', 23), ("'", 20), ('to', 20)] | Training
2025-04-09 15:39:14 | 155000 | LR0.0003 | loss:3.8201 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-419.8095 | logitMax:-394.0747 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortMemoryUsage:0.0005 | longMemoryUsage:0.0005 | shortMemorySparsity:0.0000 | longMemorySparsity:0.0000 | memoryGateShort:0.0051 | memoryGateLong:-0.0053 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.17661,W21:0.61241,W16:0.38341,W13:0.37753,W19:0.34529,W2:0.33151,W9:-0.17626,W3:-0.82901,W5:-1.26971 | memoryGatesShort:12.652, Long:-13.176, Current:1.524 | topTokens[('to', 28), ('the', 27), ('.', 24), ('of', 24), (',', 23), ('s', 21), ('i', 19), ('and', 17), ('in', 17), ('that', 15)] | Training

--- 2025-04-09 15:43:03 --- babyLLM 'right, last time i got to step 155482... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 155482! what am i learning today?' - charis: ''
2025-04-09 15:48:17 | 2500 | LR0.0003 | loss:2.4740 | gradNorm:0.9984 | logitMin:-427.2857 | logitMax:-401.1091 | scheduledSampling:0.0000 | tokenCount:45000.0000 | memoryGateShort:0.0032 | memoryGateLong:-0.0033 | memoryGateCurrent:0.0005 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:0.97813,W21:0.52573,W16:0.35975,W13:0.35113,W19:0.33016,W2:0.28039,W9:-0.12307,W3:-0.68445,W5:-1.05909 | memoryGatesShort:7.898, Long:-8.263, Current:1.365 | topTokens[(',', 94), ('the', 26), ('i', 23), ('s', 17), ('it', 16), ('and', 15), ('.', 15), ('you', 13), ('in', 9), ('s', 9)] | Training
2025-04-09 15:53:32 | 5000 | LR0.0003 | loss:2.1916 | gradNorm:0.9985 | tokenCount:45000.0000 | logitMin:-472.3551 | logitMax:-442.6795 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0039 | memoryGateLong:-0.0042 | memoryGateCurrent:0.0007 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:0.89590,W21:0.47633,W13:0.31953,W16:0.31874,W19:0.30437,W2:0.27975,W9:-0.08386,W3:-0.61005,W5:-0.93932 | memoryGatesShort:9.679, Long:-10.445, Current:1.765 | topTokens[(',', 69), ('i', 33), ('the', 32), ('of', 19), ('you', 18), ('to', 17), ('it', 17), ('.', 15), ('and', 15), ('me', 12)] | Training
2025-04-09 15:58:55 | 7500 | LR0.0003 | loss:1.4415 | gradNorm:0.9996 | tokenCount:45000.0000 | logitMin:-475.6995 | logitMax:-443.8185 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0024 | memoryGateLong:-0.0025 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:0.91330,W21:0.49156,W16:0.34016,W19:0.33093,W13:0.32698,W2:0.26324,W9:-0.09135,W3:-0.65254,W5:-0.96106 | memoryGatesShort:6.093, Long:-6.315, Current:1.222 | topTokens[(',', 59), ('the', 30), ('and', 24), ('of', 22), ('.', 22), ('their', 16), ('a', 16), ('it', 14), ('was', 13), ('to', 12)] | Training
2025-04-09 16:04:18 | 10000 | LR0.0003 | loss:1.7531 | gradNorm:0.9995 | tokenCount:45000.0000 | logitMin:-533.0475 | logitMax:-501.6675 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0022 | memoryGateLong:-0.0022 | memoryGateCurrent:0.0004 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:0.91642,W21:0.50606,W19:0.34135,W16:0.32998,W13:0.30826,W2:0.26752,W9:-0.09725,W3:-0.64926,W5:-0.96198 | memoryGatesShort:5.504, Long:-5.482, Current:0.978 | topTokens[(',', 99), ('i', 35), ('the', 26), ('me', 17), ('you', 15), ('to', 14), ('and', 12), ('s', 10), ("'m", 10), ('ing', 10)] | Training
2025-04-09 16:09:38 | 12500 | LR0.0003 | loss:4.4420 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-507.4453 | logitMax:-476.5514 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0038 | memoryGateLong:-0.0039 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.10849,W21:0.58069,W19:0.38791,W16:0.35135,W13:0.30860,W2:0.28733,W9:-0.16479,W3:-0.75882,W5:-1.14538 | memoryGatesShort:9.434, Long:-9.752, Current:1.318 | topTokens[(',', 56), ('i', 38), ('.', 33), ('you', 25), ('to', 24), ('the', 21), ('a', 16), ('me', 14), ("'s", 14), ('it', 13)] | Training
2025-04-09 16:14:55 | 15000 | LR0.0003 | loss:4.6032 | gradNorm:0.9997 | tokenCount:45000.0000 | logitMin:-502.2262 | logitMax:-472.6555 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0036 | memoryGateLong:-0.0037 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.18119,W21:0.61079,W19:0.40732,W16:0.34761,W13:0.30106,W2:0.29778,W9:-0.17736,W3:-0.80816,W5:-1.20700 | memoryGatesShort:8.974, Long:-9.249, Current:1.275 | topTokens[("'", 46), ("'", 39), (':', 31), (',', 20), ('you', 17), ('i', 17), ('charis', 14), ('.', 13), ('the', 13), ('prom', 13)] | Training
2025-04-09 16:20:12 | 17500 | LR0.0003 | loss:4.8284 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-471.5686 | logitMax:-446.3943 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0028 | memoryGateLong:-0.0030 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.47855,W21:0.71006,W19:0.46780,W16:0.39230,W2:0.37085,W13:0.31212,W9:-0.27550,W3:-1.00049,W5:-1.51286 | memoryGatesShort:7.006, Long:-7.485, Current:1.480 | topTokens[(',', 113), ('i', 47), ('u', 27), ('im', 16), ('it', 15), ('s', 13), ('like', 10), ('just', 10), ('we', 10), ('you', 9)] | Training
2025-04-09 16:25:40 | 20000 | LR0.0003 | loss:2.5169 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-445.4466 | logitMax:-419.4253 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0032 | memoryGateLong:-0.0033 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.30636,W21:0.64414,W19:0.45040,W16:0.40697,W13:0.31178,W2:0.29309,W9:-0.20458,W3:-0.90791,W5:-1.35073 | memoryGatesShort:8.013, Long:-8.370, Current:1.357 | topTokens[(',', 72), ('a', 33), ('the', 21), ('and', 21), ('.', 20), ('to', 19), ('in', 18), ('of', 16), ('ed', 14), ('was', 14)] | Training
2025-04-09 16:31:01 | 22500 | LR0.0003 | loss:4.7735 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-496.3983 | logitMax:-471.3858 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0039 | memoryGateLong:-0.0042 | memoryGateCurrent:0.0007 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.58622,W21:0.73495,W19:0.48645,W16:0.44265,W2:0.38645,W13:0.31755,W9:-0.28787,W3:-1.08437,W5:-1.64257 | memoryGatesShort:9.832, Long:-10.499, Current:1.667 | topTokens[(',', 65), ('i', 27), ('the', 17), ("'", 14), (':', 14), ('a', 13), ('0', 13), ('.', 11), ('-', 11), ('4', 11)] | Training
2025-04-09 16:36:19 | 25000 | LR0.0003 | loss:4.3887 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-476.5195 | logitMax:-452.1178 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0044 | memoryGateLong:-0.0046 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.93570,W21:0.87266,W19:0.53675,W16:0.49218,W2:0.48278,W13:0.29485,W9:-0.40238,W3:-1.29856,W5:-1.98662 | memoryGatesShort:10.951, Long:-11.414, Current:1.464 | topTokens[('i', 49), (',', 36), ('.', 33), ('and', 22), ('to', 18), ('me', 17), ('of', 11), ('but', 11), ('s', 11), ('she', 11)] | Training
2025-04-09 16:41:31 | 27500 | LR0.0003 | loss:3.5427 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-420.8347 | logitMax:-394.0515 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0098 | memoryGateLong:-0.0112 | memoryGateCurrent:0.0018 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.31533,W21:1.02304,W2:0.68451,W19:0.54931,W16:0.52266,W13:0.29267,W9:-0.52627,W3:-1.57424,W5:-2.37551 | memoryGatesShort:24.608, Long:-28.005, Current:4.398 | topTokens[('should', 64), (',', 36), ('the', 31), ('!', 30), ('and', 27), ('.', 25), ('charis', 18), ('brain', 15), ('i', 14), ('kevin', 13)] | Training
2025-04-09 16:46:58 | 30000 | LR0.0003 | loss:0.8992 | gradNorm:0.9981 | tokenCount:45000.0000 | logitMin:-419.4324 | logitMax:-389.7657 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0026 | memoryGateLong:-0.0029 | memoryGateCurrent:0.0007 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.39708,W21:0.63381,W2:0.45947,W16:0.41883,W19:0.39223,W13:0.27833,W9:-0.23975,W3:-0.97978,W5:-1.41683 | memoryGatesShort:6.450, Long:-7.310, Current:1.860 | topTokens[(',', 61), ('a', 29), ('.', 21), ('and', 16), ('their', 15), ('to', 15), ('they', 14), ('s', 14), ('m', 13), ('ed', 13)] | Training
2025-04-09 16:52:26 | 32500 | LR0.0003 | loss:0.8986 | gradNorm:0.9666 | tokenCount:45000.0000 | logitMin:-517.8234 | logitMax:-481.4746 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0017 | memoryGateLong:-0.0016 | memoryGateCurrent:0.0003 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.25625,W21:0.59779,W16:0.40903,W2:0.39139,W19:0.36492,W13:0.28906,W9:-0.18987,W3:-0.89815,W5:-1.27141 | memoryGatesShort:4.157, Long:-4.013, Current:0.856 | topTokens[(',', 71), ('of', 29), ('the', 27), ('to', 21), ('a', 20), ('and', 17), ('s', 15), ('it', 14), ('.', 14), ('that', 13)] | Training
2025-04-09 16:58:32 | 35000 | LR0.0003 | loss:0.6109 | gradNorm:0.9651 | tokenCount:45000.0000 | logitMin:-598.9586 | logitMax:-558.1637 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0016 | memoryGateLong:-0.0017 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.22077,W21:0.55603,W2:0.41346,W16:0.39751,W19:0.34325,W13:0.31709,W9:-0.19015,W3:-0.86771,W5:-1.24074 | memoryGatesShort:4.085, Long:-4.219, Current:1.134 | topTokens[(',', 64), ('the', 22), ('and', 16), ('ed', 15), ('their', 15), ('was', 11), ('that', 11), ('a', 11), ('of', 11), ('!', 11)] | Training
2025-04-09 17:04:02 | 37500 | LR0.0003 | loss:4.6886 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-547.8118 | logitMax:-514.9128 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0041 | memoryGateLong:-0.0041 | memoryGateCurrent:0.0003 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.37731,W21:0.61043,W16:0.42446,W2:0.40872,W19:0.37642,W13:0.31282,W9:-0.23850,W3:-0.95730,W5:-1.36887 | memoryGatesShort:10.302, Long:-10.173, Current:0.871 | topTokens[('.', 54), (',', 42), ('a', 22), ('?', 22), ('i', 20), ('you', 17), ('the', 16), ('to', 14), ('m', 12), ('!', 11)] | Training
2025-04-09 17:10:04 | 40000 | LR0.0003 | loss:4.5935 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-490.5034 | logitMax:-459.5577 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0020 | memoryGateLong:-0.0020 | memoryGateCurrent:0.0004 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.69338,W21:0.73084,W2:0.50425,W16:0.45443,W19:0.43403,W13:0.33019,W9:-0.34309,W3:-1.16558,W5:-1.70415 | memoryGatesShort:5.075, Long:-5.065, Current:0.990 | topTokens[('.', 77), ('i', 34), ('?', 20), ('lo', 17), ('it', 16), ('no', 16), ('a', 14), ('you', 14), ('s', 12), ('not', 12)] | Training
2025-04-09 17:16:01 | 42500 | LR0.0003 | loss:1.9775 | gradNorm:0.9945 | tokenCount:45000.0000 | logitMin:-504.7562 | logitMax:-470.4085 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0023 | memoryGateLong:-0.0023 | memoryGateCurrent:0.0004 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.34705,W21:0.61409,W2:0.41196,W16:0.38973,W19:0.38908,W13:0.28982,W9:-0.23014,W3:-0.92284,W5:-1.34236 | memoryGatesShort:5.696, Long:-5.657, Current:0.961 | topTokens[(',', 84), ('i', 47), ('the', 35), ('you', 21), ('to', 17), ('of', 15), ('this', 14), ('me', 13), ('it', 11), ('in', 10)] | Training
2025-04-09 17:22:06 | 45000 | LR0.0003 | loss:3.2972 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-449.2363 | logitMax:-417.6550 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0050 | memoryGateLong:-0.0055 | memoryGateCurrent:0.0009 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.44383,W21:0.67161,W2:0.43696,W19:0.43568,W16:0.39535,W13:0.27104,W9:-0.27731,W3:-0.98982,W5:-1.44437 | memoryGatesShort:12.535, Long:-13.868, Current:2.333 | topTokens[(',', 58), ('will', 40), ('you', 31), ('.', 31), ('i', 30), ('the', 21), ('it', 20), ('to', 17), ('and', 15), ('s', 14)] | Training
2025-04-09 17:27:53 | 47500 | LR0.0003 | loss:1.9145 | gradNorm:0.9997 | tokenCount:45000.0000 | logitMin:-366.5314 | logitMax:-329.8235 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0067 | memoryGateLong:-0.0074 | memoryGateCurrent:0.0011 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.34888,W21:0.62315,W2:0.44767,W19:0.39572,W16:0.36067,W13:0.25703,W9:-0.27579,W3:-0.91454,W5:-1.29712 | memoryGatesShort:16.710, Long:-18.409, Current:2.699 | topTokens[('will', 121), ('!', 52), ('the', 43), ('.', 41), ('elodie', 34), (',', 31), ('kevin', 30), ('charis', 22), ('and', 19), ('you', 18)] | Training
2025-04-09 17:33:24 | 50000 | LR0.0003 | loss:5.3423 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-484.9187 | logitMax:-457.8510 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0037 | memoryGateLong:-0.0038 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.75531,W21:0.78061,W2:0.49333,W19:0.48421,W16:0.39273,W13:0.25995,W9:-0.38602,W3:-1.17468,W5:-1.67222 | memoryGatesShort:9.281, Long:-9.516, Current:1.235 | topTokens[(',', 76), ('i', 42), ('and', 19), ('the', 17), ('to', 17), ('.', 15), ('a', 15), ('like', 14), ('me', 14), ('my', 13)] | Training
2025-04-09 17:38:49 | 52500 | LR0.0003 | loss:4.4555 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-473.4534 | logitMax:-446.8804 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0034 | memoryGateLong:-0.0036 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.13163,W21:0.89031,W2:0.59884,W19:0.52828,W16:0.44388,W13:0.29178,W9:-0.49690,W3:-1.43463,W5:-2.03333 | memoryGatesShort:8.623, Long:-9.006, Current:1.383 | topTokens[('to', 41), ('and', 22), ('the', 21), ('.', 21), ('i', 20), (',', 18), ('that', 15), ('a', 15), ('it', 11), ('of', 9)] | Training
2025-04-09 17:44:22 | 55000 | LR0.0003 | loss:4.2732 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-422.8549 | logitMax:-396.9618 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0034 | memoryGateLong:-0.0036 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.07427,W21:0.85996,W2:0.54940,W19:0.52374,W16:0.47258,W13:0.27363,W9:-0.47516,W3:-1.40546,W5:-1.95017 | memoryGatesShort:8.599, Long:-8.974, Current:1.375 | topTokens[(',', 32), ('.', 31), ('the', 30), ('and', 24), ('on', 19), ('al', 15), ('of', 13), ('her', 12), ('ance', 11), ('a', 11)] | Training
2025-04-09 17:51:01 | 57500 | LR0.0003 | loss:0.9796 | gradNorm:0.9994 | tokenCount:45000.0000 | logitMin:-444.1004 | logitMax:-414.3580 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0017 | memoryGateLong:-0.0018 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.28734,W21:0.55406,W16:0.38591,W2:0.37773,W19:0.35332,W13:0.29880,W9:-0.17681,W3:-0.91085,W5:-1.22050 | memoryGatesShort:4.320, Long:-4.480, Current:1.160 | topTokens[(',', 58), ('ed', 19), ('and', 18), ('.', 18), ('of', 17), ('the', 16), ('a', 15), ('their', 15), ('to', 14), ('was', 11)] | Training
2025-04-09 17:57:38 | 60000 | LR0.0003 | loss:4.2155 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-412.4164 | logitMax:-383.1911 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0035 | memoryGateLong:-0.0035 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.53680,W21:0.65259,W16:0.42016,W2:0.40719,W19:0.38229,W13:0.29947,W9:-0.25251,W3:-1.05640,W5:-1.44829 | memoryGatesShort:8.666, Long:-8.873, Current:1.208 | topTokens[(',', 52), ('.', 47), ('!', 37), ('?', 35), ('you', 26), ('is', 21), ('the', 19), ('it', 18), ('to', 16), ('he', 16)] | Training
2025-04-09 18:03:18 | 62500 | LR0.0003 | loss:3.5132 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-477.3250 | logitMax:-451.3110 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0045 | memoryGateLong:-0.0048 | memoryGateCurrent:0.0007 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.47159,W21:0.58494,W2:0.44282,W16:0.39487,W19:0.32754,W13:0.28097,W9:-0.24547,W3:-0.93458,W5:-1.38014 | memoryGatesShort:11.248, Long:-12.107, Current:1.858 | topTokens[('?', 97), ('.', 80), ('is', 58), ('you', 44), ('!', 37), ('equ', 22), ('als', 20), ('plus', 19), ('what', 19), ('i', 16)] | Training
2025-04-09 18:08:38 | 65000 | LR0.0003 | loss:2.2440 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-460.0245 | logitMax:-432.8278 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0028 | memoryGateLong:-0.0030 | memoryGateCurrent:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.14196,W21:0.49676,W16:0.36272,W2:0.34435,W19:0.29907,W13:0.28635,W9:-0.16254,W3:-0.72795,W5:-1.08670 | memoryGatesShort:6.912, Long:-7.470, Current:1.558 | topTokens[('.', 39), ('?', 36), ('!', 23), ('is', 22), (',', 22), ('you', 18), ('the', 17), ('a', 16), ('and', 15), ('it', 11)] | Training
2025-04-09 18:14:04 | 67500 | LR0.0003 | loss:2.0124 | gradNorm:0.9971 | tokenCount:45000.0000 | logitMin:-462.5922 | logitMax:-430.0451 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0019 | memoryGateLong:-0.0018 | memoryGateCurrent:0.0003 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.10431,W21:0.49753,W16:0.38690,W2:0.30717,W19:0.30266,W13:0.29886,W9:-0.14733,W3:-0.72716,W5:-1.06719 | memoryGatesShort:4.772, Long:-4.606, Current:0.834 | topTokens[(',', 51), ('the', 32), ('.', 27), ('a', 25), ('to', 25), ('and', 22), ('of', 17), ('it', 15), ('was', 11), ('their', 11)] | Training
2025-04-09 18:19:43 | 70000 | LR0.0003 | loss:1.7018 | gradNorm:0.9883 | tokenCount:45000.0000 | logitMin:-541.0192 | logitMax:-510.6031 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0020 | memoryGateLong:-0.0020 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.06159,W21:0.47834,W16:0.37272,W2:0.30882,W19:0.29896,W13:0.27871,W9:-0.12386,W3:-0.69144,W5:-1.02689 | memoryGatesShort:4.942, Long:-5.124, Current:1.182 | topTokens[(',', 96), ('you', 33), ('i', 29), ('s', 20), ('the', 20), ('in', 15), ('f', 13), ('your', 13), ('and', 10), ('me', 10)] | Training
2025-04-09 18:25:45 | 72500 | LR0.0003 | loss:1.5085 | gradNorm:0.9779 | tokenCount:45000.0000 | logitMin:-605.8299 | logitMax:-569.3202 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0017 | memoryGateLong:-0.0018 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:0.98050,W21:0.44801,W16:0.33328,W2:0.31917,W19:0.27862,W13:0.25745,W9:-0.09555,W3:-0.62241,W5:-0.94000 | memoryGatesShort:4.355, Long:-4.615, Current:1.260 | topTokens[(',', 73), ('i', 30), ('the', 28), ('to', 21), ('and', 16), ('.', 16), ('of', 15), ('you', 14), ('that', 13), ('not', 11)] | Training
2025-04-09 18:31:18 | 75000 | LR0.0003 | loss:2.5088 | gradNorm:0.9968 | tokenCount:45000.0000 | logitMin:-548.0172 | logitMax:-510.5540 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0028 | memoryGateLong:-0.0029 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.04394,W21:0.46673,W16:0.34168,W2:0.30060,W19:0.29332,W13:0.26210,W9:-0.10338,W3:-0.65928,W5:-0.98784 | memoryGatesShort:7.009, Long:-7.330, Current:1.321 | topTokens[(',', 62), ('.', 34), ('a', 27), ('is', 20), ('the', 18), ('?', 18), ('was', 16), ('and', 16), ('i', 16), ('you', 16)] | Training
2025-04-09 18:36:40 | 77500 | LR0.0003 | loss:4.0284 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-543.6821 | logitMax:-513.1701 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0050 | memoryGateLong:-0.0055 | memoryGateCurrent:0.0009 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.18841,W21:0.51966,W16:0.33684,W2:0.33569,W19:0.30173,W13:0.24448,W9:-0.15332,W3:-0.72571,W5:-1.09450 | memoryGatesShort:12.408, Long:-13.684, Current:2.276 | topTokens[('.', 61), ('?', 58), (',', 37), ('to', 37), ('you', 29), ('is', 28), ('i', 25), ('a', 20), ('will', 20), ('was', 18)] | Training
2025-04-09 18:42:04 | 80000 | LR0.0003 | loss:0.5749 | gradNorm:0.9668 | tokenCount:45000.0000 | logitMin:-502.2430 | logitMax:-462.6616 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | memoryGateShort:0.0012 | memoryGateLong:-0.0013 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.05908,W21:0.46774,W2:0.33790,W16:0.33417,W19:0.27624,W13:0.25655,W9:-0.11616,W3:-0.66984,W5:-0.98901 | memoryGatesShort:3.112, Long:-3.347, Current:1.235 | topTokens[(',', 56), ('the', 33), ('.', 26), ('to', 19), ('and', 19), ('a', 17), ('of', 15), ('you', 10), ('ed', 10), ('they', 9)] | Training
2025-04-09 19:11:34 | 2500 | LR0.0003 | loss:5.2157 | gradNorm:0.9996 | logitMin:-526.8810 | logitMax:-497.1856 | scheduledSampling:0.0000 | tokenCount:44982.0000 | memoryGateShort:7.2125 | memoryGateLong:-7.3591 | memoryGateCurrent:1.1462 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:nan | windowWeightsW25:1.41524,W21:0.64403,W16:0.37836,W2:0.36926,W19:0.36515,W13:0.24923,W9:-0.22981,W3:-0.91681,W5:-1.32914 | topTokens[('the', 43), ('.', 42), ('to', 25), ('and', 25), (',', 24), ('i', 21), ('ed', 21), ('a', 19), ('y', 18), ('ing', 14)] | [('the', 43), ('.', 42), ('to', 25), ('and', 25), (',', 24), ('i', 21), ('ed', 21), ('a', 19), ('y', 18), ('ing', 14)] | babyLLM.py 2500
2025-04-09 19:22:23 | 2500 | LR0.0003 | loss:4.7725 | gradNorm:0.9996 | logitMin:-452.0297 | logitMax:-427.0963 | scheduledSampling:0.0000 | tokenCount:44982.0000 | memoryGateShort:10.3557 | memoryGateLong:-11.2051 | memoryGateCurrent:1.8490 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0006 | windowWeightsW25:1.70441,W21:0.72082,W2:0.45885,W16:0.42974,W19:0.41946,W13:0.24645,W9:-0.31734,W3:-1.10411,W5:-1.62338 | topTokens[(',', 61), ('i', 45), ('.', 39), ('is', 28), ('?', 27), ('you', 20), ('s', 15), ('!', 15), ('the', 14), ('a', 14)] | tokenPerfect: 8394 / 44982  18.66% | babyLLM.py 2500

--- 2025-04-09 19:25:57 --- babyLLM 'right, last time i got to step 248400... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 248400! what am i learning today?' - charis: ''
2025-04-09 19:31:06 | 2500 | LR0.0003 | loss:2.3035 | gradNorm:0.9994 | logitMin:-433.8242 | logitMax:-406.4986 | scheduledSampling:0.0000 | tokenCount:45000.0000 | memoryGateShort:9.1519 | memoryGateLong:-10.1499 | memoryGateCurrent:1.9980 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0006 | windowWeightsW25:1.10582,W21:0.48599,W2:0.35778,W16:0.33449,W19:0.32541,W13:0.19504,W9:-0.14444,W3:-0.68367,W5:-1.02175 | topTokens[('?', 51), ('.', 51), ('you', 37), ('i', 29), (',', 26), ('do', 21), ('to', 21), ('is', 19), ('ace', 16), ('a', 15)] | tokenPerfect: 22109 / 45000  49.13% | babyLLM.py 2500
2025-04-09 19:36:11 | 5000 | LR0.0003 | loss:5.1905 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-418.1696 | logitMax:-391.1776 | memoryGateShort:9.3493 | memoryGateLong:-9.7105 | memoryGateCurrent:1.3612 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.36260,W21:0.58966,W2:0.39522,W19:0.37589,W16:0.35964,W13:0.18857,W9:-0.21501,W3:-0.86139,W5:-1.24850 | topTokens[(',', 113), ('.', 78), ('i', 62), ('?', 54), ('you', 43), ('to', 32), ('the', 31), ('of', 29), ('on', 29), ('do', 27)] | tokenPerfect: 30460 / 90000  33.84% | babyLLM.py 2500
2025-04-09 19:41:28 | 7500 | LR0.0003 | loss:3.5718 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-469.7229 | logitMax:-442.8818 | memoryGateShort:10.2289 | memoryGateLong:-10.9940 | memoryGateCurrent:1.7651 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.27121,W21:0.54312,W2:0.38498,W16:0.35106,W19:0.34722,W13:0.19422,W9:-0.17097,W3:-0.80674,W5:-1.16468 | topTokens[(',', 139), ('.', 106), ('i', 93), ('?', 74), ('the', 58), ('you', 55), ('a', 45), ('to', 40), ('is', 37), ('do', 36)] | tokenPerfect: 44777 / 135000  33.17% | babyLLM.py 2500
2025-04-09 19:53:05 | 10000 | LR0.0003 | loss:3.8536 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-424.0875 | logitMax:-398.2006 | memoryGateShort:9.0389 | memoryGateLong:-9.7164 | memoryGateCurrent:1.6775 | embedMean:0.0000 | embedStd:0.0004 | embedSparsity:0.0000 | meanActivation:-0.0002 | activationSparsity:0.0000 | windowCount:0.0072 | windowEntropy:0.0013 | shortDecay:0.0005 | longDecay:0.0006 | windowWeightsW25:1.36916,W21:0.61098,W2:0.38055,W19:0.37480,W16:0.36630,W13:0.19304,W9:-0.19124,W3:-0.88618,W5:-1.27075 | topTokens[(',', 167), ('i', 119), ('.', 118), ('the', 100), ('?', 74), ('to', 71), ('a', 60), ('you', 58), ('of', 48), ('is', 46)] | babyLLM.py 2500
2025-04-09 19:58:21 | 12500 | LR0.0003 | loss:0.8476 | gradNorm:0.9957 | tokenCount:45000.0000 | logitMin:-414.3053 | logitMax:-381.1186 | memoryGateShort:5.6126 | memoryGateLong:-6.1480 | memoryGateCurrent:1.5354 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.17775,W21:0.50429,W16:0.36493,W2:0.34828,W19:0.32738,W13:0.23784,W9:-0.11876,W3:-0.78453,W5:-1.10434 | topTokens[(',', 231), ('.', 139), ('i', 124), ('the', 124), ('to', 81), ('?', 75), ('a', 75), ('of', 66), ('you', 59), ('and', 54)] | tokenPerfect: 33310 / 45000  74.02% | babyLLM.py 2500
2025-04-09 20:03:32 | 15000 | LR0.0003 | loss:4.0897 | gradNorm:0.9993 | tokenCount:45000.0000 | logitMin:-514.3787 | logitMax:-483.8861 | memoryGateShort:7.1525 | memoryGateLong:-7.2358 | memoryGateCurrent:1.0834 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.35178,W21:0.57823,W16:0.38270,W19:0.36113,W2:0.35945,W13:0.23942,W9:-0.15667,W3:-0.91086,W5:-1.25743 | topTokens[(',', 322), ('the', 153), ('.', 148), ('i', 142), ('a', 104), ('to', 98), ('?', 78), ('of', 76), ('you', 71), ('it', 68)] | tokenPerfect: 47559 / 90000  52.84% | babyLLM.py 2500
2025-04-09 20:08:42 | 17500 | LR0.0003 | loss:3.3705 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-484.2176 | logitMax:-456.6223 | memoryGateShort:8.1121 | memoryGateLong:-8.5525 | memoryGateCurrent:1.4404 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0002 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.32644,W21:0.56526,W2:0.39316,W16:0.38854,W19:0.35545,W13:0.23502,W9:-0.14392,W3:-0.89620,W5:-1.27627 | topTokens[(',', 376), ('the', 180), ('.', 161), ('i', 156), ('a', 123), ('to', 115), ('?', 91), ('of', 88), ('and', 81), ('it', 78)] | tokenPerfect: 64057 / 135000  47.45% | babyLLM.py 2500
2025-04-09 20:13:57 | 20000 | LR0.0003 | loss:3.9781 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-471.4935 | logitMax:-444.0445 | memoryGateShort:8.4173 | memoryGateLong:-8.8688 | memoryGateCurrent:1.4516 | embedMean:0.0000 | embedStd:0.0004 | embedSparsity:0.0000 | meanActivation:-0.0002 | activationSparsity:0.0000 | windowCount:0.0072 | windowEntropy:0.0013 | shortDecay:0.0005 | longDecay:0.0006 | windowWeightsW25:1.58761,W21:0.66261,W16:0.42575,W2:0.41468,W19:0.40602,W13:0.22496,W9:-0.21180,W3:-1.06416,W5:-1.50596 | topTokens[(',', 405), ('the', 228), ('.', 198), ('i', 160), ('a', 132), ('to', 129), ('of', 108), ('and', 95), ('?', 91), ('s', 84)] | babyLLM.py 2500
2025-04-09 20:19:05 | 22500 | LR0.0003 | loss:3.2523 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-427.9108 | logitMax:-401.7743 | memoryGateShort:8.4879 | memoryGateLong:-9.0731 | memoryGateCurrent:1.5852 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.30534,W21:0.57168,W16:0.39354,W19:0.35526,W2:0.35209,W13:0.21816,W9:-0.14626,W3:-0.87753,W5:-1.22305 | topTokens[(',', 453), ('the', 248), ('.', 238), ('i', 201), ('to', 144), ('a', 137), ('and', 125), ('of', 115), ('s', 97), ('?', 95)] | tokenPerfect: 14711 / 45000  32.69% | babyLLM.py 2500
2025-04-09 20:24:13 | 25000 | LR0.0003 | loss:2.6529 | gradNorm:0.9992 | tokenCount:45000.0000 | logitMin:-449.1864 | logitMax:-422.0703 | memoryGateShort:7.2748 | memoryGateLong:-7.6262 | memoryGateCurrent:1.3514 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.26160,W21:0.56889,W16:0.39417,W19:0.35470,W2:0.33446,W13:0.22656,W9:-0.14600,W3:-0.84223,W5:-1.20136 | topTokens[(',', 568), ('the', 260), ('.', 248), ('i', 227), ('to', 161), ('and', 151), ('a', 145), ('of', 122), ('s', 112), ('you', 110)] | tokenPerfect: 33057 / 90000  36.73% | babyLLM.py 2500
2025-04-09 20:29:22 | 27500 | LR0.0003 | loss:2.7536 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-352.9367 | logitMax:-322.6665 | memoryGateShort:10.5584 | memoryGateLong:-11.7030 | memoryGateCurrent:2.1446 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.24441,W21:0.55799,W2:0.37492,W16:0.36988,W19:0.34016,W13:0.21450,W9:-0.18197,W3:-0.79869,W5:-1.17082 | topTokens[(',', 668), ('the', 314), ('.', 251), ('and', 238), ('i', 234), ('to', 173), ('a', 149), ('s', 130), ('you', 127), ('of', 125)] | tokenPerfect: 49654 / 135000  36.78% | babyLLM.py 2500
2025-04-09 20:34:52 | 30000 | LR0.0003 | loss:1.6296 | gradNorm:0.9985 | tokenCount:45000.0000 | logitMin:-395.8879 | logitMax:-365.4096 | memoryGateShort:7.3746 | memoryGateLong:-8.0024 | memoryGateCurrent:1.6278 | embedMean:0.0000 | embedStd:0.0004 | embedSparsity:0.0000 | meanActivation:-0.0002 | activationSparsity:0.0000 | windowCount:0.0072 | windowEntropy:0.0013 | shortDecay:0.0005 | longDecay:0.0006 | windowWeightsW25:1.08827,W21:0.49962,W16:0.35025,W2:0.32880,W19:0.31530,W13:0.22809,W9:-0.11335,W3:-0.71282,W5:-1.02832 | topTokens[(',', 743), ('the', 342), ('.', 269), ('and', 267), ('i', 235), ('to', 189), ('a', 153), ('s', 144), ('you', 139), ('of', 136)] | babyLLM.py 2500
2025-04-09 20:40:20 | 32500 | LR0.0003 | loss:2.2941 | gradNorm:0.9871 | tokenCount:45000.0000 | logitMin:-442.6989 | logitMax:-410.6173 | memoryGateShort:9.6052 | memoryGateLong:-10.6057 | memoryGateCurrent:2.0005 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0007 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.05436,W21:0.45635,W2:0.37396,W16:0.34377,W19:0.26081,W13:0.23904,W9:-0.11186,W3:-0.66706,W5:-0.99378 | topTokens[(',', 759), ('the', 346), ('.', 304), ('and', 275), ('i', 247), ('to', 243), ('a', 162), ('you', 161), ('of', 150), ('s', 149)] | tokenPerfect: 23866 / 45000  53.04% | babyLLM.py 2500
2025-04-09 20:45:42 | 35000 | LR0.0003 | loss:0.6451 | gradNorm:0.8830 | tokenCount:45000.0000 | logitMin:-428.2523 | logitMax:-387.9587 | memoryGateShort:4.4512 | memoryGateLong:-4.6367 | memoryGateCurrent:1.1855 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0007 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.00408,W21:0.43200,W2:0.36360,W16:0.35600,W19:0.24750,W13:0.24260,W9:-0.09210,W3:-0.65779,W5:-0.93870 | topTokens[(',', 810), ('the', 373), ('.', 340), ('and', 289), ('i', 262), ('to', 252), ('a', 183), ('you', 173), ('of', 168), ('s', 160)] | tokenPerfect: 60522 / 90000  67.25% | babyLLM.py 2500
2025-04-09 20:50:57 | 37500 | LR0.0003 | loss:4.9015 | gradNorm:0.9863 | tokenCount:45000.0000 | logitMin:-527.2772 | logitMax:-494.9515 | memoryGateShort:7.2434 | memoryGateLong:-7.1399 | memoryGateCurrent:0.8965 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0007 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.12734,W21:0.49046,W16:0.37792,W2:0.32692,W19:0.28967,W13:0.24448,W9:-0.11323,W3:-0.74901,W5:-1.03970 | topTokens[(',', 844), ('the', 396), ('.', 362), ('and', 298), ('i', 269), ('to', 267), ('a', 197), ('you', 181), ('it', 177), ('s', 175)] | tokenPerfect: 72619 / 135000  53.79% | babyLLM.py 2500
2025-04-09 20:56:20 | 40000 | LR0.0003 | loss:6.0030 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-460.1422 | logitMax:-430.7738 | memoryGateShort:9.5260 | memoryGateLong:-9.3358 | memoryGateCurrent:0.8097 | embedMean:-0.0000 | embedStd:0.0004 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0072 | windowEntropy:0.0013 | shortDecay:0.0005 | longDecay:0.0006 | windowWeightsW25:1.51363,W21:0.63747,W16:0.42843,W2:0.39768,W19:0.34724,W13:0.24007,W9:-0.22985,W3:-0.99701,W5:-1.39534 | topTokens[(',', 862), ('the', 408), ('.', 379), ('and', 308), ('i', 277), ('to', 270), ('a', 215), ('s', 197), ('you', 187), ('it', 184)] | babyLLM.py 2500
2025-04-09 21:01:30 | 42500 | LR0.0003 | loss:5.4567 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-440.9664 | logitMax:-415.8640 | memoryGateShort:9.1955 | memoryGateLong:-9.4091 | memoryGateCurrent:1.2136 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.99637,W21:0.82902,W16:0.50124,W2:0.46741,W19:0.44175,W13:0.24550,W9:-0.36080,W3:-1.33041,W5:-1.86345 | topTokens[(',', 873), ('.', 457), ('the', 420), ('and', 323), ('i', 301), ('to', 282), ('a', 234), ('s', 203), ('it', 195), ('you', 191)] | tokenPerfect: 5404 / 45000  12.01% | babyLLM.py 2500
2025-04-09 21:06:45 | 45000 | LR0.0003 | loss:1.8959 | gradNorm:0.9997 | tokenCount:45000.0000 | logitMin:-438.1951 | logitMax:-409.4826 | memoryGateShort:5.6654 | memoryGateLong:-5.9889 | memoryGateCurrent:1.3235 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.39733,W21:0.62000,W16:0.44743,W19:0.38416,W2:0.33728,W13:0.26563,W9:-0.18919,W3:-0.96488,W5:-1.35170 | topTokens[(',', 952), ('.', 486), ('the', 436), ('and', 342), ('i', 303), ('to', 291), ('a', 260), ('s', 211), ('it', 203), ('of', 201)] | tokenPerfect: 29002 / 90000  32.22% | babyLLM.py 2500
2025-04-09 21:12:00 | 47500 | LR0.0003 | loss:5.1408 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-464.9112 | logitMax:-438.9024 | memoryGateShort:7.5835 | memoryGateLong:-7.8131 | memoryGateCurrent:1.2296 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.80545,W21:0.78594,W16:0.50656,W19:0.46690,W2:0.39313,W13:0.25160,W9:-0.29680,W3:-1.24770,W5:-1.73207 | topTokens[(',', 1038), ('.', 508), ('the', 449), ('and', 354), ('i', 327), ('to', 307), ('a', 280), ('s', 222), ('it', 207), ('of', 206)] | tokenPerfect: 36355 / 135000  26.93% | babyLLM.py 2500
2025-04-09 21:17:35 | 50000 | LR0.0003 | loss:2.5861 | gradNorm:0.9943 | tokenCount:45000.0000 | logitMin:-469.7843 | logitMax:-441.4944 | memoryGateShort:6.4093 | memoryGateLong:-6.9285 | memoryGateCurrent:1.5192 | embedMean:-0.0000 | embedStd:0.0004 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0072 | windowEntropy:0.0013 | shortDecay:0.0005 | longDecay:0.0006 | windowWeightsW25:1.68894,W21:0.69488,W16:0.49921,W2:0.47724,W19:0.38030,W13:0.27930,W9:-0.22666,W3:-1.18519,W5:-1.67395 | topTokens[(',', 1127), ('.', 517), ('the', 470), ('and', 368), ('i', 342), ('to', 320), ('a', 295), ('s', 227), ('it', 220), ('of', 218)] | babyLLM.py 2500
2025-04-09 21:22:45 | 52500 | LR0.0003 | loss:0.5713 | gradNorm:0.9945 | tokenCount:45000.0000 | logitMin:-510.1657 | logitMax:-473.3796 | memoryGateShort:3.8563 | memoryGateLong:-4.1007 | memoryGateCurrent:1.2443 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.42273,W21:0.58099,W16:0.46170,W2:0.40543,W19:0.31355,W13:0.28505,W9:-0.13003,W3:-0.98287,W5:-1.41310 | topTokens[(',', 1191), ('.', 526), ('the', 487), ('and', 381), ('i', 342), ('to', 331), ('a', 307), ('of', 234), ('s', 234), ('it', 222)] | tokenPerfect: 36935 / 45000  82.08% | babyLLM.py 2500
2025-04-09 21:28:09 | 55000 | LR0.0003 | loss:5.1507 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-514.1333 | logitMax:-484.0927 | memoryGateShort:6.9246 | memoryGateLong:-7.0258 | memoryGateCurrent:1.1013 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0006 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:1.84687,W21:0.72840,W16:0.52079,W2:0.46176,W19:0.36605,W13:0.28495,W9:-0.21377,W3:-1.28051,W5:-1.78431 | topTokens[(',', 1233), ('.', 559), ('the', 499), ('and', 409), ('i', 355), ('to', 352), ('a', 329), ('of', 254), ('s', 243), ('it', 228)] | tokenPerfect: 46395 / 90000  51.55% | babyLLM.py 2500

--- 2025-04-09 21:32:10 --- babyLLM 'right, last time i got to step 304103... want to restart from there?'  - charis: '0 please' - babyLLM 'umm... i don't think i heard you properly, i'll just start from step 0 :) but, what am i learning today?' - charis: ''
2025-04-09 21:37:20 | 2500 | LR0.0003 | loss:5.2875 | gradNorm:1.0000 | logitMin:-501.4458 | logitMax:-475.5126 | scheduledSampling:0.0000 | tokenCount:45000.0000 | memoryGateShort:8.9678 | memoryGateLong:-9.6072 | memoryGateCurrent:1.6393 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0008 | topTokens[('i', 37), ('.', 35), ('and', 23), ('the', 20), (',', 19), ('a', 17), ('to', 15), ('it', 15), ('me', 13), ('?', 13)] | tokenPerfect: 7035 / 45000  15.63% | babyLLM.py 2500
2025-04-09 21:42:35 | 5000 | LR0.0003 | loss:4.7722 | gradNorm:0.9945 | tokenCount:45000.0000 | logitMin:-450.7110 | logitMax:-424.8387 | memoryGateShort:9.1642 | memoryGateLong:-9.9713 | memoryGateCurrent:1.8071 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0008 | shortDecay:0.0003 | longDecay:0.0003 | topTokens[(',', 65), ('.', 61), ('i', 61), ('the', 58), ('and', 44), ('to', 35), ('it', 29), ('s', 23), ('a', 21), ('but', 21)] | tokenPerfect: 16052 / 90000  17.84% | babyLLM.py 2500
2025-04-09 21:47:53 | 7500 | LR0.0003 | loss:3.7805 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-375.2606 | logitMax:-347.8847 | memoryGateShort:10.9605 | memoryGateLong:-12.4159 | memoryGateCurrent:2.4553 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0008 | shortDecay:0.0003 | longDecay:0.0003 | topTokens[(',', 167), ('i', 91), ('the', 70), ('.', 68), ('and', 62), ('to', 51), ('you', 46), ('it', 37), ('ing', 34), ('me', 30)] | tokenPerfect: 27951 / 135000  20.70% | babyLLM.py 2500
2025-04-09 21:53:17 | 10000 | LR0.0003 | loss:1.9856 | gradNorm:0.9994 | tokenCount:45000.0000 | logitMin:-459.3854 | logitMax:-432.0576 | memoryGateShort:7.7365 | memoryGateLong:-8.4755 | memoryGateCurrent:1.7390 | embedMean:-0.0000 | embedStd:0.0004 | embedSparsity:0.0000 | meanActivation:-0.0002 | activationSparsity:0.0000 | windowCount:0.0072 | windowEntropy:0.0016 | shortDecay:0.0005 | longDecay:0.0006 | topTokens[(',', 261), ('i', 131), ('the', 100), ('and', 79), ('.', 75), ('to', 73), ('you', 65), ('a', 47), ('me', 45), ('it', 44)] | babyLLM.py 2500
2025-04-09 21:58:28 | 12500 | LR0.0003 | loss:2.0209 | gradNorm:0.9962 | tokenCount:45000.0000 | logitMin:-543.6123 | logitMax:-513.6153 | memoryGateShort:5.9662 | memoryGateLong:-6.2420 | memoryGateCurrent:1.2758 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0008 | shortDecay:0.0003 | longDecay:0.0003 | topTokens[(',', 362), ('i', 158), ('the', 127), ('you', 92), ('and', 86), ('.', 84), ('to', 81), ('it', 61), ('a', 57), ('me', 53)] | tokenPerfect: 23168 / 45000  51.48% | babyLLM.py 2500
2025-04-09 22:03:37 | 15000 | LR0.0003 | loss:3.9362 | gradNorm:0.9917 | tokenCount:45000.0000 | logitMin:-572.9311 | logitMax:-541.6182 | memoryGateShort:6.7041 | memoryGateLong:-7.0613 | memoryGateCurrent:1.3572 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0008 | shortDecay:0.0003 | longDecay:0.0003 | topTokens[(',', 436), ('i', 210), ('the', 145), ('you', 107), ('.', 95), ('and', 95), ('to', 94), ('it', 78), ('a', 73), ('me', 62)] | tokenPerfect: 40695 / 90000  45.22% | babyLLM.py 2500
2025-04-09 22:08:52 | 17500 | LR0.0003 | loss:5.3216 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-547.3875 | logitMax:-521.1975 | memoryGateShort:8.3267 | memoryGateLong:-8.5835 | memoryGateCurrent:1.2568 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0008 | shortDecay:0.0003 | longDecay:0.0003 | topTokens[(',', 489), ('i', 244), ('the', 167), ('and', 119), ('you', 111), ('.', 108), ('to', 102), ('it', 97), ('a', 82), ('me', 71)] | tokenPerfect: 46851 / 135000  34.70% | babyLLM.py 2500
2025-04-09 22:14:16 | 20000 | LR0.0003 | loss:4.9386 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-510.8986 | logitMax:-486.1370 | memoryGateShort:9.1926 | memoryGateLong:-9.8339 | memoryGateCurrent:1.6413 | embedMean:-0.0000 | embedStd:0.0004 | embedSparsity:0.0000 | meanActivation:-0.0002 | activationSparsity:0.0000 | windowCount:0.0072 | windowEntropy:0.0016 | shortDecay:0.0005 | longDecay:0.0006 | topTokens[(',', 552), ('i', 287), ('the', 183), ('and', 134), ('.', 119), ('it', 118), ('to', 114), ('you', 113), ('a', 88), ('of', 76)] | babyLLM.py 2500
2025-04-09 22:19:28 | 22500 | LR0.0003 | loss:4.7599 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-477.4882 | logitMax:-453.4700 | memoryGateShort:9.9431 | memoryGateLong:-10.7437 | memoryGateCurrent:1.8006 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0008 | shortDecay:0.0003 | longDecay:0.0003 | topTokens[(',', 611), ('i', 325), ('the', 195), ('and', 147), ('it', 139), ('to', 128), ('.', 125), ('you', 120), ('a', 100), ('s', 84)] | tokenPerfect: 7457 / 45000  16.57% | babyLLM.py 2500
2025-04-09 22:24:49 | 25000 | LR0.0003 | loss:4.9388 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-431.7934 | logitMax:-407.0446 | memoryGateShort:10.0638 | memoryGateLong:-10.8882 | memoryGateCurrent:1.8244 | embedMean:-0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0008 | shortDecay:0.0003 | longDecay:0.0003 | topTokens[(',', 641), ('i', 354), ('the', 212), ('.', 173), ('and', 162), ('it', 147), ('to', 144), ('you', 130), ('a', 119), ('s', 100)] | tokenPerfect: 14541 / 90000  16.16% | babyLLM.py 2500
2025-04-09 22:29:59 | 27500 | LR0.0003 | loss:4.5392 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-431.5169 | logitMax:-406.8092 | memoryGateShort:10.9478 | memoryGateLong:-11.9896 | memoryGateCurrent:2.0418 | embedMean:0.0000 | embedStd:0.0002 | embedSparsity:0.0000 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowCount:0.0036 | windowEntropy:0.0008 | shortDecay:0.0003 | longDecay:0.0003 | topTokens[(',', 671), ('i', 374), ('the', 225), ('.', 201), ('to', 172), ('and', 172), ('it', 158), ('you', 142), ('a', 136), ('s', 114)] | tokenPerfect: 22989 / 135000  17.03% | babyLLM.py 2500
2025-04-09 22:35:23 | 30000 | LR0.0003 | loss:4.7187 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-417.4874 | logitMax:-393.1960 | memoryGateShort:11.2616 | memoryGateLong:-12.3455 | memoryGateCurrent:2.0839 | embedMean:0.0000 | embedStd:0.0004 | embedSparsity:0.0000 | meanActivation:-0.0003 | activationSparsity:0.0000 | windowCount:0.0072 | windowEntropy:0.0016 | shortDecay:0.0005 | longDecay:0.0006 | topTokens[(',', 710), ('i', 397), ('the', 239), ('.', 236), ('to', 190), ('and', 189), ('it', 173), ('a', 152), ('you', 149), ('s', 125)] | babyLLM.py 2500

--- 2025-04-09 22:52:54 --- babyLLM 'right, last time i got to step 31851... want to restart from there?'  - charis: 'y' - babyLLM 'ok! let's go to step 31851! what am i learning today?' - charis: ''
2025-04-09 22:58:11 | 2500 | LR0.0003 | loss:3.2239 | gradNorm:1.0000 | logitMin:-442.6723 | logitMax:-418.5853 | scheduledSampling:0.0000 | tokenCount:45000.0000 | memoryGateShort:10.6486 | memoryGateLong:-12.0287 | memoryGateCurrent:2.3801 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateMean:0.3333 | memoryGateStd:11.4794 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.0001 | windowEntropy:0.0006 | topWindowWeight:0.0002 | effectiveWindowCount:0.0018 | windowWeightsW25:2.46730 (0.54),W21:0.99440 (0.12),W2:0.71088 (0.09),W16:0.46137 (0.07),W19:0.43547 (0.07),W13:0.15787 (0.05),W9:-0.53689 (0.03),W3:-1.85889 (0.01),W5:-2.58268 (0.00) | topTokens[(',', 49), ('.', 33), ('i', 26), ('to', 19), ('of', 18), ('the', 17), ('my', 15), ('so', 14), ('on', 13), ('line', 13)] | tokenPerfect: 15711 / 45000  34.91% | babyLLM.py 2500
2025-04-09 23:04:06 | 5000 | LR0.0003 | loss:1.4438 | gradNorm:0.9772 | tokenCount:45000.0000 | logitMin:-513.2122 | logitMax:-483.5547 | memoryGateShort:8.5906 | memoryGateLong:-10.0533 | memoryGateCurrent:2.4627 | memoryGateMean:0.3333 | memoryGateStd:9.5037 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.0001 | windowEntropy:0.0006 | topWindowWeight:0.0002 | effectiveWindowCount:0.0020 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.35291 (0.51),W21:0.98624 (0.13),W2:0.76858 (0.10),W16:0.56140 (0.08),W19:0.41369 (0.07),W13:0.19936 (0.06),W9:-0.40354 (0.03),W3:-1.74191 (0.01),W5:-2.41596 (0.00) | topTokens[('.', 81), (',', 78), ('i', 43), ('and', 33), ('to', 32), ('the', 31), ('you', 31), ('it', 30), ('so', 30), ('of', 26)] | tokenPerfect: 46458 / 90000  51.62% | babyLLM.py 2500
2025-04-09 23:09:19 | 7500 | LR0.0003 | loss:2.9740 | gradNorm:0.9936 | tokenCount:45000.0000 | logitMin:-537.6824 | logitMax:-508.2056 | memoryGateShort:8.9347 | memoryGateLong:-9.7555 | memoryGateCurrent:1.8207 | memoryGateMean:0.3333 | memoryGateStd:9.4448 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.0001 | windowEntropy:0.0006 | topWindowWeight:0.0002 | effectiveWindowCount:0.0019 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.36888 (0.51),W21:1.00709 (0.13),W2:0.76513 (0.10),W16:0.53099 (0.08),W19:0.41691 (0.07),W13:0.12728 (0.05),W9:-0.39815 (0.03),W3:-1.74276 (0.01),W5:-2.39016 (0.00) | topTokens[('.', 131), (',', 112), ('i', 72), ('you', 62), ('to', 57), ('the', 46), ('and', 46), ('a', 42), ('was', 37), ('so', 35)] | tokenPerfect: 68314 / 135000  50.60% | babyLLM.py 2500
2025-04-09 23:14:52 | 10000 | LR0.0003 | loss:3.4800 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-482.3062 | logitMax:-455.8410 | memoryGateShort:11.1305 | memoryGateLong:-11.9168 | memoryGateCurrent:1.7863 | memoryGateMean:0.3333 | memoryGateStd:11.5929 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.0001 | windowEntropy:0.0006 | topWindowWeight:0.0002 | effectiveWindowCount:0.0020 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.32795 (0.50),W21:0.98588 (0.13),W2:0.79131 (0.11),W16:0.50534 (0.08),W19:0.39729 (0.07),W13:0.10583 (0.05),W9:-0.33116 (0.04),W3:-1.64450 (0.01),W5:-2.28420 (0.00) | topTokens[('.', 196), (',', 138), ('?', 103), ('i', 91), ('to', 87), ('you', 87), ('a', 70), ('is', 64), ('the', 57), ('was', 53)] | babyLLM.py 2500
2025-04-09 23:20:08 | 12500 | LR0.0003 | loss:3.0923 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-473.5315 | logitMax:-447.7773 | memoryGateShort:11.0903 | memoryGateLong:-11.8826 | memoryGateCurrent:1.7923 | memoryGateMean:0.3333 | memoryGateStd:11.5562 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.0001 | windowEntropy:0.0006 | topWindowWeight:0.0002 | effectiveWindowCount:0.0020 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.30747 (0.50),W21:1.00474 (0.14),W2:0.80097 (0.11),W16:0.47298 (0.08),W19:0.40655 (0.07),W13:0.06627 (0.05),W9:-0.30865 (0.04),W3:-1.60058 (0.01),W5:-2.24810 (0.01) | topTokens[('.', 261), ('?', 163), (',', 158), ('i', 119), ('you', 114), ('to', 113), ('a', 92), ('is', 88), ('was', 76), ('what', 68)] | tokenPerfect: 16639 / 45000  36.98% | babyLLM.py 2500
2025-04-09 23:25:34 | 15000 | LR0.0003 | loss:2.8882 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-446.3123 | logitMax:-420.1763 | memoryGateShort:11.7226 | memoryGateLong:-12.6445 | memoryGateCurrent:1.9219 | memoryGateMean:0.3333 | memoryGateStd:12.2619 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.0001 | windowEntropy:0.0007 | topWindowWeight:0.0002 | effectiveWindowCount:0.0021 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.25390 (0.48),W21:0.99842 (0.14),W2:0.81345 (0.11),W16:0.43747 (0.08),W19:0.39830 (0.08),W13:0.14402 (0.06),W9:-0.19425 (0.04),W3:-1.51836 (0.01),W5:-2.09125 (0.01) | topTokens[('.', 325), ('?', 215), (',', 180), ('i', 151), ('you', 146), ('to', 137), ('is', 119), ('a', 112), ('was', 96), ('what', 96)] | tokenPerfect: 34930 / 90000  38.81% | babyLLM.py 2500

--- 2025-04-09 23:35:26 --- babyLLM 'right, last time i got to step 48710... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 48710! what am i learning today?' - charis: ''
2025-04-09 23:40:43 | 2500 | LR0.0003 | loss:2.4593 | gradNorm:1.0000 | logitMin:-397.3090 | logitMax:-371.1520 | scheduledSampling:0.0000 | tokenCount:45000.0000 | memoryGateShort:12.0780 | memoryGateLong:-13.2629 | memoryGateCurrent:2.1849 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateMean:0.3333 | memoryGateStd:12.7727 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.0001 | windowEntropy:0.0007 | topWindowWeight:0.0002 | effectiveWindowCount:0.0021 | windowWeightsW25:2.24676 (0.48),W21:0.96708 (0.13),W2:0.81522 (0.11),W19:0.41832 (0.08),W16:0.37824 (0.07),W13:0.16199 (0.06),W9:-0.13713 (0.04),W3:-1.50265 (0.01),W5:-2.00386 (0.01) | topTokens[('.', 57), ('is', 51), (',', 41), ('are', 32), ('!', 24), ('charis', 24), ('the', 24), ('ing', 21), ('?', 20), ('to', 20)] | tokenPerfect: 19157 / 45000  42.57% | babyLLM.py 2500
2025-04-09 23:46:13 | 5000 | LR0.0003 | loss:1.7609 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-314.7187 | logitMax:-284.4880 | memoryGateShort:14.8407 | memoryGateLong:-16.6871 | memoryGateCurrent:2.8464 | memoryGateMean:0.3333 | memoryGateStd:15.9140 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.0001 | windowEntropy:0.0007 | topWindowWeight:0.0002 | effectiveWindowCount:0.0021 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.24431 (0.48),W21:0.98723 (0.14),W2:0.79151 (0.11),W19:0.44326 (0.08),W16:0.37792 (0.07),W13:0.19982 (0.06),W9:-0.09312 (0.05),W3:-1.49713 (0.01),W5:-1.93848 (0.01) | topTokens[('is', 110), ('.', 102), (',', 91), ('are', 78), ('charis', 67), ('ing', 66), ('the', 58), ('!', 57), ('elodie', 42), ('they', 33)] | tokenPerfect: 41626 / 90000  46.25% | babyLLM.py 2500
2025-04-09 23:52:27 | 7500 | LR0.0003 | loss:1.6221 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-301.2381 | logitMax:-270.4152 | memoryGateShort:16.1826 | memoryGateLong:-17.9914 | memoryGateCurrent:2.8088 | memoryGateMean:0.3333 | memoryGateStd:17.2218 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.0001 | windowEntropy:0.0007 | topWindowWeight:0.0002 | effectiveWindowCount:0.0022 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.20710 (0.46),W21:1.00038 (0.14),W2:0.77292 (0.11),W19:0.45897 (0.08),W16:0.40119 (0.08),W13:0.28544 (0.07),W9:-0.01926 (0.05),W3:-1.51723 (0.01),W5:-1.85817 (0.01) | topTokens[('is', 178), (',', 138), ('.', 130), ('are', 127), ('charis', 109), ('ing', 108), ('!', 100), ('the', 98), ('elodie', 61), ('eating', 54)] | tokenPerfect: 64423 / 135000  47.72% | babyLLM.py 2500
2025-04-09 23:58:07 | 10000 | LR0.0003 | loss:1.5434 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-286.1839 | logitMax:-254.1892 | memoryGateShort:17.8828 | memoryGateLong:-19.7366 | memoryGateCurrent:2.8538 | memoryGateMean:0.3333 | memoryGateStd:18.9366 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.0001 | windowEntropy:0.0007 | topWindowWeight:0.0002 | effectiveWindowCount:0.0022 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.18824 (0.45),W21:0.96461 (0.13),W2:0.77015 (0.11),W19:0.45367 (0.08),W16:0.43296 (0.08),W13:0.30657 (0.07),W9:0.04229 (0.05),W3:-1.50327 (0.01),W5:-1.82112 (0.01) | topTokens[('is', 236), ('are', 193), (',', 180), ('.', 165), ('charis', 146), ('ing', 143), ('!', 140), ('the', 125), ('elodie', 96), ('eating', 71)] | babyLLM.py 2500

--- 2025-04-10 00:03:26 --- babyLLM 'right, last time i got to step 60790... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 60790! what am i learning today?' - charis: ''
2025-04-10 00:08:57 | 2500 | LR0.0003 | loss:2.5693 | gradNorm:0.9999 | logitMin:-263.9587 | logitMax:-232.5737 | scheduledSampling:0.0000 | tokenCount:45000.0000 | memoryGateShort:21.4444 | memoryGateLong:-23.6498 | memoryGateCurrent:3.2053 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateMean:833.3333 | memoryGateStd:56712.7485 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1395 | windowEntropy:1.6877 | topWindowWeight:0.4684 | effectiveWindowCount:5.4071 | windowWeightsW25:2.23978 (0.47),W21:0.95360 (0.13),W2:0.71042 (0.10),W19:0.47713 (0.08),W16:0.41274 (0.08),W13:0.35795 (0.07),W9:0.05710 (0.05),W3:-1.41163 (0.01),W5:-1.75938 (0.01) | topTokens[(',', 125), ('and', 98), ('elodie', 31), ('charis', 31), ('the', 30), ('but', 22), ('you', 21), ('weed', 17), ('her', 16), ('he', 15)] | tokenPerfect: 17599 / 45000  39.11% | babyLLM.py 2500
2025-04-10 00:14:41 | 5000 | LR0.0003 | loss:2.4671 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-258.8108 | logitMax:-228.2323 | memoryGateShort:21.9410 | memoryGateLong:-24.3974 | memoryGateCurrent:3.4565 | memoryGateMean:833.3332 | memoryGateStd:58319.0752 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1336 | windowEntropy:1.7214 | topWindowWeight:0.4524 | effectiveWindowCount:5.5925 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.18449 (0.45),W21:0.90630 (0.13),W2:0.73240 (0.11),W19:0.46893 (0.08),W16:0.43875 (0.08),W13:0.42114 (0.08),W9:0.07861 (0.06),W3:-1.33903 (0.01),W5:-1.69737 (0.01) | topTokens[(',', 232), ('and', 168), ('the', 71), ('but', 50), ('elodie', 48), ('charis', 47), ('you', 42), ('her', 34), ('kevin', 33), ('they', 30)] | tokenPerfect: 35233 / 90000  39.15% | babyLLM.py 2500
2025-04-10 00:20:20 | 7500 | LR0.0003 | loss:2.2341 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-260.0084 | logitMax:-229.7357 | memoryGateShort:22.3499 | memoryGateLong:-24.8845 | memoryGateCurrent:3.5346 | memoryGateMean:833.3333 | memoryGateStd:59449.1234 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1336 | windowEntropy:1.7241 | topWindowWeight:0.4532 | effectiveWindowCount:5.6076 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.19385 (0.45),W21:0.90083 (0.12),W2:0.69545 (0.10),W19:0.48568 (0.08),W16:0.47123 (0.08),W13:0.45108 (0.08),W9:0.08652 (0.06),W3:-1.29288 (0.01),W5:-1.63489 (0.01) | topTokens[(',', 344), ('and', 258), ('the', 98), ('charis', 83), ('elodie', 70), ('but', 67), ('you', 55), ('kevin', 52), ('her', 51), ('he', 43)] | tokenPerfect: 54469 / 135000  40.35% | babyLLM.py 2500
2025-04-10 00:26:16 | 10000 | LR0.0003 | loss:2.2676 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-259.4464 | logitMax:-229.6378 | memoryGateShort:22.7626 | memoryGateLong:-25.1503 | memoryGateCurrent:3.3876 | memoryGateMean:833.3332 | memoryGateStd:60257.1667 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1312 | windowEntropy:1.7384 | topWindowWeight:0.4462 | effectiveWindowCount:5.6883 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.15198 (0.45),W21:0.86557 (0.12),W2:0.74692 (0.11),W16:0.45606 (0.08),W19:0.43838 (0.08),W13:0.40302 (0.08),W9:0.06488 (0.06),W3:-1.20503 (0.02),W5:-1.61135 (0.01) | topTokens[(',', 447), ('and', 335), ('the', 138), ('charis', 102), ('elodie', 89), ('but', 81), ('you', 76), ('her', 69), ('kevin', 67), ("'s", 56)] | babyLLM.py 2500
2025-04-10 00:31:52 | 12500 | LR0.0003 | loss:2.7784 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-252.2704 | logitMax:-221.2670 | memoryGateShort:25.4095 | memoryGateLong:-27.9719 | memoryGateCurrent:3.5625 | memoryGateMean:833.3332 | memoryGateStd:74252.1294 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1338 | windowEntropy:1.7279 | topWindowWeight:0.4540 | effectiveWindowCount:5.6286 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.17970 (0.45),W21:0.88156 (0.12),W2:0.71713 (0.11),W16:0.44179 (0.08),W19:0.43504 (0.08),W13:0.39393 (0.08),W9:0.05454 (0.05),W3:-1.15048 (0.02),W5:-1.53569 (0.01) | topTokens[(',', 551), ('and', 408), ('the', 169), ('charis', 128), ('elodie', 111), ('but', 100), ('kevin', 90), ('you', 87), ('her', 79), ('s', 73)] | tokenPerfect: 17524 / 45000  38.94% | babyLLM.py 2500
2025-04-10 00:37:43 | 15000 | LR0.0003 | loss:5.3795 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-308.0252 | logitMax:-282.3949 | memoryGateShort:18.5784 | memoryGateLong:-19.5218 | memoryGateCurrent:1.9434 | memoryGateMean:833.3333 | memoryGateStd:69648.6270 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1387 | windowEntropy:1.6996 | topWindowWeight:0.4678 | effectiveWindowCount:5.4718 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.24837 (0.47),W21:0.93994 (0.13),W2:0.64433 (0.09),W16:0.47549 (0.08),W19:0.47277 (0.08),W13:0.42975 (0.08),W9:0.05730 (0.05),W3:-1.21042 (0.01),W5:-1.59538 (0.01) | topTokens[(',', 584), ('and', 425), ('the', 189), ('charis', 130), ('elodie', 113), ('but', 105), ('you', 96), ('kevin', 96), ('i', 86), ('s', 83)] | tokenPerfect: 23467 / 90000  26.07% | babyLLM.py 2500
2025-04-10 00:43:29 | 17500 | LR0.0003 | loss:4.9779 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-333.0744 | logitMax:-309.6269 | memoryGateShort:19.1735 | memoryGateLong:-20.2718 | memoryGateCurrent:2.0983 | memoryGateMean:833.3333 | memoryGateStd:49456.4997 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1400 | windowEntropy:1.6887 | topWindowWeight:0.4707 | effectiveWindowCount:5.4124 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.28071 (0.47),W21:0.98075 (0.13),W2:0.60203 (0.09),W16:0.54213 (0.08),W19:0.53905 (0.08),W13:0.46026 (0.08),W9:0.02211 (0.05),W3:-1.27739 (0.01),W5:-1.66741 (0.01) | topTokens[(',', 606), ('and', 446), ('the', 196), ('charis', 130), ('i', 129), ('.', 119), ('elodie', 113), ('but', 109), ('you', 98), ('s', 96)] | tokenPerfect: 29798 / 135000  22.07% | babyLLM.py 2500

--- 2025-04-10 00:51:31 --- babyLLM 'right, last time i got to step 79014... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 79014! what am i learning today?' - charis: ''
2025-04-10 00:56:40 | 2500 | LR0.0003 | loss:4.4068 | gradNorm:1.0000 | logitMin:-407.3128 | logitMax:-383.2939 | scheduledSampling:0.0000 | tokenCount:45000.0000 | memoryGateShort:15.9353 | memoryGateLong:-17.1045 | memoryGateCurrent:2.1691 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateMean:833.3333 | memoryGateStd:41491.3237 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1447 | windowEntropy:1.6608 | topWindowWeight:0.4838 | effectiveWindowCount:5.2633 | windowWeightsW25:2.32727 (0.48),W21:0.99326 (0.13),W2:0.58434 (0.08),W19:0.56276 (0.08),W16:0.53901 (0.08),W13:0.44744 (0.07),W9:-0.03257 (0.05),W3:-1.32113 (0.01),W5:-1.74291 (0.01) | topTokens[('i', 28), ('.', 27), ('it', 25), (',', 25), ('the', 16), ('that', 16), ("'t", 14), ('ly', 13), ('is', 13), ('to', 13)] | tokenPerfect: 8841 / 45000  19.65% | babyLLM.py 2500
2025-04-10 01:03:08 | 5000 | LR0.0003 | loss:4.2422 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-403.4366 | logitMax:-378.6481 | memoryGateShort:15.8346 | memoryGateLong:-17.1509 | memoryGateCurrent:2.3163 | memoryGateMean:833.3333 | memoryGateStd:41455.5651 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1473 | windowEntropy:1.6463 | topWindowWeight:0.4909 | effectiveWindowCount:5.1878 | shortDecay:0.0003 | longDecay:0.0003 | windowWeightsW25:2.34003 (0.49),W21:1.00322 (0.13),W2:0.60492 (0.09),W19:0.55671 (0.08),W16:0.46921 (0.08),W13:0.38903 (0.07),W9:-0.05682 (0.04),W3:-1.31570 (0.01),W5:-1.73334 (0.01) | topTokens[('.', 73), (',', 50), ('i', 49), ('it', 41), ('the', 41), ('is', 35), ('that', 30), ('a', 28), ('to', 24), ('and', 24)] | tokenPerfect: 18060 / 90000  20.07% | babyLLM.py 2500

--- 2025-04-10 01:16:21 --- babyLLM 'right, last time i got to step 84130... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 84130! what am i learning today?' - charis: ''
2025-04-10 01:21:45 | 2500 | LR0.0003 | loss:4.4205 | gradNorm:1.0000 | logitMin:-426.8018 | logitMax:-402.9384 | scheduledSampling:0.0000 | tokenCount:45000.0000 | memoryGateShort:0.0056 | memoryGateLong:-0.0061 | memoryGateCurrent:0.0009 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1490 | windowEntropy:1.6350 | topWindowWeight:0.4955 | effectiveWindowCount:5.1296 | memoryGateMean:0.3333 | memoryGateStd:14.6655 | windowWeightsW25:2.36214 (0.50),W21:1.00201 (0.13),W2:0.58758 (0.08),W19:0.55777 (0.08),W16:0.50720 (0.08),W13:0.42400 (0.07),W9:-0.07037 (0.04),W3:-1.38812 (0.01),W5:-1.80256 (0.01) | topTokens[('.', 51), (',', 37), ('that', 23), ('and', 20), ('the', 17), ('a', 17), ('i', 16), ('it', 14), ('to', 13), ('be', 13)] | tokenPerfect: 8970 / 45000  19.93% | babyLLM.py 2500
2025-04-10 01:27:00 | 5000 | LR0.0003 | loss:2.2108 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-358.8430 | logitMax:-331.0893 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1351 | windowEntropy:1.7071 | topWindowWeight:0.4545 | effectiveWindowCount:5.5128 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0052 | memoryGateLong:-0.0057 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:13.7208 | windowWeightsW25:2.25006 (0.45),W21:1.05988 (0.14),W2:0.62039 (0.09),W19:0.60604 (0.09),W13:0.55000 (0.08),W16:0.53172 (0.08),W9:-0.07902 (0.04),W3:-1.34006 (0.01),W5:-1.67882 (0.01) | topTokens[(',', 127), ('.', 63), ('have', 52), ('must', 40), ('i', 36), ('to', 35), ('and', 35), ('the', 31), ('you', 31), ('felt', 27)] | tokenPerfect: 28999 / 90000  32.22% | babyLLM.py 2500
2025-04-10 01:32:18 | 7500 | LR0.0003 | loss:1.1168 | gradNorm:0.9997 | tokenCount:45000.0000 | logitMin:-322.8076 | logitMax:-286.9255 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1337 | windowEntropy:1.7140 | topWindowWeight:0.4506 | effectiveWindowCount:5.5510 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0068 | memoryGateLong:-0.0074 | memoryGateCurrent:0.0010 | memoryGateMean:0.3333 | memoryGateStd:17.9254 | windowWeightsW25:2.23446 (0.45),W21:1.05165 (0.14),W2:0.63179 (0.09),W19:0.61725 (0.09),W13:0.56955 (0.09),W16:0.49496 (0.08),W9:-0.06121 (0.05),W3:-1.34547 (0.01),W5:-1.69685 (0.01) | topTokens[(',', 167), ('have', 166), ('must', 158), ('.', 91), ('felt', 91), ('!', 72), ('the', 62), ('and', 50), ('charis', 45), ('you', 43)] | tokenPerfect: 56458 / 135000  41.82% | babyLLM.py 2500

--- 2025-04-10 01:35:10 --- babyLLM 'right, last time i got to step 92168... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 92168! what am i learning today?' - charis: ''
2025-04-10 01:40:25 | 2500 | LR0.0003 | loss:1.0758 | gradNorm:1.0000 | logitMin:-277.2072 | logitMax:-237.7352 | scheduledSampling:0.0000 | tokenCount:45000.0000 | memoryGateShort:0.0090 | memoryGateLong:-0.0096 | memoryGateCurrent:0.0010 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1290 | windowEntropy:1.7397 | topWindowWeight:0.4376 | effectiveWindowCount:5.6955 | memoryGateMean:0.3333 | memoryGateStd:23.4151 | windowWeightsW25:2.19219 (0.44),W21:1.02836 (0.14),W2:0.63874 (0.09),W19:0.62269 (0.09),W13:0.60614 (0.09),W16:0.50370 (0.08),W9:0.01128 (0.05),W3:-1.32563 (0.01),W5:-1.67686 (0.01) | topTokens[('must', 117), ('have', 115), ('felt', 64), ('!', 48), (',', 39), ('charis', 33), ('it', 25), ('know', 23), ('.', 23), ('elodie', 20)] | tokenPerfect: 27651 / 45000  61.45% | babyLLM.py 2500
2025-04-10 01:45:40 | 5000 | LR0.0003 | loss:2.5567 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-303.6220 | logitMax:-272.3986 | scheduledSampling:0.0000 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1237 | windowEntropy:1.7571 | topWindowWeight:0.4199 | effectiveWindowCount:5.7958 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0047 | memoryGateLong:-0.0050 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:12.1662 | windowWeightsW25:2.19891 (0.42),W21:1.11212 (0.14),W19:0.77369 (0.10),W13:0.75484 (0.10),W16:0.68074 (0.09),W2:0.51417 (0.08),W9:0.06228 (0.05),W3:-1.47937 (0.01),W5:-1.72120 (0.01) | topTokens[('must', 131), ('have', 124), (',', 102), ('felt', 67), ('!', 67), ('.', 61), ('it', 57), ('charis', 44), ('and', 32), ('the', 27)] | tokenPerfect: 45120 / 90000  50.13% | babyLLM.py 2500
2025-04-10 01:50:55 | 7500 | LR0.0003 | loss:5.5363 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-427.2531 | logitMax:-402.3172 | scheduledSampling:0.0000 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1345 | windowEntropy:1.6985 | topWindowWeight:0.4501 | effectiveWindowCount:5.4660 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0055 | memoryGateLong:-0.0056 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:13.8476 | windowWeightsW25:2.30089 (0.45),W21:1.17146 (0.15),W19:0.77660 (0.10),W13:0.67166 (0.09),W16:0.63139 (0.08),W2:0.48418 (0.07),W9:-0.04179 (0.04),W3:-1.53496 (0.01),W5:-1.83595 (0.01) | topTokens[('must', 132), ('.', 132), ('have', 131), (',', 116), ('!', 80), ('it', 72), ('felt', 70), ('i', 54), ('and', 51), ('charis', 44)] | tokenPerfect: 50352 / 135000  37.30% | babyLLM.py 2500

--- 2025-04-10 01:52:13 --- babyLLM 'right, last time i got to step 100006... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 100006! what am i learning today?' - charis: ''
2025-04-10 01:57:23 | 2500 | LR0.0003 | loss:4.7929 | gradNorm:1.0000 | logitMin:-438.7451 | logitMax:-415.7213 | scheduledSampling:0.0000 | tokenCount:45000.0000 | memoryGateShort:0.0060 | memoryGateLong:-0.0064 | memoryGateCurrent:0.0009 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1468 | windowEntropy:1.6316 | topWindowWeight:0.4861 | effectiveWindowCount:5.1121 | memoryGateMean:0.3333 | memoryGateStd:15.5687 | windowWeightsW25:2.39812 (0.49),W21:1.15761 (0.14),W19:0.72093 (0.09),W13:0.59488 (0.08),W16:0.56762 (0.08),W2:0.48004 (0.07),W9:-0.15512 (0.04),W3:-1.61079 (0.01),W5:-1.94351 (0.01) | topTokens[('.', 91), ('i', 28), ('that', 14), ('you', 13), ('is', 12), ('u', 12), ('was', 12), ('?', 12), ('spea', 11), ('o', 11)] | tokenPerfect: 6620 / 45000  14.71% | babyLLM.py 2500
2025-04-10 02:02:38 | 5000 | LR0.0003 | loss:4.6556 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-429.5211 | logitMax:-405.7445 | scheduledSampling:0.0000 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1611 | windowEntropy:1.5496 | topWindowWeight:0.5269 | effectiveWindowCount:4.7097 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0054 | memoryGateLong:-0.0057 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:13.9382 | windowWeightsW25:2.50993 (0.53),W21:1.15618 (0.14),W19:0.67263 (0.08),W13:0.50718 (0.07),W16:0.46330 (0.07),W2:0.46233 (0.07),W9:-0.28599 (0.03),W3:-1.66432 (0.01),W5:-2.01808 (0.01) | topTokens[('.', 164), ('i', 45), ('?', 31), ('you', 31), ('and', 28), ('im', 26), ('u', 21), ('is', 20), ('xd', 19), ('y', 18)] | tokenPerfect: 13456 / 90000  14.95% | babyLLM.py 2500
2025-04-10 02:07:50 | 7500 | LR0.0003 | loss:4.6460 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-427.4051 | logitMax:-403.8756 | scheduledSampling:0.0000 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1619 | windowEntropy:1.5439 | topWindowWeight:0.5291 | effectiveWindowCount:4.6829 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0056 | memoryGateLong:-0.0059 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:14.5128 | windowWeightsW25:2.50758 (0.53),W21:1.15564 (0.14),W19:0.64838 (0.08),W2:0.49203 (0.07),W16:0.47726 (0.07),W13:0.43980 (0.07),W9:-0.33868 (0.03),W3:-1.64801 (0.01),W5:-2.03453 (0.01) | topTokens[('.', 247), ('i', 73), ('?', 44), ('and', 44), ('you', 37), ('lo', 35), ('im', 33), ('u', 29), ('l', 29), ('a', 28)] | tokenPerfect: 20240 / 135000  14.99% | babyLLM.py 2500
2025-04-10 02:13:12 | 10000 | LR0.0003 | loss:4.8311 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-414.5633 | logitMax:-390.8188 | scheduledSampling:0.0000 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1666 | windowEntropy:1.5166 | topWindowWeight:0.5427 | effectiveWindowCount:4.5568 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0069 | memoryGateLong:-0.0074 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:17.9885 | windowWeightsW25:2.52877 (0.54),W21:1.12557 (0.13),W19:0.59824 (0.08),W2:0.51849 (0.07),W16:0.41974 (0.07),W13:0.39200 (0.06),W9:-0.40960 (0.03),W3:-1.66080 (0.01),W5:-2.05403 (0.01) | topTokens[('.', 311), ('i', 110), ('and', 65), ('?', 53), ('im', 45), ('you', 44), ('a', 41), ('lo', 37), ('l', 36), ('u', 35)] | babyLLM.py 2500

--- 2025-04-10 02:20:37 --- babyLLM 'right, last time i got to step 111426... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 111426! what am i learning today?' - charis: ''
2025-04-10 02:25:49 | 2500 | LR0.0003 | loss:3.2696 | gradNorm:0.9877 | logitMin:-368.9346 | logitMax:-343.5431 | scheduledSampling:0.0000 | tokenCount:45000.0000 | memoryGateShort:0.0058 | memoryGateLong:-0.0064 | memoryGateCurrent:0.0010 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1494 | windowEntropy:1.6199 | topWindowWeight:0.4944 | effectiveWindowCount:5.0526 | memoryGateMean:0.3333 | memoryGateStd:15.3200 | windowWeightsW25:2.37571 (0.49),W21:1.07014 (0.13),W2:0.58939 (0.08),W19:0.56508 (0.08),W13:0.54563 (0.08),W16:0.54164 (0.08),W9:-0.31839 (0.03),W3:-1.54502 (0.01),W5:-1.97798 (0.01) | topTokens[(',', 77), ('i', 25), ('the', 21), ('you', 19), ('ing', 19), ('to', 18), ('my', 17), ('it', 15), ('a', 11), ('in', 11)] | tokenPerfect: 15591 / 45000  34.65% | babyLLM.py 2500

--- 2025-04-10 02:30:07 --- babyLLM 'right, last time i got to step 111426... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 111426! what am i learning today?' - charis: ''
2025-04-10 02:35:22 | 2500 | LR0.0003 | loss:3.2117 | gradNorm:0.9849 | logitMin:-365.4277 | logitMax:-339.9070 | scheduledSampling:0.0000 | tokenCount:45000.0000 | memoryGateShort:0.0054 | memoryGateLong:-0.0060 | memoryGateCurrent:0.0010 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1484 | windowEntropy:1.6245 | topWindowWeight:0.4913 | effectiveWindowCount:5.0756 | memoryGateMean:0.3333 | memoryGateStd:14.3070 | windowWeightsW25:2.37108 (0.49),W21:1.07951 (0.14),W2:0.58716 (0.08),W19:0.57209 (0.08),W16:0.56240 (0.08),W13:0.56001 (0.08),W9:-0.33495 (0.03),W3:-1.53940 (0.01),W5:-1.98214 (0.01) | topTokens[(',', 70), ('the', 25), ('i', 20), ('you', 20), ('ing', 17), ('to', 16), ('my', 15), ('er', 14), ('?', 12), ('a', 12)] | tokenPerfect: 15834 / 45000  35.19% | babyLLM.py 2500
2025-04-10 02:40:34 | 5000 | LR0.0003 | loss:2.5387 | gradNorm:0.9990 | tokenCount:45000.0000 | logitMin:-335.9158 | logitMax:-308.6426 | scheduledSampling:0.0000 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1369 | windowEntropy:1.6865 | topWindowWeight:0.4582 | effectiveWindowCount:5.4005 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0045 | memoryGateLong:-0.0049 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:11.7903 | windowWeightsW25:2.27709 (0.46),W21:1.07013 (0.14),W13:0.65178 (0.09),W2:0.62902 (0.09),W16:0.62228 (0.09),W19:0.59545 (0.09),W9:-0.26753 (0.04),W3:-1.49383 (0.01),W5:-1.91117 (0.01) | topTokens[(',', 164), ('i', 55), ('you', 43), ('to', 43), ('the', 40), ('my', 31), ('a', 22), ('ing', 22), ('and', 21), ('.', 19)] | tokenPerfect: 33913 / 90000  37.68% | babyLLM.py 2500

--- 2025-04-10 02:42:41 --- babyLLM 'right, last time i got to step 117082... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 117082! what am i learning today?' - charis: ''
2025-04-10 02:47:56 | 2500 | LR0.0003 | loss:2.4653 | gradNorm:0.9997 | logitMin:-426.6656 | logitMax:-400.6116 | scheduledSampling:0.0000 | tokenCount:45000.0000 | memoryGateShort:0.0031 | memoryGateLong:-0.0032 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1331 | windowEntropy:1.6995 | topWindowWeight:0.4447 | effectiveWindowCount:5.4710 | memoryGateMean:0.3333 | memoryGateStd:7.8429 | windowWeightsW25:2.28507 (0.44),W21:1.18273 (0.15),W16:0.74297 (0.10),W19:0.70734 (0.09),W13:0.69417 (0.09),W2:0.52949 (0.08),W9:-0.19005 (0.04),W3:-1.57290 (0.01),W5:-1.96918 (0.01) | topTokens[(',', 89), ('i', 27), ('you', 26), ('me', 21), ('the', 18), ('and', 15), ('to', 14), ("'m", 14), ('.', 14), ('your', 13)] | 0.0 | tokenPerfect: 18263 / 45000  40.58% | babyLLM.py 2500
2025-04-10 02:53:10 | 5000 | LR0.0003 | loss:1.7499 | gradNorm:0.9985 | tokenCount:45000.0000 | logitMin:-495.6027 | logitMax:-465.6288 | scheduledSampling:0.0000 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1300 | windowEntropy:1.7198 | topWindowWeight:0.4368 | effectiveWindowCount:5.5837 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0027 | memoryGateLong:-0.0029 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:7.1346 | windowWeightsW25:2.23059 (0.44),W21:1.14062 (0.15),W19:0.68471 (0.09),W16:0.67515 (0.09),W13:0.62382 (0.09),W2:0.60486 (0.09),W9:-0.16459 (0.04),W3:-1.49625 (0.01),W5:-1.89348 (0.01) | topTokens[(',', 166), ('i', 61), ('you', 46), ('the', 42), ('me', 33), ('and', 31), ('to', 29), ("'m", 26), ('.', 23), ('of', 20)] | 0.0 | tokenPerfect: 44055 / 90000  48.95% | babyLLM.py 2500

--- 2025-04-10 03:02:24 --- babyLLM 'right, last time i got to step 125124... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 125124! what am i learning today?' - charis: ''
2025-04-10 03:07:36 | 2500 | LR0.0003 | loss:5.4861 | gradNorm:1.0000 | logitMin:-295.3537 | logitMax:-259.4850 | scheduledSampling:0.6002 | tokenCount:45000.0000 | memoryGateShort:0.0065 | memoryGateLong:-0.0056 | memoryGateCurrent:-0.0006 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1523 | windowEntropy:1.5831 | topWindowWeight:0.4972 | effectiveWindowCount:4.8703 | memoryGateMean:0.3333 | memoryGateStd:15.1545 | windowWeightsW25:2.48998 (0.50),W21:1.33917 (0.16),W19:0.86962 (0.10),W16:0.61766 (0.08),W13:0.48618 (0.07),W2:0.40374 (0.06),W9:-0.34616 (0.03),W3:-1.70337 (0.01),W5:-2.07862 (0.01) | topTokens[('i', 78), ('.', 60), (',', 27), ('a', 23), ('you', 22), ('do', 21), ('!', 21), ('is', 20), ('?', 19), ('to', 18)] | 1.0 | tokenPerfect: 2385 / 45000  5.30% | babyLLM.py 2500
2025-04-10 03:12:46 | 5000 | LR0.0003 | loss:8.0879 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-232.2800 | logitMax:-187.0785 | scheduledSampling:1.0000 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1785 | windowEntropy:1.4015 | topWindowWeight:0.5674 | effectiveWindowCount:4.0612 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0365 | memoryGateLong:-0.0325 | memoryGateCurrent:-0.0036 | memoryGateMean:0.3333 | memoryGateStd:86.5216 | windowWeightsW25:2.80452 (0.57),W21:1.58722 (0.17),W19:0.97452 (0.09),W16:0.54085 (0.06),W13:0.34306 (0.05),W2:0.06972 (0.04),W9:-0.48813 (0.02),W3:-1.98216 (0.00),W5:-2.25132 (0.00) | topTokens[('i', 102), ('.', 88), ('am', 87), (',', 58), ('you', 40), ('a', 37), ('think', 37), ('need', 36), ('is', 36), ('it', 34)] | 1.0 | tokenPerfect: 2888 / 90000  3.21% | babyLLM.py 2500

--- 2025-04-10 03:13:31 --- babyLLM 'right, last time i got to step 130162... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 130162! what am i learning today?' - charis: ''
2025-04-10 03:18:45 | 2500 | LR0.0003 | loss:4.8757 | gradNorm:1.0000 | logitMin:-46.2169 | logitMax:0.7566 | scheduledSampling:0.0001 | tokenCount:45000.0000 | memoryGateShort:0.0026 | memoryGateLong:-0.0031 | memoryGateCurrent:0.0009 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1674 | windowEntropy:1.4878 | topWindowWeight:0.5389 | effectiveWindowCount:4.4272 | memoryGateMean:0.3333 | memoryGateStd:7.2434 | windowWeightsW25:2.62769 (0.54),W21:1.41819 (0.16),W19:0.84706 (0.09),W16:0.53085 (0.07),W2:0.33199 (0.05),W13:0.31192 (0.05),W9:-0.44627 (0.02),W3:-1.77780 (0.01),W5:-2.17653 (0.00) | topTokens[(',', 65), ('!', 44), ('d', 28), ('the', 28), ('it', 21), ('angle', 19), ('you', 18), ('.', 15), ('ed', 15), ('i', 14)] | 0.0002500000000000052 | tokenPerfect: 9230 / 45000  20.51% | babyLLM.py 2500
2025-04-10 03:23:57 | 5000 | LR0.0003 | loss:2.9363 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-61.6438 | logitMax:-19.0109 | scheduledSampling:0.0004 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1569 | windowEntropy:1.5614 | topWindowWeight:0.5108 | effectiveWindowCount:4.7654 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0051 | memoryGateLong:-0.0062 | memoryGateCurrent:0.0015 | memoryGateMean:0.3333 | memoryGateStd:14.3788 | windowWeightsW25:2.46868 (0.51),W21:1.28898 (0.16),W19:0.74591 (0.09),W2:0.53967 (0.07),W16:0.44146 (0.07),W13:0.27314 (0.06),W9:-0.43848 (0.03),W3:-1.55980 (0.01),W5:-2.05133 (0.01) | topTokens[(',', 112), ('!', 101), ('the', 61), ('it', 55), ('d', 41), ('a', 41), ('you', 31), ('m', 31), ('i', 29), ('he', 29)] | 0.0005000000000000049 | tokenPerfect: 25453 / 90000  28.28% | babyLLM.py 2500
2025-04-10 03:29:04 | 7500 | LR0.0003 | loss:2.7856 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-94.9026 | logitMax:-53.8450 | scheduledSampling:0.0006 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1522 | windowEntropy:1.5958 | topWindowWeight:0.4990 | effectiveWindowCount:4.9324 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0032 | memoryGateLong:-0.0036 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:8.6557 | windowWeightsW25:2.40473 (0.50),W21:1.21864 (0.15),W19:0.68746 (0.09),W2:0.60167 (0.08),W16:0.43247 (0.07),W13:0.28580 (0.06),W9:-0.39128 (0.03),W3:-1.43066 (0.01),W5:-1.98027 (0.01) | topTokens[(',', 179), ('!', 136), ('the', 89), ('it', 82), ('a', 55), ('i', 52), ('d', 51), ('you', 47), ('she', 43), ('m', 42)] | 0.0007499999999998754 | tokenPerfect: 41636 / 135000  30.84% | babyLLM.py 2500
2025-04-10 03:34:22 | 10000 | LR0.0003 | loss:2.4961 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-91.2819 | logitMax:-51.5057 | scheduledSampling:0.0009 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1541 | windowEntropy:1.5905 | topWindowWeight:0.5055 | effectiveWindowCount:4.9062 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0034 | memoryGateLong:-0.0039 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:9.2706 | windowWeightsW25:2.38998 (0.51),W21:1.15063 (0.15),W2:0.65241 (0.09),W19:0.59871 (0.08),W16:0.35958 (0.07),W13:0.24051 (0.06),W9:-0.39544 (0.03),W3:-1.35812 (0.01),W5:-1.95741 (0.01) | topTokens[(',', 235), ('!', 189), ('the', 121), ('it', 114), ('a', 71), ('i', 62), ('d', 61), ('you', 59), ('he', 59), ('to', 59)] | 0.0009999999999997715 | babyLLM.py 2500
2025-04-10 03:39:32 | 12500 | LR0.0003 | loss:5.4720 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-265.6666 | logitMax:-233.3367 | scheduledSampling:0.0011 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1630 | windowEntropy:1.5370 | topWindowWeight:0.5314 | effectiveWindowCount:4.6508 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0035 | memoryGateLong:-0.0037 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:9.0421 | windowWeightsW25:2.48096 (0.53),W21:1.16168 (0.14),W19:0.61159 (0.08),W2:0.58953 (0.08),W16:0.34516 (0.06),W13:0.24028 (0.06),W9:-0.44057 (0.03),W3:-1.42036 (0.01),W5:-2.03361 (0.01) | topTokens[(',', 344), ('!', 217), ('the', 146), ('it', 129), ('i', 91), ('a', 88), ('you', 71), ('to', 71), ('angle', 69), ('he', 67)] | 0.001249999999999913 | tokenPerfect: 7086 / 45000  15.75% | babyLLM.py 2500
2025-04-10 03:44:47 | 15000 | LR0.0003 | loss:5.1312 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-317.1613 | logitMax:-291.6183 | scheduledSampling:0.0014 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1760 | windowEntropy:1.4573 | topWindowWeight:0.5683 | effectiveWindowCount:4.2945 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0033 | memoryGateLong:-0.0034 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:8.4635 | windowWeightsW25:2.59820 (0.57),W21:1.15984 (0.13),W19:0.60253 (0.08),W2:0.51293 (0.07),W16:0.31446 (0.06),W13:0.19531 (0.05),W9:-0.52121 (0.03),W3:-1.49215 (0.01),W5:-2.12660 (0.01) | topTokens[(',', 489), ('!', 219), ('the', 165), ('it', 138), ('i', 120), ('a', 108), ('to', 83), ('you', 71), ('he', 71), ('angle', 70)] | 0.0015000000000000547 | tokenPerfect: 13251 / 90000  14.72% | babyLLM.py 2500
2025-04-10 03:50:01 | 17500 | LR0.0003 | loss:4.8206 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-297.4426 | logitMax:-273.9722 | scheduledSampling:0.0016 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1821 | windowEntropy:1.4183 | topWindowWeight:0.5858 | effectiveWindowCount:4.1300 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0029 | memoryGateLong:-0.0032 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:7.7482 | windowWeightsW25:2.63310 (0.59),W21:1.13244 (0.13),W19:0.55307 (0.07),W2:0.52553 (0.07),W16:0.24352 (0.05),W13:0.14222 (0.05),W9:-0.61157 (0.02),W3:-1.49972 (0.01),W5:-2.16986 (0.00) | topTokens[(',', 548), ('!', 220), ('the', 177), ('it', 151), ('i', 149), ('a', 114), ('to', 99), ('ed', 79), ('she', 78), ('angle', 73)] | 0.0017500000000001963 | tokenPerfect: 19524 / 135000  14.46% | babyLLM.py 2500
2025-04-10 03:55:20 | 20000 | LR0.0003 | loss:4.7834 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-334.4790 | logitMax:-311.9671 | scheduledSampling:0.0019 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1834 | windowEntropy:1.4139 | topWindowWeight:0.5900 | effectiveWindowCount:4.1121 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0034 | memoryGateLong:-0.0037 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:9.0185 | windowWeightsW25:2.63347 (0.59),W21:1.08898 (0.13),W2:0.53254 (0.07),W19:0.51408 (0.07),W16:0.23678 (0.05),W13:0.15327 (0.05),W9:-0.59912 (0.02),W3:-1.48560 (0.01),W5:-2.12895 (0.01) | topTokens[(',', 624), ('!', 220), ('i', 187), ('the', 186), ('it', 159), ('a', 129), ('to', 113), ('ed', 85), ('she', 81), ('you', 80)] | 0.0020000000000002364 | babyLLM.py 2500
2025-04-10 04:00:33 | 22500 | LR0.0003 | loss:4.2435 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-306.2263 | logitMax:-283.3793 | scheduledSampling:0.0021 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1800 | windowEntropy:1.4346 | topWindowWeight:0.5802 | effectiveWindowCount:4.1981 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0030 | memoryGateLong:-0.0035 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:8.2457 | windowWeightsW25:2.58146 (0.58),W21:1.05648 (0.13),W2:0.60498 (0.08),W19:0.50634 (0.07),W16:0.19155 (0.05),W13:0.11713 (0.05),W9:-0.67599 (0.02),W3:-1.45507 (0.01),W5:-2.11630 (0.01) | topTokens[(',', 688), ('!', 227), ('i', 217), ('the', 198), ('it', 172), ('a', 142), ('to', 129), ('and', 96), ('she', 90), ('you', 88)] | 0.002249999999999836 | tokenPerfect: 8286 / 45000  18.41% | babyLLM.py 2500
2025-04-10 04:05:47 | 25000 | LR0.0003 | loss:1.9065 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-218.7798 | logitMax:-188.6067 | scheduledSampling:0.0024 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1709 | windowEntropy:1.4916 | topWindowWeight:0.5543 | effectiveWindowCount:4.4441 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0050 | memoryGateLong:-0.0058 | memoryGateCurrent:0.0011 | memoryGateMean:0.3333 | memoryGateStd:13.6781 | windowWeightsW25:2.49450 (0.55),W21:1.06411 (0.13),W2:0.65857 (0.09),W19:0.49923 (0.08),W16:0.21647 (0.06),W13:0.08787 (0.05),W9:-0.61119 (0.02),W3:-1.38356 (0.01),W5:-1.99287 (0.01) | topTokens[(',', 732), ('!', 272), ('the', 234), ('i', 226), ('it', 179), ('will', 150), ('a', 143), ('to', 134), ('and', 117), ('.', 108)] | 0.0024999999999994354 | tokenPerfect: 27914 / 90000  31.02% | babyLLM.py 2500
2025-04-10 04:11:01 | 27500 | LR0.0003 | loss:1.7359 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-185.4057 | logitMax:-152.9582 | scheduledSampling:0.0026 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1621 | windowEntropy:1.5464 | topWindowWeight:0.5292 | effectiveWindowCount:4.6945 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0057 | memoryGateLong:-0.0064 | memoryGateCurrent:0.0011 | memoryGateMean:0.3333 | memoryGateStd:15.3224 | windowWeightsW25:2.41159 (0.53),W21:1.06598 (0.14),W2:0.70308 (0.10),W19:0.46909 (0.08),W16:0.24587 (0.06),W13:0.11349 (0.05),W9:-0.53335 (0.03),W3:-1.35379 (0.01),W5:-1.85221 (0.01) | topTokens[(',', 774), ('!', 315), ('will', 287), ('the', 271), ('i', 236), ('it', 185), ('.', 147), ('a', 143), ('to', 142), ('and', 124)] | 0.002749999999999035 | tokenPerfect: 48623 / 135000  36.02% | babyLLM.py 2500
2025-04-10 04:16:24 | 30000 | LR0.0003 | loss:1.7367 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-183.1326 | logitMax:-150.7823 | scheduledSampling:0.0029 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1598 | windowEntropy:1.5652 | topWindowWeight:0.5236 | effectiveWindowCount:4.7835 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0063 | memoryGateLong:-0.0069 | memoryGateCurrent:0.0010 | memoryGateMean:0.3333 | memoryGateStd:16.6264 | windowWeightsW25:2.38735 (0.52),W21:1.01715 (0.13),W2:0.71459 (0.10),W19:0.46010 (0.08),W16:0.26999 (0.06),W13:0.12460 (0.05),W9:-0.44837 (0.03),W3:-1.33551 (0.01),W5:-1.78649 (0.01) | topTokens[(',', 814), ('will', 409), ('!', 349), ('the', 294), ('i', 240), ('.', 201), ('it', 192), ('to', 149), ('a', 148), ('and', 140)] | 0.0029999999999986344 | babyLLM.py 2500
2025-04-10 04:21:37 | 32500 | LR0.0003 | loss:2.9746 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-264.5401 | logitMax:-238.6099 | scheduledSampling:0.0031 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1593 | windowEntropy:1.5725 | topWindowWeight:0.5223 | effectiveWindowCount:4.8187 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0055 | memoryGateLong:-0.0060 | memoryGateCurrent:0.0010 | memoryGateMean:0.3333 | memoryGateStd:14.5144 | windowWeightsW25:2.37539 (0.52),W21:1.01822 (0.13),W2:0.71511 (0.10),W19:0.38823 (0.07),W16:0.23337 (0.06),W13:0.13057 (0.06),W9:-0.40096 (0.03),W3:-1.22198 (0.01),W5:-1.70268 (0.01) | topTokens[(',', 829), ('will', 420), ('!', 355), ('the', 309), ('i', 282), ('.', 268), ('it', 197), ('to', 189), ('you', 165), ('a', 155)] | 0.003249999999998234 | tokenPerfect: 14883 / 45000  33.07% | babyLLM.py 2500
2025-04-10 04:26:52 | 35000 | LR0.0003 | loss:2.5551 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-249.0585 | logitMax:-223.3931 | scheduledSampling:0.0034 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1521 | windowEntropy:1.6182 | topWindowWeight:0.5022 | effectiveWindowCount:5.0440 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0043 | memoryGateLong:-0.0047 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:11.3832 | windowWeightsW25:2.30239 (0.50),W21:0.99723 (0.14),W2:0.75052 (0.11),W19:0.34965 (0.07),W16:0.21358 (0.06),W13:0.15255 (0.06),W9:-0.31837 (0.04),W3:-1.10298 (0.02),W5:-1.60992 (0.01) | topTokens[(',', 840), ('will', 435), ('!', 361), ('.', 335), ('i', 317), ('the', 315), ('to', 220), ('you', 206), ('it', 199), ('a', 165)] | 0.0034999999999978334 | tokenPerfect: 31939 / 90000  35.49% | babyLLM.py 2500
2025-04-10 04:32:08 | 37500 | LR0.0003 | loss:2.2918 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-236.8665 | logitMax:-210.6525 | scheduledSampling:0.0036 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1427 | windowEntropy:1.6748 | topWindowWeight:0.4753 | effectiveWindowCount:5.3379 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0106 | memoryGateLong:-0.0122 | memoryGateCurrent:0.0020 | memoryGateMean:0.3333 | memoryGateStd:28.8318 | windowWeightsW25:2.20884 (0.48),W21:0.98961 (0.14),W2:0.79938 (0.12),W19:0.32076 (0.07),W16:0.17492 (0.06),W13:0.13568 (0.06),W9:-0.21251 (0.04),W3:-0.95816 (0.02),W5:-1.46547 (0.01) | topTokens[(',', 851), ('will', 441), ('.', 394), ('!', 368), ('i', 355), ('the', 317), ('to', 247), ('you', 234), ('it', 204), ('?', 184)] | 0.003749999999997433 | tokenPerfect: 50496 / 135000  37.40% | babyLLM.py 2500
2025-04-10 04:37:28 | 40000 | LR0.0003 | loss:2.6462 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-110.5721 | logitMax:-84.2559 | scheduledSampling:0.0039 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1416 | windowEntropy:1.6833 | topWindowWeight:0.4731 | effectiveWindowCount:5.3831 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0044 | memoryGateLong:-0.0047 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:11.4083 | windowWeightsW25:2.25219 (0.47),W21:1.05700 (0.14),W2:0.67817 (0.10),W19:0.49143 (0.08),W16:0.31028 (0.07),W13:0.23940 (0.06),W9:-0.16533 (0.04),W3:-0.95120 (0.02),W5:-1.43617 (0.01) | topTokens[(',', 923), ('will', 441), ('!', 419), ('.', 410), ('i', 370), ('the', 348), ('to', 260), ('you', 244), ('it', 227), ('?', 191)] | 0.003999999999997439 | babyLLM.py 2500
2025-04-10 04:42:45 | 42500 | LR0.0003 | loss:1.9991 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-110.3481 | logitMax:-82.4284 | scheduledSampling:0.0041 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1404 | windowEntropy:1.6871 | topWindowWeight:0.4687 | effectiveWindowCount:5.4040 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0045 | memoryGateLong:-0.0050 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:11.9009 | windowWeightsW25:2.24868 (0.47),W21:1.10136 (0.15),W2:0.66455 (0.10),W19:0.52491 (0.08),W16:0.31800 (0.07),W13:0.23326 (0.06),W9:-0.17904 (0.04),W3:-0.93928 (0.02),W5:-1.44749 (0.01) | topTokens[(',', 966), ('!', 469), ('will', 441), ('.', 416), ('the', 393), ('i', 385), ('to', 274), ('it', 260), ('you', 255), ('a', 202)] | 0.0042499999999981225 | tokenPerfect: 20495 / 45000  45.54% | babyLLM.py 2500
2025-04-10 04:48:02 | 45000 | LR0.0003 | loss:2.0179 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-118.5844 | logitMax:-90.9193 | scheduledSampling:0.0044 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.1394 | windowEntropy:1.6940 | topWindowWeight:0.4662 | effectiveWindowCount:5.4413 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0039 | memoryGateLong:-0.0041 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:10.0161 | windowWeightsW25:2.24429 (0.47),W21:1.10260 (0.15),W2:0.65255 (0.09),W19:0.50837 (0.08),W16:0.35285 (0.07),W13:0.26000 (0.06),W9:-0.17825 (0.04),W3:-0.89412 (0.02),W5:-1.43026 (0.01) | topTokens[(',', 1035), ('!', 519), ('will', 441), ('.', 432), ('the', 431), ('i', 405), ('to', 289), ('it', 285), ('you', 275), ('a', 210)] | 0.004499999999998806 | tokenPerfect: 39956 / 90000  44.40% | babyLLM.py 2500
2025-04-10 04:53:14 | 47500 | LR0.0003 | loss:1.9841 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-113.8428 | logitMax:-85.5549 | scheduledSampling:0.0046 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1395 | windowEntropy:1.6916 | topWindowWeight:0.4659 | effectiveWindowCount:5.4282 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0048 | memoryGateLong:-0.0052 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:12.5702 | windowWeightsW25:2.24651 (0.47),W21:1.12496 (0.15),W2:0.64863 (0.09),W19:0.51835 (0.08),W16:0.35589 (0.07),W13:0.23740 (0.06),W9:-0.18523 (0.04),W3:-0.90227 (0.02),W5:-1.44332 (0.01) | topTokens[(',', 1092), ('!', 567), ('the', 462), ('will', 441), ('.', 439), ('i', 418), ('to', 302), ('it', 302), ('you', 282), ('a', 227)] | 0.00474999999999949 | tokenPerfect: 60335 / 135000  44.69% | babyLLM.py 2500
2025-04-10 04:58:30 | 50000 | LR0.0003 | loss:3.3374 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-294.0687 | logitMax:-270.3588 | scheduledSampling:0.0049 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1405 | windowEntropy:1.6782 | topWindowWeight:0.4668 | effectiveWindowCount:5.3558 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0032 | memoryGateLong:-0.0033 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:8.1247 | windowWeightsW25:2.30556 (0.47),W21:1.22164 (0.16),W19:0.67207 (0.09),W2:0.53974 (0.08),W16:0.46179 (0.07),W13:0.32737 (0.06),W9:-0.18051 (0.04),W3:-1.01791 (0.02),W5:-1.52065 (0.01) | topTokens[(',', 1175), ('!', 583), ('the', 477), ('.', 447), ('i', 445), ('will', 442), ('to', 317), ('it', 315), ('you', 290), ('a', 235)] | 0.005000000000000174 | babyLLM.py 2500
2025-04-10 05:03:38 | 52500 | LR0.0003 | loss:3.1554 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-361.5127 | logitMax:-338.4896 | scheduledSampling:0.0051 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1506 | windowEntropy:1.6167 | topWindowWeight:0.4949 | effectiveWindowCount:5.0364 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0031 | memoryGateLong:-0.0032 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:7.9507 | windowWeightsW25:2.41975 (0.49),W21:1.26548 (0.16),W19:0.71838 (0.09),W16:0.47722 (0.07),W2:0.44921 (0.07),W13:0.33006 (0.06),W9:-0.23824 (0.03),W3:-1.12901 (0.01),W5:-1.62050 (0.01) | topTokens[(',', 1251), ('!', 585), ('the', 481), ('i', 466), ('.', 449), ('will', 442), ('to', 330), ('it', 324), ('you', 292), ('a', 255)] | 0.005250000000000857 | tokenPerfect: 12935 / 45000  28.74% | babyLLM.py 2500
2025-04-10 05:08:46 | 55000 | LR0.0003 | loss:2.9681 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-363.5472 | logitMax:-339.8924 | scheduledSampling:0.0054 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1557 | windowEntropy:1.5865 | topWindowWeight:0.5094 | effectiveWindowCount:4.8866 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0029 | memoryGateLong:-0.0031 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:7.4775 | windowWeightsW25:2.46100 (0.51),W21:1.27078 (0.15),W19:0.70870 (0.09),W2:0.43659 (0.07),W16:0.40797 (0.07),W13:0.30947 (0.06),W9:-0.26472 (0.03),W3:-1.15289 (0.01),W5:-1.64857 (0.01) | topTokens[(',', 1344), ('!', 586), ('i', 498), ('the', 485), ('.', 457), ('will', 443), ('to', 342), ('it', 340), ('you', 294), ('a', 259)] | 0.005500000000001541 | tokenPerfect: 26771 / 90000  29.75% | babyLLM.py 2500
2025-04-10 05:13:54 | 57500 | LR0.0003 | loss:3.0196 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-428.4789 | logitMax:-404.3257 | scheduledSampling:0.0056 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1605 | windowEntropy:1.5597 | topWindowWeight:0.5242 | effectiveWindowCount:4.7575 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0026 | memoryGateLong:-0.0028 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:6.8166 | windowWeightsW25:2.49592 (0.52),W21:1.24112 (0.15),W19:0.65247 (0.08),W2:0.43218 (0.07),W16:0.41133 (0.07),W13:0.29875 (0.06),W9:-0.29908 (0.03),W3:-1.17211 (0.01),W5:-1.68570 (0.01) | topTokens[(',', 1418), ('!', 586), ('i', 547), ('the', 500), ('.', 467), ('will', 443), ('to', 358), ('it', 348), ('you', 296), ('a', 270)] | 0.005750000000002225 | tokenPerfect: 41066 / 135000  30.42% | babyLLM.py 2500
2025-04-10 05:19:11 | 60000 | LR0.0003 | loss:2.8364 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-379.0395 | logitMax:-353.8228 | scheduledSampling:0.0059 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1620 | windowEntropy:1.5496 | topWindowWeight:0.5278 | effectiveWindowCount:4.7096 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0052 | memoryGateLong:-0.0059 | memoryGateCurrent:0.0011 | memoryGateMean:0.3333 | memoryGateStd:14.1202 | windowWeightsW25:2.49484 (0.53),W21:1.23808 (0.15),W19:0.63612 (0.08),W2:0.46691 (0.07),W16:0.36638 (0.06),W13:0.25911 (0.06),W9:-0.38383 (0.03),W3:-1.17319 (0.01),W5:-1.70215 (0.01) | topTokens[(',', 1504), ('!', 594), ('i', 583), ('the', 517), ('.', 472), ('will', 469), ('to', 375), ('it', 361), ('you', 301), ('a', 278)] | 0.006000000000002908 | babyLLM.py 2500
2025-04-10 05:24:24 | 62500 | LR0.0003 | loss:1.7620 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-196.8803 | logitMax:-164.3605 | scheduledSampling:0.0061 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1615 | windowEntropy:1.5542 | topWindowWeight:0.5266 | effectiveWindowCount:4.7311 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0046 | memoryGateLong:-0.0051 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:12.1519 | windowWeightsW25:2.46230 (0.53),W21:1.20074 (0.15),W19:0.58508 (0.08),W2:0.54114 (0.08),W16:0.31334 (0.06),W13:0.15413 (0.05),W9:-0.40438 (0.03),W3:-1.15608 (0.01),W5:-1.64894 (0.01) | topTokens[(',', 1541), ('!', 649), ('will', 599), ('i', 594), ('the', 546), ('.', 502), ('to', 384), ('it', 369), ('you', 317), ('a', 280)] | 0.006250000000003592 | tokenPerfect: 21210 / 45000  47.13% | babyLLM.py 2500
2025-04-10 05:29:41 | 65000 | LR0.0003 | loss:1.6434 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-184.1439 | logitMax:-149.4746 | scheduledSampling:0.0064 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1550 | windowEntropy:1.5932 | topWindowWeight:0.5077 | effectiveWindowCount:4.9195 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0045 | memoryGateLong:-0.0049 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:11.8390 | windowWeightsW25:2.39598 (0.51),W21:1.20404 (0.15),W2:0.58651 (0.08),W19:0.56466 (0.08),W16:0.30620 (0.06),W13:0.15645 (0.05),W9:-0.35650 (0.03),W3:-1.15668 (0.01),W5:-1.53772 (0.01) | topTokens[(',', 1587), ('will', 719), ('!', 691), ('i', 605), ('the', 587), ('.', 546), ('to', 394), ('it', 376), ('you', 337), ('a', 284)] | 0.006500000000004276 | tokenPerfect: 43076 / 90000  47.86% | babyLLM.py 2500
2025-04-10 05:34:58 | 67500 | LR0.0003 | loss:1.6139 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-191.8656 | logitMax:-156.4258 | scheduledSampling:0.0066 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1529 | windowEntropy:1.6094 | topWindowWeight:0.5031 | effectiveWindowCount:5.0001 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0054 | memoryGateLong:-0.0058 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:13.9627 | windowWeightsW25:2.37432 (0.50),W21:1.15801 (0.15),W2:0.60501 (0.09),W19:0.56222 (0.08),W16:0.32638 (0.06),W13:0.16080 (0.05),W9:-0.30250 (0.03),W3:-1.17181 (0.01),W5:-1.45600 (0.01) | topTokens[(',', 1622), ('will', 848), ('!', 731), ('the', 632), ('i', 610), ('.', 593), ('to', 403), ('it', 388), ('you', 349), ('and', 299)] | 0.0067500000000049595 | tokenPerfect: 65181 / 135000  48.28% | babyLLM.py 2500
2025-04-10 05:40:19 | 70000 | LR0.0003 | loss:2.1539 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-303.7605 | logitMax:-276.6642 | scheduledSampling:0.0069 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1505 | windowEntropy:1.6265 | topWindowWeight:0.4962 | effectiveWindowCount:5.0859 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0038 | memoryGateLong:-0.0040 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:9.8244 | windowWeightsW25:2.34480 (0.50),W21:1.15913 (0.15),W2:0.61509 (0.09),W19:0.49848 (0.08),W16:0.30387 (0.06),W13:0.17624 (0.06),W9:-0.24892 (0.04),W3:-1.08979 (0.02),W5:-1.41577 (0.01) | topTokens[(',', 1635), ('will', 868), ('!', 736), ('i', 656), ('.', 648), ('the', 638), ('to', 439), ('you', 393), ('it', 390), ('and', 300)] | 0.007000000000005643 | babyLLM.py 2500
2025-04-10 05:45:27 | 72500 | LR0.0003 | loss:2.0586 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-282.0457 | logitMax:-254.5086 | scheduledSampling:0.0071 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1445 | windowEntropy:1.6620 | topWindowWeight:0.4789 | effectiveWindowCount:5.2700 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0039 | memoryGateLong:-0.0041 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:9.9885 | windowWeightsW25:2.28546 (0.48),W21:1.15845 (0.16),W2:0.64207 (0.09),W19:0.49434 (0.08),W16:0.28628 (0.06),W13:0.18702 (0.06),W9:-0.20741 (0.04),W3:-0.99304 (0.02),W5:-1.38109 (0.01) | topTokens[(',', 1642), ('will', 878), ('!', 738), ('.', 711), ('i', 699), ('the', 642), ('to', 481), ('you', 444), ('it', 392), ('?', 324)] | 0.007250000000006327 | tokenPerfect: 20922 / 45000  46.49% | babyLLM.py 2500
2025-04-10 05:50:45 | 75000 | LR0.0003 | loss:1.8494 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-262.8669 | logitMax:-234.8003 | scheduledSampling:0.0074 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1386 | windowEntropy:1.6982 | topWindowWeight:0.4619 | effectiveWindowCount:5.4643 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0035 | memoryGateLong:-0.0037 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:9.0722 | windowWeightsW25:2.21897 (0.46),W21:1.15420 (0.16),W2:0.67522 (0.10),W19:0.47116 (0.08),W16:0.22137 (0.06),W13:0.16201 (0.06),W9:-0.17356 (0.04),W3:-0.85087 (0.02),W5:-1.25073 (0.01) | topTokens[(',', 1646), ('will', 889), ('.', 767), ('!', 752), ('i', 748), ('the', 643), ('to', 519), ('you', 486), ('it', 398), ('?', 386)] | 0.007500000000007011 | tokenPerfect: 43449 / 90000  48.28% | babyLLM.py 2500
2025-04-10 05:55:54 | 77500 | LR0.0003 | loss:2.1340 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-96.4088 | logitMax:-69.3542 | scheduledSampling:0.0076 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1435 | windowEntropy:1.6656 | topWindowWeight:0.4747 | effectiveWindowCount:5.2888 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0040 | memoryGateLong:-0.0042 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:10.2666 | windowWeightsW25:2.29156 (0.47),W21:1.21564 (0.16),W2:0.59428 (0.09),W19:0.59327 (0.09),W16:0.29435 (0.06),W13:0.13554 (0.05),W9:-0.23434 (0.04),W3:-0.90679 (0.02),W5:-1.32335 (0.01) | topTokens[(',', 1708), ('will', 890), ('!', 798), ('.', 780), ('i', 757), ('the', 671), ('to', 539), ('you', 492), ('it', 424), ('?', 389)] | 0.007750000000007694 | tokenPerfect: 63921 / 135000  47.35% | babyLLM.py 2500
2025-04-10 06:01:09 | 80000 | LR0.0003 | loss:1.8181 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-102.6661 | logitMax:-73.1257 | scheduledSampling:0.0079 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1444 | windowEntropy:1.6561 | topWindowWeight:0.4756 | effectiveWindowCount:5.2390 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0038 | memoryGateLong:-0.0041 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:9.9070 | windowWeightsW25:2.29802 (0.48),W21:1.24979 (0.17),W19:0.62144 (0.09),W2:0.59521 (0.09),W16:0.26677 (0.06),W13:0.08760 (0.05),W9:-0.27919 (0.04),W3:-0.90277 (0.02),W5:-1.37443 (0.01) | topTokens[(',', 1767), ('will', 890), ('!', 855), ('.', 784), ('i', 767), ('the', 711), ('to', 549), ('you', 503), ('it', 450), ('?', 391)] | 0.008000000000006752 | babyLLM.py 2500
2025-04-10 06:06:17 | 82500 | LR0.0003 | loss:1.8162 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-125.8075 | logitMax:-96.7105 | scheduledSampling:0.0081 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1449 | windowEntropy:1.6528 | topWindowWeight:0.4772 | effectiveWindowCount:5.2217 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0046 | memoryGateLong:-0.0049 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:11.9288 | windowWeightsW25:2.30547 (0.48),W21:1.24736 (0.17),W19:0.63236 (0.09),W2:0.58502 (0.09),W16:0.28795 (0.06),W13:0.09243 (0.05),W9:-0.29030 (0.04),W3:-0.90233 (0.02),W5:-1.41092 (0.01) | topTokens[(',', 1823), ('!', 900), ('will', 890), ('.', 794), ('i', 789), ('the', 744), ('to', 561), ('you', 517), ('it', 471), ('?', 391)] | 0.008250000000005267 | tokenPerfect: 21926 / 45000  48.72% | babyLLM.py 2500
2025-04-10 06:11:26 | 85000 | LR0.0003 | loss:1.8004 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-109.6100 | logitMax:-79.6484 | scheduledSampling:0.0084 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1437 | windowEntropy:1.6585 | topWindowWeight:0.4740 | effectiveWindowCount:5.2516 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0048 | memoryGateLong:-0.0052 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:12.5235 | windowWeightsW25:2.28960 (0.47),W21:1.23444 (0.17),W19:0.62380 (0.09),W2:0.60843 (0.09),W16:0.30583 (0.07),W13:0.06570 (0.05),W9:-0.28665 (0.04),W3:-0.91757 (0.02),W5:-1.43868 (0.01) | topTokens[(',', 1887), ('!', 943), ('will', 890), ('.', 807), ('i', 800), ('the', 793), ('to', 578), ('you', 530), ('it', 488), ('?', 391)] | 0.008500000000003782 | tokenPerfect: 44392 / 90000  49.32% | babyLLM.py 2500
2025-04-10 06:16:35 | 87500 | LR0.0003 | loss:2.2637 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-358.0763 | logitMax:-331.8387 | scheduledSampling:0.0086 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1419 | windowEntropy:1.6641 | topWindowWeight:0.4680 | effectiveWindowCount:5.2809 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0026 | memoryGateLong:-0.0026 | memoryGateCurrent:0.0004 | memoryGateMean:0.3333 | memoryGateStd:6.5893 | windowWeightsW25:2.31008 (0.47),W21:1.27848 (0.17),W19:0.75026 (0.10),W2:0.52799 (0.08),W16:0.40984 (0.07),W13:0.16150 (0.05),W9:-0.25570 (0.04),W3:-0.99641 (0.02),W5:-1.49366 (0.01) | topTokens[(',', 1972), ('!', 947), ('will', 890), ('i', 838), ('.', 811), ('the', 804), ('to', 595), ('you', 535), ('it', 503), ('?', 394)] | 0.008750000000002298 | tokenPerfect: 64024 / 135000  47.43% | babyLLM.py 2500
2025-04-10 06:21:58 | 90000 | LR0.0003 | loss:2.2176 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-429.1019 | logitMax:-402.4819 | scheduledSampling:0.0089 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1501 | windowEntropy:1.6136 | topWindowWeight:0.4911 | effectiveWindowCount:5.0208 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0027 | memoryGateLong:-0.0027 | memoryGateCurrent:0.0004 | memoryGateMean:0.3333 | memoryGateStd:6.7128 | windowWeightsW25:2.40009 (0.49),W21:1.30683 (0.16),W19:0.77236 (0.10),W2:0.47224 (0.07),W16:0.42155 (0.07),W13:0.15693 (0.05),W9:-0.32376 (0.03),W3:-1.08088 (0.02),W5:-1.59171 (0.01) | topTokens[(',', 2076), ('!', 951), ('will', 890), ('i', 854), ('the', 817), ('.', 815), ('to', 609), ('you', 535), ('it', 509), ('a', 406)] | 0.009000000000000813 | babyLLM.py 2500
2025-04-10 06:27:11 | 92500 | LR0.0003 | loss:2.0480 | gradNorm:0.9957 | tokenCount:45000.0000 | logitMin:-437.3072 | logitMax:-409.3589 | scheduledSampling:0.0091 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1554 | windowEntropy:1.5805 | topWindowWeight:0.5059 | effectiveWindowCount:4.8576 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0023 | memoryGateLong:-0.0024 | memoryGateCurrent:0.0004 | memoryGateMean:0.3333 | memoryGateStd:5.9290 | windowWeightsW25:2.45322 (0.51),W21:1.32793 (0.16),W19:0.77779 (0.09),W2:0.43954 (0.07),W16:0.37744 (0.06),W13:0.16285 (0.05),W9:-0.36345 (0.03),W3:-1.12199 (0.01),W5:-1.63247 (0.01) | topTokens[(',', 2167), ('!', 951), ('i', 897), ('will', 891), ('the', 826), ('.', 822), ('to', 628), ('you', 536), ('it', 519), ('a', 408)] | 0.009249999999999328 | tokenPerfect: 20521 / 45000  45.60% | babyLLM.py 2500
2025-04-10 06:32:18 | 95000 | LR0.0003 | loss:2.1520 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-516.2612 | logitMax:-487.7183 | scheduledSampling:0.0094 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1602 | windowEntropy:1.5535 | topWindowWeight:0.5204 | effectiveWindowCount:4.7281 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0028 | memoryGateLong:-0.0028 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:6.9917 | windowWeightsW25:2.48943 (0.52),W21:1.30938 (0.16),W19:0.73365 (0.09),W2:0.43703 (0.07),W16:0.36501 (0.06),W13:0.14534 (0.05),W9:-0.40187 (0.03),W3:-1.12891 (0.01),W5:-1.68314 (0.01) | topTokens[(',', 2231), ('!', 951), ('i', 934), ('will', 893), ('the', 836), ('.', 828), ('to', 648), ('you', 542), ('it', 531), ('a', 417)] | 0.009499999999997844 | tokenPerfect: 40766 / 90000  45.30% | babyLLM.py 2500
2025-04-10 06:37:36 | 97500 | LR0.0003 | loss:2.1280 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-450.2110 | logitMax:-421.1431 | scheduledSampling:0.0096 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1636 | windowEntropy:1.5324 | topWindowWeight:0.5302 | effectiveWindowCount:4.6294 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0042 | memoryGateLong:-0.0047 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:11.2240 | windowWeightsW25:2.50066 (0.53),W21:1.28398 (0.16),W19:0.70292 (0.09),W2:0.48213 (0.07),W16:0.28664 (0.06),W13:0.10232 (0.05),W9:-0.48390 (0.03),W3:-1.16267 (0.01),W5:-1.70932 (0.01) | topTokens[(',', 2315), ('i', 973), ('!', 962), ('will', 923), ('the', 851), ('.', 839), ('to', 660), ('you', 548), ('it', 538), ('a', 421)] | 0.009749999999996359 | tokenPerfect: 60779 / 135000  45.02% | babyLLM.py 2500
2025-04-10 06:42:57 | 100000 | LR0.0003 | loss:1.7142 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-233.7954 | logitMax:-199.4146 | scheduledSampling:0.0099 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1616 | windowEntropy:1.5438 | topWindowWeight:0.5241 | effectiveWindowCount:4.6822 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0047 | memoryGateLong:-0.0052 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:12.4430 | windowWeightsW25:2.46913 (0.52),W21:1.27591 (0.16),W19:0.68795 (0.09),W2:0.53440 (0.08),W16:0.26637 (0.06),W13:0.02253 (0.05),W9:-0.47810 (0.03),W3:-1.16635 (0.01),W5:-1.67567 (0.01) | topTokens[(',', 2357), ('will', 1036), ('!', 1006), ('i', 981), ('the', 883), ('.', 865), ('to', 669), ('you', 559), ('it', 541), ('she', 422)] | 0.009999999999994874 | babyLLM.py 2500

--- 2025-04-10 06:44:07 --- babyLLM 'right, last time i got to step 230400... want to restart from there?'  - charis: 'no' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: ''
2025-04-10 06:49:21 | 2500 | LR0.0003 | loss:5.4333 | gradNorm:1.0000 | logitMin:-378.5639 | logitMax:-352.4648 | scheduledSampling:0.0006 | tokenCount:45000.0000 | memoryGateShort:0.0031 | memoryGateLong:-0.0031 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1768 | windowEntropy:1.4417 | topWindowWeight:0.5667 | effectiveWindowCount:4.2279 | memoryGateMean:0.3333 | memoryGateStd:7.7927 | windowWeightsW25:2.61089 (0.57),W21:1.31511 (0.16),W19:0.67353 (0.08),W2:0.46001 (0.07),W16:0.22147 (0.05),W13:-0.06297 (0.04),W9:-0.64226 (0.02),W3:-1.33165 (0.01),W5:-1.83790 (0.01) | topTokens[('.', 37), ('i', 30), (',', 28), ('and', 23), ('the', 20), ('it', 19), ('a', 17), ('to', 16), ('you', 15), ('but', 13)] | tokenPerfect: 7333 / 45000  16.30% | babyLLM.py 2500
2025-04-10 06:54:34 | 5000 | LR0.0003 | loss:5.0574 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-358.7004 | logitMax:-333.5673 | scheduledSampling:0.0019 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1854 | windowEntropy:1.3884 | topWindowWeight:0.5927 | effectiveWindowCount:4.0083 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0028 | memoryGateLong:-0.0029 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:7.0973 | windowWeightsW25:2.66024 (0.59),W21:1.23841 (0.14),W19:0.59439 (0.08),W2:0.49756 (0.07),W16:0.16524 (0.05),W13:-0.13061 (0.04),W9:-0.75332 (0.02),W3:-1.37753 (0.01),W5:-1.95628 (0.01) | topTokens[('.', 72), (',', 59), ('i', 50), ('the', 41), ('it', 38), ('and', 34), ('you', 30), ('to', 29), ('s', 29), ('a', 25)] | tokenPerfect: 14942 / 90000  16.60% | babyLLM.py 2500

--- 2025-04-10 06:55:41 --- babyLLM 'right, last time i got to step 5236... want to restart from there?'  - charis: 'n' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: ''
2025-04-10 07:00:57 | 2500 | LR0.0003 | loss:1.6928 | gradNorm:1.0000 | logitMin:-415.1287 | logitMax:-389.8147 | scheduledSampling:0.0006 | tokenCount:45000.0000 | memoryGateShort:0.0022 | memoryGateLong:-0.0023 | memoryGateCurrent:0.0005 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1678 | windowEntropy:1.5037 | topWindowWeight:0.5429 | effectiveWindowCount:4.4982 | memoryGateMean:0.3333 | memoryGateStd:5.7419 | windowWeightsW25:2.53799 (0.54),W21:1.25683 (0.15),W19:0.68114 (0.08),W2:0.51003 (0.07),W16:0.34933 (0.06),W13:0.08746 (0.05),W9:-0.58174 (0.02),W3:-1.32289 (0.01),W5:-1.81018 (0.01) | topTokens[(',', 28), ('.', 25), ('to', 25), ('a', 18), ('the', 18), ('is', 16), ('ing', 15), ('i', 15), ('it', 14), ('for', 11)] | tokenPerfect: 23026 / 45000  51.17% | babyLLM.py 2500
2025-04-10 07:06:12 | 5000 | LR0.0003 | loss:1.8735 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-483.3352 | logitMax:-455.0047 | scheduledSampling:0.0019 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1601 | windowEntropy:1.5461 | topWindowWeight:0.5194 | effectiveWindowCount:4.6929 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0019 | memoryGateLong:-0.0019 | memoryGateCurrent:0.0004 | memoryGateMean:0.3333 | memoryGateStd:4.8936 | windowWeightsW25:2.48917 (0.52),W21:1.30748 (0.16),W19:0.74803 (0.09),W2:0.49350 (0.07),W16:0.43395 (0.07),W13:0.13598 (0.05),W9:-0.54787 (0.02),W3:-1.31415 (0.01),W5:-1.79685 (0.01) | topTokens[('.', 54), (',', 47), ('the', 42), ('it', 40), ('to', 39), ('a', 29), ('i', 28), ('ing', 24), ('is', 22), ('and', 22)] | tokenPerfect: 46485 / 90000  51.65% | babyLLM.py 2500
2025-04-10 07:11:29 | 7500 | LR0.0003 | loss:4.6361 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-441.7342 | logitMax:-413.5751 | scheduledSampling:0.0031 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1767 | windowEntropy:1.4423 | topWindowWeight:0.5673 | effectiveWindowCount:4.2302 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0032 | memoryGateLong:-0.0033 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:8.1606 | windowWeightsW25:2.61192 (0.57),W21:1.27949 (0.15),W19:0.67159 (0.08),W2:0.48216 (0.07),W16:0.30179 (0.06),W13:-0.01628 (0.04),W9:-0.70699 (0.02),W3:-1.40182 (0.01),W5:-1.94111 (0.01) | topTokens[('.', 82), (',', 70), ('to', 66), ('the', 59), ('i', 54), ('it', 53), ('a', 44), ('and', 38), ('that', 30), ('is', 29)] | tokenPerfect: 56991 / 135000  42.22% | babyLLM.py 2500
2025-04-10 07:16:55 | 10000 | LR0.0003 | loss:4.7194 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-390.5214 | logitMax:-365.1739 | scheduledSampling:0.0044 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1858 | windowEntropy:1.3834 | topWindowWeight:0.5936 | effectiveWindowCount:3.9885 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0031 | memoryGateLong:-0.0032 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:7.8848 | windowWeightsW25:2.66667 (0.59),W21:1.24026 (0.14),W19:0.59917 (0.08),W2:0.50144 (0.07),W16:0.19916 (0.05),W13:-0.12415 (0.04),W9:-0.79196 (0.02),W3:-1.43719 (0.01),W5:-2.04581 (0.01) | topTokens[('.', 106), ('to', 90), (',', 88), ('i', 86), ('the', 84), ('it', 67), ('a', 55), ('and', 51), ('that', 43), ('is', 38)] | babyLLM.py 2500
2025-04-10 07:22:07 | 12500 | LR0.0003 | loss:4.5222 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-348.7031 | logitMax:-324.1053 | scheduledSampling:0.0056 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1870 | windowEntropy:1.3781 | topWindowWeight:0.5977 | effectiveWindowCount:3.9673 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0035 | memoryGateLong:-0.0039 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:9.3279 | windowWeightsW25:2.65440 (0.60),W21:1.17835 (0.14),W19:0.55521 (0.07),W2:0.54668 (0.07),W16:0.18057 (0.05),W13:-0.15464 (0.04),W9:-0.84022 (0.02),W3:-1.43651 (0.01),W5:-2.07955 (0.01) | topTokens[('.', 138), (',', 116), ('to', 104), ('the', 103), ('i', 103), ('it', 78), ('and', 65), ('a', 62), ('ing', 50), ('that', 49)] | tokenPerfect: 8807 / 45000  19.57% | babyLLM.py 2500
2025-04-10 07:27:16 | 15000 | LR0.0003 | loss:3.8018 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-308.1522 | logitMax:-283.9345 | scheduledSampling:0.0069 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1768 | windowEntropy:1.4441 | topWindowWeight:0.5686 | effectiveWindowCount:4.2380 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0037 | memoryGateLong:-0.0041 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:9.8792 | windowWeightsW25:2.55536 (0.57),W21:1.16877 (0.14),W2:0.61793 (0.08),W19:0.55033 (0.08),W16:0.20534 (0.05),W13:-0.10161 (0.04),W9:-0.80404 (0.02),W3:-1.36244 (0.01),W5:-2.05283 (0.01) | topTokens[('.', 163), (',', 134), ('i', 131), ('the', 115), ('to', 112), ('it', 106), ('a', 84), ('and', 70), ('ing', 58), ('that', 57)] | tokenPerfect: 19611 / 90000  21.79% | babyLLM.py 2500
2025-04-10 07:32:25 | 17500 | LR0.0003 | loss:2.2029 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-236.1562 | logitMax:-207.5714 | scheduledSampling:0.0081 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1666 | windowEntropy:1.5082 | topWindowWeight:0.5392 | effectiveWindowCount:4.5187 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0048 | memoryGateLong:-0.0053 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:12.7409 | windowWeightsW25:2.43936 (0.54),W21:1.13774 (0.15),W2:0.72477 (0.10),W19:0.48345 (0.08),W16:0.18104 (0.06),W13:-0.10023 (0.04),W9:-0.78006 (0.02),W3:-1.20305 (0.01),W5:-2.02026 (0.01) | topTokens[('it', 192), ('.', 165), ('!', 160), ('i', 143), (',', 137), ('to', 118), ('the', 116), ('a', 110), ('and', 87), ('have', 69)] | tokenPerfect: 39340 / 135000  29.14% | babyLLM.py 2500
2025-04-10 07:37:40 | 20000 | LR0.0003 | loss:2.6720 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-246.8362 | logitMax:-218.1921 | scheduledSampling:0.0094 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1635 | windowEntropy:1.5284 | topWindowWeight:0.5305 | effectiveWindowCount:4.6109 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0040 | memoryGateLong:-0.0040 | memoryGateCurrent:0.0004 | memoryGateMean:0.3333 | memoryGateStd:9.9792 | windowWeightsW25:2.41084 (0.53),W21:1.12554 (0.15),W2:0.74125 (0.10),W19:0.45628 (0.08),W16:0.23514 (0.06),W13:-0.07559 (0.04),W9:-0.74980 (0.02),W3:-1.17164 (0.01),W5:-2.04092 (0.01) | topTokens[('!', 271), ('it', 269), ('.', 170), ('i', 157), (',', 148), ('a', 131), ('to', 123), ('the', 118), ('and', 106), ('have', 97)] | babyLLM.py 2500
2025-04-10 07:42:48 | 22500 | LR0.0003 | loss:3.8504 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-311.8905 | logitMax:-288.9613 | scheduledSampling:0.0106 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1628 | windowEntropy:1.5278 | topWindowWeight:0.5278 | effectiveWindowCount:4.6080 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0039 | memoryGateLong:-0.0042 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:10.1797 | windowWeightsW25:2.44975 (0.53),W21:1.22107 (0.15),W2:0.65686 (0.09),W19:0.55591 (0.08),W16:0.32626 (0.06),W13:0.01273 (0.05),W9:-0.68225 (0.02),W3:-1.27574 (0.01),W5:-2.12122 (0.01) | topTokens[('it', 281), ('!', 274), ('i', 196), ('.', 189), (',', 169), ('a', 146), ('to', 139), ('the', 134), ('and', 111), ('have', 100)] | tokenPerfect: 10895 / 45000  24.21% | babyLLM.py 2500
2025-04-10 07:47:56 | 25000 | LR0.0003 | loss:3.4726 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-323.1958 | logitMax:-300.3465 | scheduledSampling:0.0119 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1618 | windowEntropy:1.5305 | topWindowWeight:0.5239 | effectiveWindowCount:4.6206 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0033 | memoryGateLong:-0.0036 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:8.7237 | windowWeightsW25:2.46330 (0.52),W21:1.27430 (0.16),W19:0.62460 (0.08),W2:0.62227 (0.08),W16:0.34077 (0.06),W13:0.04766 (0.05),W9:-0.64733 (0.02),W3:-1.31768 (0.01),W5:-2.13805 (0.01) | topTokens[('it', 297), ('!', 275), ('i', 225), ('.', 206), (',', 192), ('a', 164), ('to', 164), ('the', 152), ('and', 115), ('have', 105)] | tokenPerfect: 23852 / 90000  26.50% | babyLLM.py 2500
2025-04-10 07:53:04 | 27500 | LR0.0003 | loss:5.0206 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-361.3419 | logitMax:-338.9833 | scheduledSampling:0.0131 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1768 | windowEntropy:1.4372 | topWindowWeight:0.5670 | effectiveWindowCount:4.2088 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0037 | memoryGateLong:-0.0040 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:9.6542 | windowWeightsW25:2.59124 (0.57),W21:1.27506 (0.15),W19:0.58280 (0.08),W2:0.56231 (0.07),W16:0.25790 (0.05),W13:-0.05177 (0.04),W9:-0.74089 (0.02),W3:-1.42131 (0.01),W5:-2.22948 (0.00) | topTokens[('it', 306), ('!', 285), ('i', 275), ('.', 234), (',', 209), ('to', 179), ('a', 173), ('the', 172), ('and', 127), ('have', 110)] | tokenPerfect: 30586 / 135000  22.66% | babyLLM.py 2500
2025-04-10 07:58:21 | 30000 | LR0.0003 | loss:4.8834 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-355.2477 | logitMax:-333.6134 | scheduledSampling:0.0144 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1848 | windowEntropy:1.3820 | topWindowWeight:0.5892 | effectiveWindowCount:3.9827 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0035 | memoryGateLong:-0.0036 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:8.9397 | windowWeightsW25:2.65948 (0.59),W21:1.29579 (0.15),W19:0.54746 (0.07),W2:0.53336 (0.07),W16:0.20477 (0.05),W13:-0.11783 (0.04),W9:-0.84795 (0.02),W3:-1.47163 (0.01),W5:-2.30406 (0.00) | topTokens[('i', 332), ('it', 315), ('!', 291), ('.', 283), (',', 222), ('to', 195), ('a', 187), ('the', 182), ('and', 143), ('have', 118)] | babyLLM.py 2500
2025-04-10 08:03:29 | 32500 | LR0.0003 | loss:4.4373 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-336.6060 | logitMax:-314.2344 | scheduledSampling:0.0156 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1831 | windowEntropy:1.3968 | topWindowWeight:0.5853 | effectiveWindowCount:4.0423 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0044 | memoryGateLong:-0.0048 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:11.4855 | windowWeightsW25:2.63357 (0.59),W21:1.24576 (0.15),W2:0.55688 (0.07),W19:0.53409 (0.07),W16:0.23154 (0.05),W13:-0.08194 (0.04),W9:-0.86129 (0.02),W3:-1.45141 (0.01),W5:-2.30306 (0.00) | topTokens[('i', 380), ('it', 326), ('.', 306), ('!', 294), (',', 245), ('to', 213), ('the', 196), ('a', 195), ('and', 166), ('have', 128)] | tokenPerfect: 7200 / 45000  16.00% | babyLLM.py 2500
2025-04-10 08:08:37 | 35000 | LR0.0003 | loss:4.8486 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-360.9657 | logitMax:-339.5818 | scheduledSampling:0.0169 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1829 | windowEntropy:1.4002 | topWindowWeight:0.5856 | effectiveWindowCount:4.0560 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0041 | memoryGateLong:-0.0043 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:10.4760 | windowWeightsW25:2.63524 (0.59),W21:1.21684 (0.14),W19:0.54878 (0.07),W2:0.54853 (0.07),W16:0.27584 (0.06),W13:-0.03995 (0.04),W9:-0.87012 (0.02),W3:-1.45518 (0.01),W5:-2.31770 (0.00) | topTokens[('i', 419), ('.', 338), ('it', 336), ('!', 307), (',', 254), ('to', 223), ('a', 213), ('the', 203), ('and', 176), ('have', 133)] | tokenPerfect: 13178 / 90000  14.64% | babyLLM.py 2500
2025-04-10 08:13:46 | 37500 | LR0.0003 | loss:4.4785 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-323.6384 | logitMax:-301.8821 | scheduledSampling:0.0181 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1801 | windowEntropy:1.4208 | topWindowWeight:0.5781 | effectiveWindowCount:4.1403 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0047 | memoryGateLong:-0.0052 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:12.5191 | windowWeightsW25:2.60717 (0.58),W21:1.18789 (0.14),W2:0.56842 (0.08),W19:0.56326 (0.07),W16:0.27895 (0.06),W13:0.00208 (0.04),W9:-0.83587 (0.02),W3:-1.44521 (0.01),W5:-2.29882 (0.00) | topTokens[('i', 435), ('.', 380), ('it', 351), ('!', 310), (',', 262), ('to', 243), ('a', 228), ('the', 215), ('and', 194), ('that', 140)] | tokenPerfect: 20580 / 135000  15.24% | babyLLM.py 2500
2025-04-10 08:19:06 | 40000 | LR0.0003 | loss:3.7554 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-286.3541 | logitMax:-263.8647 | scheduledSampling:0.0194 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1704 | windowEntropy:1.4846 | topWindowWeight:0.5515 | effectiveWindowCount:4.4133 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0044 | memoryGateLong:-0.0049 | memoryGateCurrent:0.0010 | memoryGateMean:0.3333 | memoryGateStd:11.7586 | windowWeightsW25:2.51857 (0.55),W21:1.14205 (0.14),W2:0.61966 (0.08),W19:0.57233 (0.08),W16:0.34931 (0.06),W13:0.08453 (0.05),W9:-0.74998 (0.02),W3:-1.40855 (0.01),W5:-2.26378 (0.00) | topTokens[('i', 453), ('.', 397), ('it', 357), ('!', 310), (',', 294), ('the', 260), ('to', 257), ('a', 238), ('and', 205), ('that', 143)] | babyLLM.py 2500
2025-04-10 08:24:18 | 42500 | LR0.0003 | loss:3.7044 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-296.4046 | logitMax:-273.6614 | scheduledSampling:0.0206 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1624 | windowEntropy:1.5340 | topWindowWeight:0.5289 | effectiveWindowCount:4.6367 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0044 | memoryGateLong:-0.0049 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:11.7638 | windowWeightsW25:2.45571 (0.53),W21:1.13402 (0.14),W2:0.64028 (0.09),W19:0.60152 (0.08),W16:0.41491 (0.07),W13:0.16037 (0.05),W9:-0.68581 (0.02),W3:-1.39245 (0.01),W5:-2.21865 (0.00) | topTokens[('i', 479), ('.', 419), ('it', 362), (',', 315), ('!', 310), ('the', 297), ('to', 272), ('a', 247), ('and', 217), ('s', 153)] | tokenPerfect: 11066 / 45000  24.59% | babyLLM.py 2500
2025-04-10 08:29:27 | 45000 | LR0.0003 | loss:3.5361 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-305.7386 | logitMax:-282.7576 | scheduledSampling:0.0219 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1589 | windowEntropy:1.5550 | topWindowWeight:0.5189 | effectiveWindowCount:4.7349 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0042 | memoryGateLong:-0.0046 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:11.0452 | windowWeightsW25:2.42843 (0.52),W21:1.12366 (0.14),W2:0.64491 (0.09),W19:0.62412 (0.09),W16:0.46104 (0.07),W13:0.18954 (0.06),W9:-0.65858 (0.02),W3:-1.40195 (0.01),W5:-2.23238 (0.00) | topTokens[('i', 484), ('.', 442), ('it', 366), (',', 335), ('the', 324), ('!', 310), ('to', 289), ('a', 253), ('and', 234), ('s', 170)] | tokenPerfect: 23488 / 90000  26.10% | babyLLM.py 2500
2025-04-10 08:34:35 | 47500 | LR0.0003 | loss:3.5578 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-297.6938 | logitMax:-274.5383 | scheduledSampling:0.0231 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1602 | windowEntropy:1.5488 | topWindowWeight:0.5231 | effectiveWindowCount:4.7060 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0080 | memoryGateLong:-0.0090 | memoryGateCurrent:0.0014 | memoryGateMean:0.3333 | memoryGateStd:21.3811 | windowWeightsW25:2.44002 (0.52),W21:1.10865 (0.14),W2:0.63519 (0.09),W19:0.62912 (0.09),W16:0.45480 (0.07),W13:0.19391 (0.06),W9:-0.64281 (0.02),W3:-1.40440 (0.01),W5:-2.23382 (0.00) | topTokens[('i', 502), ('.', 458), ('it', 374), (',', 352), ('the', 342), ('to', 314), ('!', 310), ('a', 265), ('and', 252), ('s', 184)] | tokenPerfect: 35966 / 135000  26.64% | babyLLM.py 2500
2025-04-10 08:39:52 | 50000 | LR0.0003 | loss:3.8682 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-252.8030 | logitMax:-226.5251 | scheduledSampling:0.0244 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1597 | windowEntropy:1.5547 | topWindowWeight:0.5224 | effectiveWindowCount:4.7336 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0129 | memoryGateLong:-0.0145 | memoryGateCurrent:0.0020 | memoryGateMean:0.3333 | memoryGateStd:34.4471 | windowWeightsW25:2.43255 (0.52),W21:1.08091 (0.14),W2:0.63494 (0.09),W19:0.60532 (0.08),W16:0.46183 (0.07),W13:0.22755 (0.06),W9:-0.61162 (0.02),W3:-1.35492 (0.01),W5:-2.26232 (0.00) | topTokens[('i', 533), ('.', 505), ('it', 385), (',', 377), ('the', 362), ('to', 335), ('!', 320), ('a', 292), ('and', 264), ('s', 186)] | babyLLM.py 2500
2025-04-10 08:45:01 | 52500 | LR0.0003 | loss:3.3627 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-227.0561 | logitMax:-197.5774 | scheduledSampling:0.0256 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1569 | windowEntropy:1.5753 | topWindowWeight:0.5153 | effectiveWindowCount:4.8321 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0044 | memoryGateLong:-0.0047 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:11.4010 | windowWeightsW25:2.39080 (0.52),W21:1.02304 (0.13),W2:0.67779 (0.09),W19:0.57864 (0.08),W16:0.43658 (0.07),W13:0.21439 (0.06),W9:-0.58129 (0.03),W3:-1.26647 (0.01),W5:-2.19114 (0.01) | topTokens[('i', 587), ('.', 584), ('it', 402), (',', 391), ('the', 372), ('to', 359), ('!', 332), ('a', 316), ('and', 269), ('s', 187)] | tokenPerfect: 11434 / 45000  25.41% | babyLLM.py 2500
2025-04-10 08:50:09 | 55000 | LR0.0003 | loss:2.8777 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-302.5304 | logitMax:-278.5303 | scheduledSampling:0.0269 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1479 | windowEntropy:1.6332 | topWindowWeight:0.4910 | effectiveWindowCount:5.1204 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0050 | memoryGateLong:-0.0056 | memoryGateCurrent:0.0011 | memoryGateMean:0.3333 | memoryGateStd:13.3764 | windowWeightsW25:2.29903 (0.49),W21:0.92398 (0.12),W2:0.73838 (0.10),W19:0.55296 (0.09),W16:0.45305 (0.08),W13:0.29919 (0.07),W9:-0.46782 (0.03),W3:-1.14991 (0.02),W5:-2.15046 (0.01) | topTokens[('.', 616), ('i', 611), ('to', 420), (',', 411), ('it', 407), ('the', 388), ('!', 339), ('a', 331), ('and', 271), ('you', 197)] | tokenPerfect: 29389 / 90000  32.65% | babyLLM.py 2500
2025-04-10 08:55:16 | 57500 | LR0.0003 | loss:2.7132 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-304.1463 | logitMax:-279.8247 | scheduledSampling:0.0281 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1420 | windowEntropy:1.6687 | topWindowWeight:0.4751 | effectiveWindowCount:5.3053 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0057 | memoryGateLong:-0.0061 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:14.8457 | windowWeightsW25:2.24837 (0.48),W21:0.87090 (0.12),W2:0.76273 (0.11),W19:0.52373 (0.08),W16:0.51876 (0.08),W13:0.35585 (0.07),W9:-0.38121 (0.03),W3:-1.09486 (0.02),W5:-2.12553 (0.01) | topTokens[('.', 657), ('i', 634), ('to', 451), (',', 433), ('it', 410), ('the', 402), ('!', 351), ('a', 348), ('and', 274), ('you', 218)] | tokenPerfect: 48288 / 135000  35.77% | babyLLM.py 2500
2025-04-10 09:00:34 | 60000 | LR0.0003 | loss:2.6915 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-288.7360 | logitMax:-263.8346 | scheduledSampling:0.0294 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1373 | windowEntropy:1.6959 | topWindowWeight:0.4618 | effectiveWindowCount:5.4517 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0072 | memoryGateLong:-0.0079 | memoryGateCurrent:0.0012 | memoryGateMean:0.3333 | memoryGateStd:18.9834 | windowWeightsW25:2.20269 (0.46),W21:0.82358 (0.12),W2:0.78234 (0.11),W19:0.53543 (0.09),W16:0.53503 (0.09),W13:0.39466 (0.08),W9:-0.34482 (0.04),W3:-1.03392 (0.02),W5:-2.14037 (0.01) | topTokens[('.', 694), ('i', 657), ('to', 505), (',', 445), ('the', 427), ('it', 414), ('!', 368), ('a', 364), ('and', 285), ('you', 237)] | babyLLM.py 2500
2025-04-10 09:05:42 | 62500 | LR0.0003 | loss:2.6551 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-231.4897 | logitMax:-206.7046 | scheduledSampling:0.0306 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1408 | windowEntropy:1.6778 | topWindowWeight:0.4720 | effectiveWindowCount:5.3536 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0057 | memoryGateLong:-0.0061 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:14.8534 | windowWeightsW25:2.23513 (0.47),W21:0.82672 (0.12),W2:0.76616 (0.11),W19:0.54767 (0.09),W16:0.51580 (0.08),W13:0.37445 (0.07),W9:-0.38715 (0.03),W3:-1.01318 (0.02),W5:-2.13795 (0.01) | topTokens[('.', 728), ('i', 667), ('to', 513), (',', 487), ('the', 454), ('it', 433), ('!', 408), ('a', 377), ('and', 293), ('you', 251)] | tokenPerfect: 15802 / 45000  35.12% | babyLLM.py 2500
2025-04-10 09:10:49 | 65000 | LR0.0003 | loss:2.7402 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-206.6083 | logitMax:-180.6743 | scheduledSampling:0.0319 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1405 | windowEntropy:1.6806 | topWindowWeight:0.4714 | effectiveWindowCount:5.3687 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0051 | memoryGateLong:-0.0056 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:13.4475 | windowWeightsW25:2.23866 (0.47),W21:0.84680 (0.12),W2:0.74924 (0.11),W19:0.55739 (0.09),W16:0.52639 (0.09),W13:0.36607 (0.07),W9:-0.36085 (0.04),W3:-1.00095 (0.02),W5:-2.07014 (0.01) | topTokens[('.', 745), ('i', 675), (',', 536), ('to', 529), ('the', 502), ('it', 467), ('!', 463), ('a', 397), ('and', 298), ('you', 267)] | tokenPerfect: 31357 / 90000  34.84% | babyLLM.py 2500
2025-04-10 09:15:58 | 67500 | LR0.0003 | loss:2.3966 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-222.4622 | logitMax:-196.6260 | scheduledSampling:0.0331 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1367 | windowEntropy:1.7032 | topWindowWeight:0.4609 | effectiveWindowCount:5.4915 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0053 | memoryGateLong:-0.0056 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:13.7406 | windowWeightsW25:2.21189 (0.46),W21:0.84856 (0.12),W2:0.74084 (0.11),W19:0.58223 (0.09),W16:0.52812 (0.09),W13:0.40214 (0.08),W9:-0.28840 (0.04),W3:-0.95257 (0.02),W5:-2.02836 (0.01) | topTokens[('.', 760), ('i', 694), (',', 597), ('to', 545), ('the', 537), ('!', 503), ('it', 491), ('a', 405), ('and', 300), ('you', 282)] | tokenPerfect: 48792 / 135000  36.14% | babyLLM.py 2500
2025-04-10 09:21:17 | 70000 | LR0.0003 | loss:2.3182 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-212.4967 | logitMax:-185.6819 | scheduledSampling:0.0344 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1364 | windowEntropy:1.7073 | topWindowWeight:0.4604 | effectiveWindowCount:5.5140 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0072 | memoryGateLong:-0.0080 | memoryGateCurrent:0.0011 | memoryGateMean:0.3333 | memoryGateStd:19.1356 | windowWeightsW25:2.20044 (0.46),W21:0.81972 (0.12),W2:0.75217 (0.11),W19:0.54772 (0.09),W16:0.53160 (0.09),W13:0.37725 (0.07),W9:-0.26009 (0.04),W3:-0.92777 (0.02),W5:-1.99000 (0.01) | topTokens[('.', 770), ('i', 703), (',', 655), ('the', 564), ('to', 563), ('!', 554), ('it', 519), ('a', 425), ('you', 309), ('and', 306)] | babyLLM.py 2500
2025-04-10 09:26:29 | 72500 | LR0.0003 | loss:3.3832 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-292.5460 | logitMax:-268.2627 | scheduledSampling:0.0356 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1373 | windowEntropy:1.7024 | topWindowWeight:0.4629 | effectiveWindowCount:5.4872 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0059 | memoryGateLong:-0.0066 | memoryGateCurrent:0.0011 | memoryGateMean:0.3333 | memoryGateStd:15.7223 | windowWeightsW25:2.20512 (0.46),W21:0.82158 (0.12),W2:0.75536 (0.11),W19:0.54555 (0.09),W16:0.51162 (0.09),W13:0.36274 (0.07),W9:-0.26768 (0.04),W3:-0.96203 (0.02),W5:-1.93685 (0.01) | topTokens[('.', 780), ('i', 722), (',', 683), ('the', 587), ('to', 584), ('!', 573), ('it', 538), ('a', 444), ('you', 320), ('and', 311)] | tokenPerfect: 14737 / 45000  32.75% | babyLLM.py 2500
2025-04-10 09:31:39 | 75000 | LR0.0003 | loss:4.3832 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-355.7681 | logitMax:-333.1586 | scheduledSampling:0.0369 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1452 | windowEntropy:1.6567 | topWindowWeight:0.4855 | effectiveWindowCount:5.2418 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0051 | memoryGateLong:-0.0053 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:13.0089 | windowWeightsW25:2.29346 (0.49),W21:0.85489 (0.12),W2:0.69699 (0.10),W19:0.56986 (0.09),W16:0.53358 (0.08),W13:0.37946 (0.07),W9:-0.31007 (0.04),W3:-1.07093 (0.02),W5:-2.02541 (0.01) | topTokens[('.', 793), ('i', 757), (',', 712), ('the', 615), ('to', 598), ('!', 584), ('it', 554), ('a', 457), ('you', 329), ('and', 324)] | tokenPerfect: 25422 / 90000  28.25% | babyLLM.py 2500
2025-04-10 09:36:47 | 77500 | LR0.0003 | loss:5.1438 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-355.8197 | logitMax:-334.8313 | scheduledSampling:0.0381 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1581 | windowEntropy:1.5806 | topWindowWeight:0.5215 | effectiveWindowCount:4.8579 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0049 | memoryGateLong:-0.0051 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:12.4711 | windowWeightsW25:2.39990 (0.52),W21:0.88734 (0.11),W2:0.65262 (0.09),W19:0.57219 (0.08),W16:0.46429 (0.08),W13:0.27246 (0.06),W9:-0.42647 (0.03),W3:-1.14730 (0.02),W5:-2.14050 (0.01) | topTokens[('.', 822), ('i', 792), (',', 733), ('the', 627), ('to', 619), ('!', 584), ('it', 562), ('a', 466), ('and', 341), ('you', 331)] | tokenPerfect: 30494 / 135000  22.59% | babyLLM.py 2500
2025-04-10 09:42:05 | 80000 | LR0.0003 | loss:4.7220 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-340.6221 | logitMax:-319.3860 | scheduledSampling:0.0394 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1642 | windowEntropy:1.5424 | topWindowWeight:0.5383 | effectiveWindowCount:4.6759 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0054 | memoryGateLong:-0.0057 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:14.0280 | windowWeightsW25:2.44338 (0.54),W21:0.88042 (0.11),W2:0.65262 (0.09),W19:0.57368 (0.08),W16:0.42588 (0.07),W13:0.20430 (0.06),W9:-0.51521 (0.03),W3:-1.18547 (0.01),W5:-2.23241 (0.01) | topTokens[('.', 859), ('i', 837), (',', 754), ('the', 634), ('to', 634), ('!', 585), ('it', 572), ('a', 478), ('and', 351), ('you', 339)] | babyLLM.py 2500
2025-04-10 09:47:13 | 82500 | LR0.0003 | loss:4.8346 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-364.3672 | logitMax:-343.6355 | scheduledSampling:0.0406 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1651 | windowEntropy:1.5334 | topWindowWeight:0.5402 | effectiveWindowCount:4.6340 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0057 | memoryGateLong:-0.0058 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:14.4061 | windowWeightsW25:2.46976 (0.54),W21:0.93997 (0.12),W19:0.62427 (0.09),W2:0.61735 (0.08),W16:0.45021 (0.07),W13:0.20297 (0.06),W9:-0.51297 (0.03),W3:-1.25022 (0.01),W5:-2.28200 (0.00) | topTokens[('i', 881), ('.', 878), (',', 772), ('the', 652), ('to', 651), ('!', 587), ('it', 582), ('a', 491), ('and', 375), ('you', 346)] | tokenPerfect: 6238 / 45000  13.86% | babyLLM.py 2500
2025-04-10 09:52:21 | 85000 | LR0.0003 | loss:3.6304 | gradNorm:0.9975 | tokenCount:45000.0000 | logitMin:-309.4922 | logitMax:-287.4583 | scheduledSampling:0.0419 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1580 | windowEntropy:1.5761 | topWindowWeight:0.5200 | effectiveWindowCount:4.8360 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0054 | memoryGateLong:-0.0061 | memoryGateCurrent:0.0011 | memoryGateMean:0.3333 | memoryGateStd:14.4554 | windowWeightsW25:2.41087 (0.52),W21:0.95598 (0.12),W2:0.63603 (0.09),W19:0.59824 (0.08),W16:0.50187 (0.08),W13:0.25606 (0.06),W9:-0.47661 (0.03),W3:-1.19681 (0.01),W5:-2.20716 (0.01) | topTokens[('i', 917), ('.', 882), (',', 860), ('the', 679), ('to', 662), ('it', 591), ('!', 588), ('a', 499), ('and', 381), ('you', 360)] | tokenPerfect: 18067 / 90000  20.07% | babyLLM.py 2500
2025-04-10 09:57:29 | 87500 | LR0.0003 | loss:3.4060 | gradNorm:0.9988 | tokenCount:45000.0000 | logitMin:-290.4633 | logitMax:-267.5572 | scheduledSampling:0.0431 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1501 | windowEntropy:1.6184 | topWindowWeight:0.4970 | effectiveWindowCount:5.0452 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0053 | memoryGateLong:-0.0061 | memoryGateCurrent:0.0012 | memoryGateMean:0.3333 | memoryGateStd:14.4939 | windowWeightsW25:2.35518 (0.50),W21:1.00446 (0.13),W2:0.65253 (0.09),W19:0.64075 (0.09),W16:0.51533 (0.08),W13:0.32623 (0.07),W9:-0.44463 (0.03),W3:-1.19243 (0.01),W5:-2.16091 (0.01) | topTokens[('i', 949), (',', 948), ('.', 885), ('the', 710), ('to', 675), ('it', 595), ('!', 590), ('a', 504), ('and', 397), ('you', 389)] | tokenPerfect: 29600 / 135000  21.93% | babyLLM.py 2500
2025-04-10 10:02:51 | 90000 | LR0.0003 | loss:3.3212 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-323.7948 | logitMax:-301.3429 | scheduledSampling:0.0444 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1453 | windowEntropy:1.6429 | topWindowWeight:0.4825 | effectiveWindowCount:5.1699 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0044 | memoryGateLong:-0.0047 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:11.4675 | windowWeightsW25:2.34170 (0.48),W21:1.06125 (0.13),W19:0.71802 (0.10),W2:0.61074 (0.09),W16:0.57267 (0.08),W13:0.40340 (0.07),W9:-0.37936 (0.03),W3:-1.19773 (0.01),W5:-2.17228 (0.01) | topTokens[(',', 1038), ('i', 987), ('.', 891), ('the', 726), ('to', 687), ('it', 602), ('!', 591), ('a', 521), ('and', 410), ('you', 405)] | babyLLM.py 2500
2025-04-10 10:07:59 | 92500 | LR0.0003 | loss:3.1044 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-350.7880 | logitMax:-328.0081 | scheduledSampling:0.0456 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1435 | windowEntropy:1.6510 | topWindowWeight:0.4765 | effectiveWindowCount:5.2122 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0055 | memoryGateLong:-0.0061 | memoryGateCurrent:0.0010 | memoryGateMean:0.3333 | memoryGateStd:14.6740 | windowWeightsW25:2.34395 (0.48),W21:1.11478 (0.14),W19:0.76529 (0.10),W16:0.59276 (0.08),W2:0.57009 (0.08),W13:0.43248 (0.07),W9:-0.32630 (0.03),W3:-1.21760 (0.01),W5:-2.14526 (0.01) | topTokens[(',', 1118), ('i', 1013), ('.', 901), ('the', 745), ('to', 697), ('it', 606), ('!', 592), ('a', 529), ('you', 423), ('and', 420)] | tokenPerfect: 13413 / 45000  29.81% | babyLLM.py 2500
2025-04-10 10:13:07 | 95000 | LR0.0003 | loss:3.3648 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-336.6454 | logitMax:-312.8305 | scheduledSampling:0.0469 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1406 | windowEntropy:1.6638 | topWindowWeight:0.4671 | effectiveWindowCount:5.2792 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0058 | memoryGateLong:-0.0062 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:15.0932 | windowWeightsW25:2.33211 (0.47),W21:1.16275 (0.15),W19:0.81345 (0.10),W16:0.61706 (0.08),W2:0.54746 (0.08),W13:0.44145 (0.07),W9:-0.28774 (0.03),W3:-1.22357 (0.01),W5:-2.15358 (0.01) | topTokens[(',', 1203), ('i', 1068), ('.', 914), ('the', 768), ('to', 718), ('it', 614), ('!', 592), ('a', 538), ('you', 443), ('and', 431)] | tokenPerfect: 26995 / 90000  29.99% | babyLLM.py 2500
2025-04-10 10:18:16 | 97500 | LR0.0003 | loss:3.4332 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-339.2154 | logitMax:-315.8624 | scheduledSampling:0.0481 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1435 | windowEntropy:1.6431 | topWindowWeight:0.4741 | effectiveWindowCount:5.1712 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0044 | memoryGateLong:-0.0047 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:11.4577 | windowWeightsW25:2.36343 (0.47),W21:1.22294 (0.15),W19:0.82221 (0.10),W16:0.59052 (0.08),W2:0.52981 (0.08),W13:0.40226 (0.07),W9:-0.31266 (0.03),W3:-1.28552 (0.01),W5:-2.19790 (0.00) | topTokens[(',', 1264), ('i', 1105), ('.', 931), ('the', 789), ('to', 730), ('it', 627), ('!', 594), ('a', 558), ('you', 462), ('and', 449)] | tokenPerfect: 38218 / 135000  28.31% | babyLLM.py 2500
2025-04-10 10:23:34 | 100000 | LR0.0003 | loss:4.2124 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-407.0193 | logitMax:-384.3146 | scheduledSampling:0.0494 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1520 | windowEntropy:1.5915 | topWindowWeight:0.4979 | effectiveWindowCount:4.9110 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0039 | memoryGateLong:-0.0041 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:10.0157 | windowWeightsW25:2.44586 (0.50),W21:1.26064 (0.15),W19:0.81954 (0.10),W16:0.56807 (0.08),W2:0.48271 (0.07),W13:0.34335 (0.06),W9:-0.35953 (0.03),W3:-1.39415 (0.01),W5:-2.28309 (0.00) | topTokens[(',', 1338), ('i', 1131), ('.', 955), ('the', 799), ('to', 740), ('it', 636), ('!', 595), ('a', 570), ('you', 464), ('and', 458)] | babyLLM.py 2500
2025-04-10 10:28:42 | 102500 | LR0.0003 | loss:4.8279 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-413.2959 | logitMax:-391.4085 | scheduledSampling:0.0506 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1635 | windowEntropy:1.5284 | topWindowWeight:0.5323 | effectiveWindowCount:4.6107 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0042 | memoryGateLong:-0.0046 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:11.0407 | windowWeightsW25:2.50747 (0.53),W21:1.17775 (0.14),W19:0.71741 (0.09),W2:0.54214 (0.07),W16:0.44264 (0.07),W13:0.22500 (0.05),W9:-0.46819 (0.03),W3:-1.44144 (0.01),W5:-2.34173 (0.00) | topTokens[(',', 1404), ('i', 1177), ('.', 962), ('the', 812), ('to', 761), ('it', 647), ('!', 597), ('a', 578), ('and', 482), ('you', 469)] | tokenPerfect: 6574 / 45000  14.61% | babyLLM.py 2500
2025-04-10 10:33:53 | 105000 | LR0.0003 | loss:4.8665 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-404.6216 | logitMax:-383.3682 | scheduledSampling:0.0519 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1724 | windowEntropy:1.4754 | topWindowWeight:0.5579 | effectiveWindowCount:4.3728 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0042 | memoryGateLong:-0.0044 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:10.8312 | windowWeightsW25:2.55973 (0.56),W21:1.14181 (0.14),W19:0.65258 (0.08),W2:0.55931 (0.08),W16:0.33800 (0.06),W13:0.13126 (0.05),W9:-0.53800 (0.03),W3:-1.47251 (0.01),W5:-2.39647 (0.00) | topTokens[(',', 1467), ('i', 1222), ('.', 967), ('the', 818), ('to', 786), ('it', 667), ('!', 597), ('a', 584), ('and', 505), ('you', 478)] | tokenPerfect: 12429 / 90000  13.81% | babyLLM.py 2500
2025-04-10 10:39:01 | 107500 | LR0.0003 | loss:4.8713 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-367.5084 | logitMax:-346.2096 | scheduledSampling:0.0531 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1794 | windowEntropy:1.4309 | topWindowWeight:0.5779 | effectiveWindowCount:4.1824 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0049 | memoryGateLong:-0.0051 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:12.5238 | windowWeightsW25:2.58583 (0.58),W21:1.09454 (0.13),W2:0.60178 (0.08),W19:0.57527 (0.08),W16:0.21884 (0.05),W13:0.02509 (0.04),W9:-0.64949 (0.02),W3:-1.47745 (0.01),W5:-2.45977 (0.00) | topTokens[(',', 1553), ('i', 1275), ('.', 970), ('the', 831), ('to', 800), ('it', 678), ('!', 598), ('a', 592), ('and', 521), ('you', 481)] | tokenPerfect: 18031 / 135000  13.36% | babyLLM.py 2500
2025-04-10 10:44:18 | 110000 | LR0.0003 | loss:3.8688 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-380.1962 | logitMax:-357.6731 | scheduledSampling:0.0544 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1721 | windowEntropy:1.4817 | topWindowWeight:0.5580 | effectiveWindowCount:4.4003 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0046 | memoryGateLong:-0.0052 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:12.3546 | windowWeightsW25:2.48671 (0.56),W21:0.98019 (0.12),W2:0.71293 (0.09),W19:0.48522 (0.08),W16:0.21562 (0.06),W13:0.09118 (0.05),W9:-0.65009 (0.02),W3:-1.39541 (0.01),W5:-2.44662 (0.00) | topTokens[(',', 1595), ('i', 1294), ('.', 985), ('the', 837), ('to', 829), ('it', 687), ('a', 610), ('!', 600), ('and', 524), ('you', 487)] | babyLLM.py 2500
2025-04-10 10:49:27 | 112500 | LR0.0003 | loss:2.2668 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-364.9698 | logitMax:-339.8546 | scheduledSampling:0.0556 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1644 | windowEntropy:1.5339 | topWindowWeight:0.5368 | effectiveWindowCount:4.6360 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0051 | memoryGateLong:-0.0057 | memoryGateCurrent:0.0011 | memoryGateMean:0.3333 | memoryGateStd:13.6177 | windowWeightsW25:2.38382 (0.54),W21:0.86701 (0.12),W2:0.81941 (0.11),W19:0.35815 (0.07),W16:0.18389 (0.06),W13:0.12744 (0.06),W9:-0.59021 (0.03),W3:-1.23728 (0.01),W5:-2.33181 (0.00) | topTokens[(',', 1596), ('i', 1317), ('.', 1025), ('to', 897), ('the', 838), ('it', 691), ('a', 621), ('!', 606), ('and', 524), ('you', 511)] | tokenPerfect: 20135 / 45000  44.74% | babyLLM.py 2500
2025-04-10 10:54:35 | 115000 | LR0.0003 | loss:2.2519 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-338.2292 | logitMax:-311.2444 | scheduledSampling:0.0569 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1591 | windowEntropy:1.5680 | topWindowWeight:0.5218 | effectiveWindowCount:4.7970 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0048 | memoryGateLong:-0.0053 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:12.7332 | windowWeightsW25:2.31462 (0.52),W2:0.88205 (0.12),W21:0.78624 (0.11),W19:0.27532 (0.07),W16:0.16038 (0.06),W13:0.15038 (0.06),W9:-0.53667 (0.03),W3:-1.12862 (0.02),W5:-2.28057 (0.01) | topTokens[(',', 1608), ('i', 1339), ('.', 1061), ('to', 969), ('the', 846), ('it', 693), ('a', 633), ('!', 613), ('you', 533), ('and', 526)] | tokenPerfect: 41279 / 90000  45.87% | babyLLM.py 2500
2025-04-10 10:59:43 | 117500 | LR0.0003 | loss:1.9676 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-343.7714 | logitMax:-316.4912 | scheduledSampling:0.0581 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1553 | windowEntropy:1.5935 | topWindowWeight:0.5113 | effectiveWindowCount:4.9211 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0053 | memoryGateLong:-0.0056 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:13.7509 | windowWeightsW25:2.28608 (0.51),W2:0.88444 (0.13),W21:0.76610 (0.11),W13:0.25212 (0.07),W19:0.23584 (0.07),W16:0.18294 (0.06),W9:-0.45656 (0.03),W3:-1.09958 (0.02),W5:-2.23302 (0.01) | topTokens[(',', 1609), ('i', 1362), ('.', 1105), ('to', 1043), ('the', 847), ('it', 696), ('a', 642), ('!', 620), ('you', 545), ('and', 528)] | tokenPerfect: 64288 / 135000  47.62% | babyLLM.py 2500
2025-04-10 11:05:00 | 120000 | LR0.0003 | loss:2.5258 | gradNorm:0.9899 | tokenCount:45000.0000 | logitMin:-337.1398 | logitMax:-312.3452 | scheduledSampling:0.0594 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1492 | windowEntropy:1.6313 | topWindowWeight:0.4957 | effectiveWindowCount:5.1106 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0071 | memoryGateLong:-0.0075 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:18.3083 | windowWeightsW25:2.29605 (0.50),W21:0.85715 (0.12),W2:0.79452 (0.11),W13:0.44658 (0.08),W16:0.34924 (0.07),W19:0.33274 (0.07),W9:-0.34279 (0.04),W3:-1.10679 (0.02),W5:-2.12452 (0.01) | topTokens[(',', 1684), ('i', 1406), ('.', 1115), ('to', 1047), ('the', 868), ('it', 713), ('a', 652), ('!', 628), ('you', 558), ('and', 531)] | babyLLM.py 2500
2025-04-10 11:10:08 | 122500 | LR0.0003 | loss:2.4526 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-333.4690 | logitMax:-308.9909 | scheduledSampling:0.0606 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1411 | windowEntropy:1.6742 | topWindowWeight:0.4723 | effectiveWindowCount:5.3343 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0041 | memoryGateLong:-0.0045 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:10.8558 | windowWeightsW25:2.25870 (0.47),W21:0.92795 (0.12),W2:0.75381 (0.10),W13:0.56173 (0.09),W16:0.43515 (0.08),W19:0.42762 (0.08),W9:-0.27854 (0.04),W3:-1.12773 (0.02),W5:-2.08100 (0.01) | topTokens[(',', 1805), ('i', 1439), ('.', 1122), ('to', 1072), ('the', 887), ('it', 721), ('a', 660), ('!', 628), ('you', 580), ('and', 540)] | tokenPerfect: 17409 / 45000  38.69% | babyLLM.py 2500
2025-04-10 11:15:17 | 125000 | LR0.0003 | loss:2.2725 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-393.6429 | logitMax:-369.6401 | scheduledSampling:0.0619 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1408 | windowEntropy:1.6722 | topWindowWeight:0.4705 | effectiveWindowCount:5.3239 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0038 | memoryGateLong:-0.0039 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:9.6356 | windowWeightsW25:2.28906 (0.47),W21:1.02999 (0.13),W2:0.68334 (0.09),W13:0.57829 (0.09),W19:0.52526 (0.08),W16:0.49722 (0.08),W9:-0.25696 (0.04),W3:-1.16982 (0.01),W5:-2.12762 (0.01) | topTokens[(',', 1882), ('i', 1466), ('.', 1139), ('to', 1090), ('the', 912), ('it', 733), ('a', 671), ('!', 629), ('you', 604), ('and', 550)] | tokenPerfect: 35560 / 90000  39.51% | babyLLM.py 2500
2025-04-10 11:20:26 | 127500 | LR0.0003 | loss:1.8437 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-434.2022 | logitMax:-408.3730 | scheduledSampling:0.0631 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1373 | windowEntropy:1.6895 | topWindowWeight:0.4602 | effectiveWindowCount:5.4168 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0031 | memoryGateLong:-0.0033 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:8.0385 | windowWeightsW25:2.27452 (0.46),W21:1.07086 (0.14),W2:0.66033 (0.09),W19:0.59339 (0.09),W13:0.59331 (0.09),W16:0.51801 (0.08),W9:-0.19005 (0.04),W3:-1.18136 (0.01),W5:-2.11578 (0.01) | topTokens[(',', 1950), ('i', 1493), ('.', 1147), ('to', 1103), ('the', 936), ('it', 743), ('a', 677), ('you', 634), ('!', 630), ('and', 557)] | tokenPerfect: 57779 / 135000  42.80% | babyLLM.py 2500
2025-04-10 11:25:43 | 130000 | LR0.0003 | loss:2.5418 | gradNorm:0.9996 | tokenCount:45000.0000 | logitMin:-424.0412 | logitMax:-396.4148 | scheduledSampling:0.0644 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1358 | windowEntropy:1.6949 | topWindowWeight:0.4550 | effectiveWindowCount:5.4459 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0032 | memoryGateLong:-0.0033 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:8.2515 | windowWeightsW25:2.27541 (0.46),W21:1.11804 (0.14),W19:0.65497 (0.09),W2:0.63823 (0.09),W13:0.57751 (0.08),W16:0.55068 (0.08),W9:-0.17624 (0.04),W3:-1.18538 (0.01),W5:-2.13937 (0.01) | topTokens[(',', 2030), ('i', 1524), ('.', 1160), ('to', 1111), ('the', 958), ('it', 761), ('a', 694), ('you', 663), ('!', 630), ('and', 571)] | babyLLM.py 2500
2025-04-10 11:30:52 | 132500 | LR0.0003 | loss:3.1727 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-377.0205 | logitMax:-347.5271 | scheduledSampling:0.0656 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1445 | windowEntropy:1.6468 | topWindowWeight:0.4795 | effectiveWindowCount:5.1906 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0054 | memoryGateLong:-0.0059 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:14.2819 | windowWeightsW25:2.34021 (0.48),W21:1.13776 (0.14),W19:0.63808 (0.09),W2:0.63450 (0.09),W13:0.47071 (0.07),W16:0.45757 (0.07),W9:-0.25707 (0.04),W3:-1.18652 (0.01),W5:-2.20297 (0.01) | topTokens[(',', 2115), ('i', 1542), ('.', 1163), ('to', 1119), ('the', 1000), ('it', 770), ('a', 697), ('you', 681), ('!', 636), ('and', 635)] | tokenPerfect: 14323 / 45000  31.83% | babyLLM.py 2500
2025-04-10 11:36:05 | 135000 | LR0.0003 | loss:2.8016 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-323.8377 | logitMax:-292.8576 | scheduledSampling:0.0669 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1492 | windowEntropy:1.6217 | topWindowWeight:0.4929 | effectiveWindowCount:5.0615 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0048 | memoryGateLong:-0.0053 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:12.7078 | windowWeightsW25:2.36446 (0.49),W21:1.11712 (0.14),W2:0.64979 (0.09),W19:0.63189 (0.09),W13:0.39635 (0.07),W16:0.38268 (0.07),W9:-0.34540 (0.03),W3:-1.13739 (0.01),W5:-2.20336 (0.01) | topTokens[(',', 2214), ('i', 1551), ('.', 1166), ('to', 1130), ('the', 1027), ('it', 778), ('and', 720), ('you', 701), ('a', 699), ('!', 643)] | tokenPerfect: 29455 / 90000  32.73% | babyLLM.py 2500
2025-04-10 11:41:14 | 137500 | LR0.0003 | loss:2.5244 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-294.2558 | logitMax:-260.6904 | scheduledSampling:0.0681 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1543 | windowEntropy:1.5949 | topWindowWeight:0.5079 | effectiveWindowCount:4.9277 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0055 | memoryGateLong:-0.0060 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:14.5291 | windowWeightsW25:2.38130 (0.51),W21:1.06707 (0.14),W2:0.68312 (0.09),W19:0.56994 (0.08),W16:0.32233 (0.06),W13:0.30557 (0.06),W9:-0.45450 (0.03),W3:-1.06372 (0.02),W5:-2.20040 (0.01) | topTokens[(',', 2327), ('i', 1560), ('.', 1169), ('to', 1140), ('the', 1051), ('and', 795), ('it', 784), ('you', 719), ('a', 700), ('!', 648)] | tokenPerfect: 45914 / 135000  34.01% | babyLLM.py 2500
2025-04-10 11:46:30 | 140000 | LR0.0003 | loss:1.7958 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-319.9342 | logitMax:-282.3410 | scheduledSampling:0.0694 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1484 | windowEntropy:1.6303 | topWindowWeight:0.4909 | effectiveWindowCount:5.1052 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0062 | memoryGateLong:-0.0069 | memoryGateCurrent:0.0011 | memoryGateMean:0.3333 | memoryGateStd:16.5462 | windowWeightsW25:2.30726 (0.49),W21:1.03775 (0.14),W2:0.74549 (0.10),W19:0.51951 (0.08),W16:0.29251 (0.07),W13:0.29210 (0.07),W9:-0.47724 (0.03),W3:-0.96579 (0.02),W5:-2.07378 (0.01) | topTokens[(',', 2356), ('i', 1569), ('.', 1213), ('to', 1146), ('the', 1072), ('and', 830), ('it', 795), ('you', 738), ('a', 702), ('!', 688)] | babyLLM.py 2500
2025-04-10 11:51:39 | 142500 | LR0.0003 | loss:1.2177 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-312.7721 | logitMax:-271.9384 | scheduledSampling:0.0706 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1460 | windowEntropy:1.6406 | topWindowWeight:0.4830 | effectiveWindowCount:5.1580 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0110 | memoryGateLong:-0.0124 | memoryGateCurrent:0.0017 | memoryGateMean:0.3333 | memoryGateStd:29.4364 | windowWeightsW25:2.28620 (0.48),W21:1.06586 (0.14),W2:0.75679 (0.10),W19:0.55236 (0.09),W13:0.29401 (0.07),W16:0.27736 (0.06),W9:-0.52591 (0.03),W3:-0.97011 (0.02),W5:-2.05497 (0.01) | topTokens[(',', 2357), ('i', 1575), ('.', 1275), ('to', 1146), ('the', 1092), ('and', 842), ('it', 810), ('you', 754), ('!', 736), ('a', 705)] | tokenPerfect: 26159 / 45000  58.13% | babyLLM.py 2500
2025-04-10 11:56:47 | 145000 | LR0.0003 | loss:1.7709 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-281.0872 | logitMax:-238.5542 | scheduledSampling:0.0719 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1487 | windowEntropy:1.6299 | topWindowWeight:0.4918 | effectiveWindowCount:5.1035 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0042 | memoryGateLong:-0.0043 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:10.6263 | windowWeightsW25:2.30400 (0.49),W21:1.02846 (0.14),W2:0.75306 (0.10),W19:0.48940 (0.08),W13:0.32689 (0.07),W16:0.24669 (0.06),W9:-0.48765 (0.03),W3:-0.96760 (0.02),W5:-1.99348 (0.01) | topTokens[(',', 2358), ('i', 1583), ('.', 1349), ('to', 1146), ('the', 1111), ('and', 852), ('it', 825), ('!', 784), ('you', 768), ('a', 706)] | tokenPerfect: 50601 / 90000  56.22% | babyLLM.py 2500
2025-04-10 12:01:56 | 147500 | LR0.0003 | loss:5.1828 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-319.3987 | logitMax:-291.0643 | scheduledSampling:0.0731 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1571 | windowEntropy:1.5784 | topWindowWeight:0.5154 | effectiveWindowCount:4.8472 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0044 | memoryGateLong:-0.0044 | memoryGateCurrent:0.0004 | memoryGateMean:0.3333 | memoryGateStd:11.0175 | windowWeightsW25:2.38150 (0.52),W21:1.05478 (0.14),W2:0.71427 (0.10),W19:0.50042 (0.08),W13:0.28252 (0.06),W16:0.21783 (0.06),W9:-0.58162 (0.03),W3:-1.02223 (0.02),W5:-2.09716 (0.01) | topTokens[(',', 2416), ('i', 1597), ('.', 1404), ('to', 1154), ('the', 1124), ('and', 857), ('it', 833), ('!', 806), ('you', 785), ('a', 714)] | tokenPerfect: 57561 / 135000  42.64% | babyLLM.py 2500
2025-04-10 12:07:13 | 150000 | LR0.0003 | loss:5.5705 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-357.8584 | logitMax:-335.4848 | scheduledSampling:0.0744 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1660 | windowEntropy:1.5219 | topWindowWeight:0.5404 | effectiveWindowCount:4.5811 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0046 | memoryGateLong:-0.0048 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:11.7061 | windowWeightsW25:2.46393 (0.54),W21:1.07805 (0.14),W2:0.67379 (0.09),W19:0.50469 (0.08),W13:0.23636 (0.06),W16:0.19449 (0.06),W9:-0.66380 (0.02),W3:-1.11616 (0.02),W5:-2.19070 (0.01) | topTokens[(',', 2467), ('i', 1636), ('.', 1424), ('to', 1170), ('the', 1133), ('and', 870), ('it', 840), ('!', 806), ('you', 790), ('a', 743)] | babyLLM.py 2500
2025-04-10 12:12:23 | 152500 | LR0.0003 | loss:5.1698 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-357.2154 | logitMax:-335.8395 | scheduledSampling:0.0756 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1775 | windowEntropy:1.4472 | topWindowWeight:0.5727 | effectiveWindowCount:4.2511 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0054 | memoryGateLong:-0.0057 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:13.9304 | windowWeightsW25:2.56099 (0.57),W21:1.09252 (0.13),W2:0.62746 (0.08),W19:0.48432 (0.07),W13:0.16442 (0.05),W16:0.13406 (0.05),W9:-0.75320 (0.02),W3:-1.23416 (0.01),W5:-2.31330 (0.00) | topTokens[(',', 2507), ('i', 1653), ('.', 1440), ('to', 1189), ('the', 1143), ('and', 880), ('it', 849), ('!', 807), ('you', 802), ('a', 753)] | tokenPerfect: 4981 / 45000  11.07% | babyLLM.py 2500
2025-04-10 12:17:33 | 155000 | LR0.0003 | loss:2.1802 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-306.6594 | logitMax:-277.1067 | scheduledSampling:0.0769 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1686 | windowEntropy:1.5066 | topWindowWeight:0.5481 | effectiveWindowCount:4.5115 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0063 | memoryGateLong:-0.0072 | memoryGateCurrent:0.0013 | memoryGateMean:0.3333 | memoryGateStd:17.0341 | windowWeightsW25:2.44614 (0.55),W21:0.98721 (0.13),W2:0.74883 (0.10),W19:0.41763 (0.07),W13:0.17034 (0.06),W16:0.10213 (0.05),W9:-0.74606 (0.02),W3:-1.13247 (0.02),W5:-2.18314 (0.01) | topTokens[(',', 2551), ('i', 1686), ('.', 1471), ('to', 1193), ('the', 1161), ('and', 890), ('it', 879), ('!', 841), ('you', 811), ('a', 757)] | tokenPerfect: 26180 / 90000  29.09% | babyLLM.py 2500
2025-04-10 12:22:42 | 157500 | LR0.0003 | loss:1.2480 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-273.8562 | logitMax:-238.7775 | scheduledSampling:0.0781 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1611 | windowEntropy:1.5532 | topWindowWeight:0.5267 | effectiveWindowCount:4.7266 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0067 | memoryGateLong:-0.0075 | memoryGateCurrent:0.0012 | memoryGateMean:0.3333 | memoryGateStd:17.9724 | windowWeightsW25:2.37833 (0.53),W21:0.97284 (0.13),W2:0.78751 (0.11),W19:0.42329 (0.07),W13:0.25211 (0.06),W16:0.07052 (0.05),W9:-0.68922 (0.02),W3:-1.08675 (0.02),W5:-2.07641 (0.01) | topTokens[(',', 2586), ('i', 1695), ('.', 1489), ('to', 1193), ('the', 1178), ('!', 903), ('and', 900), ('it', 894), ('you', 821), ('a', 757)] | tokenPerfect: 51757 / 135000  38.34% | babyLLM.py 2500
2025-04-10 12:28:00 | 160000 | LR0.0003 | loss:1.4044 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:-254.5997 | logitMax:-218.1865 | scheduledSampling:0.0794 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1563 | windowEntropy:1.5845 | topWindowWeight:0.5138 | effectiveWindowCount:4.8770 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0062 | memoryGateLong:-0.0068 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:16.3514 | windowWeightsW25:2.34624 (0.51),W21:0.95297 (0.13),W2:0.78850 (0.11),W19:0.43811 (0.08),W13:0.31272 (0.07),W16:0.14145 (0.06),W9:-0.57819 (0.03),W3:-1.09633 (0.02),W5:-2.04451 (0.01) | topTokens[(',', 2639), ('i', 1708), ('.', 1514), ('to', 1193), ('the', 1191), ('!', 950), ('and', 916), ('it', 911), ('have', 860), ('you', 834)] | babyLLM.py 2500
2025-04-10 12:33:09 | 162500 | LR0.0003 | loss:3.9632 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-283.3072 | logitMax:-259.6560 | scheduledSampling:0.0806 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1588 | windowEntropy:1.5688 | topWindowWeight:0.5207 | effectiveWindowCount:4.8009 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0053 | memoryGateLong:-0.0054 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:13.3991 | windowWeightsW25:2.36679 (0.52),W21:0.97021 (0.13),W2:0.77460 (0.11),W19:0.41399 (0.07),W13:0.29873 (0.07),W16:0.13431 (0.06),W9:-0.61293 (0.03),W3:-1.09904 (0.02),W5:-2.07322 (0.01) | topTokens[(',', 2661), ('i', 1732), ('.', 1577), ('to', 1221), ('the', 1192), ('!', 962), ('and', 918), ('it', 913), ('you', 869), ('have', 861)] | tokenPerfect: 10763 / 45000  23.92% | babyLLM.py 2500
2025-04-10 12:38:19 | 165000 | LR0.0003 | loss:3.4604 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-302.2083 | logitMax:-279.4071 | scheduledSampling:0.0819 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1595 | windowEntropy:1.5646 | topWindowWeight:0.5224 | effectiveWindowCount:4.7806 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0051 | memoryGateLong:-0.0055 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:13.2637 | windowWeightsW25:2.35403 (0.52),W21:0.94936 (0.13),W2:0.80349 (0.11),W19:0.37660 (0.07),W13:0.21501 (0.06),W16:0.10184 (0.05),W9:-0.62553 (0.03),W3:-1.07264 (0.02),W5:-2.06994 (0.01) | topTokens[(',', 2677), ('i', 1750), ('.', 1620), ('to', 1265), ('the', 1194), ('!', 974), ('and', 920), ('you', 916), ('it', 913), ('have', 862)] | tokenPerfect: 23416 / 90000  26.02% | babyLLM.py 2500
2025-04-10 12:43:31 | 167500 | LR0.0003 | loss:2.0054 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-302.3812 | logitMax:-273.7533 | scheduledSampling:0.0831 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1606 | windowEntropy:1.5610 | topWindowWeight:0.5259 | effectiveWindowCount:4.7635 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0062 | memoryGateLong:-0.0069 | memoryGateCurrent:0.0011 | memoryGateMean:0.3333 | memoryGateStd:16.5152 | windowWeightsW25:2.35841 (0.53),W21:0.91495 (0.12),W2:0.80474 (0.11),W19:0.38134 (0.07),W13:0.19802 (0.06),W16:0.09250 (0.05),W9:-0.59972 (0.03),W3:-1.09674 (0.02),W5:-1.98846 (0.01) | topTokens[(',', 2715), ('i', 1752), ('.', 1644), ('to', 1271), ('the', 1229), ('!', 1055), ('you', 935), ('and', 930), ('it', 918), ('have', 862)] | tokenPerfect: 42429 / 135000  31.43% | babyLLM.py 2500
2025-04-10 12:48:48 | 170000 | LR0.0003 | loss:2.1629 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-269.9777 | logitMax:-238.9519 | scheduledSampling:0.0844 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1591 | windowEntropy:1.5692 | topWindowWeight:0.5214 | effectiveWindowCount:4.8028 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0066 | memoryGateLong:-0.0072 | memoryGateCurrent:0.0010 | memoryGateMean:0.3333 | memoryGateStd:17.4364 | windowWeightsW25:2.34745 (0.52),W21:0.93085 (0.13),W2:0.80842 (0.11),W19:0.35496 (0.07),W13:0.20510 (0.06),W16:0.13914 (0.06),W9:-0.59797 (0.03),W3:-1.12449 (0.02),W5:-1.95496 (0.01) | topTokens[(',', 2757), ('i', 1758), ('.', 1670), ('to', 1288), ('the', 1267), ('!', 1115), ('you', 951), ('and', 937), ('it', 924), ('have', 862)] | babyLLM.py 2500
2025-04-10 12:53:58 | 172500 | LR0.0003 | loss:3.2390 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-260.2417 | logitMax:-237.0178 | scheduledSampling:0.0856 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1581 | windowEntropy:1.5706 | topWindowWeight:0.5182 | effectiveWindowCount:4.8094 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0050 | memoryGateLong:-0.0054 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:13.0338 | windowWeightsW25:2.41989 (0.52),W21:1.09757 (0.14),W2:0.64134 (0.09),W19:0.56408 (0.08),W13:0.35082 (0.07),W16:0.30659 (0.06),W9:-0.49968 (0.03),W3:-1.27505 (0.01),W5:-1.99785 (0.01) | topTokens[(',', 2805), ('i', 1762), ('.', 1704), ('to', 1298), ('the', 1291), ('!', 1130), ('and', 967), ('you', 954), ('it', 939), ('have', 863)] | tokenPerfect: 11316 / 45000  25.15% | babyLLM.py 2500
2025-04-10 12:59:06 | 175000 | LR0.0003 | loss:3.9124 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-288.3998 | logitMax:-266.1232 | scheduledSampling:0.0869 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1597 | windowEntropy:1.5549 | topWindowWeight:0.5223 | effectiveWindowCount:4.7347 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0051 | memoryGateLong:-0.0056 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:13.5283 | windowWeightsW25:2.48129 (0.52),W21:1.16584 (0.14),W19:0.65796 (0.08),W2:0.54730 (0.08),W13:0.45039 (0.07),W16:0.42038 (0.07),W9:-0.48155 (0.03),W3:-1.43264 (0.01),W5:-2.11676 (0.01) | topTokens[(',', 2869), ('i', 1762), ('.', 1720), ('the', 1315), ('to', 1310), ('!', 1136), ('and', 989), ('it', 955), ('you', 954), ('have', 867)] | tokenPerfect: 20261 / 90000  22.51% | babyLLM.py 2500
2025-04-10 13:04:15 | 177500 | LR0.0003 | loss:3.5635 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-309.2403 | logitMax:-285.8396 | scheduledSampling:0.0881 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1524 | windowEntropy:1.5983 | topWindowWeight:0.5010 | effectiveWindowCount:4.9445 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0053 | memoryGateLong:-0.0058 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:13.9898 | windowWeightsW25:2.39195 (0.50),W21:1.14780 (0.14),W2:0.64391 (0.09),W19:0.62858 (0.09),W13:0.39478 (0.07),W16:0.37284 (0.07),W9:-0.44595 (0.03),W3:-1.33598 (0.01),W5:-2.09679 (0.01) | topTokens[(',', 2905), ('i', 1795), ('.', 1763), ('to', 1330), ('the', 1324), ('!', 1146), ('and', 1000), ('you', 973), ('it', 970), ('have', 868)] | tokenPerfect: 31667 / 135000  23.46% | babyLLM.py 2500
2025-04-10 13:09:32 | 180000 | LR0.0003 | loss:2.8150 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-324.0197 | logitMax:-298.9836 | scheduledSampling:0.0894 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1493 | windowEntropy:1.6211 | topWindowWeight:0.4929 | effectiveWindowCount:5.0588 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0053 | memoryGateLong:-0.0058 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:13.9460 | windowWeightsW25:2.31986 (0.49),W21:1.05608 (0.14),W2:0.76566 (0.10),W19:0.51709 (0.08),W13:0.30641 (0.07),W16:0.26862 (0.06),W9:-0.39844 (0.03),W3:-1.20358 (0.01),W5:-2.05687 (0.01) | topTokens[(',', 2915), ('.', 1825), ('i', 1824), ('to', 1366), ('the', 1326), ('!', 1147), ('you', 1009), ('and', 1000), ('it', 972), ('have', 870)] | babyLLM.py 2500
2025-04-10 13:14:41 | 182500 | LR0.0003 | loss:2.7162 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-313.2214 | logitMax:-288.0300 | scheduledSampling:0.0906 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1460 | windowEntropy:1.6427 | topWindowWeight:0.4838 | effectiveWindowCount:5.1693 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0048 | memoryGateLong:-0.0051 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:12.3809 | windowWeightsW25:2.27395 (0.48),W21:1.02344 (0.14),W2:0.80699 (0.11),W19:0.45762 (0.08),W13:0.27752 (0.07),W16:0.22222 (0.06),W9:-0.29898 (0.04),W3:-1.13579 (0.02),W5:-2.01117 (0.01) | topTokens[(',', 2922), ('.', 1893), ('i', 1862), ('to', 1403), ('the', 1331), ('!', 1151), ('you', 1042), ('and', 1000), ('it', 974), ('have', 870)] | tokenPerfect: 15590 / 45000  34.64% | babyLLM.py 2500
2025-04-10 13:19:51 | 185000 | LR0.0003 | loss:3.8127 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-300.0077 | logitMax:-276.2296 | scheduledSampling:0.0919 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1502 | windowEntropy:1.6193 | topWindowWeight:0.4957 | effectiveWindowCount:5.0496 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0054 | memoryGateLong:-0.0057 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:13.9499 | windowWeightsW25:2.30359 (0.50),W21:1.02372 (0.14),W2:0.80325 (0.11),W19:0.44345 (0.08),W13:0.20076 (0.06),W16:0.17271 (0.06),W9:-0.28808 (0.04),W3:-1.15811 (0.02),W5:-1.99629 (0.01) | topTokens[(',', 2948), ('.', 1933), ('i', 1872), ('to', 1428), ('the', 1343), ('!', 1180), ('you', 1113), ('and', 1002), ('it', 978), ('have', 870)] | tokenPerfect: 26368 / 90000  29.30% | babyLLM.py 2500
2025-04-10 13:25:00 | 187500 | LR0.0003 | loss:4.4359 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-307.5182 | logitMax:-285.5936 | scheduledSampling:0.0931 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1553 | windowEntropy:1.5879 | topWindowWeight:0.5099 | effectiveWindowCount:4.8933 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0043 | memoryGateLong:-0.0045 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:11.0895 | windowWeightsW25:2.35770 (0.51),W21:1.05514 (0.14),W2:0.76069 (0.10),W19:0.48544 (0.08),W16:0.18188 (0.06),W13:0.16783 (0.06),W9:-0.33958 (0.03),W3:-1.21850 (0.01),W5:-2.04679 (0.01) | topTokens[(',', 2974), ('.', 1963), ('i', 1873), ('to', 1440), ('the', 1363), ('!', 1248), ('you', 1208), ('and', 1008), ('it', 979), ('a', 877)] | tokenPerfect: 33784 / 135000  25.03% | babyLLM.py 2500
2025-04-10 13:30:18 | 190000 | LR0.0003 | loss:4.8374 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-330.8355 | logitMax:-309.7757 | scheduledSampling:0.0944 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1616 | windowEntropy:1.5479 | topWindowWeight:0.5275 | effectiveWindowCount:4.7018 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0036 | memoryGateLong:-0.0038 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:9.2758 | windowWeightsW25:2.41656 (0.53),W21:1.07631 (0.14),W2:0.72628 (0.10),W19:0.48951 (0.08),W16:0.20225 (0.06),W13:0.13081 (0.05),W9:-0.43470 (0.03),W3:-1.28608 (0.01),W5:-2.12446 (0.01) | topTokens[(',', 3001), ('.', 1984), ('i', 1884), ('to', 1457), ('the', 1385), ('!', 1268), ('you', 1228), ('and', 1024), ('it', 989), ('a', 887)] | babyLLM.py 2500
2025-04-10 13:35:27 | 192500 | LR0.0003 | loss:4.6252 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-348.2743 | logitMax:-327.4655 | scheduledSampling:0.0956 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1703 | windowEntropy:1.4921 | topWindowWeight:0.5518 | effectiveWindowCount:4.4465 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0036 | memoryGateLong:-0.0038 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:9.2621 | windowWeightsW25:2.48031 (0.55),W21:1.07849 (0.14),W2:0.70854 (0.09),W19:0.45844 (0.07),W16:0.14878 (0.05),W13:0.03310 (0.05),W9:-0.52851 (0.03),W3:-1.37530 (0.01),W5:-2.17636 (0.01) | topTokens[(',', 3025), ('.', 2010), ('i', 1888), ('to', 1476), ('the', 1401), ('!', 1268), ('you', 1229), ('and', 1033), ('it', 995), ('a', 905)] | tokenPerfect: 6814 / 45000  15.14% | babyLLM.py 2500
2025-04-10 13:40:36 | 195000 | LR0.0003 | loss:3.8524 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-375.8574 | logitMax:-353.6702 | scheduledSampling:0.0969 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1719 | windowEntropy:1.4877 | topWindowWeight:0.5574 | effectiveWindowCount:4.4268 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0047 | memoryGateLong:-0.0051 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:12.3556 | windowWeightsW25:2.48645 (0.56),W21:1.02489 (0.13),W2:0.70225 (0.09),W19:0.45072 (0.07),W16:0.11722 (0.05),W13:0.06014 (0.05),W9:-0.53795 (0.03),W3:-1.28339 (0.01),W5:-2.11685 (0.01) | topTokens[(',', 3048), ('.', 2039), ('i', 1892), ('to', 1485), ('the', 1411), ('!', 1269), ('you', 1229), ('and', 1045), ('it', 1001), ('a', 914)] | tokenPerfect: 17976 / 90000  19.97% | babyLLM.py 2500
2025-04-10 13:45:49 | 197500 | LR0.0003 | loss:3.7438 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-367.1001 | logitMax:-345.1051 | scheduledSampling:0.0981 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1711 | windowEntropy:1.4953 | topWindowWeight:0.5557 | effectiveWindowCount:4.4606 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0039 | memoryGateLong:-0.0042 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:10.2060 | windowWeightsW25:2.47614 (0.56),W21:0.98309 (0.12),W2:0.71094 (0.10),W19:0.45012 (0.07),W16:0.13972 (0.05),W13:0.08584 (0.05),W9:-0.51424 (0.03),W3:-1.27636 (0.01),W5:-2.14060 (0.01) | topTokens[(',', 3067), ('.', 2067), ('i', 1893), ('to', 1496), ('the', 1432), ('!', 1270), ('you', 1229), ('and', 1054), ('it', 1001), ('a', 926)] | tokenPerfect: 28574 / 135000  21.17% | babyLLM.py 2500
2025-04-10 13:51:08 | 200000 | LR0.0003 | loss:4.5021 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-348.1206 | logitMax:-326.7070 | scheduledSampling:0.0994 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1739 | windowEntropy:1.4800 | topWindowWeight:0.5642 | effectiveWindowCount:4.3931 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0046 | memoryGateLong:-0.0048 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:11.7333 | windowWeightsW25:2.50122 (0.56),W21:0.95210 (0.12),W2:0.69123 (0.09),W19:0.45705 (0.07),W16:0.15896 (0.05),W13:0.09279 (0.05),W9:-0.52322 (0.03),W3:-1.28853 (0.01),W5:-2.14864 (0.01) | topTokens[(',', 3083), ('.', 2101), ('i', 1901), ('to', 1505), ('the', 1443), ('!', 1276), ('you', 1231), ('and', 1066), ('it', 1007), ('a', 940)] | babyLLM.py 2500
2025-04-10 13:56:17 | 202500 | LR0.0003 | loss:5.4088 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-344.0916 | logitMax:-324.3435 | scheduledSampling:0.1006 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1787 | windowEntropy:1.4470 | topWindowWeight:0.5775 | effectiveWindowCount:4.2502 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0051 | memoryGateLong:-0.0055 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:13.4156 | windowWeightsW25:2.54050 (0.58),W21:0.96873 (0.12),W2:0.66881 (0.09),W19:0.45257 (0.07),W16:0.12467 (0.05),W13:0.06190 (0.05),W9:-0.59439 (0.03),W3:-1.32982 (0.01),W5:-2.21338 (0.00) | topTokens[(',', 3084), ('.', 2158), ('i', 1929), ('to', 1516), ('the', 1452), ('!', 1304), ('you', 1238), ('and', 1080), ('it', 1018), ('a', 951)] | tokenPerfect: 3622 / 45000  8.05% | babyLLM.py 2500
2025-04-10 14:01:26 | 205000 | LR0.0003 | loss:5.2172 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-333.8164 | logitMax:-314.4021 | scheduledSampling:0.1019 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1869 | windowEntropy:1.3933 | topWindowWeight:0.6003 | effectiveWindowCount:4.0279 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0054 | memoryGateLong:-0.0060 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:14.3704 | windowWeightsW25:2.58957 (0.60),W21:0.94642 (0.12),W2:0.66865 (0.09),W19:0.37248 (0.07),W16:0.03153 (0.05),W13:-0.01335 (0.04),W9:-0.67466 (0.02),W3:-1.34578 (0.01),W5:-2.27105 (0.00) | topTokens[(',', 3089), ('.', 2220), ('i', 1958), ('to', 1522), ('the', 1464), ('!', 1315), ('you', 1249), ('and', 1104), ('it', 1036), ('a', 956)] | tokenPerfect: 7127 / 90000  7.92% | babyLLM.py 2500
2025-04-10 14:06:45 | 207500 | LR0.0003 | loss:4.8779 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-342.7524 | logitMax:-323.0702 | scheduledSampling:0.1031 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1835 | windowEntropy:1.4173 | topWindowWeight:0.5909 | effectiveWindowCount:4.1260 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0045 | memoryGateLong:-0.0051 | memoryGateCurrent:0.0010 | memoryGateMean:0.3333 | memoryGateStd:12.0928 | windowWeightsW25:2.55720 (0.59),W21:0.91469 (0.11),W2:0.69056 (0.09),W19:0.38662 (0.07),W16:0.05307 (0.05),W13:0.02758 (0.05),W9:-0.65324 (0.02),W3:-1.34630 (0.01),W5:-2.24224 (0.00) | topTokens[(',', 3107), ('.', 2257), ('i', 1996), ('to', 1533), ('the', 1476), ('!', 1323), ('you', 1266), ('and', 1113), ('it', 1056), ('a', 971)] | tokenPerfect: 11694 / 135000  8.66% | babyLLM.py 2500
2025-04-10 14:12:03 | 210000 | LR0.0003 | loss:4.5915 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-351.4111 | logitMax:-331.5353 | scheduledSampling:0.1044 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1793 | windowEntropy:1.4434 | topWindowWeight:0.5794 | effectiveWindowCount:4.2353 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0053 | memoryGateLong:-0.0060 | memoryGateCurrent:0.0011 | memoryGateMean:0.3333 | memoryGateStd:14.3280 | windowWeightsW25:2.55634 (0.58),W21:0.97515 (0.12),W2:0.64483 (0.09),W19:0.47130 (0.07),W16:0.16119 (0.05),W13:0.10360 (0.05),W9:-0.59926 (0.02),W3:-1.37278 (0.01),W5:-2.19425 (0.01) | topTokens[(',', 3122), ('.', 2288), ('i', 2010), ('to', 1546), ('the', 1493), ('!', 1326), ('you', 1282), ('and', 1132), ('it', 1073), ('a', 981)] | babyLLM.py 2500
2025-04-10 14:17:13 | 212500 | LR0.0003 | loss:4.4500 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-369.1415 | logitMax:-349.0320 | scheduledSampling:0.1056 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1795 | windowEntropy:1.4410 | topWindowWeight:0.5794 | effectiveWindowCount:4.2251 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0041 | memoryGateLong:-0.0046 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:11.0346 | windowWeightsW25:2.55241 (0.58),W21:0.98976 (0.12),W2:0.65255 (0.09),W19:0.45812 (0.07),W16:0.13866 (0.05),W13:0.06595 (0.05),W9:-0.60239 (0.02),W3:-1.37513 (0.01),W5:-2.20687 (0.00) | topTokens[(',', 3142), ('.', 2314), ('i', 2029), ('to', 1557), ('the', 1510), ('!', 1329), ('you', 1286), ('and', 1146), ('it', 1089), ('a', 985)] | tokenPerfect: 6402 / 45000  14.23% | babyLLM.py 2500
2025-04-10 14:22:22 | 215000 | LR0.0003 | loss:4.5235 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-375.2326 | logitMax:-355.2704 | scheduledSampling:0.1069 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1805 | windowEntropy:1.4354 | topWindowWeight:0.5823 | effectiveWindowCount:4.2014 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0041 | memoryGateLong:-0.0044 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:10.7271 | windowWeightsW25:2.57055 (0.58),W21:1.00273 (0.12),W2:0.62411 (0.08),W19:0.46830 (0.07),W16:0.16735 (0.05),W13:0.08202 (0.05),W9:-0.57669 (0.03),W3:-1.39070 (0.01),W5:-2.20966 (0.00) | topTokens[(',', 3162), ('.', 2338), ('i', 2047), ('to', 1574), ('the', 1529), ('!', 1329), ('you', 1292), ('and', 1162), ('it', 1100), ('a', 996)] | tokenPerfect: 12379 / 90000  13.75% | babyLLM.py 2500
2025-04-10 14:27:31 | 217500 | LR0.0003 | loss:4.3160 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-385.3250 | logitMax:-365.0106 | scheduledSampling:0.1081 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1799 | windowEntropy:1.4397 | topWindowWeight:0.5810 | effectiveWindowCount:4.2193 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0042 | memoryGateLong:-0.0047 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:11.3630 | windowWeightsW25:2.55711 (0.58),W21:0.97370 (0.12),W2:0.63983 (0.09),W19:0.46929 (0.07),W16:0.16848 (0.05),W13:0.05815 (0.05),W9:-0.58901 (0.02),W3:-1.38333 (0.01),W5:-2.19127 (0.01) | topTokens[(',', 3183), ('.', 2363), ('i', 2057), ('to', 1585), ('the', 1545), ('!', 1330), ('you', 1294), ('and', 1174), ('it', 1113), ('a', 1008)] | tokenPerfect: 19414 / 135000  14.38% | babyLLM.py 2500
2025-04-10 14:32:48 | 220000 | LR0.0003 | loss:4.3151 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-365.4321 | logitMax:-345.0052 | scheduledSampling:0.1094 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1802 | windowEntropy:1.4381 | topWindowWeight:0.5818 | effectiveWindowCount:4.2126 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0038 | memoryGateLong:-0.0043 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:10.3042 | windowWeightsW25:2.57005 (0.58),W21:0.98816 (0.12),W2:0.61642 (0.08),W19:0.48986 (0.07),W16:0.19521 (0.05),W13:0.08635 (0.05),W9:-0.58622 (0.02),W3:-1.39143 (0.01),W5:-2.18699 (0.00) | topTokens[(',', 3208), ('.', 2407), ('i', 2087), ('to', 1596), ('the', 1561), ('!', 1334), ('you', 1307), ('and', 1181), ('it', 1126), ('a', 1024)] | babyLLM.py 2500
2025-04-10 14:37:58 | 222500 | LR0.0003 | loss:2.7404 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-343.8571 | logitMax:-319.2975 | scheduledSampling:0.1106 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1728 | windowEntropy:1.4837 | topWindowWeight:0.5604 | effectiveWindowCount:4.4091 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0042 | memoryGateLong:-0.0048 | memoryGateCurrent:0.0010 | memoryGateMean:0.3333 | memoryGateStd:11.4267 | windowWeightsW25:2.46628 (0.56),W21:0.94649 (0.12),W2:0.72870 (0.10),W19:0.39701 (0.07),W16:0.13500 (0.05),W13:0.00987 (0.05),W9:-0.59464 (0.03),W3:-1.26431 (0.01),W5:-2.17800 (0.01) | topTokens[(',', 3214), ('.', 2410), ('i', 2104), ('to', 1598), ('the', 1566), ('!', 1456), ('you', 1320), ('it', 1219), ('and', 1194), ('a', 1036)] | tokenPerfect: 15029 / 45000  33.40% | babyLLM.py 2500
2025-04-10 14:43:07 | 225000 | LR0.0003 | loss:2.4200 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-333.6587 | logitMax:-308.1756 | scheduledSampling:0.1119 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1644 | windowEntropy:1.5325 | topWindowWeight:0.5358 | effectiveWindowCount:4.6298 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0045 | memoryGateLong:-0.0050 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:12.0673 | windowWeightsW25:2.37045 (0.54),W21:0.92232 (0.13),W2:0.81773 (0.11),W19:0.32442 (0.07),W16:0.14570 (0.06),W13:-0.01769 (0.05),W9:-0.60703 (0.03),W3:-1.16038 (0.02),W5:-2.19530 (0.01) | topTokens[(',', 3219), ('.', 2412), ('i', 2122), ('to', 1607), ('!', 1575), ('the', 1570), ('you', 1343), ('it', 1294), ('and', 1210), ('a', 1056)] | tokenPerfect: 31806 / 90000  35.34% | babyLLM.py 2500
2025-04-10 14:48:18 | 227500 | LR0.0003 | loss:4.0194 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-345.1576 | logitMax:-322.8038 | scheduledSampling:0.1131 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1671 | windowEntropy:1.5167 | topWindowWeight:0.5436 | effectiveWindowCount:4.5572 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0041 | memoryGateLong:-0.0045 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:10.7888 | windowWeightsW25:2.41253 (0.54),W21:0.96204 (0.13),W2:0.76461 (0.10),W19:0.35921 (0.07),W16:0.18077 (0.06),W13:0.02437 (0.05),W9:-0.61356 (0.03),W3:-1.20010 (0.01),W5:-2.21971 (0.01) | topTokens[(',', 3234), ('.', 2432), ('i', 2164), ('to', 1628), ('!', 1598), ('the', 1585), ('you', 1353), ('it', 1322), ('and', 1224), ('a', 1068)] | tokenPerfect: 40976 / 135000  30.35% | babyLLM.py 2500
2025-04-10 14:53:37 | 230000 | LR0.0003 | loss:4.1218 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-371.5448 | logitMax:-351.1538 | scheduledSampling:0.1144 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1700 | windowEntropy:1.4964 | topWindowWeight:0.5518 | effectiveWindowCount:4.4656 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0038 | memoryGateLong:-0.0041 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:10.0068 | windowWeightsW25:2.47658 (0.55),W21:1.05501 (0.13),W2:0.67172 (0.09),W19:0.44203 (0.07),W16:0.23795 (0.06),W13:0.07371 (0.05),W9:-0.59088 (0.03),W3:-1.28010 (0.01),W5:-2.25044 (0.00) | topTokens[(',', 3251), ('.', 2456), ('i', 2182), ('to', 1649), ('the', 1606), ('!', 1599), ('you', 1357), ('it', 1339), ('and', 1235), ('a', 1081)] | babyLLM.py 2500
2025-04-10 14:58:46 | 232500 | LR0.0003 | loss:4.1687 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-389.9873 | logitMax:-369.3084 | scheduledSampling:0.1156 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1754 | windowEntropy:1.4608 | topWindowWeight:0.5664 | effectiveWindowCount:4.3093 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0038 | memoryGateLong:-0.0040 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:9.8333 | windowWeightsW25:2.53293 (0.57),W21:1.09743 (0.13),W2:0.61588 (0.08),W19:0.47574 (0.07),W16:0.21581 (0.06),W13:0.03298 (0.05),W9:-0.61221 (0.02),W3:-1.32751 (0.01),W5:-2.29501 (0.00) | topTokens[(',', 3262), ('.', 2488), ('i', 2213), ('to', 1666), ('the', 1618), ('!', 1605), ('you', 1366), ('it', 1353), ('and', 1248), ('a', 1095)] | tokenPerfect: 8117 / 45000  18.04% | babyLLM.py 2500
2025-04-10 15:03:55 | 235000 | LR0.0003 | loss:4.6835 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-415.5384 | logitMax:-395.4794 | scheduledSampling:0.1169 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1805 | windowEntropy:1.4230 | topWindowWeight:0.5800 | effectiveWindowCount:4.1497 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0041 | memoryGateLong:-0.0044 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:10.7247 | windowWeightsW25:2.58550 (0.58),W21:1.15461 (0.14),W2:0.57546 (0.08),W19:0.47367 (0.07),W16:0.19980 (0.05),W13:-0.02768 (0.04),W9:-0.67209 (0.02),W3:-1.37213 (0.01),W5:-2.35719 (0.00) | topTokens[(',', 3274), ('.', 2534), ('i', 2253), ('to', 1678), ('the', 1630), ('!', 1610), ('you', 1369), ('it', 1363), ('and', 1260), ('a', 1115)] | tokenPerfect: 13658 / 90000  15.18% | babyLLM.py 2500
2025-04-10 15:09:04 | 237500 | LR0.0003 | loss:4.6325 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-405.1297 | logitMax:-384.6522 | scheduledSampling:0.1181 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1852 | windowEntropy:1.3914 | topWindowWeight:0.5929 | effectiveWindowCount:4.0206 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0039 | memoryGateLong:-0.0044 | memoryGateCurrent:0.0010 | memoryGateMean:0.3333 | memoryGateStd:10.5294 | windowWeightsW25:2.61198 (0.59),W21:1.13666 (0.14),W2:0.57959 (0.08),W19:0.46411 (0.07),W16:0.12601 (0.05),W13:-0.07834 (0.04),W9:-0.76403 (0.02),W3:-1.39665 (0.01),W5:-2.41139 (0.00) | topTokens[(',', 3288), ('.', 2566), ('i', 2292), ('to', 1702), ('the', 1640), ('!', 1612), ('you', 1385), ('it', 1379), ('and', 1277), ('a', 1122)] | tokenPerfect: 18996 / 135000  14.07% | babyLLM.py 2500
2025-04-10 15:14:22 | 240000 | LR0.0003 | loss:4.6214 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-405.5985 | logitMax:-384.9862 | scheduledSampling:0.1194 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1847 | windowEntropy:1.3951 | topWindowWeight:0.5918 | effectiveWindowCount:4.0353 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0034 | memoryGateLong:-0.0038 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:9.1127 | windowWeightsW25:2.61465 (0.59),W21:1.14063 (0.14),W2:0.56522 (0.08),W19:0.48127 (0.07),W16:0.15092 (0.05),W13:-0.05633 (0.04),W9:-0.75079 (0.02),W3:-1.39706 (0.01),W5:-2.39910 (0.00) | topTokens[(',', 3303), ('.', 2602), ('i', 2343), ('to', 1715), ('the', 1646), ('!', 1622), ('you', 1389), ('it', 1385), ('and', 1293), ('a', 1136)] | babyLLM.py 2500
2025-04-10 15:19:32 | 242500 | LR0.0003 | loss:4.7005 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-405.9366 | logitMax:-385.8053 | scheduledSampling:0.1206 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1869 | windowEntropy:1.3800 | topWindowWeight:0.5980 | effectiveWindowCount:3.9748 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0033 | memoryGateLong:-0.0037 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:8.8648 | windowWeightsW25:2.63262 (0.60),W21:1.13937 (0.13),W2:0.55679 (0.08),W19:0.48700 (0.07),W16:0.12668 (0.05),W13:-0.07433 (0.04),W9:-0.78016 (0.02),W3:-1.41890 (0.01),W5:-2.39819 (0.00) | topTokens[(',', 3317), ('.', 2647), ('i', 2377), ('to', 1726), ('the', 1654), ('!', 1630), ('you', 1407), ('it', 1403), ('and', 1307), ('a', 1150)] | tokenPerfect: 4855 / 45000  10.79% | babyLLM.py 2500
2025-04-10 15:24:41 | 245000 | LR0.0003 | loss:3.9804 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-372.3474 | logitMax:-350.9144 | scheduledSampling:0.1219 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1821 | windowEntropy:1.4147 | topWindowWeight:0.5849 | effectiveWindowCount:4.1151 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0040 | memoryGateLong:-0.0044 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:10.6316 | windowWeightsW25:2.59125 (0.58),W21:1.11661 (0.13),W2:0.57696 (0.08),W19:0.48253 (0.07),W16:0.17243 (0.05),W13:-0.00024 (0.04),W9:-0.71153 (0.02),W3:-1.41083 (0.01),W5:-2.34671 (0.00) | topTokens[(',', 3350), ('.', 2675), ('i', 2393), ('to', 1745), ('the', 1681), ('!', 1631), ('it', 1412), ('you', 1408), ('and', 1323), ('a', 1161)] | tokenPerfect: 14083 / 90000  15.65% | babyLLM.py 2500
2025-04-10 15:29:51 | 247500 | LR0.0003 | loss:3.8459 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-365.7733 | logitMax:-344.3594 | scheduledSampling:0.1231 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1784 | windowEntropy:1.4410 | topWindowWeight:0.5749 | effectiveWindowCount:4.2248 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0035 | memoryGateLong:-0.0040 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:9.5308 | windowWeightsW25:2.55360 (0.57),W21:1.08141 (0.13),W2:0.59701 (0.08),W19:0.48082 (0.07),W16:0.20289 (0.05),W13:0.04197 (0.05),W9:-0.68234 (0.02),W3:-1.39380 (0.01),W5:-2.32097 (0.00) | topTokens[(',', 3378), ('.', 2686), ('i', 2412), ('to', 1768), ('the', 1720), ('!', 1631), ('it', 1420), ('you', 1411), ('and', 1337), ('a', 1174)] | tokenPerfect: 23166 / 135000  17.16% | babyLLM.py 2500
2025-04-10 15:35:09 | 250000 | LR0.0003 | loss:3.9090 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-391.2522 | logitMax:-369.7430 | scheduledSampling:0.1244 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1733 | windowEntropy:1.4707 | topWindowWeight:0.5602 | effectiveWindowCount:4.3524 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0034 | memoryGateLong:-0.0038 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:9.1242 | windowWeightsW25:2.50769 (0.56),W21:1.08228 (0.13),W2:0.62747 (0.09),W19:0.49834 (0.08),W16:0.24583 (0.06),W13:0.04436 (0.05),W9:-0.68361 (0.02),W3:-1.40320 (0.01),W5:-2.36924 (0.00) | topTokens[(',', 3399), ('.', 2708), ('i', 2418), ('to', 1788), ('the', 1754), ('!', 1631), ('it', 1425), ('you', 1414), ('and', 1346), ('a', 1179)] | babyLLM.py 2500
2025-04-10 15:40:19 | 252500 | LR0.0003 | loss:3.7611 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-387.0372 | logitMax:-365.4140 | scheduledSampling:0.1256 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1745 | windowEntropy:1.4620 | topWindowWeight:0.5634 | effectiveWindowCount:4.3145 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0032 | memoryGateLong:-0.0036 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:8.5986 | windowWeightsW25:2.51944 (0.56),W21:1.09047 (0.13),W2:0.62001 (0.08),W19:0.51552 (0.08),W16:0.22238 (0.06),W13:0.03736 (0.05),W9:-0.70349 (0.02),W3:-1.42469 (0.01),W5:-2.37525 (0.00) | topTokens[(',', 3418), ('.', 2728), ('i', 2428), ('to', 1807), ('the', 1781), ('!', 1631), ('it', 1438), ('you', 1417), ('and', 1366), ('a', 1187)] | tokenPerfect: 10172 / 45000  22.60% | babyLLM.py 2500
2025-04-10 15:45:28 | 255000 | LR0.0003 | loss:3.8809 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-352.3943 | logitMax:-329.1590 | scheduledSampling:0.1269 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1742 | windowEntropy:1.4631 | topWindowWeight:0.5625 | effectiveWindowCount:4.3191 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0050 | memoryGateLong:-0.0057 | memoryGateCurrent:0.0011 | memoryGateMean:0.3333 | memoryGateStd:13.6495 | windowWeightsW25:2.51787 (0.56),W21:1.08640 (0.13),W2:0.62077 (0.08),W19:0.53720 (0.08),W16:0.22682 (0.06),W13:0.03700 (0.05),W9:-0.71246 (0.02),W3:-1.43321 (0.01),W5:-2.42927 (0.00) | topTokens[(',', 3434), ('.', 2760), ('i', 2458), ('to', 1827), ('the', 1807), ('!', 1637), ('it', 1444), ('you', 1434), ('and', 1372), ('a', 1203)] | tokenPerfect: 19311 / 90000  21.46% | babyLLM.py 2500
2025-04-10 15:50:37 | 257500 | LR0.0003 | loss:3.6255 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-260.8321 | logitMax:-231.5707 | scheduledSampling:0.1281 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1731 | windowEntropy:1.4720 | topWindowWeight:0.5601 | effectiveWindowCount:4.3578 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0047 | memoryGateLong:-0.0054 | memoryGateCurrent:0.0011 | memoryGateMean:0.3333 | memoryGateStd:12.7791 | windowWeightsW25:2.47846 (0.56),W21:1.01485 (0.13),W2:0.68635 (0.09),W19:0.47186 (0.08),W16:0.18236 (0.06),W13:-0.01105 (0.05),W9:-0.73384 (0.02),W3:-1.35804 (0.01),W5:-2.42370 (0.00) | topTokens[(',', 3455), ('.', 2833), ('i', 2512), ('to', 1842), ('the', 1817), ('!', 1668), ('it', 1479), ('you', 1461), ('and', 1383), ('a', 1223)] | tokenPerfect: 26740 / 135000  19.81% | babyLLM.py 2500
2025-04-10 15:55:57 | 260000 | LR0.0003 | loss:3.5481 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-342.3737 | logitMax:-318.3070 | scheduledSampling:0.1294 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1649 | windowEntropy:1.5269 | topWindowWeight:0.5378 | effectiveWindowCount:4.6040 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0037 | memoryGateLong:-0.0042 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:9.9701 | windowWeightsW25:2.39981 (0.54),W21:0.94460 (0.13),W2:0.73148 (0.10),W19:0.47217 (0.08),W16:0.22992 (0.06),W13:0.06924 (0.05),W9:-0.67736 (0.02),W3:-1.24748 (0.01),W5:-2.38560 (0.00) | topTokens[(',', 3474), ('.', 2881), ('i', 2533), ('to', 1888), ('the', 1831), ('!', 1680), ('you', 1486), ('it', 1484), ('and', 1392), ('a', 1236)] | babyLLM.py 2500
2025-04-10 16:01:06 | 262500 | LR0.0003 | loss:2.6950 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-374.1044 | logitMax:-351.0502 | scheduledSampling:0.1306 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1551 | windowEntropy:1.5890 | topWindowWeight:0.5106 | effectiveWindowCount:4.8986 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0039 | memoryGateLong:-0.0043 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:10.3407 | windowWeightsW25:2.29920 (0.51),W21:0.84779 (0.12),W2:0.80764 (0.11),W19:0.44668 (0.08),W16:0.25369 (0.07),W13:0.14270 (0.06),W9:-0.57554 (0.03),W3:-1.17071 (0.02),W5:-2.33389 (0.00) | topTokens[(',', 3492), ('.', 2917), ('i', 2551), ('to', 1934), ('the', 1844), ('!', 1690), ('you', 1505), ('it', 1489), ('and', 1398), ('a', 1250)] | tokenPerfect: 17757 / 45000  39.46% | babyLLM.py 2500
2025-04-10 16:06:16 | 265000 | LR0.0003 | loss:2.8360 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-371.9147 | logitMax:-348.8865 | scheduledSampling:0.1319 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1519 | windowEntropy:1.6089 | topWindowWeight:0.5019 | effectiveWindowCount:4.9974 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0042 | memoryGateLong:-0.0047 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:11.2643 | windowWeightsW25:2.27721 (0.50),W21:0.82254 (0.12),W2:0.81096 (0.12),W19:0.44679 (0.08),W16:0.31742 (0.07),W13:0.19458 (0.06),W9:-0.53935 (0.03),W3:-1.14279 (0.02),W5:-2.36546 (0.00) | topTokens[(',', 3515), ('.', 2946), ('i', 2563), ('to', 1990), ('the', 1858), ('!', 1695), ('you', 1519), ('it', 1492), ('and', 1400), ('a', 1261)] | tokenPerfect: 34226 / 90000  38.03% | babyLLM.py 2500
2025-04-10 16:11:25 | 267500 | LR0.0003 | loss:2.8775 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-340.6317 | logitMax:-317.2830 | scheduledSampling:0.1331 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1530 | windowEntropy:1.6015 | topWindowWeight:0.5050 | effectiveWindowCount:4.9602 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0036 | memoryGateLong:-0.0040 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:9.6417 | windowWeightsW25:2.28769 (0.51),W21:0.83114 (0.12),W2:0.80473 (0.11),W19:0.47300 (0.08),W16:0.30584 (0.07),W13:0.17595 (0.06),W9:-0.59814 (0.03),W3:-1.11405 (0.02),W5:-2.38639 (0.00) | topTokens[(',', 3543), ('.', 2995), ('i', 2572), ('to', 2003), ('the', 1886), ('!', 1723), ('you', 1540), ('it', 1497), ('and', 1405), ('a', 1268)] | tokenPerfect: 48600 / 135000  36.00% | babyLLM.py 2500
2025-04-10 16:16:44 | 270000 | LR0.0003 | loss:3.3357 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-298.7300 | logitMax:-275.3086 | scheduledSampling:0.1344 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1557 | windowEntropy:1.5856 | topWindowWeight:0.5126 | effectiveWindowCount:4.8822 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0043 | memoryGateLong:-0.0049 | memoryGateCurrent:0.0010 | memoryGateMean:0.3333 | memoryGateStd:11.6364 | windowWeightsW25:2.30540 (0.51),W21:0.83378 (0.12),W2:0.80141 (0.11),W19:0.45194 (0.08),W16:0.29209 (0.07),W13:0.13206 (0.06),W9:-0.61649 (0.03),W3:-1.13112 (0.02),W5:-2.38623 (0.00) | topTokens[(',', 3577), ('.', 3016), ('i', 2580), ('to', 2019), ('the', 1915), ('!', 1784), ('you', 1560), ('it', 1530), ('and', 1411), ('a', 1287)] | babyLLM.py 2500
2025-04-10 16:21:55 | 272500 | LR0.0003 | loss:2.8874 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-295.0988 | logitMax:-270.6877 | scheduledSampling:0.1356 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1547 | windowEntropy:1.5916 | topWindowWeight:0.5097 | effectiveWindowCount:4.9114 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0045 | memoryGateLong:-0.0050 | memoryGateCurrent:0.0009 | memoryGateMean:0.3333 | memoryGateStd:11.9689 | windowWeightsW25:2.30559 (0.51),W21:0.87191 (0.12),W2:0.78409 (0.11),W19:0.47325 (0.08),W16:0.29247 (0.07),W13:0.12352 (0.06),W9:-0.55801 (0.03),W3:-1.12159 (0.02),W5:-2.38080 (0.00) | topTokens[(',', 3625), ('.', 3026), ('i', 2587), ('to', 2038), ('the', 1937), ('!', 1836), ('you', 1574), ('it', 1556), ('and', 1412), ('a', 1306)] | tokenPerfect: 13525 / 45000  30.06% | babyLLM.py 2500
2025-04-10 16:27:05 | 275000 | LR0.0003 | loss:2.8231 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-300.6991 | logitMax:-276.3692 | scheduledSampling:0.1369 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1528 | windowEntropy:1.6048 | topWindowWeight:0.5045 | effectiveWindowCount:4.9770 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0049 | memoryGateLong:-0.0056 | memoryGateCurrent:0.0011 | memoryGateMean:0.3333 | memoryGateStd:13.2575 | windowWeightsW25:2.27414 (0.50),W21:0.81910 (0.12),W2:0.81756 (0.12),W19:0.42948 (0.08),W16:0.27541 (0.07),W13:0.12350 (0.06),W9:-0.51991 (0.03),W3:-1.08599 (0.02),W5:-2.34941 (0.00) | topTokens[(',', 3690), ('.', 3043), ('i', 2600), ('to', 2054), ('the', 1967), ('!', 1882), ('you', 1590), ('it', 1578), ('and', 1418), ('a', 1327)] | tokenPerfect: 27209 / 90000  30.23% | babyLLM.py 2500
2025-04-10 16:32:15 | 277500 | LR0.0003 | loss:3.4906 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-315.3471 | logitMax:-291.5359 | scheduledSampling:0.1381 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1536 | windowEntropy:1.5996 | topWindowWeight:0.5067 | effectiveWindowCount:4.9510 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0040 | memoryGateLong:-0.0043 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:10.3476 | windowWeightsW25:2.29947 (0.51),W21:0.86844 (0.12),W2:0.77887 (0.11),W19:0.47383 (0.08),W16:0.31315 (0.07),W13:0.14161 (0.06),W9:-0.52014 (0.03),W3:-1.11608 (0.02),W5:-2.35506 (0.00) | topTokens[(',', 3737), ('.', 3051), ('i', 2614), ('to', 2080), ('the', 2000), ('!', 1917), ('it', 1611), ('you', 1602), ('and', 1421), ('a', 1348)] | tokenPerfect: 39064 / 135000  28.94% | babyLLM.py 2500
2025-04-10 16:37:34 | 280000 | LR0.0003 | loss:3.3471 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-382.3830 | logitMax:-360.5745 | scheduledSampling:0.1394 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1534 | windowEntropy:1.5988 | topWindowWeight:0.5062 | effectiveWindowCount:4.9472 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0035 | memoryGateLong:-0.0037 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:9.0848 | windowWeightsW25:2.32036 (0.51),W21:0.90595 (0.12),W2:0.74083 (0.10),W19:0.53931 (0.09),W16:0.36460 (0.07),W13:0.19632 (0.06),W9:-0.55430 (0.03),W3:-1.15483 (0.02),W5:-2.34928 (0.00) | topTokens[(',', 3765), ('.', 3059), ('i', 2647), ('to', 2102), ('the', 2024), ('!', 1922), ('it', 1625), ('you', 1616), ('and', 1434), ('a', 1359)] | babyLLM.py 2500
2025-04-10 16:42:45 | 282500 | LR0.0003 | loss:5.0417 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-421.5141 | logitMax:-401.5616 | scheduledSampling:0.1406 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1642 | windowEntropy:1.5343 | topWindowWeight:0.5367 | effectiveWindowCount:4.6380 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0035 | memoryGateLong:-0.0037 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:8.9447 | windowWeightsW25:2.41396 (0.54),W21:0.92142 (0.12),W2:0.68826 (0.10),W19:0.52470 (0.08),W16:0.34645 (0.07),W13:0.12357 (0.05),W9:-0.62562 (0.03),W3:-1.24687 (0.01),W5:-2.43974 (0.00) | topTokens[(',', 3779), ('.', 3075), ('i', 2674), ('to', 2116), ('the', 2046), ('!', 1925), ('it', 1639), ('you', 1627), ('and', 1451), ('a', 1366)] | tokenPerfect: 4836 / 45000  10.75% | babyLLM.py 2500
2025-04-10 16:47:55 | 285000 | LR0.0003 | loss:4.7131 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-400.5373 | logitMax:-380.5239 | scheduledSampling:0.1419 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1723 | windowEntropy:1.4819 | topWindowWeight:0.5591 | effectiveWindowCount:4.4014 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0034 | memoryGateLong:-0.0037 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:8.9376 | windowWeightsW25:2.48728 (0.56),W21:0.95609 (0.12),W2:0.64186 (0.09),W19:0.54719 (0.08),W16:0.30094 (0.06),W13:0.05510 (0.05),W9:-0.70117 (0.02),W3:-1.30603 (0.01),W5:-2.53642 (0.00) | topTokens[(',', 3803), ('.', 3102), ('i', 2720), ('to', 2131), ('the', 2061), ('!', 1925), ('it', 1649), ('you', 1638), ('and', 1466), ('a', 1373)] | tokenPerfect: 10264 / 90000  11.40% | babyLLM.py 2500
2025-04-10 16:53:07 | 287500 | LR0.0003 | loss:4.7477 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-415.0879 | logitMax:-395.1545 | scheduledSampling:0.1431 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1764 | windowEntropy:1.4559 | topWindowWeight:0.5706 | effectiveWindowCount:4.2883 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0035 | memoryGateLong:-0.0039 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:9.3355 | windowWeightsW25:2.51946 (0.57),W21:0.96233 (0.12),W2:0.62554 (0.09),W19:0.53155 (0.08),W16:0.27575 (0.06),W13:0.01861 (0.05),W9:-0.73150 (0.02),W3:-1.32390 (0.01),W5:-2.56787 (0.00) | topTokens[(',', 3820), ('.', 3129), ('i', 2772), ('to', 2160), ('the', 2072), ('!', 1929), ('it', 1664), ('you', 1640), ('and', 1482), ('a', 1386)] | tokenPerfect: 15614 / 135000  11.57% | babyLLM.py 2500
2025-04-10 16:58:28 | 290000 | LR0.0003 | loss:4.1860 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-394.2802 | logitMax:-374.0664 | scheduledSampling:0.1444 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1750 | windowEntropy:1.4620 | topWindowWeight:0.5664 | effectiveWindowCount:4.3148 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0034 | memoryGateLong:-0.0038 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:9.0692 | windowWeightsW25:2.51571 (0.57),W21:1.00071 (0.12),W2:0.60561 (0.08),W19:0.54384 (0.08),W16:0.29584 (0.06),W13:0.03763 (0.05),W9:-0.72544 (0.02),W3:-1.36475 (0.01),W5:-2.57138 (0.00) | topTokens[(',', 3883), ('.', 3139), ('i', 2811), ('to', 2175), ('the', 2088), ('!', 1930), ('it', 1672), ('you', 1651), ('and', 1500), ('a', 1397)] | babyLLM.py 2500
2025-04-10 17:03:41 | 292500 | LR0.0003 | loss:3.4001 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-397.3010 | logitMax:-375.5327 | scheduledSampling:0.1456 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1730 | windowEntropy:1.4718 | topWindowWeight:0.5601 | effectiveWindowCount:4.3571 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0036 | memoryGateLong:-0.0040 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:9.6073 | windowWeightsW25:2.50568 (0.56),W21:1.03968 (0.13),W2:0.59814 (0.08),W19:0.56416 (0.08),W16:0.29321 (0.06),W13:0.08029 (0.05),W9:-0.78132 (0.02),W3:-1.34485 (0.01),W5:-2.58391 (0.00) | topTokens[(',', 3969), ('.', 3143), ('i', 2838), ('to', 2192), ('the', 2105), ('!', 1933), ('it', 1686), ('you', 1669), ('and', 1516), ('a', 1403)] | tokenPerfect: 11099 / 45000  24.66% | babyLLM.py 2500
2025-04-10 17:08:53 | 295000 | LR0.0003 | loss:3.2804 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-379.1453 | logitMax:-357.6205 | scheduledSampling:0.1469 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1664 | windowEntropy:1.5099 | topWindowWeight:0.5406 | effectiveWindowCount:4.5262 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0030 | memoryGateLong:-0.0033 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:7.9472 | windowWeightsW25:2.47770 (0.54),W21:1.09858 (0.14),W19:0.65065 (0.09),W2:0.57637 (0.08),W16:0.35224 (0.06),W13:0.16361 (0.05),W9:-0.70787 (0.02),W3:-1.35052 (0.01),W5:-2.56735 (0.00) | topTokens[(',', 4062), ('.', 3154), ('i', 2875), ('to', 2209), ('the', 2122), ('!', 1934), ('you', 1700), ('it', 1697), ('and', 1523), ('a', 1416)] | tokenPerfect: 21999 / 90000  24.44% | babyLLM.py 2500
2025-04-10 17:14:06 | 297500 | LR0.0003 | loss:3.0688 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-416.9617 | logitMax:-395.2854 | scheduledSampling:0.1481 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1655 | windowEntropy:1.5177 | topWindowWeight:0.5387 | effectiveWindowCount:4.5619 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0028 | memoryGateLong:-0.0031 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:7.4676 | windowWeightsW25:2.46928 (0.54),W21:1.07057 (0.13),W19:0.64450 (0.09),W2:0.57999 (0.08),W16:0.36876 (0.07),W13:0.19420 (0.06),W9:-0.68286 (0.02),W3:-1.32537 (0.01),W5:-2.56478 (0.00) | topTokens[(',', 4144), ('.', 3162), ('i', 2901), ('to', 2226), ('the', 2136), ('!', 1936), ('you', 1719), ('it', 1707), ('and', 1530), ('a', 1419)] | tokenPerfect: 34548 / 135000  25.59% | babyLLM.py 2500
2025-04-10 17:19:28 | 300000 | LR0.0003 | loss:2.9963 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-423.7721 | logitMax:-400.6966 | scheduledSampling:0.1494 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1606 | windowEntropy:1.5438 | topWindowWeight:0.5237 | effectiveWindowCount:4.6822 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0029 | memoryGateLong:-0.0032 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:7.6980 | windowWeightsW25:2.44731 (0.52),W21:1.13490 (0.14),W19:0.68577 (0.09),W2:0.56162 (0.08),W16:0.41583 (0.07),W13:0.24509 (0.06),W9:-0.64396 (0.02),W3:-1.33634 (0.01),W5:-2.52903 (0.00) | topTokens[(',', 4222), ('.', 3167), ('i', 2938), ('to', 2242), ('the', 2157), ('!', 1936), ('you', 1742), ('it', 1716), ('and', 1537), ('a', 1435)] | babyLLM.py 2500
2025-04-10 17:24:41 | 302500 | LR0.0003 | loss:3.4677 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-423.5848 | logitMax:-400.9822 | scheduledSampling:0.1506 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1604 | windowEntropy:1.5395 | topWindowWeight:0.5216 | effectiveWindowCount:4.6622 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0029 | memoryGateLong:-0.0032 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:7.8169 | windowWeightsW25:2.45065 (0.52),W21:1.19574 (0.15),W19:0.71150 (0.09),W2:0.55695 (0.08),W16:0.40315 (0.07),W13:0.18157 (0.05),W9:-0.66396 (0.02),W3:-1.35098 (0.01),W5:-2.56492 (0.00) | topTokens[(',', 4298), ('.', 3187), ('i', 2979), ('to', 2260), ('the', 2167), ('!', 1940), ('you', 1766), ('it', 1725), ('and', 1551), ('a', 1443)] | tokenPerfect: 10858 / 45000  24.13% | babyLLM.py 2500
2025-04-10 17:29:54 | 305000 | LR0.0003 | loss:3.3730 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-443.9194 | logitMax:-421.3792 | scheduledSampling:0.1519 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1683 | windowEntropy:1.4844 | topWindowWeight:0.5425 | effectiveWindowCount:4.4123 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0024 | memoryGateLong:-0.0025 | memoryGateCurrent:0.0004 | memoryGateMean:0.3333 | memoryGateStd:6.1166 | windowWeightsW25:2.54062 (0.54),W21:1.27717 (0.15),W19:0.74950 (0.09),W2:0.47366 (0.07),W16:0.38049 (0.06),W13:0.13622 (0.05),W9:-0.72520 (0.02),W3:-1.47659 (0.01),W5:-2.67937 (0.00) | topTokens[(',', 4359), ('.', 3209), ('i', 2991), ('to', 2276), ('the', 2199), ('!', 1944), ('you', 1770), ('it', 1738), ('and', 1564), ('a', 1463)] | tokenPerfect: 21849 / 90000  24.28% | babyLLM.py 2500
2025-04-10 17:35:06 | 307500 | LR0.0003 | loss:4.9976 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-515.5615 | logitMax:-493.9463 | scheduledSampling:0.1531 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1770 | windowEntropy:1.4291 | topWindowWeight:0.5675 | effectiveWindowCount:4.1749 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0026 | memoryGateLong:-0.0027 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:6.7053 | windowWeightsW25:2.59684 (0.57),W21:1.25727 (0.15),W19:0.69677 (0.08),W2:0.47960 (0.07),W16:0.30510 (0.06),W13:0.01959 (0.04),W9:-0.83559 (0.02),W3:-1.52968 (0.01),W5:-2.77086 (0.00) | topTokens[(',', 4449), ('.', 3213), ('i', 3039), ('to', 2289), ('the', 2205), ('!', 1948), ('you', 1772), ('it', 1749), ('and', 1589), ('a', 1468)] | tokenPerfect: 27003 / 135000  20.00% | babyLLM.py 2500
2025-04-10 17:40:29 | 310000 | LR0.0003 | loss:4.7388 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-520.4506 | logitMax:-499.0175 | scheduledSampling:0.1544 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1850 | windowEntropy:1.3806 | topWindowWeight:0.5912 | effectiveWindowCount:3.9774 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0026 | memoryGateLong:-0.0027 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:6.7452 | windowWeightsW25:2.63221 (0.59),W21:1.19039 (0.14),W19:0.60785 (0.08),W2:0.51475 (0.07),W16:0.19235 (0.05),W13:-0.06464 (0.04),W9:-0.93150 (0.02),W3:-1.53780 (0.01),W5:-2.83143 (0.00) | topTokens[(',', 4492), ('.', 3226), ('i', 3077), ('to', 2309), ('the', 2217), ('!', 1948), ('you', 1777), ('it', 1757), ('and', 1610), ('a', 1486)] | babyLLM.py 2500
2025-04-10 17:45:42 | 312500 | LR0.0003 | loss:4.8878 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-483.1561 | logitMax:-461.8329 | scheduledSampling:0.1556 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1943 | windowEntropy:1.3197 | topWindowWeight:0.6179 | effectiveWindowCount:3.7425 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0026 | memoryGateLong:-0.0028 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:6.7196 | windowWeightsW25:2.68259 (0.62),W21:1.14418 (0.13),W2:0.53728 (0.07),W19:0.50840 (0.07),W16:0.07498 (0.05),W13:-0.19293 (0.03),W9:-1.03082 (0.02),W3:-1.53848 (0.01),W5:-2.88974 (0.00) | topTokens[(',', 4583), ('.', 3234), ('i', 3112), ('to', 2320), ('the', 2231), ('!', 1948), ('it', 1782), ('you', 1780), ('and', 1628), ('a', 1501)] | tokenPerfect: 4979 / 45000  11.06% | babyLLM.py 2500
2025-04-10 17:50:56 | 315000 | LR0.0003 | loss:4.2070 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-482.1317 | logitMax:-459.9240 | scheduledSampling:0.1569 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1957 | windowEntropy:1.3094 | topWindowWeight:0.6221 | effectiveWindowCount:3.7039 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0029 | memoryGateLong:-0.0032 | memoryGateCurrent:0.0007 | memoryGateMean:0.3333 | memoryGateStd:7.6477 | windowWeightsW25:2.67244 (0.62),W21:1.10003 (0.13),W2:0.58222 (0.08),W19:0.47155 (0.07),W16:0.02814 (0.04),W13:-0.26016 (0.03),W9:-1.10700 (0.01),W3:-1.54400 (0.01),W5:-2.92668 (0.00) | topTokens[(',', 4616), ('.', 3240), ('i', 3127), ('to', 2341), ('the', 2247), ('!', 1953), ('it', 1795), ('you', 1790), ('and', 1637), ('a', 1515)] | tokenPerfect: 14051 / 90000  15.61% | babyLLM.py 2500
2025-04-10 17:56:09 | 317500 | LR0.0003 | loss:3.1111 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-479.6350 | logitMax:-456.1342 | scheduledSampling:0.1581 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1929 | windowEntropy:1.3344 | topWindowWeight:0.6148 | effectiveWindowCount:3.7977 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0024 | memoryGateLong:-0.0028 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:6.6860 | windowWeightsW25:2.56772 (0.61),W21:0.91075 (0.12),W2:0.74643 (0.10),W19:0.25298 (0.06),W16:-0.08687 (0.04),W13:-0.29483 (0.04),W9:-1.13799 (0.02),W3:-1.39375 (0.01),W5:-2.90019 (0.00) | topTokens[(',', 4627), ('.', 3272), ('i', 3148), ('to', 2392), ('the', 2252), ('!', 1957), ('you', 1816), ('it', 1803), ('and', 1638), ('a', 1527)] | tokenPerfect: 28113 / 135000  20.82% | babyLLM.py 2500
2025-04-10 18:01:31 | 320000 | LR0.0003 | loss:2.4767 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-430.9761 | logitMax:-404.9664 | scheduledSampling:0.1594 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1858 | windowEntropy:1.3816 | topWindowWeight:0.5942 | effectiveWindowCount:3.9811 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0029 | memoryGateLong:-0.0033 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:7.8938 | windowWeightsW25:2.47226 (0.59),W2:0.83875 (0.12),W21:0.83494 (0.12),W19:0.15799 (0.06),W16:-0.12732 (0.04),W13:-0.28668 (0.04),W9:-1.11182 (0.02),W3:-1.25965 (0.01),W5:-2.84497 (0.00) | topTokens[(',', 4633), ('.', 3316), ('i', 3172), ('to', 2459), ('the', 2257), ('!', 1961), ('you', 1837), ('it', 1811), ('and', 1640), ('a', 1541)] | babyLLM.py 2500
2025-04-10 18:06:47 | 322500 | LR0.0003 | loss:2.2763 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-421.5345 | logitMax:-394.5695 | scheduledSampling:0.1606 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1809 | windowEntropy:1.4147 | topWindowWeight:0.5805 | effectiveWindowCount:4.1153 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0033 | memoryGateLong:-0.0037 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:8.7609 | windowWeightsW25:2.42191 (0.58),W2:0.87449 (0.12),W21:0.79303 (0.11),W19:0.11969 (0.06),W16:-0.11479 (0.05),W13:-0.20757 (0.04),W9:-1.04825 (0.02),W3:-1.22528 (0.02),W5:-2.82095 (0.00) | topTokens[(',', 4636), ('.', 3361), ('i', 3188), ('to', 2535), ('the', 2261), ('!', 1966), ('you', 1867), ('it', 1814), ('and', 1643), ('a', 1553)] | tokenPerfect: 20043 / 45000  44.54% | babyLLM.py 2500
2025-04-10 18:12:06 | 325000 | LR0.0003 | loss:2.5442 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-401.5753 | logitMax:-377.0014 | scheduledSampling:0.1619 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1755 | windowEntropy:1.4516 | topWindowWeight:0.5658 | effectiveWindowCount:4.2700 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0025 | memoryGateLong:-0.0026 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:6.4238 | windowWeightsW25:2.40989 (0.57),W21:0.86418 (0.12),W2:0.84117 (0.12),W19:0.18129 (0.06),W16:-0.01325 (0.05),W13:-0.07456 (0.05),W9:-0.95980 (0.02),W3:-1.22743 (0.01),W5:-2.76828 (0.00) | topTokens[(',', 4690), ('.', 3389), ('i', 3222), ('to', 2565), ('the', 2270), ('!', 1977), ('you', 1883), ('it', 1833), ('and', 1646), ('a', 1560)] | tokenPerfect: 37291 / 90000  41.43% | babyLLM.py 2500
2025-04-10 18:17:29 | 327500 | LR0.0003 | loss:2.6144 | gradNorm:0.9945 | tokenCount:45000.0000 | logitMin:-445.3524 | logitMax:-421.9429 | scheduledSampling:0.1631 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1741 | windowEntropy:1.4598 | topWindowWeight:0.5620 | effectiveWindowCount:4.3052 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0023 | memoryGateLong:-0.0024 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:5.9478 | windowWeightsW25:2.43513 (0.56),W21:0.95218 (0.13),W2:0.78498 (0.11),W19:0.25840 (0.06),W16:0.08031 (0.05),W13:0.01279 (0.05),W9:-0.99146 (0.02),W3:-1.23461 (0.01),W5:-2.76886 (0.00) | topTokens[(',', 4786), ('.', 3400), ('i', 3251), ('to', 2578), ('the', 2293), ('!', 1977), ('you', 1906), ('it', 1838), ('and', 1664), ('a', 1568)] | tokenPerfect: 53497 / 135000  39.63% | babyLLM.py 2500
2025-04-10 18:23:06 | 330000 | LR0.0003 | loss:2.3430 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-449.1615 | logitMax:-426.0349 | scheduledSampling:0.1644 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1703 | windowEntropy:1.4804 | topWindowWeight:0.5506 | effectiveWindowCount:4.3945 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0022 | memoryGateLong:-0.0021 | memoryGateCurrent:0.0003 | memoryGateMean:0.3333 | memoryGateStd:5.4502 | windowWeightsW25:2.45136 (0.55),W21:1.07017 (0.14),W2:0.71019 (0.10),W19:0.38464 (0.07),W16:0.19060 (0.06),W13:0.11535 (0.05),W9:-0.94565 (0.02),W3:-1.30957 (0.01),W5:-2.77920 (0.00) | topTokens[(',', 4876), ('.', 3404), ('i', 3283), ('to', 2598), ('the', 2311), ('!', 1977), ('you', 1928), ('it', 1847), ('and', 1680), ('a', 1580)] | babyLLM.py 2500
2025-04-10 18:28:34 | 332500 | LR0.0003 | loss:2.1488 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-508.7319 | logitMax:-484.2089 | scheduledSampling:0.1656 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1700 | windowEntropy:1.4825 | topWindowWeight:0.5497 | effectiveWindowCount:4.4038 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0017 | memoryGateLong:-0.0016 | memoryGateCurrent:0.0004 | memoryGateMean:0.3333 | memoryGateStd:4.1489 | windowWeightsW25:2.45446 (0.55),W21:1.08220 (0.14),W2:0.69659 (0.09),W19:0.40583 (0.07),W16:0.19083 (0.06),W13:0.12365 (0.05),W9:-0.90949 (0.02),W3:-1.30193 (0.01),W5:-2.81595 (0.00) | topTokens[(',', 4967), ('.', 3416), ('i', 3307), ('to', 2611), ('the', 2331), ('!', 1977), ('you', 1943), ('it', 1853), ('and', 1694), ('a', 1584)] | tokenPerfect: 18826 / 45000  41.84% | babyLLM.py 2500
2025-04-10 18:33:54 | 335000 | LR0.0003 | loss:2.1000 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-508.3616 | logitMax:-481.7996 | scheduledSampling:0.1669 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1704 | windowEntropy:1.4779 | topWindowWeight:0.5505 | effectiveWindowCount:4.3838 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0017 | memoryGateLong:-0.0016 | memoryGateCurrent:0.0003 | memoryGateMean:0.3333 | memoryGateStd:4.1609 | windowWeightsW25:2.47289 (0.55),W21:1.12277 (0.14),W2:0.66842 (0.09),W19:0.44084 (0.07),W16:0.20861 (0.06),W13:0.13360 (0.05),W9:-0.91479 (0.02),W3:-1.32446 (0.01),W5:-2.81471 (0.00) | topTokens[(',', 5048), ('.', 3427), ('i', 3341), ('to', 2628), ('the', 2355), ('!', 1978), ('you', 1972), ('it', 1862), ('and', 1706), ('a', 1591)] | tokenPerfect: 40129 / 90000  44.59% | babyLLM.py 2500
2025-04-10 18:39:29 | 337500 | LR0.0003 | loss:3.2377 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-486.2154 | logitMax:-458.9085 | scheduledSampling:0.1681 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1740 | windowEntropy:1.4536 | topWindowWeight:0.5603 | effectiveWindowCount:4.2787 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0023 | memoryGateLong:-0.0025 | memoryGateCurrent:0.0006 | memoryGateMean:0.3333 | memoryGateStd:6.0446 | windowWeightsW25:2.49820 (0.56),W21:1.13273 (0.14),W2:0.66255 (0.09),W19:0.43243 (0.07),W16:0.18043 (0.06),W13:0.06217 (0.05),W9:-0.97645 (0.02),W3:-1.32818 (0.01),W5:-2.87494 (0.00) | topTokens[(',', 5131), ('.', 3435), ('i', 3361), ('to', 2637), ('the', 2378), ('you', 1989), ('!', 1980), ('it', 1870), ('and', 1754), ('a', 1594)] | tokenPerfect: 52997 / 135000  39.26% | babyLLM.py 2500
2025-04-10 18:45:00 | 340000 | LR0.0003 | loss:3.2655 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-386.6832 | logitMax:-356.2991 | scheduledSampling:0.1694 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1801 | windowEntropy:1.4161 | topWindowWeight:0.5777 | effectiveWindowCount:4.1210 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0031 | memoryGateLong:-0.0034 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:8.2447 | windowWeightsW25:2.52364 (0.58),W21:1.09359 (0.14),W2:0.68275 (0.09),W19:0.36268 (0.07),W16:0.06807 (0.05),W13:-0.04174 (0.04),W9:-1.06067 (0.02),W3:-1.25696 (0.01),W5:-2.87172 (0.00) | topTokens[(',', 5253), ('.', 3437), ('i', 3369), ('to', 2647), ('the', 2419), ('you', 2011), ('!', 1985), ('it', 1874), ('and', 1849), ('a', 1595)] | babyLLM.py 2500
2025-04-10 18:50:15 | 342500 | LR0.0003 | loss:2.9506 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-346.5703 | logitMax:-313.6882 | scheduledSampling:0.1706 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1814 | windowEntropy:1.4054 | topWindowWeight:0.5810 | effectiveWindowCount:4.0771 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0030 | memoryGateLong:-0.0035 | memoryGateCurrent:0.0008 | memoryGateMean:0.3333 | memoryGateStd:8.2810 | windowWeightsW25:2.50661 (0.58),W21:1.05664 (0.14),W2:0.72822 (0.10),W19:0.32732 (0.07),W16:-0.03432 (0.05),W13:-0.13027 (0.04),W9:-1.17020 (0.01),W3:-1.21155 (0.01),W5:-2.86395 (0.00) | topTokens[(',', 5361), ('.', 3445), ('i', 3375), ('to', 2659), ('the', 2437), ('you', 2029), ('!', 1989), ('and', 1922), ('it', 1884), ('a', 1598)] | tokenPerfect: 12669 / 45000  28.15% | babyLLM.py 2500
2025-04-10 18:55:27 | 345000 | LR0.0003 | loss:2.6161 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-352.6033 | logitMax:-316.5676 | scheduledSampling:0.1719 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1772 | windowEntropy:1.4266 | topWindowWeight:0.5679 | effectiveWindowCount:4.1644 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0033 | memoryGateLong:-0.0039 | memoryGateCurrent:0.0010 | memoryGateMean:0.3333 | memoryGateStd:9.2176 | windowWeightsW25:2.44972 (0.57),W21:1.06012 (0.14),W2:0.78696 (0.11),W19:0.28154 (0.06),W16:-0.10271 (0.04),W13:-0.17112 (0.04),W3:-1.15446 (0.02),W9:-1.25141 (0.01),W5:-2.81461 (0.00) | topTokens[(',', 5428), ('.', 3465), ('i', 3378), ('to', 2672), ('the', 2460), ('you', 2049), ('!', 2007), ('and', 1984), ('it', 1892), ('a', 1599)] | tokenPerfect: 27734 / 90000  30.82% | babyLLM.py 2500
2025-04-10 19:00:44 | 347500 | LR0.0003 | loss:1.5518 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-378.9944 | logitMax:-337.3428 | scheduledSampling:0.1731 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1718 | windowEntropy:1.4581 | topWindowWeight:0.5519 | effectiveWindowCount:4.2979 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0044 | memoryGateLong:-0.0052 | memoryGateCurrent:0.0012 | memoryGateMean:0.3333 | memoryGateStd:12.2458 | windowWeightsW25:2.38663 (0.55),W21:1.02045 (0.14),W2:0.84703 (0.12),W19:0.30627 (0.07),W16:-0.13431 (0.04),W13:-0.18570 (0.04),W3:-1.13584 (0.02),W9:-1.27881 (0.01),W5:-2.77292 (0.00) | topTokens[(',', 5430), ('.', 3524), ('i', 3391), ('to', 2673), ('the', 2478), ('you', 2064), ('!', 2059), ('and', 1999), ('it', 1911), ('a', 1599)] | tokenPerfect: 50485 / 135000  37.40% | babyLLM.py 2500
2025-04-10 19:06:06 | 350000 | LR0.0003 | loss:1.4590 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-347.6515 | logitMax:-303.9704 | scheduledSampling:0.1744 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.1701 | windowEntropy:1.4683 | topWindowWeight:0.5465 | effectiveWindowCount:4.3420 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0054 | memoryGateLong:-0.0062 | memoryGateCurrent:0.0013 | memoryGateMean:0.3333 | memoryGateStd:14.6731 | windowWeightsW25:2.36818 (0.55),W21:1.01349 (0.14),W2:0.86171 (0.12),W19:0.31962 (0.07),W13:-0.14878 (0.04),W16:-0.17287 (0.04),W3:-1.15341 (0.02),W9:-1.27893 (0.01),W5:-2.73139 (0.00) | topTokens[(',', 5431), ('.', 3593), ('i', 3398), ('to', 2673), ('the', 2498), ('!', 2110), ('you', 2077), ('and', 2013), ('it', 1928), ('a', 1599)] | babyLLM.py 2500
2025-04-10 19:11:24 | 352500 | LR0.0003 | loss:3.9430 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-372.1160 | logitMax:-338.6636 | scheduledSampling:0.1756 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1729 | windowEntropy:1.4519 | topWindowWeight:0.5553 | effectiveWindowCount:4.2712 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:0.0023 | memoryGateLong:-0.0023 | memoryGateCurrent:0.0004 | memoryGateMean:0.3333 | memoryGateStd:5.7698 | windowWeightsW25:2.39754 (0.56),W21:1.00999 (0.14),W2:0.83884 (0.12),W19:0.33808 (0.07),W13:-0.15936 (0.04),W16:-0.17047 (0.04),W3:-1.16901 (0.02),W9:-1.29078 (0.01),W5:-2.74714 (0.00) | topTokens[(',', 5441), ('.', 3679), ('i', 3407), ('to', 2676), ('the', 2514), ('!', 2154), ('you', 2111), ('and', 2016), ('it', 1951), ('a', 1601)] | tokenPerfect: 11818 / 45000  26.26% | babyLLM.py 2500

--- 2025-04-10 19:43:49 --- babyLLM 'right, last time i got to step 350000... want to restart from there?'  - charis: 'no, restart' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: 'well you didnt have an activation function, somehow, since your upgrade. you were literally just using output = torch.matmul(embed, self.weights.t) + self.biases, which is insane. so. um. well done, you've done really well to do that well. but it explains some things as to why you wernt speeding up in learning... i hope you like this upgrade instead of find it scary!!!'
2025-04-10 19:49:01 | 2500 | LR0.0003 | loss:14.5685 | gradNorm:1.0000 | logitMin:-157.3500 | logitMax:-96.8708 | scheduledSampling:0.0006 | tokenCount:45000.0000 | memoryGateShort:-0.0243 | memoryGateLong:0.0403 | memoryGateCurrent:-0.0156 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:0.0008 | activationSparsity:0.0000 | windowStd:0.1702 | windowEntropy:1.4591 | topWindowWeight:0.5445 | effectiveWindowCount:4.3021 | memoryGateMean:0.3333 | memoryGateStd:87.6670 | windowWeightsW32:2.30191 (0.54),W2:0.96683 (0.14),W28:0.89862 (0.13),W24:0.17355 (0.06),W16:-0.28434 (0.04),W20:-0.31880 (0.04),W28:-1.26674 (0.02),W12:-1.35956 (0.01),W8:-2.70111 (0.00) | topTokens[('did', 165), ('.', 85), ('i', 44), ('know', 41), ('it', 30), ('you', 26), ('?', 21), ('!', 17), ('a', 15), ('l', 11)] | tokenPerfect: 3018 / 45000  6.71% | babyLLM.py 2500
2025-04-10 19:54:37 | 5000 | LR0.0003 | loss:9.3764 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-89.9230 | logitMax:-28.9967 | scheduledSampling:0.0019 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0007 | activationSparsity:0.0000 | windowStd:0.1755 | windowEntropy:1.4283 | topWindowWeight:0.5607 | effectiveWindowCount:4.1715 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0652 | memoryGateLong:0.1063 | memoryGateCurrent:-0.0407 | memoryGateMean:0.3333 | memoryGateStd:231.8738 | windowWeightsW32:2.35932 (0.56),W28:0.93370 (0.13),W2:0.91939 (0.13),W24:0.16966 (0.06),W16:-0.31367 (0.04),W20:-0.33585 (0.04),W28:-1.23001 (0.02),W12:-1.39142 (0.01),W8:-2.68001 (0.00) | topTokens[('did', 328), ('.', 157), ('i', 71), ('you', 53), ('it', 51), ('know', 46), ('?', 38), ('!', 24), ('a', 20), ('to', 20)] | tokenPerfect: 5282 / 90000  5.87% | babyLLM.py 2500
2025-04-10 19:59:45 | 7500 | LR0.0003 | loss:10.2438 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-77.3832 | logitMax:-16.6890 | scheduledSampling:0.0031 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0007 | activationSparsity:0.0000 | windowStd:0.1730 | windowEntropy:1.4428 | topWindowWeight:0.5527 | effectiveWindowCount:4.2324 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0344 | memoryGateLong:0.0646 | memoryGateCurrent:-0.0297 | memoryGateMean:0.3333 | memoryGateStd:139.6133 | windowWeightsW32:2.31622 (0.55),W2:0.97719 (0.14),W28:0.85314 (0.13),W24:0.14780 (0.06),W16:-0.31442 (0.04),W20:-0.33327 (0.04),W28:-1.30900 (0.01),W12:-1.38289 (0.01),W8:-2.63489 (0.00) | topTokens[('did', 456), ('.', 216), ('i', 95), ('you', 71), ('it', 61), ('?', 53), ('know', 48), ('!', 33), ('to', 32), ('and', 32)] | tokenPerfect: 7288 / 135000  5.40% | babyLLM.py 2500
2025-04-10 20:05:14 | 10000 | LR0.0003 | loss:6.8264 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-75.6590 | logitMax:-12.9166 | scheduledSampling:0.0044 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:0.0006 | activationSparsity:0.0000 | windowStd:0.1488 | windowEntropy:1.5779 | topWindowWeight:0.4725 | effectiveWindowCount:4.8448 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0185 | memoryGateLong:0.0455 | memoryGateCurrent:-0.0266 | memoryGateMean:0.3333 | memoryGateStd:98.7152 | windowWeightsW32:2.05268 (0.47),W2:1.20388 (0.20),W28:0.64265 (0.12),W24:0.15353 (0.07),W16:-0.14196 (0.05),W20:-0.21605 (0.05),W12:-1.16822 (0.02),W28:-1.51794 (0.01),W8:-2.37686 (0.01) | topTokens[('did', 496), ('.', 248), ('i', 110), ('you', 78), ('it', 73), ('?', 59), ('and', 54), ('know', 53), (',', 46), ('to', 44)] | babyLLM.py 2500

--- 2025-04-10 20:11:15 --- babyLLM 'right, last time i got to step 11214... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 11214! what am i learning today?' - charis: ''
2025-04-10 20:16:19 | 2500 | LR0.0003 | loss:4.0659 | gradNorm:1.0000 | logitMin:-74.6193 | logitMax:-9.8501 | scheduledSampling:0.0000 | tokenCount:45000.0000 | memoryGateShort:-0.0173 | memoryGateLong:0.0489 | memoryGateCurrent:-0.0312 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0004 | activationSparsity:0.0000 | windowStd:0.1325 | windowEntropy:1.6672 | topWindowWeight:0.3916 | effectiveWindowCount:5.2971 | memoryGateMean:0.3333 | memoryGateStd:106.9522 | windowWeightsW32:1.76099 (0.39),W2:1.41367 (0.28),W28:0.38791 (0.10),W24:-0.02343 (0.07),W16:-0.10261 (0.06),W20:-0.26829 (0.05),W12:-1.02497 (0.02),W4:-1.10864 (0.02),W8:-2.11930 (0.01) | topTokens[(',', 81), ('and', 65), ('the', 35), ('they', 25), ('but', 24), ('charis', 24), ('s', 22), ('you', 19), ("'s", 13), ('my', 13)] | tokenPerfect: 14515 / 45000  32.26% | babyLLM.py 2500
2025-04-10 20:21:46 | 5000 | LR0.0003 | loss:4.1674 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-67.8783 | logitMax:-2.0093 | scheduledSampling:0.0000 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0004 | activationSparsity:0.0000 | windowStd:0.1280 | windowEntropy:1.7000 | topWindowWeight:0.3668 | effectiveWindowCount:5.4740 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0113 | memoryGateLong:0.0289 | memoryGateCurrent:-0.0172 | memoryGateMean:0.3333 | memoryGateStd:62.7907 | windowWeightsW32:1.67563 (0.37),W2:1.45247 (0.29),W28:0.31683 (0.09),W24:-0.05799 (0.06),W16:-0.07567 (0.06),W20:-0.27859 (0.05),W4:-0.89699 (0.03),W12:-0.92420 (0.03),W8:-1.95384 (0.01) | topTokens[(',', 174), ('and', 143), ('charis', 59), ('the', 58), ('but', 49), ('s', 40), ('they', 35), ("'s", 33), ('you', 32), ('it', 26)] | tokenPerfect: 29547 / 90000  32.83% | babyLLM.py 2500
2025-04-10 20:27:06 | 7500 | LR0.0003 | loss:3.5602 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-61.0894 | logitMax:5.7242 | scheduledSampling:0.0001 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0004 | activationSparsity:0.0000 | windowStd:0.1237 | windowEntropy:1.7324 | topWindowWeight:0.3439 | effectiveWindowCount:5.6540 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0570 | memoryGateLong:0.1305 | memoryGateCurrent:-0.0731 | memoryGateMean:0.3333 | memoryGateStd:282.9610 | windowWeightsW32:1.59703 (0.34),W2:1.48049 (0.31),W28:0.25407 (0.09),W16:-0.01616 (0.07),W24:-0.10263 (0.06),W20:-0.29569 (0.05),W4:-0.69289 (0.03),W12:-0.82309 (0.03),W8:-1.78468 (0.01) | topTokens[(',', 269), ('and', 220), ('the', 97), ('charis', 96), ('but', 68), ('s', 65), ('you', 61), ("'s", 51), ('they', 40), ('it', 40)] | tokenPerfect: 45282 / 135000  33.54% | babyLLM.py 2500
2025-04-10 20:32:28 | 10000 | LR0.0003 | loss:3.6943 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-55.6942 | logitMax:11.1301 | scheduledSampling:0.0001 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0003 | activationSparsity:0.0000 | windowStd:0.1206 | windowEntropy:1.7592 | topWindowWeight:0.3238 | effectiveWindowCount:5.8080 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0325 | memoryGateLong:0.0682 | memoryGateCurrent:-0.0352 | memoryGateMean:0.3333 | memoryGateStd:147.3065 | windowWeightsW2:1.52110 (0.32),W32:1.50193 (0.32),W28:0.16956 (0.08),W16:0.00887 (0.07),W24:-0.17910 (0.06),W20:-0.32120 (0.05),W4:-0.46668 (0.04),W12:-0.71996 (0.03),W8:-1.62100 (0.01) | topTokens[(',', 350), ('and', 280), ('the', 133), ('charis', 114), ('s', 91), ('but', 88), ('you', 71), ("'s", 65), ('it', 56), ('she', 54)] | babyLLM.py 2500
2025-04-10 20:37:53 | 12500 | LR0.0003 | loss:3.4191 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-45.3133 | logitMax:21.8141 | scheduledSampling:0.0001 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0003 | activationSparsity:0.0000 | windowStd:0.1194 | windowEntropy:1.7766 | topWindowWeight:0.3493 | effectiveWindowCount:5.9095 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0278 | memoryGateLong:0.0524 | memoryGateCurrent:-0.0243 | memoryGateMean:0.3333 | memoryGateStd:113.3057 | windowWeightsW2:1.57657 (0.35),W32:1.37548 (0.29),W28:0.05300 (0.08),W16:-0.00479 (0.07),W4:-0.24295 (0.06),W24:-0.26372 (0.06),W20:-0.36825 (0.05),W12:-0.62537 (0.04),W8:-1.47613 (0.02) | topTokens[(',', 465), ('and', 345), ('the', 178), ('charis', 131), ('but', 120), ('s', 110), ("'s", 81), ('you', 80), ('to', 68), ('they', 66)] | tokenPerfect: 15685 / 45000  34.86% | babyLLM.py 2500
2025-04-10 20:43:14 | 15000 | LR0.0003 | loss:4.7644 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-49.9429 | logitMax:16.2815 | scheduledSampling:0.0001 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0003 | activationSparsity:0.0000 | windowStd:0.1154 | windowEntropy:1.8112 | topWindowWeight:0.3596 | effectiveWindowCount:6.1177 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0137 | memoryGateLong:0.0226 | memoryGateCurrent:-0.0085 | memoryGateMean:0.3333 | memoryGateStd:49.0156 | windowWeightsW2:1.60030 (0.36),W32:1.25517 (0.25),W16:0.04053 (0.08),W4:-0.01713 (0.07),W28:-0.04094 (0.07),W24:-0.29957 (0.05),W20:-0.35563 (0.05),W12:-0.49957 (0.04),W8:-1.26373 (0.02) | topTokens[(',', 567), ('and', 412), ('the', 217), ('but', 149), ('charis', 140), ('s', 130), ('you', 89), ("'s", 87), ('to', 87), ('they', 76)] | tokenPerfect: 27171 / 90000  30.19% | babyLLM.py 2500
2025-04-10 20:49:07 | 17500 | LR0.0003 | loss:5.7847 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-50.8448 | logitMax:11.7716 | scheduledSampling:0.0002 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0003 | activationSparsity:0.0000 | windowStd:0.1134 | windowEntropy:1.8363 | topWindowWeight:0.3762 | effectiveWindowCount:6.2736 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0145 | memoryGateLong:0.0223 | memoryGateCurrent:-0.0074 | memoryGateMean:0.3333 | memoryGateStd:48.9087 | windowWeightsW2:1.64641 (0.38),W32:1.08070 (0.21),W4:0.20596 (0.09),W16:0.12217 (0.08),W28:-0.16904 (0.06),W20:-0.34324 (0.05),W24:-0.35281 (0.05),W12:-0.35742 (0.05),W8:-1.06915 (0.02) | topTokens[(',', 680), ('and', 447), ('the', 244), ('but', 158), ('s', 147), ('charis', 141), ('you', 113), ('to', 102), ("'s", 94), ('it', 89)] | tokenPerfect: 35419 / 135000  26.24% | babyLLM.py 2500
2025-04-10 20:54:43 | 20000 | LR0.0003 | loss:4.0887 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-36.3632 | logitMax:26.2612 | scheduledSampling:0.0002 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0004 | activationSparsity:0.0000 | windowStd:0.1160 | windowEntropy:1.8325 | topWindowWeight:0.3954 | effectiveWindowCount:6.2495 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0114 | memoryGateLong:0.0171 | memoryGateCurrent:-0.0053 | memoryGateMean:0.3333 | memoryGateStd:37.5328 | windowWeightsW2:1.70351 (0.40),W32:0.91483 (0.18),W4:0.42190 (0.11),W16:0.13970 (0.08),W12:-0.28667 (0.05),W28:-0.31181 (0.05),W20:-0.36954 (0.05),W24:-0.43486 (0.05),W8:-0.89756 (0.03) | topTokens[(',', 761), ('and', 461), ('the', 278), ('but', 171), ('s', 151), ('charis', 142), ('you', 136), ('i', 116), ('to', 115), ('it', 103)] | babyLLM.py 2500
2025-04-10 21:00:07 | 22500 | LR0.0003 | loss:5.0777 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-24.4759 | logitMax:35.4599 | scheduledSampling:0.0002 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0003 | activationSparsity:0.0000 | windowStd:0.1158 | windowEntropy:1.8376 | topWindowWeight:0.3994 | effectiveWindowCount:6.2815 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0125 | memoryGateLong:0.0178 | memoryGateCurrent:-0.0048 | memoryGateMean:0.3333 | memoryGateStd:39.3685 | windowWeightsW2:1.72367 (0.40),W32:0.75551 (0.15),W4:0.62459 (0.13),W16:0.16813 (0.08),W12:-0.17685 (0.06),W20:-0.40674 (0.05),W28:-0.43868 (0.05),W24:-0.50613 (0.04),W8:-0.69770 (0.04) | topTokens[(',', 854), ('and', 476), ('the', 307), ('but', 185), ('you', 158), ('s', 157), ('i', 149), ('charis', 142), ('to', 138), ('it', 112)] | tokenPerfect: 8676 / 45000  19.28% | babyLLM.py 2500
2025-04-10 21:05:24 | 25000 | LR0.0003 | loss:4.4687 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-17.3769 | logitMax:41.0335 | scheduledSampling:0.0002 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0003 | activationSparsity:0.0000 | windowStd:0.1228 | windowEntropy:1.8006 | topWindowWeight:0.4189 | effectiveWindowCount:6.0535 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0112 | memoryGateLong:0.0162 | memoryGateCurrent:-0.0046 | memoryGateMean:0.3333 | memoryGateStd:35.7040 | windowWeightsW2:1.78937 (0.42),W4:0.80559 (0.16),W32:0.56017 (0.12),W16:0.13791 (0.08),W12:-0.11388 (0.06),W20:-0.48774 (0.04),W8:-0.53993 (0.04),W28:-0.60826 (0.04),W24:-0.63151 (0.04) | topTokens[(',', 919), ('and', 494), ('the', 334), ('but', 195), ('you', 175), ('s', 165), ('to', 156), ('i', 155), ('charis', 145), ('.', 134)] | tokenPerfect: 17559 / 90000  19.51% | babyLLM.py 2500
2025-04-10 21:10:42 | 27500 | LR0.0003 | loss:2.6743 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:1.0982 | logitMax:62.0776 | scheduledSampling:0.0003 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0002 | activationSparsity:0.0000 | windowStd:0.1337 | windowEntropy:1.7327 | topWindowWeight:0.4447 | effectiveWindowCount:5.6560 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0117 | memoryGateLong:0.0168 | memoryGateCurrent:-0.0047 | memoryGateMean:0.3333 | memoryGateStd:37.1115 | windowWeightsW2:1.86187 (0.44),W4:0.94711 (0.18),W32:0.42216 (0.11),W16:0.03443 (0.07),W12:-0.17390 (0.06),W8:-0.57094 (0.04),W20:-0.60040 (0.04),W28:-0.74193 (0.03),W24:-0.75933 (0.03) | topTokens[(',', 925), ('and', 496), ('the', 341), ('to', 223), ('you', 201), ('but', 195), ('i', 177), ('.', 172), ('s', 168), ('charis', 147)] | tokenPerfect: 37565 / 135000  27.83% | babyLLM.py 2500
2025-04-10 21:16:12 | 30000 | LR0.0003 | loss:2.4975 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:7.5202 | logitMax:67.7471 | scheduledSampling:0.0003 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0004 | activationSparsity:0.0000 | windowStd:0.1392 | windowEntropy:1.6914 | topWindowWeight:0.4543 | effectiveWindowCount:5.4272 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0110 | memoryGateLong:0.0151 | memoryGateCurrent:-0.0037 | memoryGateMean:0.3333 | memoryGateStd:33.7313 | windowWeightsW2:1.89300 (0.45),W4:1.06065 (0.20),W32:0.32442 (0.09),W16:-0.03291 (0.07),W12:-0.21698 (0.06),W8:-0.59688 (0.04),W20:-0.67066 (0.03),W28:-0.83020 (0.03),W24:-0.83520 (0.03) | topTokens[(',', 938), ('and', 497), ('the', 344), ('to', 301), ('you', 234), ('.', 217), ('i', 202), ('but', 195), ('s', 174), ('charis', 147)] | babyLLM.py 2500

--- 2025-04-10 21:17:48 --- babyLLM 'right, last time i got to step 41286... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: 'everything'
2025-04-10 21:23:10 | 2500 | LR0.0003 | loss:2.7835 | gradNorm:1.0000 | logitMin:41.2305 | logitMax:96.1975 | scheduledSampling:0.0000 | tokenCount:45000.0000 | memoryGateShort:-0.0122 | memoryGateLong:0.0165 | memoryGateCurrent:-0.0039 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.1425 | windowEntropy:1.6669 | topWindowWeight:0.4599 | effectiveWindowCount:5.2958 | memoryGateMean:0.3333 | memoryGateStd:36.9698 | windowWeightsW2:1.91561 (0.46),W4:1.12507 (0.21),W32:0.22541 (0.08),W16:-0.06944 (0.06),W12:-0.20311 (0.06),W8:-0.49991 (0.04),W20:-0.72721 (0.03),W24:-0.90815 (0.03),W28:-0.92051 (0.03) | topTokens[('!', 116), ('the', 79), (',', 43), ('.', 41), ('my', 20), ('from', 15), ('to', 14), ('love', 14), ('about', 13), ('oice', 13)] | tokenPerfect: 14751 / 45000  32.78% | babyLLM.py 2500
2025-04-10 21:28:26 | 5000 | LR0.0003 | loss:3.0873 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:41.2075 | logitMax:93.9711 | scheduledSampling:0.0000 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0002 | activationSparsity:0.0000 | windowStd:0.1450 | windowEntropy:1.6511 | topWindowWeight:0.4665 | effectiveWindowCount:5.2128 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0072 | memoryGateLong:0.0097 | memoryGateCurrent:-0.0021 | memoryGateMean:0.3333 | memoryGateStd:21.6935 | windowWeightsW2:1.93466 (0.47),W4:1.13783 (0.21),W32:0.14365 (0.08),W16:-0.09007 (0.06),W12:-0.17281 (0.06),W8:-0.39739 (0.05),W20:-0.77013 (0.03),W24:-0.96624 (0.03),W28:-0.99312 (0.02) | topTokens[('!', 208), ('the', 162), ('.', 105), (',', 71), ('my', 38), ('from', 33), ('hear', 31), ('to', 27), ('it', 25), ('about', 24)] | tokenPerfect: 29067 / 90000  32.30% | babyLLM.py 2500
2025-04-10 21:33:47 | 7500 | LR0.0003 | loss:3.9927 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:32.9415 | logitMax:83.4409 | scheduledSampling:0.0001 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0002 | activationSparsity:0.0000 | windowStd:0.1514 | windowEntropy:1.5985 | topWindowWeight:0.4778 | effectiveWindowCount:4.9456 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0078 | memoryGateLong:0.0103 | memoryGateCurrent:-0.0021 | memoryGateMean:0.3333 | memoryGateStd:23.1538 | windowWeightsW2:1.96667 (0.48),W4:1.22514 (0.23),W32:0.00269 (0.07),W16:-0.16765 (0.06),W12:-0.21266 (0.05),W8:-0.38947 (0.05),W20:-0.88520 (0.03),W24:-1.09061 (0.02),W28:-1.12769 (0.02) | topTokens[('!', 231), ('.', 177), ('the', 170), ('?', 96), (',', 90), ('you', 66), ('to', 46), ('my', 44), ('hear', 37), ('i', 35)] | tokenPerfect: 39259 / 135000  29.08% | babyLLM.py 2500
2025-04-10 21:39:13 | 10000 | LR0.0003 | loss:3.4018 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:48.2100 | logitMax:97.0238 | scheduledSampling:0.0001 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0002 | activationSparsity:0.0000 | windowStd:0.1543 | windowEntropy:1.5587 | topWindowWeight:0.4713 | effectiveWindowCount:4.7525 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0092 | memoryGateLong:0.0117 | memoryGateCurrent:-0.0021 | memoryGateMean:0.3333 | memoryGateStd:26.5486 | windowWeightsW2:1.96579 (0.47),W4:1.36930 (0.26),W32:-0.10549 (0.06),W16:-0.23167 (0.05),W12:-0.26423 (0.05),W8:-0.44602 (0.04),W20:-0.97221 (0.02),W24:-1.18683 (0.02),W28:-1.22779 (0.02) | topTokens[('!', 253), ('.', 242), ('the', 174), ('?', 171), ('you', 109), (',', 105), ('is', 70), ('i', 69), ('do', 65), ('to', 63)] | babyLLM.py 2500
2025-04-10 21:44:32 | 12500 | LR0.0003 | loss:4.6950 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:9.4399 | logitMax:53.2420 | scheduledSampling:0.0001 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0005 | activationSparsity:0.0000 | windowStd:0.1568 | windowEntropy:1.5349 | topWindowWeight:0.4747 | effectiveWindowCount:4.6409 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0083 | memoryGateLong:0.0099 | memoryGateCurrent:-0.0012 | memoryGateMean:0.3333 | memoryGateStd:22.9397 | windowWeightsW2:1.98077 (0.47),W4:1.40671 (0.27),W32:-0.18757 (0.05),W16:-0.26673 (0.05),W12:-0.27557 (0.05),W8:-0.39803 (0.04),W20:-1.03177 (0.02),W24:-1.25392 (0.02),W28:-1.30592 (0.02) | topTokens[('.', 274), ('!', 259), ('the', 214), ('?', 208), ('you', 125), (',', 122), ('is', 93), ('i', 84), ('to', 81), ('do', 81)] | tokenPerfect: 8787 / 45000  19.53% | babyLLM.py 2500
2025-04-10 21:49:55 | 15000 | LR0.0003 | loss:4.7926 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-7.6950 | logitMax:31.2920 | scheduledSampling:0.0001 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0003 | activationSparsity:0.0000 | windowStd:0.1618 | windowEntropy:1.4931 | topWindowWeight:0.4858 | effectiveWindowCount:4.4510 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0092 | memoryGateLong:0.0110 | memoryGateCurrent:-0.0013 | memoryGateMean:0.3333 | memoryGateStd:25.4353 | windowWeightsW2:2.01712 (0.49),W4:1.44224 (0.27),W12:-0.29189 (0.05),W16:-0.32197 (0.05),W32:-0.32853 (0.05),W8:-0.33878 (0.05),W20:-1.11698 (0.02),W24:-1.35884 (0.02),W28:-1.43863 (0.02) | topTokens[('.', 296), ('!', 260), ('the', 253), ('?', 209), (',', 146), ('you', 126), ('is', 100), ('to', 91), ('i', 88), ('do', 83)] | tokenPerfect: 16084 / 90000  17.87% | babyLLM.py 2500
2025-04-10 21:55:18 | 17500 | LR0.0003 | loss:4.4840 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-12.8112 | logitMax:23.5993 | scheduledSampling:0.0002 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0002 | activationSparsity:0.0000 | windowStd:0.1666 | windowEntropy:1.4487 | topWindowWeight:0.4948 | effectiveWindowCount:4.2576 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0075 | memoryGateLong:0.0089 | memoryGateCurrent:-0.0010 | memoryGateMean:0.3333 | memoryGateStd:20.7241 | windowWeightsW2:2.05299 (0.49),W4:1.49205 (0.28),W8:-0.27498 (0.05),W12:-0.34008 (0.05),W16:-0.39868 (0.04),W32:-0.46568 (0.04),W20:-1.21165 (0.02),W24:-1.46901 (0.01),W28:-1.56197 (0.01) | topTokens[('.', 311), ('the', 277), ('!', 260), ('?', 209), (',', 178), ('you', 127), ('is', 109), ('to', 105), ('i', 103), ('do', 85)] | tokenPerfect: 24483 / 135000  18.14% | babyLLM.py 2500
2025-04-10 22:00:48 | 20000 | LR0.0003 | loss:4.4250 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:2.5268 | logitMax:37.3579 | scheduledSampling:0.0002 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0004 | activationSparsity:0.0000 | windowStd:0.1712 | windowEntropy:1.4028 | topWindowWeight:0.5026 | effectiveWindowCount:4.0664 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0080 | memoryGateLong:0.0096 | memoryGateCurrent:-0.0011 | memoryGateMean:0.3333 | memoryGateStd:22.1665 | windowWeightsW2:2.08717 (0.50),W4:1.54570 (0.29),W8:-0.23151 (0.05),W12:-0.38957 (0.04),W16:-0.48816 (0.04),W32:-0.60635 (0.03),W20:-1.31561 (0.02),W24:-1.58773 (0.01),W28:-1.69354 (0.01) | topTokens[('.', 335), ('the', 308), ('!', 262), ('?', 209), (',', 200), ('you', 127), ('to', 119), ('is', 117), ('i', 113), ('do', 85)] |  | babyLLM.py 2500
2025-04-10 22:06:08 | 22500 | LR0.0003 | loss:4.3096 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:5.4834 | logitMax:39.2102 | scheduledSampling:0.0002 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0006 | activationSparsity:0.0000 | windowStd:0.1764 | windowEntropy:1.3428 | topWindowWeight:0.5064 | effectiveWindowCount:3.8298 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0078 | memoryGateLong:0.0097 | memoryGateCurrent:-0.0015 | memoryGateMean:0.3333 | memoryGateStd:22.2605 | windowWeightsW2:2.11795 (0.51),W4:1.63545 (0.31),W8:-0.23980 (0.05),W12:-0.46551 (0.04),W16:-0.61848 (0.03),W32:-0.78274 (0.03),W20:-1.46419 (0.01),W24:-1.74476 (0.01),W28:-1.86140 (0.01) | topTokens[('.', 348), ('the', 342), ('!', 265), (',', 231), ('?', 209), ('to', 132), ('i', 130), ('you', 129), ('is', 118), ('a', 102)] | tokenPerfect: 7994 / 45000  17.76% | babyLLM.py 2500
2025-04-10 22:11:39 | 25000 | LR0.0003 | loss:2.7820 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:0.0810 | logitMax:35.5516 | scheduledSampling:0.0002 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0002 | activationSparsity:0.0000 | windowStd:0.1841 | windowEntropy:1.2530 | topWindowWeight:0.5105 | effectiveWindowCount:3.5008 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0075 | memoryGateLong:0.0097 | memoryGateCurrent:-0.0017 | memoryGateMean:0.3333 | memoryGateStd:21.8737 | windowWeightsW2:2.16209 (0.51),W4:1.76402 (0.34),W8:-0.33646 (0.04),W12:-0.65118 (0.03),W16:-0.82193 (0.03),W32:-1.00374 (0.02),W20:-1.67095 (0.01),W24:-1.95194 (0.01),W28:-2.07799 (0.01) | topTokens[('the', 369), ('.', 365), ('!', 265), (',', 254), ('?', 210), ('to', 144), ('i', 139), ('you', 129), ('is', 126), ('s', 108)] | tokenPerfect: 23540 / 90000  26.16% | babyLLM.py 2500
2025-04-10 22:17:07 | 27500 | LR0.0003 | loss:3.1173 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-18.8126 | logitMax:16.1250 | scheduledSampling:0.0003 | embedMean:-0.0000 | embedStd:0.0002 | meanActivation:0.0003 | activationSparsity:0.0000 | windowStd:0.1893 | windowEntropy:1.1985 | topWindowWeight:0.5233 | effectiveWindowCount:3.3151 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0105 | memoryGateLong:0.0128 | memoryGateCurrent:-0.0019 | memoryGateMean:0.3333 | memoryGateStd:29.3753 | windowWeightsW2:2.20912 (0.52),W4:1.79876 (0.35),W8:-0.36940 (0.04),W12:-0.73525 (0.03),W16:-0.94730 (0.02),W32:-1.17620 (0.02),W20:-1.82092 (0.01),W24:-2.11311 (0.01),W28:-2.24648 (0.01) | topTokens[('.', 378), ('the', 374), (',', 273), ('!', 272), ('?', 226), ('i', 157), ('to', 152), ('you', 134), ('is', 127), ('a', 115)] | tokenPerfect: 40096 / 135000  29.70% | babyLLM.py 2500
2025-04-10 22:22:41 | 30000 | LR0.0003 | loss:3.9343 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-0.9722 | logitMax:36.6434 | scheduledSampling:0.0003 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1905 | windowEntropy:1.1746 | topWindowWeight:0.5180 | effectiveWindowCount:3.2368 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0148 | memoryGateLong:0.0167 | memoryGateCurrent:-0.0016 | memoryGateMean:0.3333 | memoryGateStd:39.5897 | windowWeightsW2:2.20852 (0.52),W4:1.84713 (0.36),W8:-0.37416 (0.04),W12:-0.78778 (0.03),W16:-1.02874 (0.02),W32:-1.28161 (0.02),W20:-1.91584 (0.01),W24:-2.21741 (0.01),W28:-2.35159 (0.01) | topTokens[('.', 404), ('the', 387), (',', 300), ('!', 282), ('?', 233), ('to', 175), ('i', 171), ('you', 148), ('a', 134), (':', 133)] |  | babyLLM.py 2500
2025-04-10 22:28:03 | 32500 | LR0.0003 | loss:4.9843 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:12.0919 | logitMax:50.6375 | scheduledSampling:0.0003 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0003 | activationSparsity:0.0000 | windowStd:0.1919 | windowEntropy:1.1565 | topWindowWeight:0.5208 | effectiveWindowCount:3.1788 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0105 | memoryGateLong:0.0119 | memoryGateCurrent:-0.0010 | memoryGateMean:0.3333 | memoryGateStd:28.1841 | windowWeightsW2:2.21981 (0.52),W4:1.85819 (0.36),W8:-0.33405 (0.04),W12:-0.81857 (0.02),W16:-1.09546 (0.02),W32:-1.39177 (0.01),W20:-2.00561 (0.01),W24:-2.31928 (0.01),W28:-2.45571 (0.00) | topTokens[('.', 430), ('the', 398), (',', 333), ('!', 287), ('?', 235), ('i', 206), ('to', 189), ('you', 160), ('a', 159), (':', 144)] | tokenPerfect: 4133 / 45000  9.18% | babyLLM.py 2500
2025-04-10 22:33:26 | 35000 | LR0.0003 | loss:5.3044 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:31.7435 | logitMax:60.3549 | scheduledSampling:0.0003 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0003 | activationSparsity:0.0000 | windowStd:0.1956 | windowEntropy:1.1306 | topWindowWeight:0.5437 | effectiveWindowCount:3.0974 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0083 | memoryGateLong:0.0095 | memoryGateCurrent:-0.0007 | memoryGateMean:0.3333 | memoryGateStd:22.3046 | windowWeightsW2:2.27052 (0.54),W4:1.81363 (0.34),W8:-0.30017 (0.04),W12:-0.84468 (0.02),W16:-1.16210 (0.02),W32:-1.50759 (0.01),W20:-2.08933 (0.01),W24:-2.41823 (0.01),W28:-2.56625 (0.00) | topTokens[('.', 436), ('the', 413), (',', 402), ('!', 289), ('i', 243), ('?', 237), ('to', 198), ('a', 175), ('you', 162), (':', 148)] | tokenPerfect: 8798 / 90000  9.78% | babyLLM.py 2500
2025-04-10 22:38:51 | 37500 | LR0.0003 | loss:5.4483 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:49.1720 | logitMax:73.9258 | scheduledSampling:0.0004 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.1994 | windowEntropy:1.0909 | topWindowWeight:0.5568 | effectiveWindowCount:2.9770 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0070 | memoryGateLong:0.0081 | memoryGateCurrent:-0.0007 | memoryGateMean:0.3333 | memoryGateStd:18.9376 | windowWeightsW2:2.30885 (0.56),W4:1.82059 (0.34),W8:-0.31476 (0.04),W12:-0.93064 (0.02),W16:-1.29800 (0.02),W32:-1.66666 (0.01),W20:-2.23828 (0.01),W24:-2.56919 (0.00),W28:-2.72277 (0.00) | topTokens[(',', 472), ('.', 437), ('the', 431), ('!', 290), ('i', 276), ('?', 238), ('to', 209), ('a', 182), ('you', 165), ('is', 156)] | tokenPerfect: 11922 / 135000  8.83% | babyLLM.py 2500
2025-04-10 22:44:20 | 40000 | LR0.0003 | loss:5.3240 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:51.1106 | logitMax:74.7769 | scheduledSampling:0.0004 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0003 | activationSparsity:0.0000 | windowStd:0.2020 | windowEntropy:1.0623 | topWindowWeight:0.5649 | effectiveWindowCount:2.8931 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0062 | memoryGateLong:0.0073 | memoryGateCurrent:-0.0007 | memoryGateMean:0.3333 | memoryGateStd:16.9699 | windowWeightsW2:2.33296 (0.56),W4:1.82722 (0.34),W8:-0.31071 (0.04),W12:-0.99639 (0.02),W16:-1.40658 (0.01),W32:-1.82503 (0.01),W20:-2.36888 (0.01),W24:-2.71921 (0.00),W28:-2.87743 (0.00) | topTokens[(',', 538), ('.', 444), ('the', 439), ('i', 314), ('!', 290), ('?', 243), ('to', 218), ('a', 198), ('you', 177), ('is', 163)] |  | babyLLM.py 2500
2025-04-10 22:49:40 | 42500 | LR0.0003 | loss:5.1788 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:57.9385 | logitMax:82.2343 | scheduledSampling:0.0004 | embedMean:0.0000 | embedStd:0.0002 | meanActivation:0.0003 | activationSparsity:0.0000 | windowStd:0.2039 | windowEntropy:1.0355 | topWindowWeight:0.5678 | effectiveWindowCount:2.8166 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0064 | memoryGateLong:0.0075 | memoryGateCurrent:-0.0007 | memoryGateMean:0.3333 | memoryGateStd:17.5685 | windowWeightsW2:2.34679 (0.57),W4:1.84884 (0.35),W8:-0.31999 (0.04),W12:-1.08142 (0.02),W16:-1.53383 (0.01),W32:-1.98449 (0.01),W20:-2.51344 (0.00),W24:-2.87002 (0.00),W28:-3.03435 (0.00) | topTokens[(',', 606), ('.', 445), ('the', 445), ('i', 350), ('!', 290), ('?', 247), ('to', 228), ('a', 213), ('you', 185), ('is', 169)] | tokenPerfect: 4332 / 45000  9.63% | babyLLM.py 2500
2025-04-10 22:54:57 | 45000 | LR0.0003 | loss:5.1600 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:56.7667 | logitMax:80.0902 | scheduledSampling:0.0004 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0003 | activationSparsity:0.0000 | windowStd:0.2034 | windowEntropy:1.0186 | topWindowWeight:0.5536 | effectiveWindowCount:2.7692 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0062 | memoryGateLong:0.0074 | memoryGateCurrent:-0.0008 | memoryGateMean:0.3333 | memoryGateStd:17.1267 | windowWeightsW2:2.32458 (0.55),W4:1.91025 (0.37),W8:-0.33400 (0.04),W12:-1.17901 (0.02),W16:-1.66099 (0.01),W32:-2.15728 (0.01),W20:-2.66213 (0.00),W24:-3.02525 (0.00),W28:-3.19490 (0.00) | topTokens[(',', 673), ('the', 451), ('.', 449), ('i', 380), ('!', 290), ('?', 256), ('to', 240), ('a', 226), ('you', 194), ('is', 176)] | tokenPerfect: 8856 / 90000  9.84% | babyLLM.py 2500
2025-04-10 23:00:19 | 47500 | LR0.0003 | loss:5.2629 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:71.6698 | logitMax:95.7294 | scheduledSampling:0.0005 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2038 | windowEntropy:1.0022 | topWindowWeight:0.5478 | effectiveWindowCount:2.7243 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0064 | memoryGateLong:0.0075 | memoryGateCurrent:-0.0007 | memoryGateMean:0.3333 | memoryGateStd:17.5400 | windowWeightsW2:2.31799 (0.55),W4:1.94181 (0.38),W8:-0.31958 (0.04),W12:-1.25512 (0.02),W16:-1.78797 (0.01),W32:-2.34010 (0.01),W20:-2.81324 (0.00),W24:-3.19194 (0.00),W28:-3.36857 (0.00) | topTokens[(',', 749), ('the', 463), ('.', 452), ('i', 405), ('!', 290), ('?', 260), ('to', 251), ('a', 234), ('you', 200), ('is', 184)] | tokenPerfect: 13420 / 135000  9.94% | babyLLM.py 2500
2025-04-10 23:05:48 | 50000 | LR0.0003 | loss:4.1968 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:70.7814 | logitMax:100.4122 | scheduledSampling:0.0005 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2083 | windowEntropy:0.9560 | topWindowWeight:0.5663 | effectiveWindowCount:2.6013 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0088 | memoryGateLong:0.0107 | memoryGateCurrent:-0.0015 | memoryGateMean:0.3333 | memoryGateStd:24.5819 | windowWeightsW2:2.37064 (0.57),W4:1.94145 (0.37),W8:-0.39388 (0.04),W12:-1.42743 (0.01),W16:-1.99013 (0.01),W32:-2.63818 (0.00),W20:-3.04227 (0.00),W24:-3.44141 (0.00),W28:-3.64530 (0.00) | topTokens[(',', 817), ('the', 481), ('.', 476), ('i', 420), ('!', 304), ('to', 263), ('?', 262), ('a', 247), ('you', 208), ('s', 191)] |  | babyLLM.py 2500
2025-04-10 23:11:05 | 52500 | LR0.0003 | loss:4.6999 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:58.8829 | logitMax:85.2948 | scheduledSampling:0.0005 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0002 | activationSparsity:0.0000 | windowStd:0.2070 | windowEntropy:0.9563 | topWindowWeight:0.5559 | effectiveWindowCount:2.6022 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0071 | memoryGateLong:0.0083 | memoryGateCurrent:-0.0008 | memoryGateMean:0.3333 | memoryGateStd:19.3095 | windowWeightsW2:2.35099 (0.56),W4:1.96711 (0.38),W8:-0.32092 (0.04),W12:-1.45536 (0.01),W16:-2.07348 (0.01),W32:-2.81901 (0.00),W20:-3.16120 (0.00),W24:-3.58816 (0.00),W28:-3.81542 (0.00) | topTokens[(',', 882), ('the', 507), ('.', 484), ('i', 420), ('!', 308), ('to', 275), ('a', 264), ('?', 264), ('you', 208), ('and', 202)] | tokenPerfect: 6383 / 45000  14.18% | babyLLM.py 2500
2025-04-10 23:16:21 | 55000 | LR0.0003 | loss:4.0063 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:87.4198 | logitMax:115.4798 | scheduledSampling:0.0005 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2089 | windowEntropy:0.9330 | topWindowWeight:0.5615 | effectiveWindowCount:2.5421 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0063 | memoryGateLong:0.0079 | memoryGateCurrent:-0.0012 | memoryGateMean:0.3333 | memoryGateStd:17.9072 | windowWeightsW2:2.36830 (0.56),W4:1.97504 (0.38),W8:-0.36457 (0.04),W12:-1.57959 (0.01),W16:-2.22846 (0.01),W32:-3.01174 (0.00),W20:-3.33209 (0.00),W24:-3.76691 (0.00),W28:-4.00388 (0.00) | topTokens[(',', 930), ('the', 531), ('.', 501), ('i', 423), ('!', 346), ('to', 290), ('a', 276), ('?', 264), ('you', 219), ('and', 217)] | tokenPerfect: 15827 / 90000  17.59% | babyLLM.py 2500
2025-04-10 23:21:38 | 57500 | LR0.0003 | loss:2.0544 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:116.0643 | logitMax:150.1370 | scheduledSampling:0.0006 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2098 | windowEntropy:0.9255 | topWindowWeight:0.5671 | effectiveWindowCount:2.5231 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0076 | memoryGateLong:0.0093 | memoryGateCurrent:-0.0013 | memoryGateMean:0.3333 | memoryGateStd:21.4015 | windowWeightsW2:2.38015 (0.57),W4:1.96413 (0.37),W8:-0.35242 (0.04),W12:-1.60335 (0.01),W16:-2.29614 (0.01),W32:-3.12285 (0.00),W20:-3.42357 (0.00),W24:-3.86137 (0.00),W28:-4.10751 (0.00) | topTokens[(',', 964), ('the', 568), ('.', 533), ('i', 426), ('!', 412), ('to', 301), ('a', 279), ('?', 264), ('and', 234), ('you', 229)] | tokenPerfect: 33977 / 135000  25.17% | babyLLM.py 2500
2025-04-10 23:27:01 | 60000 | LR0.0003 | loss:1.9757 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:102.4985 | logitMax:139.0900 | scheduledSampling:0.0006 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2112 | windowEntropy:0.9147 | topWindowWeight:0.5761 | effectiveWindowCount:2.4961 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0083 | memoryGateLong:0.0103 | memoryGateCurrent:-0.0016 | memoryGateMean:0.3333 | memoryGateStd:23.5369 | windowWeightsW2:2.39907 (0.58),W4:1.94775 (0.37),W8:-0.35823 (0.04),W12:-1.65205 (0.01),W16:-2.35893 (0.00),W32:-3.21816 (0.00),W20:-3.49174 (0.00),W24:-3.94354 (0.00),W28:-4.19577 (0.00) | topTokens[(',', 1011), ('the', 594), ('.', 560), ('!', 481), ('i', 438), ('would', 315), ('to', 306), ('a', 280), ('?', 264), ('and', 250)] |  | babyLLM.py 2500
2025-04-10 23:32:23 | 62500 | LR0.0003 | loss:1.9893 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:101.4781 | logitMax:139.6369 | scheduledSampling:0.0006 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2105 | windowEntropy:0.9132 | topWindowWeight:0.5690 | effectiveWindowCount:2.4923 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0068 | memoryGateLong:0.0084 | memoryGateCurrent:-0.0012 | memoryGateMean:0.3333 | memoryGateStd:19.2546 | windowWeightsW2:2.38355 (0.57),W4:1.96529 (0.37),W8:-0.33692 (0.04),W12:-1.70287 (0.01),W16:-2.44343 (0.00),W32:-3.35163 (0.00),W20:-3.59574 (0.00),W24:-4.05278 (0.00),W28:-4.31773 (0.00) | topTokens[(',', 1045), ('the', 634), ('.', 591), ('!', 549), ('i', 443), ('would', 440), ('to', 316), ('a', 280), ('you', 266), ('?', 265)] | tokenPerfect: 18056 / 45000  40.12% | babyLLM.py 2500
2025-04-10 23:37:42 | 65000 | LR0.0003 | loss:1.8937 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:91.5582 | logitMax:132.6003 | scheduledSampling:0.0006 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2112 | windowEntropy:0.9047 | topWindowWeight:0.5716 | effectiveWindowCount:2.4712 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0085 | memoryGateLong:0.0104 | memoryGateCurrent:-0.0015 | memoryGateMean:0.3333 | memoryGateStd:23.8570 | windowWeightsW2:2.38855 (0.57),W4:1.96469 (0.37),W8:-0.36541 (0.04),W12:-1.73787 (0.01),W16:-2.50536 (0.00),W32:-3.45321 (0.00),W20:-3.68279 (0.00),W24:-4.14064 (0.00),W28:-4.41143 (0.00) | topTokens[(',', 1087), ('the', 661), ('!', 611), ('.', 608), ('would', 565), ('i', 451), ('to', 328), ('you', 285), ('a', 282), ('and', 280)] | tokenPerfect: 37280 / 90000  41.42% | babyLLM.py 2500
2025-04-10 23:43:03 | 67500 | LR0.0003 | loss:1.8284 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:94.5511 | logitMax:136.1254 | scheduledSampling:0.0007 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2118 | windowEntropy:0.8973 | topWindowWeight:0.5727 | effectiveWindowCount:2.4530 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0092 | memoryGateLong:0.0113 | memoryGateCurrent:-0.0017 | memoryGateMean:0.3333 | memoryGateStd:25.8534 | windowWeightsW2:2.39047 (0.57),W4:1.96684 (0.37),W8:-0.39280 (0.04),W12:-1.78201 (0.01),W16:-2.56545 (0.00),W32:-3.54115 (0.00),W20:-3.74940 (0.00),W24:-4.22580 (0.00),W28:-4.49504 (0.00) | topTokens[(',', 1128), ('the', 691), ('would', 690), ('!', 675), ('.', 625), ('i', 456), ('to', 339), ('you', 301), ('and', 300), ('a', 283)] | tokenPerfect: 56690 / 135000  41.99% | babyLLM.py 2500
2025-04-10 23:48:32 | 70000 | LR0.0003 | loss:1.8325 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:83.5642 | logitMax:127.0715 | scheduledSampling:0.0007 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2125 | windowEntropy:0.8912 | topWindowWeight:0.5776 | effectiveWindowCount:2.4381 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0093 | memoryGateLong:0.0113 | memoryGateCurrent:-0.0016 | memoryGateMean:0.3333 | memoryGateStd:26.0454 | windowWeightsW2:2.39976 (0.58),W4:1.95701 (0.37),W8:-0.39414 (0.04),W12:-1.82185 (0.01),W16:-2.61383 (0.00),W32:-3.61242 (0.00),W20:-3.81204 (0.00),W24:-4.29217 (0.00),W28:-4.56420 (0.00) | topTokens[(',', 1158), ('would', 823), ('!', 743), ('the', 725), ('.', 653), ('i', 462), ('to', 351), ('you', 322), ('and', 312), ('charis', 289)] |  | babyLLM.py 2500
2025-04-10 23:53:56 | 72500 | LR0.0003 | loss:2.8964 | gradNorm:0.9998 | tokenCount:45000.0000 | logitMin:59.6427 | logitMax:102.8758 | scheduledSampling:0.0007 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0002 | activationSparsity:0.0000 | windowStd:0.2113 | windowEntropy:0.8938 | topWindowWeight:0.5666 | effectiveWindowCount:2.4444 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0116 | memoryGateLong:0.0137 | memoryGateCurrent:-0.0016 | memoryGateMean:0.3333 | memoryGateStd:31.8730 | windowWeightsW2:2.37553 (0.57),W4:1.98156 (0.38),W8:-0.38332 (0.04),W12:-1.85527 (0.01),W16:-2.67138 (0.00),W32:-3.69452 (0.00),W20:-3.88209 (0.00),W24:-4.35764 (0.00),W28:-4.64895 (0.00) | topTokens[(',', 1193), ('would', 863), ('!', 811), ('the', 765), ('.', 674), ('i', 472), ('to', 361), ('you', 354), ('and', 324), ('charis', 321)] | tokenPerfect: 15938 / 45000  35.42% | babyLLM.py 2500
2025-04-10 23:59:21 | 75000 | LR0.0003 | loss:7.0103 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:20.2635 | logitMax:59.4569 | scheduledSampling:0.0007 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.2094 | windowEntropy:0.8987 | topWindowWeight:0.5474 | effectiveWindowCount:2.4563 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0066 | memoryGateLong:0.0077 | memoryGateCurrent:-0.0007 | memoryGateMean:0.3333 | memoryGateStd:18.0014 | windowWeightsW2:2.33553 (0.55),W4:2.02461 (0.40),W8:-0.36390 (0.04),W12:-1.89589 (0.01),W16:-2.73842 (0.00),W32:-3.80513 (0.00),W20:-3.96508 (0.00),W24:-4.45109 (0.00),W28:-4.75359 (0.00) | topTokens[(',', 1211), ('would', 865), ('!', 819), ('the', 778), ('.', 734), ('i', 512), ('you', 384), ('to', 377), ('and', 352), ('charis', 339)] | tokenPerfect: 20049 / 90000  22.28% | babyLLM.py 2500
2025-04-11 00:04:44 | 77500 | LR0.0003 | loss:5.5161 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:56.5981 | logitMax:84.1265 | scheduledSampling:0.0008 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0002 | activationSparsity:0.0000 | windowStd:0.2100 | windowEntropy:0.8942 | topWindowWeight:0.5528 | effectiveWindowCount:2.4453 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0068 | memoryGateLong:0.0080 | memoryGateCurrent:-0.0007 | memoryGateMean:0.3333 | memoryGateStd:18.5759 | windowWeightsW2:2.34555 (0.55),W4:2.01153 (0.40),W8:-0.34176 (0.04),W12:-1.93277 (0.01),W16:-2.82083 (0.00),W32:-3.93350 (0.00),W20:-4.06879 (0.00),W24:-4.57015 (0.00),W28:-4.87942 (0.00) | topTokens[(',', 1225), ('would', 865), ('!', 825), ('the', 794), ('.', 788), ('i', 544), ('you', 404), ('to', 390), ('and', 360), ('charis', 343)] | tokenPerfect: 24469 / 135000  18.13% | babyLLM.py 2500
2025-04-11 00:10:13 | 80000 | LR0.0003 | loss:5.2302 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:66.0653 | logitMax:91.8563 | scheduledSampling:0.0008 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2093 | windowEntropy:0.8901 | topWindowWeight:0.5397 | effectiveWindowCount:2.4354 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0070 | memoryGateLong:0.0082 | memoryGateCurrent:-0.0008 | memoryGateMean:0.3333 | memoryGateStd:19.0047 | windowWeightsW2:2.32007 (0.54),W4:2.04727 (0.41),W8:-0.35546 (0.04),W12:-2.02232 (0.01),W16:-2.94710 (0.00),W32:-4.08913 (0.00),W20:-4.21099 (0.00),W24:-4.72005 (0.00),W28:-5.03335 (0.00) | topTokens[(',', 1241), ('would', 867), ('.', 847), ('!', 828), ('the', 805), ('i', 594), ('you', 419), ('to', 406), ('and', 376), ('charis', 343)] |  | babyLLM.py 2500
2025-04-11 00:15:36 | 82500 | LR0.0003 | loss:5.9643 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:24.8197 | logitMax:54.8427 | scheduledSampling:0.0008 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2093 | windowEntropy:0.8834 | topWindowWeight:0.5337 | effectiveWindowCount:2.4190 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0071 | memoryGateLong:0.0085 | memoryGateCurrent:-0.0009 | memoryGateMean:0.3333 | memoryGateStd:19.6508 | windowWeightsW2:2.30806 (0.53),W4:2.06580 (0.42),W8:-0.37585 (0.04),W12:-2.12436 (0.01),W16:-3.06640 (0.00),W32:-4.24482 (0.00),W20:-4.34466 (0.00),W24:-4.86648 (0.00),W28:-5.18473 (0.00) | topTokens[(',', 1256), ('.', 889), ('would', 868), ('!', 832), ('the', 820), ('i', 624), ('you', 428), ('to', 417), ('and', 392), ('charis', 343)] | tokenPerfect: 5222 / 45000  11.60% | babyLLM.py 2500
2025-04-11 00:20:56 | 85000 | LR0.0003 | loss:4.9950 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:77.6589 | logitMax:104.3337 | scheduledSampling:0.0008 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2117 | windowEntropy:0.8683 | topWindowWeight:0.5565 | effectiveWindowCount:2.3828 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0063 | memoryGateLong:0.0076 | memoryGateCurrent:-0.0010 | memoryGateMean:0.3333 | memoryGateStd:17.5411 | windowWeightsW2:2.35478 (0.56),W4:2.02034 (0.40),W8:-0.40063 (0.04),W12:-2.21616 (0.01),W16:-3.19203 (0.00),W32:-4.39093 (0.00),W20:-4.47785 (0.00),W24:-4.99729 (0.00),W28:-5.32450 (0.00) | topTokens[(',', 1267), ('.', 952), ('would', 875), ('!', 840), ('the', 831), ('i', 679), ('you', 439), ('to', 434), ('and', 404), ('charis', 344)] | tokenPerfect: 10401 / 90000  11.56% | babyLLM.py 2500
2025-04-11 00:26:16 | 87500 | LR0.0003 | loss:3.3497 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:92.7789 | logitMax:126.2422 | scheduledSampling:0.0009 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2139 | windowEntropy:0.8493 | topWindowWeight:0.5699 | effectiveWindowCount:2.3381 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0063 | memoryGateLong:0.0083 | memoryGateCurrent:-0.0016 | memoryGateMean:0.3333 | memoryGateStd:18.6085 | windowWeightsW2:2.38306 (0.57),W4:2.00161 (0.39),W8:-0.47639 (0.03),W12:-2.35779 (0.00),W16:-3.35850 (0.00),W32:-4.59738 (0.00),W20:-4.66085 (0.00),W24:-5.18843 (0.00),W28:-5.52164 (0.00) | topTokens[(',', 1291), ('.', 986), ('!', 880), ('would', 877), ('the', 851), ('i', 694), ('you', 451), ('to', 445), ('and', 429), ('charis', 365)] | tokenPerfect: 23244 / 135000  17.22% | babyLLM.py 2500
2025-04-11 00:31:44 | 90000 | LR0.0003 | loss:1.9752 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:97.2939 | logitMax:137.2339 | scheduledSampling:0.0009 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2123 | windowEntropy:0.8514 | topWindowWeight:0.5490 | effectiveWindowCount:2.3429 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0092 | memoryGateLong:0.0117 | memoryGateCurrent:-0.0021 | memoryGateMean:0.3333 | memoryGateStd:26.6409 | windowWeightsW2:2.33979 (0.55),W4:2.05083 (0.41),W8:-0.50448 (0.03),W12:-2.42213 (0.00),W16:-3.45597 (0.00),W32:-4.71619 (0.00),W20:-4.75315 (0.00),W24:-5.29280 (0.00),W28:-5.63286 (0.00) | topTokens[(',', 1337), ('.', 1006), ('!', 941), ('would', 877), ('the', 871), ('i', 701), ('you', 469), ('to', 449), ('and', 448), ('charis', 399)] |  | babyLLM.py 2500
2025-04-11 00:37:08 | 92500 | LR0.0003 | loss:1.8589 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:88.1413 | logitMax:130.1878 | scheduledSampling:0.0009 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.2128 | windowEntropy:0.8443 | topWindowWeight:0.5495 | effectiveWindowCount:2.3263 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0097 | memoryGateLong:0.0122 | memoryGateCurrent:-0.0021 | memoryGateMean:0.3333 | memoryGateStd:27.8926 | windowWeightsW2:2.34021 (0.55),W4:2.05489 (0.41),W8:-0.56284 (0.03),W12:-2.46353 (0.00),W16:-3.52630 (0.00),W32:-4.81953 (0.00),W20:-4.84253 (0.00),W24:-5.38604 (0.00),W28:-5.72921 (0.00) | topTokens[(',', 1377), ('.', 1026), ('!', 1003), ('the', 909), ('would', 877), ('i', 707), ('you', 489), ('and', 460), ('to', 455), ('charis', 444)] | tokenPerfect: 19143 / 45000  42.54% | babyLLM.py 2500
2025-04-11 00:42:55 | 95000 | LR0.0003 | loss:1.9083 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:85.8163 | logitMax:128.0335 | scheduledSampling:0.0009 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2140 | windowEntropy:0.8357 | topWindowWeight:0.5584 | effectiveWindowCount:2.3065 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0084 | memoryGateLong:0.0107 | memoryGateCurrent:-0.0018 | memoryGateMean:0.3333 | memoryGateStd:24.2851 | windowWeightsW2:2.35738 (0.56),W4:2.03821 (0.41),W8:-0.60651 (0.03),W12:-2.51124 (0.00),W16:-3.59893 (0.00),W32:-4.91271 (0.00),W20:-4.92374 (0.00),W24:-5.47201 (0.00),W28:-5.81605 (0.00) | topTokens[(',', 1411), ('!', 1066), ('.', 1059), ('the', 940), ('would', 877), ('i', 711), ('you', 508), ('can', 489), ('and', 471), ('charis', 470)] | tokenPerfect: 38580 / 90000  42.87% | babyLLM.py 2500
2025-04-11 00:48:26 | 97500 | LR0.0003 | loss:1.8560 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:80.1594 | logitMax:123.4501 | scheduledSampling:0.0010 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2137 | windowEntropy:0.8319 | topWindowWeight:0.5507 | effectiveWindowCount:2.2976 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0149 | memoryGateLong:0.0188 | memoryGateCurrent:-0.0036 | memoryGateMean:0.3333 | memoryGateStd:42.8822 | windowWeightsW2:2.34076 (0.55),W4:2.05856 (0.42),W8:-0.64440 (0.03),W12:-2.60495 (0.00),W16:-3.71030 (0.00),W20:-5.04034 (0.00),W32:-5.04584 (0.00),W24:-5.59898 (0.00),W28:-5.94379 (0.00) | topTokens[(',', 1457), ('!', 1127), ('.', 1082), ('the', 972), ('would', 877), ('i', 714), ('can', 608), ('you', 527), ('charis', 509), ('and', 489)] | tokenPerfect: 58100 / 135000  43.04% | babyLLM.py 2500
2025-04-11 00:54:02 | 100000 | LR0.0003 | loss:1.8845 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:70.2591 | logitMax:114.7809 | scheduledSampling:0.0010 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.2137 | windowEntropy:0.8313 | topWindowWeight:0.5509 | effectiveWindowCount:2.2963 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0095 | memoryGateLong:0.0120 | memoryGateCurrent:-0.0021 | memoryGateMean:0.3333 | memoryGateStd:27.3588 | windowWeightsW2:2.33997 (0.55),W4:2.05668 (0.42),W8:-0.64068 (0.03),W12:-2.61990 (0.00),W16:-3.74424 (0.00),W20:-5.08711 (0.00),W32:-5.10403 (0.00),W24:-5.64580 (0.00),W28:-5.99643 (0.00) | topTokens[(',', 1499), ('!', 1192), ('.', 1106), ('the', 1011), ('would', 877), ('can', 728), ('i', 723), ('you', 546), ('charis', 539), ('and', 500)] |  | babyLLM.py 2500
2025-04-11 00:59:31 | 102500 | LR0.0003 | loss:1.8263 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:64.7695 | logitMax:110.6223 | scheduledSampling:0.0010 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.2139 | windowEntropy:0.8276 | topWindowWeight:0.5493 | effectiveWindowCount:2.2879 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0102 | memoryGateLong:0.0130 | memoryGateCurrent:-0.0024 | memoryGateMean:0.3333 | memoryGateStd:29.4425 | windowWeightsW2:2.33564 (0.55),W4:2.06231 (0.42),W8:-0.67524 (0.03),W12:-2.66283 (0.00),W16:-3.79650 (0.00),W20:-5.15782 (0.00),W32:-5.19448 (0.00),W24:-5.72639 (0.00),W28:-6.07866 (0.00) | topTokens[(',', 1541), ('!', 1247), ('.', 1131), ('the', 1043), ('would', 878), ('can', 855), ('i', 735), ('charis', 574), ('you', 557), ('and', 517)] | tokenPerfect: 19341 / 45000  42.98% | babyLLM.py 2500
2025-04-11 01:05:01 | 105000 | LR0.0003 | loss:2.0214 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:49.8593 | logitMax:95.1225 | scheduledSampling:0.0010 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2144 | windowEntropy:0.8226 | topWindowWeight:0.5532 | effectiveWindowCount:2.2765 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0103 | memoryGateLong:0.0128 | memoryGateCurrent:-0.0022 | memoryGateMean:0.3333 | memoryGateStd:29.2811 | windowWeightsW2:2.34268 (0.55),W4:2.05550 (0.42),W8:-0.70711 (0.03),W12:-2.69711 (0.00),W16:-3.86053 (0.00),W20:-5.23038 (0.00),W32:-5.28503 (0.00),W24:-5.80979 (0.00),W28:-6.16261 (0.00) | topTokens[(',', 1574), ('!', 1307), ('.', 1158), ('the', 1067), ('can', 922), ('would', 878), ('i', 745), ('charis', 601), ('you', 577), ('elodie', 529)] | tokenPerfect: 39257 / 90000  43.62% | babyLLM.py 2500
2025-04-11 01:10:35 | 107500 | LR0.0003 | loss:1.6817 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:48.7530 | logitMax:92.1971 | scheduledSampling:0.0011 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2160 | windowEntropy:0.8162 | topWindowWeight:0.5694 | effectiveWindowCount:2.2620 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0126 | memoryGateLong:0.0152 | memoryGateCurrent:-0.0022 | memoryGateMean:0.3333 | memoryGateStd:35.1227 | windowWeightsW2:2.37390 (0.57),W4:2.01884 (0.40),W8:-0.71159 (0.03),W12:-2.70982 (0.00),W16:-3.88833 (0.00),W20:-5.26658 (0.00),W32:-5.33466 (0.00),W24:-5.85218 (0.00),W28:-6.21087 (0.00) | topTokens[(',', 1621), ('!', 1353), ('.', 1173), ('the', 1096), ('can', 923), ('would', 878), ('i', 751), ('charis', 637), ('you', 589), ('elodie', 559)] | tokenPerfect: 61489 / 135000  45.55% | babyLLM.py 2500
2025-04-11 01:16:14 | 110000 | LR0.0003 | loss:1.5947 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:44.8369 | logitMax:88.4327 | scheduledSampling:0.0011 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2184 | windowEntropy:0.8046 | topWindowWeight:0.5892 | effectiveWindowCount:2.2358 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0085 | memoryGateLong:0.0105 | memoryGateCurrent:-0.0016 | memoryGateMean:0.3333 | memoryGateStd:24.0609 | windowWeightsW2:2.41365 (0.59),W4:1.97641 (0.38),W8:-0.74096 (0.03),W12:-2.74924 (0.00),W16:-3.92555 (0.00),W20:-5.31335 (0.00),W32:-5.39410 (0.00),W24:-5.90567 (0.00),W28:-6.26596 (0.00) | topTokens[(',', 1666), ('!', 1384), ('.', 1198), ('the', 1112), ('can', 923), ('would', 878), ('i', 758), ('charis', 677), ('you', 606), ('elodie', 590)] |  | babyLLM.py 2500
2025-04-11 01:21:49 | 112500 | LR0.0003 | loss:1.5669 | gradNorm:0.9997 | tokenCount:45000.0000 | logitMin:44.9052 | logitMax:89.7245 | scheduledSampling:0.0011 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:-0.0002 | activationSparsity:0.0000 | windowStd:0.2176 | windowEntropy:0.8067 | topWindowWeight:0.5824 | effectiveWindowCount:2.2406 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0103 | memoryGateLong:0.0123 | memoryGateCurrent:-0.0016 | memoryGateMean:0.3333 | memoryGateStd:28.4808 | windowWeightsW2:2.39810 (0.58),W4:1.99055 (0.39),W8:-0.75151 (0.02),W12:-2.74782 (0.00),W16:-3.95924 (0.00),W20:-5.34175 (0.00),W32:-5.43711 (0.00),W24:-5.94845 (0.00),W28:-6.30803 (0.00) | topTokens[(',', 1709), ('!', 1420), ('.', 1215), ('the', 1134), ('can', 923), ('would', 878), ('i', 769), ('charis', 723), ('you', 623), ('elodie', 611)] | tokenPerfect: 23105 / 45000  51.34% | babyLLM.py 2500
2025-04-11 01:27:22 | 115000 | LR0.0003 | loss:1.5771 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:41.6779 | logitMax:87.3800 | scheduledSampling:0.0011 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2176 | windowEntropy:0.8049 | topWindowWeight:0.5812 | effectiveWindowCount:2.2365 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0263 | memoryGateLong:0.0308 | memoryGateCurrent:-0.0042 | memoryGateMean:0.3333 | memoryGateStd:71.9432 | windowWeightsW2:2.39395 (0.58),W4:1.99365 (0.39),W8:-0.77654 (0.02),W12:-2.76915 (0.00),W16:-3.99994 (0.00),W20:-5.37723 (0.00),W32:-5.49528 (0.00),W24:-5.99928 (0.00),W28:-6.35998 (0.00) | topTokens[(',', 1753), ('!', 1455), ('.', 1230), ('the', 1161), ('can', 923), ('would', 878), ('i', 778), ('charis', 756), ('elodie', 637), ('you', 626)] | tokenPerfect: 46192 / 90000  51.32% | babyLLM.py 2500
2025-04-11 01:32:48 | 117500 | LR0.0003 | loss:1.5488 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:41.5890 | logitMax:87.9902 | scheduledSampling:0.0012 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.2180 | windowEntropy:0.8002 | topWindowWeight:0.5816 | effectiveWindowCount:2.2261 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0104 | memoryGateLong:0.0124 | memoryGateCurrent:-0.0016 | memoryGateMean:0.3333 | memoryGateStd:28.7402 | windowWeightsW2:2.39366 (0.58),W4:1.99478 (0.39),W8:-0.82059 (0.02),W12:-2.82721 (0.00),W16:-4.06888 (0.00),W20:-5.44564 (0.00),W32:-5.56783 (0.00),W24:-6.06076 (0.00),W28:-6.42623 (0.00) | topTokens[(',', 1795), ('!', 1500), ('.', 1249), ('the', 1189), ('can', 923), ('would', 878), ('i', 787), ('charis', 780), ('elodie', 671), ('you', 637)] | tokenPerfect: 69441 / 135000  51.44% | babyLLM.py 2500
2025-04-11 01:38:26 | 120000 | LR0.0003 | loss:1.4828 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:42.0705 | logitMax:88.8207 | scheduledSampling:0.0012 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2189 | windowEntropy:0.7943 | topWindowWeight:0.5879 | effectiveWindowCount:2.2129 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0107 | memoryGateLong:0.0128 | memoryGateCurrent:-0.0017 | memoryGateMean:0.3333 | memoryGateStd:29.5958 | windowWeightsW2:2.40545 (0.59),W4:1.98219 (0.39),W8:-0.85398 (0.02),W12:-2.86112 (0.00),W16:-4.12161 (0.00),W20:-5.49319 (0.00),W32:-5.63413 (0.00),W24:-6.12222 (0.00),W28:-6.48272 (0.00) | topTokens[(',', 1840), ('!', 1549), ('.', 1262), ('the', 1220), ('can', 923), ('would', 878), ('charis', 806), ('i', 800), ('been', 708), ('elodie', 700)] |  | babyLLM.py 2500
2025-04-11 01:43:50 | 122500 | LR0.0003 | loss:2.0192 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:15.7987 | logitMax:65.9600 | scheduledSampling:0.0012 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0002 | activationSparsity:0.0000 | windowStd:0.2213 | windowEntropy:0.7806 | topWindowWeight:0.6042 | effectiveWindowCount:2.1829 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0138 | memoryGateLong:0.0167 | memoryGateCurrent:-0.0025 | memoryGateMean:0.3333 | memoryGateStd:38.5945 | windowWeightsW2:2.43876 (0.60),W4:1.94970 (0.37),W8:-0.91241 (0.02),W12:-2.94400 (0.00),W16:-4.20953 (0.00),W20:-5.59071 (0.00),W32:-5.75016 (0.00),W24:-6.23285 (0.00),W28:-6.59378 (0.00) | topTokens[(',', 1875), ('!', 1596), ('.', 1303), ('the', 1246), ('can', 924), ('would', 878), ('charis', 833), ('i', 808), ('been', 742), ('elodie', 720)] | tokenPerfect: 19521 / 45000  43.38% | babyLLM.py 2500
2025-04-11 01:49:20 | 125000 | LR0.0003 | loss:3.7272 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:9.0953 | logitMax:55.2550 | scheduledSampling:0.0012 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2183 | windowEntropy:0.7928 | topWindowWeight:0.5802 | effectiveWindowCount:2.2095 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0077 | memoryGateLong:0.0084 | memoryGateCurrent:-0.0003 | memoryGateMean:0.3333 | memoryGateStd:20.1016 | windowWeightsW2:2.38714 (0.58),W4:2.00015 (0.39),W8:-0.89550 (0.02),W12:-2.95204 (0.00),W16:-4.23473 (0.00),W20:-5.61604 (0.00),W32:-5.79406 (0.00),W24:-6.26857 (0.00),W28:-6.63218 (0.00) | topTokens[(',', 1930), ('!', 1650), ('.', 1327), ('the', 1280), ('can', 925), ('would', 878), ('charis', 868), ('i', 830), ('elodie', 760), ('been', 743)] | tokenPerfect: 33417 / 90000  37.13% | babyLLM.py 2500
2025-04-11 01:54:46 | 127500 | LR0.0003 | loss:6.1547 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-0.0190 | logitMax:29.9771 | scheduledSampling:0.0013 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0002 | activationSparsity:0.0000 | windowStd:0.2181 | windowEntropy:0.7932 | topWindowWeight:0.5781 | effectiveWindowCount:2.2104 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0075 | memoryGateLong:0.0084 | memoryGateCurrent:-0.0005 | memoryGateMean:0.3333 | memoryGateStd:19.9578 | windowWeightsW2:2.38141 (0.58),W4:2.00312 (0.40),W8:-0.88960 (0.02),W12:-2.97811 (0.00),W16:-4.28890 (0.00),W20:-5.68505 (0.00),W32:-5.88580 (0.00),W24:-6.34451 (0.00),W28:-6.71780 (0.00) | topTokens[(',', 2015), ('!', 1655), ('.', 1331), ('the', 1295), ('can', 925), ('would', 878), ('charis', 876), ('i', 858), ('elodie', 771), ('been', 743)] | tokenPerfect: 36708 / 135000  27.19% | babyLLM.py 2500
2025-04-11 02:00:51 | 130000 | LR0.0003 | loss:5.3941 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-0.3398 | logitMax:27.0681 | scheduledSampling:0.0013 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.2194 | windowEntropy:0.7863 | topWindowWeight:0.5890 | effectiveWindowCount:2.1953 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0075 | memoryGateLong:0.0086 | memoryGateCurrent:-0.0008 | memoryGateMean:0.3333 | memoryGateStd:20.2254 | windowWeightsW2:2.40270 (0.59),W4:1.97905 (0.39),W8:-0.89086 (0.02),W12:-3.06035 (0.00),W16:-4.41331 (0.00),W20:-5.82970 (0.00),W32:-6.05280 (0.00),W24:-6.50042 (0.00),W28:-6.87962 (0.00) | topTokens[(',', 2090), ('!', 1657), ('.', 1336), ('the', 1302), ('can', 925), ('i', 896), ('charis', 878), ('would', 878), ('elodie', 771), ('been', 747)] |  | babyLLM.py 2500
2025-04-11 02:06:23 | 132500 | LR0.0003 | loss:5.1744 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:0.4464 | logitMax:27.2761 | scheduledSampling:0.0013 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0002 | activationSparsity:0.0000 | windowStd:0.2216 | windowEntropy:0.7764 | topWindowWeight:0.6068 | effectiveWindowCount:2.1736 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0066 | memoryGateLong:0.0077 | memoryGateCurrent:-0.0007 | memoryGateMean:0.3333 | memoryGateStd:17.9857 | windowWeightsW2:2.43804 (0.61),W4:1.93816 (0.37),W8:-0.88100 (0.02),W12:-3.13862 (0.00),W16:-4.53040 (0.00),W20:-5.97290 (0.00),W32:-6.21324 (0.00),W24:-6.64959 (0.00),W28:-7.03179 (0.00) | topTokens[(',', 2173), ('!', 1660), ('.', 1336), ('the', 1315), ('i', 936), ('can', 935), ('charis', 878), ('would', 878), ('elodie', 771), ('been', 747)] | tokenPerfect: 4703 / 45000  10.45% | babyLLM.py 2500
2025-04-11 02:12:04 | 135000 | LR0.0003 | loss:5.3110 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:0.1674 | logitMax:26.0094 | scheduledSampling:0.0013 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2197 | windowEntropy:0.7841 | topWindowWeight:0.5925 | effectiveWindowCount:2.1905 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0067 | memoryGateLong:0.0079 | memoryGateCurrent:-0.0008 | memoryGateMean:0.3333 | memoryGateStd:18.3818 | windowWeightsW2:2.40667 (0.59),W4:1.96705 (0.38),W8:-0.84788 (0.02),W12:-3.21099 (0.00),W16:-4.64866 (0.00),W20:-6.11080 (0.00),W32:-6.38313 (0.00),W24:-6.80272 (0.00),W28:-7.19228 (0.00) | topTokens[(',', 2277), ('!', 1661), ('.', 1339), ('the', 1331), ('i', 970), ('can', 937), ('charis', 878), ('would', 878), ('elodie', 771), ('been', 748)] | tokenPerfect: 9237 / 90000  10.26% | babyLLM.py 2500
2025-04-11 02:17:35 | 137500 | LR0.0003 | loss:5.1227 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-1.8229 | logitMax:23.3028 | scheduledSampling:0.0014 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0004 | activationSparsity:0.0000 | windowStd:0.2218 | windowEntropy:0.7742 | topWindowWeight:0.6080 | effectiveWindowCount:2.1689 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0059 | memoryGateLong:0.0070 | memoryGateCurrent:-0.0008 | memoryGateMean:0.3333 | memoryGateStd:16.2332 | windowWeightsW2:2.43809 (0.61),W4:1.93244 (0.37),W8:-0.85694 (0.02),W12:-3.28980 (0.00),W16:-4.76295 (0.00),W20:-6.24882 (0.00),W32:-6.53581 (0.00),W24:-6.94430 (0.00),W28:-7.33755 (0.00) | topTokens[(',', 2355), ('!', 1661), ('.', 1345), ('the', 1343), ('i', 1008), ('can', 938), ('charis', 879), ('would', 879), ('elodie', 771), ('been', 748)] | tokenPerfect: 13721 / 135000  10.16% | babyLLM.py 2500
2025-04-11 02:23:16 | 140000 | LR0.0003 | loss:5.0343 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:9.8897 | logitMax:35.8963 | scheduledSampling:0.0014 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2192 | windowEntropy:0.7834 | topWindowWeight:0.5877 | effectiveWindowCount:2.1889 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0057 | memoryGateLong:0.0068 | memoryGateCurrent:-0.0006 | memoryGateMean:0.3333 | memoryGateStd:15.7114 | windowWeightsW2:2.39429 (0.59),W4:1.97625 (0.39),W8:-0.85075 (0.02),W12:-3.35748 (0.00),W16:-4.88504 (0.00),W20:-6.38337 (0.00),W32:-6.69313 (0.00),W24:-7.08695 (0.00),W28:-7.48350 (0.00) | topTokens[(',', 2459), ('!', 1662), ('the', 1350), ('.', 1345), ('i', 1038), ('can', 944), ('charis', 879), ('would', 879), ('elodie', 771), ('been', 748)] |  | babyLLM.py 2500
2025-04-11 02:28:47 | 142500 | LR0.0003 | loss:4.9407 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:8.1774 | logitMax:33.5206 | scheduledSampling:0.0014 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2185 | windowEntropy:0.7853 | topWindowWeight:0.5810 | effectiveWindowCount:2.1930 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0055 | memoryGateLong:0.0066 | memoryGateCurrent:-0.0006 | memoryGateMean:0.3333 | memoryGateStd:15.1987 | windowWeightsW2:2.37917 (0.58),W4:1.98991 (0.39),W8:-0.84613 (0.02),W12:-3.44142 (0.00),W16:-5.00960 (0.00),W20:-6.52586 (0.00),W32:-6.85992 (0.00),W24:-7.24272 (0.00),W28:-7.64348 (0.00) | topTokens[(',', 2538), ('!', 1664), ('the', 1356), ('.', 1345), ('i', 1067), ('can', 945), ('charis', 881), ('would', 880), ('elodie', 771), ('been', 750)] | tokenPerfect: 5117 / 45000  11.37% | babyLLM.py 2500
2025-04-11 02:34:23 | 145000 | LR0.0003 | loss:4.8264 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:8.6216 | logitMax:34.8600 | scheduledSampling:0.0014 | embedMean:-0.0000 | embedStd:0.0004 | meanActivation:-0.0002 | activationSparsity:0.0000 | windowStd:0.2212 | windowEntropy:0.7715 | topWindowWeight:0.6013 | effectiveWindowCount:2.1630 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0081 | memoryGateLong:0.0100 | memoryGateCurrent:-0.0015 | memoryGateMean:0.3333 | memoryGateStd:22.8996 | windowWeightsW2:2.42066 (0.60),W4:1.94799 (0.37),W8:-0.89044 (0.02),W12:-3.55869 (0.00),W16:-5.15872 (0.00),W20:-6.68299 (0.00),W32:-7.03880 (0.00),W24:-7.40735 (0.00),W28:-7.81137 (0.00) | topTokens[(',', 2610), ('!', 1672), ('the', 1363), ('.', 1351), ('i', 1105), ('can', 948), ('charis', 881), ('would', 881), ('elodie', 771), ('and', 754)] | tokenPerfect: 10822 / 90000  12.02% | babyLLM.py 2500
2025-04-11 02:40:22 | 147500 | LR0.0003 | loss:3.6255 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:32.8367 | logitMax:70.3405 | scheduledSampling:0.0015 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.2199 | windowEntropy:0.7763 | topWindowWeight:0.5919 | effectiveWindowCount:2.1734 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0062 | memoryGateLong:0.0077 | memoryGateCurrent:-0.0011 | memoryGateMean:0.3333 | memoryGateStd:17.5327 | windowWeightsW2:2.39953 (0.59),W4:1.96622 (0.38),W8:-0.87002 (0.02),W12:-3.63779 (0.00),W16:-5.28528 (0.00),W20:-6.84096 (0.00),W32:-7.22881 (0.00),W24:-7.57810 (0.00),W28:-7.99085 (0.00) | topTokens[(',', 2630), ('!', 1685), ('.', 1445), ('the', 1380), ('i', 1156), ('can', 952), ('charis', 887), ('would', 882), ('elodie', 774), ('and', 759)] | tokenPerfect: 18668 / 135000  13.83% | babyLLM.py 2500
2025-04-11 02:46:03 | 150000 | LR0.0003 | loss:4.4502 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-5.3114 | logitMax:27.0985 | scheduledSampling:0.0015 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2182 | windowEntropy:0.7822 | topWindowWeight:0.5759 | effectiveWindowCount:2.1863 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0057 | memoryGateLong:0.0069 | memoryGateCurrent:-0.0007 | memoryGateMean:0.3333 | memoryGateStd:15.8050 | windowWeightsW2:2.36529 (0.58),W4:2.00012 (0.40),W8:-0.86758 (0.02),W12:-3.72589 (0.00),W16:-5.42023 (0.00),W20:-6.99850 (0.00),W32:-7.42969 (0.00),W24:-7.75138 (0.00),W28:-8.17634 (0.00) | topTokens[(',', 2696), ('!', 1690), ('.', 1469), ('the', 1393), ('i', 1199), ('can', 957), ('charis', 890), ('would', 882), ('elodie', 776), ('and', 773)] |  | babyLLM.py 2500
2025-04-11 02:51:48 | 152500 | LR0.0003 | loss:4.2319 | gradNorm:0.9991 | tokenCount:45000.0000 | logitMin:-6.2137 | logitMax:24.5378 | scheduledSampling:0.0015 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2145 | windowEntropy:0.7941 | topWindowWeight:0.5238 | effectiveWindowCount:2.2124 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0062 | memoryGateLong:0.0075 | memoryGateCurrent:-0.0009 | memoryGateMean:0.3333 | memoryGateStd:17.2450 | windowWeightsW2:2.25768 (0.52),W4:2.11058 (0.45),W8:-0.88564 (0.02),W12:-3.83256 (0.00),W16:-5.57237 (0.00),W20:-7.17107 (0.00),W32:-7.63916 (0.00),W24:-7.93533 (0.00),W28:-8.37155 (0.00) | topTokens[(',', 2787), ('!', 1692), ('.', 1478), ('the', 1414), ('i', 1238), ('can', 959), ('charis', 891), ('would', 883), ('you', 787), ('and', 785)] | tokenPerfect: 9965 / 45000  22.14% | babyLLM.py 2500
2025-04-11 02:57:21 | 155000 | LR0.0003 | loss:4.4411 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-12.4755 | logitMax:19.5452 | scheduledSampling:0.0015 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.2139 | windowEntropy:0.7957 | topWindowWeight:0.5039 | effectiveWindowCount:2.2161 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0065 | memoryGateLong:0.0078 | memoryGateCurrent:-0.0009 | memoryGateMean:0.3333 | memoryGateStd:18.0341 | windowWeightsW2:2.21605 (0.50),W4:2.15069 (0.47),W8:-0.87885 (0.02),W12:-3.94138 (0.00),W16:-5.71988 (0.00),W20:-7.33642 (0.00),W32:-7.86397 (0.00),W24:-8.12657 (0.00),W28:-8.57712 (0.00) | topTokens[(',', 2868), ('!', 1692), ('.', 1481), ('the', 1427), ('i', 1274), ('can', 961), ('charis', 891), ('would', 883), ('you', 807), ('and', 802)] | tokenPerfect: 18190 / 90000  20.21% | babyLLM.py 2500
2025-04-11 03:02:56 | 157500 | LR0.0003 | loss:4.2500 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-26.8512 | logitMax:4.2368 | scheduledSampling:0.0016 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0004 | activationSparsity:0.0000 | windowStd:0.2149 | windowEntropy:0.7906 | topWindowWeight:0.5285 | effectiveWindowCount:2.2047 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0095 | memoryGateLong:0.0117 | memoryGateCurrent:-0.0018 | memoryGateMean:0.3333 | memoryGateStd:26.7604 | windowWeightsW2:2.26473 (0.53),W4:2.09915 (0.45),W8:-0.89759 (0.02),W12:-4.03954 (0.00),W16:-5.85312 (0.00),W20:-7.50671 (0.00),W32:-8.09262 (0.00),W24:-8.31531 (0.00),W28:-8.78608 (0.00) | topTokens[(',', 2947), ('!', 1696), ('.', 1494), ('the', 1446), ('i', 1298), ('can', 968), ('charis', 893), ('would', 883), ('you', 820), ('and', 809)] | tokenPerfect: 27852 / 135000  20.63% | babyLLM.py 2500
2025-04-11 03:08:53 | 160000 | LR0.0003 | loss:3.9027 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-25.0136 | logitMax:7.5738 | scheduledSampling:0.0016 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0002 | activationSparsity:0.0000 | windowStd:0.2148 | windowEntropy:0.7887 | topWindowWeight:0.5215 | effectiveWindowCount:2.2004 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0070 | memoryGateLong:0.0084 | memoryGateCurrent:-0.0011 | memoryGateMean:0.3333 | memoryGateStd:19.4094 | windowWeightsW2:2.24950 (0.52),W4:2.11489 (0.46),W8:-0.93034 (0.02),W12:-4.15774 (0.00),W16:-6.00669 (0.00),W20:-7.67598 (0.00),W32:-8.30244 (0.00),W24:-8.49486 (0.00),W28:-8.98034 (0.00) | topTokens[(',', 3024), ('!', 1697), ('.', 1505), ('the', 1470), ('i', 1345), ('can', 970), ('charis', 894), ('would', 886), ('you', 836), ('and', 821)] |  | babyLLM.py 2500
2025-04-11 03:14:36 | 162500 | LR0.0003 | loss:4.2255 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-26.2685 | logitMax:5.8791 | scheduledSampling:0.0016 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.2149 | windowEntropy:0.7866 | topWindowWeight:0.5217 | effectiveWindowCount:2.1958 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0071 | memoryGateLong:0.0088 | memoryGateCurrent:-0.0013 | memoryGateMean:0.3333 | memoryGateStd:20.2193 | windowWeightsW2:2.24887 (0.52),W4:2.11463 (0.46),W8:-0.95328 (0.02),W12:-4.24165 (0.00),W16:-6.12654 (0.00),W20:-7.79980 (0.00),W32:-8.45108 (0.00),W24:-8.62458 (0.00),W28:-9.11654 (0.00) | topTokens[(',', 3101), ('!', 1707), ('.', 1516), ('the', 1491), ('i', 1375), ('can', 972), ('charis', 897), ('would', 886), ('you', 865), ('and', 832)] | tokenPerfect: 9249 / 45000  20.55% | babyLLM.py 2500
2025-04-11 03:20:31 | 165000 | LR0.0003 | loss:1.6974 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:14.4154 | logitMax:55.6199 | scheduledSampling:0.0016 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2159 | windowEntropy:0.7817 | topWindowWeight:0.5396 | effectiveWindowCount:2.1851 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0084 | memoryGateLong:0.0106 | memoryGateCurrent:-0.0018 | memoryGateMean:0.3333 | memoryGateStd:24.2032 | windowWeightsW2:2.28359 (0.54),W4:2.07666 (0.44),W8:-0.97436 (0.02),W12:-4.30384 (0.00),W16:-6.21516 (0.00),W20:-7.89216 (0.00),W32:-8.55031 (0.00),W24:-8.71726 (0.00),W28:-9.20890 (0.00) | topTokens[(',', 3147), ('!', 1749), ('.', 1554), ('the', 1510), ('i', 1387), ('can', 973), ('charis', 938), ('would', 886), ('you', 882), ('and', 846)] | tokenPerfect: 29814 / 90000  33.13% | babyLLM.py 2500
2025-04-11 03:26:18 | 167500 | LR0.0003 | loss:1.4941 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:1.8667 | logitMax:46.4138 | scheduledSampling:0.0017 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.2163 | windowEntropy:0.7795 | topWindowWeight:0.5454 | effectiveWindowCount:2.1805 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0088 | memoryGateLong:0.0110 | memoryGateCurrent:-0.0018 | memoryGateMean:0.3333 | memoryGateStd:25.1660 | windowWeightsW2:2.29378 (0.55),W4:2.06347 (0.43),W8:-0.98647 (0.02),W12:-4.32119 (0.00),W16:-6.23405 (0.00),W20:-7.92151 (0.00),W32:-8.59953 (0.00),W24:-8.74954 (0.00),W28:-9.24899 (0.00) | topTokens[(',', 3181), ('!', 1804), ('.', 1596), ('the', 1534), ('i', 1395), ('can', 973), ('charis', 969), ('you', 900), ('would', 886), ('and', 862)] | tokenPerfect: 51215 / 135000  37.94% | babyLLM.py 2500
2025-04-11 03:32:06 | 170000 | LR0.0003 | loss:1.5115 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-11.7921 | logitMax:35.1310 | scheduledSampling:0.0017 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2163 | windowEntropy:0.7782 | topWindowWeight:0.5419 | effectiveWindowCount:2.1775 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0139 | memoryGateLong:0.0172 | memoryGateCurrent:-0.0029 | memoryGateMean:0.3333 | memoryGateStd:39.4862 | windowWeightsW2:2.28540 (0.54),W4:2.07109 (0.44),W8:-1.01713 (0.02),W12:-4.38267 (0.00),W16:-6.31322 (0.00),W20:-8.00932 (0.00),W32:-8.68990 (0.00),W24:-8.82955 (0.00),W28:-9.33201 (0.00) | topTokens[(',', 3224), ('!', 1855), ('.', 1639), ('the', 1557), ('i', 1401), ('charis', 1005), ('can', 973), ('you', 933), ('would', 886), ('and', 878)] |  | babyLLM.py 2500
2025-04-11 03:37:38 | 172500 | LR0.0003 | loss:1.4886 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-17.9800 | logitMax:30.6586 | scheduledSampling:0.0017 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.2162 | windowEntropy:0.7783 | topWindowWeight:0.5404 | effectiveWindowCount:2.1777 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0087 | memoryGateLong:0.0107 | memoryGateCurrent:-0.0016 | memoryGateMean:0.3333 | memoryGateStd:24.6112 | windowWeightsW2:2.28055 (0.54),W4:2.07254 (0.44),W8:-1.02033 (0.02),W12:-4.40494 (0.00),W16:-6.33800 (0.00),W20:-8.03734 (0.00),W32:-8.73009 (0.00),W24:-8.86171 (0.00),W28:-9.36918 (0.00) | topTokens[(',', 3277), ('!', 1905), ('.', 1671), ('the', 1577), ('i', 1413), ('charis', 1034), ('can', 973), ('you', 953), ('and', 894), ('elodie', 888)] | tokenPerfect: 21229 / 45000  47.18% | babyLLM.py 2500
2025-04-11 03:43:17 | 175000 | LR0.0003 | loss:3.5051 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-46.5067 | logitMax:4.8096 | scheduledSampling:0.0017 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2161 | windowEntropy:0.7757 | topWindowWeight:0.5330 | effectiveWindowCount:2.1722 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0112 | memoryGateLong:0.0141 | memoryGateCurrent:-0.0026 | memoryGateMean:0.3333 | memoryGateStd:32.1812 | windowWeightsW2:2.26463 (0.53),W4:2.08977 (0.45),W8:-1.07648 (0.02),W12:-4.52642 (0.00),W16:-6.50745 (0.00),W20:-8.21160 (0.00),W32:-8.93412 (0.00),W24:-9.03811 (0.00),W28:-9.54881 (0.00) | topTokens[(',', 3334), ('!', 1940), ('.', 1707), ('the', 1597), ('i', 1436), ('charis', 1052), ('can', 973), ('you', 969), ('elodie', 915), ('and', 909)] | tokenPerfect: 35896 / 90000  39.88% | babyLLM.py 2500
2025-04-11 03:48:54 | 177500 | LR0.0003 | loss:4.6116 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-70.3791 | logitMax:-31.4448 | scheduledSampling:0.0018 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0003 | activationSparsity:0.0000 | windowStd:0.2160 | windowEntropy:0.7754 | topWindowWeight:0.5307 | effectiveWindowCount:2.1715 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0068 | memoryGateLong:0.0083 | memoryGateCurrent:-0.0011 | memoryGateMean:0.3333 | memoryGateStd:19.0633 | windowWeightsW2:2.25867 (0.53),W4:2.09334 (0.45),W8:-1.08325 (0.02),W12:-4.60363 (0.00),W16:-6.60399 (0.00),W20:-8.32621 (0.00),W32:-9.09070 (0.00),W24:-9.16142 (0.00),W28:-9.68978 (0.00) | topTokens[(',', 3379), ('!', 1945), ('.', 1734), ('the', 1621), ('i', 1451), ('charis', 1053), ('can', 974), ('you', 973), ('and', 924), ('elodie', 919)] | tokenPerfect: 46796 / 135000  34.66% | babyLLM.py 2500
2025-04-11 03:54:37 | 180000 | LR0.0003 | loss:3.4170 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-62.6021 | logitMax:-26.3498 | scheduledSampling:0.0018 | embedMean:0.0000 | embedStd:0.0003 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.2166 | windowEntropy:0.7702 | topWindowWeight:0.5376 | effectiveWindowCount:2.1602 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0060 | memoryGateLong:0.0075 | memoryGateCurrent:-0.0011 | memoryGateMean:0.3333 | memoryGateStd:16.9811 | windowWeightsW2:2.27183 (0.54),W4:2.08095 (0.44),W8:-1.14313 (0.02),W12:-4.70951 (0.00),W16:-6.73728 (0.00),W20:-8.45532 (0.00),W32:-9.23614 (0.00),W24:-9.29110 (0.00),W28:-9.82100 (0.00) | topTokens[(',', 3397), ('!', 1950), ('.', 1764), ('the', 1632), ('i', 1470), ('charis', 1054), ('you', 997), ('can', 975), ('and', 927), ('elodie', 922)] |  | babyLLM.py 2500
2025-04-11 04:00:26 | 182500 | LR0.0003 | loss:2.2076 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-49.2721 | logitMax:-3.5274 | scheduledSampling:0.0018 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2173 | windowEntropy:0.7658 | topWindowWeight:0.5464 | effectiveWindowCount:2.1506 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0088 | memoryGateLong:0.0112 | memoryGateCurrent:-0.0020 | memoryGateMean:0.3333 | memoryGateStd:25.4155 | windowWeightsW2:2.28848 (0.55),W4:2.06309 (0.44),W8:-1.18153 (0.02),W12:-4.81141 (0.00),W16:-6.84402 (0.00),W20:-8.57840 (0.00),W32:-9.36203 (0.00),W24:-9.40534 (0.00),W28:-9.93415 (0.00) | topTokens[(',', 3428), ('!', 1980), ('.', 1785), ('the', 1650), ('i', 1477), ('charis', 1070), ('you', 1010), ('can', 975), ('elodie', 950), ('and', 938)] | tokenPerfect: 22265 / 45000  49.48% | babyLLM.py 2500
2025-04-11 04:06:02 | 185000 | LR0.0003 | loss:1.5863 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-49.0041 | logitMax:2.0838 | scheduledSampling:0.0018 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.2165 | windowEntropy:0.7671 | topWindowWeight:0.5290 | effectiveWindowCount:2.1536 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0085 | memoryGateLong:0.0106 | memoryGateCurrent:-0.0017 | memoryGateMean:0.3333 | memoryGateStd:24.2127 | windowWeightsW2:2.25202 (0.53),W4:2.09922 (0.45),W8:-1.21741 (0.02),W12:-4.85562 (0.00),W16:-6.90011 (0.00),W20:-8.65368 (0.00),W32:-9.44374 (0.00),W24:-9.47544 (0.00),W28:-10.00738 (0.00) | topTokens[(',', 3463), ('!', 2027), ('.', 1804), ('the', 1673), ('i', 1483), ('charis', 1092), ('you', 1018), ('elodie', 981), ('been', 980), ('can', 975)] | tokenPerfect: 48249 / 90000  53.61% | babyLLM.py 2500
2025-04-11 04:11:31 | 187500 | LR0.0003 | loss:1.5266 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-52.5028 | logitMax:-0.1152 | scheduledSampling:0.0019 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.2166 | windowEntropy:0.7664 | topWindowWeight:0.5275 | effectiveWindowCount:2.1520 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0095 | memoryGateLong:0.0118 | memoryGateCurrent:-0.0019 | memoryGateMean:0.3333 | memoryGateStd:27.0905 | windowWeightsW2:2.24743 (0.53),W4:2.10129 (0.46),W8:-1.23444 (0.02),W12:-4.89595 (0.00),W16:-6.93858 (0.00),W20:-8.70824 (0.00),W32:-9.50468 (0.00),W24:-9.52278 (0.00),W28:-10.05568 (0.00) | topTokens[(',', 3492), ('!', 2068), ('.', 1826), ('the', 1697), ('i', 1498), ('charis', 1108), ('been', 1071), ('you', 1028), ('elodie', 1005), ('can', 975)] | tokenPerfect: 73955 / 135000  54.78% | babyLLM.py 2500
2025-04-11 04:17:33 | 190000 | LR0.0003 | loss:4.6314 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-117.7806 | logitMax:-82.3049 | scheduledSampling:0.0019 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0002 | activationSparsity:0.0000 | windowStd:0.2165 | windowEntropy:0.7676 | topWindowWeight:0.5297 | effectiveWindowCount:2.1546 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0056 | memoryGateLong:0.0066 | memoryGateCurrent:-0.0006 | memoryGateMean:0.3333 | memoryGateStd:15.4031 | windowWeightsW2:2.24974 (0.53),W4:2.09372 (0.45),W8:-1.20478 (0.02),W12:-4.94163 (0.00),W16:-7.01659 (0.00),W20:-8.80431 (0.00),W24:-9.62850 (0.00),W32:-9.63466 (0.00),W28:-10.16253 (0.00) | topTokens[(',', 3522), ('!', 2077), ('.', 1850), ('the', 1745), ('i', 1507), ('charis', 1124), ('been', 1088), ('you', 1033), ('elodie', 1019), ('can', 976)] |  | babyLLM.py 2500
2025-04-11 04:23:14 | 192500 | LR0.0003 | loss:4.5732 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-138.4380 | logitMax:-107.7548 | scheduledSampling:0.0019 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2174 | windowEntropy:0.7649 | topWindowWeight:0.5466 | effectiveWindowCount:2.1488 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0069 | memoryGateLong:0.0082 | memoryGateCurrent:-0.0009 | memoryGateMean:0.3333 | memoryGateStd:19.0765 | windowWeightsW2:2.28210 (0.55),W4:2.05591 (0.44),W8:-1.18783 (0.02),W12:-5.02225 (0.00),W16:-7.16244 (0.00),W20:-8.95737 (0.00),W24:-9.78118 (0.00),W32:-9.81282 (0.00),W28:-10.31197 (0.00) | topTokens[(',', 3548), ('!', 2077), ('.', 1872), ('the', 1785), ('i', 1512), ('charis', 1125), ('been', 1089), ('you', 1035), ('elodie', 1019), ('and', 992)] | tokenPerfect: 8982 / 45000  19.96% | babyLLM.py 2500
2025-04-11 04:28:47 | 195000 | LR0.0003 | loss:4.7722 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-150.0796 | logitMax:-119.5692 | scheduledSampling:0.0019 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0003 | activationSparsity:0.0000 | windowStd:0.2187 | windowEntropy:0.7606 | topWindowWeight:0.5650 | effectiveWindowCount:2.1396 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0061 | memoryGateLong:0.0072 | memoryGateCurrent:-0.0007 | memoryGateMean:0.3333 | memoryGateStd:16.7014 | windowWeightsW2:2.31760 (0.56),W4:2.01485 (0.42),W8:-1.17109 (0.02),W12:-5.09541 (0.00),W16:-7.28408 (0.00),W20:-9.08504 (0.00),W24:-9.90848 (0.00),W32:-9.94870 (0.00),W28:-10.43053 (0.00) | topTokens[(',', 3574), ('!', 2077), ('.', 1897), ('the', 1796), ('i', 1524), ('charis', 1125), ('been', 1090), ('you', 1040), ('elodie', 1020), ('and', 1003)] | tokenPerfect: 16693 / 90000  18.55% | babyLLM.py 2500

--- 2025-04-11 04:33:43 --- babyLLM 'right, last time i got to step 196525... want to restart from there?'  - charis: 'no, restart, got'cha some new data!' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: 'well, you have decided to nerf nearly all your windows so... i guess... continue???'
2025-04-11 04:39:00 | 2500 | LR0.0003 | loss:1.5390 | gradNorm:1.0000 | logitMin:-74.0292 | logitMax:-28.8055 | scheduledSampling:0.0000 | tokenCount:45000.0000 | memoryGateShort:-0.0094 | memoryGateLong:0.0116 | memoryGateCurrent:-0.0018 | shortDecay:0.0003 | longDecay:0.0003 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.2181 | windowEntropy:0.7600 | topWindowWeight:0.5543 | effectiveWindowCount:2.1383 | memoryGateMean:0.3333 | memoryGateStd:26.5949 | windowWeightsW2:2.29402 (0.55),W4:2.03811 (0.43),W8:-1.23382 (0.02),W12:-5.24733 (0.00),W16:-7.48365 (0.00),W20:-9.27999 (0.00),W24:-10.09239 (0.00),W32:-10.13794 (0.00),W28:-10.59164 (0.00) | topTokens[('have', 118), ('will', 111), ('.', 66), ('felt', 51), ('!', 43), ('know', 31), ('charis', 27), ('elodie', 25), ('the', 23), ('n', 20)] | tokenPerfect: 24566 / 45000  54.59% | babyLLM.py 2500
2025-04-11 04:44:21 | 5000 | LR0.0003 | loss:3.1630 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-107.2149 | logitMax:-59.4982 | scheduledSampling:0.0000 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.2171 | windowEntropy:0.7588 | topWindowWeight:0.5278 | effectiveWindowCount:2.1357 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0056 | memoryGateLong:0.0070 | memoryGateCurrent:-0.0010 | memoryGateMean:0.3333 | memoryGateStd:15.8302 | windowWeightsW2:2.24057 (0.53),W4:2.09741 (0.46),W8:-1.35664 (0.01),W12:-5.41503 (0.00),W16:-7.67142 (0.00),W20:-9.46230 (0.00),W24:-10.26940 (0.00),W32:-10.34277 (0.00),W28:-10.76688 (0.00) | topTokens[('have', 149), ('will', 149), ('.', 112), ('!', 75), ('felt', 66), ('the', 51), (',', 47), ('know', 41), ('charis', 40), ('it', 39)] | tokenPerfect: 41238 / 90000  45.82% | babyLLM.py 2500
2025-04-11 04:49:43 | 7500 | LR0.0003 | loss:4.6144 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-154.6458 | logitMax:-121.7979 | scheduledSampling:0.0001 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2166 | windowEntropy:0.7608 | topWindowWeight:0.5168 | effectiveWindowCount:2.1399 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0084 | memoryGateLong:0.0098 | memoryGateCurrent:-0.0010 | memoryGateMean:0.3333 | memoryGateStd:22.8912 | windowWeightsW2:2.21666 (0.52),W4:2.11803 (0.47),W8:-1.34431 (0.01),W12:-5.46343 (0.00),W16:-7.73809 (0.00),W20:-9.54276 (0.00),W24:-10.35962 (0.00),W32:-10.45524 (0.00),W28:-10.86069 (0.00) | topTokens[('will', 151), ('have', 149), ('.', 134), (',', 102), ('the', 82), ('!', 79), ('felt', 66), ('it', 52), ('and', 46), ('they', 45)] | tokenPerfect: 49168 / 135000  36.42% | babyLLM.py 2500
2025-04-11 04:55:12 | 10000 | LR0.0003 | loss:4.8807 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-164.8061 | logitMax:-135.9435 | scheduledSampling:0.0001 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2178 | windowEntropy:0.7567 | topWindowWeight:0.5433 | effectiveWindowCount:2.1312 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0067 | memoryGateLong:0.0078 | memoryGateCurrent:-0.0008 | memoryGateMean:0.3333 | memoryGateStd:18.2303 | windowWeightsW2:2.26837 (0.54),W4:2.06152 (0.44),W8:-1.34039 (0.01),W12:-5.52898 (0.00),W16:-7.83628 (0.00),W20:-9.64743 (0.00),W24:-10.45976 (0.00),W32:-10.57398 (0.00),W28:-10.95871 (0.00) | topTokens[('.', 157), (',', 157), ('will', 152), ('have', 150), ('the', 104), ('!', 92), ('and', 67), ('a', 67), ('felt', 66), ('it', 59)] |  | babyLLM.py 2500
2025-04-11 05:00:34 | 12500 | LR0.0003 | loss:3.7952 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-164.4535 | logitMax:-134.6651 | scheduledSampling:0.0001 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2199 | windowEntropy:0.7459 | topWindowWeight:0.5685 | effectiveWindowCount:2.1083 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0070 | memoryGateLong:0.0084 | memoryGateCurrent:-0.0010 | memoryGateMean:0.3333 | memoryGateStd:19.3433 | windowWeightsW2:2.31869 (0.57),W4:2.01055 (0.42),W8:-1.42057 (0.01),W12:-5.63113 (0.00),W16:-7.94791 (0.00),W20:-9.75677 (0.00),W24:-10.56086 (0.00),W32:-10.67445 (0.00),W28:-11.04281 (0.00) | topTokens[('.', 211), (',', 177), ('will', 165), ('have', 150), ('the', 107), ('!', 99), ('to', 79), ('a', 77), ('you', 76), ('and', 70)] | tokenPerfect: 11903 / 45000  26.45% | babyLLM.py 2500
2025-04-11 05:05:55 | 15000 | LR0.0003 | loss:3.4050 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-167.6489 | logitMax:-137.4810 | scheduledSampling:0.0001 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0003 | activationSparsity:0.0000 | windowStd:0.2212 | windowEntropy:0.7378 | topWindowWeight:0.5799 | effectiveWindowCount:2.0913 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0064 | memoryGateLong:0.0079 | memoryGateCurrent:-0.0011 | memoryGateMean:0.3333 | memoryGateStd:17.9793 | windowWeightsW2:2.34089 (0.58),W4:1.98849 (0.41),W8:-1.51158 (0.01),W12:-5.73084 (0.00),W16:-8.05341 (0.00),W20:-9.86168 (0.00),W24:-10.65236 (0.00),W32:-10.77140 (0.00),W28:-11.12018 (0.00) | topTokens[('.', 266), (',', 196), ('will', 171), ('have', 150), ('?', 121), ('the', 109), ('you', 109), ('a', 107), ('to', 105), ('!', 103)] | tokenPerfect: 25946 / 90000  28.83% | babyLLM.py 2500
2025-04-11 05:11:17 | 17500 | LR0.0003 | loss:3.3087 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-169.6401 | logitMax:-137.6982 | scheduledSampling:0.0002 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0003 | activationSparsity:0.0000 | windowStd:0.2236 | windowEntropy:0.7261 | topWindowWeight:0.6002 | effectiveWindowCount:2.0670 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0054 | memoryGateLong:0.0067 | memoryGateCurrent:-0.0009 | memoryGateMean:0.3333 | memoryGateStd:15.3744 | windowWeightsW2:2.38236 (0.60),W4:1.94671 (0.39),W8:-1.58849 (0.01),W12:-5.82357 (0.00),W16:-8.14986 (0.00),W20:-9.96514 (0.00),W24:-10.74250 (0.00),W32:-10.86182 (0.00),W28:-11.19890 (0.00) | topTokens[('.', 327), (',', 204), ('?', 181), ('will', 179), ('have', 152), ('to', 140), ('you', 134), ('a', 123), ('the', 114), ('!', 112)] | tokenPerfect: 40726 / 135000  30.17% | babyLLM.py 2500
2025-04-11 05:16:46 | 20000 | LR0.0003 | loss:2.7098 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-169.6423 | logitMax:-136.1736 | scheduledSampling:0.0002 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0003 | activationSparsity:0.0000 | windowStd:0.2244 | windowEntropy:0.7198 | topWindowWeight:0.6045 | effectiveWindowCount:2.0541 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0066 | memoryGateLong:0.0084 | memoryGateCurrent:-0.0014 | memoryGateMean:0.3333 | memoryGateStd:18.9962 | windowWeightsW2:2.39086 (0.60),W4:1.94001 (0.39),W8:-1.69567 (0.01),W12:-5.95085 (0.00),W16:-8.28327 (0.00),W20:-10.08605 (0.00),W24:-10.84317 (0.00),W32:-10.96313 (0.00),W28:-11.28073 (0.00) | topTokens[('.', 392), ('?', 228), (',', 220), ('will', 195), ('to', 182), ('you', 160), ('have', 155), ('a', 151), ('is', 128), ('i', 125)] |  | babyLLM.py 2500
2025-04-11 05:22:09 | 22500 | LR0.0003 | loss:2.1133 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-159.9351 | logitMax:-121.1883 | scheduledSampling:0.0002 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2229 | windowEntropy:0.7215 | topWindowWeight:0.5888 | effectiveWindowCount:2.0576 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0071 | memoryGateLong:0.0090 | memoryGateCurrent:-0.0015 | memoryGateMean:0.3333 | memoryGateStd:20.4755 | windowWeightsW2:2.35776 (0.59),W4:1.97671 (0.40),W8:-1.83544 (0.01),W12:-6.08290 (0.00),W16:-8.42515 (0.00),W20:-10.19694 (0.00),W24:-10.94168 (0.00),W32:-11.06403 (0.00),W28:-11.36516 (0.00) | topTokens[('.', 433), ('?', 271), ('to', 256), (',', 220), ('will', 211), ('you', 183), ('a', 158), ('have', 156), ('i', 147), ('is', 137)] | tokenPerfect: 23626 / 45000  52.50% | babyLLM.py 2500
2025-04-11 05:27:28 | 25000 | LR0.0003 | loss:1.9406 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-151.9062 | logitMax:-109.5949 | scheduledSampling:0.0002 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.2229 | windowEntropy:0.7194 | topWindowWeight:0.5872 | effectiveWindowCount:2.0532 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0083 | memoryGateLong:0.0103 | memoryGateCurrent:-0.0017 | memoryGateMean:0.3333 | memoryGateStd:23.5563 | windowWeightsW2:2.35352 (0.59),W4:1.98062 (0.40),W8:-1.91577 (0.01),W12:-6.18768 (0.00),W16:-8.51928 (0.00),W20:-10.27558 (0.00),W24:-11.01142 (0.00),W32:-11.13808 (0.00),W28:-11.42854 (0.00) | topTokens[('.', 478), ('to', 327), ('?', 325), ('will', 229), (',', 222), ('you', 206), ('i', 174), ('a', 168), ('what', 166), ('music', 164)] | tokenPerfect: 47901 / 90000  53.22% | babyLLM.py 2500
2025-04-11 05:32:53 | 27500 | LR0.0003 | loss:2.5679 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-152.6855 | logitMax:-105.3156 | scheduledSampling:0.0003 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2192 | windowEntropy:0.7289 | topWindowWeight:0.5323 | effectiveWindowCount:2.0727 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0142 | memoryGateLong:0.0180 | memoryGateCurrent:-0.0034 | memoryGateMean:0.3333 | memoryGateStd:40.9420 | windowWeightsW2:2.24088 (0.53),W4:2.09602 (0.46),W8:-2.07802 (0.01),W12:-6.38690 (0.00),W16:-8.71824 (0.00),W20:-10.44528 (0.00),W24:-11.16556 (0.00),W32:-11.30822 (0.00),W28:-11.57442 (0.00) | topTokens[('.', 517), ('to', 367), ('?', 359), (',', 245), ('will', 238), ('you', 220), ('i', 195), ('a', 190), ('what', 189), ('music', 186)] | tokenPerfect: 68400 / 135000  50.67% | babyLLM.py 2500
2025-04-11 05:38:27 | 30000 | LR0.0003 | loss:3.6005 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-185.9439 | logitMax:-144.8736 | scheduledSampling:0.0003 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0002 | activationSparsity:0.0000 | windowStd:0.2187 | windowEntropy:0.7290 | topWindowWeight:0.5128 | effectiveWindowCount:2.0730 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0067 | memoryGateLong:0.0081 | memoryGateCurrent:-0.0010 | memoryGateMean:0.3333 | memoryGateStd:18.6608 | windowWeightsW2:2.20027 (0.51),W4:2.13522 (0.48),W8:-2.14413 (0.01),W12:-6.47905 (0.00),W16:-8.81301 (0.00),W20:-10.53793 (0.00),W24:-11.25482 (0.00),W32:-11.40409 (0.00),W28:-11.65665 (0.00) | topTokens[('.', 552), ('?', 403), ('to', 386), (',', 284), ('will', 250), ('you', 241), ('i', 221), ('a', 206), ('what', 201), ('music', 189)] |  | babyLLM.py 2500
2025-04-11 05:43:52 | 32500 | LR0.0003 | loss:3.4714 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-203.5060 | logitMax:-167.5134 | scheduledSampling:0.0003 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0002 | activationSparsity:0.0000 | windowStd:0.2196 | windowEntropy:0.7247 | topWindowWeight:0.5367 | effectiveWindowCount:2.0641 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0101 | memoryGateLong:0.0122 | memoryGateCurrent:-0.0017 | memoryGateMean:0.3333 | memoryGateStd:28.0607 | windowWeightsW2:2.24668 (0.54),W4:2.08591 (0.46),W8:-2.19913 (0.01),W12:-6.53951 (0.00),W16:-8.86998 (0.00),W20:-10.59746 (0.00),W24:-11.30166 (0.00),W32:-11.45086 (0.00),W28:-11.69592 (0.00) | topTokens[('.', 628), ('?', 465), ('to', 411), (',', 303), ('you', 282), ('will', 265), ('i', 251), ('what', 227), ('a', 217), ('music', 202)] | tokenPerfect: 14036 / 45000  31.19% | babyLLM.py 2500
2025-04-11 05:49:11 | 35000 | LR0.0003 | loss:3.4272 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-204.0579 | logitMax:-166.4888 | scheduledSampling:0.0003 | embedMean:-0.0000 | embedStd:0.0004 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2195 | windowEntropy:0.7231 | topWindowWeight:0.5323 | effectiveWindowCount:2.0607 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0094 | memoryGateLong:0.0111 | memoryGateCurrent:-0.0012 | memoryGateMean:0.3333 | memoryGateStd:25.7481 | windowWeightsW2:2.23651 (0.53),W4:2.09467 (0.46),W8:-2.28690 (0.01),W12:-6.61999 (0.00),W16:-8.94365 (0.00),W20:-10.66395 (0.00),W24:-11.35580 (0.00),W32:-11.50990 (0.00),W28:-11.74404 (0.00) | topTokens[('.', 691), ('?', 513), ('to', 441), (',', 328), ('you', 309), ('i', 279), ('will', 278), ('what', 251), ('a', 236), ('is', 220)] | tokenPerfect: 29268 / 90000  32.52% | babyLLM.py 2500
2025-04-11 05:54:47 | 37500 | LR0.0003 | loss:3.6361 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-144.1017 | logitMax:-101.0410 | scheduledSampling:0.0004 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2212 | windowEntropy:0.7179 | topWindowWeight:0.5632 | effectiveWindowCount:2.0500 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0112 | memoryGateLong:0.0132 | memoryGateCurrent:-0.0016 | memoryGateMean:0.3333 | memoryGateStd:30.7780 | windowWeightsW2:2.29741 (0.56),W4:2.02915 (0.43),W8:-2.23709 (0.01),W12:-6.63323 (0.00),W16:-8.98872 (0.00),W20:-10.71174 (0.00),W24:-11.39376 (0.00),W32:-11.55144 (0.00),W28:-11.77820 (0.00) | topTokens[('.', 774), ('?', 530), ('to', 458), (',', 352), ('i', 336), ('you', 333), ('will', 282), ('a', 262), ('what', 257), ('is', 244)] | tokenPerfect: 37599 / 135000  27.85% | babyLLM.py 2500
2025-04-11 06:00:31 | 40000 | LR0.0003 | loss:5.0408 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-219.7785 | logitMax:-183.4265 | scheduledSampling:0.0004 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0004 | activationSparsity:0.0000 | windowStd:0.2224 | windowEntropy:0.7146 | topWindowWeight:0.5783 | effectiveWindowCount:2.0434 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0065 | memoryGateLong:0.0076 | memoryGateCurrent:-0.0007 | memoryGateMean:0.3333 | memoryGateStd:17.7029 | windowWeightsW2:2.32653 (0.58),W4:1.99521 (0.42),W8:-2.18336 (0.01),W12:-6.66104 (0.00),W16:-9.04570 (0.00),W20:-10.76126 (0.00),W24:-11.43244 (0.00),W32:-11.59528 (0.00),W28:-11.81195 (0.00) | topTokens[('.', 827), ('?', 537), ('to', 475), (',', 365), ('i', 362), ('you', 345), ('a', 286), ('will', 282), ('what', 260), ('is', 255)] |  | babyLLM.py 2500
2025-04-11 06:05:52 | 42500 | LR0.0003 | loss:4.3998 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-275.9924 | logitMax:-244.0104 | scheduledSampling:0.0004 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:-0.0001 | activationSparsity:0.0000 | windowStd:0.2245 | windowEntropy:0.7071 | topWindowWeight:0.5984 | effectiveWindowCount:2.0281 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0070 | memoryGateLong:0.0082 | memoryGateCurrent:-0.0008 | memoryGateMean:0.3333 | memoryGateStd:19.1826 | windowWeightsW2:2.36641 (0.60),W4:1.95148 (0.40),W8:-2.17739 (0.01),W12:-6.73314 (0.00),W16:-9.14568 (0.00),W20:-10.84269 (0.00),W24:-11.49381 (0.00),W32:-11.66111 (0.00),W28:-11.86450 (0.00) | topTokens[('.', 852), ('?', 539), ('to', 482), (',', 389), ('i', 365), ('you', 345), ('a', 311), ('will', 284), ('is', 271), ('what', 261)] | tokenPerfect: 9712 / 45000  21.58% | babyLLM.py 2500
2025-04-11 06:11:16 | 45000 | LR0.0003 | loss:4.4993 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-257.6289 | logitMax:-222.8756 | scheduledSampling:0.0004 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2262 | windowEntropy:0.6994 | topWindowWeight:0.6123 | effectiveWindowCount:2.0126 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0081 | memoryGateLong:0.0097 | memoryGateCurrent:-0.0012 | memoryGateMean:0.3333 | memoryGateStd:22.3423 | windowWeightsW2:2.39408 (0.61),W4:1.92141 (0.38),W8:-2.22892 (0.01),W12:-6.85461 (0.00),W16:-9.28236 (0.00),W20:-10.94327 (0.00),W24:-11.57190 (0.00),W32:-11.73856 (0.00),W28:-11.93064 (0.00) | topTokens[('.', 871), ('?', 543), ('to', 496), (',', 412), ('i', 382), ('you', 348), ('a', 314), ('will', 286), ('is', 277), ('the', 275)] | tokenPerfect: 20227 / 90000  22.47% | babyLLM.py 2500
2025-04-11 06:16:39 | 47500 | LR0.0003 | loss:3.2911 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-227.9025 | logitMax:-188.4353 | scheduledSampling:0.0005 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2274 | windowEntropy:0.6950 | topWindowWeight:0.6209 | effectiveWindowCount:2.0037 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0077 | memoryGateLong:0.0094 | memoryGateCurrent:-0.0013 | memoryGateMean:0.3333 | memoryGateStd:21.5706 | windowWeightsW2:2.41080 (0.62),W4:1.90142 (0.37),W8:-2.23187 (0.01),W12:-6.93149 (0.00),W16:-9.37216 (0.00),W20:-11.00729 (0.00),W24:-11.61879 (0.00),W32:-11.78506 (0.00),W28:-11.96913 (0.00) | topTokens[('.', 904), ('?', 559), ('to', 502), (',', 419), ('i', 394), ('you', 360), ('a', 322), ('will', 290), ('the', 278), ('is', 278)] | tokenPerfect: 39129 / 135000  28.98% | babyLLM.py 2500
2025-04-11 06:22:11 | 50000 | LR0.0003 | loss:2.6353 | gradNorm:0.9999 | tokenCount:45000.0000 | logitMin:-178.8201 | logitMax:-131.9077 | scheduledSampling:0.0005 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2276 | windowEntropy:0.6941 | topWindowWeight:0.6226 | effectiveWindowCount:2.0020 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0069 | memoryGateLong:0.0083 | memoryGateCurrent:-0.0010 | memoryGateMean:0.3333 | memoryGateStd:19.1024 | windowWeightsW2:2.41287 (0.62),W4:1.89606 (0.37),W8:-2.23128 (0.01),W12:-6.96392 (0.00),W16:-9.44003 (0.00),W20:-11.06218 (0.00),W24:-11.66565 (0.00),W32:-11.83522 (0.00),W28:-12.00972 (0.00) | topTokens[('.', 907), ('?', 559), ('to', 502), (',', 429), ('i', 408), ('you', 381), ('a', 348), ('!', 342), ('will', 319), ('is', 282)] |  | babyLLM.py 2500
2025-04-11 06:27:34 | 52500 | LR0.0003 | loss:2.5423 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-187.5071 | logitMax:-140.2745 | scheduledSampling:0.0005 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2307 | windowEntropy:0.6824 | topWindowWeight:0.6430 | effectiveWindowCount:1.9787 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0109 | memoryGateLong:0.0132 | memoryGateCurrent:-0.0019 | memoryGateMean:0.3333 | memoryGateStd:30.3699 | windowWeightsW2:2.45525 (0.64),W4:1.84973 (0.35),W8:-2.22916 (0.01),W12:-7.03372 (0.00),W16:-9.53848 (0.00),W20:-11.12914 (0.00),W24:-11.71727 (0.00),W32:-11.88885 (0.00),W28:-12.05274 (0.00) | topTokens[('.', 908), ('?', 559), ('to', 507), ('!', 456), (',', 435), ('i', 422), ('you', 391), ('a', 378), ('will', 339), ('it', 318)] | tokenPerfect: 17447 / 45000  38.77% | babyLLM.py 2500
2025-04-11 06:32:54 | 55000 | LR0.0003 | loss:2.6335 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-185.7161 | logitMax:-136.4545 | scheduledSampling:0.0005 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0002 | activationSparsity:0.0000 | windowStd:0.2312 | windowEntropy:0.6804 | topWindowWeight:0.6464 | effectiveWindowCount:1.9747 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0060 | memoryGateLong:0.0074 | memoryGateCurrent:-0.0009 | memoryGateMean:0.3333 | memoryGateStd:16.9573 | windowWeightsW2:2.46103 (0.65),W4:1.84041 (0.35),W8:-2.22358 (0.01),W12:-7.09377 (0.00),W16:-9.60217 (0.00),W20:-11.17702 (0.00),W24:-11.75396 (0.00),W32:-11.92458 (0.00),W28:-12.08144 (0.00) | topTokens[('.', 910), ('!', 569), ('?', 560), ('to', 508), (',', 446), ('i', 437), ('it', 404), ('you', 403), ('a', 392), ('will', 358)] | tokenPerfect: 35512 / 90000  39.46% | babyLLM.py 2500
2025-04-11 06:38:14 | 57500 | LR0.0003 | loss:3.7250 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-230.2136 | logitMax:-184.3002 | scheduledSampling:0.0006 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2306 | windowEntropy:0.6831 | topWindowWeight:0.6428 | effectiveWindowCount:1.9800 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0071 | memoryGateLong:0.0085 | memoryGateCurrent:-0.0010 | memoryGateMean:0.3333 | memoryGateStd:19.6809 | windowWeightsW2:2.45145 (0.64),W4:1.84652 (0.35),W8:-2.20812 (0.01),W12:-7.15416 (0.00),W16:-9.69857 (0.00),W20:-11.24970 (0.00),W24:-11.81161 (0.00),W32:-11.98476 (0.00),W28:-12.13223 (0.00) | topTokens[('.', 926), ('!', 630), ('?', 561), ('to', 523), (',', 499), ('i', 450), ('it', 424), ('you', 418), ('a', 411), ('will', 362)] | tokenPerfect: 47786 / 135000  35.40% | babyLLM.py 2500
2025-04-11 06:43:46 | 60000 | LR0.0003 | loss:3.0657 | gradNorm:1.0000 | tokenCount:45000.0000 | logitMin:-236.8917 | logitMax:-190.3430 | scheduledSampling:0.0006 | embedMean:-0.0000 | embedStd:0.0003 | meanActivation:0.0002 | activationSparsity:0.0000 | windowStd:0.2311 | windowEntropy:0.6810 | topWindowWeight:0.6459 | effectiveWindowCount:1.9759 | shortDecay:0.0003 | longDecay:0.0003 | memoryGateShort:-0.0072 | memoryGateLong:0.0084 | memoryGateCurrent:-0.0008 | memoryGateMean:0.3333 | memoryGateStd:19.5995 | windowWeightsW2:2.45670 (0.65),W4:1.83811 (0.35),W8:-2.21305 (0.01),W12:-7.22427 (0.00),W16:-9.79189 (0.00),W20:-11.31661 (0.00),W24:-11.86653 (0.00),W32:-12.03824 (0.00),W28:-12.17871 (0.00) | topTokens[('.', 939), ('!', 677), ('?', 561), (',', 549), ('to', 544), ('i', 460), ('it', 451), ('you', 432), ('a', 428), ('will', 363)] |  | babyLLM.py 2500

--- 2025-04-11 16:11:37 --- babyLLM 'right, last time i got to step 60230... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 16:14:18 --- babyLLM 'right, last time i got to step 7... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 17:21:05 --- babyLLM 'right, last time i got to step 24... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 17:22:05 --- babyLLM 'right, last time i got to step 80... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 20:54:10 --- babyLLM 'right, last time i got to step 209... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 21:19:01 --- babyLLM 'right, last time i got to step 153... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 21:20:51 --- babyLLM 'right, last time i got to step 153... want to restart from there?'  - charis: '-0' - babyLLM 'umm... i don't think i heard you properly, i'll just start from step 0 :) but, what am i learning today?' - charis: ''

--- 2025-04-11 21:57:17 --- babyLLM 'right, last time i got to step 153... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: 'i am happy i fuckin did it i broke u i am it'

--- 2025-04-11 22:04:25 --- babyLLM 'right, last time i got to step 153... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 22:43:55 --- babyLLM 'right, last time i got to step 153... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 22:57:25 --- babyLLM 'right, last time i got to step 153... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 22:59:10 --- babyLLM 'right, last time i got to step 153... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 23:00:57 --- babyLLM 'right, last time i got to step 153... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 23:07:11 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 23:18:12 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-11 23:25:58 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 23:31:52 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-11 23:37:01 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-11 23:45:53 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-12 00:09:49 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 00:30:51 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-12 00:51:43 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 03:31:34 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 03:38:49 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 07:52:39 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 07:54:51 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:06:38 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:12:48 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:14:59 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:17:32 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:20:17 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:27:30 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:36:20 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:38:00 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:42:32 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:45:35 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 18:04:41 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 21:27:20 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 21:34:00 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 21:49:22 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 21:53:36 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 22:04:11 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:11:11 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:14:31 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:17:30 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:20:57 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:24:50 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:28:07 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:29:53 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:37:10 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:38:09 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:52:46 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:54:39 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:56:09 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 01:00:12 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 02:12:10 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 02:16:40 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-13 02:17:01 | 100 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('together', 3), ('good', 3), ('ont', 3), ('g', 2), ('als', 2), ('in', 2), ('proud', 2), ('ad', 2), ('!?', 2), ('rop', 2)] |  | TUTOR.py 100
2025-04-13 02:17:22 | 200 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('together', 4), ('effort', 4), ('15', 3), ('good', 3), ('tu', 3), ('foc', 3), ('ont', 3), ('ower', 3), ('seeing', 3), ('moment', 3)] |  | TUTOR.py 100
2025-04-13 02:17:44 | 300 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('together', 4), ('effort', 4), ('igh', 4), ('health', 4), ('dunno', 4), ('psych', 4), ('-', 4), ('guess', 4), ('should', 4), ('poss', 4)] |  | TUTOR.py 100
2025-04-13 02:18:06 | 400 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('9', 6), ('together', 5), ('dunno', 5), ('sense', 5), ('g', 4), ('tr', 4), ('effort', 4), ('was', 4), ('ner', 4), ('igh', 4)] |  | TUTOR.py 100
2025-04-13 02:18:30 | 500 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('moment', 6), ('9', 6), ('together', 5), ('ugs', 5), ('dunno', 5), ('ever', 5), ('sense', 5), ('psych', 5), ('-', 5), ('g', 4)] |  | TUTOR.py 100
2025-04-13 02:18:54 | 600 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0001 | scheduledSampling:0.0000 | topTokens[('moment', 6), ('bl', 6), ('dunno', 6), ('9', 6), ('ever', 6), ('-', 6), ('together', 5), ('was', 5), ('ugs', 5), ('cra', 5)] |  | TUTOR.py 100
2025-04-13 02:19:19 | 700 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0001 | scheduledSampling:0.0000 | topTokens[('moment', 7), ('-', 7), ('together', 6), ('bro', 6), ('was', 6), ('bl', 6), ('dunno', 6), ('9', 6), ('ever', 6), ('contro', 6)] |  | TUTOR.py 100
2025-04-13 02:19:44 | 800 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('moment', 7), ('dunno', 7), ('-', 7), ('should', 7), ('together', 6), ('rop', 6), ('bro', 6), ('was', 6), ('bl', 6), ('9', 6)] |  | TUTOR.py 100
2025-04-13 02:20:11 | 900 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('bro', 8), ('together', 7), ('rop', 7), ('moment', 7), ('bl', 7), ('dunno', 7), ('-', 7), ('should', 7), ('was', 6), ('cra', 6)] |  | TUTOR.py 100
2025-04-13 02:20:39 | 1000 | LR0.0003 | loss:0.0760 | gradNorm:0.0054 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0001 | scheduledSampling:0.0000 | topTokens[('bro', 9), ('together', 8), ('moment', 8), ('.', 8), ('ma', 8), ('rop', 7), ('bl', 7), ('dunno', 7), ('9', 7), ('-', 7)] |  | TUTOR.py 100
2025-04-13 02:21:01 | 1100 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('bro', 9), ('together', 8), ('moment', 8), ('leave', 8), ('yes', 8), ('.', 8), ('ma', 8), ('ad', 7), ('rop', 7), ('ont', 7)] |  | TUTOR.py 100
2025-04-13 02:21:24 | 1200 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0003 | scheduledSampling:0.0000 | topTokens[('bro', 10), ('together', 8), ('in', 8), ('ont', 8), ('moment', 8), ('dunno', 8), ('leave', 8), ('yes', 8), ('.', 8), ('should', 8)] |  | TUTOR.py 100
2025-04-13 02:21:47 | 1300 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('bro', 10), ('moment', 9), ('leave', 9), ('ma', 9), ('together', 8), ('in', 8), ('ont', 8), ('dunno', 8), ('yes', 8), ('.', 8)] |  | TUTOR.py 100
2025-04-13 02:22:11 | 1400 | LR0.0003 | loss:0.0759 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('bro', 10), ('moment', 9), ('leave', 9), ('.', 9), ('should', 9), ('ma', 9), ('thanks', 9), ('together', 8), ('in', 8), ('ont', 8)] |  | TUTOR.py 100
2025-04-13 02:22:34 | 1500 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('bro', 10), ('moment', 9), ('happening', 9), ('leave', 9), ('.', 9), ('should', 9), ('few', 9), ('ma', 9), ('thanks', 9), ('together', 8)] |  | TUTOR.py 100
2025-04-13 02:22:59 | 1600 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('bro', 10), ('few', 10), ('thanks', 10), ('in', 9), ('<UNK>', 9), ('moment', 9), ('bl', 9), ('happening', 9), ('leave', 9), ('yes', 9)] |  | TUTOR.py 100
2025-04-13 02:23:24 | 1700 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('bro', 10), ('bl', 10), ('happening', 10), ('yes', 10), ('few', 10), ('thanks', 10), ('in', 9), ('ook', 9), ('<UNK>', 9), ('moment', 9)] |  | TUTOR.py 100
2025-04-13 02:23:49 | 1800 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('bro', 10), ('<UNK>', 10), ('bl', 10), ('happening', 10), ('yes', 10), ('few', 10), ('thanks', 10), ('your', 10), ('together', 9), ('in', 9)] |  | TUTOR.py 100
2025-04-13 02:24:16 | 1900 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('bl', 11), ('your', 11), ('video', 10), ('bro', 10), ('<UNK>', 10), ('happening', 10), ('took', 10), ('leave', 10), ('yes', 10), ('few', 10)] |  | TUTOR.py 100
2025-04-13 02:24:43 | 2000 | LR0.0003 | loss:0.0760 | gradNorm:0.0054 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('video', 11), ('bl', 11), ('your', 11), ('eee', 11), ('get', 11), ('airs', 10), ('bro', 10), ('<UNK>', 10), ('igh', 10), ('happening', 10)] |  | TUTOR.py 100
2025-04-13 02:25:06 | 2100 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0002 | logitMax:0.0003 | scheduledSampling:0.0000 | topTokens[('your', 12), ('eee', 12), ('video', 11), ('bl', 11), ('leave', 11), ('should', 11), ('few', 11), ('tw', 11), ('get', 11), ('ptop', 10)] |  | TUTOR.py 100
2025-04-13 02:25:28 | 2200 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0002 | logitMax:0.0003 | scheduledSampling:0.0000 | topTokens[('eee', 14), ('your', 12), ('video', 11), ('won', 11), ('remember', 11), ('bl', 11), ('forg', 11), ('leave', 11), ('yes', 11), ('should', 11)] |  | TUTOR.py 100
2025-04-13 02:25:51 | 2300 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0002 | logitMax:0.0003 | scheduledSampling:0.0000 | topTokens[('eee', 14), ('forg', 12), ('ten', 12), ('your', 12), ('video', 11), ('won', 11), ('remember', 11), ('slightly', 11), ('bl', 11), ('happening', 11)] |  | TUTOR.py 100
2025-04-13 02:26:14 | 2400 | LR0.0003 | loss:0.0759 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0002 | logitMax:0.0003 | scheduledSampling:0.0000 | topTokens[('eee', 14), ('won', 12), ('forg', 12), ('ten', 12), ('your', 12), ('atter', 12), ('video', 11), ('airs', 11), ('real', 11), ('remember', 11)] |  | TUTOR.py 100

--- 2025-04-13 03:56:26 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-13 03:56:46 | 100 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0001 | scheduledSampling:0.0000 | topTokens[('z', 3), ('est', 3), ('spec', 3), ('said', 3), ('iting', 2), ('basically', 2), ('rel', 2), ('currently', 2), ('few', 2), ('end', 2)] |  | TUTOR.py 100
2025-04-13 03:57:07 | 200 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('ill', 4), ('enjoy', 4), ('getting', 3), ('important', 3), ('ool', 3), ('z', 3), ('ject', 3), ('talk', 3), ('est', 3), ('spec', 3)] |  | TUTOR.py 100
2025-04-13 03:57:28 | 300 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0001 | scheduledSampling:0.0000 | topTokens[('p', 5), ('everything', 4), ('important', 4), ('record', 4), ('ill', 4), ('boi', 4), ('clean', 4), ('enjoy', 4), ('i', 4), ('ger', 4)] |  | TUTOR.py 100
2025-04-13 03:57:51 | 400 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0001 | scheduledSampling:0.0000 | topTokens[('p', 6), ('important', 5), ('se', 5), ('<UNK>', 5), ('brain', 4), ('everything', 4), ('e', 4), ('ass', 4), ('record', 4), ('ill', 4)] |  | TUTOR.py 100
2025-04-13 03:58:16 | 500 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('p', 6), ('asked', 5), ('important', 5), ('est', 5), ('else', 5), ('se', 5), ('mental', 5), ('<UNK>', 5), ('well', 5), ('new', 5)] |  | TUTOR.py 100

--- 2025-04-13 04:02:56 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-13 04:03:17 | 100 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0003 | scheduledSampling:0.0000 | topTokens[('rude', 2), ('g', 2), ('cold', 2), ('aring', 2), (":'(", 2), ('mor', 2), ('her', 2), (':)', 2), ('confused', 2), ('ght', 2)] |  | TUTOR.py 100
2025-04-13 04:03:39 | 200 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0003 | scheduledSampling:0.0000 | topTokens[('idea', 4), ('ual', 4), ('they', 4), ('mor', 3), ('read', 3), ('stu', 3), ('ready', 3), ('ically', 3), ('coming', 3), ('discord', 3)] |  | TUTOR.py 100
2025-04-13 04:04:01 | 300 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0003 | scheduledSampling:0.0000 | topTokens[('stu', 5), ('idea', 4), ('ically', 4), ('ama', 4), ('ig', 4), ('ual', 4), ('they', 4), ('poo', 4), ('laptop', 4), ('ver', 4)] |  | TUTOR.py 100
2025-04-13 04:04:25 | 400 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0003 | scheduledSampling:0.0000 | topTokens[('cold', 5), ('stu', 5), ('ically', 5), ('video', 4), ('idea', 4), ('ather', 4), ('keep', 4), ('df', 4), ('ama', 4), ('ig', 4)] |  | TUTOR.py 100
2025-04-13 04:04:50 | 500 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0003 | scheduledSampling:0.0000 | topTokens[('ama', 6), ('video', 5), ('cold', 5), ('idea', 5), ('ather', 5), ('df', 5), ('usually', 5), ('stu', 5), ('ically', 5), ('laptop', 5)] |  | TUTOR.py 100
2025-04-13 04:05:15 | 600 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0003 | scheduledSampling:0.0000 | topTokens[('ama', 6), ('video', 5), ('per', 5), ('cold', 5), ('idea', 5), ('icul', 5), ('ather', 5), ('df', 5), ('usually', 5), ('stu', 5)] |  | TUTOR.py 100
2025-04-13 04:05:41 | 700 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('ama', 6), ('hon', 6), ('to', 6), ('video', 5), ('per', 5), ('cold', 5), ('idea', 5), ('ake', 5), ('icul', 5), ('ah', 5)] |  | TUTOR.py 100
2025-04-13 04:06:08 | 800 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0003 | scheduledSampling:0.0000 | topTokens[('ah', 7), ('ready', 7), ('ake', 6), ('ama', 6), ('hon', 6), ('to', 6), ('ri', 6), ('video', 5), ('per', 5), ('cold', 5)] |  | TUTOR.py 100
2025-04-13 04:06:36 | 900 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0003 | scheduledSampling:0.0000 | topTokens[('ake', 9), ('.', 8), ('ah', 7), ('ready', 7), ('ible', 7), ('hon', 7), ('low', 7), ('to', 7), ('must', 7), ('ri', 7)] |  | TUTOR.py 100
2025-04-13 04:07:04 | 1000 | LR0.0003 | loss:0.0760 | gradNorm:0.0055 | tokenCount:4.0000 | logitMin:-0.0001 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[('ake', 9), ('.', 8), ('ah', 7), ('iety', 7), ('ready', 7), ('ible', 7), ('act', 7), ('hon', 7), ('mm', 7), ('low', 7)] |  | TUTOR.py 100
2025-04-13 04:07:26 | 1100 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0002 | logitMax:0.0003 | scheduledSampling:0.0000 | topTokens[('ake', 9), ('act', 9), ('.', 9), ('scr', 8), ('elod', 7), ('ah', 7), ('iety', 7), ('ready', 7), ('ible', 7), ('engl', 7)] |  | TUTOR.py 100
2025-04-13 04:07:49 | 1200 | LR0.0003 | loss:0.0760 | gradNorm:0.0051 | tokenCount:4.0000 | logitMin:-0.0002 | logitMax:0.0004 | scheduledSampling:0.0000 | topTokens[('ake', 9), ('act', 9), ('.', 9), ('ah', 8), ('ready', 8), ('scr', 8), ('elod', 7), ('ather', 7), ('iety', 7), ('ically', 7)] |  | TUTOR.py 100
2025-04-13 04:08:12 | 1300 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0002 | logitMax:0.0003 | scheduledSampling:0.0000 | topTokens[('.', 10), ('ake', 9), ('act', 9), ('ah', 8), ('iety', 8), ('ready', 8), ('ible', 8), ('low', 8), ('to', 8), ('scr', 8)] |  | TUTOR.py 100
2025-04-13 04:08:36 | 1400 | LR0.0003 | loss:0.0759 | gradNorm:0.0051 | tokenCount:4.0000 | logitMin:-0.0002 | logitMax:0.0005 | scheduledSampling:0.0000 | topTokens[('.', 10), ('to', 10), ('ake', 9), ('iety', 9), ('act', 9), ('ah', 8), ('ready', 8), ('ouse', 8), ('ible', 8), ('engl', 8)] |  | TUTOR.py 100
2025-04-13 04:09:01 | 1500 | LR0.0003 | loss:0.0759 | gradNorm:0.0051 | tokenCount:4.0000 | logitMin:-0.0002 | logitMax:0.0003 | scheduledSampling:0.0000 | topTokens[('iety', 10), ('act', 10), ('.', 10), ('to', 10), ('ake', 9), ('ose', 9), ('ah', 8), ('ready', 8), ('ouse', 8), ('ible', 8)] |  | TUTOR.py 100
2025-04-13 04:09:29 | 1600 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0002 | logitMax:0.0003 | scheduledSampling:0.0000 | topTokens[('iety', 10), ('ose', 10), ('act', 10), ('.', 10), ('to', 10), ('ake', 9), ('scr', 9), ('remember', 9), ('ah', 8), ('ready', 8)] |  | TUTOR.py 100
2025-04-13 04:09:54 | 1700 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0002 | logitMax:0.0003 | scheduledSampling:0.0000 | topTokens[('ose', 11), ('iety', 10), ('act', 10), ('.', 10), ('to', 10), ('remember', 10), ('comput', 10), ('ake', 9), ('ah', 9), ('engl', 9)] |  | TUTOR.py 100
2025-04-13 04:10:19 | 1800 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0002 | logitMax:0.0003 | scheduledSampling:0.0000 | topTokens[('ose', 11), ('remember', 11), ('iety', 10), ('engl', 10), ('act', 10), ('.', 10), ('to', 10), ('comput', 10), ('ake', 9), ('ah', 9)] |  | TUTOR.py 100
2025-04-13 04:10:47 | 1900 | LR0.0003 | loss:0.0759 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0002 | logitMax:0.0005 | scheduledSampling:0.0000 | topTokens[('ose', 11), ('.', 11), ('remember', 11), ('ake', 10), ('mom', 10), ('iety', 10), ('engl', 10), ('act', 10), ('to', 10), ('ign', 10)] |  | TUTOR.py 100
2025-04-13 04:11:15 | 2000 | LR0.0003 | loss:0.0760 | gradNorm:0.0055 | tokenCount:4.0000 | logitMin:-0.0002 | logitMax:0.0004 | scheduledSampling:0.0000 | topTokens[('ose', 12), ('.', 12), ('to', 11), ('remember', 11), ('ake', 10), ('mom', 10), ('iety', 10), ('engl', 10), ('act', 10), ('fl', 10)] |  | TUTOR.py 100
2025-04-13 04:11:37 | 2100 | LR0.0003 | loss:0.0760 | gradNorm:0.0051 | tokenCount:4.0000 | logitMin:-0.0003 | logitMax:0.0005 | scheduledSampling:0.0000 | topTokens[('.', 13), ('ose', 12), ('act', 11), ('to', 11), ('remember', 11), ('ake', 10), ('ah', 10), ('mom', 10), ('iety', 10), ('rant', 10)] |  | TUTOR.py 100
2025-04-13 04:11:59 | 2200 | LR0.0003 | loss:0.0760 | gradNorm:0.0050 | tokenCount:4.0000 | logitMin:-0.0002 | logitMax:0.0004 | scheduledSampling:0.0000 | topTokens[('.', 13), ('ose', 12), ('engl', 11), ('act', 11), ('fl', 11), ('to', 11), ('less', 11), ('blue', 11), ('remember', 11), ('ake', 10)] |  | TUTOR.py 100
2025-04-13 04:12:23 | 2300 | LR0.0003 | loss:0.0760 | gradNorm:0.0051 | tokenCount:4.0000 | logitMin:-0.0003 | logitMax:0.0005 | scheduledSampling:0.0000 | topTokens[('.', 14), ('ose', 12), ('fl', 12), ('blue', 12), ('engl', 11), ('act', 11), ('to', 11), ('asking', 11), ('less', 11), ('ffect', 11)] |  | TUTOR.py 100
2025-04-13 04:12:46 | 2400 | LR0.0003 | loss:0.0759 | gradNorm:0.0051 | tokenCount:4.0000 | logitMin:-0.0003 | logitMax:0.0006 | scheduledSampling:0.0000 | topTokens[('.', 14), ('ose', 12), ('fl', 12), ('to', 12), ('blue', 12), ('mix', 12), ('cond', 11), ('engl', 11), ('act', 11), ('birth', 11)] |  | TUTOR.py 100

--- 2025-04-13 17:57:51 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-13 18:06:26 | 500 | LR0.0003 | loss:0.1484 | gradNorm:8.5033 | tokenCount:18.0000 | logitMin:-1.5456 | logitMax:-1.3324 | scheduledSampling:0.0000 | topTokens[('angle', 1731), ('wind', 68), (1067, 18), ('reme', 1)] |  | TUTOR.py 500

--- 2025-04-13 18:10:11 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 18:18:19 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 18:25:18 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 18:37:48 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-13 18:46:31 | 500 | LR0.0003 | loss:0.1430 | gradNorm:8.4731 | tokenCount:18.0000 | logitMin:-1.5052 | logitMax:-1.2995 | scheduledSampling:0.0000 | topTokens[('angle', 1727), ('wind', 62), (1067, 18), ('reme', 11)] |  | TUTOR.py 500

--- 2025-04-13 19:05:54 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 19:09:44 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 19:17:41 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 19:18:54 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 19:40:46 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 20:08:41 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 20:19:22 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 20:23:02 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 20:24:39 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 20:46:12 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 21:02:51 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 21:13:30 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 22:22:24 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 22:33:39 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 23:01:45 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 23:09:26 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 23:32:12 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 23:33:58 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 23:40:23 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 23:44:21 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 23:49:32 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 00:14:49 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 00:31:54 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 00:44:49 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 00:55:21 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 00:58:24 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 01:00:23 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-14 01:03:40 | 50 | LR0.0003 | loss:9.1100 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-42.3672 | logitMax:13.2697 | scheduledSampling:0.0000 | topTokens[('-', 74), ('in', 74), ('up', 46), ('ired', 42), ('le', 33), ('ad', 31), ('fre', 23), ('gr', 22), ('x', 21), ('ers', 21)] |  | TUTOR.py 50
2025-04-14 01:07:20 | 100 | LR0.0003 | loss:4.7135 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-78.2605 | logitMax:17.5440 | scheduledSampling:0.0000 | topTokens[('up', 113), ('in', 112), ('-', 76), ('es', 73), ('sy', 55), ('the', 51), ('h', 51), ('ired', 42), ('and', 40), ('x', 34)] |  | TUTOR.py 50

--- 2025-04-14 01:13:12 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-14 01:16:22 | 50 | LR0.0003 | loss:3.5923 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-44.5540 | logitMax:7.6235 | scheduledSampling:0.0000 | topTokens[('-', 64), ('le', 46), ('em', 42), ('in', 36), ('hs', 33), ('p', 29), ('es', 26), ('en', 25), ('ical', 24), ('d', 20)] |  | TUTOR.py 50

--- 2025-04-14 01:19:49 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-14 01:22:59 | 50 | LR0.0003 | loss:1.7959 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-32.3183 | logitMax:9.1093 | scheduledSampling:0.0000 | topTokens[('em', 57), ('in', 57), ('lling', 43), ('-', 41), ('sy', 36), ('ins', 35), ('m', 34), ('ath', 25), ('ci', 21), ('ired', 20)] |  | TUTOR.py 50
2025-04-14 01:26:14 | 100 | LR0.0003 | loss:2.3474 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-36.0890 | logitMax:8.6868 | scheduledSampling:0.0000 | topTokens[('in', 82), ('em', 72), ('nt', 64), ('sy', 62), ('the', 60), ('es', 59), ('-', 57), ('lling', 43), ('h', 42), ('and', 40)] |  | TUTOR.py 50

--- 2025-04-14 01:53:36 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 01:57:25 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-14 01:58:06 | 50 | LR0.0003 | loss:0.2368 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-1.4101 | logitMax:-0.3296 | scheduledSampling:0.0000 | topTokens[('she', 43), ('s', 33), ('d', 30), ('!', 29), ('we', 25), ('they', 20), ('your', 20), ('i', 20), ('you', 17), ('an', 17)] |  | TUTOR.py 50
2025-04-14 01:58:48 | 100 | LR0.0003 | loss:0.2459 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-1.4978 | logitMax:-0.2854 | scheduledSampling:0.0000 | topTokens[('s', 93), ('she', 92), ('!', 69), ('d', 55), ('and', 44), ('it', 43), ('we', 43), ('an', 42), ('your', 41), ('know', 41)] |  | TUTOR.py 50
2025-04-14 01:59:31 | 150 | LR0.0003 | loss:0.2321 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-1.4756 | logitMax:-0.3498 | scheduledSampling:0.0000 | topTokens[('s', 121), ('she', 106), ('es', 102), ('!', 94), ('d', 82), ('a', 75), ('h', 74), ('and', 71), ('up', 68), ('an', 66)] |  | TUTOR.py 50
2025-04-14 02:00:13 | 200 | LR0.0003 | loss:0.2952 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-1.4731 | logitMax:-0.3742 | scheduledSampling:0.0000 | topTokens[('es', 143), ('s', 136), ('!', 127), ('she', 122), ('the', 107), ('d', 105), ('a', 100), ('this', 94), ('h', 88), ('up', 84)] |  | TUTOR.py 50
2025-04-14 02:00:56 | 250 | LR0.0003 | loss:0.1787 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-1.5085 | logitMax:-0.3727 | scheduledSampling:0.0000 | topTokens[('es', 187), ('s', 146), ('!', 136), ('a', 133), ('she', 130), ('d', 118), ('the', 118), ('h', 114), ('and', 111), ('this', 99)] |  | TUTOR.py 50
2025-04-14 02:01:38 | 300 | LR0.0003 | loss:0.2285 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-1.5170 | logitMax:-0.3843 | scheduledSampling:0.0000 | topTokens[('es', 223), ('s', 154), ('a', 154), ('to', 145), ('!', 143), ('h', 143), ('the', 137), ('she', 132), (',', 125), ('and', 121)] |  | TUTOR.py 50

--- 2025-04-14 02:03:03 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-14 02:03:53 | 50 | LR0.0003 | loss:0.1251 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-1.5899 | logitMax:-0.4894 | scheduledSampling:0.0000 | topTokens[('it', 49), ('-', 44), ('nt', 42), ('!', 39), ('sy', 36), ('or', 34), ('the', 28), ('p', 28), ('pro', 20), ('by', 19)] |  | TUTOR.py 50
2025-04-14 02:04:44 | 100 | LR0.0003 | loss:0.1229 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-1.6447 | logitMax:-0.4288 | scheduledSampling:0.0000 | topTokens[('es', 100), ('nt', 95), ('sy', 92), ('the', 66), ('-', 63), ('and', 61), ('it', 58), ('h', 55), ('h', 41), ('iz', 41)] |  | TUTOR.py 50
2025-04-14 02:05:34 | 150 | LR0.0003 | loss:0.1423 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-1.5935 | logitMax:-0.4645 | scheduledSampling:0.0000 | topTokens[('the', 120), ('es', 118), ('nt', 110), ('sy', 109), ('and', 82), ('-', 79), ('it', 73), ('iz', 70), ('h', 68), ('h', 58)] |  | TUTOR.py 50
2025-04-14 02:06:24 | 200 | LR0.0003 | loss:0.1408 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-1.5599 | logitMax:-0.5012 | scheduledSampling:0.0000 | topTokens[('es', 159), ('the', 159), ('sy', 141), ('nt', 139), ('-', 102), ('h', 98), ('and', 94), ('iz', 83), ('it', 82), ('ed', 73)] |  | TUTOR.py 50
2025-04-14 02:07:16 | 250 | LR0.0003 | loss:0.1180 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-1.5884 | logitMax:-0.4608 | scheduledSampling:0.0000 | topTokens[('es', 179), ('the', 172), ('sy', 155), ('nt', 144), ('-', 114), ('and', 106), ('h', 103), ('to', 88), ('iz', 87), ('it', 86)] |  | TUTOR.py 50
2025-04-14 02:08:06 | 300 | LR0.0003 | loss:0.1385 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-1.5366 | logitMax:-0.4533 | scheduledSampling:0.0000 | topTokens[('the', 222), ('es', 193), ('sy', 174), ('nt', 153), ('-', 133), ('and', 123), ('to', 120), ('h', 120), ('.', 99), ('a', 96)] |  | TUTOR.py 50
2025-04-14 02:08:57 | 350 | LR0.0003 | loss:0.1600 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-1.5168 | logitMax:-0.4627 | scheduledSampling:0.0000 | topTokens[('the', 232), ('es', 212), ('sy', 179), ('nt', 157), ('-', 138), ('and', 137), ('to', 131), ('h', 122), ('.', 120), ('a', 119)] |  | TUTOR.py 50
2025-04-14 02:09:50 | 400 | LR0.0003 | loss:0.1732 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-1.5771 | logitMax:-0.5644 | scheduledSampling:0.0000 | topTokens[('the', 239), ('es', 217), ('sy', 185), ('nt', 173), ('-', 147), ('a', 142), ('and', 140), ('to', 132), ('.', 130), ('h', 129)] |  | TUTOR.py 50
2025-04-14 02:10:42 | 450 | LR0.0003 | loss:0.1875 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-1.5077 | logitMax:-0.5144 | scheduledSampling:0.0000 | topTokens[('the', 243), ('es', 221), ('sy', 192), ('nt', 180), ('and', 159), ('-', 158), ('a', 154), (',', 150), ('.', 144), ('h', 138)] |  | TUTOR.py 50

--- 2025-04-14 02:23:50 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 02:34:44 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 02:41:37 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-14 02:44:52 | 50 | LR0.0003 | loss:2.4403 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-19.4086 | logitMax:5.8048 | scheduledSampling:0.0000 | topTokens[('in', 61), ('l', 41), ('the', 35), ('sy', 34), ('h', 34), ('nt', 32), ('-', 30), ('le', 26), ('em', 25), ('qu', 21)] |  | TUTOR.py 50
2025-04-14 02:48:22 | 100 | LR0.0003 | loss:0.8261 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-29.6208 | logitMax:6.1606 | scheduledSampling:0.0000 | topTokens[('in', 125), ('l', 74), ('nt', 68), ('h', 68), ('the', 58), ('and', 55), ('sy', 52), ('es', 50), ('comp', 47), ('id', 38)] |  | TUTOR.py 50
2025-04-14 02:51:46 | 150 | LR0.0003 | loss:4.2642 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-21.0729 | logitMax:5.5122 | scheduledSampling:0.0000 | topTokens[('in', 196), ('-', 123), ('es', 96), ('the', 95), ('h', 75), ('l', 74), ('nt', 72), ('s', 71), ('and', 65), ('comp', 55)] |  | TUTOR.py 50
2025-04-14 02:55:06 | 200 | LR0.0003 | loss:2.7132 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-3.5168 | logitMax:1.0773 | scheduledSampling:0.0000 | topTokens[('in', 297), ('thing', 256), ('es', 159), ('-', 153), ('the', 144), ('nt', 116), ('h', 90), ('l', 74), ('s', 73), ('and', 65)] |  | TUTOR.py 50
2025-04-14 02:58:26 | 250 | LR0.0003 | loss:7.8358 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-8.6933 | logitMax:9.9708 | scheduledSampling:0.0000 | topTokens[('thing', 697), ('in', 553), ('nt', 183), ('-', 165), ('es', 159), ('the', 144), ('up', 115), ('h', 90), ('l', 74), ('s', 73)] |  | TUTOR.py 50

--- 2025-04-14 03:00:39 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-14 03:03:56 | 50 | LR0.0003 | loss:2.7579 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-25.5105 | logitMax:5.9937 | scheduledSampling:0.0000 | topTokens[('in', 364), ('thing', 241), ('ath', 87), ('i', 63), ('the', 33), (',', 33), ('en', 18), ('!', 14), ('h', 10), ('h', 9)] |  | TUTOR.py 50

--- 2025-04-14 03:05:54 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:08:14 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-14 03:11:45 | 50 | LR0.0003 | loss:0.8758 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-37.1863 | logitMax:9.5672 | scheduledSampling:0.0000 | topTokens[('i', 139), ('it', 108), ('!', 88), (',', 79), ('.', 64), ('am', 52), ('know', 50), ('thing', 45), ('happy', 40), ('feel', 36)] |  | TUTOR.py 50
2025-04-14 03:15:24 | 100 | LR0.0003 | loss:1.0495 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-28.6795 | logitMax:12.0547 | scheduledSampling:0.0000 | topTokens[('i', 252), ('!', 182), ('it', 175), ('know', 126), ('.', 100), ('am', 86), (',', 83), ('feel', 77), ('thing', 75), ('did', 75)] |  | TUTOR.py 50

--- 2025-04-14 03:18:34 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:21:14 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:25:50 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:29:37 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-14 03:33:03 | 50 | LR0.0003 | loss:3.1888 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-4.3755 | logitMax:4.6134 | scheduledSampling:0.0000 | topTokens[('can', 121), ('f', 76), ('!', 70), ('the', 40), ('it', 39), ('we', 37), ('smink', 36), ('touch', 36), ('break', 34), ('love', 30)] |  | TUTOR.py 50

--- 2025-04-14 03:39:54 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:42:28 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:43:35 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-14 03:46:45 | 50 | LR0.0003 | loss:2.2612 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-23.3620 | logitMax:2.6662 | scheduledSampling:0.0000 | topTokens[('can', 114), ('!', 62), ('hear', 61), (',', 61), ('the', 60), ('from', 54), ('we', 52), ('i', 41), ('er', 38), ('it', 34)] |  | TUTOR.py 50

--- 2025-04-14 03:49:18 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-14 03:52:29 | 50 | LR0.0003 | loss:1.7062 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-26.2870 | logitMax:2.7100 | scheduledSampling:0.0000 | topTokens[('can', 146), ('it', 44), ('from', 43), ('we', 43), (',', 38), ('.', 38), ('!', 36), ('the', 33), ('weed', 32), ('break', 31)] |  | TUTOR.py 50

--- 2025-04-14 03:53:21 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:55:08 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:57:32 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 04:08:55 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 04:13:38 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-14 04:14:00 | 50 | LR0.0003 | loss:32974.0742 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-4834.4795 | logitMax:32963.7461 | scheduledSampling:0.0000 | topTokens[('thing', 900), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50

--- 2025-04-14 04:14:41 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-14 04:15:03 | 50 | LR0.0003 | loss:31510.3047 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-4529.8447 | logitMax:31975.9277 | scheduledSampling:0.0000 | topTokens[('thing', 900), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50
2025-04-14 04:15:25 | 100 | LR0.0003 | loss:30229.1445 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-3505.7769 | logitMax:27427.2695 | scheduledSampling:0.0000 | topTokens[('thing', 1800), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50
2025-04-14 04:15:48 | 150 | LR0.0003 | loss:24118.1074 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-3087.9788 | logitMax:23638.9531 | scheduledSampling:0.0000 | topTokens[('thing', 2700), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50
2025-04-14 04:16:10 | 200 | LR0.0003 | loss:28404.9941 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-4041.6418 | logitMax:29678.3203 | scheduledSampling:0.0000 | topTokens[('thing', 3600), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50
2025-04-14 04:16:33 | 250 | LR0.0003 | loss:28374.7852 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-4149.3765 | logitMax:29924.9141 | scheduledSampling:0.0000 | topTokens[('thing', 4500), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50
2025-04-14 04:16:55 | 300 | LR0.0003 | loss:25934.3398 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-3835.9326 | logitMax:26175.0156 | scheduledSampling:0.0000 | topTokens[('thing', 5400), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50
2025-04-14 04:17:18 | 350 | LR0.0003 | loss:26208.3105 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-3382.8013 | logitMax:27145.1680 | scheduledSampling:0.0000 | topTokens[('thing', 6300), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50
2025-04-14 04:17:40 | 400 | LR0.0003 | loss:24391.7617 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-3511.2009 | logitMax:26984.0254 | scheduledSampling:0.0000 | topTokens[('thing', 7200), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50
2025-04-14 04:18:02 | 450 | LR0.0003 | loss:22591.1367 | gradNorm:0.0200 | tokenCount:18.0000 | logitMin:-3706.3269 | logitMax:27719.8691 | scheduledSampling:0.0000 | topTokens[('thing', 8100), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50

--- 2025-04-14 04:24:10 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-14 04:24:32 | 50 | LR0.0003 | loss:31510.3047 | logitMin:-4529.8447 | logitMax:31975.9277 | scheduledSampling:0.0000 | topTokens[('thing', 900), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50
2025-04-14 04:24:54 | 100 | LR0.0003 | loss:30229.1445 | logitMin:-3505.7769 | logitMax:27427.2695 | scheduledSampling:0.0000 | topTokens[('thing', 1800), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50

--- 2025-04-14 04:25:26 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-14 04:25:48 | 50 | LR0.0003 | logitMin:-4529.8447 | logitMax:31975.9277 | scheduledSampling:0.0000 | topTokens[('thing', 900), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50
2025-04-14 04:26:10 | 100 | LR0.0003 | logitMin:-3505.7769 | logitMax:27427.2695 | scheduledSampling:0.0000 | topTokens[('thing', 1800), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50
2025-04-14 04:26:32 | 150 | LR0.0003 | logitMin:-3087.9788 | logitMax:23638.9531 | scheduledSampling:0.0000 | topTokens[('thing', 2700), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50
2025-04-14 04:26:55 | 200 | LR0.0003 | logitMin:-4041.6418 | logitMax:29678.3203 | scheduledSampling:0.0000 | topTokens[('thing', 3600), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50
2025-04-14 04:27:17 | 250 | LR0.0003 | logitMin:-4149.3765 | logitMax:29924.9141 | scheduledSampling:0.0000 | topTokens[('thing', 4500), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50
2025-04-14 04:27:40 | 300 | LR0.0003 | logitMin:-3835.9326 | logitMax:26175.0156 | scheduledSampling:0.0000 | topTokens[('thing', 5400), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50
2025-04-14 04:28:03 | 350 | LR0.0003 | logitMin:-3382.8013 | logitMax:27145.1680 | scheduledSampling:0.0000 | topTokens[('thing', 6300), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50
2025-04-14 04:28:26 | 400 | LR0.0003 | logitMin:-3511.2009 | logitMax:26984.0254 | scheduledSampling:0.0000 | topTokens[('thing', 7200), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50
2025-04-14 04:28:49 | 450 | LR0.0003 | logitMin:-3706.3269 | logitMax:27719.8691 | scheduledSampling:0.0000 | topTokens[('thing', 8100), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1), (tensor([[359]], device='mps:0'), 1)] |  | TUTOR.py 50

--- 2025-04-14 04:41:47 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 04:42:49 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 04:43:12 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 04:54:54 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 05:17:58 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 05:18:58 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 05:22:37 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 05:25:58 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 05:26:59 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 05:29:13 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 05:31:25 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 05:33:05 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 05:40:06 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 15:55:06 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 16:08:06 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 16:25:42 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 16:29:51 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-14 16:31:01 | 20 | LR0.0003 | logitMin:-17930.6367 | logitMax:10010.2578 | scheduledSampling:0.0000 | topTokens[('can', 47), ('!', 26), ('we', 24), ('it', 19), ('i', 18), ('n', 18), (',', 16), ('in', 16), ('creat', 16), ('from', 16)] |  | TUTOR.py 20
2025-04-14 16:32:15 | 40 | LR0.0003 | logitMin:-22329.6211 | logitMax:29321.7754 | scheduledSampling:0.0000 | topTokens[('can', 93), ('!', 58), ('we', 41), ('with', 28), ('it', 25), ('walk', 24), ('elodie', 23), ('it', 19), ('.', 19), ('i', 18)] |  | TUTOR.py 20
2025-04-14 16:33:29 | 60 | LR0.0003 | logitMin:-14262.1191 | logitMax:11776.0879 | scheduledSampling:0.0000 | topTokens[('can', 156), ('!', 81), ('we', 76), (',', 59), ('it', 55), ('elodie', 46), ('love', 37), ('i', 36), ('our', 32), ('friends', 30)] |  | TUTOR.py 20
2025-04-14 16:34:44 | 80 | LR0.0003 | logitMin:-15171.2002 | logitMax:7420.7227 | scheduledSampling:0.0000 | topTokens[('can', 208), ('!', 126), ('we', 76), (',', 73), ('elodie', 73), ('it', 62), ('love', 42), ('i', 37), ('our', 32), ('friends', 30)] |  | TUTOR.py 20
2025-04-14 16:36:02 | 100 | LR0.0003 | logitMin:-13652.7344 | logitMax:7702.2354 | scheduledSampling:0.0000 | topTokens[('can', 248), ('!', 158), ('we', 76), (',', 74), ('elodie', 73), ('it', 62), ('i', 44), ('from', 42), ('love', 42), ('kevin', 42)] |  | TUTOR.py 20
2025-04-14 16:37:21 | 120 | LR0.0003 | logitMin:-13359.6123 | logitMax:7645.8623 | scheduledSampling:0.0000 | topTokens[('can', 298), ('!', 160), (',', 127), ('we', 76), ('elodie', 73), ('i', 70), ('it', 62), ('move', 58), ('kevin', 58), ('the', 47)] |  | TUTOR.py 20
2025-04-14 16:38:38 | 140 | LR0.0003 | logitMin:-13037.9717 | logitMax:7132.7041 | scheduledSampling:0.0000 | topTokens[('can', 334), ('!', 182), (',', 127), ('we', 76), ('elodie', 73), ('i', 70), ('it', 62), ('from', 62), ('kevin', 61), ('charis', 58)] |  | TUTOR.py 20
2025-04-14 16:39:55 | 160 | LR0.0003 | logitMin:-13641.3232 | logitMax:9256.0332 | scheduledSampling:0.0000 | topTokens[('can', 381), ('!', 207), (',', 169), ('charis', 88), ('we', 76), ('elodie', 73), ('i', 70), ('the', 66), ('it', 62), ('from', 62)] |  | TUTOR.py 20
2025-04-14 16:41:12 | 180 | LR0.0003 | logitMin:-14088.6465 | logitMax:9002.8477 | scheduledSampling:0.0000 | topTokens[('can', 443), ('!', 224), (',', 184), ('charis', 145), ('we', 79), ('it', 79), ('elodie', 73), ('i', 70), ('the', 66), ('from', 62)] |  | TUTOR.py 20
2025-04-14 16:42:28 | 200 | LR0.0003 | logitMin:-13090.3740 | logitMax:6760.9243 | scheduledSampling:0.0000 | topTokens[('can', 489), (',', 250), ('!', 229), ('charis', 145), ('i', 88), ('we', 84), ('it', 79), ('elodie', 73), ('kevin', 73), ('the', 69)] |  | TUTOR.py 20
2025-04-14 16:43:44 | 220 | LR0.0003 | logitMin:-13314.3828 | logitMax:6892.6851 | scheduledSampling:0.0000 | topTokens[('can', 539), ('!', 274), (',', 250), ('charis', 145), ('we', 107), ('he', 89), ('i', 88), ('the', 88), ('it', 79), ('move', 75)] |  | TUTOR.py 20
2025-04-14 16:45:00 | 240 | LR0.0003 | logitMin:-14328.5654 | logitMax:7307.6655 | scheduledSampling:0.0000 | topTokens[('can', 576), ('!', 282), (',', 250), ('charis', 181), ('we', 107), ('weed', 99), ('he', 89), ('i', 88), ('the', 88), ('elodie', 84)] |  | TUTOR.py 20
2025-04-14 16:46:16 | 260 | LR0.0003 | logitMin:-13510.4004 | logitMax:8060.9033 | scheduledSampling:0.0000 | topTokens[('can', 632), ('!', 310), (',', 259), ('charis', 187), ('weed', 108), ('we', 107), ('elodie', 92), ('kevin', 91), ('he', 89), ('i', 88)] |  | TUTOR.py 20
2025-04-14 16:47:34 | 280 | LR0.0003 | logitMin:-12432.7422 | logitMax:6979.7812 | scheduledSampling:0.0000 | topTokens[('can', 673), ('!', 349), (',', 265), ('charis', 211), ('weed', 157), ('we', 122), ('he', 105), ('kevin', 103), ('.', 96), ('love', 95)] |  | TUTOR.py 20

--- 2025-04-14 16:48:16 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-14 16:49:29 | 20 | LR0.0003 | logitMin:-13047.9082 | logitMax:5901.7559 | scheduledSampling:0.0000 | topTokens[('can', 54), ('i', 25), ('the', 23), ('!', 21), ('n', 20), ('an', 17), ('er', 17), ('lear', 16), ('from', 16), (',', 14)] |  | TUTOR.py 20
2025-04-14 16:50:46 | 40 | LR0.0003 | logitMin:-13253.3496 | logitMax:6888.9502 | scheduledSampling:0.0000 | topTokens[('can', 101), ('!', 50), (',', 33), ('it', 30), ('elodie', 29), ('the', 26), ('i', 25), ('we', 24), ('f', 23), ('walk', 21)] |  | TUTOR.py 20
2025-04-14 16:52:03 | 60 | LR0.0003 | logitMin:-14995.7158 | logitMax:7568.1729 | scheduledSampling:0.0000 | topTokens[('can', 160), ('!', 79), (',', 61), ('elodie', 55), ('it', 43), ('i', 41), ('love', 40), ('we', 38), ('move', 27), ('the', 26)] |  | TUTOR.py 20
2025-04-14 16:53:20 | 80 | LR0.0003 | logitMin:-14704.4658 | logitMax:6557.5259 | scheduledSampling:0.0000 | topTokens[('can', 209), ('!', 124), ('elodie', 77), (',', 75), ('it', 47), ('i', 41), ('love', 40), ('move', 39), ('we', 38), ('charis', 33)] |  | TUTOR.py 20
2025-04-14 16:54:39 | 100 | LR0.0003 | logitMin:-13454.3418 | logitMax:7070.5654 | scheduledSampling:0.0000 | topTokens[('can', 267), ('!', 158), ('elodie', 77), (',', 75), ('move', 55), ('kevin', 54), ('it', 47), ('butt', 46), ('the', 45), ('i', 43)] |  | TUTOR.py 20
2025-04-14 16:55:57 | 120 | LR0.0003 | logitMin:-20690.1211 | logitMax:19897.1133 | scheduledSampling:0.0000 | topTokens[('can', 329), ('!', 174), (',', 103), ('the', 86), ('elodie', 77), ('move', 76), ('kevin', 72), ('i', 61), ('it', 47), ('butt', 46)] |  | TUTOR.py 20
2025-04-14 16:57:15 | 140 | LR0.0003 | logitMin:-12009.1934 | logitMax:5141.5986 | scheduledSampling:0.0000 | topTokens[('can', 359), ('!', 201), (',', 108), ('the', 86), ('elodie', 77), ('move', 76), ('kevin', 72), ('charis', 68), ('.', 65), ('i', 61)] |  | TUTOR.py 20
2025-04-14 16:58:33 | 160 | LR0.0003 | logitMin:-12150.2695 | logitMax:6293.4775 | scheduledSampling:0.0000 | topTokens[('can', 413), ('!', 220), (',', 138), ('charis', 113), ('the', 100), ('elodie', 77), ('move', 76), ('kevin', 72), ('.', 65), ('i', 61)] |  | TUTOR.py 20

--- 2025-04-14 16:59:26 --- babyLLM 'right, last time i got to step 1... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 1! what am i learning today?' - charis: ''
2025-04-14 17:00:40 | 20 | LR0.0003 | logitMin:-13770.2861 | logitMax:6882.3047 | scheduledSampling:0.0000 | topTokens[('can', 43), ('from', 33), ('mix', 23), ('!', 21), ('the', 20), ('i', 19), ('music', 19), (',', 16), ('n', 15), ('lear', 14)] |  | TUTOR.py 20
2025-04-14 17:01:57 | 40 | LR0.0003 | logitMin:-13456.0342 | logitMax:6329.0034 | scheduledSampling:0.0000 | topTokens[('can', 94), ('!', 59), ('it', 43), (',', 33), ('from', 33), ('we', 31), ('elodie', 27), ('the', 26), ('mix', 23), ('i', 19)] |  | TUTOR.py 20
2025-04-14 17:03:13 | 60 | LR0.0003 | logitMin:-20296.3477 | logitMax:11648.3848 | scheduledSampling:0.0000 | topTokens[('can', 148), (',', 80), ('!', 77), ('it', 64), ('elodie', 49), ('we', 47), ('from', 33), ('i', 33), ('love', 29), ('move', 29)] |  | TUTOR.py 20
2025-04-14 17:04:30 | 80 | LR0.0003 | logitMin:-12713.9531 | logitMax:7469.2490 | scheduledSampling:0.0000 | topTokens[('can', 194), ('!', 126), (',', 83), ('it', 72), ('elodie', 66), ('we', 47), ('i', 40), ('move', 36), ('charis', 33), ('from', 33)] |  | TUTOR.py 20
2025-04-14 17:05:48 | 100 | LR0.0003 | logitMin:-14186.2285 | logitMax:6182.5444 | scheduledSampling:0.0000 | topTokens[('can', 251), ('!', 154), (',', 88), ('it', 72), ('elodie', 72), ('move', 58), ('kevin', 55), ('from', 52), ('i', 48), ('we', 47)] |  | TUTOR.py 20
2025-04-14 17:07:07 | 120 | LR0.0003 | logitMin:-20691.6250 | logitMax:18128.4590 | scheduledSampling:0.0000 | topTokens[('can', 301), ('!', 170), (',', 119), ('from', 86), ('the', 78), ('move', 76), ('it', 72), ('elodie', 72), ('kevin', 65), ('i', 51)] |  | TUTOR.py 20
2025-04-14 17:08:24 | 140 | LR0.0003 | logitMin:-11282.1377 | logitMax:6330.7314 | scheduledSampling:0.0000 | topTokens[('can', 346), ('!', 184), (',', 119), ('the', 96), ('from', 86), ('move', 76), ('it', 72), ('elodie', 72), ('kevin', 65), ('charis', 60)] |  | TUTOR.py 20
2025-04-14 17:09:43 | 160 | LR0.0003 | logitMin:-11593.5957 | logitMax:7230.9229 | scheduledSampling:0.0000 | topTokens[('can', 397), ('!', 198), (',', 157), ('charis', 97), ('the', 96), ('from', 86), ('move', 76), ('it', 72), ('elodie', 72), ('kevin', 65)] |  | TUTOR.py 20
2025-04-14 17:11:01 | 180 | LR0.0003 | logitMin:-11067.8037 | logitMax:6099.2295 | scheduledSampling:0.0000 | topTokens[('can', 456), ('!', 218), (',', 190), ('charis', 127), ('the', 111), ('it', 90), ('from', 87), ('move', 76), ('elodie', 72), ('he', 69)] |  | TUTOR.py 20
2025-04-14 17:12:22 | 200 | LR0.0003 | logitMin:-11092.3652 | logitMax:6545.4829 | scheduledSampling:0.0000 | topTokens[('can', 498), ('!', 231), (',', 230), ('charis', 136), ('the', 111), ('move', 91), ('it', 90), ('from', 87), ('kevin', 80), ('elodie', 72)] |  | TUTOR.py 20
2025-04-14 17:13:43 | 220 | LR0.0003 | logitMin:-10856.5322 | logitMax:6393.7290 | scheduledSampling:0.0000 | topTokens[('can', 558), ('!', 261), (',', 231), ('charis', 137), ('the', 126), ('move', 97), ('it', 90), ('from', 87), ('he', 85), ('we', 84)] |  | TUTOR.py 20

--- 2025-04-14 17:14:18 --- babyLLM 'right, last time i got to step 2... want to restart from there?'  - charis: '220' - babyLLM 'damn that's specific! heading to step 220... what am i learning today?' - charis: ''
2025-04-14 17:15:33 | 20 | LR0.0003 | logitMin:-12276.0176 | logitMax:6091.7480 | scheduledSampling:0.0000 | topTokens[('can', 51), ('weed', 32), ('charis', 27), ('.', 23), ('your', 18), ('you', 17), ('from', 17), ('king', 17), ('take', 16), ('my', 16)] |  | TUTOR.py 20
2025-04-14 17:16:50 | 40 | LR0.0003 | logitMin:-11322.2393 | logitMax:5581.5781 | scheduledSampling:0.0000 | topTokens[('can', 101), ('weed', 60), ('!', 41), ('king', 37), ('charis', 34), ('take', 34), ('your', 32), ('smo', 32), ('.', 31), ('you', 30)] |  | TUTOR.py 20
2025-04-14 17:18:07 | 60 | LR0.0003 | logitMin:-10043.3467 | logitMax:6760.8813 | scheduledSampling:0.0000 | topTokens[('can', 151), ('weed', 107), ('!', 71), ('.', 53), ('charis', 53), ('king', 53), ('smo', 46), ('your', 39), ('love', 37), ('take', 34)] |  | TUTOR.py 20
2025-04-14 17:19:25 | 80 | LR0.0003 | logitMin:-9449.8838 | logitMax:5923.8486 | scheduledSampling:0.0000 | topTokens[('can', 201), ('weed', 107), ('charis', 86), ('!', 82), (',', 73), ('king', 55), ('.', 53), ('smo', 46), ('kevin', 41), ('love', 40)] |  | TUTOR.py 20

--- 2025-04-14 17:20:22 --- babyLLM 'right, last time i got to step 221... want to restart from there?'  - charis: 'y' - babyLLM 'ok! let's go to step 221! what am i learning today?' - charis: ''
2025-04-14 17:21:37 | 20 | LR0.0003 | logitMin:-14472.7324 | logitMax:11997.5703 | scheduledSampling:0.0000 | windowWeightsW2:2.53304 (0.68),W4:1.76115 (0.31),W8:-2.28739 (0.01),W12:-7.20165 (0.00),W16:-9.73353 (0.00),W20:-11.23173 (0.00),W24:-11.78938 (0.00),W32:-12.01125 (0.00),W28:-12.18089 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 42), ('charis', 31), ('weed', 28), ('.', 23), ('take', 17), ('and', 17), (',', 16), ('smo', 16), ('king', 15), ('my', 15)] |  | blend:0.590  W32:0.59,W2:0.28,W4:0.13,W8:0.00 | TUTOR.py 20
2025-04-14 17:22:53 | 40 | LR0.0003 | logitMin:-10810.5146 | logitMax:6102.6611 | scheduledSampling:0.0000 | windowWeightsW2:2.53479 (0.68),W4:1.75942 (0.31),W8:-2.29065 (0.01),W12:-7.20464 (0.00),W16:-9.73611 (0.00),W20:-11.23418 (0.00),W24:-11.79270 (0.00),W32:-12.01474 (0.00),W28:-12.18498 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 107), ('weed', 63), ('smo', 37), ('king', 37), ('.', 34), ('charis', 34), ('!', 34), (',', 33), ('take', 28), ('mind', 25)] |  | blend:0.588  W28:0.59,W2:0.28,W4:0.13,W8:0.00 | TUTOR.py 20
2025-04-14 17:24:08 | 60 | LR0.0003 | logitMin:-9885.4375 | logitMax:6077.7529 | scheduledSampling:0.0000 | windowWeightsW2:2.53612 (0.68),W4:1.75809 (0.31),W8:-2.29275 (0.01),W12:-7.20670 (0.00),W16:-9.73781 (0.00),W20:-11.23579 (0.00),W24:-11.79470 (0.00),W32:-12.01624 (0.00),W28:-12.18837 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 156), ('weed', 98), ('!', 63), ('charis', 62), ('smo', 53), ('king', 53), ('.', 41), (',', 39), ('kevin', 35), ('love', 33)] |  | blend:0.587  W28:0.59,W2:0.28,W4:0.13,W8:0.00 | TUTOR.py 20
2025-04-14 17:25:24 | 80 | LR0.0003 | logitMin:-9269.8760 | logitMax:5812.3916 | scheduledSampling:0.0000 | windowWeightsW2:2.53622 (0.68),W4:1.75799 (0.31),W8:-2.29443 (0.01),W12:-7.20610 (0.00),W16:-9.73651 (0.00),W20:-11.23450 (0.00),W24:-11.79279 (0.00),W32:-12.01576 (0.00),W28:-12.19085 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 215), ('charis', 99), ('weed', 99), (',', 91), ('!', 72), ('smo', 54), ('king', 53), ('mind', 42), ('.', 41), ('kevin', 36)] |  | blend:0.587  W28:0.59,W2:0.28,W4:0.13,W8:0.00 | TUTOR.py 20
2025-04-14 17:26:39 | 100 | LR0.0003 | logitMin:-10170.4268 | logitMax:5653.7607 | scheduledSampling:0.0000 | windowWeightsW2:2.53558 (0.68),W4:1.75860 (0.31),W8:-2.29472 (0.01),W12:-7.20193 (0.00),W16:-9.73146 (0.00),W20:-11.22953 (0.00),W24:-11.79358 (0.00),W32:-12.01467 (0.00),W28:-12.19103 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 258), ('charis', 116), (',', 110), ('weed', 107), ('!', 85), ('.', 68), ('smo', 54), ('king', 53), ('mind', 42), ('she', 38)] |  | blend:0.586  W28:0.59,W2:0.28,W4:0.13,W8:0.00 | TUTOR.py 20
2025-04-14 17:27:56 | 120 | LR0.0003 | logitMin:-9310.9033 | logitMax:7171.2773 | scheduledSampling:0.0000 | windowWeightsW2:2.53384 (0.68),W4:1.76030 (0.31),W8:-2.29277 (0.01),W12:-7.19552 (0.00),W16:-9.72468 (0.00),W20:-11.22286 (0.00),W24:-11.79303 (0.00),W32:-12.01157 (0.00),W28:-12.18999 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 314), ('charis', 146), ('weed', 130), (',', 120), ('!', 98), ('.', 82), ('smo', 54), ('king', 53), ('a', 49), ('mind', 44)] |  | blend:0.586  W28:0.59,W2:0.28,W4:0.13,W8:0.00 | TUTOR.py 20
2025-04-14 17:29:15 | 140 | LR0.0003 | logitMin:-9345.8975 | logitMax:5251.7388 | scheduledSampling:0.0000 | windowWeightsW2:2.53125 (0.68),W4:1.76283 (0.31),W8:-2.28838 (0.01),W12:-7.18834 (0.00),W16:-9.71730 (0.00),W20:-11.21557 (0.00),W24:-11.79139 (0.00),W32:-12.00723 (0.00),W28:-12.18727 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 371), ('charis', 158), ('weed', 155), ('!', 133), (',', 126), ('.', 103), ('kevin', 61), ('to', 57), ('smo', 54), ('king', 53)] |  | blend:0.585  W28:0.59,W2:0.28,W4:0.13,W8:0.00 | TUTOR.py 20
2025-04-14 17:30:35 | 160 | LR0.0003 | logitMin:-9343.9512 | logitMax:6538.9150 | scheduledSampling:0.0000 | windowWeightsW2:2.53147 (0.68),W4:1.76253 (0.31),W8:-2.28535 (0.01),W12:-7.18198 (0.00),W16:-9.71071 (0.00),W20:-11.20904 (0.00),W24:-11.78773 (0.00),W32:-12.00636 (0.00),W28:-12.18540 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 426), ('charis', 182), ('weed', 155), ('!', 154), (',', 140), ('.', 103), ('kevin', 75), ('elodie', 61), ("'s", 59), ('to', 57)] |  | blend:0.585  W28:0.59,W2:0.28,W4:0.13,W8:0.00 | TUTOR.py 20
2025-04-14 17:31:58 | 180 | LR0.0003 | logitMin:-9025.4941 | logitMax:6448.8296 | scheduledSampling:0.0000 | windowWeightsW2:2.53123 (0.68),W4:1.76273 (0.32),W8:-2.28397 (0.01),W12:-7.17701 (0.00),W16:-9.70539 (0.00),W20:-11.20378 (0.00),W24:-11.78598 (0.00),W32:-12.00408 (0.00),W28:-12.18389 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 467), ('!', 216), ('charis', 187), ('weed', 155), (',', 144), ('.', 103), ('kevin', 93), ("'s", 65), ('elodie', 61), ('to', 57)] |  | blend:0.585  W28:0.58,W2:0.28,W4:0.13,W8:0.00 | TUTOR.py 20

--- 2025-04-14 17:38:23 --- babyLLM 'right, last time i got to step 222... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 222! what am i learning today?' - charis: ''
2025-04-14 17:39:34 | 20 | LR0.0003 | logitMin:-11924.0107 | logitMax:7469.8804 | scheduledSampling:0.0000 | windowWeightsW2:2.53138 (0.68),W4:1.76252 (0.31),W8:-2.28404 (0.01),W12:-7.17742 (0.00),W16:-9.70520 (0.00),W20:-11.20340 (0.00),W24:-11.78487 (0.00),W32:-12.00321 (0.00),W28:-12.18491 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 48), ('weed', 30), ('charis', 28), ('.', 27), ('smo', 18), ('take', 17), ('king', 17), ('my', 17), ('your', 14), ('and', 14)] |  | blend:0.584  W32:0.58,W2:0.28,W4:0.13,W8:0.00 | TUTOR.py 20
2025-04-14 17:40:51 | 40 | LR0.0003 | logitMin:-10071.2666 | logitMax:5927.9678 | scheduledSampling:0.0000 | windowWeightsW2:2.53148 (0.68),W4:1.76243 (0.31),W8:-2.28602 (0.01),W12:-7.18199 (0.00),W16:-9.70963 (0.00),W20:-11.20767 (0.00),W24:-11.78784 (0.00),W32:-12.00712 (0.00),W28:-12.18808 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 111), ('weed', 48), ('smo', 43), ('.', 41), ('king', 40), ('!', 37), ('take', 32), ('charis', 30), ('your', 27), ('you', 25)] |  | blend:0.583  W28:0.58,W2:0.28,W4:0.13,W8:0.00 | TUTOR.py 20
2025-04-14 17:42:06 | 60 | LR0.0003 | logitMin:-9539.3359 | logitMax:6163.4072 | scheduledSampling:0.0000 | windowWeightsW2:2.53306 (0.68),W4:1.76085 (0.31),W8:-2.28739 (0.01),W12:-7.18357 (0.00),W16:-9.71073 (0.00),W20:-11.20867 (0.00),W24:-11.78827 (0.00),W32:-12.00836 (0.00),W28:-12.19108 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 169), ('weed', 79), ('!', 70), ('charis', 57), ('king', 55), ('smo', 54), ('.', 50), ('love', 33), ('take', 32), ('you', 32)] |  | blend:0.582  W28:0.58,W2:0.28,W4:0.13,W8:0.00 | TUTOR.py 20
2025-04-14 17:43:20 | 80 | LR0.0003 | logitMin:-14075.4561 | logitMax:5583.8896 | scheduledSampling:0.0000 | windowWeightsW2:2.53385 (0.68),W4:1.76006 (0.31),W8:-2.28946 (0.01),W12:-7.18375 (0.00),W16:-9.71032 (0.00),W20:-11.20820 (0.00),W24:-11.79050 (0.00),W32:-12.00824 (0.00),W28:-12.19309 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 237), ('charis', 92), ('weed', 84), (',', 81), ('!', 75), ('king', 55), ('smo', 54), ('.', 50), ('love', 36), ('kevin', 34)] |  | blend:0.581  W28:0.58,W2:0.29,W4:0.13,W8:0.00 | TUTOR.py 20

--- 2025-04-14 17:44:20 --- babyLLM 'right, last time i got to step 223... want to restart from there?'  - charis: '300' - babyLLM 'damn that's specific! heading to step 300... what am i learning today?' - charis: ''
2025-04-14 17:46:07 | 20 | LR0.0003 | logitMin:-8776.8975 | logitMax:4965.1147 | scheduledSampling:0.0000 | windowWeightsW2:2.53552 (0.68),W4:1.75844 (0.31),W8:-2.29470 (0.01),W12:-7.18785 (0.00),W16:-9.71365 (0.00),W20:-11.21140 (0.00),W24:-11.79031 (0.00),W32:-12.01041 (0.00),W28:-12.19764 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 50), ('a', 35), ('.', 31), ('they', 28), (',', 20), ('sing', 20), ('t', 19), ('un', 19), ('her', 17), ('e', 16)] |  | blend:0.579  W28:0.58,W2:0.29,W4:0.13,W8:0.00 | TUTOR.py 20

--- 2025-04-14 17:48:11 --- babyLLM 'right, last time i got to step 301... want to restart from there?'  - charis: '320' - babyLLM 'damn that's specific! heading to step 320... what am i learning today?' - charis: ''
2025-04-14 17:49:50 | 20 | LR0.0003 | logitMin:-8755.2480 | logitMax:5605.0977 | scheduledSampling:0.0000 | windowWeightsW2:2.53606 (0.68),W4:1.75791 (0.31),W8:-2.29900 (0.01),W12:-7.19244 (0.00),W16:-9.71749 (0.00),W20:-11.21508 (0.00),W24:-11.79094 (0.00),W32:-12.01260 (0.00),W28:-12.20379 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 64), ('charis', 31), ('the', 24), ('listen', 19), ('they', 18), ('.', 17), ('to', 17), ('dog', 15), ('!', 15), ('w', 14)] |  | blend:0.577  W28:0.58,W2:0.29,W4:0.13,W8:0.00 | TUTOR.py 20
2025-04-14 17:51:13 | 40 | LR0.0003 | logitMin:-8789.6924 | logitMax:8314.8721 | scheduledSampling:0.0000 | windowWeightsW2:2.53606 (0.68),W4:1.75789 (0.31),W8:-2.29931 (0.01),W12:-7.19286 (0.00),W16:-9.71717 (0.00),W20:-11.21464 (0.00),W24:-11.79089 (0.00),W32:-12.01306 (0.00),W28:-12.20657 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 107), ('!', 48), ('.', 42), ('charis', 42), ('weed', 41), ('to', 39), ('listen', 37), ('the', 26), ('they', 23), ('kevin', 23)] |  | blend:0.576  W28:0.58,W2:0.29,W4:0.13,W8:0.00 | TUTOR.py 20
2025-04-14 17:52:34 | 60 | LR0.0003 | logitMin:-8079.0742 | logitMax:7306.5913 | scheduledSampling:0.0000 | windowWeightsW2:2.53690 (0.68),W4:1.75703 (0.31),W8:-2.29992 (0.01),W12:-7.19204 (0.00),W16:-9.71575 (0.00),W20:-11.21318 (0.00),W24:-11.79003 (0.00),W32:-12.01527 (0.00),W28:-12.20936 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 161), ('!', 73), ('charis', 68), ('elodie', 52), ('weed', 46), ('.', 42), ('kevin', 41), ('butt', 40), ('to', 39), (',', 38)] |  | blend:0.575  W28:0.58,W2:0.29,W4:0.13,W8:0.00 | TUTOR.py 20

--- 2025-04-14 17:54:11 --- babyLLM 'right, last time i got to step 321... want to restart from there?'  - charis: '400' - babyLLM 'damn that's specific! heading to step 400... what am i learning today?' - charis: ''
2025-04-14 17:55:28 | 20 | LR0.0003 | logitMin:-8072.3423 | logitMax:7034.4346 | scheduledSampling:0.0000 | windowWeightsW2:2.53539 (0.68),W4:1.75849 (0.31),W8:-2.30004 (0.01),W12:-7.18888 (0.00),W16:-9.71205 (0.00),W20:-11.20944 (0.00),W24:-11.78735 (0.00),W32:-12.01477 (0.00),W28:-12.20987 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 54), ('they', 21), ('take', 20), ('smo', 20), ('a', 18), ('ort', 17), ('ory', 17), ('charis', 16), (',', 15), ('king', 14)] |  | blend:0.575  W28:0.57,W2:0.29,W4:0.13,W8:0.00 | TUTOR.py 20
2025-04-14 17:56:48 | 40 | LR0.0003 | logitMin:-7384.3813 | logitMax:5136.6455 | scheduledSampling:0.0000 | windowWeightsW2:2.53467 (0.68),W4:1.75915 (0.31),W8:-2.29740 (0.01),W12:-7.18332 (0.00),W16:-9.70646 (0.00),W20:-11.20387 (0.00),W24:-11.78564 (0.00),W32:-12.01191 (0.00),W28:-12.20817 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 97), (',', 37), ('charis', 35), ('!', 34), ('the', 33), ('she', 26), ('they', 25), ('weed', 25), ("'", 23), ('king', 21)] |  | blend:0.575  W28:0.58,W2:0.29,W4:0.13,W8:0.00 | TUTOR.py 20
2025-04-14 17:58:10 | 60 | LR0.0003 | logitMin:-9224.8486 | logitMax:5430.7729 | scheduledSampling:0.0000 | windowWeightsW2:2.53203 (0.68),W4:1.76170 (0.31),W8:-2.29396 (0.01),W12:-7.17736 (0.00),W16:-9.70044 (0.00),W20:-11.19791 (0.00),W24:-11.78193 (0.00),W32:-12.00816 (0.00),W28:-12.20426 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 156), ('the', 67), ('!', 56), (',', 53), ('she', 44), ('charis', 39), ('to', 31), ('they', 25), ('weed', 25), ("'", 23)] |  | blend:0.576  W28:0.58,W2:0.29,W4:0.13,W8:0.00 | TUTOR.py 20
2025-04-14 17:59:39 | 80 | LR0.0003 | logitMin:-7926.1812 | logitMax:4854.3486 | scheduledSampling:0.0000 | windowWeightsW2:2.52962 (0.68),W4:1.76404 (0.32),W8:-2.29108 (0.01),W12:-7.17221 (0.00),W16:-9.69524 (0.00),W20:-11.19277 (0.00),W24:-11.77865 (0.00),W32:-12.00499 (0.00),W28:-12.20226 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 206), ('the', 87), (',', 79), ('!', 56), ('charis', 55), ('she', 49), ('cks', 40), ('kevin', 39), ('listen', 39), ('to', 34)] |  | blend:0.576  W28:0.58,W2:0.29,W4:0.13,W8:0.00 | TUTOR.py 20

--- 2025-04-14 18:01:25 --- babyLLM 'right, last time i got to step 401... want to restart from there?'  - charis: '500' - babyLLM 'damn that's specific! heading to step 500... what am i learning today?' - charis: ''
2025-04-14 18:02:51 | 20 | LR0.0003 | logitMin:-7255.8022 | logitMax:4844.7607 | scheduledSampling:0.0000 | windowWeightsW2:2.52550 (0.68),W4:1.76793 (0.32),W8:-2.28252 (0.01),W12:-7.16194 (0.00),W16:-9.68491 (0.00),W20:-11.18254 (0.00),W24:-11.77048 (0.00),W32:-11.99756 (0.00),W28:-12.19393 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 49), ('elodie', 41), ('!', 33), ('charis', 28), ('he', 22), ('her', 21), (',', 20), ('see', 20), ('pick', 16), ('food', 15)] |  | blend:0.577  W28:0.58,W2:0.29,W4:0.13,W8:0.00 | TUTOR.py 20
2025-04-14 18:04:15 | 40 | LR0.0003 | logitMin:-8221.6953 | logitMax:6127.7568 | scheduledSampling:0.0000 | windowWeightsW2:2.52418 (0.68),W4:1.76918 (0.32),W8:-2.28036 (0.01),W12:-7.15804 (0.00),W16:-9.68094 (0.00),W20:-11.17862 (0.00),W24:-11.76646 (0.00),W32:-11.99424 (0.00),W28:-12.19103 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 89), ('!', 66), ('elodie', 50), ('charis', 45), ('he', 41), (',', 26), ('at', 26), ('and', 24), ('love', 23), ('n', 23)] |  | blend:0.578  W28:0.58,W2:0.29,W4:0.13,W8:0.00 | TUTOR.py 20
2025-04-14 18:05:37 | 60 | LR0.0003 | logitMin:-12947.6758 | logitMax:12250.9922 | scheduledSampling:0.0000 | windowWeightsW2:2.52302 (0.68),W4:1.77027 (0.32),W8:-2.27788 (0.01),W12:-7.15284 (0.00),W16:-9.67562 (0.00),W20:-11.17334 (0.00),W24:-11.76317 (0.00),W32:-11.99003 (0.00),W28:-12.18795 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 133), ('!', 77), ('elodie', 75), (',', 62), ('charis', 58), ('and', 52), ('the', 49), ('he', 41), ('at', 35), ('look', 33)] |  | blend:0.579  W32:0.58,W2:0.28,W4:0.13,W8:0.00 | TUTOR.py 20

--- 2025-04-14 18:06:34 --- babyLLM 'right, last time i got to step 501... want to restart from there?'  - charis: '550' - babyLLM 'damn that's specific! heading to step 550... what am i learning today?' - charis: ''
2025-04-14 18:07:56 | 20 | LR0.0003 | scheduledSampling:0.0000 | windowWeightsW2:2.52157 (0.68),W4:1.77166 (0.32),W8:-2.27621 (0.01),W12:-7.15055 (0.00),W16:-9.67299 (0.00),W20:-11.17071 (0.00),W24:-11.76178 (0.00),W32:-11.98922 (0.00),W28:-12.18704 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 41), (',', 33), ('leave', 23), ('i', 22), ('nt', 20), ('he', 19), ('!', 18), ('able', 17), ('that', 16), ('t', 16)] |  | blend:0.579  W28:0.58,W2:0.28,W4:0.13,W8:0.00 | TUTOR.py 20

--- 2025-04-14 18:09:13 --- babyLLM 'right, last time i got to step 551... want to restart from there?'  - charis: '570' - babyLLM 'damn that's specific! heading to step 570... what am i learning today?' - charis: ''

--- 2025-04-14 18:10:49 --- babyLLM 'right, last time i got to step 571... want to restart from there?'  - charis: '580' - babyLLM 'damn that's specific! heading to step 580... what am i learning today?' - charis: ''

--- 2025-04-14 18:12:30 --- babyLLM 'right, last time i got to step 581... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 581! what am i learning today?' - charis: ''
2025-04-14 18:13:45 | 20 | LR0.0003 | logitMin:-15451.4199 | logitMax:4331.9951 | scheduledSampling:0.0000 | windowWeightsW2:2.52049 (0.67),W4:1.77263 (0.32),W8:-2.27651 (0.01),W12:-7.14655 (0.00),W16:-9.66764 (0.00),W20:-11.16529 (0.00),W24:-11.75828 (0.00),W32:-11.98733 (0.00),W28:-12.18677 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 49), ('!', 36), ('charis', 32), (',', 28), ('in', 28), ('love', 21), ('op', 19), ('our', 18), ('them', 18), ('take', 17)] |  | blend:0.578  W28:0.58,W2:0.28,W4:0.13,W8:0.00 | TUTOR.py 20
2025-04-14 18:15:01 | 40 | LR0.0003 | logitMin:-7087.6851 | logitMax:4177.8457 | scheduledSampling:0.0000 | windowWeightsW2:2.51889 (0.67),W4:1.77419 (0.32),W8:-2.27404 (0.01),W12:-7.14145 (0.00),W16:-9.66227 (0.00),W20:-11.15994 (0.00),W24:-11.75435 (0.00),W32:-11.98460 (0.00),W28:-12.18471 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 106), ('charis', 56), (',', 44), ('!', 36), ('butt', 32), ('in', 30), ('elodie', 29), ('love', 28), ('their', 24), ('need', 21)] |  | blend:0.578  W28:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:16:17 | 60 | LR0.0003 | logitMin:-7246.2266 | logitMax:4075.2722 | scheduledSampling:0.0000 | windowWeightsW2:2.51656 (0.67),W4:1.77643 (0.32),W8:-2.26916 (0.01),W12:-7.13487 (0.00),W16:-9.65564 (0.00),W20:-11.15333 (0.00),W24:-11.74812 (0.00),W32:-11.98018 (0.00),W28:-12.18052 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 150), (',', 77), ('charis', 76), ('them', 47), ('!', 44), ('take', 41), ('butt', 40), ('our', 36), ('elodie', 32), ('love', 31)] |  | blend:0.579  W28:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:17:32 | 80 | LR0.0003 | logitMin:-6758.9502 | logitMax:4779.0376 | scheduledSampling:0.0000 | windowWeightsW2:2.51584 (0.67),W4:1.77710 (0.32),W8:-2.26698 (0.01),W12:-7.13093 (0.00),W16:-9.65135 (0.00),W20:-11.14904 (0.00),W24:-11.74526 (0.00),W32:-11.97841 (0.00),W28:-12.17942 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 217), (',', 86), ('charis', 86), ('!', 84), ('elodie', 59), ('butt', 52), ('them', 47), ('take', 41), ('our', 36), ('.', 33)] |  | blend:0.579  W28:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:18:48 | 100 | LR0.0003 | logitMin:-7454.8857 | logitMax:5489.8403 | scheduledSampling:0.0000 | windowWeightsW2:2.51328 (0.67),W4:1.77956 (0.32),W8:-2.26175 (0.01),W12:-7.12427 (0.00),W16:-9.64454 (0.00),W20:-11.14229 (0.00),W24:-11.74075 (0.00),W32:-11.97533 (0.00),W28:-12.17415 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 251), (',', 111), ('!', 89), ('charis', 89), ('butt', 65), ('elodie', 59), ('.', 55), ('his', 52), ('them', 47), ('to', 45)] |  | blend:0.579  W28:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:20:06 | 120 | LR0.0003 | logitMin:-7481.8291 | logitMax:4755.2515 | scheduledSampling:0.0000 | windowWeightsW2:2.50972 (0.67),W4:1.78305 (0.32),W8:-2.25715 (0.01),W12:-7.11739 (0.00),W16:-9.63764 (0.00),W20:-11.13547 (0.00),W24:-11.73482 (0.00),W32:-11.96957 (0.00),W28:-12.16892 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 292), (',', 111), ('charis', 106), ('!', 102), ('elodie', 72), ('.', 68), ('our', 66), ('butt', 66), ('weed', 52), ('his', 52)] |  | blend:0.580  W28:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:21:24 | 140 | LR0.0003 | logitMin:-8872.4697 | logitMax:6109.0020 | scheduledSampling:0.0000 | windowWeightsW2:2.50931 (0.67),W4:1.78335 (0.32),W8:-2.25291 (0.01),W12:-7.11190 (0.00),W16:-9.63197 (0.00),W20:-11.12984 (0.00),W24:-11.73064 (0.00),W32:-11.96558 (0.00),W28:-12.16544 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 343), ('charis', 141), (',', 125), ('!', 117), ('elodie', 99), ('.', 85), ('our', 74), ('to', 70), ('butt', 66), ('and', 65)] |  | blend:0.581  W28:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:22:40 | 160 | LR0.0003 | logitMin:-7559.9702 | logitMax:4334.4233 | scheduledSampling:0.0000 | windowWeightsW2:2.50695 (0.67),W4:1.78565 (0.33),W8:-2.24972 (0.01),W12:-7.10804 (0.00),W16:-9.62794 (0.00),W20:-11.12584 (0.00),W24:-11.72736 (0.00),W32:-11.96205 (0.00),W28:-12.16306 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 391), ('!', 156), ('charis', 141), (',', 129), ('elodie', 115), ('our', 94), ('.', 88), ('to', 80), ('they', 76), ('and', 66)] |  | blend:0.581  W28:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:23:56 | 180 | LR0.0003 | logitMin:-7223.6455 | logitMax:4730.3564 | scheduledSampling:0.0000 | windowWeightsW2:2.50397 (0.67),W4:1.78856 (0.33),W8:-2.24661 (0.01),W12:-7.10317 (0.00),W16:-9.62306 (0.00),W20:-11.12101 (0.00),W24:-11.72318 (0.00),W32:-11.95833 (0.00),W28:-12.15964 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 439), ('!', 170), (',', 145), ('charis', 143), ('elodie', 138), ('.', 115), ('our', 94), ('they', 90), ('to', 80), ('and', 78)] |  | blend:0.582  W28:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:25:14 | 200 | LR0.0003 | logitMin:-7591.3374 | logitMax:4884.5747 | scheduledSampling:0.0000 | windowWeightsW2:2.50318 (0.67),W4:1.78935 (0.33),W8:-2.24728 (0.01),W12:-7.09865 (0.00),W16:-9.61815 (0.00),W20:-11.11611 (0.00),W24:-11.71973 (0.00),W32:-11.95827 (0.00),W28:-12.15822 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 484), ('!', 176), ('charis', 161), (',', 156), ('elodie', 146), ('.', 137), ('they', 105), ('our', 94), ('the', 92), ('and', 90)] |  | blend:0.582  W28:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:26:34 | 220 | LR0.0003 | logitMin:-12171.9717 | logitMax:12443.3281 | scheduledSampling:0.0000 | windowWeightsW2:2.50176 (0.67),W4:1.79066 (0.33),W8:-2.24309 (0.01),W12:-7.09319 (0.00),W16:-9.61269 (0.00),W20:-11.11069 (0.00),W24:-11.71573 (0.00),W32:-11.95396 (0.00),W28:-12.15500 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 521), (',', 199), ('!', 188), ('charis', 177), ('elodie', 158), ('.', 146), ('and', 109), ('they', 106), ('weed', 98), ('the', 95)] |  | blend:0.582  W32:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:28:02 | 240 | LR0.0003 | logitMin:-11886.0039 | logitMax:9118.1777 | scheduledSampling:0.0000 | windowWeightsW2:2.50083 (0.67),W4:1.79154 (0.33),W8:-2.24152 (0.01),W12:-7.08820 (0.00),W16:-9.60758 (0.00),W20:-11.10562 (0.00),W24:-11.71088 (0.00),W32:-11.95188 (0.00),W28:-12.15097 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 575), (',', 220), ('!', 216), ('charis', 216), ('elodie', 177), ('.', 146), ('and', 124), ('they', 106), ('the', 105), ('weed', 99)] |  | blend:0.583  W32:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:29:26 | 260 | LR0.0003 | logitMin:-12567.5996 | logitMax:11744.9717 | scheduledSampling:0.0000 | windowWeightsW2:2.49881 (0.67),W4:1.79348 (0.33),W8:-2.23912 (0.01),W12:-7.08330 (0.00),W16:-9.60238 (0.00),W20:-11.10043 (0.00),W24:-11.70660 (0.00),W32:-11.94851 (0.00),W28:-12.14902 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 614), ('!', 239), ('charis', 239), (',', 234), ('elodie', 180), ('.', 146), ('and', 131), ('weed', 130), ('kevin', 129), ('the', 122)] |  | blend:0.583  W32:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:30:45 | 280 | LR0.0003 | logitMin:-6652.1445 | logitMax:4444.6689 | scheduledSampling:0.0000 | windowWeightsW2:2.49687 (0.66),W4:1.79535 (0.33),W8:-2.23665 (0.01),W12:-7.07807 (0.00),W16:-9.59687 (0.00),W20:-11.09495 (0.00),W24:-11.70151 (0.00),W32:-11.94739 (0.00),W28:-12.14592 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 666), ('charis', 275), (',', 257), ('!', 243), ('elodie', 215), ('and', 165), ('.', 165), ('weed', 141), ('kevin', 139), ('the', 122)] |  | blend:0.583  W28:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:32:07 | 300 | LR0.0003 | logitMin:-6075.7822 | logitMax:4811.4253 | scheduledSampling:0.0000 | windowWeightsW2:2.49479 (0.66),W4:1.79734 (0.33),W8:-2.23329 (0.01),W12:-7.07379 (0.00),W16:-9.59225 (0.00),W20:-11.09034 (0.00),W24:-11.69779 (0.00),W32:-11.94604 (0.00),W28:-12.14336 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 717), ('!', 285), (',', 280), ('charis', 277), ('elodie', 215), ('and', 165), ('.', 165), ('kevin', 147), ('weed', 143), ('they', 122)] |  | blend:0.583  W28:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:33:24 | 320 | LR0.0003 | logitMin:-6212.6343 | logitMax:4135.1230 | scheduledSampling:0.0000 | windowWeightsW2:2.49215 (0.66),W4:1.79993 (0.33),W8:-2.23143 (0.01),W12:-7.06991 (0.00),W16:-9.58813 (0.00),W20:-11.08624 (0.00),W24:-11.69427 (0.00),W32:-11.94390 (0.00),W28:-12.14097 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 774), ('!', 315), ('charis', 293), (',', 292), ('elodie', 215), ('.', 185), ('and', 165), ('kevin', 147), ('weed', 143), ('they', 122)] |  | blend:0.583  W28:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:34:42 | 340 | LR0.0003 | logitMin:-11605.5664 | logitMax:15395.3535 | scheduledSampling:0.0000 | windowWeightsW2:2.48987 (0.66),W4:1.80214 (0.33),W8:-2.22896 (0.01),W12:-7.06546 (0.00),W16:-9.58349 (0.00),W20:-11.08163 (0.00),W24:-11.69007 (0.00),W32:-11.93971 (0.00),W28:-12.13880 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 824), ('!', 332), ('charis', 319), (',', 301), ('elodie', 215), ('.', 207), ('and', 165), ('kevin', 147), ('they', 146), ('weed', 143)] |  | blend:0.583  W32:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:35:59 | 360 | LR0.0003 | logitMin:-5748.8838 | logitMax:3256.4648 | scheduledSampling:0.0000 | windowWeightsW2:2.48890 (0.66),W4:1.80305 (0.33),W8:-2.22736 (0.01),W12:-7.06173 (0.00),W16:-9.57949 (0.00),W20:-11.07765 (0.00),W24:-11.68623 (0.00),W32:-11.93850 (0.00),W28:-12.13684 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 876), ('!', 342), (',', 329), ('charis', 319), ('elodie', 229), ('.', 220), ('and', 165), ('weed', 162), ('the', 149), ('kevin', 147)] |  | blend:0.583  W28:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20

--- 2025-04-14 18:37:09 --- babyLLM 'right, last time i got to step 582... want to restart from there?'  - charis: '900' - babyLLM 'damn that's specific! heading to step 900... what am i learning today?' - charis: ''
2025-04-14 18:38:21 | 20 | LR0.0003 | logitMin:-8958.7002 | logitMax:12869.1250 | scheduledSampling:0.0000 | windowWeightsW2:2.48798 (0.66),W4:1.80398 (0.33),W8:-2.22892 (0.01),W12:-7.06187 (0.00),W16:-9.57891 (0.00),W20:-11.07699 (0.00),W24:-11.68526 (0.00),W32:-11.93788 (0.00),W28:-12.13911 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 56), ('charis', 32), ('.', 26), ('!', 18), ('you', 17), ('take', 16), ("'", 15), ('ves', 14), ('l', 13), ('love', 13)] |  | blend:0.583  W32:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:39:36 | 40 | LR0.0003 | logitMin:-5717.8071 | logitMax:3401.7388 | scheduledSampling:0.0000 | windowWeightsW2:2.48915 (0.66),W4:1.80280 (0.33),W8:-2.23011 (0.01),W12:-7.06422 (0.00),W16:-9.58055 (0.00),W20:-11.07851 (0.00),W24:-11.68606 (0.00),W32:-11.93885 (0.00),W28:-12.14152 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 104), (',', 44), ('charis', 44), ('the', 37), ('!', 36), ('our', 35), ('she', 34), ('.', 31), ('song', 23), ('sing', 22)] |  | blend:0.582  W28:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:40:53 | 60 | LR0.0003 | logitMin:-6670.4600 | logitMax:3706.8228 | scheduledSampling:0.0000 | windowWeightsW2:2.49035 (0.66),W4:1.80159 (0.33),W8:-2.23073 (0.01),W12:-7.06315 (0.00),W16:-9.57876 (0.00),W20:-11.07668 (0.00),W24:-11.68594 (0.00),W32:-11.93740 (0.00),W28:-12.14378 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 160), (',', 81), ('charis', 63), ('the', 55), ('she', 53), ('our', 42), ('!', 36), ('.', 31), ('smink', 29), ('i', 27)] |  | blend:0.581  W28:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:42:10 | 80 | LR0.0003 | logitMin:-5675.4160 | logitMax:4174.5908 | scheduledSampling:0.0000 | windowWeightsW2:2.48930 (0.66),W4:1.80254 (0.33),W8:-2.22750 (0.01),W12:-7.05647 (0.00),W16:-9.57166 (0.00),W20:-11.06968 (0.00),W24:-11.68132 (0.00),W32:-11.93433 (0.00),W28:-12.14021 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 203), (',', 96), ('!', 78), ('charis', 76), ('the', 74), ('she', 66), ('to', 54), ('our', 42), ('we', 40), ('take', 33)] |  | blend:0.582  W28:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:43:27 | 100 | LR0.0003 | logitMin:-5586.9575 | logitMax:4056.1003 | scheduledSampling:0.0000 | windowWeightsW2:2.48743 (0.66),W4:1.80436 (0.33),W8:-2.22617 (0.01),W12:-7.05218 (0.00),W16:-9.56692 (0.00),W20:-11.06496 (0.00),W24:-11.67788 (0.00),W32:-11.93218 (0.00),W28:-12.13886 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 249), ('!', 107), (',', 96), ('charis', 79), ('the', 77), ('she', 66), ('to', 59), ('we', 49), ('i', 48), ('weed', 47)] |  | blend:0.582  W28:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:44:44 | 120 | LR0.0003 | logitMin:-5584.7490 | logitMax:4130.9873 | scheduledSampling:0.0000 | windowWeightsW2:2.48518 (0.66),W4:1.80653 (0.33),W8:-2.22349 (0.01),W12:-7.04604 (0.00),W16:-9.56061 (0.00),W20:-11.05869 (0.00),W24:-11.67292 (0.00),W32:-11.92845 (0.00),W28:-12.13531 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 301), ('!', 127), (',', 111), ('the', 105), ('charis', 79), ('she', 66), ('kevin', 64), ('to', 59), ('.', 56), ('i', 54)] |  | blend:0.582  W28:0.58,W2:0.28,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:46:02 | 140 | LR0.0003 | logitMin:-5654.6670 | logitMax:3663.3848 | scheduledSampling:0.0000 | windowWeightsW2:2.48257 (0.66),W4:1.80906 (0.34),W8:-2.22096 (0.01),W12:-7.03948 (0.00),W16:-9.55385 (0.00),W20:-11.05198 (0.00),W24:-11.66761 (0.00),W32:-11.92486 (0.00),W28:-12.13051 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 352), ('!', 176), ('the', 122), (',', 111), ('kevin', 90), ('charis', 80), ('up', 70), ('pick', 68), ('she', 66), ('.', 65)] |  | blend:0.583  W28:0.58,W2:0.27,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:47:20 | 160 | LR0.0003 | logitMin:-4808.8516 | logitMax:4345.7563 | scheduledSampling:0.0000 | windowWeightsW2:2.47987 (0.66),W4:1.81167 (0.34),W8:-2.21821 (0.01),W12:-7.03414 (0.00),W16:-9.54836 (0.00),W20:-11.04652 (0.00),W24:-11.66313 (0.00),W32:-11.92142 (0.00),W28:-12.12737 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 395), ('!', 184), (',', 124), ('the', 122), ('charis', 93), ('kevin', 93), ('pick', 86), ('up', 86), ('.', 80), ('she', 66)] |  | blend:0.583  W28:0.58,W2:0.27,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:48:38 | 180 | LR0.0003 | logitMin:-5309.0264 | logitMax:3391.7781 | scheduledSampling:0.0000 | windowWeightsW2:2.47956 (0.66),W4:1.81193 (0.34),W8:-2.21696 (0.01),W12:-7.03117 (0.00),W16:-9.54500 (0.00),W20:-11.04315 (0.00),W24:-11.66170 (0.00),W32:-11.92082 (0.00),W28:-12.12707 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 449), ('!', 228), (',', 124), ('the', 122), ('charis', 116), ('kevin', 114), ('.', 91), ('elodie', 90), ('pick', 89), ('up', 89)] |  | blend:0.583  W28:0.58,W2:0.27,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:49:54 | 200 | LR0.0003 | logitMin:-10048.2783 | logitMax:7417.3672 | scheduledSampling:0.0000 | windowWeightsW2:2.47910 (0.66),W4:1.81232 (0.34),W8:-2.21424 (0.01),W12:-7.02691 (0.00),W16:-9.54044 (0.00),W20:-11.03857 (0.00),W24:-11.65900 (0.00),W32:-11.92158 (0.00),W28:-12.12427 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 491), ('!', 250), ('the', 152), (',', 141), ('charis', 116), ('kevin', 114), ('up', 104), ('pick', 102), ('i', 94), ('.', 92)] |  | blend:0.582  W32:0.58,W2:0.27,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:51:12 | 220 | LR0.0003 | logitMin:-6256.4805 | logitMax:3150.9556 | scheduledSampling:0.0000 | windowWeightsW2:2.47620 (0.66),W4:1.81516 (0.34),W8:-2.21211 (0.01),W12:-7.02096 (0.00),W16:-9.53421 (0.00),W20:-11.03236 (0.00),W24:-11.65508 (0.00),W32:-11.91737 (0.00),W28:-12.12059 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 535), ('!', 276), (',', 162), ('the', 156), ('kevin', 126), ('charis', 116), ('pick', 107), ('up', 104), ('she', 102), ('.', 99)] |  | blend:0.583  W28:0.58,W2:0.27,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:52:38 | 240 | LR0.0003 | logitMin:-4692.5249 | logitMax:3055.2922 | scheduledSampling:0.0000 | windowWeightsW2:2.47081 (0.65),W4:1.82041 (0.34),W8:-2.20491 (0.01),W12:-7.01235 (0.00),W16:-9.52566 (0.00),W20:-11.02388 (0.00),W24:-11.65161 (0.00),W32:-11.91069 (0.00),W28:-12.11393 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 587), ('!', 327), (',', 164), ('the', 156), ('charis', 144), ('kevin', 132), ('weed', 109), ('pick', 107), ('up', 104), ('she', 103)] |  | blend:0.585  W28:0.58,W2:0.27,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:53:56 | 260 | LR0.0003 | logitMin:-5032.0273 | logitMax:3684.1602 | scheduledSampling:0.0000 | windowWeightsW2:2.46644 (0.65),W4:1.82466 (0.34),W8:-2.19924 (0.01),W12:-7.00491 (0.00),W16:-9.51821 (0.00),W20:-11.01650 (0.00),W24:-11.64738 (0.00),W32:-11.90511 (0.00),W28:-12.10783 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 625), ('!', 347), (',', 179), ('the', 168), ('charis', 160), ('kevin', 151), ('elodie', 112), ('weed', 112), ('pick', 107), ('up', 104)] |  | blend:0.586  W28:0.59,W2:0.27,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:55:17 | 280 | LR0.0003 | logitMin:-4997.5039 | logitMax:3888.9602 | scheduledSampling:0.0000 | windowWeightsW2:2.46354 (0.65),W4:1.82747 (0.34),W8:-2.19490 (0.01),W12:-7.00085 (0.00),W16:-9.51410 (0.00),W20:-11.01241 (0.00),W24:-11.64521 (0.00),W32:-11.90300 (0.00),W28:-12.10496 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 676), ('!', 386), (',', 207), ('the', 184), ('charis', 178), ('kevin', 164), ('elodie', 138), ('weed', 112), ('pick', 107), ('up', 104)] |  | blend:0.586  W28:0.59,W2:0.27,W4:0.14,W8:0.00 | TUTOR.py 20

--- 2025-04-14 18:56:08 --- babyLLM 'right, last time i got to step 901... want to restart from there?'  - charis: '1200' - babyLLM 'damn that's specific! heading to step 1200... what am i learning today?' - charis: ''
2025-04-14 18:57:22 | 20 | LR0.0003 | logitMin:-5037.0259 | logitMax:3845.1179 | scheduledSampling:0.0000 | windowWeightsW2:2.46179 (0.65),W4:1.82911 (0.34),W8:-2.19016 (0.01),W12:-6.99534 (0.00),W16:-9.50847 (0.00),W20:-11.00679 (0.00),W24:-11.64256 (0.00),W32:-11.89911 (0.00),W28:-12.10053 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('you', 39), ('can', 35), ('to', 27), ('s', 26), ('.', 26), ("'s", 25), ('kevin', 23), ('er', 18), ('!', 13), ('brain', 12)] |  | blend:0.587  W28:0.59,W2:0.27,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:58:37 | 40 | LR0.0003 | logitMin:-8296.0957 | logitMax:4278.0488 | scheduledSampling:0.0000 | windowWeightsW2:2.46272 (0.65),W4:1.82810 (0.34),W8:-2.18729 (0.01),W12:-6.99023 (0.00),W16:-9.50330 (0.00),W20:-11.00164 (0.00),W24:-11.63893 (0.00),W32:-11.89518 (0.00),W28:-12.09683 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 84), ('.', 54), ('to', 49), ('you', 48), ('charis', 41), ('weed', 34), ('elodie', 32), ('kevin', 28), ("'s", 26), ('s', 26)] |  | blend:0.588  W28:0.59,W2:0.27,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 18:59:52 | 60 | LR0.0003 | logitMin:-4501.8633 | logitMax:3975.9968 | scheduledSampling:0.0000 | windowWeightsW2:2.46306 (0.65),W4:1.82766 (0.34),W8:-2.18338 (0.01),W12:-6.98503 (0.00),W16:-9.49799 (0.00),W20:-10.99637 (0.00),W24:-11.63632 (0.00),W32:-11.89277 (0.00),W28:-12.09297 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 123), ('to', 75), ('charis', 63), ('.', 54), ('elodie', 51), ('you', 48), ('weed', 42), ('!', 40), ('listen', 31), ('kevin', 28)] |  | blend:0.588  W28:0.59,W2:0.27,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 19:01:07 | 80 | LR0.0003 | logitMin:-4637.9023 | logitMax:3592.0417 | scheduledSampling:0.0000 | windowWeightsW2:2.46210 (0.65),W4:1.82852 (0.34),W8:-2.17971 (0.01),W12:-6.97937 (0.00),W16:-9.49226 (0.00),W20:-10.99068 (0.00),W24:-11.63390 (0.00),W32:-11.88805 (0.00),W28:-12.08926 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 186), ('to', 75), ('!', 72), ('charis', 63), ('elodie', 58), ('.', 54), ('you', 48), ('weed', 42), ('he', 36), ('their', 34)] |  | blend:0.589  W28:0.59,W2:0.27,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 19:02:22 | 100 | LR0.0003 | logitMin:-4133.2109 | logitMax:3023.7107 | scheduledSampling:0.0000 | windowWeightsW2:2.45993 (0.65),W4:1.83061 (0.35),W8:-2.17612 (0.01),W12:-6.97389 (0.00),W16:-9.48659 (0.00),W20:-10.98506 (0.00),W24:-11.63074 (0.00),W32:-11.88238 (0.00),W28:-12.08545 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 217), ('charis', 94), ('!', 93), ('to', 75), (',', 66), ('you', 62), ('elodie', 58), ('.', 57), ('weed', 51), ('he', 41)] |  | blend:0.590  W28:0.59,W2:0.27,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 19:03:38 | 120 | LR0.0003 | logitMin:-5360.1968 | logitMax:3394.1113 | scheduledSampling:0.0000 | windowWeightsW2:2.45457 (0.65),W4:1.83588 (0.35),W8:-2.17094 (0.01),W12:-6.96796 (0.00),W16:-9.48072 (0.00),W20:-10.97923 (0.00),W24:-11.62798 (0.00),W32:-11.87877 (0.00),W28:-12.08042 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 282), ('!', 125), ('charis', 108), ('weed', 76), ('to', 75), ('elodie', 74), (',', 72), ('.', 68), ('you', 62), ('the', 58)] |  | blend:0.590  W28:0.59,W2:0.26,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 19:04:56 | 140 | LR0.0003 | logitMin:-6768.8467 | logitMax:3669.2886 | scheduledSampling:0.0000 | windowWeightsW2:2.45424 (0.65),W4:1.83613 (0.35),W8:-2.16857 (0.01),W12:-6.96198 (0.00),W16:-9.47466 (0.00),W20:-10.97319 (0.00),W24:-11.62578 (0.00),W32:-11.87422 (0.00),W28:-12.07570 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 333), ('!', 176), ('charis', 110), ('weed', 108), ('elodie', 98), (',', 87), ('you', 78), ('to', 75), ('.', 68), ('the', 61)] |  | blend:0.591  W28:0.59,W2:0.26,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 19:06:13 | 160 | LR0.0003 | logitMin:-6440.6406 | logitMax:4946.5615 | scheduledSampling:0.0000 | windowWeightsW2:2.45211 (0.64),W4:1.83820 (0.35),W8:-2.16605 (0.01),W12:-6.95700 (0.00),W16:-9.46961 (0.00),W20:-10.96818 (0.00),W24:-11.62447 (0.00),W32:-11.86965 (0.00),W28:-12.07247 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 373), ('!', 190), ('charis', 140), ('weed', 123), ('elodie', 108), ('you', 97), ('.', 96), (',', 87), ('the', 80), ('smo', 78)] |  | blend:0.592  W32:0.59,W2:0.26,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 19:07:29 | 180 | LR0.0003 | logitMin:-3923.1782 | logitMax:4150.0532 | scheduledSampling:0.0000 | windowWeightsW2:2.44815 (0.64),W4:1.84210 (0.35),W8:-2.16293 (0.01),W12:-6.95218 (0.00),W16:-9.46464 (0.00),W20:-10.96322 (0.00),W24:-11.62150 (0.00),W32:-11.86548 (0.00),W28:-12.06959 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 420), ('!', 207), ('charis', 148), ('weed', 132), ('.', 121), ('elodie', 116), ('you', 99), ('the', 96), ('to', 90), (',', 87)] |  | blend:0.592  W28:0.59,W2:0.26,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 19:08:45 | 200 | LR0.0003 | logitMin:-4259.9463 | logitMax:4288.0684 | scheduledSampling:0.0000 | windowWeightsW2:2.44656 (0.64),W4:1.84360 (0.35),W8:-2.15945 (0.01),W12:-6.94657 (0.00),W16:-9.45893 (0.00),W20:-10.95754 (0.00),W24:-11.61997 (0.00),W32:-11.86107 (0.00),W28:-12.06567 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 463), ('!', 247), ('charis', 170), ('weed', 132), ('.', 129), ('elodie', 128), ('the', 115), ('you', 100), (',', 99), ('to', 90)] |  | blend:0.593  W28:0.59,W2:0.26,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 19:10:00 | 220 | LR0.0003 | logitMin:-4400.9731 | logitMax:4109.4014 | scheduledSampling:0.0000 | windowWeightsW2:2.44357 (0.64),W4:1.84649 (0.35),W8:-2.15429 (0.01),W12:-6.94000 (0.00),W16:-9.45237 (0.00),W20:-10.95103 (0.00),W24:-11.61752 (0.00),W32:-11.85601 (0.00),W28:-12.06008 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 522), ('!', 302), ('charis', 175), ('weed', 132), ('.', 129), ('elodie', 128), ('the', 125), (',', 102), ('you', 100), ('to', 95)] |  | blend:0.594  W28:0.59,W2:0.26,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 19:11:17 | 240 | LR0.0003 | logitMin:-4415.1709 | logitMax:4042.0425 | scheduledSampling:0.0000 | windowWeightsW2:2.43911 (0.64),W4:1.85088 (0.35),W8:-2.15083 (0.01),W12:-6.93397 (0.00),W16:-9.44616 (0.00),W20:-10.94487 (0.00),W24:-11.61483 (0.00),W32:-11.85312 (0.00),W28:-12.05471 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 583), ('!', 337), ('charis', 181), ('the', 146), ('elodie', 134), (',', 132), ('weed', 132), ('.', 129), ('you', 100), ('her', 99)] |  | blend:0.595  W28:0.60,W2:0.26,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 19:12:34 | 260 | LR0.0003 | logitMin:-3956.0535 | logitMax:3315.6082 | scheduledSampling:0.0000 | windowWeightsW2:2.43680 (0.64),W4:1.85315 (0.36),W8:-2.14897 (0.01),W12:-6.92978 (0.00),W16:-9.44177 (0.00),W20:-10.94051 (0.00),W24:-11.61350 (0.00),W32:-11.84936 (0.00),W28:-12.05241 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 636), ('!', 364), ('charis', 208), (',', 158), ('elodie', 153), ('the', 146), ('weed', 145), ('.', 129), ('her', 103), ('you', 100)] |  | blend:0.596  W28:0.60,W2:0.26,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 19:13:53 | 280 | LR0.0003 | logitMin:-3848.9836 | logitMax:2846.3796 | scheduledSampling:0.0000 | windowWeightsW2:2.43397 (0.64),W4:1.85589 (0.36),W8:-2.14474 (0.01),W12:-6.92484 (0.00),W16:-9.43667 (0.00),W20:-10.93545 (0.00),W24:-11.61152 (0.00),W32:-11.84625 (0.00),W28:-12.04930 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 694), ('!', 383), ('charis', 218), (',', 192), ('elodie', 155), ('weed', 149), ('the', 146), ('.', 129), ('we', 106), ('her', 103)] |  | blend:0.596  W28:0.60,W2:0.26,W4:0.14,W8:0.00 | TUTOR.py 20

--- 2025-04-14 19:15:22 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''
2025-04-14 19:16:37 | 20 | LR0.0003 | logitMin:-5482.6133 | logitMax:3479.4153 | scheduledSampling:0.0000 | windowWeightsW2:2.42921 (0.63),W4:1.86050 (0.36),W8:-2.14042 (0.01),W12:-6.91891 (0.00),W16:-9.43056 (0.00),W20:-10.92937 (0.00),W24:-11.60663 (0.00),W32:-11.84134 (0.00),W28:-12.04462 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 51), ('the', 27), ('we', 22), ('!', 21), ('n', 20), (',', 18), ('your', 17), ('lear', 16), ('i', 16), ('you', 16)] |  | blend:0.597  W28:0.60,W2:0.26,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 19:17:54 | 40 | LR0.0003 | logitMin:-3697.8398 | logitMax:3616.9141 | scheduledSampling:0.0000 | windowWeightsW2:2.42757 (0.63),W4:1.86205 (0.36),W8:-2.13590 (0.01),W12:-6.91408 (0.00),W16:-9.42564 (0.00),W20:-10.92450 (0.00),W24:-11.60446 (0.00),W32:-11.83872 (0.00),W28:-12.04229 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 98), ('!', 54), ('elodie', 35), ('we', 31), (',', 28), ('the', 27), ('from', 27), ('.', 25), ('your', 21), ('lear', 21)] |  | blend:0.597  W28:0.60,W2:0.26,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 19:19:07 | 60 | LR0.0003 | logitMin:-3807.9927 | logitMax:3953.5339 | scheduledSampling:0.0000 | windowWeightsW2:2.42691 (0.63),W4:1.86256 (0.36),W8:-2.13044 (0.01),W12:-6.90908 (0.00),W16:-9.42049 (0.00),W20:-10.91946 (0.00),W24:-11.60267 (0.00),W32:-11.83582 (0.00),W28:-12.03815 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 159), ('!', 79), (',', 57), ('elodie', 52), ('we', 49), ('it', 40), ('i', 37), ('love', 34), ('the', 27), ('from', 27)] |  | blend:0.598  W28:0.60,W2:0.25,W4:0.14,W8:0.00 | TUTOR.py 20

--- 2025-04-14 19:26:21 --- babyLLM 'right, last time i got to step 1... want to restart from there?'  - charis: '2000' - babyLLM 'damn that's specific! heading to step 2000... what am i learning today?' - charis: ''

--- 2025-04-14 19:27:15 --- babyLLM 'right, last time i got to step 2001... want to restart from there?'  - charis: '800' - babyLLM 'damn that's specific! heading to step 800... what am i learning today?' - charis: ''
2025-04-14 19:28:25 | 20 | LR0.0003 | logitMin:-3763.0906 | logitMax:3361.9539 | scheduledSampling:0.0000 | windowWeightsW2:2.42674 (0.63),W4:1.86257 (0.36),W8:-2.12680 (0.01),W12:-6.90251 (0.00),W16:-9.41327 (0.00),W20:-10.91190 (0.00),W24:-11.60048 (0.00),W32:-11.83083 (0.00),W28:-12.03569 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 28), ('!', 16), ('charis', 16), ('elodie', 14), ('kevin', 11), (',', 10), ('see', 9), ('their', 7), ('up', 7), ('butt', 7)] |  | blend:0.598  W28:0.60,W2:0.25,W4:0.14,W8:0.00 | TUTOR.py 20
2025-04-14 19:29:40 | 40 | LR0.0003 | logitMin:-3576.4504 | logitMax:2992.1960 | scheduledSampling:0.0000 | windowWeightsW2:2.42426 (0.63),W4:1.86501 (0.36),W8:-2.12593 (0.01),W12:-6.90073 (0.00),W16:-9.41076 (0.00),W20:-10.90935 (0.00),W24:-11.59808 (0.00),W32:-11.82792 (0.00),W28:-12.03694 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 51), ('kevin', 28), ('charis', 25), ('!', 23), (',', 19), ('weed', 18), ('elodie', 15), ('need', 12), ('and', 11), ('see', 11)] |  | blend:0.598  W28:0.60,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:30:55 | 60 | LR0.0003 | logitMin:-3968.4055 | logitMax:3054.5012 | scheduledSampling:0.0000 | windowWeightsW2:2.41966 (0.63),W4:1.86950 (0.36),W8:-2.12180 (0.01),W12:-6.89552 (0.00),W16:-9.40515 (0.00),W20:-10.90377 (0.00),W24:-11.59542 (0.00),W32:-11.82358 (0.00),W28:-12.03422 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 68), ('charis', 39), ('and', 32), ('kevin', 31), ('elodie', 28), (',', 27), ('!', 26), ('weed', 26), ('need', 12), ('of', 12)] |  | blend:0.599  W28:0.60,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:32:09 | 80 | LR0.0003 | logitMin:-12770.2852 | logitMax:5196.2246 | scheduledSampling:0.0000 | windowWeightsW2:2.41586 (0.63),W4:1.87321 (0.37),W8:-2.11749 (0.01),W12:-6.88971 (0.00),W16:-9.39887 (0.00),W20:-10.89755 (0.00),W24:-11.59281 (0.00),W32:-11.81879 (0.00),W28:-12.03075 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 94), ('!', 50), ('charis', 43), ('kevin', 36), (',', 33), ('and', 32), ('elodie', 30), ('weed', 26), ('butt', 24), ('it', 20)] |  | blend:0.599  W32:0.60,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:33:22 | 100 | LR0.0003 | logitMin:-4159.9385 | logitMax:3195.6587 | scheduledSampling:0.0000 | windowWeightsW2:2.41253 (0.63),W4:1.87645 (0.37),W8:-2.11397 (0.01),W12:-6.88555 (0.00),W16:-9.39453 (0.00),W20:-10.89326 (0.00),W24:-11.59159 (0.00),W32:-11.81604 (0.00),W28:-12.02775 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 124), ('!', 63), ('charis', 48), (',', 41), ('kevin', 39), ('and', 32), ('elodie', 30), ('it', 28), ('you', 28), ('butt', 27)] |  | blend:0.600  W28:0.60,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:34:37 | 120 | LR0.0003 | logitMin:-6644.5093 | logitMax:6457.0029 | scheduledSampling:0.0000 | windowWeightsW2:2.41075 (0.63),W4:1.87816 (0.37),W8:-2.11150 (0.01),W12:-6.88392 (0.00),W16:-9.39242 (0.00),W20:-10.89114 (0.00),W24:-11.59106 (0.00),W32:-11.81421 (0.00),W28:-12.02766 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 150), ('!', 70), ('charis', 61), (',', 46), ('kevin', 39), ('you', 39), ('and', 32), ('elodie', 32), ('butt', 31), ('it', 29)] |  | blend:0.599  W32:0.60,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:35:53 | 140 | LR0.0003 | logitMin:-3289.8613 | logitMax:3380.5027 | scheduledSampling:0.0000 | windowWeightsW2:2.41152 (0.63),W4:1.87733 (0.37),W8:-2.10935 (0.01),W12:-6.88221 (0.00),W16:-9.39017 (0.00),W20:-10.88888 (0.00),W24:-11.58972 (0.00),W32:-11.81260 (0.00),W28:-12.02769 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 174), ('!', 78), ('charis', 67), (',', 63), ('elodie', 40), ('kevin', 39), ('you', 39), ('weed', 34), ('butt', 32), ('and', 32)] |  | blend:0.599  W28:0.60,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20

--- 2025-04-14 19:37:20 --- babyLLM 'right, last time i got to step 801... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 801! what am i learning today?' - charis: ''
2025-04-14 19:38:30 | 20 | LR0.0003 | logitMin:-7690.6655 | logitMax:5560.5781 | scheduledSampling:0.0000 | windowWeightsW2:2.41062 (0.63),W4:1.87827 (0.37),W8:-2.11131 (0.01),W12:-6.88365 (0.00),W16:-9.39081 (0.00),W20:-10.88939 (0.00),W24:-11.59036 (0.00),W32:-11.81326 (0.00),W28:-12.03079 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 25), ('charis', 21), ('!', 15), (',', 13), ('butt', 9), ('kevin', 9), ('and', 9), ('elodie', 9), ('see', 9), ('the', 8)] |  | blend:0.598  W28:0.60,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:39:44 | 40 | LR0.0003 | logitMin:-4025.8308 | logitMax:3482.8345 | scheduledSampling:0.0000 | windowWeightsW2:2.40835 (0.62),W4:1.88051 (0.37),W8:-2.11057 (0.01),W12:-6.88353 (0.00),W16:-9.39017 (0.00),W20:-10.88871 (0.00),W24:-11.59002 (0.00),W32:-11.81264 (0.00),W28:-12.03250 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 50), ('charis', 29), ('!', 26), ('kevin', 26), (',', 19), ('the', 14), ("'s", 14), ('and', 14), ('weed', 14), ('sound', 11)] |  | blend:0.597  W28:0.60,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:40:59 | 60 | LR0.0003 | logitMin:-3445.9199 | logitMax:3017.5620 | scheduledSampling:0.0000 | windowWeightsW2:2.40317 (0.62),W4:1.88566 (0.37),W8:-2.10846 (0.01),W12:-6.88293 (0.00),W16:-9.38892 (0.00),W20:-10.88738 (0.00),W24:-11.58850 (0.00),W32:-11.81164 (0.00),W28:-12.03347 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 73), ('charis', 43), (',', 33), ('and', 30), ('kevin', 29), ('!', 27), ('elodie', 24), ('weed', 17), ('butt', 16), ('the', 14)] |  | blend:0.597  W28:0.60,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20

--- 2025-04-14 19:41:51 --- babyLLM 'right, last time i got to step 802... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 802! what am i learning today?' - charis: ''
2025-04-14 19:43:20 | 20 | LR0.0003 | logitMin:-10940.8584 | logitMax:5422.6450 | scheduledSampling:0.0000 | windowWeightsW2:2.40431 (0.62),W4:1.88456 (0.37),W8:-2.11156 (0.01),W12:-6.88690 (0.00),W16:-9.39225 (0.00),W20:-10.89061 (0.00),W24:-11.59000 (0.00),W32:-11.81169 (0.00),W28:-12.03813 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 26), ('charis', 24), (',', 14), ('kevin', 14), ('!', 12), ('elodie', 10), ('and', 9), ('butt', 8), ('pick', 7), ('see', 7)] |  | blend:0.596  W32:0.60,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:44:41 | 40 | LR0.0003 | logitMin:-3389.2585 | logitMax:3403.7898 | scheduledSampling:0.0000 | windowWeightsW2:2.40433 (0.62),W4:1.88456 (0.37),W8:-2.11303 (0.01),W12:-6.89030 (0.00),W16:-9.39518 (0.00),W20:-10.89346 (0.00),W24:-11.59033 (0.00),W32:-11.81295 (0.00),W28:-12.04164 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 48), ('charis', 32), ('kevin', 27), ('!', 23), (',', 20), ('and', 17), ('weed', 15), ('elodie', 12), ("'s", 12), ('need', 11)] |  | blend:0.595  W28:0.60,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:45:58 | 60 | LR0.0003 | logitMin:-3389.0422 | logitMax:3748.6785 | scheduledSampling:0.0000 | windowWeightsW2:2.40061 (0.62),W4:1.88823 (0.37),W8:-2.11219 (0.01),W12:-6.89132 (0.00),W16:-9.39577 (0.00),W20:-10.89396 (0.00),W24:-11.58977 (0.00),W32:-11.81215 (0.00),W28:-12.04324 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 71), ('charis', 45), (',', 33), ('kevin', 33), ('and', 30), ('!', 27), ('elodie', 25), ('weed', 18), ('butt', 15), ("'s", 12)] |  | blend:0.595  W28:0.59,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:47:14 | 80 | LR0.0003 | logitMin:-4019.7251 | logitMax:3540.3159 | scheduledSampling:0.0000 | windowWeightsW2:2.39831 (0.62),W4:1.89045 (0.37),W8:-2.10935 (0.01),W12:-6.88858 (0.00),W16:-9.39207 (0.00),W20:-10.89017 (0.00),W24:-11.58849 (0.00),W32:-11.81024 (0.00),W28:-12.04250 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 97), ('!', 53), ('charis', 45), ('kevin', 38), (',', 37), ('and', 33), ('elodie', 27), ('butt', 26), ('his', 21), ('it', 19)] |  | blend:0.595  W28:0.59,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:48:28 | 100 | LR0.0003 | logitMin:-3184.0361 | logitMax:3290.7266 | scheduledSampling:0.0000 | windowWeightsW2:2.39581 (0.62),W4:1.89291 (0.37),W8:-2.10810 (0.01),W12:-6.88862 (0.00),W16:-9.39157 (0.00),W20:-10.88954 (0.00),W24:-11.58913 (0.00),W32:-11.80907 (0.00),W28:-12.04390 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 127), ('!', 60), ('charis', 51), (',', 45), ('kevin', 38), ('and', 33), ('butt', 27), ('elodie', 27), ('it', 27), ('you', 23)] |  | blend:0.594  W28:0.59,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:49:42 | 120 | LR0.0003 | logitMin:-4334.8691 | logitMax:3693.8894 | scheduledSampling:0.0000 | windowWeightsW2:2.39468 (0.62),W4:1.89403 (0.37),W8:-2.10821 (0.01),W12:-6.89204 (0.00),W16:-9.39435 (0.00),W20:-10.89218 (0.00),W24:-11.58930 (0.00),W32:-11.81115 (0.00),W28:-12.04754 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 153), ('!', 67), ('charis', 67), (',', 50), ('kevin', 38), ('butt', 35), ('and', 33), ('you', 33), ('.', 32), ('elodie', 31)] |  | blend:0.593  W28:0.59,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:50:55 | 140 | LR0.0003 | logitMin:-4009.1577 | logitMax:3103.4817 | scheduledSampling:0.0000 | windowWeightsW2:2.39440 (0.62),W4:1.89427 (0.37),W8:-2.10741 (0.01),W12:-6.89262 (0.00),W16:-9.39446 (0.00),W20:-10.89222 (0.00),W24:-11.58952 (0.00),W32:-11.80927 (0.00),W28:-12.04962 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 178), ('!', 76), ('charis', 72), (',', 67), ('kevin', 41), ('butt', 35), ('elodie', 35), ('.', 34), ('and', 33), ('you', 33)] |  | blend:0.593  W28:0.59,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:52:08 | 160 | LR0.0003 | logitMin:-4171.0435 | logitMax:3897.6531 | scheduledSampling:0.0000 | windowWeightsW2:2.39639 (0.62),W4:1.89225 (0.37),W8:-2.10833 (0.01),W12:-6.89406 (0.00),W16:-9.39512 (0.00),W20:-10.89278 (0.00),W24:-11.58905 (0.00),W32:-11.80865 (0.00),W28:-12.05386 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 204), (',', 85), ('!', 81), ('charis', 80), ('kevin', 41), ('the', 36), ('to', 36), ('butt', 35), ('elodie', 35), ('.', 35)] |  | blend:0.591  W28:0.59,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:53:21 | 180 | LR0.0003 | logitMin:-4182.0698 | logitMax:2609.1511 | scheduledSampling:0.0000 | windowWeightsW2:2.39630 (0.62),W4:1.89231 (0.37),W8:-2.10741 (0.01),W12:-6.89069 (0.00),W16:-9.39067 (0.00),W20:-10.88827 (0.00),W24:-11.58796 (0.00),W32:-11.80658 (0.00),W28:-12.05357 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 226), ('!', 101), (',', 91), ('charis', 89), ('to', 48), ('kevin', 41), ('the', 41), ('it', 38), ('she', 36), ('butt', 35)] |  | blend:0.592  W28:0.59,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:54:36 | 200 | LR0.0003 | logitMin:-2821.5996 | logitMax:3376.9302 | scheduledSampling:0.0000 | windowWeightsW2:2.39444 (0.62),W4:1.89411 (0.37),W8:-2.10565 (0.01),W12:-6.88566 (0.00),W16:-9.38454 (0.00),W20:-10.88211 (0.00),W24:-11.58624 (0.00),W32:-11.80338 (0.00),W28:-12.05084 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 252), ('!', 110), (',', 92), ('charis', 90), ('kevin', 52), ('to', 48), ('the', 45), ('weed', 45), ('you', 42), ('.', 41)] |  | blend:0.592  W28:0.59,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:55:52 | 220 | LR0.0003 | logitMin:-3444.7981 | logitMax:2705.1011 | scheduledSampling:0.0000 | windowWeightsW2:2.39049 (0.62),W4:1.89796 (0.38),W8:-2.10152 (0.01),W12:-6.87941 (0.00),W16:-9.37770 (0.00),W20:-10.87528 (0.00),W24:-11.58289 (0.00),W32:-11.79821 (0.00),W28:-12.04723 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 275), ('!', 119), (',', 98), ('charis', 90), ('kevin', 64), ('the', 59), ('.', 49), ('to', 48), ('weed', 46), ('you', 42)] |  | blend:0.593  W28:0.59,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:57:07 | 240 | LR0.0003 | logitMin:-4415.1318 | logitMax:2727.3550 | scheduledSampling:0.0000 | windowWeightsW2:2.38803 (0.62),W4:1.90035 (0.38),W8:-2.09867 (0.01),W12:-6.87559 (0.00),W16:-9.37326 (0.00),W20:-10.87081 (0.00),W24:-11.58162 (0.00),W32:-11.79556 (0.00),W28:-12.04567 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 300), ('!', 136), (',', 98), ('charis', 96), ('kevin', 75), ('the', 60), ('.', 57), ('you', 49), ('to', 48), ('weed', 47)] |  | blend:0.593  W28:0.59,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:58:22 | 260 | LR0.0003 | logitMin:-3737.9617 | logitMax:3572.7383 | scheduledSampling:0.0000 | windowWeightsW2:2.38464 (0.61),W4:1.90368 (0.38),W8:-2.09591 (0.01),W12:-6.87234 (0.00),W16:-9.36944 (0.00),W20:-10.86695 (0.00),W24:-11.58203 (0.00),W32:-11.79293 (0.00),W28:-12.04430 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 327), ('!', 151), (',', 107), ('charis', 97), ('kevin', 86), ('.', 63), ('the', 60), ('pick', 55), ('elodie', 52), ('you', 52)] |  | blend:0.593  W28:0.59,W2:0.25,W4:0.15,W8:0.00 | TUTOR.py 20
2025-04-14 19:59:37 | 280 | LR0.0003 | logitMin:-3503.2148 | logitMax:2434.6567 | scheduledSampling:0.0000 | windowWeightsW2:2.38165 (0.61),W4:1.90658 (0.38),W8:-2.09239 (0.01),W12:-6.87031 (0.00),W16:-9.36686 (0.00),W20:-10.86433 (0.00),W24:-11.58146 (0.00),W32:-11.79071 (0.00),W28:-12.04545 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 348), ('!', 166), (',', 108), ('charis', 107), ('kevin', 87), ('.', 71), ('the', 63), ('elodie', 59), ('it', 59), ('you', 58)] |  | blend:0.592  W28:0.59,W2:0.25,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:00:51 | 300 | LR0.0003 | logitMin:-2767.3411 | logitMax:2840.1628 | scheduledSampling:0.0000 | windowWeightsW2:2.37781 (0.61),W4:1.91036 (0.38),W8:-2.08967 (0.01),W12:-6.86557 (0.00),W16:-9.36164 (0.00),W20:-10.85912 (0.00),W24:-11.57944 (0.00),W32:-11.78800 (0.00),W28:-12.04282 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 371), ('!', 174), (',', 115), ('charis', 107), ('kevin', 87), ('the', 81), ('.', 71), ('pick', 66), ('to', 63), ('elodie', 62)] |  | blend:0.592  W28:0.59,W2:0.25,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:02:05 | 320 | LR0.0003 | logitMin:-5280.8188 | logitMax:3381.7681 | scheduledSampling:0.0000 | windowWeightsW2:2.37310 (0.61),W4:1.91495 (0.38),W8:-2.08370 (0.01),W12:-6.85776 (0.00),W16:-9.35339 (0.00),W20:-10.85091 (0.00),W24:-11.57599 (0.00),W32:-11.78277 (0.00),W28:-12.03662 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 396), ('!', 190), (',', 124), ('charis', 108), ('kevin', 91), ('the', 81), ('.', 71), ('weed', 69), ('pick', 66), ('to', 66)] |  | blend:0.593  W28:0.59,W2:0.25,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:03:18 | 340 | LR0.0003 | logitMin:-2655.8682 | logitMax:3219.5259 | scheduledSampling:0.0000 | windowWeightsW2:2.36853 (0.61),W4:1.91937 (0.39),W8:-2.07635 (0.01),W12:-6.84912 (0.00),W16:-9.34433 (0.00),W20:-10.84188 (0.00),W24:-11.57339 (0.00),W32:-11.77744 (0.00),W28:-12.03067 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 420), ('!', 217), ('charis', 125), (',', 124), ('kevin', 95), ('the', 85), ('weed', 73), ('.', 71), ('to', 69), ('you', 68)] |  | blend:0.595  W28:0.59,W2:0.25,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:04:32 | 360 | LR0.0003 | logitMin:-3790.0708 | logitMax:3115.0591 | scheduledSampling:0.0000 | windowWeightsW2:2.36572 (0.60),W4:1.92204 (0.39),W8:-2.07023 (0.01),W12:-6.84206 (0.00),W16:-9.33689 (0.00),W20:-10.83445 (0.00),W24:-11.57079 (0.00),W32:-11.77159 (0.00),W28:-12.02567 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 440), ('!', 230), ('charis', 136), (',', 133), ('kevin', 103), ('the', 90), ('elodie', 78), ('weed', 73), ('.', 71), ('to', 71)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:05:46 | 380 | LR0.0003 | logitMin:-7459.9834 | logitMax:10790.0820 | scheduledSampling:0.0000 | windowWeightsW2:2.36270 (0.60),W4:1.92497 (0.39),W8:-2.06666 (0.01),W12:-6.83867 (0.00),W16:-9.33323 (0.00),W20:-10.83078 (0.00),W24:-11.56831 (0.00),W32:-11.76988 (0.00),W28:-12.02463 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 467), ('!', 248), (',', 147), ('charis', 147), ('kevin', 113), ('the', 98), ('elodie', 87), ('weed', 73), ('.', 71), ('to', 71)] |  | blend:0.596  W32:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:07:00 | 400 | LR0.0003 | logitMin:-2490.3110 | logitMax:2410.8267 | scheduledSampling:0.0000 | windowWeightsW2:2.35867 (0.60),W4:1.92891 (0.39),W8:-2.06188 (0.01),W12:-6.83234 (0.00),W16:-9.32646 (0.00),W20:-10.82401 (0.00),W24:-11.56606 (0.00),W32:-11.76766 (0.00),W28:-12.02061 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 494), ('!', 258), ('charis', 161), (',', 152), ('kevin', 129), ('the', 106), ('elodie', 92), ('weed', 80), ("'s", 76), ('.', 71)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:08:14 | 420 | LR0.0003 | logitMin:-2971.2673 | logitMax:3442.7898 | scheduledSampling:0.0000 | windowWeightsW2:2.35658 (0.60),W4:1.93085 (0.39),W8:-2.05565 (0.01),W12:-6.82747 (0.00),W16:-9.32122 (0.00),W20:-10.81881 (0.00),W24:-11.56350 (0.00),W32:-11.76184 (0.00),W28:-12.01906 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 512), ('!', 263), ('charis', 171), (',', 154), ('kevin', 139), ('the', 109), ('elodie', 92), ('you', 87), ("'s", 84), ('.', 84)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:09:29 | 440 | LR0.0003 | logitMin:-4938.9658 | logitMax:3859.2539 | scheduledSampling:0.0000 | windowWeightsW2:2.35711 (0.60),W4:1.93023 (0.39),W8:-2.05323 (0.01),W12:-6.82274 (0.00),W16:-9.31621 (0.00),W20:-10.81381 (0.00),W24:-11.56159 (0.00),W32:-11.75807 (0.00),W28:-12.01635 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 533), ('!', 270), ('charis', 183), (',', 161), ('kevin', 139), ('the', 109), ('elodie', 105), ('weed', 97), ('.', 97), ('to', 93)] |  | blend:0.597  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:10:43 | 460 | LR0.0003 | logitMin:-3310.2981 | logitMax:3273.0449 | scheduledSampling:0.0000 | windowWeightsW2:2.35370 (0.60),W4:1.93355 (0.39),W8:-2.04914 (0.01),W12:-6.81678 (0.00),W16:-9.30985 (0.00),W20:-10.80747 (0.00),W24:-11.55953 (0.00),W32:-11.75527 (0.00),W28:-12.01249 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 558), ('!', 288), ('charis', 189), (',', 171), ('kevin', 139), ('elodie', 115), ('the', 114), ('to', 104), ('weed', 100), ('.', 98)] |  | blend:0.597  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:11:57 | 480 | LR0.0003 | logitMin:-3869.3660 | logitMax:2954.0264 | scheduledSampling:0.0000 | windowWeightsW2:2.35194 (0.60),W4:1.93517 (0.39),W8:-2.04369 (0.01),W12:-6.80964 (0.00),W16:-9.30235 (0.00),W20:-10.80001 (0.00),W24:-11.55698 (0.00),W32:-11.75065 (0.00),W28:-12.00740 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('can', 583), ('!', 302), ('charis', 197), (',', 182), ('kevin', 139), ('the', 118), ('elodie', 116), ('to', 104), ('weed', 101), ('.', 99)] |  | blend:0.598  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20

--- 2025-04-14 20:32:34 --- babyLLM 'right, last time i got to step 803... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''
2025-04-14 20:33:43 | 20 | LR0.0003 | logitMin:-3241.3843 | logitMax:2589.1714 | scheduledSampling:0.0000 | windowWeightsW2:2.35449 (0.60),W4:1.93257 (0.39),W8:-2.04465 (0.01),W12:-6.80204 (0.00),W16:-9.29382 (0.00),W20:-10.79147 (0.00),W24:-11.55433 (0.00),W32:-11.75116 (0.00),W28:-12.01086 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('her', 11), ('cor', 11), (',', 9), ('ner', 8), ('writing', 8), ('that', 7), ('up', 6), ('she', 6), ('found', 6), ('butt', 5)] |  | blend:0.597  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:34:57 | 40 | LR0.0003 | logitMin:-3396.3530 | logitMax:2470.9028 | scheduledSampling:0.0000 | windowWeightsW2:2.35537 (0.60),W4:1.93153 (0.39),W8:-2.04053 (0.01),W12:-6.79558 (0.00),W16:-9.28728 (0.00),W20:-10.78499 (0.00),W24:-11.54894 (0.00),W32:-11.74766 (0.00),W28:-12.00887 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 19), ('she', 17), ('.', 15), ('that', 13), ('bs', 13), ('her', 11), ('cor', 11), ('ily', 10), ('and', 10), ('rec', 10)] |  | blend:0.597  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:36:10 | 60 | LR0.0003 | logitMin:-7780.4111 | logitMax:2765.3022 | scheduledSampling:0.0000 | windowWeightsW2:2.35349 (0.60),W4:1.93332 (0.39),W8:-2.03711 (0.01),W12:-6.78973 (0.00),W16:-9.28128 (0.00),W20:-10.77905 (0.00),W24:-11.54349 (0.00),W32:-11.74477 (0.00),W28:-12.00732 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 21), ('she', 19), ('the', 15), ('.', 15), ('in', 14), ('that', 13), ('bs', 13), ('and', 12), ('s', 11), ('her', 11)] |  | blend:0.597  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:37:25 | 80 | LR0.0003 | logitMin:-4984.3677 | logitMax:2265.3240 | scheduledSampling:0.0000 | windowWeightsW2:2.34933 (0.60),W4:1.93734 (0.40),W8:-2.03127 (0.01),W12:-6.78287 (0.00),W16:-9.27435 (0.00),W20:-10.77218 (0.00),W24:-11.53688 (0.00),W32:-11.73935 (0.00),W28:-12.00252 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 31), ('she', 26), ('her', 23), ('that', 21), ('the', 18), ('.', 17), ('m', 17), ('in', 16), ('"', 16), ('o', 15)] |  | blend:0.598  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20

--- 2025-04-14 20:41:58 --- babyLLM 'right, last time i got to step 803... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''
2025-04-14 20:43:08 | 20 | LR0.0003 | logitMin:-33.7597 | logitMax:25.4565 | scheduledSampling:0.0000 | windowWeightsW2:2.35456 (0.60),W4:1.93249 (0.39),W8:-2.04488 (0.01),W12:-6.80178 (0.00),W16:-9.29361 (0.00),W20:-10.79127 (0.00),W24:-11.55423 (0.00),W32:-11.75117 (0.00),W28:-12.01080 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('her', 10), ('cor', 10), ('that', 9), ('writing', 9), (',', 8), ('ner', 8), ('up', 6), ('still', 6), ('found', 6), ('butt', 5)] |  | blend:0.597  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20

--- 2025-04-14 20:44:16 --- babyLLM 'right, last time i got to step 1... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''
2025-04-14 20:45:26 | 20 | LR0.0003 | logitMin:-41.0356 | logitMax:21.0090 | scheduledSampling:0.0000 | windowWeightsW2:2.35522 (0.60),W4:1.93179 (0.39),W8:-2.04481 (0.01),W12:-6.80136 (0.00),W16:-9.29267 (0.00),W20:-10.79027 (0.00),W24:-11.55261 (0.00),W32:-11.75006 (0.00),W28:-12.01196 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('that', 12), ('cor', 10), ('writing', 10), ('she', 9), ('ner', 9), (',', 9), ('still', 8), ('in', 8), ('found', 7), ('angle', 7)] |  | blend:0.597  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20

--- 2025-04-14 20:46:25 --- babyLLM 'right, last time i got to step 1... want to restart from there?'  - charis: '29' - babyLLM 'damn that's specific! heading to step 29... what am i learning today?' - charis: ''
2025-04-14 20:47:39 | 20 | LR0.0003 | logitMin:-61.5806 | logitMax:19.7146 | scheduledSampling:0.0000 | windowWeightsW2:2.35567 (0.60),W4:1.93122 (0.39),W8:-2.04215 (0.01),W12:-6.79583 (0.00),W16:-9.28673 (0.00),W20:-10.78434 (0.00),W24:-11.54690 (0.00),W32:-11.74570 (0.00),W28:-12.01091 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('the', 11), ('of', 11), ('t', 10), ('ed', 9), ('by', 9), ('ight', 9), ('m', 9), ('on', 8), ('s', 8), ('and', 7)] |  | blend:0.597  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20

--- 2025-04-14 20:48:36 --- babyLLM 'right, last time i got to step 30... want to restart from there?'  - charis: '50' - babyLLM 'damn that's specific! heading to step 50... what am i learning today?' - charis: ''

--- 2025-04-14 20:49:49 --- babyLLM 'right, last time i got to step 51... want to restart from there?'  - charis: '60' - babyLLM 'damn that's specific! heading to step 60... what am i learning today?' - charis: ''
2025-04-14 20:51:04 | 20 | LR0.0003 | logitMin:-48.3814 | logitMax:21.6553 | scheduledSampling:0.0000 | windowWeightsW2:2.35136 (0.60),W4:1.93535 (0.39),W8:-2.03644 (0.01),W12:-6.78830 (0.00),W16:-9.27895 (0.00),W20:-10.77655 (0.00),W24:-11.53962 (0.00),W32:-11.73736 (0.00),W28:-12.00772 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 17), ('"', 15), ('"', 13), ('f', 13), ('i', 10), ('ound', 9), ('way', 9), ('she', 8), ('that', 8), ('ate', 7)] |  | blend:0.597  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:52:20 | 40 | LR0.0003 | logitMin:-26.1880 | logitMax:17.7835 | scheduledSampling:0.0000 | windowWeightsW2:2.34825 (0.60),W4:1.93831 (0.40),W8:-2.03271 (0.01),W12:-6.78294 (0.00),W16:-9.27338 (0.00),W20:-10.77101 (0.00),W24:-11.53405 (0.00),W32:-11.73313 (0.00),W28:-12.00510 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 37), ('"', 21), ('i', 20), ('"', 13), ('f', 13), ('to', 13), ('your', 13), ('in', 13), ('way', 12), ('that', 11)] |  | blend:0.598  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:53:35 | 60 | LR0.0003 | logitMin:-36.6271 | logitMax:22.9251 | scheduledSampling:0.0000 | windowWeightsW2:2.34761 (0.60),W4:1.93882 (0.40),W8:-2.02939 (0.01),W12:-6.77773 (0.00),W16:-9.26793 (0.00),W20:-10.76557 (0.00),W24:-11.52964 (0.00),W32:-11.73049 (0.00),W28:-12.00112 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 59), ('"', 21), ('i', 20), ('to', 18), ('an', 18), ('angle', 17), ('your', 15), ('r', 14), ('!', 14), ('"', 13)] |  | blend:0.598  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20

--- 2025-04-14 20:54:29 --- babyLLM 'right, last time i got to step 61... want to restart from there?'  - charis: '80' - babyLLM 'damn that's specific! heading to step 80... what am i learning today?' - charis: ''
2025-04-14 20:55:42 | 20 | LR0.0003 | logitMin:-15.4285 | logitMax:13.3382 | scheduledSampling:0.0000 | windowWeightsW2:2.34719 (0.60),W4:1.93925 (0.40),W8:-2.03056 (0.01),W12:-6.78029 (0.00),W16:-9.26913 (0.00),W20:-10.76577 (0.00),W24:-11.52929 (0.00),W32:-11.73104 (0.00),W28:-12.00241 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 23), ('to', 15), ("'", 12), ("'s", 9), ('p', 8), ('i', 8), ('lovely', 8), ('the', 7), ('pe', 7), ('ting', 6)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20

--- 2025-04-14 20:57:15 --- babyLLM 'right, last time i got to step 81... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 81! what am i learning today?' - charis: ''
2025-04-14 20:57:22 | 20 | LR0.0003 | logitMin:-15.4991 | logitMax:16.3501 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 33), ('to', 13), ('you', 12), ('way', 10), ('without', 10), ('he', 9), ('pe', 8), ("'s", 8), ('said', 8), ('wait', 8)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:57:30 | 40 | LR0.0003 | logitMin:-21.5991 | logitMax:9.6610 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 53), ('her', 32), ('angle', 26), ('p', 25), ('you', 17), ('to', 15), ('without', 15), ('wait', 13), ('be', 12), ('way', 10)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:57:38 | 60 | LR0.0003 | logitMin:-36.4352 | logitMax:10.7808 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 126), ('p', 33), ('her', 32), ('he', 30), ('a', 28), ('angle', 26), ('without', 24), ('be', 19), ('next', 18), ('you', 17)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:57:46 | 80 | LR0.0003 | logitMin:-47.1140 | logitMax:17.0474 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 230), ('and', 49), ('he', 34), ('p', 33), ('without', 33), ('her', 32), ('a', 31), ('angle', 26), ('way', 23), ('be', 19)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:57:53 | 100 | LR0.0003 | logitMin:-17.1589 | logitMax:9.7387 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 308), ('and', 55), ('without', 48), ('a', 43), ('p', 34), ('he', 34), ('angle', 34), ('her', 32), ('way', 25), ('ci', 24)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:58:01 | 120 | LR0.0003 | logitMin:-13.3152 | logitMax:7.7632 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 357), ('and', 72), ('without', 59), ('p', 46), ('a', 43), ('he', 41), ('be', 37), ('angle', 35), ('ci', 34), ('her', 32)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:58:10 | 140 | LR0.0003 | logitMin:-40.5177 | logitMax:11.9626 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 415), ('and', 88), ('a', 66), ('without', 62), ('ci', 54), ('p', 51), ('be', 50), ('he', 49), ('for', 44), ('angle', 35)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:58:17 | 160 | LR0.0003 | logitMin:-19.2037 | logitMax:15.7500 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 455), ('and', 108), ('without', 89), ('a', 69), ('ci', 67), ('he', 59), ('be', 52), ('p', 51), ('for', 48), ('smo', 39)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:58:25 | 180 | LR0.0003 | logitMin:-17.6374 | logitMax:20.9698 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 573), ('and', 110), ('without', 90), ('ci', 70), ('a', 70), ('be', 59), ('he', 59), ('p', 51), ('for', 51), ('angle', 41)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:58:33 | 200 | LR0.0003 | logitMin:-42.1743 | logitMax:11.6720 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 648), ('and', 139), ('without', 103), ('a', 71), ('ci', 70), ('for', 60), ('be', 59), ('he', 59), ('smo', 58), ('angle', 57)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20

--- 2025-04-14 20:59:06 --- babyLLM 'right, last time i got to step 81... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 81! what am i learning today?' - charis: ''
2025-04-14 20:59:14 | 20 | LR0.0003 | logitMin:-15.4991 | logitMax:16.3501 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 33), ('to', 13), ('you', 12), ('way', 10), ('without', 10), ('he', 9), ('pe', 8), ("'s", 8), ('wait', 8), ('said', 8)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:59:22 | 40 | LR0.0003 | logitMin:-21.5991 | logitMax:9.6610 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 53), ('her', 32), ('angle', 26), ('p', 25), ('you', 17), ('to', 15), ('without', 15), ('wait', 13), ('be', 11), ('way', 10)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:59:30 | 60 | LR0.0003 | logitMin:-36.4352 | logitMax:10.7808 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 126), ('p', 33), ('he', 32), ('her', 32), ('angle', 26), ('a', 26), ('without', 24), ('next', 18), ('be', 17), ('you', 17)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:59:38 | 80 | LR0.0003 | logitMin:-47.1140 | logitMax:17.0474 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 231), ('and', 50), ('he', 36), ('p', 33), ('without', 33), ('her', 32), ('a', 29), ('angle', 26), ('way', 22), ('for', 19)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:59:46 | 100 | LR0.0003 | logitMin:-17.1589 | logitMax:9.7387 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 309), ('and', 56), ('without', 49), ('a', 40), ('he', 36), ('p', 34), ('angle', 34), ('her', 32), ('way', 26), ('ci', 24)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 20:59:54 | 120 | LR0.0003 | logitMin:-13.3152 | logitMax:7.7632 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 358), ('and', 72), ('without', 60), ('p', 46), ('he', 43), ('a', 40), ('be', 36), ('angle', 35), ('ci', 34), ('her', 32)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:00:01 | 140 | LR0.0003 | logitMin:-40.5177 | logitMax:11.9626 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 416), ('and', 88), ('without', 64), ('a', 62), ('ci', 54), ('p', 51), ('he', 51), ('be', 48), ('for', 46), ('angle', 35)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:00:09 | 160 | LR0.0003 | logitMin:-19.2037 | logitMax:15.7500 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 456), ('and', 108), ('without', 93), ('ci', 67), ('a', 65), ('he', 61), ('p', 51), ('be', 50), ('for', 49), ('her', 37)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20

--- 2025-04-14 21:00:31 --- babyLLM 'right, last time i got to step 81... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 81! what am i learning today?' - charis: ''
2025-04-14 21:00:38 | 20 | LR0.0003 | logitMin:-15.4991 | logitMax:16.3501 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 33), ('to', 13), ('without', 12), ('you', 12), ('way', 10), ('he', 9), ('pe', 8), ("'s", 8), ('said', 8), ('angle', 8)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:00:46 | 40 | LR0.0003 | logitMin:-21.5991 | logitMax:9.6610 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 54), ('her', 31), ('angle', 26), ('p', 25), ('without', 17), ('you', 17), ('to', 15), ('be', 12), ('wait', 11), ('way', 10)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:00:54 | 60 | LR0.0003 | logitMin:-36.4352 | logitMax:10.7808 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 126), ('p', 34), ('her', 31), ('he', 30), ('a', 27), ('without', 26), ('angle', 26), ('be', 19), ('next', 18), ('you', 17)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:01:02 | 80 | LR0.0003 | logitMin:-47.1140 | logitMax:17.0474 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 232), ('and', 47), ('p', 35), ('without', 35), ('he', 34), ('her', 31), ('a', 29), ('angle', 26), ('way', 23), ('for', 20)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:01:10 | 100 | LR0.0003 | logitMin:-17.1589 | logitMax:9.7387 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 310), ('and', 53), ('without', 49), ('a', 41), ('p', 36), ('he', 34), ('angle', 34), ('her', 31), ('way', 27), ('ci', 24)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:01:17 | 120 | LR0.0003 | logitMin:-13.3152 | logitMax:7.7632 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 360), ('and', 69), ('without', 60), ('p', 48), ('he', 41), ('a', 41), ('be', 37), ('angle', 35), ('ci', 34), ('her', 31)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:01:25 | 140 | LR0.0003 | logitMin:-40.5177 | logitMax:11.9626 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 418), ('and', 85), ('without', 66), ('a', 62), ('be', 54), ('ci', 54), ('p', 53), ('he', 49), ('for', 41), ('angle', 35)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:01:33 | 160 | LR0.0003 | logitMin:-19.2037 | logitMax:15.7500 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 458), ('and', 105), ('without', 93), ('ci', 67), ('a', 64), ('he', 59), ('be', 56), ('p', 53), ('for', 45), ('smo', 39)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:01:41 | 180 | LR0.0003 | logitMin:-17.6374 | logitMax:20.9698 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 576), ('and', 107), ('without', 94), ('ci', 71), ('a', 65), ('be', 63), ('he', 59), ('p', 53), ('for', 48), ('angle', 41)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:01:49 | 200 | LR0.0003 | logitMin:-42.1743 | logitMax:11.6720 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 651), ('and', 136), ('without', 106), ('ci', 71), ('a', 65), ('be', 63), ('he', 59), ('angle', 58), ('for', 58), ('smo', 58)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:01:57 | 220 | LR0.0003 | logitMin:-28.9678 | logitMax:16.0933 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 744), ('and', 149), ('without', 110), ('smo', 77), ('ci', 71), ('a', 65), ('for', 65), ('be', 63), ('angle', 60), ('he', 59)] |  | blend:0.596  W28:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:02:05 | 240 | LR0.0003 | logitMin:-38.0025 | logitMax:16.7574 | scheduledSampling:0.0000 | windowWeightsW2:2.34834 (0.60),W4:1.93806 (0.40),W8:-2.02962 (0.01),W12:-6.78045 (0.00),W16:-9.26958 (0.00),W20:-10.76607 (0.00),W24:-11.52945 (0.00),W32:-11.73196 (0.00),W28:-12.00383 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 889), ('and', 149), ('without', 114), ('smo', 77), ('ci', 76), ('a', 65), ('for', 65), ('be', 63), ('way', 63), ('p', 63)] |  | blend:0.596  W32:0.60,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20

--- 2025-04-14 21:02:25 --- babyLLM 'right, last time i got to step 81... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 81! what am i learning today?' - charis: ''

--- 2025-04-14 21:04:44 --- babyLLM 'right, last time i got to step 81... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 81! what am i learning today?' - charis: ''
2025-04-14 21:05:57 | 20 | LR0.0003 | logitMin:-19.3388 | logitMax:19.9787 | scheduledSampling:0.0000 | windowWeightsW2:2.35185 (0.60),W4:1.93453 (0.39),W8:-2.03266 (0.01),W12:-6.78240 (0.00),W16:-9.27151 (0.00),W20:-10.76752 (0.00),W24:-11.53027 (0.00),W32:-11.73293 (0.00),W28:-12.00555 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 18), ("'", 16), ('to', 13), ("'s", 9), ('lovely', 9), ('pe', 8), ('said', 8), ('p', 7), ('i', 7), ('you', 7)] |  | blend:0.595  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:07:13 | 40 | LR0.0003 | logitMin:-23.5279 | logitMax:12.1623 | scheduledSampling:0.0000 | windowWeightsW2:2.35428 (0.60),W4:1.93207 (0.39),W8:-2.03450 (0.01),W12:-6.78408 (0.00),W16:-9.27316 (0.00),W20:-10.76863 (0.00),W24:-11.53144 (0.00),W32:-11.73402 (0.00),W28:-12.00618 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 40), ('to', 21), ('her', 18), ('an', 17), ("'", 16), ('p', 15), ('for', 11), ('wait', 10), ('you', 10), ('r', 10)] |  | blend:0.594  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:08:29 | 60 | LR0.0003 | logitMin:-35.0710 | logitMax:11.5641 | scheduledSampling:0.0000 | windowWeightsW2:2.35546 (0.60),W4:1.93085 (0.39),W8:-2.03457 (0.01),W12:-6.78108 (0.00),W16:-9.27044 (0.00),W20:-10.76654 (0.00),W24:-11.53096 (0.00),W32:-11.73246 (0.00),W28:-12.00651 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 51), ('to', 28), ('p', 18), ('her', 18), ('an', 17), ("'", 17), ('be', 12), ('said', 12), ('pe', 11), ('you', 11)] |  | blend:0.594  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:09:44 | 80 | LR0.0003 | logitMin:-47.9002 | logitMax:14.5849 | scheduledSampling:0.0000 | windowWeightsW2:2.35588 (0.60),W4:1.93044 (0.39),W8:-2.03731 (0.01),W12:-6.77691 (0.00),W16:-9.26615 (0.00),W20:-10.76265 (0.00),W24:-11.52891 (0.00),W32:-11.73039 (0.00),W28:-12.00837 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 61), ('to', 28), ('p', 27), ('the', 26), ('said', 18), ('you', 18), ('her', 18), ('an', 17), ("'", 17), ("'", 15)] |  | blend:0.593  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:11:00 | 100 | LR0.0003 | logitMin:-19.7522 | logitMax:11.0322 | scheduledSampling:0.0000 | windowWeightsW2:2.35513 (0.60),W4:1.93112 (0.39),W8:-2.03514 (0.01),W12:-6.77240 (0.00),W16:-9.26159 (0.00),W20:-10.75835 (0.00),W24:-11.52628 (0.00),W32:-11.72845 (0.00),W28:-12.00836 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 71), ('the', 33), ('p', 30), ('to', 28), ('a', 23), ('pe', 21), ('said', 19), ('ing', 19), ('you', 18), ('her', 18)] |  | blend:0.593  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:12:16 | 120 | LR0.0003 | logitMin:-13.3600 | logitMax:7.6859 | scheduledSampling:0.0000 | windowWeightsW2:2.35341 (0.60),W4:1.93274 (0.39),W8:-2.03187 (0.01),W12:-6.76716 (0.00),W16:-9.25626 (0.00),W20:-10.75334 (0.00),W24:-11.52423 (0.00),W32:-11.72478 (0.00),W28:-12.00787 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 74), ('to', 37), ('the', 36), ('p', 30), ('he', 24), ('pe', 23), ('a', 23), ('said', 19), ('for', 19), ('ing', 19)] |  | blend:0.593  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:13:37 | 140 | LR0.0003 | logitMin:-23.2432 | logitMax:8.7037 | scheduledSampling:0.0000 | windowWeightsW2:2.35143 (0.60),W4:1.93462 (0.39),W8:-2.02844 (0.01),W12:-6.76277 (0.00),W16:-9.25197 (0.00),W20:-10.74932 (0.00),W24:-11.52178 (0.00),W32:-11.72198 (0.00),W28:-12.00605 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 77), ('the', 42), ('to', 37), ('he', 35), ('look', 31), ('p', 30), ('al', 28), ('a', 24), ('pe', 23), ('ed', 21)] |  | blend:0.593  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20

--- 2025-04-14 21:15:52 --- babyLLM 'right, last time i got to step 81... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 81! what am i learning today?' - charis: ''
2025-04-14 21:17:09 | 20 | LR0.0003 | logitMin:-16.4838 | logitMax:15.8676 | scheduledSampling:0.0000 | windowWeightsW2:2.35277 (0.60),W4:1.93360 (0.39),W8:-2.03248 (0.01),W12:-6.78166 (0.00),W16:-9.27075 (0.00),W20:-10.76720 (0.00),W24:-11.53058 (0.00),W32:-11.73305 (0.00),W28:-12.00603 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 22), ('to', 12), ('he', 10), ('pe', 9), ("'s", 9), ('lovely', 9), ('said', 9), ('p', 7), ('i', 7), ("'", 7)] |  | blend:0.595  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20

--- 2025-04-14 21:17:30 --- babyLLM 'right, last time i got to step 81... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 81! what am i learning today?' - charis: ''
2025-04-14 21:18:44 | 20 | LR0.0003 | logitMin:-16.4839 | logitMax:15.8676 | scheduledSampling:0.0000 | windowWeightsW2:2.35277 (0.60),W4:1.93360 (0.39),W8:-2.03248 (0.01),W12:-6.78166 (0.00),W16:-9.27075 (0.00),W20:-10.76720 (0.00),W24:-11.53058 (0.00),W32:-11.73305 (0.00),W28:-12.00603 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 22), ('to', 12), ('he', 10), ("'s", 9), ('lovely', 9), ('said', 9), ('pe', 8), ("'", 8), ('p', 7), ('i', 7)] |  | blend:0.595  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:20:02 | 40 | LR0.0003 | logitMin:-21.1694 | logitMax:9.6514 | scheduledSampling:0.0000 | windowWeightsW2:2.35443 (0.60),W4:1.93193 (0.39),W8:-2.03396 (0.01),W12:-6.78222 (0.00),W16:-9.27125 (0.00),W20:-10.76763 (0.00),W24:-11.53024 (0.00),W32:-11.73305 (0.00),W28:-12.00702 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 50), ('her', 27), ('to', 15), ('an', 14), ('p', 14), ('he', 13), ('find', 12), ('without', 11), ('said', 10), ('you', 10)] |  | blend:0.594  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:21:18 | 60 | LR0.0003 | logitMin:-45.4775 | logitMax:10.9543 | scheduledSampling:0.0000 | windowWeightsW2:2.35443 (0.60),W4:1.93192 (0.39),W8:-2.03505 (0.01),W12:-6.78056 (0.00),W16:-9.26939 (0.00),W20:-10.76592 (0.00),W24:-11.52953 (0.00),W32:-11.73228 (0.00),W28:-12.00782 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 59), ('her', 28), ('to', 24), ('il', 19), ('ing', 18), ('creep', 17), ('p', 16), ('he', 15), ('ily', 15), ('an', 14)] |  | blend:0.594  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:22:34 | 80 | LR0.0003 | logitMin:-39.8968 | logitMax:8.2904 | scheduledSampling:0.0000 | windowWeightsW2:2.35464 (0.60),W4:1.93169 (0.39),W8:-2.03553 (0.01),W12:-6.77891 (0.00),W16:-9.26766 (0.00),W20:-10.76436 (0.00),W24:-11.52891 (0.00),W32:-11.73141 (0.00),W28:-12.00827 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 83), ('er', 41), ('"', 40), ('sp', 31), ('her', 28), ('to', 24), ('and', 24), ('ing', 20), ('il', 19), ('.', 18)] |  | blend:0.594  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:23:51 | 100 | LR0.0003 | logitMin:-15.8706 | logitMax:8.6864 | scheduledSampling:0.0000 | windowWeightsW2:2.35430 (0.60),W4:1.93200 (0.39),W8:-2.03488 (0.01),W12:-6.77721 (0.00),W16:-9.26581 (0.00),W20:-10.76269 (0.00),W24:-11.52809 (0.00),W32:-11.73074 (0.00),W28:-12.00803 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 83), ('find', 51), ('er', 41), ('"', 40), ('i', 33), ('sp', 31), ('p', 30), ('her', 28), ('ing', 28), ('to', 24)] |  | blend:0.594  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:25:09 | 120 | LR0.0003 | logitMin:-17.1740 | logitMax:8.9958 | scheduledSampling:0.0000 | windowWeightsW2:2.35400 (0.60),W4:1.93227 (0.39),W8:-2.03483 (0.01),W12:-6.77651 (0.00),W16:-9.26511 (0.00),W20:-10.76206 (0.00),W24:-11.52768 (0.00),W32:-11.73002 (0.00),W28:-12.00795 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 83), ('p', 56), ('find', 51), ('er', 41), ('"', 40), ('he', 36), ('i', 33), ('sp', 31), ('down', 31), ('ing', 30)] |  | blend:0.594  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:26:28 | 140 | LR0.0003 | logitMin:-17.7195 | logitMax:5.7437 | scheduledSampling:0.0000 | windowWeightsW2:2.35387 (0.60),W4:1.93237 (0.39),W8:-2.03467 (0.01),W12:-6.77566 (0.00),W16:-9.26429 (0.00),W20:-10.76135 (0.00),W24:-11.52710 (0.00),W32:-11.72933 (0.00),W28:-12.00763 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 83), ('p', 56), ('he', 54), ('find', 51), ('the', 44), ('er', 41), ('"', 40), ('was', 35), ('i', 33), ('sp', 31)] |  | blend:0.594  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:27:50 | 160 | LR0.0003 | logitMin:-15.8482 | logitMax:5.4147 | scheduledSampling:0.0000 | windowWeightsW2:2.35375 (0.60),W4:1.93245 (0.39),W8:-2.03322 (0.01),W12:-6.77400 (0.00),W16:-9.26270 (0.00),W20:-10.75998 (0.00),W24:-11.52617 (0.00),W32:-11.72826 (0.00),W28:-12.00703 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 85), ('he', 72), ('.', 61), ('p', 59), ('find', 51), ('the', 44), ('er', 41), ('"', 40), ('dra', 40), ('was', 35)] |  | blend:0.594  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:29:13 | 180 | LR0.0003 | logitMin:-19.4277 | logitMax:7.8906 | scheduledSampling:0.0000 | windowWeightsW2:2.35356 (0.60),W4:1.93259 (0.39),W8:-2.03151 (0.01),W12:-6.77187 (0.00),W16:-9.26062 (0.00),W20:-10.75819 (0.00),W24:-11.52525 (0.00),W32:-11.72769 (0.00),W28:-12.00670 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 125), ('he', 74), ('.', 69), ('p', 62), ('find', 51), ('the', 44), ('er', 41), ('to', 40), ('"', 40), ('dra', 40)] |  | blend:0.594  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20

--- 2025-04-14 21:31:28 --- babyLLM 'right, last time i got to step 82... want to restart from there?'  - charis: '250' - babyLLM 'damn that's specific! heading to step 250... what am i learning today?' - charis: ''
2025-04-14 21:32:46 | 20 | LR0.0003 | logitMin:-41.0838 | logitMax:7.0374 | scheduledSampling:0.0000 | windowWeightsW2:2.35389 (0.60),W4:1.93218 (0.39),W8:-2.02807 (0.01),W12:-6.76862 (0.00),W16:-9.25775 (0.00),W20:-10.75604 (0.00),W24:-11.52440 (0.00),W32:-11.72665 (0.00),W28:-12.00671 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('a', 18), ('ul', 13), ('high', 9), ('at', 9), ('he', 8), ('pro', 8), ('ing', 8), ('angle', 7), ('sed', 7), ('ed', 7)] |  | blend:0.594  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:34:07 | 40 | LR0.0003 | logitMin:-52.3286 | logitMax:21.9917 | scheduledSampling:0.0000 | windowWeightsW2:2.35229 (0.60),W4:1.93373 (0.39),W8:-2.02813 (0.01),W12:-6.76384 (0.00),W16:-9.25376 (0.00),W20:-10.75363 (0.00),W24:-11.52264 (0.00),W32:-11.72576 (0.00),W28:-12.00753 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('a', 26), ('.', 24), ('ul', 13), ('angle', 13), ('i', 12), ('the', 11), ('p', 11), ('g', 11), ('ing', 10), ('pe', 10)] |  | blend:0.593  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:35:27 | 60 | LR0.0003 | logitMin:-33.4560 | logitMax:10.1906 | scheduledSampling:0.0000 | windowWeightsW2:2.35217 (0.60),W4:1.93384 (0.39),W8:-2.02882 (0.01),W12:-6.75712 (0.00),W16:-9.24788 (0.00),W20:-10.74945 (0.00),W24:-11.52154 (0.00),W32:-11.72503 (0.00),W28:-12.00914 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('.', 33), ('a', 31), ('i', 26), ('to', 20), ('ed', 15), ("'s", 15), ('ul', 13), ('angle', 13), ('aaa', 13), ('the', 12)] |  | blend:0.592  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20

--- 2025-04-14 21:37:12 --- babyLLM 'right, last time i got to step 251... want to restart from there?'  - charis: '300' - babyLLM 'damn that's specific! heading to step 300... what am i learning today?' - charis: ''
2025-04-14 21:38:29 | 20 | LR0.0003 | logitMin:-25.8535 | logitMax:11.6512 | scheduledSampling:0.0000 | windowWeightsW2:2.34952 (0.60),W4:1.93647 (0.40),W8:-2.02821 (0.01),W12:-6.75373 (0.00),W16:-9.24487 (0.00),W20:-10.74710 (0.00),W24:-11.52045 (0.00),W32:-11.72334 (0.00),W28:-12.00996 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('i', 22), ('a', 14), ('ed', 12), ('own', 11), ('c', 10), ('one', 10), ('been', 9), ('in', 8), ('never', 8), ('person', 8)] |  | blend:0.591  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:39:49 | 40 | LR0.0003 | logitMin:-25.5691 | logitMax:20.3595 | scheduledSampling:0.0000 | windowWeightsW2:2.34607 (0.60),W4:1.93979 (0.40),W8:-2.02377 (0.01),W12:-6.74851 (0.00),W16:-9.23996 (0.00),W20:-10.74307 (0.00),W24:-11.51689 (0.00),W32:-11.72085 (0.00),W28:-12.00925 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('i', 28), ('a', 26), ('c', 22), ('ma', 15), ('ed', 12), ('been', 12), ('rec', 12), ('pro', 12), ('in', 11), ('own', 11)] |  | blend:0.592  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:41:09 | 60 | LR0.0003 | logitMin:-24.8761 | logitMax:11.1491 | scheduledSampling:0.0000 | windowWeightsW2:2.34287 (0.59),W4:1.94295 (0.40),W8:-2.02183 (0.01),W12:-6.74471 (0.00),W16:-9.23621 (0.00),W20:-10.73978 (0.00),W24:-11.51381 (0.00),W32:-11.71821 (0.00),W28:-12.00830 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('to', 67), ('a', 40), ('and', 37), ('i', 28), ('c', 28), ('lo', 25), ('use', 20), ('ma', 15), ('in', 12), ('ed', 12)] |  | blend:0.592  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:42:29 | 80 | LR0.0003 | logitMin:-17.7099 | logitMax:11.3852 | scheduledSampling:0.0000 | windowWeightsW2:2.34188 (0.59),W4:1.94393 (0.40),W8:-2.02153 (0.01),W12:-6.74341 (0.00),W16:-9.23491 (0.00),W20:-10.73866 (0.00),W24:-11.51278 (0.00),W32:-11.71736 (0.00),W28:-12.00818 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('to', 67), ('x', 61), ('stud', 44), ('i', 42), ('a', 41), ('and', 37), ('use', 32), ('c', 31), ('ic', 28), ('lo', 25)] |  | blend:0.592  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20

--- 2025-04-14 21:43:18 --- babyLLM 'right, last time i got to step 301... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 301! what am i learning today?' - charis: ''
2025-04-14 21:44:33 | 20 | LR0.0003 | logitMin:-23.2568 | logitMax:10.1803 | scheduledSampling:0.0000 | windowWeightsW2:2.34343 (0.59),W4:1.94239 (0.40),W8:-2.02478 (0.01),W12:-6.74687 (0.00),W16:-9.23756 (0.00),W20:-10.74009 (0.00),W24:-11.51388 (0.00),W32:-11.71810 (0.00),W28:-12.00906 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('one', 23), ('ed', 22), ('i', 22), ('a', 11), ('.', 10), ('c', 9), ('before', 9), ('ently', 8), ('never', 5), ('p', 5)] |  | blend:0.591  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:45:53 | 40 | LR0.0003 | logitMin:-21.3826 | logitMax:18.4831 | scheduledSampling:0.0000 | windowWeightsW2:2.34282 (0.59),W4:1.94298 (0.40),W8:-2.02428 (0.01),W12:-6.74641 (0.00),W16:-9.23719 (0.00),W20:-10.73977 (0.00),W24:-11.51337 (0.00),W32:-11.71774 (0.00),W28:-12.00937 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('i', 29), ('one', 23), ('ed', 22), ('a', 21), ('c', 19), ('.', 14), ('ently', 14), ('book', 12), ('stud', 10), ('pro', 10)] |  | blend:0.591  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:47:13 | 60 | LR0.0003 | logitMin:-26.1728 | logitMax:10.3066 | scheduledSampling:0.0000 | windowWeightsW2:2.34162 (0.59),W4:1.94406 (0.40),W8:-2.02183 (0.01),W12:-6.74408 (0.00),W16:-9.23483 (0.00),W20:-10.73773 (0.00),W24:-11.51167 (0.00),W32:-11.71596 (0.00),W28:-12.00890 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('i', 36), ('and', 25), ('ed', 23), ('one', 23), ('.', 23), ('pro', 23), ('a', 22), ('c', 21), ('use', 17), ('book', 15)] |  | blend:0.591  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:48:33 | 80 | LR0.0003 | logitMin:-33.9150 | logitMax:15.3142 | scheduledSampling:0.0000 | windowWeightsW2:2.34219 (0.59),W4:1.94344 (0.40),W8:-2.02065 (0.01),W12:-6.74019 (0.00),W16:-9.23094 (0.00),W20:-10.73422 (0.00),W24:-11.50877 (0.00),W32:-11.71400 (0.00),W28:-12.00970 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('i', 41), ('and', 28), ('.', 27), ('for', 25), ('ed', 23), ('one', 23), ('pro', 23), ('m', 23), ('a', 22), ('c', 21)] |  | blend:0.591  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20

--- 2025-04-14 21:53:35 --- babyLLM 'right, last time i got to step 302... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 302! what am i learning today?' - charis: ''
2025-04-14 21:54:50 | 20 | LR0.0003 | logitMin:-26.3981 | logitMax:13.6437 | scheduledSampling:0.0000 | windowWeightsW2:2.34582 (0.60),W4:1.93985 (0.40),W8:-2.02455 (0.01),W12:-6.74307 (0.00),W16:-9.23220 (0.00),W20:-10.73383 (0.00),W24:-11.50787 (0.00),W32:-11.71331 (0.00),W28:-12.01142 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('i', 27), ('before', 17), ('ed', 11), ('c', 11), ("'d", 10), ('never', 9), ('own', 8), ('a', 8), ('one', 7), ('p', 7)] |  | blend:0.589  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:56:08 | 40 | LR0.0003 | logitMin:-24.7146 | logitMax:19.7763 | scheduledSampling:0.0000 | windowWeightsW2:2.34607 (0.60),W4:1.93956 (0.40),W8:-2.02452 (0.01),W12:-6.74297 (0.00),W16:-9.23200 (0.00),W20:-10.73365 (0.00),W24:-11.50773 (0.00),W32:-11.71308 (0.00),W28:-12.01213 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('i', 32), ('c', 22), ('a', 19), ('before', 17), ('pro', 16), ('be', 12), ('ed', 11), ('book', 11), ('.', 11), ('music', 11)] |  | blend:0.589  W28:0.59,W2:0.25,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:57:28 | 60 | LR0.0003 | logitMin:-19.2176 | logitMax:18.8340 | scheduledSampling:0.0000 | windowWeightsW2:2.34684 (0.60),W4:1.93879 (0.40),W8:-2.02612 (0.01),W12:-6.74140 (0.00),W16:-9.23026 (0.00),W20:-10.73230 (0.00),W24:-11.50634 (0.00),W32:-11.71112 (0.00),W28:-12.01339 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('i', 42), ('and', 30), ('c', 24), ('a', 20), ('book', 19), ('pro', 18), ('before', 17), ('.', 17), ('use', 17), (',', 14)] |  | blend:0.588  W28:0.59,W2:0.25,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 21:58:47 | 80 | LR0.0003 | logitMin:-21.0174 | logitMax:14.8396 | scheduledSampling:0.0000 | windowWeightsW2:2.34771 (0.60),W4:1.93787 (0.40),W8:-2.02607 (0.01),W12:-6.73994 (0.00),W16:-9.22883 (0.00),W20:-10.73107 (0.00),W24:-11.50529 (0.00),W32:-11.71056 (0.00),W28:-12.01398 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('i', 50), ('and', 33), ('c', 24), (',', 23), ('a', 20), ('book', 19), ('pro', 18), ('use', 18), ('before', 17), ('.', 17)] |  | blend:0.588  W28:0.59,W2:0.25,W4:0.16,W8:0.00 | TUTOR.py 20

--- 2025-04-14 21:59:37 --- babyLLM 'right, last time i got to step 303... want to restart from there?'  - charis: '400' - babyLLM 'damn that's specific! heading to step 400... what am i learning today?' - charis: ''

--- 2025-04-14 22:00:53 --- babyLLM 'right, last time i got to step 401... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 401! what am i learning today?' - charis: ''
2025-04-14 22:02:08 | 20 | LR0.0003 | logitMin:-33.2539 | logitMax:14.2044 | scheduledSampling:0.0000 | lossTUTOR:7.8430 | windowWeightsW2:2.34509 (0.60),W4:1.94046 (0.40),W8:-2.02371 (0.01),W12:-6.73521 (0.00),W16:-9.22425 (0.00),W20:-10.72732 (0.00),W24:-11.50232 (0.00),W32:-11.70849 (0.00),W28:-12.01426 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('c', 32), ('and', 28), ("'t", 19), ('es', 11), ('cr', 10), ('antly', 9), ('ash', 7), ('obviously', 6), ('can', 6), ('which', 5)] |  | blend:0.587  W28:0.59,W2:0.25,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 22:03:27 | 40 | LR0.0003 | logitMin:-18.1657 | logitMax:7.1263 | scheduledSampling:0.0000 | lossTUTOR:5.5322 | windowWeightsW2:2.34492 (0.60),W4:1.94050 (0.40),W8:-2.02088 (0.01),W12:-6.73038 (0.00),W16:-9.21991 (0.00),W20:-10.72403 (0.00),W24:-11.49969 (0.00),W32:-11.70705 (0.00),W28:-12.01367 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('c', 50), ('and', 28), ('con', 24), ('year', 23), ('p', 21), ("'t", 19), ('have', 14), ('obviously', 13), ('i', 11), ('es', 11)] |  | blend:0.587  W28:0.59,W2:0.25,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 22:04:47 | 60 | LR0.0003 | logitMin:-32.3967 | logitMax:12.6361 | scheduledSampling:0.0000 | lossTUTOR:7.1353 | windowWeightsW2:2.34314 (0.59),W4:1.94219 (0.40),W8:-2.01752 (0.01),W12:-6.72627 (0.00),W16:-9.21614 (0.00),W20:-10.72087 (0.00),W24:-11.49700 (0.00),W32:-11.70527 (0.00),W28:-12.01299 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('c', 52), ('and', 28), ('to', 28), ('.', 26), ('con', 24), ('the', 24), ('year', 23), ('p', 21), ("'t", 19), ('have', 14)] |  | blend:0.587  W28:0.59,W2:0.25,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 22:06:07 | 80 | LR0.0003 | logitMin:-18.3603 | logitMax:8.4430 | scheduledSampling:0.0000 | lossTUTOR:7.1312 | windowWeightsW2:2.34221 (0.59),W4:1.94308 (0.40),W8:-2.01676 (0.01),W12:-6.72382 (0.00),W16:-9.21372 (0.00),W20:-10.71887 (0.00),W24:-11.49558 (0.00),W32:-11.70382 (0.00),W28:-12.01277 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('the', 71), ('c', 52), ('to', 41), ('and', 28), ('.', 26), ('i', 24), ('con', 24), ('year', 23), ('p', 21), ('1', 20)] |  | blend:0.587  W28:0.59,W2:0.25,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 22:07:27 | 100 | LR0.0003 | logitMin:-26.0593 | logitMax:8.6273 | scheduledSampling:0.0000 | lossTUTOR:7.0088 | windowWeightsW2:2.34102 (0.59),W4:1.94421 (0.40),W8:-2.01530 (0.01),W12:-6.72125 (0.00),W16:-9.21123 (0.00),W20:-10.71685 (0.00),W24:-11.49397 (0.00),W32:-11.70230 (0.00),W28:-12.01204 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('the', 72), ('i', 69), ('c', 52), ('to', 41), ('a', 38), ('and', 28), ('.', 26), ('con', 24), ('year', 23), ('p', 21)] |  | blend:0.588  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 22:08:46 | 120 | LR0.0003 | logitMin:-25.6587 | logitMax:8.2439 | scheduledSampling:0.0000 | lossTUTOR:4.0492 | windowWeightsW2:2.33941 (0.59),W4:1.94571 (0.40),W8:-2.01117 (0.01),W12:-6.71632 (0.00),W16:-9.20661 (0.00),W20:-10.71312 (0.00),W24:-11.49151 (0.00),W32:-11.69923 (0.00),W28:-12.01045 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('the', 78), ('i', 70), ('c', 67), ('to', 46), ('.', 45), ('a', 38), ('and', 28), ('process', 27), ('con', 24), ('year', 23)] |  | blend:0.588  W32:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 22:10:06 | 140 | LR0.0003 | logitMin:-20.8484 | logitMax:7.5831 | scheduledSampling:0.0000 | lossTUTOR:6.8941 | windowWeightsW2:2.33968 (0.59),W4:1.94536 (0.40),W8:-2.00956 (0.01),W12:-6.71415 (0.00),W16:-9.20459 (0.00),W20:-10.71150 (0.00),W24:-11.49032 (0.00),W32:-11.69836 (0.00),W28:-12.01037 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('the', 80), ('i', 77), ('c', 67), ('.', 50), ('to', 49), ('a', 38), ('and', 37), ('p', 33), ('is', 33), ('it', 32)] |  | blend:0.588  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 22:11:26 | 160 | LR0.0003 | logitMin:-19.9783 | logitMax:6.8826 | scheduledSampling:0.0000 | lossTUTOR:7.3708 | windowWeightsW2:2.33870 (0.59),W4:1.94626 (0.40),W8:-2.00719 (0.01),W12:-6.71108 (0.00),W16:-9.20174 (0.00),W20:-10.70923 (0.00),W24:-11.48842 (0.00),W32:-11.69692 (0.00),W28:-12.00980 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('i', 82), ('the', 81), ('c', 67), ('.', 59), ('a', 50), ('to', 49), ('and', 42), ('p', 33), ('is', 33), ('it', 32)] |  | blend:0.589  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 22:12:48 | 180 | LR0.0003 | logitMin:-28.9742 | logitMax:12.3827 | scheduledSampling:0.0000 | lossTUTOR:11.6868 | windowWeightsW2:2.33802 (0.59),W4:1.94689 (0.40),W8:-2.00606 (0.01),W12:-6.70848 (0.00),W16:-9.19942 (0.00),W20:-10.70739 (0.00),W24:-11.48689 (0.00),W32:-11.69572 (0.00),W28:-12.00948 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('.', 119), ('i', 100), ('the', 86), ('c', 67), ('to', 53), ('a', 50), ('and', 42), (',', 34), ('p', 33), ('is', 33)] |  | blend:0.589  W28:0.59,W2:0.24,W4:0.16,W8:0.00 | TUTOR.py 20
2025-04-14 22:14:10 | 200 | LR0.0003 | logitMin:-18.4860 | logitMax:7.6712 | scheduledSampling:0.0000 | lossTUTOR:4.8190 | windowWeightsW2:2.33450 (0.59),W4:1.95035 (0.40),W8:-2.00288 (0.01),W12:-6.70299 (0.00),W16:-9.19429 (0.00),W20:-10.70334 (0.00),W24:-11.48408 (0.00),W32:-11.69270 (0.00),W28:-12.00867 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('.', 120), ('i', 105), ('the', 93), ('c', 67), ('to', 60), ('a', 55), (',', 45), ('and', 42), ('p', 33), ('is', 33)] |  | blend:0.589  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:15:32 | 220 | LR0.0003 | logitMin:-16.3471 | logitMax:17.1004 | scheduledSampling:0.0000 | lossTUTOR:8.3376 | windowWeightsW2:2.33138 (0.59),W4:1.95341 (0.40),W8:-2.00009 (0.01),W12:-6.69804 (0.00),W16:-9.18956 (0.00),W20:-10.69957 (0.00),W24:-11.48028 (0.00),W32:-11.68948 (0.00),W28:-12.00894 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('.', 127), ('i', 105), ('the', 97), ('c', 67), ('to', 60), ('a', 58), (',', 45), ('and', 42), ('p', 33), ('is', 33)] |  | blend:0.589  W24:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:16:52 | 240 | LR0.0003 | logitMin:-27.1986 | logitMax:12.8724 | scheduledSampling:0.0000 | lossTUTOR:4.0309 | windowWeightsW2:2.32893 (0.59),W4:1.95569 (0.40),W8:-1.99380 (0.01),W12:-6.69219 (0.00),W16:-9.18393 (0.00),W20:-10.69501 (0.00),W24:-11.47668 (0.00),W32:-11.68664 (0.00),W28:-12.00900 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('.', 127), ('i', 105), ('the', 97), ('a', 72), ('c', 67), ('to', 66), (',', 45), ('and', 43), ('on', 43), ('can', 37)] |  | blend:0.589  W32:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:18:12 | 260 | LR0.0003 | logitMin:-26.5209 | logitMax:20.2745 | scheduledSampling:0.0000 | lossTUTOR:8.6010 | windowWeightsW2:2.32902 (0.59),W4:1.95547 (0.40),W8:-1.98984 (0.01),W12:-6.68662 (0.00),W16:-9.17867 (0.00),W20:-10.69067 (0.00),W24:-11.47324 (0.00),W32:-11.68505 (0.00),W28:-12.00856 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('.', 127), ('i', 114), ('the', 97), ('a', 72), ('c', 67), ('to', 66), ('and', 59), (',', 45), ('on', 43), ('can', 37)] |  | blend:0.588  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:19:32 | 280 | LR0.0003 | logitMin:-39.0874 | logitMax:11.3630 | scheduledSampling:0.0000 | lossTUTOR:6.8457 | windowWeightsW2:2.32866 (0.59),W4:1.95575 (0.40),W8:-1.98798 (0.01),W12:-6.68252 (0.00),W16:-9.17491 (0.00),W20:-10.68758 (0.00),W24:-11.47125 (0.00),W32:-11.68389 (0.00),W28:-12.00842 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('i', 134), ('.', 128), ('the', 97), ('a', 72), ('to', 68), ('c', 67), ('and', 59), (',', 54), ('is', 46), ('on', 43)] |  | blend:0.588  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:20:52 | 300 | LR0.0003 | logitMin:-30.0652 | logitMax:10.1775 | scheduledSampling:0.0000 | lossTUTOR:5.0651 | windowWeightsW2:2.32646 (0.59),W4:1.95788 (0.41),W8:-1.98524 (0.01),W12:-6.67740 (0.00),W16:-9.17023 (0.00),W20:-10.68372 (0.00),W24:-11.46888 (0.00),W32:-11.68296 (0.00),W28:-12.00707 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('i', 136), ('.', 135), ('the', 101), ('to', 72), ('a', 72), ('c', 67), ('and', 59), (',', 55), ('is', 46), ('on', 46)] |  | blend:0.589  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:22:11 | 320 | LR0.0003 | logitMin:-22.3448 | logitMax:9.3199 | scheduledSampling:0.0000 | lossTUTOR:3.9659 | windowWeightsW2:2.32196 (0.58),W4:1.96234 (0.41),W8:-1.98246 (0.01),W12:-6.67302 (0.00),W16:-9.16619 (0.00),W20:-10.68035 (0.00),W24:-11.46628 (0.00),W32:-11.68051 (0.00),W28:-12.00611 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('i', 149), ('.', 139), ('the', 119), ('to', 72), ('a', 72), ('c', 67), ('and', 59), (',', 58), ('is', 52), ('on', 46)] |  | blend:0.589  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:23:31 | 340 | LR0.0003 | logitMin:-29.9688 | logitMax:32.6562 | scheduledSampling:0.0000 | lossTUTOR:11.2007 | windowWeightsW2:2.32085 (0.58),W4:1.96339 (0.41),W8:-1.98092 (0.01),W12:-6.66912 (0.00),W16:-9.16254 (0.00),W20:-10.67730 (0.00),W24:-11.46418 (0.00),W32:-11.67904 (0.00),W28:-12.00567 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('i', 149), ('.', 139), ('the', 131), ('to', 75), ('a', 72), ('c', 67), ('and', 59), (',', 58), ('is', 52), ('on', 46)] |  | blend:0.589  W32:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:24:51 | 360 | LR0.0003 | logitMin:-22.3036 | logitMax:13.2753 | scheduledSampling:0.0000 | lossTUTOR:8.8025 | windowWeightsW2:2.32088 (0.58),W4:1.96330 (0.41),W8:-1.97967 (0.01),W12:-6.66665 (0.00),W16:-9.16020 (0.00),W20:-10.67535 (0.00),W24:-11.46255 (0.00),W32:-11.67750 (0.00),W28:-12.00606 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('i', 149), ('the', 148), ('.', 139), ('to', 75), ('for', 73), ('a', 72), ('c', 67), ('and', 59), (',', 58), ('is', 52)] |  | blend:0.589  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:26:11 | 380 | LR0.0003 | logitMin:-19.6041 | logitMax:9.5703 | scheduledSampling:0.0000 | lossTUTOR:3.3288 | windowWeightsW2:2.32211 (0.58),W4:1.96187 (0.41),W8:-1.97394 (0.01),W12:-6.66053 (0.00),W16:-9.15428 (0.00),W20:-10.67039 (0.00),W24:-11.45845 (0.00),W32:-11.67313 (0.00),W28:-12.00511 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('i', 149), ('the', 148), ('.', 140), ('a', 84), ('to', 80), ('for', 78), ('c', 67), ('and', 59), (',', 58), ('is', 52)] |  | blend:0.589  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:27:31 | 400 | LR0.0003 | logitMin:-27.6915 | logitMax:10.5068 | scheduledSampling:0.0000 | lossTUTOR:8.7936 | windowWeightsW2:2.32526 (0.59),W4:1.95857 (0.41),W8:-1.97062 (0.01),W12:-6.65625 (0.00),W16:-9.15029 (0.00),W20:-10.66703 (0.00),W24:-11.45546 (0.00),W32:-11.67107 (0.00),W28:-12.00481 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('i', 149), ('the', 148), ('.', 140), ('to', 95), ('a', 84), ('for', 78), ('c', 67), ('and', 59), ('-', 59), (',', 58)] |  | blend:0.589  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:28:54 | 420 | LR0.0003 | logitMin:-27.0091 | logitMax:7.4263 | scheduledSampling:0.0000 | lossTUTOR:8.7606 | windowWeightsW2:2.32549 (0.59),W4:1.95826 (0.41),W8:-1.96867 (0.01),W12:-6.65414 (0.00),W16:-9.14840 (0.00),W20:-10.66545 (0.00),W24:-11.45424 (0.00),W32:-11.66996 (0.00),W28:-12.00455 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('i', 149), ('the', 148), ('.', 140), ('to', 105), ('a', 84), ('of', 83), (')', 80), ('for', 78), ('c', 67), ('-', 63)] |  | blend:0.589  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:30:17 | 440 | LR0.0003 | logitMin:-22.0754 | logitMax:7.1118 | scheduledSampling:0.0000 | lossTUTOR:4.4653 | windowWeightsW2:2.32494 (0.59),W4:1.95876 (0.41),W8:-1.96760 (0.01),W12:-6.65164 (0.00),W16:-9.14601 (0.00),W20:-10.66345 (0.00),W24:-11.45297 (0.00),W32:-11.66859 (0.00),W28:-12.00394 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('the', 152), ('i', 149), ('.', 140), ('to', 117), ('of', 99), ('a', 84), (')', 82), ('and', 79), ('-', 79), ('for', 78)] |  | blend:0.589  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:31:49 | 460 | LR0.0003 | logitMin:-19.8390 | logitMax:7.5483 | scheduledSampling:0.0000 | lossTUTOR:5.3139 | windowWeightsW2:2.32491 (0.59),W4:1.95872 (0.41),W8:-1.96615 (0.01),W12:-6.64930 (0.00),W16:-9.14383 (0.00),W20:-10.66162 (0.00),W24:-11.45162 (0.00),W32:-11.66730 (0.00),W28:-12.00341 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('the', 173), ('i', 149), ('.', 140), ('to', 117), ('of', 101), ('a', 87), (')', 82), (',', 80), ('and', 79), ('-', 79)] |  | blend:0.590  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:33:18 | 480 | LR0.0003 | logitMin:-23.4756 | logitMax:6.0375 | scheduledSampling:0.0000 | lossTUTOR:3.8686 | windowWeightsW2:2.32227 (0.58),W4:1.96122 (0.41),W8:-1.96155 (0.01),W12:-6.64459 (0.00),W16:-9.13942 (0.00),W20:-10.65792 (0.00),W24:-11.44879 (0.00),W32:-11.66457 (0.00),W28:-12.00175 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('the', 210), ('i', 149), ('.', 140), ('to', 117), ('of', 107), ('a', 98), (')', 84), ('-', 81), (',', 80), ('and', 79)] |  | blend:0.590  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20

--- 2025-04-14 22:38:23 --- babyLLM 'right, last time i got to step 402... want to restart from there?'  - charis: '800' - babyLLM 'damn that's specific! heading to step 800... what am i learning today?' - charis: ''
2025-04-14 22:39:38 | 20 | LR0.0003 | logitMin:-23.1090 | logitMax:11.9540 | scheduledSampling:0.0000 | lossTUTOR:1.0985 | windowWeightsW2:2.32009 (0.58),W4:1.96327 (0.41),W8:-1.95777 (0.01),W12:-6.64041 (0.00),W16:-9.13571 (0.00),W20:-10.65518 (0.00),W24:-11.44677 (0.00),W32:-11.66307 (0.00),W28:-12.00111 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('bad', 18), ('ft', 16), (',', 15), ('.', 11), ('this', 10), ('c', 10), ('er', 10), ('so', 9), ('ise', 8), ('different', 7)] |  | blend:0.591  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:40:57 | 40 | LR0.0003 | logitMin:-19.1333 | logitMax:14.7871 | scheduledSampling:0.0000 | lossTUTOR:1.8970 | windowWeightsW2:2.32004 (0.58),W4:1.96332 (0.41),W8:-1.95865 (0.01),W12:-6.63898 (0.00),W16:-9.13462 (0.00),W20:-10.65445 (0.00),W24:-11.44643 (0.00),W32:-11.66294 (0.00),W28:-12.00191 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('ft', 20), ('er', 20), ('bad', 18), ('.', 17), ('the', 17), ('on', 16), (',', 15), ('g', 14), ('s', 14), ('c', 13)] |  | blend:0.590  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:42:15 | 60 | LR0.0003 | logitMin:-17.1463 | logitMax:13.1064 | scheduledSampling:0.0000 | lossTUTOR:0.0129 | windowWeightsW2:2.32027 (0.58),W4:1.96303 (0.41),W8:-1.95774 (0.01),W12:-6.63544 (0.00),W16:-9.13109 (0.00),W20:-10.65167 (0.00),W24:-11.44421 (0.00),W32:-11.66105 (0.00),W28:-12.00327 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[('er', 26), (',', 25), ('the', 22), ('.', 20), ('ft', 20), ('bad', 18), ('on', 17), ('l', 17), ('of', 15), ('s', 15)] |  | blend:0.589  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:43:34 | 80 | LR0.0003 | logitMin:-24.7718 | logitMax:16.5028 | scheduledSampling:0.0000 | lossTUTOR:0.3995 | windowWeightsW2:2.32142 (0.58),W4:1.96186 (0.41),W8:-1.95835 (0.01),W12:-6.63315 (0.00),W16:-9.12857 (0.00),W20:-10.64966 (0.00),W24:-11.44242 (0.00),W32:-11.65957 (0.00),W28:-12.00384 (0.00) | judgeBiasW32:-0.00093 (0.11),W2:-0.00093 (0.11),W4:-0.00093 (0.11),W8:-0.00093 (0.11),W12:-0.00093 (0.11),W16:-0.00093 (0.11),W20:-0.00093 (0.11),W24:-0.00093 (0.11),W28:-0.00093 (0.11) | credibilityBiasW32:0.11128 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11094 (-0.00) | topTokens[(',', 28), ('.', 27), ('er', 26), ('the', 25), ('ed', 25), ('of', 23), ('bad', 21), ('ft', 20), ('this', 19), ('so', 18)] |  | blend:0.589  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20

--- 2025-04-14 22:44:43 --- babyLLM 'right, last time i got to step 801... want to restart from there?'  - charis: '900' - babyLLM 'damn that's specific! heading to step 900... what am i learning today?' - charis: ''
2025-04-14 22:46:00 | 20 | LR0.0003 | logitMin:-23.3086 | logitMax:11.3304 | scheduledSampling:0.0000 | lossTUTOR:3.4537 | windowWeightsW2:2.31637 (0.58),W4:1.96685 (0.41),W8:-1.95323 (0.01),W12:-6.62738 (0.00),W16:-9.12464 (0.00),W20:-10.64719 (0.00),W24:-11.44129 (0.00),W32:-11.66010 (0.00),W28:-12.00049 (0.00) | judgeBiasW32:-0.00230 (0.11),W2:-0.00230 (0.11),W4:-0.00230 (0.11),W8:-0.00230 (0.11),W12:-0.00230 (0.11),W16:-0.00230 (0.11),W20:-0.00230 (0.11),W24:-0.00230 (0.11),W28:-0.00230 (0.11) | credibilityBiasW32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11110 (-0.00) | topTokens[('.', 10), ('i', 10), (',', 8), ('vis', 8), ('-', 8), ('h', 7), ('blue', 6), ('en', 6), ('that', 6), ('ye', 6)] |  | blend:0.589  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:47:21 | 40 | LR0.0003 | logitMin:-22.9211 | logitMax:8.8093 | scheduledSampling:0.0000 | lossTUTOR:7.2426 | windowWeightsW2:2.31634 (0.58),W4:1.96677 (0.41),W8:-1.95041 (0.01),W12:-6.62349 (0.00),W16:-9.12091 (0.00),W20:-10.64411 (0.00),W24:-11.43839 (0.00),W32:-11.65899 (0.00),W28:-12.00000 (0.00) | judgeBiasW32:-0.00230 (0.11),W2:-0.00230 (0.11),W4:-0.00230 (0.11),W8:-0.00230 (0.11),W12:-0.00230 (0.11),W16:-0.00230 (0.11),W20:-0.00230 (0.11),W24:-0.00230 (0.11),W28:-0.00230 (0.11) | credibilityBiasW32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11110 (-0.00) | topTokens[('d', 33), ('t', 18), ('hair', 16), ('.', 15), ('io', 13), ('out', 13), ('le', 12), ('i', 11), ('-', 10), ('ye', 10)] |  | blend:0.589  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:48:41 | 60 | LR0.0003 | logitMin:-20.1515 | logitMax:7.1468 | scheduledSampling:0.0000 | lossTUTOR:3.5587 | windowWeightsW2:2.31619 (0.58),W4:1.96684 (0.41),W8:-1.94812 (0.01),W12:-6.62085 (0.00),W16:-9.11841 (0.00),W20:-10.64215 (0.00),W24:-11.43670 (0.00),W32:-11.65709 (0.00),W28:-11.99925 (0.00) | judgeBiasW32:-0.00230 (0.11),W2:-0.00230 (0.11),W4:-0.00230 (0.11),W8:-0.00230 (0.11),W12:-0.00230 (0.11),W16:-0.00230 (0.11),W20:-0.00230 (0.11),W24:-0.00230 (0.11),W28:-0.00230 (0.11) | credibilityBiasW32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11110 (-0.00) | topTokens[('v', 49), ('.', 38), ('d', 33), ('t', 18), ('hair', 16), ('ye', 16), ('i', 15), ('g', 15), ('io', 13), ('out', 13)] |  | blend:0.589  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:50:02 | 80 | LR0.0003 | logitMin:-14.7100 | logitMax:7.1395 | scheduledSampling:0.0000 | lossTUTOR:4.1362 | windowWeightsW2:2.31525 (0.58),W4:1.96772 (0.41),W8:-1.94653 (0.01),W12:-6.61889 (0.00),W16:-9.11657 (0.00),W20:-10.64050 (0.00),W24:-11.43512 (0.00),W32:-11.65571 (0.00),W28:-11.99831 (0.00) | judgeBiasW32:-0.00230 (0.11),W2:-0.00230 (0.11),W4:-0.00230 (0.11),W8:-0.00230 (0.11),W12:-0.00230 (0.11),W16:-0.00230 (0.11),W20:-0.00230 (0.11),W24:-0.00230 (0.11),W28:-0.00230 (0.11) | credibilityBiasW32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11110 (-0.00) | topTokens[('v', 49), ('d', 40), ('.', 39), ('co', 26), ('with', 26), ('second', 21), ('i', 18), ('t', 18), ('hair', 16), ('ye', 16)] |  | blend:0.589  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20

--- 2025-04-14 22:51:41 --- babyLLM 'right, last time i got to step 901... want to restart from there?'  - charis: '990' - babyLLM 'damn that's specific! heading to step 990... what am i learning today?' - charis: ''
2025-04-14 22:53:01 | 20 | LR0.0003 | logitMin:-18.0828 | logitMax:7.6108 | scheduledSampling:0.0000 | lossTUTOR:3.7759 | windowWeightsW2:2.31454 (0.58),W4:1.96834 (0.41),W8:-1.94295 (0.01),W12:-6.61569 (0.00),W16:-9.11410 (0.00),W20:-10.63913 (0.00),W24:-11.43418 (0.00),W32:-11.65442 (0.00),W28:-11.99790 (0.00) | judgeBiasW32:-0.00230 (0.11),W2:-0.00230 (0.11),W4:-0.00230 (0.11),W8:-0.00230 (0.11),W12:-0.00230 (0.11),W16:-0.00230 (0.11),W20:-0.00230 (0.11),W24:-0.00230 (0.11),W28:-0.00230 (0.11) | credibilityBiasW32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11110 (-0.00) | topTokens[('ad', 16), ('g', 11), ('y', 11), ('ld', 9), ('is', 8), ('blue', 8), ('re', 8), ('it', 7), ('though', 7), (',', 7)] |  | blend:0.590  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:54:22 | 40 | LR0.0003 | logitMin:-15.1239 | logitMax:10.2544 | scheduledSampling:0.0000 | lossTUTOR:3.4030 | windowWeightsW2:2.31681 (0.58),W4:1.96591 (0.41),W8:-1.94171 (0.01),W12:-6.61276 (0.00),W16:-9.11166 (0.00),W20:-10.63753 (0.00),W24:-11.43260 (0.00),W32:-11.65355 (0.00),W28:-11.99838 (0.00) | judgeBiasW32:-0.00230 (0.11),W2:-0.00230 (0.11),W4:-0.00230 (0.11),W8:-0.00230 (0.11),W12:-0.00230 (0.11),W16:-0.00230 (0.11),W20:-0.00230 (0.11),W24:-0.00230 (0.11),W28:-0.00230 (0.11) | credibilityBiasW32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11110 (-0.00) | topTokens[('blue', 21), ('.', 16), ('ad', 16), ('g', 14), ('y', 12), ('i', 11), ('the', 10), ('it', 10), (',', 10), ('to', 10)] |  | blend:0.589  W28:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20
2025-04-14 22:55:45 | 60 | LR0.0003 | logitMin:-17.2871 | logitMax:8.4322 | scheduledSampling:0.0000 | lossTUTOR:4.2586 | windowWeightsW2:2.31665 (0.58),W4:1.96599 (0.41),W8:-1.94011 (0.01),W12:-6.60821 (0.00),W16:-9.10751 (0.00),W20:-10.63429 (0.00),W24:-11.43051 (0.00),W32:-11.65219 (0.00),W28:-11.99754 (0.00) | judgeBiasW32:-0.00230 (0.11),W2:-0.00230 (0.11),W4:-0.00230 (0.11),W8:-0.00230 (0.11),W12:-0.00230 (0.11),W16:-0.00230 (0.11),W20:-0.00230 (0.11),W24:-0.00230 (0.11),W28:-0.00230 (0.11) | credibilityBiasW32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11110 (-0.00) | topTokens[('it', 27), ('to', 27), ('i', 26), ('.', 21), ('blue', 21), ('the', 19), ('ad', 16), ('y', 15), ('g', 14), ("'m", 13)] |  | blend:0.590  W32:0.59,W2:0.24,W4:0.17,W8:0.00 | TUTOR.py 20

--- 2025-04-14 22:57:00 --- babyLLM 'right, last time i got to step 991... want to restart from there?'  - charis: '1020' - babyLLM 'damn that's specific! heading to step 1020... what am i learning today?' - charis: ''
2025-04-14 22:58:18 | 20 | LR0.0003 | logitMin:-26.7840 | logitMax:8.4367 | scheduledSampling:0.0000 | lossTUTOR:3.8287 | windowWeightsW2:2.31556 (0.58),W4:1.96701 (0.41),W8:-1.93875 (0.01),W12:-6.60633 (0.00),W16:-9.10577 (0.00),W20:-10.63290 (0.00),W24:-11.42951 (0.00),W32:-11.65128 (0.00),W28:-11.99684 (0.00) | judgeBiasW32:-0.00230 (0.11),W2:-0.00230 (0.11),W4:-0.00230 (0.11),W8:-0.00230 (0.11),W12:-0.00230 (0.11),W16:-0.00230 (0.11),W20:-0.00230 (0.11),W24:-0.00230 (0.11),W28:-0.00230 (0.11) | credibilityBiasW32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11110 (-0.00) | topTokens[('it', 32), ('is', 19), ('for', 18), ('to', 16), ("'m", 9), ('through', 8), ('ac', 8), ('f', 8), ('.', 7), ('li', 7)] |  | blend:0.590  W28:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 20
2025-04-14 22:59:40 | 40 | LR0.0003 | logitMin:-21.1697 | logitMax:15.0688 | scheduledSampling:0.0000 | lossTUTOR:6.8075 | windowWeightsW2:2.31555 (0.58),W4:1.96699 (0.41),W8:-1.93874 (0.01),W12:-6.60630 (0.00),W16:-9.10572 (0.00),W20:-10.63284 (0.00),W24:-11.42944 (0.00),W32:-11.65120 (0.00),W28:-11.99677 (0.00) | judgeBiasW32:-0.00230 (0.11),W2:-0.00230 (0.11),W4:-0.00230 (0.11),W8:-0.00230 (0.11),W12:-0.00230 (0.11),W16:-0.00230 (0.11),W20:-0.00230 (0.11),W24:-0.00230 (0.11),W28:-0.00230 (0.11) | credibilityBiasW32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11110 (-0.00) | topTokens[('it', 61), ('is', 28), ('to', 21), ('for', 19), ('y', 16), ('li', 15), ('the', 15), ('f', 14), ('li', 13), ('some', 13)] |  | blend:0.590  W28:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 20
2025-04-14 23:01:03 | 60 | LR0.0003 | logitMin:-19.9326 | logitMax:11.6239 | scheduledSampling:0.0000 | lossTUTOR:31.8571 | windowWeightsW2:2.31553 (0.58),W4:1.96698 (0.41),W8:-1.93872 (0.01),W12:-6.60626 (0.00),W16:-9.10566 (0.00),W20:-10.63279 (0.00),W24:-11.42936 (0.00),W32:-11.65113 (0.00),W28:-11.99669 (0.00) | judgeBiasW32:-0.00230 (0.11),W2:-0.00230 (0.11),W4:-0.00230 (0.11),W8:-0.00230 (0.11),W12:-0.00230 (0.11),W16:-0.00230 (0.11),W20:-0.00230 (0.11),W24:-0.00230 (0.11),W28:-0.00230 (0.11) | credibilityBiasW32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W20:0.11111 (0.00),W24:0.11111 (0.00),W28:0.11110 (-0.00) | topTokens[('the', 124), ('it', 70), ('is', 40), ('to', 32), ('.', 20), ('for', 19), ('(', 16), ('some', 16), ('y', 16), ('li', 15)] |  | blend:0.590  W32:1.00,W2:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:02:26 | 80 | LR0.0003 | logitMin:-19.0602 | logitMax:17.3619 | scheduledSampling:0.0000 | lossTUTOR:25.4762 | windowWeightsW2:2.31657 (0.58),W4:1.96803 (0.41),W8:-1.93766 (0.01),W12:-6.60516 (0.00),W16:-9.10455 (0.00),W20:-10.63379 (0.00),W24:-11.42823 (0.00),W32:-11.64999 (0.00),W28:-11.99555 (0.00) | judgeBiasW32:-0.00125 (0.11),W2:-0.00125 (0.11),W4:-0.00125 (0.11),W8:-0.00125 (0.11),W12:-0.00125 (0.11),W16:-0.00125 (0.11),W20:-0.00125 (0.11),W24:-0.00125 (0.11),W28:-0.00125 (0.11) | credibilityBiasW28:0.11122 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11099 (-0.00) | topTokens[('the', 124), ('it', 112), ('is', 48), ('s', 37), ('to', 32), ('i', 28), ('ac', 26), ('(', 21), ('.', 20), ('for', 19)] |  | blend:0.590  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:03:50 | 100 | LR0.0003 | logitMin:-32.6400 | logitMax:40.7541 | scheduledSampling:0.0000 | lossTUTOR:29.7032 | windowWeightsW2:2.31798 (0.58),W4:1.96943 (0.41),W8:-1.93623 (0.01),W12:-6.60371 (0.00),W16:-9.10307 (0.00),W20:-10.63517 (0.00),W24:-11.42673 (0.00),W32:-11.64850 (0.00),W28:-11.99404 (0.00) | judgeBiasW32:0.00017 (0.11),W2:0.00017 (0.11),W4:0.00017 (0.11),W8:0.00017 (0.11),W12:0.00017 (0.11),W16:0.00017 (0.11),W20:0.00017 (0.11),W24:0.00017 (0.11),W28:0.00017 (0.11) | credibilityBiasW28:0.11138 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11083 (-0.00) | topTokens[('in', 161), ('the', 127), ('it', 112), ('is', 52), ('s', 41), ('to', 40), ('i', 38), ('ac', 26), ('(', 21), ('.', 20)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:05:14 | 120 | LR0.0003 | logitMin:-27.4079 | logitMax:11.1164 | scheduledSampling:0.0000 | lossTUTOR:6.8563 | windowWeightsW2:2.31816 (0.58),W4:1.96961 (0.41),W8:-1.93602 (0.01),W12:-6.60348 (0.00),W16:-9.10282 (0.00),W20:-10.63530 (0.00),W24:-11.42647 (0.00),W32:-11.64823 (0.00),W28:-11.99378 (0.00) | judgeBiasW32:0.00036 (0.11),W2:0.00036 (0.11),W4:0.00036 (0.11),W8:0.00036 (0.11),W12:0.00036 (0.11),W16:0.00036 (0.11),W20:0.00036 (0.11),W24:0.00036 (0.11),W28:0.00036 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('in', 201), ('the', 128), ('it', 112), ('i', 66), ('to', 56), ('is', 55), ('s', 42), ('ac', 26), ('(', 21), ('for', 20)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:06:36 | 140 | LR0.0003 | logitMin:-35.2110 | logitMax:17.0730 | scheduledSampling:0.0000 | lossTUTOR:6.7696 | windowWeightsW2:2.31817 (0.58),W4:1.96963 (0.41),W8:-1.93599 (0.01),W12:-6.60342 (0.00),W16:-9.10274 (0.00),W20:-10.63527 (0.00),W24:-11.42636 (0.00),W32:-11.64813 (0.00),W28:-11.99367 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('in', 201), ('the', 129), ('it', 121), ('i', 71), ('is', 65), ('to', 56), ('b', 48), ('s', 42), ('.', 28), ('ac', 26)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:07:58 | 160 | LR0.0003 | logitMin:-17.9081 | logitMax:11.9368 | scheduledSampling:0.0000 | lossTUTOR:13.8621 | windowWeightsW2:2.31816 (0.58),W4:1.96962 (0.41),W8:-1.93597 (0.01),W12:-6.60338 (0.00),W16:-9.10268 (0.00),W20:-10.63521 (0.00),W24:-11.42629 (0.00),W32:-11.64806 (0.00),W28:-11.99360 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('in', 201), ('it', 132), ('the', 131), ('is', 73), ('i', 71), ('to', 57), ('b', 48), ('s', 42), ('ish', 32), ('iss', 29)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:09:20 | 180 | LR0.0003 | logitMin:-23.0595 | logitMax:26.2238 | scheduledSampling:0.0000 | lossTUTOR:16.8236 | windowWeightsW2:2.31814 (0.58),W4:1.96961 (0.41),W8:-1.93596 (0.01),W12:-6.60334 (0.00),W16:-9.10262 (0.00),W20:-10.63515 (0.00),W24:-11.42621 (0.00),W32:-11.64798 (0.00),W28:-11.99352 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('in', 201), ('the', 164), ('it', 134), ('is', 86), ('i', 73), ('to', 61), ('b', 48), ('s', 42), ('ish', 32), ('iss', 29)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:10:43 | 200 | LR0.0003 | logitMin:-39.8290 | logitMax:18.2682 | scheduledSampling:0.0000 | lossTUTOR:6.2911 | windowWeightsW2:2.31813 (0.58),W4:1.96959 (0.41),W8:-1.93595 (0.01),W12:-6.60330 (0.00),W16:-9.10257 (0.00),W20:-10.63510 (0.00),W24:-11.42614 (0.00),W32:-11.64790 (0.00),W28:-11.99345 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('in', 201), ('the', 195), ('it', 153), ('is', 86), ('i', 78), ('to', 61), ('b', 48), ('s', 44), ('.', 34), ('but', 32)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:12:06 | 220 | LR0.0003 | logitMin:-19.9246 | logitMax:25.0586 | scheduledSampling:0.0000 | lossTUTOR:8.6503 | windowWeightsW2:2.31811 (0.58),W4:1.96958 (0.41),W8:-1.93593 (0.01),W12:-6.60326 (0.00),W16:-9.10251 (0.00),W20:-10.63504 (0.00),W24:-11.42606 (0.00),W32:-11.64783 (0.00),W28:-11.99337 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('in', 201), ('the', 195), ('it', 153), ('i', 94), ('is', 86), ('to', 61), ('b', 48), ('s', 44), ('.', 43), ('for', 39)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:13:32 | 240 | LR0.0003 | logitMin:-18.5898 | logitMax:13.6767 | scheduledSampling:0.0000 | lossTUTOR:17.1863 | windowWeightsW2:2.31810 (0.58),W4:1.96957 (0.41),W8:-1.93592 (0.01),W12:-6.60322 (0.00),W16:-9.10245 (0.00),W20:-10.63498 (0.00),W24:-11.42598 (0.00),W32:-11.64775 (0.00),W28:-11.99329 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('in', 201), ('the', 195), ('it', 153), ('i', 94), ('is', 86), ('to', 61), ('.', 52), ('b', 48), ('s', 46), (',', 41)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:14:56 | 260 | LR0.0003 | logitMin:-28.0279 | logitMax:14.7828 | scheduledSampling:0.0000 | lossTUTOR:17.1324 | windowWeightsW2:2.31809 (0.58),W4:1.96956 (0.41),W8:-1.93591 (0.01),W12:-6.60318 (0.00),W16:-9.10240 (0.00),W20:-10.63492 (0.00),W24:-11.42591 (0.00),W32:-11.64767 (0.00),W28:-11.99322 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('in', 201), ('the', 195), ('it', 153), ('i', 95), ('is', 86), (',', 74), ('to', 61), ('.', 61), ('b', 48), ('sorry', 48)] |  | blend:0.589  W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 20
2025-04-14 23:16:18 | 280 | LR0.0003 | logitMin:-21.2063 | logitMax:10.3415 | scheduledSampling:0.0000 | lossTUTOR:12.3279 | windowWeightsW2:2.31807 (0.58),W4:1.96955 (0.41),W8:-1.93590 (0.01),W12:-6.60315 (0.00),W16:-9.10234 (0.00),W20:-10.63487 (0.00),W24:-11.42583 (0.00),W32:-11.64760 (0.00),W28:-11.99314 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('in', 201), ('the', 197), ('it', 153), ('i', 104), ('is', 86), (',', 83), ('.', 80), ('to', 61), ('be', 52), ('b', 48)] |  | blend:0.589  W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 20
2025-04-14 23:17:40 | 300 | LR0.0003 | logitMin:-22.8489 | logitMax:15.6735 | scheduledSampling:0.0000 | lossTUTOR:9.3361 | windowWeightsW2:2.31806 (0.58),W4:1.96953 (0.41),W8:-1.93589 (0.01),W12:-6.60311 (0.00),W16:-9.10228 (0.00),W20:-10.63481 (0.00),W24:-11.42575 (0.00),W32:-11.64752 (0.00),W28:-11.99306 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('the', 214), ('in', 201), ('it', 153), ('i', 104), ('is', 89), (',', 85), ('.', 82), ('to', 61), ('this', 59), ('be', 53)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:19:00 | 320 | LR0.0003 | logitMin:-25.7082 | logitMax:14.9645 | scheduledSampling:0.0000 | lossTUTOR:10.0444 | windowWeightsW2:2.31804 (0.58),W4:1.96952 (0.41),W8:-1.93587 (0.01),W12:-6.60307 (0.00),W16:-9.10222 (0.00),W20:-10.63475 (0.00),W24:-11.42568 (0.00),W32:-11.64744 (0.00),W28:-11.99299 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('the', 225), ('in', 201), ('it', 153), ('i', 104), ('is', 92), (',', 89), ('.', 86), ('to', 76), ('this', 59), ('be', 53)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:20:21 | 340 | LR0.0003 | logitMin:-25.8774 | logitMax:19.9342 | scheduledSampling:0.0000 | lossTUTOR:12.7839 | windowWeightsW2:2.31803 (0.58),W4:1.96951 (0.41),W8:-1.93586 (0.01),W12:-6.60303 (0.00),W16:-9.10217 (0.00),W20:-10.63470 (0.00),W24:-11.42560 (0.00),W32:-11.64737 (0.00),W28:-11.99291 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('the', 272), ('in', 201), ('it', 153), ('.', 111), ('i', 107), ('is', 92), (',', 89), ('to', 76), ('this', 59), ('be', 53)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:21:41 | 360 | LR0.0003 | logitMin:-23.6321 | logitMax:23.6472 | scheduledSampling:0.0000 | lossTUTOR:14.5997 | windowWeightsW2:2.31801 (0.58),W4:1.96950 (0.41),W8:-1.93585 (0.01),W12:-6.60299 (0.00),W16:-9.10211 (0.00),W20:-10.63464 (0.00),W24:-11.42553 (0.00),W32:-11.64729 (0.00),W28:-11.99284 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('the', 287), ('in', 201), ('it', 154), ('.', 119), ('i', 107), ('is', 93), (',', 90), ('to', 80), ('for', 69), ('this', 63)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:23:02 | 380 | LR0.0003 | logitMin:-19.7863 | logitMax:7.5109 | scheduledSampling:0.0000 | lossTUTOR:9.5325 | windowWeightsW2:2.31800 (0.58),W4:1.96949 (0.41),W8:-1.93584 (0.01),W12:-6.60296 (0.00),W16:-9.10205 (0.00),W20:-10.63458 (0.00),W24:-11.42545 (0.00),W32:-11.64722 (0.00),W28:-11.99276 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('the', 288), ('in', 201), ('it', 168), ('.', 121), ('i', 107), ('is', 102), (',', 92), ('to', 89), ('for', 69), ('this', 67)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:24:23 | 400 | LR0.0003 | logitMin:-30.5786 | logitMax:11.9994 | scheduledSampling:0.0000 | lossTUTOR:15.8615 | windowWeightsW2:2.31799 (0.58),W4:1.96947 (0.41),W8:-1.93583 (0.01),W12:-6.60292 (0.00),W16:-9.10200 (0.00),W20:-10.63452 (0.00),W24:-11.42537 (0.00),W32:-11.64714 (0.00),W28:-11.99268 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('the', 288), ('in', 201), ('it', 189), ('.', 121), (',', 108), ('i', 107), ('is', 102), ('to', 89), ('for', 69), ('this', 67)] |  | blend:0.589  W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 20
2025-04-14 23:25:43 | 420 | LR0.0003 | logitMin:-25.9970 | logitMax:27.6564 | scheduledSampling:0.0000 | lossTUTOR:13.7070 | windowWeightsW2:2.31797 (0.58),W4:1.96946 (0.41),W8:-1.93581 (0.01),W12:-6.60288 (0.00),W16:-9.10194 (0.00),W20:-10.63447 (0.00),W24:-11.42530 (0.00),W32:-11.64706 (0.00),W28:-11.99261 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('the', 288), ('in', 201), ('it', 189), ('.', 121), (',', 109), ('i', 107), ('is', 102), ('to', 89), ('for', 69), ('this', 67)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:27:04 | 440 | LR0.0003 | logitMin:-28.3604 | logitMax:16.2164 | scheduledSampling:0.0000 | lossTUTOR:16.7080 | windowWeightsW2:2.31796 (0.58),W4:1.96945 (0.41),W8:-1.93580 (0.01),W12:-6.60284 (0.00),W16:-9.10188 (0.00),W20:-10.63441 (0.00),W24:-11.42522 (0.00),W32:-11.64699 (0.00),W28:-11.99253 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('the', 288), ('in', 201), ('it', 190), ('i', 133), ('.', 121), (',', 109), ('is', 102), ('to', 95), ('for', 69), ('this', 67)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:28:26 | 460 | LR0.0003 | logitMin:-28.8211 | logitMax:21.0912 | scheduledSampling:0.0000 | lossTUTOR:16.5353 | windowWeightsW2:2.31794 (0.58),W4:1.96944 (0.41),W8:-1.93579 (0.01),W12:-6.60280 (0.00),W16:-9.10182 (0.00),W20:-10.63435 (0.00),W24:-11.42514 (0.00),W32:-11.64691 (0.00),W28:-11.99245 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('the', 288), ('in', 201), ('it', 192), ('i', 134), ('.', 121), (',', 111), ('to', 105), ('is', 102), ('this', 74), ('for', 69)] |  | blend:0.589  W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 20

--- 2025-04-14 23:30:28 --- babyLLM 'right, last time i got to step 1021... want to restart from there?'  - charis: '1500' - babyLLM 'damn that's specific! heading to step 1500... what am i learning today?' - charis: ''
2025-04-14 23:31:45 | 20 | LR0.0003 | logitMin:-31.5633 | logitMax:11.2026 | scheduledSampling:0.0000 | lossTUTOR:4.9102 | windowWeightsW2:2.31792 (0.58),W4:1.96942 (0.41),W8:-1.93577 (0.01),W12:-6.60273 (0.00),W16:-9.10172 (0.00),W20:-10.63425 (0.00),W24:-11.42500 (0.00),W32:-11.64677 (0.00),W28:-11.99231 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('he', 4), ('the', 4), ('this', 3), ('ne', 3), ("'d", 2), ('i', 2), ('l', 2), ('ning', 2), ('up', 1), ('ad', 1)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:33:04 | 40 | LR0.0003 | logitMin:-30.1206 | logitMax:27.2336 | scheduledSampling:0.0000 | lossTUTOR:26.6590 | windowWeightsW2:2.31790 (0.58),W4:1.96940 (0.41),W8:-1.93576 (0.01),W12:-6.60269 (0.00),W16:-9.10166 (0.00),W20:-10.63419 (0.00),W24:-11.42493 (0.00),W32:-11.64669 (0.00),W28:-11.99224 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[(',', 18), ('l', 6), ('he', 4), ('the', 4), ('less', 4), ('this', 3), ('ne', 3), ("'d", 2), ('ch', 2), ('i', 2)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:34:25 | 60 | LR0.0003 | logitMin:-24.6922 | logitMax:12.7171 | scheduledSampling:0.0000 | lossTUTOR:4.1300 | windowWeightsW2:2.31789 (0.58),W4:1.96939 (0.41),W8:-1.93575 (0.01),W12:-6.60266 (0.00),W16:-9.10160 (0.00),W20:-10.63413 (0.00),W24:-11.42485 (0.00),W32:-11.64662 (0.00),W28:-11.99216 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[(',', 18), ('he', 8), ('l', 6), ('to', 5), ('ne', 4), ('was', 4), ('the', 4), ('less', 4), ('this', 3), ('ning', 3)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:35:48 | 80 | LR0.0003 | logitMin:-52.0074 | logitMax:30.3966 | scheduledSampling:0.0000 | lossTUTOR:10.4492 | windowWeightsW2:2.31787 (0.58),W4:1.96938 (0.41),W8:-1.93573 (0.01),W12:-6.60262 (0.00),W16:-9.10155 (0.00),W20:-10.63408 (0.00),W24:-11.42477 (0.00),W32:-11.64654 (0.00),W28:-11.99208 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[(',', 19), ('he', 12), ('l', 6), ('ne', 6), ('his', 6), ('to', 5), ('really', 5), ('was', 4), ('the', 4), ('less', 4)] |  | blend:0.589  W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 20
2025-04-14 23:37:13 | 100 | LR0.0003 | logitMin:-20.6383 | logitMax:15.3008 | scheduledSampling:0.0000 | lossTUTOR:16.0556 | windowWeightsW2:2.31786 (0.58),W4:1.96937 (0.41),W8:-1.93572 (0.01),W12:-6.60258 (0.00),W16:-9.10149 (0.00),W20:-10.63402 (0.00),W24:-11.42470 (0.00),W32:-11.64646 (0.00),W28:-11.99201 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[(',', 20), ('with', 13), ('he', 12), ('l', 7), ('ne', 6), ('his', 6), ('to', 5), ('really', 5), ('was', 4), ('the', 4)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:38:38 | 120 | LR0.0003 | logitMin:-32.8868 | logitMax:16.0013 | scheduledSampling:0.0000 | lossTUTOR:17.5287 | windowWeightsW2:2.31784 (0.58),W4:1.96936 (0.41),W8:-1.93571 (0.01),W12:-6.60254 (0.00),W16:-9.10143 (0.00),W20:-10.63396 (0.00),W24:-11.42462 (0.00),W32:-11.64639 (0.00),W28:-11.99193 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[(',', 20), ('a', 19), ('don', 13), ('with', 13), ('he', 12), ('l', 7), ('ne', 6), ('to', 6), ('his', 6), ('really', 5)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:40:05 | 140 | LR0.0003 | logitMin:-19.8275 | logitMax:18.0343 | scheduledSampling:0.0000 | lossTUTOR:14.6850 | windowWeightsW2:2.31783 (0.58),W4:1.96934 (0.41),W8:-1.93570 (0.01),W12:-6.60250 (0.00),W16:-9.10137 (0.00),W20:-10.63390 (0.00),W24:-11.42455 (0.00),W32:-11.64631 (0.00),W28:-11.99185 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[(',', 20), ('a', 19), ('s', 19), ('don', 13), ('with', 13), ('he', 12), ('l', 10), ('up', 8), ('ne', 6), ('to', 6)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:41:32 | 160 | LR0.0003 | logitMin:-22.9559 | logitMax:12.6985 | scheduledSampling:0.0000 | lossTUTOR:10.2121 | windowWeightsW2:2.31782 (0.58),W4:1.96933 (0.41),W8:-1.93569 (0.01),W12:-6.60247 (0.00),W16:-9.10132 (0.00),W20:-10.63385 (0.00),W24:-11.42447 (0.00),W32:-11.64624 (0.00),W28:-11.99178 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('a', 22), (',', 20), ('s', 19), ('be', 14), ('don', 13), ('with', 13), ('he', 12), ('illy', 11), ('l', 10), ('up', 8)] |  | blend:0.589  W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 20
2025-04-14 23:43:00 | 180 | LR0.0003 | logitMin:-21.2482 | logitMax:8.9186 | scheduledSampling:0.0000 | lossTUTOR:7.9073 | windowWeightsW2:2.31780 (0.58),W4:1.96932 (0.41),W8:-1.93567 (0.01),W12:-6.60243 (0.00),W16:-9.10126 (0.00),W20:-10.63379 (0.00),W24:-11.42439 (0.00),W32:-11.64616 (0.00),W28:-11.99170 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[(',', 24), ('a', 22), ('s', 19), ('be', 14), ('don', 13), ('with', 13), ('he', 12), ('illy', 11), ('l', 10), ('?', 9)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:44:27 | 200 | LR0.0003 | logitMin:-29.1850 | logitMax:11.8919 | scheduledSampling:0.0000 | lossTUTOR:7.4414 | windowWeightsW2:2.31779 (0.58),W4:1.96931 (0.41),W8:-1.93566 (0.01),W12:-6.60239 (0.00),W16:-9.10120 (0.00),W20:-10.63373 (0.00),W24:-11.42432 (0.00),W32:-11.64608 (0.00),W28:-11.99163 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[(',', 24), ('a', 22), ('s', 19), ('be', 14), ('don', 13), ('with', 13), ('he', 12), ('to', 12), ('it', 12), ('illy', 11)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:45:53 | 220 | LR0.0003 | logitMin:-22.8657 | logitMax:24.2180 | scheduledSampling:0.0000 | lossTUTOR:12.9695 | windowWeightsW2:2.31777 (0.58),W4:1.96930 (0.41),W8:-1.93565 (0.01),W12:-6.60235 (0.00),W16:-9.10115 (0.00),W20:-10.63367 (0.00),W24:-11.42424 (0.00),W32:-11.64601 (0.00),W28:-11.99155 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('a', 24), (',', 24), ('s', 19), ('to', 16), ('with', 15), ('be', 14), ('don', 13), ('he', 12), ('it', 12), ('illy', 11)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:47:18 | 240 | LR0.0003 | logitMin:-18.4680 | logitMax:15.4083 | scheduledSampling:0.0000 | lossTUTOR:13.6101 | windowWeightsW2:2.31776 (0.58),W4:1.96929 (0.41),W8:-1.93564 (0.01),W12:-6.60231 (0.00),W16:-9.10109 (0.00),W20:-10.63362 (0.00),W24:-11.42416 (0.00),W32:-11.64593 (0.00),W28:-11.99147 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('a', 24), (',', 24), ('s', 19), ('of', 17), ('to', 16), ('with', 15), ('feeling', 15), ('be', 14), ('don', 13), ('he', 12)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:48:43 | 260 | LR0.0003 | logitMin:-29.4084 | logitMax:15.9138 | scheduledSampling:0.0000 | lossTUTOR:3.9750 | windowWeightsW2:2.31774 (0.58),W4:1.96927 (0.41),W8:-1.93563 (0.01),W12:-6.60227 (0.00),W16:-9.10103 (0.00),W20:-10.63356 (0.00),W24:-11.42409 (0.00),W32:-11.64585 (0.00),W28:-11.99140 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('a', 24), (',', 24), ('s', 19), ('up', 18), ('of', 18), ('to', 17), ('with', 15), ('feeling', 15), ('be', 14), ('don', 13)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:50:08 | 280 | LR0.0003 | logitMin:-23.5647 | logitMax:9.2066 | scheduledSampling:0.0000 | lossTUTOR:8.9024 | windowWeightsW2:2.31773 (0.58),W4:1.96926 (0.41),W8:-1.93561 (0.01),W12:-6.60224 (0.00),W16:-9.10097 (0.00),W20:-10.63350 (0.00),W24:-11.42401 (0.00),W32:-11.64578 (0.00),W28:-11.99132 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('a', 24), (',', 24), ('s', 19), ('up', 18), ('of', 18), ('to', 17), ('this', 15), ('with', 15), ('feeling', 15), ('be', 14)] |  | blend:0.589  W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 20
2025-04-14 23:51:34 | 300 | LR0.0003 | logitMin:-34.6753 | logitMax:20.4163 | scheduledSampling:0.0000 | lossTUTOR:17.4349 | windowWeightsW2:2.31772 (0.58),W4:1.96925 (0.41),W8:-1.93560 (0.01),W12:-6.60220 (0.00),W16:-9.10092 (0.00),W20:-10.63345 (0.00),W24:-11.42393 (0.00),W32:-11.64570 (0.00),W28:-11.99124 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('a', 35), (',', 24), ('s', 19), ('of', 19), ('up', 18), ('to', 17), ('this', 15), ('with', 15), ('feeling', 15), ('be', 14)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:52:58 | 320 | LR0.0003 | logitMin:-25.6830 | logitMax:27.5321 | scheduledSampling:0.0000 | lossTUTOR:15.0240 | windowWeightsW2:2.31770 (0.58),W4:1.96924 (0.41),W8:-1.93559 (0.01),W12:-6.60216 (0.00),W16:-9.10086 (0.00),W20:-10.63339 (0.00),W24:-11.42386 (0.00),W32:-11.64563 (0.00),W28:-11.99117 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('a', 35), (',', 24), ('ment', 23), ('of', 20), ('s', 19), ('up', 18), ('to', 17), ('this', 15), ('with', 15), ('feeling', 15)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:54:23 | 340 | LR0.0003 | logitMin:-22.4026 | logitMax:8.4888 | scheduledSampling:0.0000 | lossTUTOR:11.2826 | windowWeightsW2:2.31769 (0.58),W4:1.96923 (0.41),W8:-1.93558 (0.01),W12:-6.60212 (0.00),W16:-9.10080 (0.00),W20:-10.63333 (0.00),W24:-11.42378 (0.00),W32:-11.64555 (0.00),W28:-11.99109 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('a', 35), ('of', 30), (',', 24), ('ment', 24), ('ad', 19), ('s', 19), ('up', 18), ('to', 17), ('this', 15), ('l', 15)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:55:49 | 360 | LR0.0003 | logitMin:-23.1552 | logitMax:18.7011 | scheduledSampling:0.0000 | lossTUTOR:16.7513 | windowWeightsW2:2.31767 (0.58),W4:1.96921 (0.41),W8:-1.93557 (0.01),W12:-6.60208 (0.00),W16:-9.10075 (0.00),W20:-10.63327 (0.00),W24:-11.42371 (0.00),W32:-11.64547 (0.00),W28:-11.99102 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('a', 35), ('to', 32), ('of', 30), (',', 24), ('ment', 24), ('ad', 19), ('s', 19), ('up', 18), ('this', 17), ('l', 15)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:57:20 | 380 | LR0.0003 | logitMin:-20.6205 | logitMax:12.7404 | scheduledSampling:0.0000 | lossTUTOR:7.5916 | windowWeightsW2:2.31766 (0.58),W4:1.96920 (0.41),W8:-1.93555 (0.01),W12:-6.60205 (0.00),W16:-9.10069 (0.00),W20:-10.63322 (0.00),W24:-11.42363 (0.00),W32:-11.64540 (0.00),W28:-11.99094 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('a', 35), ('to', 32), ('of', 31), ('ment', 25), (',', 24), ('ad', 19), ('it', 19), ('s', 19), ('up', 18), ('this', 17)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-14 23:58:50 | 400 | LR0.0003 | logitMin:-24.6678 | logitMax:24.8619 | scheduledSampling:0.0000 | lossTUTOR:12.7234 | windowWeightsW2:2.31764 (0.58),W4:1.96919 (0.41),W8:-1.93554 (0.01),W12:-6.60201 (0.00),W16:-9.10063 (0.00),W20:-10.63316 (0.00),W24:-11.42355 (0.00),W32:-11.64532 (0.00),W28:-11.99086 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('a', 35), ('to', 32), ('of', 31), ('this', 30), ('ment', 25), (',', 24), ('ad', 19), ('it', 19), ('s', 19), ('up', 18)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:00:11 | 420 | LR0.0003 | logitMin:-20.2587 | logitMax:21.6193 | scheduledSampling:0.0000 | lossTUTOR:10.6917 | windowWeightsW2:2.31763 (0.58),W4:1.96918 (0.41),W8:-1.93553 (0.01),W12:-6.60197 (0.00),W16:-9.10057 (0.00),W20:-10.63310 (0.00),W24:-11.42348 (0.00),W32:-11.64524 (0.00),W28:-11.99079 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('a', 35), ('to', 32), ('of', 31), ('this', 30), ('ment', 25), (',', 24), ('by', 21), ('ad', 19), ('it', 19), ('s', 19)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:01:34 | 440 | LR0.0003 | logitMin:-23.5670 | logitMax:17.2687 | scheduledSampling:0.0000 | lossTUTOR:13.9091 | windowWeightsW2:2.31762 (0.58),W4:1.96917 (0.41),W8:-1.93552 (0.01),W12:-6.60193 (0.00),W16:-9.10052 (0.00),W20:-10.63305 (0.00),W24:-11.42340 (0.00),W32:-11.64517 (0.00),W28:-11.99071 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('a', 37), ('to', 32), ('of', 31), ('this', 30), ('ment', 27), ('by', 26), (',', 24), ('ad', 19), ('.', 19), ('it', 19)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:02:58 | 460 | LR0.0003 | logitMin:-20.7195 | logitMax:11.1829 | scheduledSampling:0.0000 | lossTUTOR:9.9242 | windowWeightsW2:2.31760 (0.58),W4:1.96915 (0.41),W8:-1.93551 (0.01),W12:-6.60189 (0.00),W16:-9.10046 (0.00),W20:-10.63299 (0.00),W24:-11.42332 (0.00),W32:-11.64509 (0.00),W28:-11.99063 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('a', 55), ('to', 32), ('of', 31), ('this', 30), ('ment', 27), ('by', 26), (',', 24), ('ad', 19), ('.', 19), ('it', 19)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:04:20 | 480 | LR0.0003 | logitMin:-24.3517 | logitMax:12.2207 | scheduledSampling:0.0000 | lossTUTOR:7.8172 | windowWeightsW2:2.31759 (0.58),W4:1.96914 (0.41),W8:-1.93549 (0.01),W12:-6.60186 (0.00),W16:-9.10040 (0.00),W20:-10.63293 (0.00),W24:-11.42325 (0.00),W32:-11.64501 (0.00),W28:-11.99056 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('a', 56), ('to', 32), ('of', 31), ('this', 30), (',', 27), ('ment', 27), ('by', 26), ('.', 20), ('ad', 19), ('it', 19)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20

--- 2025-04-15 00:19:14 --- babyLLM 'right, last time i got to step 1501... want to restart from there?'  - charis: '2000' - babyLLM 'damn that's specific! heading to step 2000... what am i learning today?' - charis: ''
2025-04-15 00:20:32 | 20 | LR0.0003 | logitMin:-23.6001 | logitMax:16.7412 | scheduledSampling:0.0000 | lossTUTOR:9.9930 | windowWeightsW2:2.31756 (0.58),W4:1.96912 (0.41),W8:-1.93547 (0.01),W12:-6.60178 (0.00),W16:-9.10029 (0.00),W20:-10.63282 (0.00),W24:-11.42310 (0.00),W32:-11.64487 (0.00),W28:-11.99041 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 12), ('thinking', 8), ('froggy', 5), ('is', 5), ('you', 2), ('reading', 1), ('stream', 1), ('yeah', 1), ('im', 1), (tensor([[913]], device='mps:0'), 1)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:21:51 | 40 | LR0.0003 | logitMin:-25.9543 | logitMax:18.6387 | scheduledSampling:0.0000 | lossTUTOR:6.7481 | windowWeightsW2:2.31754 (0.58),W4:1.96911 (0.41),W8:-1.93546 (0.01),W12:-6.60174 (0.00),W16:-9.10023 (0.00),W20:-10.63276 (0.00),W24:-11.42302 (0.00),W32:-11.64479 (0.00),W28:-11.99033 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 14), ('thinking', 8), ('dream', 8), ('froggy', 5), ('is', 5), ('you', 4), ('i', 4), ('boof', 3), ('believe', 3), ('do', 3)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:23:11 | 60 | LR0.0003 | logitMin:-34.7454 | logitMax:22.7577 | scheduledSampling:0.0000 | lossTUTOR:11.1580 | windowWeightsW2:2.31753 (0.58),W4:1.96909 (0.41),W8:-1.93545 (0.01),W12:-6.60170 (0.00),W16:-9.10018 (0.00),W20:-10.63270 (0.00),W24:-11.42295 (0.00),W32:-11.64471 (0.00),W28:-11.99026 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 25), ('froggy', 12), ('do', 9), ('thinking', 8), ('dream', 8), ('no', 6), ('is', 5), ('i', 5), ('you', 4), ('boof', 3)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:24:29 | 80 | LR0.0003 | logitMin:-35.6965 | logitMax:14.1927 | scheduledSampling:0.0000 | lossTUTOR:9.8999 | windowWeightsW2:2.31752 (0.58),W4:1.96908 (0.41),W8:-1.93544 (0.01),W12:-6.60167 (0.00),W16:-9.10012 (0.00),W20:-10.63265 (0.00),W24:-11.42287 (0.00),W32:-11.64464 (0.00),W28:-11.99018 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 29), ('froggy', 13), ('do', 12), ('i', 9), ('thinking', 8), ('dream', 8), ('you', 6), ('no', 6), ('is', 5), ('?', 5)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:25:48 | 100 | LR0.0003 | logitMin:-25.9875 | logitMax:26.9981 | scheduledSampling:0.0000 | lossTUTOR:24.9898 | windowWeightsW2:2.31750 (0.58),W4:1.96907 (0.41),W8:-1.93542 (0.01),W12:-6.60163 (0.00),W16:-9.10006 (0.00),W20:-10.63259 (0.00),W24:-11.42279 (0.00),W32:-11.64456 (0.00),W28:-11.99010 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 41), ('froggy', 13), ('kevin', 13), ('do', 12), ('hug', 11), ('i', 9), ('thinking', 8), ('is', 8), ('dream', 8), ('you', 6)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:27:08 | 120 | LR0.0003 | logitMin:-27.3813 | logitMax:23.3877 | scheduledSampling:0.0000 | lossTUTOR:16.5412 | windowWeightsW2:2.31749 (0.58),W4:1.96906 (0.41),W8:-1.93541 (0.01),W12:-6.60159 (0.00),W16:-9.10000 (0.00),W20:-10.63253 (0.00),W24:-11.42272 (0.00),W32:-11.64448 (0.00),W28:-11.99003 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 52), ('is', 23), ('froggy', 19), ('kevin', 14), ('do', 12), ('hug', 11), ('i', 9), ('you', 8), ('thinking', 8), ('dream', 8)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:28:27 | 140 | LR0.0003 | logitMin:-19.4245 | logitMax:14.7095 | scheduledSampling:0.0000 | lossTUTOR:9.4750 | windowWeightsW2:2.31747 (0.58),W4:1.96905 (0.41),W8:-1.93540 (0.01),W12:-6.60155 (0.00),W16:-9.09995 (0.00),W20:-10.63248 (0.00),W24:-11.42264 (0.00),W32:-11.64441 (0.00),W28:-11.98995 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 56), ('is', 25), ('do', 23), ('froggy', 19), ('hug', 16), ('kevin', 14), ('you', 13), ('i', 9), ('thinking', 8), ('dream', 8)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:29:47 | 160 | LR0.0003 | logitMin:-35.5579 | logitMax:19.6861 | scheduledSampling:0.0000 | lossTUTOR:12.1766 | windowWeightsW2:2.31746 (0.58),W4:1.96904 (0.41),W8:-1.93539 (0.01),W12:-6.60151 (0.00),W16:-9.09989 (0.00),W20:-10.63242 (0.00),W24:-11.42257 (0.00),W32:-11.64433 (0.00),W28:-11.98987 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 59), ('do', 27), ('is', 25), ('froggy', 19), ('i', 18), ('hug', 16), ('kevin', 14), ('you', 13), ('thinking', 8), ('dream', 8)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:31:06 | 180 | LR0.0003 | logitMin:-21.4082 | logitMax:17.9765 | scheduledSampling:0.0000 | lossTUTOR:11.7504 | windowWeightsW2:2.31744 (0.58),W4:1.96902 (0.41),W8:-1.93538 (0.01),W12:-6.60148 (0.00),W16:-9.09983 (0.00),W20:-10.63236 (0.00),W24:-11.42249 (0.00),W32:-11.64426 (0.00),W28:-11.98980 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 61), ('do', 28), ('is', 25), ('froggy', 19), ('you', 19), ('i', 18), ('lunch', 17), ('hug', 16), ('kevin', 14), ('?', 10)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:32:26 | 200 | LR0.0003 | logitMin:-17.3768 | logitMax:10.6380 | scheduledSampling:0.0000 | lossTUTOR:11.4627 | windowWeightsW2:2.31743 (0.58),W4:1.96901 (0.41),W8:-1.93536 (0.01),W12:-6.60144 (0.00),W16:-9.09978 (0.00),W20:-10.63230 (0.00),W24:-11.42241 (0.00),W32:-11.64418 (0.00),W28:-11.98972 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 61), ('do', 28), ('is', 25), ('froggy', 19), ('you', 19), ('?', 19), ('i', 18), ('lunch', 17), ('hug', 16), ('kevin', 14)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:33:46 | 220 | LR0.0003 | logitMin:-22.8365 | logitMax:17.6250 | scheduledSampling:0.0000 | lossTUTOR:8.9382 | windowWeightsW2:2.31742 (0.58),W4:1.96900 (0.41),W8:-1.93535 (0.01),W12:-6.60140 (0.00),W16:-9.09972 (0.00),W20:-10.63225 (0.00),W24:-11.42234 (0.00),W32:-11.64410 (0.00),W28:-11.98965 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 67), ('do', 29), ('is', 25), ('?', 22), ('froggy', 19), ('you', 19), ('i', 18), ('lunch', 17), ('hug', 16), ('kevin', 14)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:35:08 | 240 | LR0.0003 | logitMin:-25.2425 | logitMax:12.5495 | scheduledSampling:0.0000 | lossTUTOR:12.9353 | windowWeightsW2:2.31740 (0.58),W4:1.96899 (0.41),W8:-1.93534 (0.01),W12:-6.60136 (0.00),W16:-9.09966 (0.00),W20:-10.63219 (0.00),W24:-11.42226 (0.00),W32:-11.64403 (0.00),W28:-11.98957 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 67), ('do', 30), ('is', 25), ('you', 24), ('?', 22), ('froggy', 19), ('i', 18), ('lunch', 17), ('hug', 16), ('ing', 16)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:36:29 | 260 | LR0.0003 | logitMin:-23.5148 | logitMax:20.6735 | scheduledSampling:0.0000 | lossTUTOR:20.5159 | windowWeightsW2:2.31739 (0.58),W4:1.96898 (0.41),W8:-1.93533 (0.01),W12:-6.60132 (0.00),W16:-9.09960 (0.00),W20:-10.63213 (0.00),W24:-11.42218 (0.00),W32:-11.64395 (0.00),W28:-11.98949 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 67), ('do', 30), ('is', 25), ('you', 24), ('does', 23), ('?', 22), ('froggy', 19), ('i', 18), ('to', 17), ('lunch', 17)] |  | blend:0.589  W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 20
2025-04-15 00:37:50 | 280 | LR0.0003 | logitMin:-20.0461 | logitMax:12.1451 | scheduledSampling:0.0000 | lossTUTOR:6.5444 | windowWeightsW2:2.31737 (0.58),W4:1.96896 (0.41),W8:-1.93532 (0.01),W12:-6.60128 (0.00),W16:-9.09955 (0.00),W20:-10.63208 (0.00),W24:-11.42211 (0.00),W32:-11.64387 (0.00),W28:-11.98942 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 68), ('do', 30), ('does', 29), ('?', 27), ('is', 25), ('you', 24), ('froggy', 19), ('i', 18), ('to', 17), ('lunch', 17)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:39:10 | 300 | LR0.0003 | logitMin:-14.3884 | logitMax:8.3196 | scheduledSampling:0.0000 | lossTUTOR:8.7190 | windowWeightsW2:2.31736 (0.58),W4:1.96895 (0.41),W8:-1.93530 (0.01),W12:-6.60125 (0.00),W16:-9.09949 (0.00),W20:-10.63202 (0.00),W24:-11.42203 (0.00),W32:-11.64380 (0.00),W28:-11.98934 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 68), ('do', 31), ('does', 29), ('i', 28), ('?', 28), ('is', 25), ('you', 24), ('to', 21), ('froggy', 19), ('lunch', 17)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:40:30 | 320 | LR0.0003 | logitMin:-25.1158 | logitMax:16.9481 | scheduledSampling:0.0000 | lossTUTOR:21.2616 | windowWeightsW2:2.31734 (0.58),W4:1.96894 (0.41),W8:-1.93529 (0.01),W12:-6.60121 (0.00),W16:-9.09943 (0.00),W20:-10.63196 (0.00),W24:-11.42196 (0.00),W32:-11.64372 (0.00),W28:-11.98926 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W4:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 68), ('i', 32), ('do', 31), ('does', 29), ('?', 28), ('is', 26), ('you', 24), ('to', 21), ('froggy', 19), ('it', 18)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:41:49 | 340 | LR0.0003 | logitMin:-20.8880 | logitMax:24.3364 | scheduledSampling:0.0000 | lossTUTOR:12.0355 | windowWeightsW2:2.31733 (0.58),W4:1.96897 (0.41),W8:-1.93528 (0.01),W12:-6.60117 (0.00),W16:-9.09937 (0.00),W20:-10.63190 (0.00),W24:-11.42188 (0.00),W32:-11.64365 (0.00),W28:-11.98919 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W32:0.11112 (0.00),W4:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 70), ('i', 40), ('do', 31), ('?', 29), ('does', 29), ('you', 27), ('is', 26), ('to', 21), ('it', 20), ('froggy', 19)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:43:08 | 360 | LR0.0003 | logitMin:-21.8443 | logitMax:13.1783 | scheduledSampling:0.0000 | lossTUTOR:7.8106 | windowWeightsW2:2.31732 (0.58),W4:1.96912 (0.41),W8:-1.93527 (0.01),W12:-6.60113 (0.00),W16:-9.09932 (0.00),W20:-10.63185 (0.00),W24:-11.42180 (0.00),W32:-11.64357 (0.00),W28:-11.98911 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 71), ('i', 40), ('do', 31), ('?', 30), ('does', 29), ('you', 27), ('is', 26), ('to', 22), ('it', 20), ('froggy', 19)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:44:27 | 380 | LR0.0003 | logitMin:-29.9952 | logitMax:16.6959 | scheduledSampling:0.0000 | lossTUTOR:11.7055 | windowWeightsW2:2.31730 (0.58),W4:1.96912 (0.41),W8:-1.93526 (0.01),W12:-6.60109 (0.00),W16:-9.09926 (0.00),W20:-10.63179 (0.00),W24:-11.42173 (0.00),W32:-11.64349 (0.00),W28:-11.98904 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 71), ('i', 40), ('?', 31), ('do', 31), ('is', 29), ('does', 29), ('you', 27), ('to', 22), ('it', 20), ('froggy', 19)] |  | blend:0.589  W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 20
2025-04-15 00:45:46 | 400 | LR0.0003 | logitMin:-17.4379 | logitMax:22.9540 | scheduledSampling:0.0000 | lossTUTOR:22.0812 | windowWeightsW2:2.31729 (0.58),W4:1.96911 (0.41),W8:-1.93524 (0.01),W12:-6.60106 (0.00),W16:-9.09920 (0.00),W20:-10.63173 (0.00),W24:-11.42165 (0.00),W32:-11.64342 (0.00),W28:-11.98896 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 71), ('i', 40), ('?', 31), ('do', 31), ('is', 29), ('does', 29), ('you', 27), ('to', 22), ('it', 20), ('froggy', 19)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:47:06 | 420 | LR0.0003 | logitMin:-20.5348 | logitMax:19.1946 | scheduledSampling:0.0000 | lossTUTOR:14.1101 | windowWeightsW2:2.31727 (0.58),W4:1.96910 (0.41),W8:-1.93523 (0.01),W12:-6.60102 (0.00),W16:-9.09915 (0.00),W20:-10.63167 (0.00),W24:-11.42157 (0.00),W32:-11.64334 (0.00),W28:-11.98888 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 71), ('?', 49), ('i', 40), ('do', 31), ('is', 29), ('does', 29), ('what', 28), ('you', 27), ('to', 22), ('it', 20)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:48:25 | 440 | LR0.0003 | logitMin:-24.7217 | logitMax:11.3843 | scheduledSampling:0.0000 | lossTUTOR:10.4321 | windowWeightsW2:2.31726 (0.58),W4:1.96909 (0.41),W8:-1.93522 (0.01),W12:-6.60098 (0.00),W16:-9.09909 (0.00),W20:-10.63162 (0.00),W24:-11.42150 (0.00),W32:-11.64326 (0.00),W28:-11.98881 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 71), ('?', 49), ('i', 40), ('is', 35), ('do', 31), ('does', 29), ('what', 28), ('you', 27), ('to', 22), ('me', 20)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:49:44 | 460 | LR0.0003 | logitMin:-29.7244 | logitMax:12.5142 | scheduledSampling:0.0000 | lossTUTOR:12.2110 | windowWeightsW2:2.31724 (0.58),W4:1.96908 (0.41),W8:-1.93521 (0.01),W12:-6.60094 (0.00),W16:-9.09903 (0.00),W20:-10.63156 (0.00),W24:-11.42142 (0.00),W32:-11.64319 (0.00),W28:-11.98873 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 71), ('?', 49), ('i', 40), ('is', 38), ('do', 31), ('does', 29), ('what', 28), ('you', 27), ('to', 22), ('me', 20)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:51:04 | 480 | LR0.0003 | logitMin:-22.9211 | logitMax:11.5915 | scheduledSampling:0.0000 | lossTUTOR:7.6156 | windowWeightsW2:2.31723 (0.58),W4:1.96907 (0.41),W8:-1.93520 (0.01),W12:-6.60090 (0.00),W16:-9.09897 (0.00),W20:-10.63150 (0.00),W24:-11.42134 (0.00),W32:-11.64311 (0.00),W28:-11.98865 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 71), ('?', 53), ('i', 40), ('is', 39), ('do', 31), ('does', 29), ('what', 28), ('you', 27), ('froggy', 25), ('to', 22)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:52:29 | 500 | LR0.0003 | logitMin:-44.2113 | logitMax:18.6914 | scheduledSampling:0.0000 | lossTUTOR:13.7902 | windowWeightsW2:2.31722 (0.58),W4:1.96905 (0.41),W8:-1.93519 (0.01),W12:-6.60087 (0.00),W16:-9.09892 (0.00),W20:-10.63145 (0.00),W24:-11.42127 (0.00),W32:-11.64303 (0.00),W28:-11.98858 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 86), ('?', 53), ('i', 46), ('is', 40), ('do', 31), ('does', 29), ('you', 28), ('what', 28), ('froggy', 25), ('to', 22)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:53:49 | 520 | LR0.0003 | logitMin:-25.4257 | logitMax:19.3270 | scheduledSampling:0.0000 | lossTUTOR:13.2463 | windowWeightsW2:2.31720 (0.58),W4:1.96904 (0.41),W8:-1.93517 (0.01),W12:-6.60083 (0.00),W16:-9.09886 (0.00),W20:-10.63139 (0.00),W24:-11.42119 (0.00),W32:-11.64296 (0.00),W28:-11.98850 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 86), ('?', 53), ('i', 47), ('is', 42), ('froggy', 36), ('do', 31), ('does', 29), ('you', 28), ('what', 28), ('to', 22)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:55:10 | 540 | LR0.0003 | logitMin:-37.0228 | logitMax:17.7521 | scheduledSampling:0.0000 | lossTUTOR:20.1412 | windowWeightsW2:2.31719 (0.58),W4:1.96903 (0.41),W8:-1.93516 (0.01),W12:-6.60079 (0.00),W16:-9.09880 (0.00),W20:-10.63133 (0.00),W24:-11.42112 (0.00),W32:-11.64288 (0.00),W28:-11.98843 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 89), ('?', 53), ('i', 51), ('is', 42), ('froggy', 37), ('do', 31), ('does', 29), ('you', 28), ('what', 28), ('to', 22)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:56:31 | 560 | LR0.0003 | logitMin:-25.9001 | logitMax:18.0530 | scheduledSampling:0.0000 | lossTUTOR:17.2150 | windowWeightsW2:2.31717 (0.58),W4:1.96902 (0.41),W8:-1.93515 (0.01),W12:-6.60075 (0.00),W16:-9.09875 (0.00),W20:-10.63127 (0.00),W24:-11.42104 (0.00),W32:-11.64281 (0.00),W28:-11.98835 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 89), ('?', 53), ('i', 51), ('is', 43), ('froggy', 37), ('do', 31), ('does', 29), ('you', 28), ('what', 28), ('to', 22)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:57:50 | 580 | LR0.0003 | logitMin:-23.8709 | logitMax:13.6008 | scheduledSampling:0.0000 | lossTUTOR:10.5241 | windowWeightsW2:2.31716 (0.58),W4:1.96901 (0.41),W8:-1.93514 (0.01),W12:-6.60071 (0.00),W16:-9.09869 (0.00),W20:-10.63122 (0.00),W24:-11.42096 (0.00),W32:-11.64273 (0.00),W28:-11.98827 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 89), ('?', 53), ('is', 52), ('i', 51), ('froggy', 37), ('do', 32), ('does', 29), ('you', 28), ('what', 28), ('to', 25)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 00:59:09 | 600 | LR0.0003 | logitMin:-29.2005 | logitMax:14.5435 | scheduledSampling:0.0000 | lossTUTOR:14.5577 | windowWeightsW2:2.31714 (0.58),W4:1.96899 (0.41),W8:-1.93513 (0.01),W12:-6.60067 (0.00),W16:-9.09863 (0.00),W20:-10.63116 (0.00),W24:-11.42089 (0.00),W32:-11.64265 (0.00),W28:-11.98820 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 90), ('?', 53), ('is', 52), ('i', 51), ('you', 45), ('froggy', 37), ('do', 32), ('does', 29), ('what', 28), ('to', 25)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 01:00:29 | 620 | LR0.0003 | logitMin:-27.4976 | logitMax:10.9303 | scheduledSampling:0.0000 | lossTUTOR:8.3381 | windowWeightsW2:2.31713 (0.58),W4:1.96898 (0.41),W8:-1.93511 (0.01),W12:-6.60064 (0.00),W16:-9.09857 (0.00),W20:-10.63110 (0.00),W24:-11.42081 (0.00),W32:-11.64258 (0.00),W28:-11.98812 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 92), ('?', 53), ('is', 52), ('i', 51), ('you', 45), ('froggy', 37), ('do', 32), ('does', 29), ('what', 28), ('to', 25)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 01:01:47 | 640 | LR0.0003 | logitMin:-24.0556 | logitMax:14.7754 | scheduledSampling:0.0000 | lossTUTOR:10.2989 | windowWeightsW2:2.31712 (0.58),W4:1.96897 (0.41),W8:-1.93510 (0.01),W12:-6.60060 (0.00),W16:-9.09852 (0.00),W20:-10.63105 (0.00),W24:-11.42073 (0.00),W32:-11.64250 (0.00),W28:-11.98804 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 92), ('?', 53), ('is', 52), ('i', 51), ('you', 45), ('froggy', 37), ('do', 32), ('does', 29), ('what', 28), ('to', 25)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 01:03:07 | 660 | LR0.0003 | logitMin:-18.5881 | logitMax:16.2939 | scheduledSampling:0.0000 | lossTUTOR:10.4505 | windowWeightsW2:2.31710 (0.58),W4:1.96896 (0.41),W8:-1.93509 (0.01),W12:-6.60056 (0.00),W16:-9.09846 (0.00),W20:-10.63099 (0.00),W24:-11.42066 (0.00),W32:-11.64242 (0.00),W28:-11.98797 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 93), ('i', 56), ('is', 53), ('?', 53), ('you', 52), ('froggy', 37), ('do', 33), ('does', 29), ('what', 28), ('to', 25)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 01:04:27 | 680 | LR0.0003 | logitMin:-46.9405 | logitMax:21.8376 | scheduledSampling:0.0000 | lossTUTOR:21.0856 | windowWeightsW2:2.31709 (0.58),W4:1.96895 (0.41),W8:-1.93508 (0.01),W12:-6.60052 (0.00),W16:-9.09840 (0.00),W20:-10.63093 (0.00),W24:-11.42058 (0.00),W32:-11.64235 (0.00),W28:-11.98789 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 95), ('is', 68), ('i', 56), ('?', 54), ('you', 53), ('froggy', 37), ('do', 33), ('does', 29), ('what', 28), ('to', 25)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 01:05:47 | 700 | LR0.0003 | logitMin:-24.4957 | logitMax:10.7879 | scheduledSampling:0.0000 | lossTUTOR:10.6707 | windowWeightsW2:2.31707 (0.58),W4:1.96894 (0.41),W8:-1.93507 (0.01),W12:-6.60048 (0.00),W16:-9.09834 (0.00),W20:-10.63087 (0.00),W24:-11.42051 (0.00),W32:-11.64227 (0.00),W28:-11.98781 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 95), ('is', 68), ('?', 61), ('i', 56), ('you', 53), ('froggy', 37), ('do', 33), ('does', 29), ('what', 28), ('why', 28)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 01:07:07 | 720 | LR0.0003 | logitMin:-20.7994 | logitMax:20.9035 | scheduledSampling:0.0000 | lossTUTOR:16.9021 | windowWeightsW2:2.31706 (0.58),W4:1.96892 (0.41),W8:-1.93505 (0.01),W12:-6.60045 (0.00),W16:-9.09829 (0.00),W20:-10.63082 (0.00),W24:-11.42043 (0.00),W32:-11.64220 (0.00),W28:-11.98774 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 95), ('?', 80), ('is', 71), ('i', 57), ('you', 53), ('froggy', 37), ('do', 33), ('does', 29), ('what', 28), ('why', 28)] |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 01:08:28 | 740 | LR0.0003 | logitMin:-33.8835 | logitMax:28.0269 | scheduledSampling:0.0000 | lossTUTOR:19.7351 | windowWeightsW2:2.31704 (0.58),W4:1.96891 (0.41),W8:-1.93504 (0.01),W12:-6.60041 (0.00),W16:-9.09823 (0.00),W20:-10.63076 (0.00),W24:-11.42035 (0.00),W32:-11.64212 (0.00),W28:-11.98766 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 97), ('?', 80), ('is', 71), ('i', 57), ('you', 53), ('do', 45), ('froggy', 37), ('to', 29), ('does', 29), ('what', 28)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20
2025-04-15 01:09:47 | 760 | LR0.0003 | logitMin:-52.4929 | logitMax:17.5576 | scheduledSampling:0.0000 | lossTUTOR:20.0040 | windowWeightsW2:2.31703 (0.58),W4:1.96890 (0.41),W8:-1.93503 (0.01),W12:-6.60037 (0.00),W16:-9.09817 (0.00),W20:-10.63070 (0.00),W24:-11.42028 (0.00),W32:-11.64204 (0.00),W28:-11.98759 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('.', 99), ('?', 80), ('is', 71), ('you', 57), ('i', 57), ('do', 45), ('froggy', 37), ('why', 31), ('to', 29), ('does', 29)] |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 20

--- 2025-04-15 01:11:35 --- babyLLM 'right, last time i got to step 2001... want to restart from there?'  - charis: '2700' - babyLLM 'damn that's specific! heading to step 2700... what am i learning today?' - charis: ''

--- 2025-04-15 01:14:02 --- babyLLM 'right, last time i got to step 2001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 2001! what am i learning today?' - charis: ''

--- 2025-04-15 01:23:48 --- babyLLM 'right, last time i got to step 2001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 2001! what am i learning today?' - charis: ''

--- 2025-04-15 01:26:45 --- babyLLM 'right, last time i got to step 2001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 2001! what am i learning today?' - charis: ''

--- 2025-04-15 01:38:42 --- babyLLM 'right, last time i got to step 2001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 2001! what am i learning today?' - charis: ''

--- 2025-04-15 01:39:44 --- babyLLM 'right, last time i got to step 2002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 2002! what am i learning today?' - charis: ''
2025-04-15 01:46:13 | 100 | LR0.0003 | logitMin:-8.8341 | logitMax:3.2001 | scheduledSampling:0.0000 | lossTUTOR:2.0550 | windowWeightsW2:2.31694 (0.58),W4:1.96883 (0.41),W8:-1.93496 (0.01),W12:-6.60013 (0.00),W16:-9.09782 (0.00),W20:-10.63035 (0.00),W24:-11.41980 (0.00),W32:-11.64157 (0.00),W28:-11.98711 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('you', 30), ('.', 26), ('?', 24), ('do', 12), ('no', 8), ('is', 7), ('not', 6), ('dream', 6), ('thinking', 5), ('what', 5)] | avgLoss/100: 3226.140625 |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-15 01:52:51 | 200 | LR0.0003 | logitMin:-6.9351 | logitMax:4.2982 | scheduledSampling:0.0000 | lossTUTOR:1.2205 | windowWeightsW2:2.31687 (0.58),W4:1.96877 (0.41),W8:-1.93490 (0.01),W12:-6.59994 (0.00),W16:-9.09753 (0.00),W20:-10.63006 (0.00),W24:-11.41942 (0.00),W32:-11.64119 (0.00),W28:-11.98673 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('?', 43), ('you', 43), ('.', 34), ('do', 21), ('is', 16), ('gging', 16), ('no', 8), ('what', 8), ('not', 7), ('!', 7)] | avgLoss/100: 2022.3846435546875 |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-15 01:59:21 | 300 | LR0.0003 | logitMin:-17.4813 | logitMax:5.3623 | scheduledSampling:0.0000 | lossTUTOR:1.5821 | windowWeightsW2:2.31680 (0.58),W4:1.96871 (0.41),W8:-1.93484 (0.01),W12:-6.59975 (0.00),W16:-9.09725 (0.00),W20:-10.62978 (0.00),W24:-11.41904 (0.00),W32:-11.64081 (0.00),W28:-11.98635 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('?', 68), ('.', 59), ('you', 55), ('do', 25), ('i', 16), ('is', 16), ('gging', 16), ('no', 9), ('kiss', 9), ('!', 8)] | avgLoss/100: 2931.508056640625 |  | blend:0.589  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100

--- 2025-04-15 02:03:48 --- babyLLM 'right, last time i got to step 2003... want to restart from there?'  - charis: '2300' - babyLLM 'damn that's specific! heading to step 2300... what am i learning today?' - charis: ''
2025-04-15 02:10:20 | 100 | LR0.0003 | logitMin:-4.9454 | logitMax:2.7426 | scheduledSampling:0.0000 | lossTUTOR:2.4025 | windowWeightsW2:2.31668 (0.58),W4:1.96861 (0.41),W8:-1.93474 (0.01),W12:-6.59945 (0.00),W16:-9.09679 (0.00),W20:-10.62932 (0.00),W24:-11.41844 (0.00),W32:-11.64020 (0.00),W28:-11.98575 (0.00) | judgeBiasW32:0.00039 (0.11),W2:0.00039 (0.11),W4:0.00039 (0.11),W8:0.00039 (0.11),W12:0.00039 (0.11),W16:0.00039 (0.11),W20:0.00039 (0.11),W24:0.00039 (0.11),W28:0.00039 (0.11) | credibilityBiasW28:0.11140 (0.00),W4:0.11113 (0.00),W32:0.11112 (0.00),W2:0.11111 (0.00),W8:0.11111 (0.00),W12:0.11111 (0.00),W16:0.11111 (0.00),W24:0.11111 (0.00),W20:0.11081 (-0.00) | topTokens[('is', 158), ('.', 150), ('?', 133), ('kevin', 86), ('at', 69), ('what', 68), ('up', 51), ('wants', 42), ('name', 39), ('ace', 39)] | avgLoss/100: 1887.0955810546875 |  | blend:0.589  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-15 22:07:50 | 200 | LR0.0003 | logitMin:-7.5622 | logitMax:4.6808 | scheduledSampling:0.0000 | lossTUTOR:4.1727 | windowWeightsW2:2.24464 (0.57),W4:1.93768 (0.42),W8:-1.91849 (0.01),W12:-6.54132 (0.00),W16:-9.01866 (0.00),W20:-10.54436 (0.00),W24:-11.33773 (0.00),W32:-11.52892 (0.00),W28:-11.89393 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[('.', 192), ('a', 177), ('it', 115), ('the', 107), (',', 97), ("'s", 97), ('their', 93), ('had', 92), ('-', 91), ('ried', 87)] | avgLoss/100: 228.98018981933595 |  | entropyBonus: 0.7272317409515381 blend: 0.286 top windows: W2:0.57,W4:0.42,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-15 22:14:30 | 300 | LR0.0003 | logitMin:-2.3139 | logitMax:1.2036 | scheduledSampling:0.0000 | lossTUTOR:1.3655 | windowWeightsW2:2.23493 (0.57),W4:1.94710 (0.42),W8:-1.90426 (0.01),W12:-6.52982 (0.00),W16:-9.00569 (0.00),W20:-10.53542 (0.00),W24:-11.32997 (0.00),W32:-11.51798 (0.00),W28:-11.88789 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[('the', 274), ('.', 264), (',', 230), ('ed', 209), ('a', 188), ("'s", 137), ('it', 128), ('their', 115), ('-', 105), ('had', 92)] | avgLoss/100: 159.62086853027344 |  | entropyBonus: 0.7291790246963501 blend: 0.286 top windows: W2:0.57,W4:0.42,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-15 22:21:11 | 400 | LR0.0003 | logitMin:-2.6621 | logitMax:1.2485 | scheduledSampling:0.0000 | lossTUTOR:2.0812 | windowWeightsW2:2.23133 (0.56),W4:1.95019 (0.43),W8:-1.88760 (0.01),W12:-6.51690 (0.00),W16:-8.99105 (0.00),W20:-10.52489 (0.00),W24:-11.32264 (0.00),W32:-11.50595 (0.00),W28:-11.88088 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 480), ('the', 291), ('.', 274), ('ed', 232), ('a', 216), ('-', 209), ('their', 148), ("'s", 139), ('it', 135), ('y', 124)] | avgLoss/100: 87.14156544685363 |  | entropyBonus: 0.7302869558334351 blend: 0.286 top windows: W2:0.56,W4:0.43,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-15 22:27:58 | 500 | LR0.0003 | logitMin:-2.4014 | logitMax:1.6523 | scheduledSampling:0.0000 | lossTUTOR:1.0385 | windowWeightsW2:2.22436 (0.56),W4:1.95686 (0.43),W8:-1.87801 (0.01),W12:-6.50885 (0.00),W16:-8.98288 (0.00),W20:-10.51793 (0.00),W24:-11.31682 (0.00),W32:-11.49932 (0.00),W28:-11.87623 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 746), ('the', 320), ('a', 312), ('ed', 292), ('.', 281), ('-', 214), ('and', 160), ('it', 153), ('their', 150), ('y', 141)] | avgLoss/100: 160.93175720214845 |  | entropyBonus: 0.7315890789031982 blend: 0.286 top windows: W2:0.56,W4:0.43,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-15 22:34:58 | 600 | LR0.0003 | logitMin:-3.1679 | logitMax:2.1561 | scheduledSampling:0.0000 | lossTUTOR:1.4065 | windowWeightsW2:2.20723 (0.55),W4:1.97348 (0.44),W8:-1.85523 (0.01),W12:-6.49114 (0.00),W16:-8.95984 (0.00),W20:-10.50116 (0.00),W24:-11.30498 (0.00),W32:-11.48239 (0.00),W28:-11.86685 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1011), ('a', 357), ('the', 345), ('.', 307), ('ed', 294), ('-', 220), ('and', 214), ('they', 201), ('their', 200), ('it', 168)] | avgLoss/100: 114.03127124786377 |  | entropyBonus: 0.7345724105834961 blend: 0.286 top windows: W2:0.55,W4:0.44,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-15 22:41:22 | 700 | LR0.0003 | logitMin:-2.4288 | logitMax:1.8368 | scheduledSampling:0.0000 | lossTUTOR:0.6021 | windowWeightsW2:2.19379 (0.55),W4:1.98627 (0.44),W8:-1.83111 (0.01),W12:-6.47102 (0.00),W16:-8.93968 (0.00),W20:-10.48525 (0.00),W24:-11.29355 (0.00),W32:-11.47041 (0.00),W28:-11.85627 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1157), ('a', 416), ('the', 376), ('.', 343), ('ed', 301), ('their', 283), ('-', 227), ('and', 220), ('they', 204), ('it', 197)] | avgLoss/100: 65.11106727600098 |  | entropyBonus: 0.736994743347168 blend: 0.286 top windows: W2:0.55,W4:0.44,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-15 22:47:37 | 800 | LR0.0003 | logitMin:-2.0331 | logitMax:2.4652 | scheduledSampling:0.0000 | lossTUTOR:1.0323 | windowWeightsW2:2.17977 (0.54),W4:1.99975 (0.45),W8:-1.81078 (0.01),W12:-6.45182 (0.00),W16:-8.92191 (0.00),W20:-10.47182 (0.00),W24:-11.28302 (0.00),W32:-11.45841 (0.00),W28:-11.84786 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1268), ('a', 453), ('the', 442), ('.', 373), ('their', 324), ('ed', 322), ('and', 230), ('-', 228), ('it', 223), ('they', 204)] | avgLoss/100: 79.20602794647216 |  | entropyBonus: 0.7391693592071533 blend: 0.286 top windows: W2:0.54,W4:0.45,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-15 22:53:53 | 900 | LR0.0003 | logitMin:-2.8821 | logitMax:1.8375 | scheduledSampling:0.0000 | lossTUTOR:0.3880 | windowWeightsW2:2.16435 (0.53),W4:2.01479 (0.46),W8:-1.79441 (0.01),W12:-6.43603 (0.00),W16:-8.90687 (0.00),W20:-10.46035 (0.00),W24:-11.27365 (0.00),W32:-11.44958 (0.00),W28:-11.84049 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1379), ('the', 526), ('a', 453), ('.', 392), ('ed', 349), ('their', 328), ('and', 291), ('to', 253), ('it', 244), ('-', 233)] | avgLoss/100: 103.04605562210082 |  | entropyBonus: 0.741081714630127 blend: 0.286 top windows: W2:0.53,W4:0.46,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-15 23:00:27 | 1000 | LR0.0003 | logitMin:-2.1335 | logitMax:2.0209 | scheduledSampling:0.0000 | lossTUTOR:0.5708 | windowWeightsW2:2.14236 (0.52),W4:2.03658 (0.47),W8:-1.77767 (0.01),W12:-6.42296 (0.00),W16:-8.89055 (0.00),W20:-10.44765 (0.00),W24:-11.26371 (0.00),W32:-11.43785 (0.00),W28:-11.83240 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1629), ('the', 580), ('a', 453), ('.', 409), ('ed', 401), ('their', 348), ('and', 306), ('to', 290), ('they', 264), ('it', 263)] | avgLoss/100: 98.57969738006592 |  | entropyBonus: 0.743220329284668 blend: 0.286 top windows: W2:0.52,W4:0.47,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-15 23:06:49 | 1100 | LR0.0003 | logitMin:-3.1493 | logitMax:1.7882 | scheduledSampling:0.0000 | lossTUTOR:1.6865 | windowWeightsW2:2.14017 (0.52),W4:2.03794 (0.47),W8:-1.75803 (0.01),W12:-6.40267 (0.00),W16:-8.87035 (0.00),W20:-10.43062 (0.00),W24:-11.24857 (0.00),W32:-11.42276 (0.00),W28:-11.82082 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1788), ('the', 612), ('a', 574), ('ed', 435), ('.', 413), ('their', 397), ('and', 338), ('to', 295), ('it', 284), ('they', 279)] | avgLoss/100: 128.2489058303833 |  | entropyBonus: 0.7441374659538269 blend: 0.286 top windows: W2:0.52,W4:0.47,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-15 23:13:40 | 1200 | LR0.0003 | logitMin:-4.2269 | logitMax:2.2311 | scheduledSampling:0.0000 | lossTUTOR:0.8238 | windowWeightsW2:2.12798 (0.51),W4:2.04931 (0.47),W8:-1.73488 (0.01),W12:-6.38269 (0.00),W16:-8.85173 (0.00),W20:-10.41319 (0.00),W24:-11.23604 (0.00),W32:-11.40927 (0.00),W28:-11.81056 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1941), ('a', 658), ('the', 631), ('ed', 502), ('.', 413), ('their', 401), ('and', 371), ('it', 348), ('to', 315), ('of', 279)] | avgLoss/100: 105.20035169601441 |  | entropyBonus: 0.7456536889076233 blend: 0.286 top windows: W2:0.51,W4:0.47,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-15 23:21:16 | 1300 | LR0.0003 | logitMin:-2.9784 | logitMax:2.6029 | scheduledSampling:0.0000 | lossTUTOR:0.7812 | windowWeightsW2:2.10905 (0.50),W4:2.06752 (0.48),W8:-1.70969 (0.01),W12:-6.35723 (0.00),W16:-8.82787 (0.00),W20:-10.38979 (0.00),W24:-11.22039 (0.00),W32:-11.39462 (0.00),W28:-11.79708 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 2040), ('a', 729), ('the', 659), ('ed', 570), ('.', 443), ('and', 413), ('their', 403), ('it', 371), ('in', 333), ('to', 319)] | avgLoss/100: 93.43742168426513 |  | entropyBonus: 0.7473067045211792 blend: 0.286 top windows: W2:0.50,W4:0.48,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-15 23:27:33 | 1400 | LR0.0003 | logitMin:-2.2413 | logitMax:2.3967 | scheduledSampling:0.0000 | lossTUTOR:1.3347 | windowWeightsW2:2.10552 (0.50),W4:2.07045 (0.49),W8:-1.69738 (0.01),W12:-6.34509 (0.00),W16:-8.81333 (0.00),W20:-10.37877 (0.00),W24:-11.21145 (0.00),W32:-11.38612 (0.00),W28:-11.78986 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 2042), ('a', 775), ('the', 693), ('ed', 570), ('.', 455), ('it', 430), ('and', 413), ('their', 403), ('in', 342), ('to', 321)] | avgLoss/100: 191.89279891967774 |  | entropyBonus: 0.747926652431488 blend: 0.286 top windows: W2:0.50,W4:0.49,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-15 23:34:10 | 1500 | LR0.0003 | logitMin:-1.8731 | logitMax:2.6012 | scheduledSampling:0.0000 | lossTUTOR:2.6751 | windowWeightsW2:2.09879 (0.50),W4:2.07646 (0.49),W8:-1.68160 (0.01),W12:-6.32514 (0.00),W16:-8.79669 (0.00),W20:-10.36448 (0.00),W24:-11.19889 (0.00),W32:-11.37451 (0.00),W28:-11.78049 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 2118), ('a', 823), ('the', 697), ('it', 582), ('ed', 570), ('.', 511), ('!', 432), ('and', 413), ('their', 403), ('in', 342)] | avgLoss/100: 199.40490629196168 |  | entropyBonus: 0.7487262487411499 blend: 0.286 top windows: W2:0.50,W4:0.49,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-15 23:40:38 | 1600 | LR0.0003 | logitMin:-2.3033 | logitMax:1.7401 | scheduledSampling:0.0000 | lossTUTOR:1.5793 | windowWeightsW2:2.09640 (0.50),W4:2.07857 (0.49),W8:-1.67754 (0.01),W12:-6.32051 (0.00),W16:-8.79098 (0.00),W20:-10.35966 (0.00),W24:-11.19431 (0.00),W32:-11.37045 (0.00),W28:-11.77780 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 2222), ('a', 925), ('the', 701), ('it', 696), ('ed', 570), ('.', 567), ('!', 546), ('and', 413), ('their', 403), ('in', 356)] | avgLoss/100: 228.06248054504394 |  | entropyBonus: 0.7489286065101624 blend: 0.286 top windows: W2:0.50,W4:0.49,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-15 23:47:05 | 1700 | LR0.0003 | logitMin:-3.3095 | logitMax:3.6720 | scheduledSampling:0.0000 | lossTUTOR:1.2383 | windowWeightsW2:2.09174 (0.50),W4:2.08283 (0.49),W8:-1.67000 (0.01),W12:-6.31155 (0.00),W16:-8.77895 (0.00),W20:-10.35234 (0.00),W24:-11.18524 (0.00),W32:-11.36210 (0.00),W28:-11.77242 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 2294), ('a', 929), ('it', 793), ('.', 710), ('the', 701), ('!', 616), ('ed', 571), ('i', 492), ('and', 470), ('their', 403)] | avgLoss/100: 179.9042823410034 |  | entropyBonus: 0.7493035793304443 blend: 0.286 top windows: W2:0.50,W4:0.49,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-15 23:53:29 | 1800 | LR0.0003 | logitMin:-2.3632 | logitMax:1.2789 | scheduledSampling:0.0000 | lossTUTOR:1.5031 | windowWeightsW4:2.09087 (0.50),W2:2.08338 (0.49),W8:-1.66185 (0.01),W12:-6.30091 (0.00),W16:-8.76454 (0.00),W20:-10.34107 (0.00),W24:-11.17543 (0.00),W32:-11.35288 (0.00),W28:-11.76493 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 2376), ('it', 1000), ('a', 956), ('.', 942), ('i', 820), ('the', 705), ('!', 702), ('ed', 571), ('and', 482), ('their', 403)] | avgLoss/100: 203.74726280212403 |  | entropyBonus: 0.7496697902679443 blend: 0.286 top windows: W4:0.50,W2:0.49,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-15 23:59:56 | 1900 | LR0.0003 | logitMin:-2.2569 | logitMax:1.8568 | scheduledSampling:0.0000 | lossTUTOR:1.2597 | windowWeightsW4:2.09370 (0.50),W2:2.08000 (0.49),W8:-1.65194 (0.01),W12:-6.28943 (0.00),W16:-8.74952 (0.00),W20:-10.33006 (0.00),W24:-11.16506 (0.00),W32:-11.34364 (0.00),W28:-11.75765 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 2404), ('.', 1059), ('it', 1018), ('a', 981), ('i', 876), ('the', 746), ('!', 725), ('ed', 587), ('and', 484), ('their', 403)] | avgLoss/100: 181.34881034851074 |  | entropyBonus: 0.750109851360321 blend: 0.286 top windows: W4:0.50,W2:0.49,W8:0.01,W12:0.00 | TUTOR.py 100

--- 2025-04-16 02:33:22 --- babyLLM 'right, last time i got to step 621... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 621! what am i learning today?' - charis: ''
2025-04-16 02:39:57 | 100 | LR0.0003 | logitMin:-2.7189 | logitMax:1.1148 | scheduledSampling:0.0000 | lossTUTOR:1.0633 | windowWeightsW2:2.22436 (0.56),W4:1.95673 (0.43),W8:-1.87800 (0.01),W12:-6.50872 (0.00),W16:-8.98267 (0.00),W20:-10.51769 (0.00),W24:-11.31647 (0.00),W32:-11.49899 (0.00),W28:-11.87588 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[('-', 69), ('a', 67), ('gging', 60), ('-', 48), ('of', 46), ('m', 44), ('.', 44), ('l', 43), ('om', 43), ('ation', 40)] | avgLoss/100: 1765.88037109375 |  | blend:0.571  W28:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 100
2025-04-16 02:47:50 | 200 | LR0.0003 | logitMin:-4.9080 | logitMax:3.7297 | scheduledSampling:0.0000 | lossTUTOR:0.5887 | windowWeightsW2:2.22429 (0.56),W4:1.95667 (0.43),W8:-1.87794 (0.01),W12:-6.50853 (0.00),W16:-8.98238 (0.00),W20:-10.51741 (0.00),W24:-11.31609 (0.00),W32:-11.49861 (0.00),W28:-11.87550 (0.00) | judgeBiasW32:-0.01357 (0.11),W2:-0.01357 (0.11),W4:-0.01357 (0.11),W8:-0.01357 (0.11),W12:-0.01357 (0.11),W16:-0.01357 (0.11),W20:-0.01357 (0.11),W24:-0.01357 (0.11),W28:-0.01357 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11228 (0.02),W24:0.11131 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 138), ('a', 111), ('of', 93), ('ing', 76), ('om', 73), ('-', 71), ('t', 66), ('ve', 65), ('gging', 65), ('m', 59)] | avgLoss/100: 1451.32568359375 |  | blend:0.571  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 02:54:41 | 300 | LR0.0003 | logitMin:-1.8081 | logitMax:1.3452 | scheduledSampling:0.0000 | lossTUTOR:1.9325 | windowWeightsW2:2.22452 (0.56),W4:1.95692 (0.43),W8:-1.87757 (0.01),W12:-6.51262 (0.00),W16:-8.98180 (0.00),W20:-10.51682 (0.00),W24:-11.31145 (0.00),W32:-11.49793 (0.00),W28:-11.87482 (0.00) | judgeBiasW32:-0.01327 (0.11),W2:-0.01327 (0.11),W4:-0.01327 (0.11),W8:-0.01327 (0.11),W12:-0.01327 (0.11),W16:-0.01327 (0.11),W20:-0.01327 (0.11),W24:-0.01327 (0.11),W28:-0.01327 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 259), ('ed', 225), ('a', 161), ('of', 103), ('and', 100), ('the', 84), ('.', 83), ('ing', 78), ('om', 76), ('-', 71)] | avgLoss/100: 1798.529541015625 |  | blend:0.572  W32:1.00,W2:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 03:01:55 | 400 | LR0.0003 | logitMin:-2.6950 | logitMax:2.0068 | scheduledSampling:0.0000 | lossTUTOR:1.0361 | windowWeightsW2:2.22445 (0.56),W4:1.95686 (0.43),W8:-1.87751 (0.01),W12:-6.51244 (0.00),W16:-8.98151 (0.00),W20:-10.51653 (0.00),W24:-11.31107 (0.00),W32:-11.49755 (0.00),W28:-11.87444 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 430), ('ed', 242), ('a', 190), ('they', 140), ('.', 129), ('the', 127), ('-', 124), ('of', 110), ('and', 100), ('ing', 85)] | avgLoss/100: 1187.5408935546875 |  | blend:0.572  W24:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 100
2025-04-16 03:09:00 | 500 | LR0.0003 | logitMin:-3.7580 | logitMax:2.3676 | scheduledSampling:0.0000 | lossTUTOR:1.0966 | windowWeightsW2:2.22438 (0.56),W4:1.95680 (0.43),W8:-1.87746 (0.01),W12:-6.51225 (0.00),W16:-8.98122 (0.00),W20:-10.51625 (0.00),W24:-11.31069 (0.00),W32:-11.49716 (0.00),W28:-11.87405 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 480), ('ed', 266), ('.', 237), ('a', 214), ('they', 198), ('their', 197), ('and', 189), ('of', 160), ('the', 148), ('-', 127)] | avgLoss/100: 1919.2119140625 |  | blend:0.572  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 03:15:57 | 600 | LR0.0003 | logitMin:-3.1417 | logitMax:2.4553 | scheduledSampling:0.0000 | lossTUTOR:1.7506 | windowWeightsW2:2.22431 (0.56),W4:1.95674 (0.43),W8:-1.87740 (0.01),W12:-6.51205 (0.00),W16:-8.98094 (0.00),W20:-10.51596 (0.00),W24:-11.31030 (0.00),W32:-11.49678 (0.00),W28:-11.87367 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 650), ('a', 319), ('and', 288), ('ed', 284), ('-', 275), ('the', 257), ('.', 238), ('they', 205), ('their', 204), ('of', 164)] | avgLoss/100: 3343.057861328125 |  | blend:0.572  W32:1.00,W2:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 03:23:06 | 700 | LR0.0003 | logitMin:-1.2484 | logitMax:0.7631 | scheduledSampling:0.0000 | lossTUTOR:1.0996 | windowWeightsW2:2.22423 (0.56),W4:1.95668 (0.43),W8:-1.87734 (0.01),W12:-6.51186 (0.00),W16:-8.98065 (0.00),W20:-10.51568 (0.00),W24:-11.30992 (0.00),W32:-11.49640 (0.00),W28:-11.87329 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 933), ('and', 323), ('a', 323), ('-', 298), ('the', 295), ('ed', 284), ('of', 276), ('.', 276), ('they', 248), ('their', 208)] | avgLoss/100: 3307.75537109375 |  | blend:0.572  W28:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 100
2025-04-16 03:30:13 | 800 | LR0.0003 | logitMin:-2.9268 | logitMax:1.6683 | scheduledSampling:0.0000 | lossTUTOR:0.9977 | windowWeightsW2:2.22416 (0.56),W4:1.95662 (0.43),W8:-1.87728 (0.01),W12:-6.51167 (0.00),W16:-8.98036 (0.00),W20:-10.51539 (0.00),W24:-11.30954 (0.00),W32:-11.49602 (0.00),W28:-11.87291 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1009), ('the', 380), ('and', 366), ('a', 358), ('.', 304), ('ed', 303), ('-', 300), ('of', 276), ('they', 252), ('s', 216)] | avgLoss/100: 2328.08056640625 |  | blend:0.572  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 03:37:22 | 900 | LR0.0003 | logitMin:-1.8900 | logitMax:0.7367 | scheduledSampling:0.0000 | lossTUTOR:0.7388 | windowWeightsW2:2.22409 (0.56),W4:1.95656 (0.43),W8:-1.87722 (0.01),W12:-6.51148 (0.00),W16:-8.98008 (0.00),W20:-10.51510 (0.00),W24:-11.30916 (0.00),W32:-11.49564 (0.00),W28:-11.87253 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1021), ('the', 428), ('and', 368), ('a', 360), ('-', 342), ('of', 328), ('.', 328), ('ed', 306), ('they', 277), ('s', 240)] | avgLoss/100: 3053.50439453125 |  | blend:0.572  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 03:44:34 | 1000 | LR0.0003 | logitMin:-5.3368 | logitMax:3.3920 | scheduledSampling:0.0000 | lossTUTOR:1.4033 | windowWeightsW2:2.22402 (0.56),W4:1.95650 (0.43),W8:-1.87716 (0.01),W12:-6.51129 (0.00),W16:-8.97979 (0.00),W20:-10.51482 (0.00),W24:-11.30878 (0.00),W32:-11.49526 (0.00),W28:-11.87215 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1179), ('the', 596), ('they', 482), ('and', 393), ('.', 377), ('a', 369), ('ed', 353), ('of', 349), ('-', 342), ('s', 247)] | avgLoss/100: 3459.603759765625 |  | blend:0.572  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 03:51:38 | 1100 | LR0.0003 | logitMin:-4.1263 | logitMax:2.8379 | scheduledSampling:0.0000 | lossTUTOR:0.9677 | windowWeightsW2:2.22395 (0.56),W4:1.95644 (0.43),W8:-1.87710 (0.01),W12:-6.51110 (0.00),W16:-8.97951 (0.00),W20:-10.51453 (0.00),W24:-11.30840 (0.00),W32:-11.49488 (0.00),W28:-11.87177 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1296), ('the', 616), ('they', 501), ('of', 417), ('and', 410), ('.', 403), ('a', 402), ('ed', 382), ('-', 342), ('s', 265)] | avgLoss/100: 1993.5115966796875 |  | blend:0.572  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 03:58:32 | 1200 | LR0.0003 | logitMin:-3.5258 | logitMax:2.8640 | scheduledSampling:0.0000 | lossTUTOR:1.4643 | windowWeightsW2:2.22388 (0.56),W4:1.95638 (0.43),W8:-1.87704 (0.01),W12:-6.51091 (0.00),W16:-8.97922 (0.00),W20:-10.51425 (0.00),W24:-11.30802 (0.00),W32:-11.49449 (0.00),W28:-11.87138 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11432 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1379), ('the', 651), ('a', 540), ('they', 502), ('ed', 444), ('and', 443), ('of', 433), ('.', 409), ('-', 342), ('in', 334)] | avgLoss/100: 2299.76416015625 |  | blend:0.572  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 04:05:05 | 1300 | LR0.0003 | logitMin:-2.6255 | logitMax:1.8599 | scheduledSampling:0.0000 | lossTUTOR:1.2492 | windowWeightsW2:2.22380 (0.56),W4:1.95632 (0.43),W8:-1.87698 (0.01),W12:-6.51072 (0.00),W16:-8.97893 (0.00),W20:-10.51396 (0.00),W24:-11.30763 (0.00),W32:-11.49411 (0.00),W28:-11.87100 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1570), ('the', 690), ('a', 577), ('and', 515), ('they', 502), ('ed', 458), ('of', 449), ('.', 409), ('-', 348), ('in', 344)] | avgLoss/100: 2665.413818359375 |  | blend:0.572  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 04:11:39 | 1400 | LR0.0003 | logitMin:-1.7221 | logitMax:3.9863 | scheduledSampling:0.0000 | lossTUTOR:2.4651 | windowWeightsW2:2.22373 (0.56),W4:1.95626 (0.43),W8:-1.87692 (0.01),W12:-6.51053 (0.00),W16:-8.97865 (0.00),W20:-10.51367 (0.00),W24:-11.30725 (0.00),W32:-11.49373 (0.00),W28:-11.87062 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1624), ('the', 694), ('a', 615), ('they', 538), ('and', 527), ('ed', 458), ('of', 455), ('.', 449), ('-', 365), ('in', 353)] | avgLoss/100: 2680.568359375 |  | blend:0.572  W28:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 100
2025-04-16 04:18:17 | 1500 | LR0.0003 | logitMin:-3.2251 | logitMax:1.5361 | scheduledSampling:0.0000 | lossTUTOR:1.8176 | windowWeightsW2:2.22366 (0.56),W4:1.95620 (0.43),W8:-1.87686 (0.01),W12:-6.51034 (0.00),W16:-8.97836 (0.00),W20:-10.51339 (0.00),W24:-11.30687 (0.00),W32:-11.49335 (0.00),W28:-11.87024 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1642), ('the', 720), ('it', 652), ('a', 621), ('and', 552), ('they', 538), ('.', 515), ('of', 514), ('ed', 458), ('!', 380)] | avgLoss/100: 3824.6591796875 |  | blend:0.572  W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 100
2025-04-16 04:24:50 | 1600 | LR0.0003 | logitMin:-2.0586 | logitMax:1.0042 | scheduledSampling:0.0000 | lossTUTOR:1.8646 | windowWeightsW2:2.22359 (0.56),W4:1.95615 (0.43),W8:-1.87680 (0.01),W12:-6.51015 (0.00),W16:-8.97808 (0.00),W20:-10.51310 (0.00),W24:-11.30649 (0.00),W32:-11.49297 (0.00),W28:-11.86986 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1648), ('a', 797), ('the', 733), ('it', 699), ('and', 583), ('.', 551), ('they', 538), ('of', 538), ('ed', 458), ('!', 420)] | avgLoss/100: 3865.01708984375 |  | blend:0.572  W28:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 100
2025-04-16 04:32:40 | 1700 | LR0.0003 | logitMin:-2.0032 | logitMax:2.7315 | scheduledSampling:0.0000 | lossTUTOR:2.4368 | windowWeightsW2:2.22352 (0.56),W4:1.95609 (0.43),W8:-1.87674 (0.01),W12:-6.50996 (0.00),W16:-8.97779 (0.00),W20:-10.51281 (0.00),W24:-11.30611 (0.00),W32:-11.49259 (0.00),W28:-11.86948 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1708), ('it', 893), ('a', 809), ('the', 733), ('.', 728), ('and', 583), ('they', 538), ('of', 538), ('ed', 458), ('!', 448)] | avgLoss/100: 4396.80859375 |  | blend:0.572  W32:1.00,W2:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 04:39:15 | 1800 | LR0.0003 | logitMin:-4.4263 | logitMax:2.1956 | scheduledSampling:0.0000 | lossTUTOR:1.1179 | windowWeightsW2:2.22345 (0.56),W4:1.95603 (0.43),W8:-1.87668 (0.01),W12:-6.50977 (0.00),W16:-8.97750 (0.00),W20:-10.51253 (0.00),W24:-11.30573 (0.00),W32:-11.49221 (0.00),W28:-11.86910 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1719), ('it', 895), ('a', 823), ('.', 790), ('the', 733), ('and', 583), ('they', 538), ('of', 538), ('!', 517), ('i', 503)] | avgLoss/100: 3155.974609375 |  | blend:0.572  W20:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 100
2025-04-16 04:45:48 | 1900 | LR0.0003 | logitMin:-2.4076 | logitMax:1.5500 | scheduledSampling:0.0000 | lossTUTOR:1.9526 | windowWeightsW2:2.22338 (0.56),W4:1.95597 (0.43),W8:-1.87662 (0.01),W12:-6.50957 (0.00),W16:-8.97722 (0.00),W20:-10.51224 (0.00),W24:-11.30535 (0.00),W32:-11.49182 (0.00),W28:-11.86871 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1785), ('it', 896), ('a', 886), ('.', 845), ('the', 734), ('and', 597), ('!', 579), ('i', 541), ('they', 538), ('of', 538)] | avgLoss/100: 2872.465087890625 |  | blend:0.572  W28:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 100
2025-04-16 04:52:26 | 2000 | LR0.0003 | logitMin:-0.8778 | logitMax:0.6356 | scheduledSampling:0.0000 | lossTUTOR:0.6727 | windowWeightsW2:2.22330 (0.56),W4:1.95591 (0.43),W8:-1.87656 (0.01),W12:-6.50938 (0.00),W16:-8.97693 (0.00),W20:-10.51196 (0.00),W24:-11.30496 (0.00),W32:-11.49144 (0.00),W28:-11.86833 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10510 (-0.05) | topTokens[(',', 1805), ('.', 1077), ('it', 896), ('a', 886), ('the', 734), ('and', 630), ('i', 610), ('!', 582), ('to', 546), ('of', 539)] | avgLoss/100: 3018.102294921875 |  | blend:0.572  W32:1.00,W2:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 04:59:04 | 2100 | LR0.0003 | logitMin:-1.8268 | logitMax:0.6155 | scheduledSampling:0.0000 | lossTUTOR:0.6592 | windowWeightsW2:2.22323 (0.56),W4:1.95585 (0.43),W8:-1.87650 (0.01),W12:-6.50919 (0.00),W16:-8.97665 (0.00),W20:-10.51167 (0.00),W24:-11.30458 (0.00),W32:-11.49106 (0.00),W28:-11.86795 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10511 (-0.05) | topTokens[(',', 1828), ('.', 1193), ('it', 897), ('a', 886), ('the', 785), ('to', 750), ('i', 734), ('and', 630), ('!', 591), ('?', 568)] | avgLoss/100: 2136.540283203125 |  | blend:0.572  W32:1.00,W2:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 05:05:40 | 2200 | LR0.0003 | logitMin:-3.9891 | logitMax:3.6842 | scheduledSampling:0.0000 | lossTUTOR:1.1519 | windowWeightsW2:2.22316 (0.56),W4:1.95579 (0.43),W8:-1.87644 (0.01),W12:-6.50900 (0.00),W16:-8.97636 (0.00),W20:-10.51138 (0.00),W24:-11.30420 (0.00),W32:-11.49068 (0.00),W28:-11.86757 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11367 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10511 (-0.05) | topTokens[(',', 1838), ('.', 1398), ('a', 937), ('it', 897), ('i', 867), ('to', 851), ('the', 826), ('and', 636), ('!', 628), ('?', 627)] | avgLoss/100: 2987.0615234375 |  | blend:0.572  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 05:12:16 | 2300 | LR0.0003 | logitMin:-4.7999 | logitMax:5.4589 | scheduledSampling:0.0000 | lossTUTOR:3.5960 | windowWeightsW2:2.22309 (0.56),W4:1.95573 (0.43),W8:-1.87638 (0.01),W12:-6.50881 (0.00),W16:-8.97607 (0.00),W20:-10.51110 (0.00),W24:-11.30382 (0.00),W32:-11.49030 (0.00),W28:-11.86719 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10511 (-0.05) | topTokens[(',', 1838), ('.', 1559), ('to', 963), ('a', 943), ('it', 897), ('i', 893), ('the', 838), ('?', 773), ('!', 709), ('and', 638)] | avgLoss/100: 4069.409912109375 |  | blend:0.572  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 05:18:50 | 2400 | LR0.0003 | logitMin:-2.1595 | logitMax:1.8963 | scheduledSampling:0.0000 | lossTUTOR:2.5618 | windowWeightsW2:2.22302 (0.56),W4:1.95567 (0.43),W8:-1.87632 (0.01),W12:-6.50862 (0.00),W16:-8.97579 (0.00),W20:-10.51081 (0.00),W24:-11.30344 (0.00),W32:-11.48992 (0.00),W28:-11.86681 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10511 (-0.05) | topTokens[(',', 1838), ('.', 1623), ('i', 1093), ('to', 1000), ('?', 991), ('a', 945), ('it', 900), ('the', 847), ('you', 764), ('!', 764)] | avgLoss/100: 2759.48974609375 |  | blend:0.572  W28:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 100
2025-04-16 05:25:27 | 2500 | LR0.0003 | logitMin:-1.5549 | logitMax:0.7920 | scheduledSampling:0.0000 | lossTUTOR:1.0121 | windowWeightsW2:2.22295 (0.56),W4:1.95561 (0.43),W8:-1.87626 (0.01),W12:-6.50843 (0.00),W16:-8.97550 (0.00),W20:-10.51053 (0.00),W24:-11.30306 (0.00),W32:-11.48954 (0.00),W28:-11.86643 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10511 (-0.05) | topTokens[(',', 1861), ('.', 1748), ('?', 1228), ('i', 1208), ('to', 1041), ('a', 945), ('it', 938), ('you', 877), ('the', 847), ('!', 798)] | avgLoss/100: 3170.198486328125 |  | blend:0.572  W32:1.00,W2:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 05:31:58 | 2600 | LR0.0003 | logitMin:-6.2635 | logitMax:4.9054 | scheduledSampling:0.0000 | lossTUTOR:0.5573 | windowWeightsW2:2.22287 (0.56),W4:1.95555 (0.43),W8:-1.87620 (0.01),W12:-6.50824 (0.00),W16:-8.97521 (0.00),W20:-10.51024 (0.00),W24:-11.30268 (0.00),W32:-11.48915 (0.00),W28:-11.86604 (0.00) | judgeBiasW32:-0.01326 (0.11),W2:-0.01326 (0.11),W4:-0.01326 (0.11),W8:-0.01326 (0.11),W12:-0.01326 (0.11),W16:-0.01326 (0.11),W20:-0.01326 (0.11),W24:-0.01326 (0.11),W28:-0.01326 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10706 (-0.03),W4:0.10511 (-0.05) | topTokens[(',', 1902), ('.', 1767), ('i', 1472), ('?', 1360), ('to', 1048), ('it', 1034), ('a', 972), ('you', 962), ('!', 872), ('the', 847)] | avgLoss/100: 2092.174560546875 |  | blend:0.572  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 05:38:32 | 2700 | LR0.0003 | logitMin:-2.6313 | logitMax:4.0079 | scheduledSampling:0.0000 | lossTUTOR:2.6986 | windowWeightsW2:2.22529 (0.56),W4:1.95301 (0.43),W8:-1.87366 (0.01),W12:-6.50557 (0.00),W16:-8.97245 (0.00),W20:-10.50747 (0.00),W24:-11.29981 (0.00),W32:-11.48629 (0.00),W28:-11.86318 (0.00) | judgeBiasW32:-0.01077 (0.11),W2:-0.01077 (0.11),W4:-0.01077 (0.11),W8:-0.01077 (0.11),W12:-0.01077 (0.11),W16:-0.01077 (0.11),W20:-0.01077 (0.11),W24:-0.01077 (0.11),W28:-0.01077 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10733 (-0.03),W4:0.10484 (-0.05) | topTokens[(',', 2130), ('.', 1804), ('i', 1662), ('?', 1361), ('it', 1084), ('to', 1053), ('you', 1009), ('a', 972), ('!', 954), ('the', 847)] | avgLoss/100: 3402.44677734375 |  | blend:0.572  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 05:45:03 | 2800 | LR0.0003 | logitMin:-4.7252 | logitMax:2.4686 | scheduledSampling:0.0000 | lossTUTOR:2.7158 | windowWeightsW2:2.23194 (0.57),W4:1.94622 (0.42),W8:-1.86689 (0.01),W12:-6.49867 (0.00),W16:-8.96545 (0.00),W20:-10.50047 (0.00),W24:-11.29272 (0.00),W32:-11.47919 (0.00),W28:-11.85608 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 2156), ('.', 2043), ('i', 1767), ('?', 1379), ('it', 1139), ('you', 1092), ('to', 1054), ('a', 978), ('!', 954), ('the', 912)] | avgLoss/100: 4031.319091796875 |  | blend:0.574  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 05:51:34 | 2900 | LR0.0003 | logitMin:-3.3431 | logitMax:2.6809 | scheduledSampling:0.0000 | lossTUTOR:3.0217 | windowWeightsW2:2.23187 (0.57),W4:1.94616 (0.42),W8:-1.86683 (0.01),W12:-6.49847 (0.00),W16:-8.96516 (0.00),W20:-10.50019 (0.00),W24:-11.29233 (0.00),W32:-11.47881 (0.00),W28:-11.85570 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 2301), ('.', 2044), ('i', 1834), ('?', 1399), ('you', 1218), ('it', 1148), ('to', 1061), ('a', 980), ('!', 968), ('the', 943)] | avgLoss/100: 4809.0126953125 |  | blend:0.574  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 05:58:12 | 3000 | LR0.0003 | logitMin:-0.6904 | logitMax:-0.1531 | scheduledSampling:0.0000 | lossTUTOR:0.0958 | windowWeightsW2:2.23179 (0.57),W4:1.94610 (0.42),W8:-1.86677 (0.01),W12:-6.49828 (0.00),W16:-8.96487 (0.00),W20:-10.49990 (0.00),W24:-11.29195 (0.00),W32:-11.47843 (0.00),W28:-11.85532 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 2383), ('.', 2056), ('i', 1989), ('?', 1421), ('you', 1223), ('it', 1154), ('to', 1064), ('a', 981), ('the', 975), ('!', 972)] | avgLoss/100: 3643.29931640625 |  | blend:0.574  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 06:04:44 | 3100 | LR0.0003 | logitMin:-2.9777 | logitMax:2.4726 | scheduledSampling:0.0000 | lossTUTOR:1.8296 | windowWeightsW2:2.23172 (0.57),W4:1.94604 (0.42),W8:-1.86671 (0.01),W12:-6.49809 (0.00),W16:-8.96459 (0.00),W20:-10.49961 (0.00),W24:-11.29157 (0.00),W32:-11.47805 (0.00),W28:-11.85494 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 2417), ('i', 2111), ('.', 2108), ('?', 1425), ('you', 1225), ('it', 1220), ('to', 1076), ('the', 1067), ('!', 1022), ('a', 1007)] | avgLoss/100: 3529.662841796875 |  | blend:0.574  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 06:11:15 | 3200 | LR0.0003 | logitMin:-1.8740 | logitMax:1.8112 | scheduledSampling:0.0000 | lossTUTOR:1.5535 | windowWeightsW2:2.23165 (0.57),W4:1.94598 (0.42),W8:-1.86665 (0.01),W12:-6.49790 (0.00),W16:-8.96430 (0.00),W20:-10.49933 (0.00),W24:-11.29119 (0.00),W32:-11.47767 (0.00),W28:-11.85456 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 2655), ('.', 2148), ('i', 2137), ('?', 1448), ('you', 1277), ('it', 1232), ('the', 1185), ('to', 1128), ('!', 1037), ('a', 1009)] | avgLoss/100: 3464.788818359375 |  | blend:0.574  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 06:17:47 | 3300 | LR0.0003 | logitMin:-2.7138 | logitMax:2.2526 | scheduledSampling:0.0000 | lossTUTOR:2.2612 | windowWeightsW2:2.23158 (0.57),W4:1.94592 (0.42),W8:-1.86659 (0.01),W12:-6.49771 (0.00),W16:-8.96402 (0.00),W20:-10.49904 (0.00),W24:-11.29081 (0.00),W32:-11.47729 (0.00),W28:-11.85418 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 2864), ('i', 2318), ('.', 2199), ('?', 1448), ('you', 1386), ('it', 1260), ('the', 1196), ('to', 1139), ('a', 1072), ('!', 1040)] | avgLoss/100: 3508.359375 |  | blend:0.574  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 06:24:27 | 3400 | LR0.0003 | logitMin:-2.4110 | logitMax:1.1631 | scheduledSampling:0.0000 | lossTUTOR:1.0468 | windowWeightsW2:2.23151 (0.57),W4:1.94587 (0.42),W8:-1.86653 (0.01),W12:-6.49752 (0.00),W16:-8.96373 (0.00),W20:-10.49875 (0.00),W24:-11.29043 (0.00),W32:-11.47691 (0.00),W28:-11.85380 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 2962), ('i', 2363), ('.', 2239), ('you', 1477), ('?', 1449), ('it', 1268), ('the', 1245), ('to', 1139), ('a', 1072), ('and', 1055)] | avgLoss/100: 3492.601318359375 |  | blend:0.574  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 06:31:04 | 3500 | LR0.0003 | logitMin:-2.5920 | logitMax:1.5112 | scheduledSampling:0.0000 | lossTUTOR:1.7211 | windowWeightsW2:2.23144 (0.57),W4:1.94581 (0.43),W8:-1.86647 (0.01),W12:-6.49733 (0.00),W16:-8.96344 (0.00),W20:-10.49847 (0.00),W24:-11.29005 (0.00),W32:-11.47652 (0.00),W28:-11.85341 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 3161), ('i', 2437), ('.', 2239), ('you', 1533), ('?', 1449), ('the', 1274), ('it', 1268), ('to', 1149), ('a', 1147), ('and', 1098)] | avgLoss/100: 3399.71240234375 |  | blend:0.574  W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 100
2025-04-16 06:37:36 | 3600 | LR0.0003 | logitMin:-2.9826 | logitMax:2.5154 | scheduledSampling:0.0000 | lossTUTOR:1.1402 | windowWeightsW2:2.23136 (0.57),W4:1.94575 (0.43),W8:-1.86641 (0.01),W12:-6.49714 (0.00),W16:-8.96316 (0.00),W20:-10.49818 (0.00),W24:-11.28966 (0.00),W32:-11.47614 (0.00),W28:-11.85303 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11426 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 3245), ('i', 2437), ('.', 2314), ('you', 1572), ('?', 1449), ('the', 1289), ('it', 1268), ('and', 1242), ('to', 1209), ('a', 1157)] | avgLoss/100: 3165.400634765625 |  | blend:0.574  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 06:44:08 | 3700 | LR0.0003 | logitMin:-2.1418 | logitMax:1.1515 | scheduledSampling:0.0000 | lossTUTOR:0.9757 | windowWeightsW2:2.23129 (0.57),W4:1.94569 (0.43),W8:-1.86635 (0.01),W12:-6.49695 (0.00),W16:-8.96287 (0.00),W20:-10.49790 (0.00),W24:-11.28928 (0.00),W32:-11.47576 (0.00),W28:-11.85265 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 3446), ('i', 2461), ('.', 2314), ('you', 1608), ('?', 1481), ('the', 1325), ('it', 1288), ('and', 1265), ('to', 1227), ('a', 1157)] | avgLoss/100: 2702.621337890625 |  | blend:0.574  W32:1.00,W2:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 06:50:39 | 3800 | LR0.0003 | logitMin:-3.0498 | logitMax:3.7885 | scheduledSampling:0.0000 | lossTUTOR:4.3957 | windowWeightsW2:2.23122 (0.57),W4:1.94563 (0.43),W8:-1.86629 (0.01),W12:-6.49676 (0.00),W16:-8.96259 (0.00),W20:-10.49761 (0.00),W24:-11.28890 (0.00),W32:-11.47538 (0.00),W28:-11.85227 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 3555), ('i', 2476), ('.', 2341), ('you', 1670), ('?', 1486), ('the', 1338), ('it', 1293), ('and', 1291), ('to', 1227), ('a', 1175)] | avgLoss/100: 2846.213134765625 |  | blend:0.574  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 06:57:13 | 3900 | LR0.0003 | logitMin:-2.1952 | logitMax:1.9944 | scheduledSampling:0.0000 | lossTUTOR:1.6038 | windowWeightsW2:2.23115 (0.57),W4:1.94557 (0.43),W8:-1.86623 (0.01),W12:-6.49657 (0.00),W16:-8.96230 (0.00),W20:-10.49732 (0.00),W24:-11.28852 (0.00),W32:-11.47500 (0.00),W28:-11.85189 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 3777), ('i', 2494), ('.', 2367), ('you', 1703), ('?', 1496), ('the', 1398), ('and', 1368), ('it', 1302), ('to', 1227), ('a', 1185)] | avgLoss/100: 3068.30029296875 |  | blend:0.574  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 07:03:49 | 4000 | LR0.0003 | logitMin:-1.3076 | logitMax:0.7783 | scheduledSampling:0.0000 | lossTUTOR:0.7249 | windowWeightsW2:2.23108 (0.57),W4:1.94551 (0.43),W8:-1.86617 (0.01),W12:-6.49638 (0.00),W16:-8.96201 (0.00),W20:-10.49704 (0.00),W24:-11.28814 (0.00),W32:-11.47462 (0.00),W28:-11.85151 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 3858), ('i', 2496), ('.', 2371), ('you', 1774), ('?', 1503), ('the', 1448), ('and', 1383), ('it', 1315), ('to', 1231), ('a', 1194)] | avgLoss/100: 3536.661865234375 |  | blend:0.574  W32:1.00,W2:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 07:10:20 | 4100 | LR0.0003 | logitMin:-2.3427 | logitMax:1.3713 | scheduledSampling:0.0000 | lossTUTOR:2.1283 | windowWeightsW2:2.23101 (0.57),W4:1.94545 (0.43),W8:-1.86611 (0.01),W12:-6.49619 (0.00),W16:-8.96173 (0.00),W20:-10.49675 (0.00),W24:-11.28776 (0.00),W32:-11.47424 (0.00),W28:-11.85113 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 3965), ('i', 2571), ('.', 2382), ('you', 1820), ('?', 1503), ('the', 1448), ('and', 1388), ('it', 1316), ('a', 1264), ('to', 1236)] | avgLoss/100: 3059.5927734375 |  | blend:0.574  W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 100
2025-04-16 07:17:11 | 4200 | LR0.0003 | logitMin:-2.3604 | logitMax:1.5687 | scheduledSampling:0.0000 | lossTUTOR:1.8547 | windowWeightsW2:2.23094 (0.57),W4:1.94539 (0.43),W8:-1.86605 (0.01),W12:-6.49600 (0.00),W16:-8.96144 (0.00),W20:-10.49647 (0.00),W24:-11.28738 (0.00),W32:-11.47385 (0.00),W28:-11.85074 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 4135), ('i', 2577), ('.', 2387), ('you', 1864), ('?', 1538), ('the', 1476), ('and', 1410), ('it', 1343), ('a', 1287), ('to', 1248)] | avgLoss/100: 2897.4775390625 |  | blend:0.574  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 07:23:43 | 4300 | LR0.0003 | logitMin:-2.4216 | logitMax:1.5775 | scheduledSampling:0.0000 | lossTUTOR:1.9313 | windowWeightsW2:2.23086 (0.57),W4:1.94533 (0.43),W8:-1.86599 (0.01),W12:-6.49580 (0.00),W16:-8.96115 (0.00),W20:-10.49618 (0.00),W24:-11.28699 (0.00),W32:-11.47347 (0.00),W28:-11.85036 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 4171), ('i', 2663), ('.', 2453), ('you', 1891), ('the', 1582), ('?', 1538), ('and', 1439), ('it', 1345), ('a', 1311), ('to', 1288)] | avgLoss/100: 3471.133056640625 |  | blend:0.574  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 07:30:16 | 4400 | LR0.0003 | logitMin:-2.1678 | logitMax:1.0875 | scheduledSampling:0.0000 | lossTUTOR:1.1486 | windowWeightsW2:2.23079 (0.57),W4:1.94527 (0.43),W8:-1.86593 (0.01),W12:-6.49561 (0.00),W16:-8.96087 (0.00),W20:-10.49589 (0.00),W24:-11.28661 (0.00),W32:-11.47309 (0.00),W28:-11.84998 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 4314), ('i', 2663), ('.', 2486), ('you', 1944), ('the', 1664), ('?', 1544), ('and', 1475), ('to', 1364), ('it', 1348), ('a', 1322)] | avgLoss/100: 3137.8310546875 |  | blend:0.574  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 07:36:53 | 4500 | LR0.0003 | logitMin:-1.7473 | logitMax:1.4676 | scheduledSampling:0.0000 | lossTUTOR:0.8425 | windowWeightsW2:2.23072 (0.57),W4:1.94521 (0.43),W8:-1.86588 (0.01),W12:-6.49542 (0.00),W16:-8.96058 (0.00),W20:-10.49561 (0.00),W24:-11.28623 (0.00),W32:-11.47271 (0.00),W28:-11.84960 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 4633), ('i', 2996), ('.', 2510), ('you', 1962), ('the', 1664), ('?', 1544), ('and', 1475), ('to', 1403), ('it', 1348), ('a', 1331)] | avgLoss/100: 2651.17529296875 |  | blend:0.574  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 07:43:24 | 4600 | LR0.0003 | logitMin:-2.1568 | logitMax:2.7054 | scheduledSampling:0.0000 | lossTUTOR:1.2556 | windowWeightsW2:2.23065 (0.57),W4:1.94515 (0.43),W8:-1.86582 (0.01),W12:-6.49523 (0.00),W16:-8.96030 (0.00),W20:-10.49532 (0.00),W24:-11.28585 (0.00),W32:-11.47233 (0.00),W28:-11.84922 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 4684), ('i', 3431), ('.', 2590), ('you', 1998), ('the', 1664), ('?', 1634), ('it', 1485), ('and', 1478), ('to', 1403), ('a', 1378)] | avgLoss/100: 3680.73291015625 |  | blend:0.574  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 07:49:55 | 4700 | LR0.0003 | logitMin:-2.1497 | logitMax:3.2988 | scheduledSampling:0.0000 | lossTUTOR:1.1914 | windowWeightsW2:2.23058 (0.57),W4:1.94509 (0.43),W8:-1.86576 (0.01),W12:-6.49504 (0.00),W16:-8.96001 (0.00),W20:-10.49504 (0.00),W24:-11.28547 (0.00),W32:-11.47195 (0.00),W28:-11.84884 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 4841), ('i', 3534), ('.', 2667), ('you', 2012), ('the', 1761), ('?', 1636), ('it', 1603), ('and', 1478), ('to', 1403), ('a', 1400)] | avgLoss/100: 3056.72119140625 |  | blend:0.574  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 07:56:29 | 4800 | LR0.0003 | logitMin:-3.8409 | logitMax:2.3888 | scheduledSampling:0.0000 | lossTUTOR:2.1603 | windowWeightsW2:2.23051 (0.57),W4:1.94503 (0.43),W8:-1.86570 (0.01),W12:-6.49485 (0.00),W16:-8.95972 (0.00),W20:-10.49475 (0.00),W24:-11.28509 (0.00),W32:-11.47157 (0.00),W28:-11.84846 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 4968), ('i', 3534), ('.', 2768), ('you', 2048), ('the', 1872), ('it', 1641), ('?', 1636), ('!', 1536), ('a', 1518), ('and', 1478)] | avgLoss/100: 3757.6005859375 |  | blend:0.574  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 08:03:00 | 4900 | LR0.0003 | logitMin:-5.0435 | logitMax:1.8242 | scheduledSampling:0.0000 | lossTUTOR:1.4895 | windowWeightsW2:2.23043 (0.57),W4:1.94497 (0.43),W8:-1.86564 (0.01),W12:-6.49466 (0.00),W16:-8.95944 (0.00),W20:-10.49446 (0.00),W24:-11.28471 (0.00),W32:-11.47118 (0.00),W28:-11.84807 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10414 (-0.06) | topTokens[(',', 5014), ('i', 3534), ('.', 2866), ('you', 2090), ('the', 1978), ('it', 1770), ('!', 1664), ('?', 1636), ('a', 1518), ('and', 1478)] | avgLoss/100: 3716.59521484375 |  | blend:0.574  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 08:09:39 | 5000 | LR0.0003 | logitMin:-1.7644 | logitMax:2.2476 | scheduledSampling:0.0000 | lossTUTOR:1.0384 | windowWeightsW2:2.23036 (0.57),W4:1.94491 (0.43),W8:-1.86558 (0.01),W12:-6.49447 (0.00),W16:-8.95915 (0.00),W20:-10.49418 (0.00),W24:-11.28432 (0.00),W32:-11.47080 (0.00),W28:-11.84769 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 5199), ('i', 3534), ('.', 3057), ('the', 2120), ('you', 2090), ('it', 1770), ('!', 1696), ('?', 1636), ('a', 1543), ('and', 1479)] | avgLoss/100: 4009.476318359375 |  | blend:0.574  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 08:16:11 | 5100 | LR0.0003 | logitMin:-3.1861 | logitMax:0.9922 | scheduledSampling:0.0000 | lossTUTOR:1.8958 | windowWeightsW2:2.23029 (0.57),W4:1.94485 (0.43),W8:-1.86552 (0.01),W12:-6.49428 (0.00),W16:-8.95887 (0.00),W20:-10.49389 (0.00),W24:-11.28394 (0.00),W32:-11.47042 (0.00),W28:-11.84731 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 5240), ('i', 3539), ('.', 3222), ('the', 2177), ('you', 2090), ('!', 1942), ('it', 1770), ('?', 1636), ('a', 1546), ('and', 1480)] | avgLoss/100: 3316.232421875 |  | blend:0.574  W32:1.00,W2:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 08:23:32 | 5200 | LR0.0003 | logitMin:-2.3938 | logitMax:1.7643 | scheduledSampling:0.0000 | lossTUTOR:2.2023 | windowWeightsW2:2.23022 (0.57),W4:1.94479 (0.43),W8:-1.86546 (0.01),W12:-6.49409 (0.00),W16:-8.95858 (0.00),W20:-10.49360 (0.00),W24:-11.28356 (0.00),W32:-11.47004 (0.00),W28:-11.84693 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 5318), ('i', 3544), ('.', 3262), ('the', 2400), ('!', 2215), ('you', 2092), ('it', 1774), ('?', 1636), ('a', 1557), ('and', 1480)] | avgLoss/100: 3046.359619140625 |  | blend:0.574  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 08:30:04 | 5300 | LR0.0003 | logitMin:-3.3018 | logitMax:1.3824 | scheduledSampling:0.0000 | lossTUTOR:1.4123 | windowWeightsW2:2.23015 (0.57),W4:1.94473 (0.43),W8:-1.86540 (0.01),W12:-6.49390 (0.00),W16:-8.95829 (0.00),W20:-10.49332 (0.00),W24:-11.28318 (0.00),W32:-11.46966 (0.00),W28:-11.84655 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 5502), ('i', 3554), ('.', 3365), ('the', 2506), ('!', 2395), ('you', 2092), ('it', 1774), ('?', 1636), ('a', 1567), ('and', 1480)] | avgLoss/100: 3557.928955078125 |  | blend:0.574  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 08:36:37 | 5400 | LR0.0003 | logitMin:-2.3063 | logitMax:1.8782 | scheduledSampling:0.0000 | lossTUTOR:2.1458 | windowWeightsW2:2.23008 (0.57),W4:1.94467 (0.43),W8:-1.86534 (0.01),W12:-6.49371 (0.00),W16:-8.95801 (0.00),W20:-10.49303 (0.00),W24:-11.28280 (0.00),W32:-11.46928 (0.00),W28:-11.84617 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 5585), ('i', 3583), ('.', 3436), ('!', 2596), ('the', 2532), ('you', 2144), ('it', 1774), ('?', 1636), ('a', 1572), ('to', 1547)] | avgLoss/100: 3449.6484375 |  | blend:0.574  W20:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 100
2025-04-16 08:43:14 | 5500 | LR0.0003 | logitMin:-3.4299 | logitMax:0.9959 | scheduledSampling:0.0000 | lossTUTOR:1.4844 | windowWeightsW2:2.23001 (0.57),W4:1.94461 (0.43),W8:-1.86528 (0.01),W12:-6.49352 (0.00),W16:-8.95772 (0.00),W20:-10.49275 (0.00),W24:-11.28242 (0.00),W32:-11.46889 (0.00),W28:-11.84579 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 5631), ('i', 3599), ('.', 3483), ('!', 2641), ('the', 2605), ('you', 2156), ('it', 1774), ('?', 1636), ('a', 1607), ('to', 1582)] | avgLoss/100: 3125.04833984375 |  | blend:0.574  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 08:49:46 | 5600 | LR0.0003 | logitMin:-2.7911 | logitMax:1.7041 | scheduledSampling:0.0000 | lossTUTOR:2.0617 | windowWeightsW2:2.22993 (0.57),W4:1.94455 (0.43),W8:-1.86522 (0.01),W12:-6.49332 (0.00),W16:-8.95744 (0.00),W20:-10.49246 (0.00),W24:-11.28203 (0.00),W32:-11.46851 (0.00),W28:-11.84540 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 5641), ('i', 3600), ('.', 3507), ('the', 2674), ('!', 2645), ('you', 2157), ('it', 1779), ('?', 1637), ('a', 1607), ('to', 1589)] | avgLoss/100: 3532.579345703125 |  | blend:0.574  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 08:56:19 | 5700 | LR0.0003 | logitMin:-3.3349 | logitMax:2.0826 | scheduledSampling:0.0000 | lossTUTOR:1.7620 | windowWeightsW2:2.22986 (0.57),W4:1.94449 (0.43),W8:-1.86516 (0.01),W12:-6.49313 (0.00),W16:-8.95715 (0.00),W20:-10.49217 (0.00),W24:-11.28165 (0.00),W32:-11.46813 (0.00),W28:-11.84502 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 5673), ('i', 3601), ('.', 3514), ('the', 2749), ('!', 2646), ('you', 2158), ('it', 1780), ('?', 1639), ('to', 1621), ('a', 1610)] | avgLoss/100: 2814.1474609375 |  | blend:0.574  W32:1.00,W2:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 09:02:50 | 5800 | LR0.0003 | logitMin:-2.7658 | logitMax:1.2616 | scheduledSampling:0.0000 | lossTUTOR:1.2279 | windowWeightsW2:2.22979 (0.57),W4:1.94443 (0.43),W8:-1.86510 (0.01),W12:-6.49294 (0.00),W16:-8.95686 (0.00),W20:-10.49189 (0.00),W24:-11.28127 (0.00),W32:-11.46775 (0.00),W28:-11.84464 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 5673), ('i', 3603), ('.', 3573), ('the', 2852), ('!', 2651), ('you', 2158), ('it', 1780), ('to', 1645), ('?', 1641), ('a', 1610)] | avgLoss/100: 3510.512451171875 |  | blend:0.574  W28:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 100
2025-04-16 09:09:22 | 5900 | LR0.0003 | logitMin:-2.7030 | logitMax:1.8160 | scheduledSampling:0.0000 | lossTUTOR:1.7095 | windowWeightsW2:2.22972 (0.57),W4:1.94438 (0.43),W8:-1.86504 (0.01),W12:-6.49275 (0.00),W16:-8.95658 (0.00),W20:-10.49160 (0.00),W24:-11.28089 (0.00),W32:-11.46737 (0.00),W28:-11.84426 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 5708), ('i', 3626), ('.', 3591), ('the', 2872), ('!', 2651), ('you', 2159), ('it', 1801), ('to', 1659), ('?', 1641), ('a', 1615)] | avgLoss/100: 3461.203857421875 |  | blend:0.574  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 09:15:58 | 6000 | LR0.0003 | logitMin:-0.7213 | logitMax:0.0048 | scheduledSampling:0.0000 | lossTUTOR:0.1979 | windowWeightsW2:2.22965 (0.57),W4:1.94432 (0.43),W8:-1.86498 (0.01),W12:-6.49256 (0.00),W16:-8.95629 (0.00),W20:-10.49132 (0.00),W24:-11.28051 (0.00),W32:-11.46699 (0.00),W28:-11.84388 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 5712), ('i', 3626), ('.', 3610), ('the', 2878), ('!', 2652), ('you', 2162), ('it', 1864), ('to', 1674), ('?', 1642), ('a', 1624)] | avgLoss/100: 3008.5888671875 |  | blend:0.574  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 09:22:29 | 6100 | LR0.0003 | logitMin:-2.3077 | logitMax:2.0513 | scheduledSampling:0.0000 | lossTUTOR:1.6348 | windowWeightsW2:2.22958 (0.57),W4:1.94426 (0.43),W8:-1.86492 (0.01),W12:-6.49237 (0.00),W16:-8.95601 (0.00),W20:-10.49103 (0.00),W24:-11.28013 (0.00),W32:-11.46661 (0.00),W28:-11.84350 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10805 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 5746), ('.', 3638), ('i', 3627), ('the', 2952), ('!', 2678), ('you', 2170), ('it', 1875), ('to', 1727), ('?', 1642), ('a', 1624)] | avgLoss/100: 2969.64501953125 |  | blend:0.574  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 09:29:00 | 6200 | LR0.0003 | logitMin:-1.7715 | logitMax:1.4090 | scheduledSampling:0.0000 | lossTUTOR:1.0766 | windowWeightsW2:2.22950 (0.57),W4:1.94420 (0.43),W8:-1.86486 (0.01),W12:-6.49218 (0.00),W16:-8.95572 (0.00),W20:-10.49074 (0.00),W24:-11.27975 (0.00),W32:-11.46622 (0.00),W28:-11.84311 (0.00) | judgeBiasW32:-0.00406 (0.11),W2:-0.00406 (0.11),W4:-0.00406 (0.11),W8:-0.00406 (0.11),W12:-0.00406 (0.11),W16:-0.00406 (0.11),W20:-0.00406 (0.11),W24:-0.00406 (0.11),W28:-0.00406 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 5862), ('.', 3698), ('i', 3629), ('the', 2984), ('!', 2678), ('you', 2171), ('it', 1884), ('to', 1733), ('?', 1642), ('a', 1625)] | avgLoss/100: 3097.455322265625 |  | blend:0.574  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 09:35:31 | 6300 | LR0.0003 | logitMin:-3.5612 | logitMax:1.0597 | scheduledSampling:0.0000 | lossTUTOR:0.9301 | windowWeightsW2:2.22943 (0.57),W4:1.94414 (0.43),W8:-1.86480 (0.01),W12:-6.49199 (0.00),W16:-8.95543 (0.00),W20:-10.49046 (0.00),W24:-11.27936 (0.00),W32:-11.46584 (0.00),W28:-11.84273 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 5994), ('.', 3742), ('i', 3733), ('the', 3070), ('!', 2792), ('you', 2186), ('it', 1887), ('to', 1797), ('?', 1652), ('a', 1634)] | avgLoss/100: 3069.654052734375 |  | blend:0.574  W28:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 100
2025-04-16 09:42:05 | 6400 | LR0.0003 | logitMin:-2.0248 | logitMax:1.4697 | scheduledSampling:0.0000 | lossTUTOR:1.4163 | windowWeightsW2:2.22936 (0.57),W4:1.94408 (0.43),W8:-1.86474 (0.01),W12:-6.49180 (0.00),W16:-8.95515 (0.00),W20:-10.49017 (0.00),W24:-11.27898 (0.00),W32:-11.46546 (0.00),W28:-11.84235 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 6074), ('.', 3778), ('i', 3760), ('the', 3070), ('!', 2871), ('you', 2204), ('it', 1887), ('to', 1811), ('and', 1700), ('?', 1652)] | avgLoss/100: 2960.557861328125 |  | blend:0.574  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 09:50:36 | 6500 | LR0.0003 | logitMin:-4.2148 | logitMax:1.5765 | scheduledSampling:0.0000 | lossTUTOR:1.0914 | windowWeightsW2:2.22929 (0.57),W4:1.94402 (0.43),W8:-1.86468 (0.01),W12:-6.49161 (0.00),W16:-8.95486 (0.00),W20:-10.48989 (0.00),W24:-11.27860 (0.00),W32:-11.46508 (0.00),W28:-11.84197 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 6227), ('.', 3833), ('i', 3762), ('the', 3088), ('!', 2898), ('you', 2214), ('it', 1951), ('to', 1831), ('and', 1730), ('a', 1673)] | avgLoss/100: 3003.053955078125 |  | blend:0.574  W24:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 100
2025-04-16 09:57:12 | 6600 | LR0.0003 | logitMin:-2.4162 | logitMax:2.3545 | scheduledSampling:0.0000 | lossTUTOR:2.6004 | windowWeightsW2:2.22922 (0.57),W4:1.94396 (0.43),W8:-1.86462 (0.01),W12:-6.49142 (0.00),W16:-8.95457 (0.00),W20:-10.48960 (0.00),W24:-11.27822 (0.00),W32:-11.46470 (0.00),W28:-11.84159 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 6234), ('.', 3862), ('i', 3770), ('the', 3108), ('!', 2928), ('you', 2255), ('it', 2058), ('to', 1858), ('and', 1754), ('a', 1711)] | avgLoss/100: 3069.717529296875 |  | blend:0.574  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 10:03:45 | 6700 | LR0.0003 | logitMin:-2.2136 | logitMax:1.7379 | scheduledSampling:0.0000 | lossTUTOR:1.5474 | windowWeightsW2:2.22915 (0.57),W4:1.94390 (0.43),W8:-1.86456 (0.01),W12:-6.49123 (0.00),W16:-8.95429 (0.00),W20:-10.48931 (0.00),W24:-11.27784 (0.00),W32:-11.46432 (0.00),W28:-11.84121 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 6301), ('.', 3934), ('i', 3770), ('the', 3219), ('!', 2986), ('you', 2270), ('it', 2103), ('to', 1858), ('a', 1803), ('and', 1776)] | avgLoss/100: 3674.24755859375 |  | blend:0.574  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 10:10:20 | 6800 | LR0.0003 | logitMin:-1.7894 | logitMax:1.4959 | scheduledSampling:0.0000 | lossTUTOR:0.6389 | windowWeightsW2:2.22908 (0.57),W4:1.94384 (0.43),W8:-1.86450 (0.01),W12:-6.49104 (0.00),W16:-8.95400 (0.00),W20:-10.48903 (0.00),W24:-11.27746 (0.00),W32:-11.46394 (0.00),W28:-11.84083 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 6324), ('.', 4080), ('i', 3770), ('the', 3228), ('!', 3004), ('you', 2294), ('it', 2118), ('to', 1928), ('a', 1824), ('and', 1805)] | avgLoss/100: 2050.195556640625 |  | blend:0.574  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 10:16:55 | 6900 | LR0.0003 | logitMin:-2.5447 | logitMax:1.5994 | scheduledSampling:0.0000 | lossTUTOR:2.3659 | windowWeightsW2:2.22900 (0.57),W4:1.94378 (0.43),W8:-1.86444 (0.01),W12:-6.49085 (0.00),W16:-8.95372 (0.00),W20:-10.48874 (0.00),W24:-11.27708 (0.00),W32:-11.46355 (0.00),W28:-11.84044 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 6499), ('.', 4130), ('i', 3771), ('the', 3228), ('!', 3012), ('you', 2302), ('it', 2118), ('to', 1982), ('and', 1886), ('a', 1837)] | avgLoss/100: 2611.525390625 |  | blend:0.574  W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 10:23:36 | 7000 | LR0.0003 | logitMin:-0.7981 | logitMax:0.1293 | scheduledSampling:0.0000 | lossTUTOR:0.4377 | windowWeightsW2:2.22893 (0.57),W4:1.94372 (0.43),W8:-1.86438 (0.01),W12:-6.49065 (0.00),W16:-8.95343 (0.00),W20:-10.48845 (0.00),W24:-11.27669 (0.00),W32:-11.46317 (0.00),W28:-11.84006 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 6502), ('.', 4293), ('i', 3772), ('the', 3243), ('!', 3012), ('you', 2307), ('it', 2118), ('to', 2003), ('and', 1913), ('a', 1847)] | avgLoss/100: 3081.051513671875 |  | blend:0.574  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100
2025-04-16 10:30:20 | 7100 | LR0.0003 | logitMin:-2.3402 | logitMax:2.9339 | scheduledSampling:0.0000 | lossTUTOR:2.3209 | windowWeightsW2:2.22886 (0.57),W4:1.94366 (0.43),W8:-1.86433 (0.01),W12:-6.49046 (0.00),W16:-8.95314 (0.00),W20:-10.48817 (0.00),W24:-11.27631 (0.00),W32:-11.46279 (0.00),W28:-11.83968 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10955 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[(',', 6509), ('.', 4406), ('i', 3772), ('the', 3243), ('!', 3012), ('you', 2307), ('to', 2230), ('it', 2118), ('and', 1915), ('?', 1881)] | avgLoss/100: 3554.66845703125 |  | blend:0.574  W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 100

--- 2025-04-16 10:38:17 --- babyLLM 'right, last time i got to step 622... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 622! what am i learning today?' - charis: ''

--- 2025-04-16 10:40:27 --- babyLLM 'right, last time i got to step 623... want to restart from there?'  - charis: '9000' - babyLLM 'damn that's specific! heading to step 9000... what am i learning today?' - charis: ''
2025-04-16 10:46:39 | 100 | LR0.0003 | logitMin:-3.2560 | logitMax:3.0889 | scheduledSampling:0.0000 | lossTUTOR:1.9327 | windowWeightsW2:2.20767 (0.56),W4:1.96410 (0.44),W8:-1.84608 (0.01),W12:-6.46893 (0.00),W16:-8.93407 (0.00),W20:-10.47217 (0.00),W24:-11.26170 (0.00),W32:-11.44907 (0.00),W28:-11.82778 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[('to', 101), ('.', 100), ('?', 95), ('listening', 91), ('music', 77), ('he', 73), ('what', 72), ('has', 59), ('-', 51), ('will', 50)] | avgLoss/100: 168.92631759643555 |  | entropyBonus: 0.7345383167266846 blend: 0.298 top windows: W2:0.56,W4:0.44,W8:0.01,W12:0.00 | TUTOR.py 100

--- 2025-04-16 10:47:18 --- babyLLM 'right, last time i got to step 9001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 9001! what am i learning today?' - charis: ''
2025-04-16 10:53:54 | 100 | LR0.00035 | logitMin:-5.7143 | logitMax:5.4919 | scheduledSampling:0.0000 | lossTUTOR:2.5146 | windowWeightsW2:2.19335 (0.55),W4:1.97792 (0.44),W8:-1.82317 (0.01),W12:-6.44294 (0.00),W16:-8.91201 (0.00),W20:-10.45600 (0.00),W24:-11.25008 (0.00),W32:-11.43596 (0.00),W28:-11.81829 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[('want', 146), ('to', 135), ('he', 129), ('listening', 103), ('what', 94), ('.', 76), ('music', 69), ('?', 66), ('is', 56), ('cry', 42)] | avgLoss/100: 141.82825714588165 |  | entropyBonus: 0.7370505332946777 blend: 0.298 top windows: W2:0.55,W4:0.44,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-16 11:00:37 | 200 | LR0.00035 | logitMin:-4.8183 | logitMax:2.3030 | scheduledSampling:0.0000 | lossTUTOR:2.8896 | windowWeightsW2:2.18433 (0.54),W4:1.98658 (0.45),W8:-1.81024 (0.01),W12:-6.43054 (0.00),W16:-8.90042 (0.00),W20:-10.44658 (0.00),W24:-11.24233 (0.00),W32:-11.42882 (0.00),W28:-11.81324 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[('listening', 354), ('to', 349), ('.', 250), ('tri', 202), ('will', 159), ('want', 146), ('he', 129), ('?', 127), ('what', 114), ('of', 101)] | avgLoss/100: 358.7376718139648 |  | entropyBonus: 0.7385289669036865 blend: 0.298 top windows: W2:0.54,W4:0.45,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-16 11:07:24 | 300 | LR0.00035 | logitMin:-8.8888 | logitMax:5.0790 | scheduledSampling:0.0000 | lossTUTOR:3.7774 | windowWeightsW2:2.17605 (0.54),W4:1.99448 (0.45),W8:-1.79730 (0.01),W12:-6.41538 (0.00),W16:-8.88807 (0.00),W20:-10.43604 (0.00),W24:-11.23402 (0.00),W32:-11.42134 (0.00),W28:-11.80756 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[('to', 404), ('listening', 354), ('.', 272), ('tri', 202), ('?', 192), ('will', 167), ('want', 146), ('he', 129), ('am', 117), ('what', 115)] | avgLoss/100: 325.7693000793457 |  | entropyBonus: 0.7398313283920288 blend: 0.298 top windows: W2:0.54,W4:0.45,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-16 11:14:07 | 400 | LR0.00035 | logitMin:-4.8173 | logitMax:2.6607 | scheduledSampling:0.0000 | lossTUTOR:1.6499 | windowWeightsW2:2.15939 (0.53),W4:2.01046 (0.46),W8:-1.77007 (0.01),W12:-6.39134 (0.00),W16:-8.86633 (0.00),W20:-10.41793 (0.00),W24:-11.22093 (0.00),W32:-11.40975 (0.00),W28:-11.79782 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[('to', 446), ('listening', 360), ('.', 299), ('tri', 202), ('?', 200), ('will', 167), ('want', 148), ('what', 138), (',', 137), ('he', 135)] | avgLoss/100: 262.7555755615234 |  | entropyBonus: 0.7423170208930969 blend: 0.298 top windows: W2:0.53,W4:0.46,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-16 11:21:01 | 500 | LR0.00035 | logitMin:-5.6778 | logitMax:3.3418 | scheduledSampling:0.0000 | lossTUTOR:2.4743 | windowWeightsW2:2.14934 (0.53),W4:2.01965 (0.46),W8:-1.74329 (0.01),W12:-6.36373 (0.00),W16:-8.84072 (0.00),W20:-10.39914 (0.00),W24:-11.20840 (0.00),W32:-11.39739 (0.00),W28:-11.78834 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[('to', 467), ('listening', 360), ('.', 322), ('?', 204), ('tri', 202), ('will', 167), ('want', 159), (',', 144), ('what', 138), ('he', 135)] | avgLoss/100: 280.94991065979 |  | entropyBonus: 0.7441260814666748 blend: 0.298 top windows: W2:0.53,W4:0.46,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-16 11:28:34 | 600 | LR0.00035 | logitMin:-4.9062 | logitMax:2.4534 | scheduledSampling:0.0000 | lossTUTOR:1.8710 | windowWeightsW2:2.13779 (0.52),W4:2.03008 (0.47),W8:-1.71292 (0.01),W12:-6.33364 (0.00),W16:-8.81756 (0.00),W20:-10.38149 (0.00),W24:-11.19506 (0.00),W32:-11.38576 (0.00),W28:-11.77911 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[('to', 576), ('listening', 360), ('.', 338), (',', 253), ('?', 217), ('tri', 202), ('the', 185), ('will', 167), ('want', 166), ('be', 146)] | avgLoss/100: 221.2803028869629 |  | entropyBonus: 0.7461040616035461 blend: 0.298 top windows: W2:0.52,W4:0.47,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-16 11:37:17 | 700 | LR0.00035 | logitMin:-3.6796 | logitMax:3.6634 | scheduledSampling:0.0000 | lossTUTOR:2.3614 | windowWeightsW2:2.11390 (0.51),W4:2.05339 (0.48),W8:-1.68932 (0.01),W12:-6.30785 (0.00),W16:-8.79318 (0.00),W20:-10.36320 (0.00),W24:-11.18151 (0.00),W32:-11.37259 (0.00),W28:-11.76884 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[('to', 591), (',', 474), ('listening', 364), ('.', 349), ('?', 217), ('tri', 202), ('the', 199), ('a', 174), ('will', 168), ('want', 166)] | avgLoss/100: 250.3808000946045 |  | entropyBonus: 0.7481745481491089 blend: 0.298 top windows: W2:0.51,W4:0.48,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-16 11:45:29 | 800 | LR0.00035 | logitMin:-8.8503 | logitMax:5.1740 | scheduledSampling:0.0000 | lossTUTOR:3.3745 | windowWeightsW2:2.10310 (0.50),W4:2.06337 (0.48),W8:-1.66710 (0.01),W12:-6.28565 (0.00),W16:-8.77047 (0.00),W20:-10.34733 (0.00),W24:-11.17018 (0.00),W32:-11.36260 (0.00),W28:-11.76086 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[('to', 604), (',', 543), ('.', 418), ('listening', 368), ('a', 230), ('the', 221), ('and', 220), ('?', 217), ('be', 214), ('tri', 202)] | avgLoss/100: 286.1544709777832 |  | entropyBonus: 0.7494276165962219 blend: 0.298 top windows: W2:0.50,W4:0.48,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-16 11:54:43 | 900 | LR0.00035 | logitMin:-2.7389 | logitMax:2.3335 | scheduledSampling:0.0000 | lossTUTOR:2.8746 | windowWeightsW2:2.09064 (0.50),W4:2.07491 (0.49),W8:-1.64136 (0.01),W12:-6.25752 (0.00),W16:-8.74619 (0.00),W20:-10.32759 (0.00),W24:-11.15609 (0.00),W32:-11.34889 (0.00),W28:-11.75077 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[('to', 625), (',', 551), ('.', 419), ('listening', 368), ('the', 360), ('and', 319), ('a', 260), ('in', 253), ('be', 218), ('?', 217)] | avgLoss/100: 389.2689746856689 |  | entropyBonus: 0.750774621963501 blend: 0.298 top windows: W2:0.50,W4:0.49,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-16 12:05:10 | 1000 | LR0.00035 | logitMin:-2.1888 | logitMax:1.5892 | scheduledSampling:0.0000 | lossTUTOR:0.8048 | windowWeightsW4:2.08878 (0.50),W2:2.07613 (0.49),W8:-1.62073 (0.01),W12:-6.23619 (0.00),W16:-8.72479 (0.00),W20:-10.31180 (0.00),W24:-11.14487 (0.00),W32:-11.33964 (0.00),W28:-11.74243 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[('to', 628), (',', 552), ('the', 480), ('.', 462), ('and', 387), ('listening', 368), ('es', 311), ('in', 300), ('a', 281), ('o', 229)] | avgLoss/100: 323.89264808654787 |  | entropyBonus: 0.7517342567443848 blend: 0.298 top windows: W4:0.50,W2:0.49,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-16 12:11:48 | 1100 | LR0.00035 | logitMin:-3.9676 | logitMax:2.5402 | scheduledSampling:0.0000 | lossTUTOR:2.5701 | windowWeightsW4:2.09862 (0.50),W2:2.06549 (0.49),W8:-1.59914 (0.01),W12:-6.21437 (0.00),W16:-8.70255 (0.00),W20:-10.29506 (0.00),W24:-11.13380 (0.00),W32:-11.32894 (0.00),W28:-11.73395 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[('to', 680), ('the', 593), (',', 552), ('.', 539), ('and', 387), ('listening', 368), ('es', 324), ('a', 310), ('in', 300), ('o', 229)] | avgLoss/100: 288.0549543762207 |  | entropyBonus: 0.7526295185089111 blend: 0.298 top windows: W4:0.50,W2:0.49,W8:0.01,W12:0.00 | TUTOR.py 100
2025-04-16 12:18:22 | 1200 | LR0.00035 | logitMin:-5.0525 | logitMax:3.4263 | scheduledSampling:0.0000 | lossTUTOR:1.7904 | windowWeightsW4:2.10833 (0.51),W2:2.05496 (0.48),W8:-1.57769 (0.01),W12:-6.19075 (0.00),W16:-8.67982 (0.00),W20:-10.27957 (0.00),W24:-11.12233 (0.00),W32:-11.31787 (0.00),W28:-11.72576 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[('to', 696), ('the', 684), ('.', 584), (',', 583), ('and', 387), ('es', 383), ('in', 369), ('listening', 368), ('a', 310), ('i', 289)] | avgLoss/100: 327.6721408081055 |  | entropyBonus: 0.7534111738204956 blend: 0.298 top windows: W4:0.51,W2:0.48,W8:0.01,W12:0.00 | TUTOR.py 100

--- 2025-04-16 12:27:24 --- babyLLM 'right, last time i got to step 9002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 9002! what am i learning today?' - charis: ''

--- 2025-04-16 12:29:42 --- babyLLM 'right, last time i got to step 9003... want to restart from there?'  - charis: '12000' - babyLLM 'damn that's specific! heading to step 12000... what am i learning today?' - charis: ''
2025-04-16 12:36:25 | 100 | LR0.00035 | logitMin:-6.6909 | logitMax:3.9581 | scheduledSampling:0.0000 | lossTUTOR:2.8612 | windowWeightsW4:2.12225 (0.51),W2:2.03822 (0.47),W8:-1.52951 (0.01),W12:-6.14104 (0.00),W16:-8.63102 (0.00),W20:-10.24006 (0.00),W24:-11.09139 (0.00),W32:-11.28990 (0.00),W28:-11.70146 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[('?', 155), ('ke', 155), ('a', 152), ('.', 121), ('for', 76), ('yourself', 73), ('is', 56), ('thinking', 53), ('bro', 41), ('you', 40)] | avgLoss/100: 276.1887480926514 |  | entropyBonus: 0.7552709579467773 blend: 0.298 top windows: W4:0.51,W2:0.47,W8:0.01,W12:0.00 | TUTOR.py 100

--- 2025-04-16 12:44:46 --- babyLLM 'right, last time i got to step 12001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12001! what am i learning today?' - charis: ''

--- 2025-04-16 12:46:07 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:23:37 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:24:44 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:26:07 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:28:04 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:30:11 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:31:39 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:34:46 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:38:19 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:41:52 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:43:34 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''
2025-04-16 14:44:21 | 100 | LR0.00035 | logitMin:-1.2538 | logitMax:-0.2493 | scheduledSampling:0.0000 | lossTUTOR:0.1219 | topTokens[('me', 203), ('about', 148), ('?', 125), ('you', 90), ('your', 79), ('.', 72), ('are', 59), ('i', 53), (',', 52), ('my', 39)] | avgLoss/100: 17.309098377227784 |  |  | TUTOR.py 100
2025-04-16 14:45:09 | 200 | LR0.00035 | logitMin:-1.2860 | logitMax:-0.2769 | scheduledSampling:0.0000 | lossTUTOR:0.1627 | topTokens[('me', 664), ('?', 303), ('you', 211), ('about', 189), ('your', 162), ('.', 143), ('what', 136), ('are', 114), (',', 74), ('i', 68)] | avgLoss/100: 14.820198106765748 |  |  | TUTOR.py 100
2025-04-16 14:45:57 | 300 | LR0.00035 | logitMin:-1.2568 | logitMax:-0.2777 | scheduledSampling:0.0000 | lossTUTOR:0.0876 | topTokens[('what', 1051), ('me', 696), ('?', 500), ('you', 333), ('your', 325), ('are', 218), ('about', 194), ('.', 148), (',', 82), ('i', 71)] | avgLoss/100: 20.04149857521057 |  |  | TUTOR.py 100
2025-04-16 14:46:45 | 400 | LR0.00035 | logitMin:-1.2530 | logitMax:-0.2903 | scheduledSampling:0.0000 | lossTUTOR:0.1298 | topTokens[('what', 1397), ('me', 758), ('?', 730), ('you', 473), ('your', 418), ('are', 328), ('about', 199), ('.', 172), ('at', 119), ('i', 109)] | avgLoss/100: 2160.7630902957917 |  |  | TUTOR.py 100
2025-04-16 14:47:37 | 500 | LR0.00035 | logitMin:-1.2748 | logitMax:-0.2515 | scheduledSampling:0.0000 | lossTUTOR:0.1257 | topTokens[('what', 1506), ('me', 806), ('?', 773), ('you', 636), ('to', 469), ('your', 434), ('are', 342), ('.', 208), ('about', 206), ('i', 204)] | avgLoss/100: 27.840539960861207 |  |  | TUTOR.py 100
2025-04-16 14:48:26 | 600 | LR0.00035 | logitMin:-1.2911 | logitMax:-0.1710 | scheduledSampling:0.0000 | lossTUTOR:0.3578 | topTokens[('to', 1800), ('what', 1550), ('me', 813), ('?', 783), ('you', 739), ('your', 440), ('are', 350), ('.', 209), ('about', 207), ('i', 204)] | avgLoss/100: 28.76221106529236 |  |  | TUTOR.py 100
2025-04-16 14:49:16 | 700 | LR0.00035 | logitMin:-1.2610 | logitMax:-0.2475 | scheduledSampling:0.0000 | lossTUTOR:0.1376 | topTokens[('to', 2978), ('what', 1566), ('you', 910), ('me', 815), ('?', 785), ('your', 446), ('are', 351), ('i', 213), ('.', 212), ('about', 209)] | avgLoss/100: 21.677163772583008 |  |  | TUTOR.py 100
2025-04-16 14:50:06 | 800 | LR0.00035 | logitMin:-1.2577 | logitMax:-0.3009 | scheduledSampling:0.0000 | lossTUTOR:0.1000 | topTokens[('to', 3422), ('what', 1629), ('you', 1049), ('me', 836), ('?', 830), ('your', 456), ('are', 367), ('.', 254), ('i', 234), ('about', 220)] | avgLoss/100: 17.834493026733398 |  |  | TUTOR.py 100

--- 2025-04-16 15:10:31 --- babyLLM 'right, last time i got to step 12003... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12003! what am i learning today?' - charis: ''
2025-04-16 15:11:39 | 100 | LR0.00035 | logitMin:-1.2852 | logitMax:-0.2549 | scheduledSampling:0.0000 | lossTUTOR:0.1161 | topTokens[('you', 444), ('!', 119), ('me', 82), ('to', 81), ('.', 73), ('?', 68), ('what', 54), ('are', 45), ('will', 42), ('when', 41)] | avgLoss/100: 16.745239849090577 |  |  | TUTOR.py 100
2025-04-16 15:12:49 | 200 | LR0.00035 | logitMin:-1.3012 | logitMax:-0.0271 | scheduledSampling:0.0000 | lossTUTOR:0.4060 | topTokens[('you', 1272), ('to', 154), ('!', 135), ('me', 105), ('your', 89), ('?', 87), ('are', 84), ('.', 82), ('was', 69), ('will', 67)] | avgLoss/100: 22.17236277580261 |  |  | TUTOR.py 100
2025-04-16 15:13:59 | 300 | LR0.00035 | logitMin:-1.2611 | logitMax:-0.0444 | scheduledSampling:0.0000 | lossTUTOR:0.3214 | topTokens[('you', 2715), ('!', 157), ('to', 156), ('me', 107), ('your', 95), ('are', 91), ('?', 87), ('.', 85), ('was', 72), ('what', 72)] | avgLoss/100: 42.373419542312625 |  |  | TUTOR.py 100

--- 2025-04-16 15:15:17 --- babyLLM 'right, last time i got to step 12004... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12004! what am i learning today?' - charis: ''
2025-04-16 15:16:23 | 100 | LR0.00035 | logitMin:-1.2743 | logitMax:-0.3270 | scheduledSampling:0.0000 | lossTUTOR:0.0787 | topTokens[('you', 650), ('.', 118), (',', 93), ('?', 92), ('is', 67), ('about', 59), ('!', 52), ('ke', 50), ('what', 42), ('me', 40)] | avgLoss/100: 17.241574263572694 |  |  | TUTOR.py 100

--- 2025-04-16 15:20:14 --- babyLLM 'right, last time i got to step 12005... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12005! what am i learning today?' - charis: ''
2025-04-16 15:20:57 | 100 | LR0.00035 | logitMin:-1.2679 | logitMax:-0.3639 | scheduledSampling:0.0000 | lossTUTOR:0.0483 | topTokens[('.', 182), ('?', 131), ('is', 111), (',', 95), ('bro', 88), ('a', 85), ('ke', 84), ('you', 69), ('me', 63), ('dont', 58)] | avgLoss/100: 8.208322114944458 |  |  | TUTOR.py 100
2025-04-16 15:21:42 | 200 | LR0.00035 | logitMin:-1.2684 | logitMax:-0.3900 | scheduledSampling:0.0000 | lossTUTOR:0.0789 | topTokens[('.', 322), ('?', 255), ('you', 192), ('is', 170), ('to', 146), ('looking', 139), ('i', 131), ('a', 123), (',', 118), ('at', 112)] | avgLoss/100: 5.562021911144257 |  |  | TUTOR.py 100
2025-04-16 15:22:28 | 300 | LR0.00035 | logitMin:-1.2600 | logitMax:-0.3855 | scheduledSampling:0.0000 | lossTUTOR:0.0598 | topTokens[('you', 452), ('.', 444), ('?', 376), ('is', 290), ('i', 278), ('a', 239), ('to', 221), (',', 174), ('looking', 153), ('about', 137)] | avgLoss/100: 10.113026428222657 |  |  | TUTOR.py 100
2025-04-16 15:23:14 | 400 | LR0.00035 | logitMin:-1.2621 | logitMax:-0.3506 | scheduledSampling:0.0000 | lossTUTOR:0.1361 | topTokens[('you', 1393), ('.', 551), ('?', 452), ('i', 353), ('is', 335), ('a', 269), ('to', 243), (',', 193), ('looking', 162), ('at', 159)] | avgLoss/100: 8.10356252670288 |  |  | TUTOR.py 100
2025-04-16 15:24:03 | 500 | LR0.00035 | logitMin:-1.2590 | logitMax:-0.1639 | scheduledSampling:0.0000 | lossTUTOR:0.2436 | topTokens[('you', 3189), ('.', 551), ('?', 452), ('i', 353), ('is', 335), ('a', 269), ('to', 243), (',', 193), ('looking', 162), ('at', 159)] | avgLoss/100: 21.456893339157105 |  |  | TUTOR.py 100
2025-04-16 15:24:49 | 600 | LR0.00035 | logitMin:-1.2637 | logitMax:0.0426 | scheduledSampling:0.0000 | lossTUTOR:0.4546 | topTokens[('you', 4989), ('.', 551), ('?', 452), ('i', 353), ('is', 335), ('a', 269), ('to', 243), (',', 193), ('looking', 162), ('at', 159)] | avgLoss/100: 40.25680597305298 |  |  | TUTOR.py 100
2025-04-16 15:25:35 | 700 | LR0.00035 | logitMin:-1.2655 | logitMax:0.2235 | scheduledSampling:0.0000 | lossTUTOR:0.6149 | topTokens[('you', 6789), ('.', 551), ('?', 452), ('i', 353), ('is', 335), ('a', 269), ('to', 243), (',', 193), ('looking', 162), ('at', 159)] | avgLoss/100: 56.08957656860352 |  |  | TUTOR.py 100
2025-04-16 15:26:19 | 800 | LR0.00035 | logitMin:-1.2733 | logitMax:0.3676 | scheduledSampling:0.0000 | lossTUTOR:0.5762 | topTokens[('you', 8589), ('.', 551), ('?', 452), ('i', 353), ('is', 335), ('a', 269), ('to', 243), (',', 193), ('looking', 162), ('at', 159)] | avgLoss/100: 67.10637386322021 |  |  | TUTOR.py 100
2025-04-16 15:27:06 | 900 | LR0.00035 | logitMin:-1.2839 | logitMax:0.5406 | scheduledSampling:0.0000 | lossTUTOR:0.8819 | topTokens[('you', 10389), ('.', 551), ('?', 452), ('i', 353), ('is', 335), ('a', 269), ('to', 243), (',', 193), ('looking', 162), ('at', 159)] | avgLoss/100: 76.04996078491212 |  |  | TUTOR.py 100
2025-04-16 15:27:55 | 1000 | LR0.00035 | logitMin:-1.2460 | logitMax:-0.2836 | scheduledSampling:0.0000 | lossTUTOR:0.1792 | topTokens[('you', 12171), ('.', 551), ('?', 452), ('i', 353), ('is', 335), ('a', 269), ('to', 243), (',', 193), ('looking', 162), ('at', 159)] | avgLoss/100: 84.20425397872924 |  |  | TUTOR.py 100
2025-04-16 15:28:42 | 1100 | LR0.00035 | logitMin:-1.3067 | logitMax:0.7045 | scheduledSampling:0.0000 | lossTUTOR:0.9292 | topTokens[('you', 13971), ('.', 551), ('?', 452), ('i', 353), ('is', 335), ('a', 269), ('to', 243), (',', 193), ('looking', 162), ('at', 159)] | avgLoss/100: 91.07002750396728 |  |  | TUTOR.py 100
2025-04-16 15:29:29 | 1200 | LR0.00035 | logitMin:-1.3293 | logitMax:0.7106 | scheduledSampling:0.0000 | lossTUTOR:1.0020 | topTokens[('you', 15771), ('.', 551), ('?', 452), ('i', 353), ('is', 335), ('a', 269), ('to', 243), (',', 193), ('looking', 162), ('at', 159)] | avgLoss/100: 95.07303855895996 |  |  | TUTOR.py 100
2025-04-16 15:30:15 | 1300 | LR0.00035 | logitMin:-1.3361 | logitMax:0.7746 | scheduledSampling:0.0000 | lossTUTOR:0.8684 | topTokens[('you', 17571), ('.', 551), ('?', 452), ('i', 353), ('is', 335), ('a', 269), ('to', 243), (',', 193), ('looking', 162), ('at', 159)] | avgLoss/100: 91.28305213928223 |  |  | TUTOR.py 100
2025-04-16 15:31:02 | 1400 | LR0.00035 | logitMin:-1.3480 | logitMax:0.7483 | scheduledSampling:0.0000 | lossTUTOR:0.8321 | topTokens[('you', 19371), ('.', 551), ('?', 452), ('i', 353), ('is', 335), ('a', 269), ('to', 243), (',', 193), ('looking', 162), ('at', 159)] | avgLoss/100: 84.73123252868652 |  |  | TUTOR.py 100
2025-04-16 15:31:52 | 1500 | LR0.00035 | logitMin:-1.3501 | logitMax:0.6992 | scheduledSampling:0.0000 | lossTUTOR:0.7348 | topTokens[('you', 20955), ('.', 551), ('?', 452), (',', 409), ('i', 353), ('is', 335), ('a', 269), ('to', 243), ('looking', 162), ('at', 159)] | avgLoss/100: 74.98491870880127 |  |  | TUTOR.py 100
2025-04-16 15:32:39 | 1600 | LR0.00035 | logitMin:-1.3503 | logitMax:0.6780 | scheduledSampling:0.0000 | lossTUTOR:0.6932 | topTokens[('you', 22336), (',', 622), ('.', 582), ('?', 452), ('a', 444), ('i', 353), ('is', 335), ('to', 243), ('looking', 162), ('at', 159)] | avgLoss/100: 69.90179302215576 |  |  | TUTOR.py 100
2025-04-16 15:33:25 | 1700 | LR0.00035 | logitMin:-1.3761 | logitMax:0.7953 | scheduledSampling:0.0000 | lossTUTOR:0.7954 | topTokens[('you', 22883), ('a', 1433), (',', 810), ('.', 657), ('?', 452), ('i', 353), ('is', 335), ('to', 243), ('looking', 162), ('at', 159)] | avgLoss/100: 66.55559505462647 |  |  | TUTOR.py 100
2025-04-16 15:34:11 | 1800 | LR0.00035 | logitMin:-1.4155 | logitMax:1.3333 | scheduledSampling:0.0000 | lossTUTOR:1.2349 | topTokens[('you', 22883), ('a', 3233), (',', 810), ('.', 657), ('?', 452), ('i', 353), ('is', 335), ('to', 243), ('looking', 162), ('at', 159)] | avgLoss/100: 99.76361167907714 |  |  | TUTOR.py 100
2025-04-16 15:34:56 | 1900 | LR0.00035 | logitMin:-1.3705 | logitMax:0.9394 | scheduledSampling:0.0000 | lossTUTOR:0.8583 | topTokens[('you', 22894), ('a', 4317), (',', 869), ('.', 701), ('?', 458), ('i', 353), ('is', 340), ('to', 274), ('at', 164), ('about', 163)] | avgLoss/100: 87.87061769485473 |  |  | TUTOR.py 100
2025-04-16 15:35:46 | 2000 | LR0.00035 | logitMin:-15.0799 | logitMax:0.6785 | scheduledSampling:0.0000 | lossTUTOR:2.9485 | topTokens[('you', 22894), ('a', 6040), (',', 882), ('.', 709), ('?', 458), ('i', 353), ('is', 340), ('to', 274), ('at', 164), ('about', 163)] | avgLoss/100: 170.4679062652588 |  |  | TUTOR.py 100
2025-04-16 15:36:32 | 2100 | LR0.00035 | logitMin:-1.4419 | logitMax:2.0783 | scheduledSampling:0.0000 | lossTUTOR:1.8990 | topTokens[('you', 22894), ('a', 7476), (',', 908), ('.', 737), ('?', 461), ('i', 353), ('is', 345), ('to', 280), ('at', 165), ('was', 164)] | avgLoss/100: 140.75262594223022 |  |  | TUTOR.py 100
2025-04-16 15:37:18 | 2200 | LR0.00035 | logitMin:-1.4270 | logitMax:1.7498 | scheduledSampling:0.0000 | lossTUTOR:1.4516 | topTokens[('you', 22894), ('a', 9276), (',', 908), ('.', 737), ('?', 461), ('i', 353), ('is', 345), ('to', 280), ('at', 165), ('was', 164)] | avgLoss/100: 169.3606558227539 |  |  | TUTOR.py 100
2025-04-16 15:38:04 | 2300 | LR0.00035 | logitMin:-1.4326 | logitMax:1.5405 | scheduledSampling:0.0000 | lossTUTOR:1.4111 | topTokens[('you', 22894), ('a', 10948), (',', 949), ('.', 742), ('?', 461), ('i', 353), ('is', 345), ('to', 283), ('at', 170), ('was', 168)] | avgLoss/100: 152.5774994659424 |  |  | TUTOR.py 100
2025-04-16 15:38:50 | 2400 | LR0.00035 | logitMin:-1.4340 | logitMax:1.3342 | scheduledSampling:0.0000 | lossTUTOR:1.1040 | topTokens[('you', 22894), ('a', 12748), (',', 949), ('.', 742), ('?', 461), ('i', 353), ('is', 345), ('to', 283), ('at', 170), ('was', 168)] | avgLoss/100: 128.35637382507323 |  |  | TUTOR.py 100
2025-04-16 15:39:39 | 2500 | LR0.00035 | logitMin:-1.4193 | logitMax:1.0451 | scheduledSampling:0.0000 | lossTUTOR:1.0709 | topTokens[('you', 22894), ('a', 14289), (',', 1143), ('.', 807), ('?', 461), ('i', 353), ('is', 345), ('to', 283), ('at', 170), ('was', 168)] | avgLoss/100: 112.58477241516113 |  |  | TUTOR.py 100
2025-04-16 15:40:26 | 2600 | LR0.00035 | logitMin:-1.4235 | logitMax:0.8173 | scheduledSampling:0.0000 | lossTUTOR:0.9832 | topTokens[('you', 22894), ('a', 15742), (',', 1373), ('.', 890), ('?', 461), ('i', 353), ('is', 345), ('to', 283), ('at', 170), ('was', 168)] | avgLoss/100: 105.21798904418945 |  |  | TUTOR.py 100
2025-04-16 15:41:12 | 2700 | LR0.00035 | logitMin:-1.4317 | logitMax:0.7763 | scheduledSampling:0.0000 | lossTUTOR:0.6893 | topTokens[('you', 22894), ('a', 17134), (',', 1570), ('.', 961), ('?', 461), ('i', 353), ('is', 345), ('to', 283), ('at', 170), ('was', 168)] | avgLoss/100: 79.1448713684082 |  |  | TUTOR.py 100
2025-04-16 15:41:59 | 2800 | LR0.00035 | logitMin:-1.4254 | logitMax:0.6329 | scheduledSampling:0.0000 | lossTUTOR:0.6165 | topTokens[('you', 22894), ('a', 18138), (',', 1796), ('.', 1008), ('?', 461), ('i', 427), ('to', 349), ('is', 345), ('at', 170), ('was', 168)] | avgLoss/100: 66.81584510803222 |  |  | TUTOR.py 100
2025-04-16 15:42:46 | 2900 | LR0.00035 | logitMin:-1.4365 | logitMax:0.5543 | scheduledSampling:0.0000 | lossTUTOR:0.4547 | topTokens[('you', 22894), ('a', 18996), (',', 1992), ('.', 1042), ('i', 513), ('?', 461), ('to', 414), ('is', 383), ('the', 196), ('of', 194)] | avgLoss/100: 61.20919200897217 |  |  | TUTOR.py 100
2025-04-16 15:43:35 | 3000 | LR0.00035 | logitMin:-2.9873 | logitMax:-0.0859 | scheduledSampling:0.0000 | lossTUTOR:1.7743 | topTokens[('you', 22894), ('a', 19689), (',', 2145), ('.', 1074), ('i', 629), ('?', 476), ('to', 442), ('is', 420), ('the', 313), ('of', 244)] | avgLoss/100: 54.55966014862061 |  |  | TUTOR.py 100
2025-04-16 15:44:20 | 3100 | LR0.00035 | logitMin:-1.4248 | logitMax:0.3394 | scheduledSampling:0.0000 | lossTUTOR:0.4528 | topTokens[('you', 22894), ('a', 20272), (',', 2266), ('.', 1135), ('i', 697), ('?', 491), ('is', 489), ('to', 470), ('the', 383), ('and', 319)] | avgLoss/100: 45.49040538787842 |  |  | TUTOR.py 100
2025-04-16 15:45:06 | 3200 | LR0.00035 | logitMin:-1.4208 | logitMax:0.2761 | scheduledSampling:0.0000 | lossTUTOR:0.3644 | topTokens[('you', 22895), ('a', 20722), (',', 2437), ('.', 1161), ('i', 789), ('is', 552), ('to', 514), ('?', 502), ('the', 418), ('and', 382)] | avgLoss/100: 35.75379941940307 |  |  | TUTOR.py 100
2025-04-16 15:45:53 | 3300 | LR0.00035 | logitMin:-1.4243 | logitMax:0.2382 | scheduledSampling:0.0000 | lossTUTOR:0.3152 | topTokens[('you', 22922), ('a', 21076), (',', 2564), ('.', 1188), ('i', 855), ('is', 603), ('to', 552), ('?', 505), ('the', 448), ('and', 443)] | avgLoss/100: 34.966638584136966 |  |  | TUTOR.py 100
2025-04-16 15:46:40 | 3400 | LR0.00035 | logitMin:-1.4254 | logitMax:0.1826 | scheduledSampling:0.0000 | lossTUTOR:0.2447 | topTokens[('you', 22954), ('a', 21323), (',', 2675), ('.', 1223), ('i', 910), ('is', 623), ('to', 608), ('?', 514), ('and', 511), ('the', 497)] | avgLoss/100: 32.31570636749267 |  |  | TUTOR.py 100
2025-04-16 15:47:29 | 3500 | LR0.00035 | logitMin:-1.4299 | logitMax:0.1662 | scheduledSampling:0.0000 | lossTUTOR:0.4024 | topTokens[('you', 22970), ('a', 21531), (',', 2804), ('.', 1311), ('i', 970), ('is', 647), ('to', 621), ('and', 576), ('?', 515), ('the', 510)] | avgLoss/100: 26.423919882774353 |  |  | TUTOR.py 100
2025-04-16 15:48:16 | 3600 | LR0.00035 | logitMin:-1.4365 | logitMax:0.1504 | scheduledSampling:0.0000 | lossTUTOR:0.1784 | topTokens[('you', 23020), ('a', 21626), (',', 2966), ('.', 1346), ('i', 1095), ('is', 659), ('to', 641), ('and', 621), ('the', 587), ('?', 541)] | avgLoss/100: 21.96849437713623 |  |  | TUTOR.py 100
2025-04-16 15:49:03 | 3700 | LR0.00035 | logitMin:-1.4157 | logitMax:0.0376 | scheduledSampling:0.0000 | lossTUTOR:0.3136 | topTokens[('you', 23036), ('a', 21808), (',', 3088), ('.', 1362), ('i', 1152), ('is', 688), ('and', 662), ('to', 652), ('the', 643), ('?', 550)] | avgLoss/100: 26.462067012786864 |  |  | TUTOR.py 100
2025-04-16 15:49:49 | 3800 | LR0.00035 | logitMin:-1.4300 | logitMax:0.1019 | scheduledSampling:0.0000 | lossTUTOR:0.1028 | topTokens[('you', 23043), ('a', 21909), (',', 3186), ('.', 1387), ('i', 1282), ('is', 732), ('to', 723), ('and', 677), ('the', 675), ('?', 571)] | avgLoss/100: 18.32893838405609 |  |  | TUTOR.py 100
2025-04-16 15:50:35 | 3900 | LR0.00035 | logitMin:-1.4155 | logitMax:0.0335 | scheduledSampling:0.0000 | lossTUTOR:0.1972 | topTokens[('you', 23050), ('a', 22038), (',', 3294), ('.', 1423), ('i', 1376), ('to', 792), ('is', 759), ('and', 714), ('the', 705), ('?', 581)] | avgLoss/100: 21.033875064849852 |  |  | TUTOR.py 100
2025-04-16 15:51:25 | 4000 | LR0.00035 | logitMin:-3.6521 | logitMax:-0.1392 | scheduledSampling:0.0000 | lossTUTOR:1.5476 | topTokens[('you', 23060), ('a', 22094), (',', 3450), ('.', 1444), ('i', 1395), ('to', 857), ('is', 776), ('and', 769), ('the', 729), ('?', 583)] | avgLoss/100: 19.161390905380248 |  |  | TUTOR.py 100
2025-04-16 15:52:11 | 4100 | LR0.00035 | logitMin:-1.4297 | logitMax:0.0744 | scheduledSampling:0.0000 | lossTUTOR:0.1420 | topTokens[('you', 23065), ('a', 22158), (',', 3515), ('.', 1538), ('i', 1401), ('to', 867), ('is', 782), ('and', 782), ('the', 737), ('it', 586)] | avgLoss/100: 14.467738156318665 |  |  | TUTOR.py 100
2025-04-16 15:52:59 | 4200 | LR0.00035 | logitMin:-1.4239 | logitMax:0.0660 | scheduledSampling:0.0000 | lossTUTOR:0.1639 | topTokens[('you', 23103), ('a', 22186), (',', 3572), ('.', 1613), ('i', 1416), ('to', 871), ('and', 794), ('is', 784), ('the', 760), ('?', 603)] | avgLoss/100: 7.985971508026123 |  |  | TUTOR.py 100
2025-04-16 15:53:45 | 4300 | LR0.00035 | logitMin:-1.4288 | logitMax:0.0542 | scheduledSampling:0.0000 | lossTUTOR:0.1032 | topTokens[('you', 23145), ('a', 22209), (',', 3619), ('.', 1640), ('i', 1446), ('to', 877), ('and', 800), ('is', 785), ('the', 764), ("'", 648)] | avgLoss/100: 10.7476629114151 |  |  | TUTOR.py 100
2025-04-16 15:54:31 | 4400 | LR0.00035 | logitMin:-1.4171 | logitMax:0.0136 | scheduledSampling:0.0000 | lossTUTOR:0.0313 | topTokens[('you', 23148), ('a', 22213), (',', 3638), ('.', 1728), ('i', 1494), ('to', 879), ("'", 820), ('and', 809), ("'", 802), ('is', 789)] | avgLoss/100: 13.512253427505494 |  |  | TUTOR.py 100
2025-04-16 15:55:21 | 4500 | LR0.00035 | logitMin:-1.4309 | logitMax:0.0474 | scheduledSampling:0.0000 | lossTUTOR:0.0333 | topTokens[('you', 23183), ('a', 22229), (',', 3673), ('.', 1799), ('i', 1535), ("'", 964), ("'", 960), ('to', 888), ('and', 813), ('is', 794)] | avgLoss/100: 12.680780673027039 |  |  | TUTOR.py 100
2025-04-16 15:56:08 | 4600 | LR0.00035 | logitMin:-1.4150 | logitMax:0.0034 | scheduledSampling:0.0000 | lossTUTOR:0.1823 | topTokens[('you', 23229), ('a', 22237), (',', 3693), ('.', 1895), ('i', 1578), ("'", 1128), ("'", 1119), ('to', 906), (':', 899), ('and', 816)] | avgLoss/100: 12.624537861347198 |  |  | TUTOR.py 100
2025-04-16 15:56:53 | 4700 | LR0.00035 | logitMin:-1.4192 | logitMax:-0.0123 | scheduledSampling:0.0000 | lossTUTOR:0.1252 | topTokens[('you', 23257), ('a', 22265), (',', 3702), ('.', 1975), ('i', 1627), ("'", 1267), ("'", 1264), (':', 1027), ('to', 913), ('is', 819)] | avgLoss/100: 11.829840245246887 |  |  | TUTOR.py 100
2025-04-16 15:57:40 | 4800 | LR0.00035 | logitMin:-1.4162 | logitMax:0.0166 | scheduledSampling:0.0000 | lossTUTOR:0.0548 | topTokens[('you', 23262), ('a', 22282), (',', 3707), ('.', 2071), ('i', 1631), ("'", 1398), ("'", 1387), (':', 1140), ('to', 923), ('is', 825)] | avgLoss/100: 10.678966832160949 |  |  | TUTOR.py 100
2025-04-16 15:58:27 | 4900 | LR0.00035 | logitMin:-1.4344 | logitMax:0.0217 | scheduledSampling:0.0000 | lossTUTOR:0.0974 | topTokens[('you', 23265), ('a', 22289), (',', 3728), ('.', 2189), ('i', 1634), ("'", 1492), ("'", 1487), (':', 1248), ('to', 926), ('and', 828)] | avgLoss/100: 11.260492898225785 |  |  | TUTOR.py 100
2025-04-16 15:59:18 | 5000 | LR0.00035 | logitMin:-4.8765 | logitMax:-0.1346 | scheduledSampling:0.0000 | lossTUTOR:1.7680 | topTokens[('you', 23322), ('a', 22294), (',', 3748), ('.', 2222), ('i', 1666), ("'", 1636), ("'", 1623), (':', 1388), ('to', 940), ('the', 872)] | avgLoss/100: 11.878835711479187 |  |  | TUTOR.py 100
2025-04-16 16:00:04 | 5100 | LR0.00035 | logitMin:-1.4009 | logitMax:0.0165 | scheduledSampling:0.0000 | lossTUTOR:0.1153 | topTokens[('you', 23346), ('a', 22308), (',', 3822), ('.', 2259), ('i', 1717), ("'", 1691), ("'", 1672), (':', 1454), ('to', 968), ('the', 893)] | avgLoss/100: 13.722056775093078 |  |  | TUTOR.py 100
2025-04-16 16:00:51 | 5200 | LR0.00035 | logitMin:-1.3952 | logitMax:-0.0316 | scheduledSampling:0.0000 | lossTUTOR:0.0787 | topTokens[('you', 23350), ('a', 22383), (',', 4084), ('.', 2263), ('i', 1767), ("'", 1696), ("'", 1687), (':', 1475), ('to', 972), ('the', 904)] | avgLoss/100: 12.73252611875534 |  |  | TUTOR.py 100
2025-04-16 16:01:38 | 5300 | LR0.00035 | logitMin:-1.4019 | logitMax:-0.0214 | scheduledSampling:0.0000 | lossTUTOR:0.1527 | topTokens[('you', 23353), ('a', 22503), (',', 4259), ('.', 2265), ('i', 1847), ("'", 1697), ("'", 1695), (':', 1478), ('to', 984), ('and', 942)] | avgLoss/100: 11.517643003463744 |  |  | TUTOR.py 100
2025-04-16 16:02:24 | 5400 | LR0.00035 | logitMin:-1.3960 | logitMax:-0.0300 | scheduledSampling:0.0000 | lossTUTOR:0.1141 | topTokens[('you', 23357), ('a', 22544), (',', 4532), ('.', 2271), ('i', 1920), ("'", 1703), ("'", 1700), (':', 1487), ('to', 993), ('and', 993)] | avgLoss/100: 13.267090520858766 |  |  | TUTOR.py 100
2025-04-16 16:03:14 | 5500 | LR0.00035 | logitMin:-1.3957 | logitMax:-0.0462 | scheduledSampling:0.0000 | lossTUTOR:0.0673 | topTokens[('you', 23359), ('a', 22570), (',', 4785), ('.', 2272), ('i', 1985), ("'", 1704), ("'", 1703), (':', 1491), ('to', 1044), ('and', 1006)] | avgLoss/100: 10.982427911758423 |  |  | TUTOR.py 100
2025-04-16 16:04:01 | 5600 | LR0.00035 | logitMin:-1.3991 | logitMax:-0.0726 | scheduledSampling:0.0000 | lossTUTOR:0.0585 | topTokens[('you', 23381), ('a', 22616), (',', 4934), ('.', 2367), ('i', 2021), ("'", 1706), ("'", 1705), (':', 1493), ('to', 1071), ('the', 1060)] | avgLoss/100: 12.530927557945251 |  |  | TUTOR.py 100

--- 2025-04-16 16:04:52 --- babyLLM 'right, last time i got to step 12006... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12006! what am i learning today?' - charis: ''

--- 2025-04-16 16:05:30 --- babyLLM 'right, last time i got to step 12007... want to restart from there?'  - charis: '17000' - babyLLM 'damn that's specific! heading to step 17000... what am i learning today?' - charis: ''
2025-04-16 16:06:16 | 100 | LR0.00035 | logitMin:-1.4322 | logitMax:0.1886 | scheduledSampling:0.0000 | lossTUTOR:0.1227 | topTokens[(',', 864), ('i', 54), ("'", 50), ('a', 48), ('the', 38), ('and', 35), ('b', 27), ('.', 24), ('him', 23), ('you', 22)] | avgLoss/100: 13.508964543342591 |  |  | TUTOR.py 100
2025-04-16 16:07:02 | 200 | LR0.00035 | logitMin:-1.3634 | logitMax:0.0697 | scheduledSampling:0.0000 | lossTUTOR:0.1148 | topTokens[(',', 1615), ('a', 106), ('i', 83), ('b', 82), ('and', 60), ('the', 59), ("'", 54), ('just', 48), ('it', 45), ('t', 45)] | avgLoss/100: 16.24755549430847 |  |  | TUTOR.py 100
2025-04-16 16:07:49 | 300 | LR0.00035 | logitMin:-1.4380 | logitMax:-0.0101 | scheduledSampling:0.0000 | lossTUTOR:0.1721 | topTokens[(',', 2661), ('i', 129), ('a', 127), ('and', 110), ('b', 82), ('the', 67), ("'", 54), ('s', 53), ('just', 48), ('it', 47)] | avgLoss/100: 29.479467935562134 |  |  | TUTOR.py 100
2025-04-16 16:08:34 | 400 | LR0.00035 | logitMin:-1.3969 | logitMax:0.6486 | scheduledSampling:0.0000 | lossTUTOR:0.6265 | topTokens[(',', 3624), ('and', 159), ('i', 154), ('a', 141), ('the', 88), ('b', 82), ('it', 79), ('im', 62), ('s', 60), ("'", 57)] | avgLoss/100: 34.34057960510254 |  |  | TUTOR.py 100
2025-04-16 16:09:22 | 500 | LR0.00035 | logitMin:-1.5085 | logitMax:0.6212 | scheduledSampling:0.0000 | lossTUTOR:0.4139 | topTokens[(',', 5105), ('and', 165), ('i', 164), ('a', 143), ('the', 107), ('b', 82), ('it', 80), ('l', 69), ('lo', 68), ('im', 65)] | avgLoss/100: 59.39909816741943 |  |  | TUTOR.py 100
2025-04-16 16:10:09 | 600 | LR0.00035 | logitMin:-1.5148 | logitMax:0.1426 | scheduledSampling:0.0000 | lossTUTOR:0.6295 | topTokens[(',', 6044), ('and', 188), ('the', 180), ('i', 177), ('a', 157), ('.', 92), ('s', 88), ('it', 87), ('b', 85), ('to', 70)] | avgLoss/100: 44.06384804725647 |  |  | TUTOR.py 100
2025-04-16 16:10:55 | 700 | LR0.00035 | logitMin:-1.4096 | logitMax:0.9673 | scheduledSampling:0.0000 | lossTUTOR:0.8358 | topTokens[(',', 7677), ('the', 194), ('and', 188), ('i', 177), ('a', 157), ('.', 92), ('b', 92), ('s', 88), ('it', 87), ('to', 79)] | avgLoss/100: 84.86609663963318 |  |  | TUTOR.py 100
2025-04-16 16:11:42 | 800 | LR0.00035 | logitMin:-1.4051 | logitMax:0.7952 | scheduledSampling:0.0000 | lossTUTOR:0.7641 | topTokens[(',', 9477), ('the', 194), ('and', 188), ('i', 177), ('a', 157), ('.', 92), ('b', 92), ('s', 88), ('it', 87), ('to', 79)] | avgLoss/100: 81.79225601196289 |  |  | TUTOR.py 100
2025-04-16 16:12:29 | 900 | LR0.00035 | logitMin:-1.3939 | logitMax:0.5653 | scheduledSampling:0.0000 | lossTUTOR:0.6009 | topTokens[(',', 11194), ('the', 194), ('and', 188), ('i', 177), ('a', 157), ('you', 106), ('.', 92), ('b', 92), ('s', 88), ('it', 87)] | avgLoss/100: 64.0921841430664 |  |  | TUTOR.py 100
2025-04-16 16:13:19 | 1000 | LR0.00035 | logitMin:-2.9609 | logitMax:-0.2147 | scheduledSampling:0.0000 | lossTUTOR:1.4502 | topTokens[(',', 12796), ('i', 239), ('the', 197), ('you', 195), ('and', 188), ('a', 157), ('.', 92), ('b', 92), ('s', 88), ('it', 87)] | avgLoss/100: 54.534160690307615 |  |  | TUTOR.py 100
2025-04-16 16:14:05 | 1100 | LR0.00035 | logitMin:-1.3895 | logitMax:0.4100 | scheduledSampling:0.0000 | lossTUTOR:0.3428 | topTokens[(',', 14100), ('i', 324), ('the', 275), ('you', 262), ('and', 188), ('a', 157), ('to', 114), ('.', 92), ('b', 92), ('s', 88)] | avgLoss/100: 40.21981283187866 |  |  | TUTOR.py 100
2025-04-16 16:14:50 | 1200 | LR0.00035 | logitMin:-1.3949 | logitMax:0.4060 | scheduledSampling:0.0000 | lossTUTOR:0.3569 | topTokens[(',', 15169), ('i', 397), ('the', 355), ('you', 303), ('and', 218), ('to', 165), ('a', 157), ('c', 99), ('it', 98), ('on', 98)] | avgLoss/100: 34.05247688293457 |  |  | TUTOR.py 100
2025-04-16 16:15:36 | 1300 | LR0.00035 | logitMin:-1.3976 | logitMax:0.3568 | scheduledSampling:0.0000 | lossTUTOR:0.3749 | topTokens[(',', 16061), ('i', 463), ('the', 423), ('you', 345), ('and', 278), ('to', 216), ('a', 196), ('s', 136), ('c', 136), ('on', 127)] | avgLoss/100: 29.343899974823 |  |  | TUTOR.py 100
2025-04-16 16:16:22 | 1400 | LR0.00035 | logitMin:-1.3924 | logitMax:0.2668 | scheduledSampling:0.0000 | lossTUTOR:0.2892 | topTokens[(',', 16961), ('i', 494), ('the', 471), ('you', 381), ('and', 294), ('a', 271), ('to', 228), ('on', 155), ('c', 151), ('s', 142)] | avgLoss/100: 30.346739082336427 |  |  | TUTOR.py 100
2025-04-16 16:17:12 | 1500 | LR0.00035 | logitMin:-1.3702 | logitMax:0.1444 | scheduledSampling:0.0000 | lossTUTOR:0.2024 | topTokens[(',', 17771), ('i', 539), ('the', 508), ('you', 410), ('and', 326), ('a', 322), ('to', 247), ('im', 166), ('on', 165), ('c', 161)] | avgLoss/100: 24.395867671966553 |  |  | TUTOR.py 100
2025-04-16 16:17:58 | 1600 | LR0.00035 | logitMin:-1.3891 | logitMax:0.2156 | scheduledSampling:0.0000 | lossTUTOR:0.1594 | topTokens[(',', 18522), ('i', 608), ('the', 548), ('you', 450), ('a', 361), ('and', 336), ('to', 264), ('im', 215), ('s', 172), ('on', 172)] | avgLoss/100: 24.167232398986815 |  |  | TUTOR.py 100
2025-04-16 16:18:43 | 1700 | LR0.00035 | logitMin:-1.3636 | logitMax:0.1441 | scheduledSampling:0.0000 | lossTUTOR:0.2676 | topTokens[(',', 19252), ('i', 676), ('the', 583), ('you', 466), ('a', 390), ('and', 345), ('to', 293), ('im', 215), ('on', 186), ('s', 174)] | avgLoss/100: 17.458915729522705 |  |  | TUTOR.py 100
2025-04-16 16:19:29 | 1800 | LR0.00035 | logitMin:-1.3723 | logitMax:0.3723 | scheduledSampling:0.0000 | lossTUTOR:0.1452 | topTokens[(',', 19682), ('i', 732), ('the', 590), ('you', 468), ('a', 401), ('and', 359), ('to', 299), ('on', 233), ('im', 229), ('we', 208)] | avgLoss/100: 20.23824164390564 |  |  | TUTOR.py 100
2025-04-16 16:20:15 | 1900 | LR0.00035 | logitMin:-1.3723 | logitMax:0.4956 | scheduledSampling:0.0000 | lossTUTOR:0.2421 | topTokens[(',', 20174), ('i', 783), ('the', 627), ('you', 468), ('a', 419), ('and', 373), ('to', 329), ('im', 253), ('on', 240), ('we', 221)] | avgLoss/100: 21.333542032241823 |  |  | TUTOR.py 100

--- 2025-04-16 16:21:32 --- babyLLM 'right, last time i got to step 17001... want to restart from there?'  - charis: '19000' - babyLLM 'damn that's specific! heading to step 19000... what am i learning today?' - charis: ''
2025-04-16 16:22:18 | 100 | LR0.00035 | logitMin:-1.3980 | logitMax:0.4382 | scheduledSampling:0.0000 | lossTUTOR:0.4228 | topTokens[(',', 1633), ('ably', 38), ('to', 22), ('wise', 17), ("'", 14), ('tw', 12), ('tr', 12), ('things', 7), ('show', 6), ('i', 6)] | avgLoss/100: 65.23662496566773 |  |  | TUTOR.py 100
2025-04-16 16:23:04 | 200 | LR0.00035 | logitMin:-1.3439 | logitMax:0.2790 | scheduledSampling:0.0000 | lossTUTOR:0.2796 | topTokens[(',', 3250), ('i', 45), ('ably', 38), ('to', 28), ('f', 26), ('is', 26), ('im', 20), ('wise', 17), ('of', 17), ("'", 14)] | avgLoss/100: 35.890980129241946 |  |  | TUTOR.py 100
2025-04-16 16:23:50 | 300 | LR0.00035 | logitMin:-1.6498 | logitMax:1.9315 | scheduledSampling:0.0000 | lossTUTOR:0.4599 | topTokens[(',', 3952), ('i', 106), ('f', 106), ('s', 98), ('ing', 80), ('to', 79), ('no', 51), ('im', 43), ('is', 42), ('u', 41)] | avgLoss/100: 24.7142924785614 |  |  | TUTOR.py 100
2025-04-16 16:24:37 | 400 | LR0.00035 | logitMin:-1.4392 | logitMax:0.4945 | scheduledSampling:0.0000 | lossTUTOR:0.4137 | topTokens[(',', 4547), ('i', 165), ('f', 119), ('s', 109), ('ing', 108), ('to', 95), ('my', 67), ('im', 63), ('it', 63), ('o', 58)] | avgLoss/100: 32.13386262893677 |  |  | TUTOR.py 100
2025-04-16 16:25:27 | 500 | LR0.00035 | logitMin:-1.4933 | logitMax:1.2059 | scheduledSampling:0.0000 | lossTUTOR:0.3289 | topTokens[(',', 5277), ('i', 258), ('ing', 139), ('f', 126), ('to', 122), ('s', 118), ('my', 103), ('it', 89), ('the', 86), ('im', 76)] | avgLoss/100: 33.33588245391846 |  |  | TUTOR.py 100
2025-04-16 16:26:13 | 600 | LR0.00035 | logitMin:-1.7259 | logitMax:3.1336 | scheduledSampling:0.0000 | lossTUTOR:0.5631 | topTokens[(',', 5906), ('i', 353), ('to', 159), ('ing', 151), ('s', 130), ('f', 129), ('is', 118), ('my', 115), ('it', 112), ('the', 101)] | avgLoss/100: 34.13303599357605 |  |  | TUTOR.py 100
2025-04-16 16:26:59 | 700 | LR0.00035 | logitMin:-1.5192 | logitMax:0.8918 | scheduledSampling:0.0000 | lossTUTOR:0.5347 | topTokens[(',', 6608), ('i', 367), ('is', 210), ('to', 164), ('ing', 153), ('?', 150), ('f', 141), ('s', 136), ('it', 124), ('my', 115)] | avgLoss/100: 43.058025732040406 |  |  | TUTOR.py 100
2025-04-16 16:27:44 | 800 | LR0.00035 | logitMin:-1.3937 | logitMax:1.0112 | scheduledSampling:0.0000 | lossTUTOR:0.5218 | topTokens[(',', 7239), ('i', 402), ('is', 326), ('.', 266), ('?', 248), ('ing', 170), ('to', 165), ('s', 145), ('f', 144), ('you', 136)] | avgLoss/100: 43.50881815910339 |  |  | TUTOR.py 100
2025-04-16 16:28:31 | 900 | LR0.00035 | logitMin:-1.6861 | logitMax:0.5077 | scheduledSampling:0.0000 | lossTUTOR:0.2610 | topTokens[(',', 7952), ('i', 420), ('is', 403), ('.', 395), ('?', 294), ('you', 216), ('to', 176), ('ing', 173), ('f', 172), ('s', 153)] | avgLoss/100: 47.1505509185791 |  |  | TUTOR.py 100
2025-04-16 16:29:21 | 1000 | LR0.00035 | logitMin:-49.3315 | logitMax:8.1816 | scheduledSampling:0.0000 | lossTUTOR:20.0322 | topTokens[(',', 8795), ('.', 497), ('is', 470), ('i', 431), ('?', 381), ('you', 278), ('to', 205), ('f', 194), ('ing', 173), ('s', 164)] | avgLoss/100: 65.7486526107788 |  |  | TUTOR.py 100
2025-04-16 16:30:07 | 1100 | LR0.00035 | logitMin:-1.3730 | logitMax:0.7421 | scheduledSampling:0.0000 | lossTUTOR:0.7676 | topTokens[(',', 10523), ('.', 497), ('is', 470), ('i', 431), ('?', 381), ('you', 278), ('to', 205), ('f', 194), ('ing', 173), ('s', 164)] | avgLoss/100: 102.96635643005371 |  |  | TUTOR.py 100
2025-04-16 16:30:53 | 1200 | LR0.00035 | logitMin:-1.3659 | logitMax:0.4048 | scheduledSampling:0.0000 | lossTUTOR:0.4407 | topTokens[(',', 12323), ('.', 497), ('is', 470), ('i', 431), ('?', 381), ('you', 278), ('to', 205), ('f', 194), ('ing', 173), ('s', 164)] | avgLoss/100: 67.87099739074706 |  |  | TUTOR.py 100
2025-04-16 16:31:40 | 1300 | LR0.00035 | logitMin:-1.3748 | logitMax:0.2233 | scheduledSampling:0.0000 | lossTUTOR:0.2374 | topTokens[(',', 13447), ('.', 643), ('is', 470), ('i', 431), ('you', 430), ('?', 403), ('!', 246), ('f', 212), ('to', 205), ('ing', 173)] | avgLoss/100: 31.230222129821776 |  |  | TUTOR.py 100
2025-04-16 16:32:26 | 1400 | LR0.00035 | logitMin:-1.3698 | logitMax:0.1478 | scheduledSampling:0.0000 | lossTUTOR:0.2279 | topTokens[(',', 13924), ('.', 888), ('?', 686), ('you', 588), ('is', 489), ('i', 432), ('!', 365), ('f', 252), ('to', 205), ('s', 185)] | avgLoss/100: 28.868923568725585 |  |  | TUTOR.py 100
2025-04-16 16:33:15 | 1500 | LR0.00035 | logitMin:-1.3775 | logitMax:0.1376 | scheduledSampling:0.0000 | lossTUTOR:0.2093 | topTokens[(',', 14152), ('.', 1160), ('?', 938), ('you', 716), ('is', 587), ('i', 485), ('!', 428), ('f', 273), ('als', 230), ('what', 216)] | avgLoss/100: 20.712306385040282 |  |  | TUTOR.py 100
2025-04-16 16:34:02 | 1600 | LR0.00035 | logitMin:-1.3832 | logitMax:0.0949 | scheduledSampling:0.0000 | lossTUTOR:0.1180 | topTokens[(',', 14377), ('.', 1340), ('?', 1094), ('you', 819), ('is', 727), ('i', 513), ('!', 478), ('f', 321), ('what', 295), ('als', 265)] | avgLoss/100: 18.455051765441894 |  |  | TUTOR.py 100
2025-04-16 16:34:49 | 1700 | LR0.00035 | logitMin:-1.3809 | logitMax:0.0357 | scheduledSampling:0.0000 | lossTUTOR:0.1050 | topTokens[(',', 14477), ('.', 1505), ('?', 1284), ('you', 905), ('is', 890), ('i', 543), ('!', 538), ('what', 346), ('f', 325), ('als', 316)] | avgLoss/100: 10.447084052562714 |  |  | TUTOR.py 100
2025-04-16 16:35:36 | 1800 | LR0.00035 | logitMin:-1.3649 | logitMax:0.0179 | scheduledSampling:0.0000 | lossTUTOR:0.1340 | topTokens[(',', 14537), ('.', 1697), ('?', 1507), ('is', 1039), ('you', 974), ('!', 601), ('i', 558), ('what', 440), ('are', 374), ('als', 355)] | avgLoss/100: 14.923042578697205 |  |  | TUTOR.py 100
2025-04-16 16:36:22 | 1900 | LR0.00035 | logitMin:-1.3913 | logitMax:0.0793 | scheduledSampling:0.0000 | lossTUTOR:0.1208 | topTokens[(',', 14671), ('.', 1847), ('?', 1674), ('is', 1074), ('you', 1069), ('!', 650), ('i', 634), ('what', 460), ('are', 437), ('als', 435)] | avgLoss/100: 8.886001899242402 |  |  | TUTOR.py 100
2025-04-16 16:37:12 | 2000 | LR0.00035 | logitMin:-2.7810 | logitMax:-0.1609 | scheduledSampling:0.0000 | lossTUTOR:0.6885 | topTokens[(',', 14812), ('.', 2030), ('?', 1788), ('is', 1130), ('you', 1123), ('!', 757), ('i', 670), ('are', 524), ('als', 507), ('what', 466)] | avgLoss/100: 11.116730399131775 |  |  | TUTOR.py 100
2025-04-16 16:37:58 | 2100 | LR0.00035 | logitMin:-1.3714 | logitMax:-0.0505 | scheduledSampling:0.0000 | lossTUTOR:0.1003 | topTokens[(',', 14908), ('.', 2134), ('?', 1951), ('is', 1256), ('you', 1180), ('!', 837), ('i', 696), ('are', 585), ('what', 569), ('als', 541)] | avgLoss/100: 16.753224210739134 |  |  | TUTOR.py 100
2025-04-16 16:38:45 | 2200 | LR0.00035 | logitMin:-1.3875 | logitMax:-0.0013 | scheduledSampling:0.0000 | lossTUTOR:0.0713 | topTokens[(',', 14942), ('.', 2257), ('?', 2139), ('is', 1334), ('you', 1302), ('!', 925), ('i', 747), ('are', 648), ('what', 603), ('als', 558)] | avgLoss/100: 8.243240714073181 |  |  | TUTOR.py 100
2025-04-16 16:39:32 | 2300 | LR0.00035 | logitMin:-1.3825 | logitMax:-0.0368 | scheduledSampling:0.0000 | lossTUTOR:0.0827 | topTokens[(',', 15002), ('.', 2452), ('?', 2270), ('is', 1444), ('you', 1331), ('!', 939), ('i', 750), ('are', 665), ('als', 630), ('what', 627)] | avgLoss/100: 7.486955795288086 |  |  | TUTOR.py 100
2025-04-16 16:40:18 | 2400 | LR0.00035 | logitMin:-1.3773 | logitMax:-0.0408 | scheduledSampling:0.0000 | lossTUTOR:0.1708 | topTokens[(',', 15028), ('.', 2567), ('?', 2421), ('is', 1487), ('you', 1385), ('!', 1025), ('i', 759), ('are', 700), ('als', 686), ('what', 654)] | avgLoss/100: 10.64281965970993 |  |  | TUTOR.py 100
2025-04-16 16:41:08 | 2500 | LR0.00035 | logitMin:-1.3756 | logitMax:-0.0440 | scheduledSampling:0.0000 | lossTUTOR:0.1150 | topTokens[(',', 15037), ('.', 2638), ('?', 2444), ('is', 1527), ('you', 1402), ('!', 1095), ('i', 774), ('are', 713), ('als', 690), ('what', 662)] | avgLoss/100: 14.017311100959779 |  |  | TUTOR.py 100
2025-04-16 16:41:55 | 2600 | LR0.00035 | logitMin:-1.3681 | logitMax:-0.0780 | scheduledSampling:0.0000 | lossTUTOR:0.1300 | topTokens[(',', 15264), ('.', 2693), ('?', 2459), ('is', 1554), ('you', 1410), ('!', 1108), ('i', 819), ('are', 721), ('als', 691), ('what', 667)] | avgLoss/100: 12.95622769355774 |  |  | TUTOR.py 100
2025-04-16 16:42:42 | 2700 | LR0.00035 | logitMin:-1.3443 | logitMax:-0.1112 | scheduledSampling:0.0000 | lossTUTOR:0.0582 | topTokens[(',', 15467), ('.', 2703), ('?', 2467), ('is', 1558), ('you', 1413), ('!', 1111), ('i', 898), ('are', 725), ('als', 693), ('what', 668)] | avgLoss/100: 10.286708779335022 |  |  | TUTOR.py 100
2025-04-16 16:43:27 | 2800 | LR0.00035 | logitMin:-1.3723 | logitMax:-0.0961 | scheduledSampling:0.0000 | lossTUTOR:0.0985 | topTokens[(',', 15632), ('.', 2712), ('?', 2490), ('is', 1561), ('you', 1468), ('!', 1131), ('i', 917), ('are', 727), ('als', 694), ('what', 670)] | avgLoss/100: 10.810844426155091 |  |  | TUTOR.py 100
2025-04-16 16:44:12 | 2900 | LR0.00035 | logitMin:-1.3777 | logitMax:-0.0925 | scheduledSampling:0.0000 | lossTUTOR:0.0562 | topTokens[(',', 15828), ('.', 2728), ('?', 2494), ('is', 1563), ('you', 1469), ('!', 1174), ('i', 917), ('are', 730), ('als', 696), ('what', 672)] | avgLoss/100: 7.527855668067932 |  |  | TUTOR.py 100
2025-04-16 16:45:02 | 3000 | LR0.00035 | logitMin:-2.6974 | logitMax:-0.2425 | scheduledSampling:0.0000 | lossTUTOR:0.5809 | topTokens[(',', 16033), ('.', 2744), ('?', 2496), ('is', 1564), ('you', 1469), ('!', 1233), ('i', 937), ('are', 730), ('a', 697), ('als', 696)] | avgLoss/100: 5.379039118289947 |  |  | TUTOR.py 100
2025-04-16 16:45:48 | 3100 | LR0.00035 | logitMin:-1.3829 | logitMax:-0.0901 | scheduledSampling:0.0000 | lossTUTOR:0.0954 | topTokens[(',', 16271), ('.', 2758), ('?', 2497), ('is', 1565), ('you', 1488), ('!', 1295), ('i', 953), ('to', 780), ('are', 745), ('a', 738)] | avgLoss/100: 6.141414272785187 |  |  | TUTOR.py 100
2025-04-16 16:46:36 | 3200 | LR0.00035 | logitMin:-1.3583 | logitMax:-0.1116 | scheduledSampling:0.0000 | lossTUTOR:0.0388 | topTokens[(',', 16385), ('.', 2760), ('?', 2520), ('is', 1582), ('you', 1508), ('!', 1316), ('i', 956), ('to', 826), ('a', 811), ('are', 748)] | avgLoss/100: 8.757054426670074 |  |  | TUTOR.py 100
2025-04-16 16:47:23 | 3300 | LR0.00035 | logitMin:-1.3871 | logitMax:-0.1066 | scheduledSampling:0.0000 | lossTUTOR:0.0420 | topTokens[(',', 16564), ('.', 2770), ('?', 2523), ('is', 1595), ('you', 1526), ('!', 1375), ('i', 956), ('to', 914), ('a', 876), ('are', 748)] | avgLoss/100: 4.585100829601288 |  |  | TUTOR.py 100
2025-04-16 16:48:09 | 3400 | LR0.00035 | logitMin:-1.3705 | logitMax:-0.1122 | scheduledSampling:0.0000 | lossTUTOR:0.0426 | topTokens[(',', 16795), ('.', 2798), ('?', 2523), ('is', 1595), ('you', 1547), ('!', 1438), ('to', 1034), ('i', 979), ('a', 920), ('are', 749)] | avgLoss/100: 4.694555358886719 |  |  | TUTOR.py 100
2025-04-16 16:48:59 | 3500 | LR0.00035 | logitMin:-1.3831 | logitMax:-0.1039 | scheduledSampling:0.0000 | lossTUTOR:0.0562 | topTokens[(',', 17047), ('.', 2814), ('?', 2524), ('is', 1596), ('you', 1581), ('!', 1516), ('to', 1063), ('i', 1021), ('a', 938), ('are', 749)] | avgLoss/100: 4.97092554807663 |  |  | TUTOR.py 100
2025-04-16 16:49:46 | 3600 | LR0.00035 | logitMin:-1.3339 | logitMax:-0.1624 | scheduledSampling:0.0000 | lossTUTOR:0.0925 | topTokens[(',', 17197), ('.', 2818), ('?', 2526), ('is', 1597), ('you', 1589), ('!', 1552), ('to', 1176), ('i', 1021), ('a', 951), ('they', 758)] | avgLoss/100: 4.1175082540512085 |  |  | TUTOR.py 100
2025-04-16 16:50:34 | 3700 | LR0.00035 | logitMin:-1.3857 | logitMax:0.0534 | scheduledSampling:0.0000 | lossTUTOR:0.0719 | topTokens[(',', 17210), ('.', 2821), ('?', 2534), ('you', 1609), ('is', 1600), ('!', 1560), ('to', 1192), ('i', 1026), ('boof', 970), ('a', 962)] | avgLoss/100: 14.511495652198791 |  |  | TUTOR.py 100
2025-04-16 16:51:21 | 3800 | LR0.00035 | logitMin:-1.4358 | logitMax:0.0046 | scheduledSampling:0.0000 | lossTUTOR:0.1559 | topTokens[(',', 17382), ('.', 2839), ('?', 2534), ('!', 1616), ('you', 1609), ('is', 1600), ('boof', 1513), ('to', 1233), ('i', 1057), ('a', 994)] | avgLoss/100: 10.059160413742065 |  |  | TUTOR.py 100
2025-04-16 16:52:07 | 3900 | LR0.00035 | logitMin:-1.4126 | logitMax:0.3270 | scheduledSampling:0.0000 | lossTUTOR:0.3574 | topTokens[(',', 17572), ('.', 2859), ('?', 2537), ('boof', 2014), ('!', 1643), ('you', 1609), ('is', 1601), ('to', 1284), ('i', 1079), ('a', 1056)] | avgLoss/100: 19.395213136672975 |  |  | TUTOR.py 100
2025-04-16 16:52:56 | 4000 | LR0.00035 | logitMin:-7.6318 | logitMax:0.1083 | scheduledSampling:0.0000 | lossTUTOR:2.1051 | topTokens[(',', 17676), ('boof', 3223), ('.', 2860), ('?', 2537), ('!', 1652), ('you', 1611), ('is', 1601), ('to', 1326), ('a', 1081), ('i', 1080)] | avgLoss/100: 60.965494041442874 |  |  | TUTOR.py 100
2025-04-16 16:53:43 | 4100 | LR0.00035 | logitMin:-1.3349 | logitMax:0.1982 | scheduledSampling:0.0000 | lossTUTOR:0.3170 | topTokens[(',', 17712), ('boof', 4803), ('.', 2860), ('?', 2537), ('!', 1655), ('you', 1631), ('is', 1601), ('to', 1326), ('a', 1081), ('i', 1080)] | avgLoss/100: 44.72409698486328 |  |  | TUTOR.py 100
2025-04-16 16:54:29 | 4200 | LR0.00035 | logitMin:-1.3779 | logitMax:0.3436 | scheduledSampling:0.0000 | lossTUTOR:0.2733 | topTokens[(',', 18000), ('boof', 6128), ('.', 2860), ('?', 2537), ('!', 1679), ('you', 1651), ('is', 1601), ('to', 1345), ('a', 1103), ('i', 1080)] | avgLoss/100: 31.448159885406493 |  |  | TUTOR.py 100
2025-04-16 16:55:15 | 4300 | LR0.00035 | logitMin:-1.3629 | logitMax:0.3103 | scheduledSampling:0.0000 | lossTUTOR:0.0904 | topTokens[(',', 18230), ('boof', 6776), ('.', 2865), ('?', 2537), ('!', 1708), ('you', 1689), ('is', 1601), ('to', 1452), ('a', 1193), ('i', 1090)] | avgLoss/100: 17.39547320365906 |  |  | TUTOR.py 100
2025-04-16 16:56:02 | 4400 | LR0.00035 | logitMin:-1.3500 | logitMax:0.0320 | scheduledSampling:0.0000 | lossTUTOR:0.0699 | topTokens[(',', 18476), ('boof', 7000), ('.', 2883), ('?', 2537), ('!', 1731), ('you', 1691), ('is', 1601), ('to', 1540), ('a', 1255), ('i', 1115)] | avgLoss/100: 13.439580640792848 |  |  | TUTOR.py 100
2025-04-16 16:56:52 | 4500 | LR0.00035 | logitMin:-1.4908 | logitMax:1.5732 | scheduledSampling:0.0000 | lossTUTOR:0.4771 | topTokens[(',', 18599), ('boof', 7465), ('.', 2902), ('?', 2537), ('!', 1773), ('you', 1710), ('is', 1601), ('to', 1590), ('a', 1286), ('i', 1135)] | avgLoss/100: 18.83547001838684 |  |  | TUTOR.py 100
2025-04-16 16:57:39 | 4600 | LR0.00035 | logitMin:-1.4106 | logitMax:0.5593 | scheduledSampling:0.0000 | lossTUTOR:0.2422 | topTokens[(',', 18738), ('boof', 8130), ('.', 2930), ('?', 2537), ('!', 1773), ('you', 1710), ('to', 1616), ('is', 1601), ('a', 1298), ('i', 1166)] | avgLoss/100: 30.18692985534668 |  |  | TUTOR.py 100
2025-04-16 16:58:24 | 4700 | LR0.00035 | logitMin:-1.4621 | logitMax:0.2749 | scheduledSampling:0.0000 | lossTUTOR:0.1442 | topTokens[(',', 18960), ('boof', 8587), ('.', 2941), ('?', 2537), ('!', 1789), ('you', 1710), ('to', 1647), ('is', 1601), ('a', 1320), ('i', 1260)] | avgLoss/100: 21.194193120002748 |  |  | TUTOR.py 100
2025-04-16 16:59:10 | 4800 | LR0.00035 | logitMin:-1.7949 | logitMax:1.7014 | scheduledSampling:0.0000 | lossTUTOR:0.5601 | topTokens[(',', 19143), ('boof', 9171), ('.', 2968), ('?', 2537), ('!', 1837), ('you', 1724), ('to', 1704), ('is', 1601), ('a', 1368), ('i', 1298)] | avgLoss/100: 28.484513602256776 |  |  | TUTOR.py 100
2025-04-16 16:59:56 | 4900 | LR0.00035 | logitMin:-1.4089 | logitMax:0.7258 | scheduledSampling:0.0000 | lossTUTOR:0.5318 | topTokens[(',', 19176), ('boof', 10711), ('.', 2968), ('?', 2537), ('!', 1837), ('you', 1725), ('to', 1707), ('is', 1601), ('a', 1389), ('i', 1307)] | avgLoss/100: 83.09257933616638 |  |  | TUTOR.py 100
2025-04-16 17:00:46 | 5000 | LR0.00035 | logitMin:-1.8093 | logitMax:3.7292 | scheduledSampling:0.0000 | lossTUTOR:2.2269 | topTokens[(',', 19257), ('boof', 11498), ('.', 2999), ('?', 2562), ('!', 2020), ('you', 1749), ('to', 1707), ('is', 1601), ('i', 1581), ('a', 1389)] | avgLoss/100: 20.486149578094484 |  |  | TUTOR.py 100
2025-04-16 17:01:33 | 5100 | LR0.00035 | logitMin:-1.3269 | logitMax:0.0562 | scheduledSampling:0.0000 | lossTUTOR:0.2413 | topTokens[(',', 19462), ('boof', 11679), ('.', 3155), ('?', 2587), ('!', 2150), ('you', 1801), ('to', 1735), ('i', 1729), ('is', 1601), ('a', 1508)] | avgLoss/100: 47.154995918273926 |  |  | TUTOR.py 100
2025-04-16 17:02:18 | 5200 | LR0.00035 | logitMin:-1.3572 | logitMax:0.1834 | scheduledSampling:0.0000 | lossTUTOR:0.1108 | topTokens[(',', 19509), ('boof', 12061), ('.', 3212), ('?', 2619), ('!', 2227), ('you', 1819), ('to', 1813), ('i', 1776), ('is', 1601), ('a', 1528)] | avgLoss/100: 20.803950157165527 |  |  | TUTOR.py 100
2025-04-16 17:03:03 | 5300 | LR0.00035 | logitMin:-1.3522 | logitMax:0.1526 | scheduledSampling:0.0000 | lossTUTOR:0.0810 | topTokens[(',', 19549), ('boof', 12162), ('.', 3224), ('?', 2671), ('!', 2270), ('to', 1864), ('you', 1821), ('i', 1818), ('is', 1601), ('a', 1532)] | avgLoss/100: 9.72801931142807 |  |  | TUTOR.py 100
2025-04-16 17:03:49 | 5400 | LR0.00035 | logitMin:-1.3591 | logitMax:0.1603 | scheduledSampling:0.0000 | lossTUTOR:0.0332 | topTokens[(',', 19580), ('boof', 12179), ('.', 3225), ('?', 2706), ('!', 2310), ('to', 1964), ('i', 1871), ('you', 1821), ('is', 1601), ('a', 1535)] | avgLoss/100: 4.600867197513581 |  |  | TUTOR.py 100
2025-04-16 17:04:40 | 5500 | LR0.00035 | logitMin:-1.3614 | logitMax:0.1871 | scheduledSampling:0.0000 | lossTUTOR:0.0309 | topTokens[(',', 19597), ('boof', 12188), ('.', 3225), ('?', 2749), ('!', 2364), ('to', 2052), ('i', 1908), ('you', 1821), ('is', 1601), ('a', 1535)] | avgLoss/100: 3.480023305416107 |  |  | TUTOR.py 100

--- 2025-04-16 17:05:34 --- babyLLM 'right, last time i got to step 19001... want to restart from there?'  - charis: '24000' - babyLLM 'damn that's specific! heading to step 24000... what am i learning today?' - charis: ''

--- 2025-04-16 17:07:08 --- babyLLM 'right, last time i got to step 19001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 19001! what am i learning today?' - charis: ''

--- 2025-04-16 17:08:31 --- babyLLM 'right, last time i got to step 19001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 19001! what am i learning today?' - charis: ''
2025-04-16 17:09:17 | 100 | LR0.00035 | logitMin:-1.3648 | logitMax:0.0259 | scheduledSampling:0.0000 | lossTUTOR:0.2116 | topTokens[(',', 324), ('boof', 153), ('a', 151), ('to', 82), ('i', 73), ("'", 67), ('no', 57), ('step', 53), ('it', 47), ('at', 42)] | avgLoss/100: 31.359550065994263 |  |  | TUTOR.py 100
2025-04-16 17:10:04 | 200 | LR0.00035 | logitMin:-1.3667 | logitMax:-0.0572 | scheduledSampling:0.0000 | lossTUTOR:0.1647 | topTokens[(',', 704), ('boof', 245), ('a', 226), ('i', 141), ('to', 104), ("'", 100), ('no', 86), ('f', 86), ('step', 76), ('is', 75)] | avgLoss/100: 17.341608896255494 |  |  | TUTOR.py 100
2025-04-16 17:10:51 | 300 | LR0.00035 | logitMin:-1.3604 | logitMax:-0.1230 | scheduledSampling:0.0000 | lossTUTOR:0.1681 | topTokens[(',', 937), ('boof', 275), ('a', 235), ('i', 194), ('no', 169), ('to', 156), ('f', 155), ('ing', 150), ('s', 118), ('al', 115)] | avgLoss/100: 12.487258625030517 |  |  | TUTOR.py 100

--- 2025-04-16 17:11:39 --- babyLLM 'right, last time i got to step 19001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 19001! what am i learning today?' - charis: ''
2025-04-16 17:12:25 | 100 | LR0.00035 | logitMin:-1.3648 | logitMax:0.0259 | scheduledSampling:0.0000 | lossTUTOR:0.2115 | topTokens[(',', 308), ('a', 153), ('boof', 147), ('i', 77), ('to', 72), ("'", 59), ('no', 54), ('step', 50), ('it', 47), ('p', 45)] | avgLoss/100: 31.359461650848388 |  |  | TUTOR.py 100
2025-04-16 17:13:12 | 200 | LR0.00035 | logitMin:-1.3660 | logitMax:-0.0568 | scheduledSampling:0.0000 | lossTUTOR:0.1645 | topTokens[(',', 708), ('boof', 242), ('a', 219), ('i', 138), ('to', 91), ("'", 84), ('f', 78), ('no', 77), ('step', 75), ('it', 69)] | avgLoss/100: 17.32665686607361 |  |  | TUTOR.py 100
2025-04-16 17:13:59 | 300 | LR0.00035 | logitMin:-1.3594 | logitMax:-0.1229 | scheduledSampling:0.0000 | lossTUTOR:0.1689 | topTokens[(',', 952), ('boof', 273), ('a', 228), ('i', 198), ('f', 167), ('no', 158), ('ing', 139), ('to', 133), ('s', 110), ('ad', 105)] | avgLoss/100: 12.47126051902771 |  |  | TUTOR.py 100
2025-04-16 17:14:45 | 400 | LR0.00035 | logitMin:-1.3545 | logitMax:-0.1829 | scheduledSampling:0.0000 | lossTUTOR:0.1363 | topTokens[(',', 1179), ('boof', 290), ('i', 285), ('a', 239), ('f', 173), ('no', 166), ('ing', 164), ('to', 149), ('s', 117), ('it', 113)] | avgLoss/100: 13.729107942581177 |  |  | TUTOR.py 100
2025-04-16 17:15:35 | 500 | LR0.00035 | logitMin:-1.3523 | logitMax:-0.1912 | scheduledSampling:0.0000 | lossTUTOR:0.0410 | topTokens[(',', 1358), ('i', 397), ('boof', 318), ('a', 245), ('ing', 187), ('f', 176), ('to', 174), ('no', 167), ('my', 143), ('it', 129)] | avgLoss/100: 8.268484976291656 |  |  | TUTOR.py 100

--- 2025-04-16 17:16:27 --- babyLLM 'right, last time i got to step 19002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 19002! what am i learning today?' - charis: ''
2025-04-16 17:17:14 | 100 | LR0.00035 | logitMin:-1.3569 | logitMax:-0.2490 | scheduledSampling:0.0000 | lossTUTOR:0.0432 | topTokens[(',', 234), ('a', 117), ('i', 60), ('min', 58), ('to', 56), ('sweet', 47), ('boof', 45), ('no', 41), ('o', 39), ('l', 39)] | avgLoss/100: 9.719978275299072 |  |  | TUTOR.py 100
2025-04-16 17:18:01 | 200 | LR0.00035 | logitMin:-1.3587 | logitMax:-0.2595 | scheduledSampling:0.0000 | lossTUTOR:0.0420 | topTokens[(',', 524), ('a', 155), ('i', 110), ('ten', 78), ('min', 70), ('im', 63), ('to', 61), ('no', 58), ('f', 58), ('ing', 55)] | avgLoss/100: 4.619809474945068 |  |  | TUTOR.py 100
2025-04-16 17:18:48 | 300 | LR0.00035 | logitMin:-1.3581 | logitMax:-0.2601 | scheduledSampling:0.0000 | lossTUTOR:0.0599 | topTokens[(',', 730), ('a', 156), ('i', 154), ('no', 138), ('ing', 135), ('f', 132), ('ad', 123), ('to', 118), ('s', 114), ('al', 106)] | avgLoss/100: 4.937447698116302 |  |  | TUTOR.py 100
2025-04-16 17:19:34 | 400 | LR0.00035 | logitMin:-1.3515 | logitMax:-0.2702 | scheduledSampling:0.0000 | lossTUTOR:0.0386 | topTokens[(',', 907), ('i', 219), ('a', 159), ('ing', 154), ('no', 150), ('f', 134), ('to', 128), ('ad', 124), ('s', 114), ('al', 106)] | avgLoss/100: 4.9669708776474 |  |  | TUTOR.py 100
2025-04-16 17:20:25 | 500 | LR0.00035 | logitMin:-1.3526 | logitMax:-0.2538 | scheduledSampling:0.0000 | lossTUTOR:0.0350 | topTokens[(',', 1087), ('i', 327), ('ing', 188), ('a', 159), ('no', 150), ('to', 140), ('my', 137), ('f', 134), ('ad', 125), ('al', 122)] | avgLoss/100: 4.549360821247101 |  |  | TUTOR.py 100
2025-04-16 17:21:12 | 600 | LR0.00035 | logitMin:-1.3656 | logitMax:-0.2314 | scheduledSampling:0.0000 | lossTUTOR:0.0587 | topTokens[(',', 1212), ('i', 437), ('ing', 194), ('a', 179), ('to', 172), ('is', 152), ('no', 150), ('my', 148), ('f', 134), ('the', 130)] | avgLoss/100: 4.67910808801651 |  |  | TUTOR.py 100
2025-04-16 17:21:59 | 700 | LR0.00035 | logitMin:-1.3784 | logitMax:-0.2418 | scheduledSampling:0.0000 | lossTUTOR:0.0681 | topTokens[(',', 1220), ('i', 460), ('is', 284), ('?', 227), ('ing', 195), ('a', 191), ('to', 174), ('no', 169), ('you', 168), ('!', 165)] | avgLoss/100: 6.098377892971039 |  |  | TUTOR.py 100
2025-04-16 17:22:46 | 800 | LR0.00035 | logitMin:-1.3748 | logitMax:-0.2660 | scheduledSampling:0.0000 | lossTUTOR:0.0609 | topTokens[(',', 1223), ('i', 506), ('is', 416), ('?', 371), ('.', 317), ('you', 230), ('ing', 207), ('a', 193), ('!', 183), ('to', 176)] | avgLoss/100: 5.4150318431854245 |  |  | TUTOR.py 100
2025-04-16 17:23:34 | 900 | LR0.00035 | logitMin:-1.3663 | logitMax:-0.2756 | scheduledSampling:0.0000 | lossTUTOR:0.0533 | topTokens[(',', 1263), ('is', 529), ('i', 520), ('.', 483), ('?', 466), ('you', 334), ('!', 216), ('ing', 214), ('what', 207), ('a', 195)] | avgLoss/100: 4.931804659366608 |  |  | TUTOR.py 100
2025-04-16 17:24:24 | 1000 | LR0.00035 | logitMin:-1.5826 | logitMax:0.5071 | scheduledSampling:0.0000 | lossTUTOR:0.7954 | topTokens[(',', 1301), ('is', 666), ('.', 648), ('?', 616), ('i', 566), ('you', 420), ('to', 254), ('!', 248), ('no', 239), ('are', 228)] | avgLoss/100: 6.259943776130676 |  |  | TUTOR.py 100
2025-04-16 17:25:11 | 1100 | LR0.00035 | logitMin:-1.3655 | logitMax:-0.2422 | scheduledSampling:0.0000 | lossTUTOR:0.0437 | topTokens[(',', 1334), ('.', 786), ('?', 779), ('is', 724), ('i', 602), ('you', 519), ('!', 298), ('no', 279), ('are', 273), ('to', 255)] | avgLoss/100: 6.945853815078736 |  |  | TUTOR.py 100
2025-04-16 17:25:58 | 1200 | LR0.00035 | logitMin:-1.3615 | logitMax:-0.2527 | scheduledSampling:0.0000 | lossTUTOR:0.0404 | topTokens[(',', 1348), ('?', 943), ('.', 939), ('is', 846), ('i', 604), ('you', 554), ('!', 341), ('are', 298), ('f', 296), ('no', 295)] | avgLoss/100: 4.206248774528503 |  |  | TUTOR.py 100
2025-04-16 17:26:44 | 1300 | LR0.00035 | logitMin:-1.3513 | logitMax:-0.2687 | scheduledSampling:0.0000 | lossTUTOR:0.0455 | topTokens[(',', 1348), ('?', 1108), ('.', 1070), ('is', 885), ('you', 659), ('i', 622), ('!', 458), ('what', 342), ('f', 337), ('are', 325)] | avgLoss/100: 4.101040205955505 |  |  | TUTOR.py 100
2025-04-16 17:27:31 | 1400 | LR0.00035 | logitMin:-1.3481 | logitMax:-0.2808 | scheduledSampling:0.0000 | lossTUTOR:0.0427 | topTokens[(',', 1382), ('?', 1266), ('.', 1196), ('is', 960), ('you', 756), ('i', 666), ('!', 559), ('are', 373), ('what', 358), ('f', 342)] | avgLoss/100: 4.97502067565918 |  |  | TUTOR.py 100
2025-04-16 17:28:22 | 1500 | LR0.00035 | logitMin:-1.3657 | logitMax:-0.2404 | scheduledSampling:0.0000 | lossTUTOR:0.0486 | topTokens[('?', 1436), (',', 1387), ('.', 1380), ('is', 1002), ('you', 841), ('i', 698), ('!', 614), ('are', 445), ('what', 374), ('f', 344)] | avgLoss/100: 4.622959582805634 |  |  | TUTOR.py 100
2025-04-16 17:29:09 | 1600 | LR0.00035 | logitMin:-1.3624 | logitMax:-0.2515 | scheduledSampling:0.0000 | lossTUTOR:0.0372 | topTokens[('?', 1576), ('.', 1526), (',', 1420), ('is', 1098), ('you', 919), ('i', 720), ('!', 651), ('are', 506), ('what', 464), ('f', 370)] | avgLoss/100: 4.286008403301239 |  |  | TUTOR.py 100
2025-04-16 17:29:55 | 1700 | LR0.00035 | logitMin:-1.3463 | logitMax:-0.2739 | scheduledSampling:0.0000 | lossTUTOR:0.0303 | topTokens[('?', 1756), ('.', 1679), (',', 1443), ('is', 1241), ('you', 987), ('i', 753), ('!', 700), ('are', 561), ('what', 517), ('f', 372)] | avgLoss/100: 3.9320705580711364 |  |  | TUTOR.py 100
2025-04-16 17:30:42 | 1800 | LR0.00035 | logitMin:-1.3461 | logitMax:-0.2711 | scheduledSampling:0.0000 | lossTUTOR:0.0393 | topTokens[('?', 1906), ('.', 1831), (',', 1443), ('is', 1366), ('you', 1049), ('!', 755), ('i', 754), ('are', 603), ('what', 581), ('f', 385)] | avgLoss/100: 4.585146622657776 |  |  | TUTOR.py 100
2025-04-16 17:31:28 | 1900 | LR0.00035 | logitMin:-1.3596 | logitMax:-0.2466 | scheduledSampling:0.0000 | lossTUTOR:0.0352 | topTokens[('?', 2075), ('.', 1992), (',', 1536), ('is', 1403), ('you', 1144), ('i', 842), ('!', 791), ('are', 661), ('what', 597), ('als', 443)] | avgLoss/100: 4.075203475952148 |  |  | TUTOR.py 100
2025-04-16 17:32:16 | 2000 | LR0.00035 | logitMin:-1.4042 | logitMax:0.0186 | scheduledSampling:0.0000 | lossTUTOR:0.2870 | topTokens[('?', 2188), ('.', 2142), (',', 1550), ('is', 1458), ('you', 1192), ('!', 918), ('i', 857), ('are', 727), ('what', 606), ('als', 505)] | avgLoss/100: 4.579229929447174 |  |  | TUTOR.py 100
2025-04-16 17:33:04 | 2100 | LR0.00035 | logitMin:-1.3460 | logitMax:-0.2732 | scheduledSampling:0.0000 | lossTUTOR:0.0318 | topTokens[('?', 2351), ('.', 2256), (',', 1573), ('is', 1557), ('you', 1220), ('!', 1021), ('i', 877), ('are', 805), ('what', 719), ('als', 540)] | avgLoss/100: 6.402101619243622 |  |  | TUTOR.py 100
2025-04-16 17:33:51 | 2200 | LR0.00035 | logitMin:-1.3432 | logitMax:-0.2691 | scheduledSampling:0.0000 | lossTUTOR:0.0335 | topTokens[('?', 2511), ('.', 2412), ('is', 1624), (',', 1593), ('you', 1319), ('!', 1110), ('i', 912), ('are', 862), ('what', 754), ('als', 547)] | avgLoss/100: 4.309547393321991 |  |  | TUTOR.py 100
2025-04-16 17:34:38 | 2300 | LR0.00035 | logitMin:-1.3536 | logitMax:-0.2576 | scheduledSampling:0.0000 | lossTUTOR:0.0407 | topTokens[('?', 2633), ('.', 2579), ('is', 1733), (',', 1615), ('you', 1334), ('!', 1126), ('i', 912), ('are', 880), ('what', 771), ('als', 613)] | avgLoss/100: 4.28932119846344 |  |  | TUTOR.py 100
2025-04-16 17:35:25 | 2400 | LR0.00035 | logitMin:-1.3506 | logitMax:-0.2316 | scheduledSampling:0.0000 | lossTUTOR:0.0659 | topTokens[('?', 2746), ('.', 2675), ('is', 1780), (',', 1636), ('you', 1395), ('!', 1188), ('i', 927), ('are', 924), ('what', 791), ('als', 651)] | avgLoss/100: 5.254060735702515 |  |  | TUTOR.py 100
2025-04-16 17:36:15 | 2500 | LR0.00035 | logitMin:-1.3532 | logitMax:-0.2258 | scheduledSampling:0.0000 | lossTUTOR:0.0581 | topTokens[('?', 2750), ('.', 2710), ('is', 1819), (',', 1712), ('you', 1396), ('!', 1255), ('i', 928), ('are', 924), ('what', 792), ('als', 651)] | avgLoss/100: 5.918690936565399 |  |  | TUTOR.py 100
2025-04-16 17:37:02 | 2600 | LR0.00035 | logitMin:-1.3467 | logitMax:-0.2291 | scheduledSampling:0.0000 | lossTUTOR:0.0707 | topTokens[('?', 2752), ('.', 2748), (',', 1922), ('is', 1824), ('you', 1397), ('!', 1264), ('i', 973), ('are', 924), ('what', 792), ('als', 651)] | avgLoss/100: 5.895663933753967 |  |  | TUTOR.py 100
2025-04-16 17:37:50 | 2700 | LR0.00035 | logitMin:-1.3527 | logitMax:-0.2312 | scheduledSampling:0.0000 | lossTUTOR:0.0469 | topTokens[('?', 2753), ('.', 2748), (',', 2089), ('is', 1826), ('you', 1397), ('!', 1265), ('i', 1047), ('are', 924), ('what', 792), ('als', 651)] | avgLoss/100: 5.475455088615417 |  |  | TUTOR.py 100
2025-04-16 17:38:35 | 2800 | LR0.00035 | logitMin:-1.3596 | logitMax:-0.2211 | scheduledSampling:0.0000 | lossTUTOR:0.0471 | topTokens[('?', 2762), ('.', 2748), (',', 2279), ('is', 1826), ('you', 1454), ('!', 1279), ('i', 1058), ('are', 924), ('what', 792), ('a', 684)] | avgLoss/100: 5.2389832520484925 |  |  | TUTOR.py 100
2025-04-16 17:39:20 | 2900 | LR0.00035 | logitMin:-1.3681 | logitMax:-0.1941 | scheduledSampling:0.0000 | lossTUTOR:0.0608 | topTokens[('?', 2762), ('.', 2755), (',', 2471), ('is', 1826), ('you', 1455), ('!', 1322), ('i', 1058), ('are', 924), ('what', 792), ('a', 774)] | avgLoss/100: 4.88938015460968 |  |  | TUTOR.py 100
2025-04-16 17:40:08 | 3000 | LR0.00035 | logitMin:-1.4069 | logitMax:-0.0740 | scheduledSampling:0.0000 | lossTUTOR:0.1287 | topTokens[('.', 2775), ('?', 2762), (',', 2676), ('is', 1826), ('you', 1455), ('!', 1374), ('i', 1080), ('are', 924), ('a', 810), ('what', 792)] | avgLoss/100: 4.3769318699836735 |  |  | TUTOR.py 100
2025-04-16 17:40:55 | 3100 | LR0.00035 | logitMin:-1.3658 | logitMax:-0.1865 | scheduledSampling:0.0000 | lossTUTOR:0.0514 | topTokens[(',', 2919), ('.', 2784), ('?', 2762), ('is', 1826), ('you', 1473), ('!', 1435), ('i', 1089), ('are', 942), ('a', 854), ('what', 792)] | avgLoss/100: 4.982669832706452 |  |  | TUTOR.py 100
2025-04-16 17:41:41 | 3200 | LR0.00035 | logitMin:-1.3504 | logitMax:-0.2278 | scheduledSampling:0.0000 | lossTUTOR:0.0343 | topTokens[(',', 3027), ('.', 2785), ('?', 2776), ('is', 1841), ('you', 1491), ('!', 1457), ('i', 1090), ('are', 943), ('a', 932), ('what', 792)] | avgLoss/100: 5.996179411411285 |  |  | TUTOR.py 100
2025-04-16 17:42:28 | 3300 | LR0.00035 | logitMin:-1.3575 | logitMax:-0.1891 | scheduledSampling:0.0000 | lossTUTOR:0.0383 | topTokens[(',', 3199), ('.', 2800), ('?', 2776), ('is', 1861), ('!', 1527), ('you', 1524), ('i', 1090), ('a', 982), ('are', 944), ('to', 885)] | avgLoss/100: 4.216469657421112 |  |  | TUTOR.py 100
2025-04-16 17:43:15 | 3400 | LR0.00035 | logitMin:-1.3567 | logitMax:-0.1983 | scheduledSampling:0.0000 | lossTUTOR:0.0395 | topTokens[(',', 3410), ('.', 2836), ('?', 2776), ('is', 1862), ('!', 1602), ('you', 1550), ('i', 1111), ('a', 1013), ('to', 997), ('are', 944)] | avgLoss/100: 4.162033720016479 |  |  | TUTOR.py 100

--- 2025-04-16 17:43:46 --- babyLLM 'right, last time i got to step 19003... want to restart from there?'  - charis: '22000' - babyLLM 'damn that's specific! heading to step 22000... what am i learning today?' - charis: ''
2025-04-16 17:44:32 | 100 | LR0.00035 | logitMin:-1.3597 | logitMax:-0.2126 | scheduledSampling:0.0000 | lossTUTOR:0.0450 | topTokens[(',', 270), ('to', 92), ('called', 76), ('and', 66), ('he', 60), ('they', 57), ('!', 56), ('going', 55), ("'s", 48), ('y', 46)] | avgLoss/100: 4.7860634326934814 |  |  | TUTOR.py 100
2025-04-16 17:45:17 | 200 | LR0.00035 | logitMin:-1.3455 | logitMax:-0.2474 | scheduledSampling:0.0000 | lossTUTOR:0.0375 | topTokens[(',', 374), ('to', 145), ('a', 115), ('they', 90), ('and', 85), ('!', 85), ('going', 84), ('called', 76), ('keep', 73), ('he', 67)] | avgLoss/100: 5.04420086145401 |  |  | TUTOR.py 100
2025-04-16 17:46:03 | 300 | LR0.00035 | logitMin:-1.3603 | logitMax:-0.2175 | scheduledSampling:0.0000 | lossTUTOR:0.0478 | topTokens[(',', 547), ('to', 228), ('a', 162), ('!', 159), ('they', 133), ('going', 124), ('he', 123), ('and', 107), ('keep', 103), ('d', 96)] | avgLoss/100: 4.115272481441497 |  |  | TUTOR.py 100
2025-04-16 17:46:49 | 400 | LR0.00035 | logitMin:-1.3575 | logitMax:-0.2178 | scheduledSampling:0.0000 | lossTUTOR:0.0322 | topTokens[(',', 773), ('to', 344), ('they', 244), ('!', 224), ('a', 196), ('going', 177), ('he', 170), ('and', 139), ('ch', 139), ('felt', 132)] | avgLoss/100: 3.9884084987640382 |  |  | TUTOR.py 100
2025-04-16 17:47:39 | 500 | LR0.00035 | logitMin:-1.3511 | logitMax:-0.2135 | scheduledSampling:0.0000 | lossTUTOR:0.0398 | topTokens[(',', 1026), ('to', 394), ('they', 327), ('!', 279), ('and', 242), ('a', 217), ('going', 212), ('ch', 205), ('called', 190), ('he', 183)] | avgLoss/100: 4.6520226645469664 |  |  | TUTOR.py 100
2025-04-16 17:48:25 | 600 | LR0.00035 | logitMin:-1.3100 | logitMax:-0.2388 | scheduledSampling:0.0000 | lossTUTOR:0.0000 | topTokens[(',', 1177), ('to', 483), ('they', 384), ('!', 311), ('and', 261), ('going', 248), ('boof', 235), ('ch', 230), ('a', 229), ('the', 224)] | avgLoss/100: 3.70530173999432 |  |  | TUTOR.py 100
2025-04-16 17:49:12 | 700 | LR0.00035 | logitMin:-1.3585 | logitMax:-0.2015 | scheduledSampling:0.0000 | lossTUTOR:0.0376 | topTokens[(',', 1297), ('boof', 528), ('to', 518), ('they', 428), ('!', 323), ('going', 274), ('ch', 273), ('and', 272), ('a', 252), ('the', 227)] | avgLoss/100: 4.884763671137335 |  |  | TUTOR.py 100
2025-04-16 17:49:59 | 800 | LR0.00035 | logitMin:-1.3592 | logitMax:-0.2033 | scheduledSampling:0.0000 | lossTUTOR:0.0420 | topTokens[(',', 1485), ('to', 583), ('boof', 531), ('they', 508), ('!', 405), ('ch', 331), ('going', 328), ('and', 316), ('a', 281), ('the', 244)] | avgLoss/100: 4.70795168876648 |  |  | TUTOR.py 100
2025-04-16 17:50:46 | 900 | LR0.00035 | logitMin:-1.3547 | logitMax:-0.2082 | scheduledSampling:0.0000 | lossTUTOR:0.0419 | topTokens[(',', 1699), ('to', 663), ('they', 535), ('boof', 531), ('!', 450), ('ch', 386), ('going', 375), ('a', 357), ('and', 339), ('he', 268)] | avgLoss/100: 4.2642350769042965 |  |  | TUTOR.py 100
2025-04-16 17:51:36 | 1000 | LR0.00035 | logitMin:-1.3699 | logitMax:-0.1360 | scheduledSampling:0.0000 | lossTUTOR:0.1035 | topTokens[(',', 1875), ('to', 736), ('they', 632), ('boof', 531), ('!', 500), ('a', 407), ('ch', 404), ('going', 400), ('and', 382), ('keep', 293)] | avgLoss/100: 4.199582636356354 |  |  | TUTOR.py 100
2025-04-16 17:52:23 | 1100 | LR0.00035 | logitMin:-1.3367 | logitMax:-0.2301 | scheduledSampling:0.0000 | lossTUTOR:0.0426 | topTokens[(',', 2012), ('to', 802), ('they', 662), ('boof', 623), ('!', 515), ('going', 444), ('ch', 440), ('a', 408), ('and', 402), ('keep', 331)] | avgLoss/100: 4.505032632350922 |  |  | TUTOR.py 100
2025-04-16 17:53:10 | 1200 | LR0.00035 | logitMin:-1.3565 | logitMax:-0.2181 | scheduledSampling:0.0000 | lossTUTOR:0.0459 | topTokens[(',', 2226), ('to', 884), ('they', 663), ('boof', 631), ('!', 559), ('going', 499), ('a', 488), ('ch', 477), ('and', 402), ('keep', 369)] | avgLoss/100: 4.735188274383545 |  |  | TUTOR.py 100
2025-04-16 17:53:56 | 1300 | LR0.00035 | logitMin:-1.3537 | logitMax:-0.2098 | scheduledSampling:0.0000 | lossTUTOR:0.0364 | topTokens[(',', 2398), ('to', 958), ('they', 699), ('boof', 632), ('!', 597), ('a', 561), ('going', 520), ('ch', 504), ('and', 414), ('the', 387)] | avgLoss/100: 4.381643869876862 |  |  | TUTOR.py 100
2025-04-16 17:54:43 | 1400 | LR0.00035 | logitMin:-1.3572 | logitMax:-0.2004 | scheduledSampling:0.0000 | lossTUTOR:0.0469 | topTokens[(',', 2622), ('to', 1042), ('they', 731), ('boof', 632), ('a', 631), ('!', 619), ('ch', 575), ('going', 556), ('and', 455), ('the', 442)] | avgLoss/100: 4.577362613677979 |  |  | TUTOR.py 100
2025-04-16 17:55:32 | 1500 | LR0.00035 | logitMin:-1.3395 | logitMax:-0.2337 | scheduledSampling:0.0000 | lossTUTOR:0.1286 | topTokens[(',', 2764), ('to', 1093), ('they', 779), ('a', 672), ('!', 650), ('boof', 632), ('going', 607), ('ch', 594), ('and', 489), ('the', 470)] | avgLoss/100: 4.4322188138961796 |  |  | TUTOR.py 100
2025-04-16 17:56:17 | 1600 | LR0.00035 | logitMin:-1.3499 | logitMax:-0.2202 | scheduledSampling:0.0000 | lossTUTOR:0.0506 | topTokens[(',', 2894), ('to', 1126), ('they', 816), ('a', 683), ('!', 655), ('going', 639), ('boof', 633), ('ch', 595), ('and', 531), ('the', 483)] | avgLoss/100: 6.505750358104706 |  |  | TUTOR.py 100
2025-04-16 17:57:03 | 1700 | LR0.00035 | logitMin:-1.3532 | logitMax:-0.2109 | scheduledSampling:0.0000 | lossTUTOR:0.0377 | topTokens[(',', 3149), ('to', 1166), ('they', 833), ('a', 730), ('ch', 675), ('going', 668), ('!', 668), ('and', 649), ('boof', 633), ('roid', 510)] | avgLoss/100: 4.284877569675445 |  |  | TUTOR.py 100
2025-04-16 17:57:49 | 1800 | LR0.00035 | logitMin:-1.3569 | logitMax:-0.2017 | scheduledSampling:0.0000 | lossTUTOR:0.0472 | topTokens[(',', 3333), ('to', 1249), ('they', 890), ('a', 819), ('!', 733), ('going', 731), ('ch', 704), ('and', 671), ('boof', 633), ('roid', 571)] | avgLoss/100: 4.039883189201355 |  |  | TUTOR.py 100
2025-04-16 17:58:36 | 1900 | LR0.00035 | logitMin:-1.3441 | logitMax:-0.1980 | scheduledSampling:0.0000 | lossTUTOR:0.0264 | topTokens[(',', 3509), ('to', 1290), ('they', 907), ('a', 877), ('!', 818), ('going', 755), ('ch', 725), ('and', 694), ('roid', 635), ('boof', 633)] | avgLoss/100: 4.600110971927643 |  |  | TUTOR.py 100
2025-04-16 17:59:27 | 2000 | LR0.00035 | logitMin:-1.3885 | logitMax:-0.0974 | scheduledSampling:0.0000 | lossTUTOR:0.1023 | topTokens[(',', 3591), ('to', 1292), ('!', 1041), ('a', 927), ('they', 909), ('i', 902), ('going', 772), ('ch', 725), ('and', 694), ('roid', 635)] | avgLoss/100: 3.201291263103485 |  |  | TUTOR.py 100
2025-04-16 18:00:13 | 2100 | LR0.00035 | logitMin:-1.3076 | logitMax:-0.3147 | scheduledSampling:0.0000 | lossTUTOR:0.0528 | topTokens[(',', 3642), ('to', 1331), ('!', 1057), ('a', 969), ('i', 912), ('they', 911), ('going', 774), ('and', 731), ('ch', 725), ('it', 645)] | avgLoss/100: 6.529908909797668 |  |  | TUTOR.py 100
2025-04-16 18:00:59 | 2200 | LR0.00035 | logitMin:-1.3333 | logitMax:-0.2200 | scheduledSampling:0.0000 | lossTUTOR:0.0402 | topTokens[(',', 3646), ('to', 1391), ('!', 1091), ('a', 970), ('i', 926), ('they', 912), ('going', 775), ('and', 752), ('ch', 725), ('the', 680)] | avgLoss/100: 4.708498430252075 |  |  | TUTOR.py 100
2025-04-16 18:01:45 | 2300 | LR0.00035 | logitMin:-1.3350 | logitMax:-0.2284 | scheduledSampling:0.0000 | lossTUTOR:0.0343 | topTokens[(',', 3669), ('to', 1446), ('!', 1130), ('a', 970), ('i', 965), ('they', 912), ('going', 776), ('and', 753), ('ch', 725), ('the', 681)] | avgLoss/100: 3.820597558021545 |  |  | TUTOR.py 100
2025-04-16 18:02:31 | 2400 | LR0.00035 | logitMin:-1.3399 | logitMax:-0.2279 | scheduledSampling:0.0000 | lossTUTOR:0.0290 | topTokens[(',', 3712), ('to', 1528), ('!', 1162), ('i', 1011), ('a', 970), ('they', 912), ('going', 776), ('and', 753), ('ch', 725), ('the', 682)] | avgLoss/100: 3.1402528738975524 |  |  | TUTOR.py 100
2025-04-16 18:03:21 | 2500 | LR0.00035 | logitMin:-1.3365 | logitMax:-0.2159 | scheduledSampling:0.0000 | lossTUTOR:0.0281 | topTokens[(',', 3742), ('to', 1595), ('!', 1223), ('i', 1050), ('a', 970), ('they', 912), ('going', 776), ('and', 753), ('ch', 725), ('the', 683)] | avgLoss/100: 3.0026779866218565 |  |  | TUTOR.py 100
2025-04-16 18:04:07 | 2600 | LR0.00035 | logitMin:-1.3351 | logitMax:-0.2230 | scheduledSampling:0.0000 | lossTUTOR:0.0219 | topTokens[(',', 3766), ('to', 1663), ('!', 1261), ('i', 1121), ('a', 970), ('they', 912), ('going', 777), ('-', 772), ('and', 753), ('ch', 725)] | avgLoss/100: 2.7930036926269532 |  |  | TUTOR.py 100
2025-04-16 18:04:54 | 2700 | LR0.00035 | logitMin:-1.3831 | logitMax:-0.1453 | scheduledSampling:0.0000 | lossTUTOR:0.0200 | topTokens[(',', 3805), ('to', 1723), ('!', 1289), ('i', 1167), ('a', 970), ('they', 912), ('-', 882), ('going', 777), (':', 772), ('and', 753)] | avgLoss/100: 1.9650793182849884 |  |  | TUTOR.py 100
2025-04-16 18:05:40 | 2800 | LR0.00035 | logitMin:-1.3783 | logitMax:-0.1490 | scheduledSampling:0.0000 | lossTUTOR:0.0150 | topTokens[(',', 3817), ('to', 1796), ('!', 1335), ('i', 1213), ('-', 1009), ('a', 970), ('they', 912), (':', 849), ("'", 782), ('going', 777)] | avgLoss/100: 1.618589034676552 |  |  | TUTOR.py 100
2025-04-16 18:06:27 | 2900 | LR0.00035 | logitMin:-1.3422 | logitMax:-0.2177 | scheduledSampling:0.0000 | lossTUTOR:0.0114 | topTokens[(',', 3843), ('to', 1858), ('!', 1395), ('i', 1265), ('-', 1118), ('a', 970), (':', 938), ('they', 912), ("'", 873), ("'", 870)] | avgLoss/100: 1.4149998584389687 |  |  | TUTOR.py 100
2025-04-16 18:07:18 | 3000 | LR0.00035 | logitMin:-2.4577 | logitMax:4.4668 | scheduledSampling:0.0000 | lossTUTOR:3.5189 | topTokens[(',', 3869), ('to', 1925), ('!', 1437), ('i', 1319), ('-', 1228), (':', 1062), ('a', 970), ("'", 963), ('0', 956), ("'", 945)] | avgLoss/100: 5.416760101914406 |  |  | TUTOR.py 100
2025-04-16 18:08:04 | 3100 | LR0.00035 | logitMin:-1.3389 | logitMax:-0.1856 | scheduledSampling:0.0000 | lossTUTOR:0.0234 | topTokens[(',', 3919), ('to', 2021), ('!', 1470), ('i', 1367), ('-', 1341), (':', 1127), ("'", 1085), ("'", 1041), ('0', 1036), ('a', 970)] | avgLoss/100: 6.407004232406616 |  |  | TUTOR.py 100

--- 2025-04-16 18:17:09 --- babyLLM 'right, last time i got to step 22001... want to restart from there?'  - charis: '25000' - babyLLM 'damn that's specific! heading to step 25000... what am i learning today?' - charis: ''
2025-04-16 18:17:59 | 100 | LR0.00035 | logitMin:-1.3385 | logitMax:-0.1880 | scheduledSampling:0.0000 | lossTUTOR:0.0223 | topTokens[('to', 116), ('-', 109), ("'", 102), ("'", 95), (':', 94), ('step', 79), ('0', 69), ('', 65), ('?', 58), ('20', 55)] | avgLoss/100: 4.0366040706634525 |  |  | TUTOR.py 100
2025-04-16 18:18:49 | 200 | LR0.00035 | logitMin:-1.3461 | logitMax:-0.1834 | scheduledSampling:0.0000 | lossTUTOR:0.0234 | topTokens[('-', 221), ("'", 192), ('to', 188), (':', 183), ("'", 182), ('0', 149), ('step', 141), ('', 113), ('?', 112), ('!', 109)] | avgLoss/100: 2.394532837867737 |  |  | TUTOR.py 100
2025-04-16 18:19:41 | 300 | LR0.00035 | logitMin:-1.3323 | logitMax:-0.1940 | scheduledSampling:0.0000 | lossTUTOR:0.0182 | topTokens[('-', 344), ("'", 281), (':', 281), ("'", 277), ('to', 240), ('0', 216), ('2', 201), ('step', 181), ('baby', 163), ('', 160)] | avgLoss/100: 2.1883023476600645 |  |  | TUTOR.py 100
2025-04-16 18:20:33 | 400 | LR0.00035 | logitMin:-1.3593 | logitMax:-0.0850 | scheduledSampling:0.0000 | lossTUTOR:0.0108 | topTokens[('-', 473), ("'", 395), ("'", 382), (':', 368), ('to', 320), ('0', 291), ('2', 248), ('step', 235), ('baby', 222), ('', 216)] | avgLoss/100: 1.294219560623169 |  |  | TUTOR.py 100

--- 2025-04-16 18:23:36 --- babyLLM 'right, last time i got to step 25001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 25001! what am i learning today?' - charis: ''
2025-04-16 18:24:58 | 100 | LR0.00035 | logitMin:-1.3341 | logitMax:-0.1699 | scheduledSampling:0.0000 | lossTUTOR:0.0120 | topTokens[("'", 128), ('-', 128), ("'", 115), (':', 96), ('to', 93), ('0', 72), ('?', 68), ('rest', 66), ('step', 62), ('', 59)] | avgLoss/100: 11.384116859436036 |  |  | TUTOR.py 100
2025-04-16 18:26:21 | 200 | LR0.00035 | logitMin:-1.3436 | logitMax:-0.1735 | scheduledSampling:0.0000 | lossTUTOR:0.0160 | topTokens[('-', 249), ("'", 219), ("'", 202), (':', 175), ('to', 160), ('0', 144), ('', 120), ('?', 115), ('step', 114), ('i', 112)] | avgLoss/100: 1.3785156828165055 |  |  | TUTOR.py 100

--- 2025-04-16 18:40:32 --- babyLLM 'right, last time i got to step 25002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 25002! what am i learning today?' - charis: ''
2025-04-16 18:42:08 | 100 | LR0.00035 | logitMin:-1.3359 | logitMax:-0.1566 | scheduledSampling:0.0000 | lossTUTOR:0.0130 | topTokens[('-', 135), ("'", 131), ("'", 109), ('to', 98), (':', 97), ('0', 79), ('step', 77), ('charis', 63), ('?', 58), ('baby', 54)] | avgLoss/100: 6.5115539169311525 |  |  | TUTOR.py 100

--- 2025-04-16 18:48:53 --- babyLLM 'right, last time i got to step 25003... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 25003! what am i learning today?' - charis: ''
2025-04-16 18:50:15 | 100 | LR0.00035 | logitMin:-1.3451 | logitMax:-0.1512 | scheduledSampling:0.0000 | lossTUTOR:0.0164 | topTokens[('-', 125), ("'", 124), ("'", 115), (':', 92), ('to', 92), ('step', 70), ('0', 63), ('charis', 61), ('ll', 57), ('m', 57)] | avgLoss/100: 4.92889235496521 |  |  | TUTOR.py 100
2025-04-16 18:51:40 | 200 | LR0.00035 | logitMin:-1.3435 | logitMax:-0.1736 | scheduledSampling:0.0000 | lossTUTOR:0.0221 | topTokens[('-', 245), ("'", 226), ("'", 202), (':', 184), ('to', 163), ('0', 145), ('step', 116), ('!', 116), ('?', 106), ('charis', 105)] | avgLoss/100: 1.4286726659536362 |  |  | TUTOR.py 100
2025-04-16 18:53:04 | 300 | LR0.00035 | logitMin:-1.3129 | logitMax:-0.1821 | scheduledSampling:0.0000 | lossTUTOR:0.0066 | topTokens[('-', 368), ("'", 305), (':', 297), ("'", 295), ('to', 230), ('0', 217), ('2', 181), ('m', 162), ('ll', 161), ('1', 157)] | avgLoss/100: 1.303134129047394 |  |  | TUTOR.py 100
2025-04-16 18:54:28 | 400 | LR0.00035 | logitMin:-1.3322 | logitMax:-0.1588 | scheduledSampling:0.0000 | lossTUTOR:0.0042 | topTokens[('-', 484), ("'", 413), ("'", 393), (':', 391), ('to', 316), ('0', 287), ('2', 245), ('1', 216), ('ll', 208), ('charis', 206)] | avgLoss/100: 0.8545314362645149 |  |  | TUTOR.py 100
2025-04-16 18:55:57 | 500 | LR0.00035 | logitMin:-1.3647 | logitMax:-0.1319 | scheduledSampling:0.0000 | lossTUTOR:0.0162 | topTokens[('-', 616), ("'", 501), ("'", 497), (':', 477), ('to', 385), ('0', 362), ('1', 311), ('2', 274), ('', 260), ('charis', 258)] | avgLoss/100: 0.8944786167144776 |  |  | TUTOR.py 100

--- 2025-04-16 18:56:43 --- babyLLM 'right, last time i got to step 25004... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 25004! what am i learning today?' - charis: ''
2025-04-16 18:58:11 | 100 | LR0.00035 | logitMin:-1.3515 | logitMax:-0.1214 | scheduledSampling:0.0000 | lossTUTOR:0.0104 | topTokens[('-', 131), ("'", 118), ("'", 114), ('to', 106), (':', 94), ('0', 78), ('step', 75), ('', 72), ('charis', 69), ('?', 58)] | avgLoss/100: 9.288636931180953 |  |  | TUTOR.py 100

--- 2025-04-16 19:12:17 --- babyLLM 'right, last time i got to step 25005... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 25005! what am i learning today?' - charis: ''
2025-04-16 19:12:30 | 100 | LR0.00035 | logitMin:-1.3325 | logitMax:-0.1049 | scheduledSampling:0.0000 | lossTUTOR:0.0010 | topTokens[('-', 231), ("'", 214), ('step', 136), ("'", 115), ('0', 81), (':', 72), ('to', 69), ('rest', 50), ('charis', 46), ('?', 43)] | avgLoss/100: 0.10000001639127731 |  |  | TUTOR.py 100
2025-04-16 19:12:42 | 200 | LR0.00035 | logitMin:-1.3344 | logitMax:-0.1928 | scheduledSampling:0.0000 | lossTUTOR:0.0010 | topTokens[('-', 474), ("'", 411), ("'", 254), ('0', 195), ('step', 179), (':', 157), ('to', 125), ('charis', 98), ('?', 90), ('00', 88)] | avgLoss/100: 0.10000001639127731 |  |  | TUTOR.py 100
2025-04-16 19:12:54 | 300 | LR0.00035 | logitMin:-1.3343 | logitMax:-0.1611 | scheduledSampling:0.0000 | lossTUTOR:0.0010 | topTokens[('-', 704), ("'", 590), ("'", 382), ('0', 292), (':', 288), ('step', 211), ('to', 181), ('00', 137), ('...', 137), ('charis', 134)] | avgLoss/100: 0.10000001639127731 |  |  | TUTOR.py 100
2025-04-16 19:13:07 | 400 | LR0.00035 | logitMin:-1.3365 | logitMax:-0.1299 | scheduledSampling:0.0000 | lossTUTOR:0.0010 | topTokens[('-', 946), ("'", 784), ("'", 522), ('0', 392), (':', 364), ('to', 259), ('step', 238), ('charis', 210), ('?', 187), ('...', 177)] | avgLoss/100: 0.10000001639127731 |  |  | TUTOR.py 100
2025-04-16 19:13:23 | 500 | LR0.00035 | logitMin:-1.3386 | logitMax:-0.1656 | scheduledSampling:0.0000 | lossTUTOR:0.0010 | topTokens[('-', 1269), ("'", 976), ("'", 647), ('0', 484), (':', 425), ('to', 323), ('step', 280), ('charis', 253), ('?', 231), ('00', 216)] | avgLoss/100: 0.10000001639127731 |  |  | TUTOR.py 100
2025-04-16 19:13:35 | 600 | LR0.00035 | logitMin:-1.3288 | logitMax:-0.1532 | scheduledSampling:0.0000 | lossTUTOR:0.0010 | topTokens[('-', 1554), ("'", 1185), ("'", 774), ('0', 579), (':', 503), ('to', 384), ('step', 308), ('charis', 287), ('?', 267), ('00', 258)] | avgLoss/100: 0.10000001639127731 |  |  | TUTOR.py 100

--- 2025-04-16 19:14:20 --- babyLLM 'right, last time i got to step 25006... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 25006! what am i learning today?' - charis: ''
2025-04-16 19:15:43 | 100 | LR0.00035 | logitMin:-1.3258 | logitMax:-0.1473 | scheduledSampling:0.0000 | lossTUTOR:0.0106 | topTokens[('-', 132), ("'", 127), ("'", 114), (':', 106), ('to', 88), ('0', 66), ('!', 65), ('charis', 63), ('step', 58), ('2', 58)] | avgLoss/100: 5.52289104104042 |  |  | TUTOR.py 100

--- 2025-04-16 19:40:21 --- babyLLM 'right, last time i got to step 25007... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 25007! what am i learning today?' - charis: ''
2025-04-16 19:41:43 | 100 | LR0.00035 | logitMin:-1.3309 | logitMax:-0.1693 | scheduledSampling:0.0000 | lossTUTOR:0.0109 | topTokens[('-', 136), ("'", 111), ("'", 107), (':', 99), ('0', 77), ('!', 71), ('to', 66), ('m', 64), ('step', 51), ('rest', 51)] | avgLoss/100: 4.123714619874955 |  |  | TUTOR.py 100
2025-04-16 19:43:07 | 200 | LR0.00035 | logitMin:-1.3276 | logitMax:-0.1967 | scheduledSampling:0.0000 | lossTUTOR:0.0185 | topTokens[('-', 268), ("'", 220), ("'", 202), (':', 193), ('0', 161), ('to', 132), ('!', 124), ('2', 108), ('charis', 101), ('m', 101)] | avgLoss/100: 1.3189637452363967 |  |  | TUTOR.py 100
2025-04-16 19:44:33 | 300 | LR0.00035 | logitMin:-1.3704 | logitMax:-0.0750 | scheduledSampling:0.0000 | lossTUTOR:0.0126 | topTokens[('-', 377), (':', 310), ("'", 293), ("'", 284), ('0', 219), ('to', 212), ('2', 179), ('!', 168), ('m', 157), ('i', 157)] | avgLoss/100: 1.0234506136178971 |  |  | TUTOR.py 100
2025-04-16 19:45:55 | 400 | LR0.00035 | logitMin:-1.3642 | logitMax:-0.0435 | scheduledSampling:0.0000 | lossTUTOR:0.0008 | topTokens[('-', 499), ("'", 404), (':', 403), ("'", 391), ('0', 308), ('to', 287), ('2', 237), ('!', 213), ('1', 207), ('baby', 204)] | avgLoss/100: 0.7004906513541936 |  |  | TUTOR.py 100

--- 2025-04-16 19:47:20 --- babyLLM 'right, last time i got to step 25008... want to restart from there?'  - charis: '27500' - babyLLM 'damn that's specific! heading to step 27500... what am i learning today?' - charis: ''
2025-04-16 19:48:42 | 100 | LR0.00035 | logitMin:-1.3738 | logitMax:-0.2274 | scheduledSampling:0.0000 | lossTUTOR:0.0300 | topTokens[('!', 172), ('charis', 145), ('step', 113), (':', 89), ("'s", 88), ('have', 88), ('will', 76), ('00', 71), ('know', 71), ('rest', 65)] | avgLoss/100: 29.294227650165556 |  |  | TUTOR.py 100
2025-04-16 19:50:04 | 200 | LR0.00035 | logitMin:-1.3685 | logitMax:-0.2320 | scheduledSampling:0.0000 | lossTUTOR:0.0267 | topTokens[('have', 319), ('will', 312), ('charis', 247), ('!', 235), ('.', 210), ('felt', 178), ('step', 146), ('elodie', 126), ("'s", 123), ('know', 114)] | avgLoss/100: 4.062540066242218 |  |  | TUTOR.py 100
2025-04-16 19:51:28 | 300 | LR0.00035 | logitMin:-1.3628 | logitMax:-0.2434 | scheduledSampling:0.0000 | lossTUTOR:0.0334 | topTokens[('will', 571), ('have', 536), ('.', 404), ('charis', 367), ('!', 344), ('felt', 276), ('elodie', 204), ('you', 162), ('step', 154), ('know', 134)] | avgLoss/100: 3.8739371967315672 |  |  | TUTOR.py 100
2025-04-16 19:52:51 | 400 | LR0.00035 | logitMin:-1.3603 | logitMax:-0.2485 | scheduledSampling:0.0000 | lossTUTOR:0.0250 | topTokens[('will', 796), ('have', 749), ('.', 541), ('!', 444), ('charis', 413), ('felt', 359), ('elodie', 265), ('know', 210), ('n', 193), ('you', 188)] | avgLoss/100: 3.0982609391212463 |  |  | TUTOR.py 100
2025-04-16 19:54:18 | 500 | LR0.00035 | logitMin:-1.3425 | logitMax:-0.2514 | scheduledSampling:0.0000 | lossTUTOR:0.0544 | topTokens[('will', 1030), ('have', 986), ('.', 677), ('!', 554), ('charis', 478), ('felt', 467), ('elodie', 335), ('know', 279), ('you', 262), ('n', 253)] | avgLoss/100: 3.529934062957764 |  |  | TUTOR.py 100
2025-04-16 19:55:40 | 600 | LR0.00035 | logitMin:-1.3516 | logitMax:-0.3130 | scheduledSampling:0.0000 | lossTUTOR:0.0634 | topTokens[('will', 1073), ('have', 1043), ('.', 720), ('!', 574), ('felt', 494), ('charis', 486), ('elodie', 342), ('you', 336), ('know', 280), ('n', 258)] | avgLoss/100: 8.637000823020935 |  |  | TUTOR.py 100
2025-04-16 19:57:04 | 700 | LR0.00035 | logitMin:-1.3422 | logitMax:-0.3456 | scheduledSampling:0.0000 | lossTUTOR:0.0699 | topTokens[('will', 1086), ('have', 1059), ('.', 752), ('!', 583), ('felt', 500), ('charis', 494), ('you', 347), ('elodie', 345), (',', 343), ('know', 285)] | avgLoss/100: 9.09870898246765 |  |  | TUTOR.py 100
2025-04-16 19:58:29 | 800 | LR0.00035 | logitMin:-1.3236 | logitMax:-0.3774 | scheduledSampling:0.0000 | lossTUTOR:0.1162 | topTokens[('will', 1089), ('have', 1063), ('.', 754), (',', 645), ('!', 619), ('felt', 502), ('charis', 495), ('you', 430), ('it', 372), ('elodie', 349)] | avgLoss/100: 6.196788909435273 |  |  | TUTOR.py 100
2025-04-16 19:59:54 | 900 | LR0.00035 | logitMin:-1.3306 | logitMax:-0.4087 | scheduledSampling:0.0000 | lossTUTOR:0.0919 | topTokens[(',', 1110), ('will', 1091), ('have', 1069), ('.', 758), ('!', 640), ('you', 534), ('felt', 507), ('charis', 498), ('it', 377), ('elodie', 351)] | avgLoss/100: 8.986709206104278 |  |  | TUTOR.py 100
2025-04-16 20:01:23 | 1000 | LR0.00035 | logitMin:-2.8852 | logitMax:3.2813 | scheduledSampling:0.0000 | lossTUTOR:4.0948 | topTokens[(',', 1391), ('will', 1094), ('have', 1071), ('.', 761), ('!', 649), ('you', 544), ('felt', 510), ('charis', 501), ('it', 391), ('elodie', 351)] | avgLoss/100: 10.08021491765976 |  |  | TUTOR.py 100
2025-04-16 20:02:47 | 1100 | LR0.00035 | logitMin:-1.3140 | logitMax:-0.3939 | scheduledSampling:0.0000 | lossTUTOR:0.0488 | topTokens[(',', 1690), ('will', 1094), ('have', 1087), ('.', 791), ('you', 685), ('!', 662), ('felt', 510), ('charis', 501), ('it', 403), ('i', 368)] | avgLoss/100: 12.165805947780608 |  |  | TUTOR.py 100
2025-04-16 20:04:11 | 1200 | LR0.00035 | logitMin:-1.3238 | logitMax:-0.3868 | scheduledSampling:0.0000 | lossTUTOR:0.0777 | topTokens[(',', 1792), ('will', 1111), ('have', 1110), ('.', 830), ('you', 691), ('!', 669), ('felt', 510), ('charis', 501), ('i', 475), ('it', 404)] | avgLoss/100: 6.883648517131806 |  |  | TUTOR.py 100
2025-04-16 20:05:36 | 1300 | LR0.00035 | logitMin:-1.3209 | logitMax:-0.4032 | scheduledSampling:0.0000 | lossTUTOR:0.0761 | topTokens[(',', 2053), ('have', 1121), ('will', 1115), ('.', 835), ('you', 693), ('!', 669), ('i', 525), ('felt', 513), ('charis', 506), ('it', 456)] | avgLoss/100: 7.1942169260978694 |  |  | TUTOR.py 100
2025-04-16 20:06:59 | 1400 | LR0.00035 | logitMin:-1.3314 | logitMax:-0.4114 | scheduledSampling:0.0000 | lossTUTOR:0.0507 | topTokens[(',', 2140), ('have', 1124), ('will', 1117), ('.', 893), ('you', 735), ('!', 675), ('i', 554), ('felt', 513), ('charis', 506), ('it', 458)] | avgLoss/100: 6.475657789707184 |  |  | TUTOR.py 100
2025-04-16 20:08:26 | 1500 | LR0.00035 | logitMin:-1.3153 | logitMax:-0.4124 | scheduledSampling:0.0000 | lossTUTOR:0.0334 | topTokens[(',', 2141), ('have', 1124), ('will', 1117), ('.', 1009), ('you', 920), ('!', 719), ('i', 642), ('?', 523), ('felt', 513), ('charis', 507)] | avgLoss/100: 4.1113103580474855 |  |  | TUTOR.py 100
2025-04-16 20:09:50 | 1600 | LR0.00035 | logitMin:-1.3313 | logitMax:-0.4131 | scheduledSampling:0.0000 | lossTUTOR:0.0507 | topTokens[(',', 2153), ('will', 1170), ('.', 1133), ('have', 1124), ('you', 1036), ('!', 788), ('i', 758), ('?', 694), ('felt', 513), ('charis', 507)] | avgLoss/100: 4.328507552146911 |  |  | TUTOR.py 100
2025-04-16 20:11:13 | 1700 | LR0.00035 | logitMin:-1.3175 | logitMax:-0.4063 | scheduledSampling:0.0000 | lossTUTOR:0.0433 | topTokens[(',', 2168), ('.', 1267), ('will', 1173), ('have', 1124), ('you', 1113), ('?', 838), ('!', 821), ('i', 812), ('is', 596), ('to', 518)] | avgLoss/100: 3.7697561287879946 |  |  | TUTOR.py 100
2025-04-16 20:12:37 | 1800 | LR0.00035 | logitMin:-1.3312 | logitMax:-0.4057 | scheduledSampling:0.0000 | lossTUTOR:0.0651 | topTokens[(',', 2186), ('.', 1360), ('you', 1196), ('will', 1173), ('have', 1124), ('?', 968), ('i', 901), ('!', 863), ('is', 657), ('to', 570)] | avgLoss/100: 3.8427800798416136 |  |  | TUTOR.py 100
2025-04-16 20:14:00 | 1900 | LR0.00035 | logitMin:-1.3197 | logitMax:-0.4045 | scheduledSampling:0.0000 | lossTUTOR:0.0295 | topTokens[(',', 2208), ('.', 1458), ('you', 1239), ('will', 1173), ('have', 1137), ('?', 1121), ('i', 933), ('!', 887), ('is', 736), ('to', 629)] | avgLoss/100: 4.287215778827667 |  |  | TUTOR.py 100
2025-04-16 20:15:28 | 2000 | LR0.00035 | logitMin:-1.6341 | logitMax:0.5185 | scheduledSampling:0.0000 | lossTUTOR:1.0991 | topTokens[(',', 2214), ('.', 1599), ('you', 1305), ('?', 1224), ('will', 1192), ('have', 1143), ('i', 1003), ('!', 901), ('is', 810), ('to', 658)] | avgLoss/100: 5.200388817787171 |  |  | TUTOR.py 100
2025-04-16 20:16:51 | 2100 | LR0.00035 | logitMin:-1.3323 | logitMax:-0.4103 | scheduledSampling:0.0000 | lossTUTOR:0.0342 | topTokens[(',', 2215), ('.', 1674), ('you', 1404), ('?', 1344), ('will', 1224), ('have', 1143), ('i', 1056), ('!', 978), ('is', 858), ('to', 685)] | avgLoss/100: 7.9183798909187315 |  |  | TUTOR.py 100
2025-04-16 20:18:15 | 2200 | LR0.00035 | logitMin:-1.3304 | logitMax:-0.3976 | scheduledSampling:0.0000 | lossTUTOR:0.0398 | topTokens[(',', 2217), ('.', 1794), ('?', 1541), ('you', 1483), ('will', 1228), ('have', 1143), ('i', 1116), ('!', 998), ('is', 954), ('to', 732)] | avgLoss/100: 4.691089661121368 |  |  | TUTOR.py 100
2025-04-16 20:19:39 | 2300 | LR0.00035 | logitMin:-1.3247 | logitMax:-0.4065 | scheduledSampling:0.0000 | lossTUTOR:0.0275 | topTokens[(',', 2234), ('.', 1894), ('?', 1719), ('you', 1625), ('will', 1263), ('i', 1165), ('have', 1143), ('is', 1042), ('!', 1039), ('to', 750)] | avgLoss/100: 3.4890921664237977 |  |  | TUTOR.py 100
2025-04-16 20:21:02 | 2400 | LR0.00035 | logitMin:-1.3298 | logitMax:-0.4105 | scheduledSampling:0.0000 | lossTUTOR:0.0307 | topTokens[(',', 2285), ('.', 2053), ('?', 1875), ('you', 1726), ('will', 1303), ('i', 1239), ('is', 1167), ('have', 1143), ('!', 1065), ('to', 751)] | avgLoss/100: 4.042104475498199 |  |  | TUTOR.py 100
2025-04-16 20:22:29 | 2500 | LR0.00035 | logitMin:-1.3087 | logitMax:-0.4197 | scheduledSampling:0.0000 | lossTUTOR:0.0764 | topTokens[(',', 2320), ('.', 2205), ('?', 2039), ('you', 1863), ('i', 1346), ('will', 1305), ('is', 1175), ('have', 1143), ('!', 1067), ('to', 802)] | avgLoss/100: 3.768873212337494 |  |  | TUTOR.py 100
2025-04-16 20:23:52 | 2600 | LR0.00035 | logitMin:-1.3263 | logitMax:-0.4025 | scheduledSampling:0.0000 | lossTUTOR:0.0329 | topTokens[(',', 2364), ('.', 2350), ('?', 2195), ('you', 1982), ('i', 1390), ('will', 1336), ('is', 1242), ('have', 1158), ('!', 1098), ('to', 807)] | avgLoss/100: 4.641139855384827 |  |  | TUTOR.py 100
2025-04-16 20:25:17 | 2700 | LR0.00035 | logitMin:-1.3235 | logitMax:-0.4108 | scheduledSampling:0.0000 | lossTUTOR:0.0730 | topTokens[('.', 2494), (',', 2370), ('?', 2344), ('you', 2093), ('i', 1463), ('will', 1336), ('is', 1290), ('have', 1159), ('!', 1117), ('do', 854)] | avgLoss/100: 3.620464823246002 |  |  | TUTOR.py 100
2025-04-16 20:26:41 | 2800 | LR0.00035 | logitMin:-1.3295 | logitMax:-0.4100 | scheduledSampling:0.0000 | lossTUTOR:0.0410 | topTokens[('.', 2646), ('?', 2486), (',', 2391), ('you', 2194), ('i', 1521), ('is', 1379), ('will', 1378), ('have', 1162), ('!', 1141), ('to', 895)] | avgLoss/100: 4.407561542987824 |  |  | TUTOR.py 100
2025-04-16 20:28:06 | 2900 | LR0.00035 | logitMin:-1.3319 | logitMax:-0.4078 | scheduledSampling:0.0000 | lossTUTOR:0.0335 | topTokens[('.', 2745), ('?', 2638), (',', 2441), ('you', 2295), ('i', 1601), ('is', 1439), ('will', 1384), ('!', 1179), ('have', 1179), ('do', 931)] | avgLoss/100: 3.7368133020401 |  |  | TUTOR.py 100
2025-04-16 20:29:34 | 3000 | LR0.00035 | logitMin:-1.6079 | logitMax:0.5096 | scheduledSampling:0.0000 | lossTUTOR:0.9397 | topTokens[('.', 2927), ('?', 2806), (',', 2450), ('you', 2379), ('i', 1694), ('is', 1531), ('will', 1421), ('!', 1227), ('have', 1180), ('do', 1010)] | avgLoss/100: 4.440181863307953 |  |  | TUTOR.py 100
2025-04-16 20:30:58 | 3100 | LR0.00035 | logitMin:-1.3230 | logitMax:-0.4016 | scheduledSampling:0.0000 | lossTUTOR:0.0292 | topTokens[('.', 3047), ('?', 2968), ('you', 2454), (',', 2450), ('i', 1781), ('is', 1616), ('will', 1435), ('!', 1297), ('have', 1180), ('do', 1014)] | avgLoss/100: 6.991412675380706 |  |  | TUTOR.py 100
2025-04-16 20:32:23 | 3200 | LR0.00035 | logitMin:-1.3265 | logitMax:-0.3970 | scheduledSampling:0.0000 | lossTUTOR:0.0281 | topTokens[('.', 3186), ('?', 3150), ('you', 2591), (',', 2477), ('i', 1910), ('is', 1634), ('will', 1457), ('!', 1298), ('have', 1180), ('do', 1067)] | avgLoss/100: 3.411166837215424 |  |  | TUTOR.py 100
2025-04-16 20:33:47 | 3300 | LR0.00035 | logitMin:-1.3236 | logitMax:-0.3854 | scheduledSampling:0.0000 | lossTUTOR:0.0549 | topTokens[('.', 3288), ('?', 3267), ('you', 2692), (',', 2493), ('i', 1999), ('is', 1673), ('will', 1459), ('!', 1310), ('have', 1180), ('do', 1130)] | avgLoss/100: 4.538065576553345 |  |  | TUTOR.py 100

--- 2025-04-16 20:34:40 --- babyLLM 'right, last time i got to step 27501... want to restart from there?'  - charis: '30000' - babyLLM 'damn that's specific! heading to step 30000... what am i learning today?' - charis: ''
2025-04-16 20:36:03 | 100 | LR0.00035 | logitMin:-1.3289 | logitMax:-0.4259 | scheduledSampling:0.0000 | lossTUTOR:0.0320 | topTokens[('.', 132), ('?', 131), ('you', 116), ('do', 77), (',', 76), ('is', 75), ('!', 52), ('dad', 47), ('are', 47), ('not', 41)] | avgLoss/100: 5.476708719730377 |  |  | TUTOR.py 100
2025-04-16 20:37:27 | 200 | LR0.00035 | logitMin:-1.3188 | logitMax:-0.4421 | scheduledSampling:0.0000 | lossTUTOR:0.0333 | topTokens[('?', 277), ('you', 253), ('.', 250), ('do', 165), ('is', 128), (',', 87), ('me', 85), ('i', 85), ('him', 81), ('ing', 75)] | avgLoss/100: 3.664571175575256 |  |  | TUTOR.py 100

--- 2025-04-16 20:38:46 --- babyLLM 'right, last time i got to step 30001... want to restart from there?'  - charis: '30250' - babyLLM 'damn that's specific! heading to step 30250... what am i learning today?' - charis: ''
2025-04-16 20:40:09 | 100 | LR0.00035 | logitMin:-1.3204 | logitMax:-0.4770 | scheduledSampling:0.0000 | topTokens[('?', 173), ('.', 146), ('you', 142), ('i', 99), ('is', 78), ('will', 60), ('who', 55), ('are', 55), ('plus', 52), ('my', 47)] | avgLoss/100: 6.974562599658966 |  |  | TUTOR.py 100
2025-04-16 20:41:32 | 200 | LR0.00035 | logitMin:-1.3240 | logitMax:-0.4878 | scheduledSampling:0.0000 | topTokens[('?', 344), ('.', 315), ('you', 248), ('i', 179), ('is', 164), ('will', 85), ('do', 76), ('he', 76), ('to', 65), ('not', 64)] | avgLoss/100: 4.048107409477234 |  |  | TUTOR.py 100
2025-04-16 20:42:55 | 300 | LR0.00035 | logitMin:-1.3088 | logitMax:-0.5255 | scheduledSampling:0.0000 | topTokens[('?', 488), ('.', 433), ('you', 329), ('is', 264), ('i', 252), ('do', 161), ('!', 125), ('are', 114), ('not', 103), ('will', 102)] | avgLoss/100: 3.7720367217063906 |  |  | TUTOR.py 100
2025-04-16 20:44:18 | 400 | LR0.00035 | logitMin:-1.3224 | logitMax:-0.5012 | scheduledSampling:0.0000 | topTokens[('?', 644), ('.', 578), ('you', 447), ('i', 362), ('is', 315), ('do', 187), ('are', 164), ('!', 149), ('will', 135), ('what', 135)] | avgLoss/100: 3.2784081077575684 |  |  | TUTOR.py 100
2025-04-16 20:45:44 | 500 | LR0.00035 | logitMin:-1.3206 | logitMax:-0.4792 | scheduledSampling:0.0000 | topTokens[('?', 827), ('.', 726), ('you', 586), ('i', 484), ('is', 366), ('do', 250), ('are', 203), ('what', 170), ('to', 150), ('!', 150)] | avgLoss/100: 3.243266501426697 |  |  | TUTOR.py 100
2025-04-16 20:47:08 | 600 | LR0.00035 | logitMin:-1.3228 | logitMax:-0.4834 | scheduledSampling:0.0000 | topTokens[('?', 865), ('.', 801), ('you', 630), ('i', 531), ('is', 369), ('do', 262), ('are', 205), ('!', 193), ('what', 171), ('kevin', 162)] | avgLoss/100: 4.601439216136932 |  |  | TUTOR.py 100
2025-04-16 20:48:33 | 700 | LR0.00035 | logitMin:-1.3321 | logitMax:-0.4578 | scheduledSampling:0.0000 | topTokens[('?', 865), ('.', 857), ('you', 636), ('i', 535), ('is', 407), (',', 288), ('he', 288), ('!', 265), ('do', 263), ('are', 205)] | avgLoss/100: 3.8765352535247803 |  |  | TUTOR.py 100
--- 2025-04-16 20:53:05 --- babyLLM 'right, last time i got to step 30253... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 30253! what am i learning today?' - charis: ''
2025-04-16 20:54:27 | 100 | LR0.00035 | logitMin:-1.3198 | logitMax:-0.5428 | scheduledSampling:0.0000 | topTokens[('?', 185), ('.', 164), ('you', 131), ('i', 119), ('is', 76), ('ind', 58), ('will', 58), ('hug', 49), ('who', 49), ('bl', 48)] | avgLoss/100: 6.299515473842621 |  |  | TUTOR.py 100
2025-04-16 20:55:48 | 200 | LR0.00035 | logitMin:-1.3304 | logitMax:-0.5601 | scheduledSampling:0.0000 | topTokens[('?', 363), ('.', 315), ('you', 244), ('i', 203), ('is', 159), ('will', 91), ('do', 87), ('not', 84), ('hug', 74), ('he', 66)] | avgLoss/100: 4.0006524538993835 |  |  | TUTOR.py 100
2025-04-16 20:57:13 | 300 | LR0.00035 | logitMin:-1.3122 | logitMax:-0.5788 | scheduledSampling:0.0000 | topTokens[('?', 533), ('.', 431), ('you', 331), ('i', 291), ('is', 226), ('do', 167), ('!', 124), ('not', 108), ('will', 98), ('to', 96)] | avgLoss/100: 3.450699191093445 |  |  | TUTOR.py 100
--- 2025-04-16 21:11:42 --- babyLLM 'right, last time i got to step 30257... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 30257! what am i learning today?' - charis: ''
2025-04-16 21:20:53 | 100 | LR0.00035 | logitMin:-45.3102 | logitMax:17.6208 | scheduledSampling:0.0000 | windowWeightsW4:2.12282 (0.51),W2:2.03643 (0.47),W8:-1.52267 (0.01),W12:-6.13127 (0.00),W16:-8.62142 (0.00),W20:-10.23060 (0.00),W24:-11.08218 (0.00),W32:-11.28103 (0.00),W28:-11.69310 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[('?', 159), ('.', 146), ('you', 118), ('i', 89), ('is', 69), ('who', 56), ('are', 56), ('hug', 56), ('geepy', 46), ('do', 45)] | avgLoss/100: 931.9415228271484 |  | entropyBonus: -0.0 blend: 0.298 top windows: W28:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 100
--- 2025-04-16 21:33:55 --- babyLLM 'right, last time i got to step 31001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 31001! what am i learning today?' - charis: ''
2025-04-16 21:42:56 | 100 | LR0.00035 | logitMin:-42.0393 | logitMax:16.2494 | scheduledSampling:0.0000 | windowWeightsW4:2.12255 (0.51),W2:2.03615 (0.47),W8:-1.52244 (0.01),W12:-6.13036 (0.00),W16:-8.62032 (0.00),W20:-10.22913 (0.00),W24:-11.08071 (0.00),W32:-11.27957 (0.00),W28:-11.69163 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[('could', 222), ('have', 214), ('felt', 108), (',', 100), ('elodie', 92), ('!', 92), ('charis', 58), ('it', 50), ('she', 47), ("'s", 44)] | avgLoss/100: 882.538309173584 |  | entropyBonus: -0.0 blend: 0.298 top windows: W28:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 100
2025-04-16 21:52:05 | 200 | LR0.00035 | logitMin:-67.0375 | logitMax:27.1511 | scheduledSampling:0.0000 | windowWeightsW4:2.12240 (0.51),W2:2.03601 (0.47),W8:-1.52232 (0.01),W12:-6.12988 (0.00),W16:-8.61975 (0.00),W20:-10.22837 (0.00),W24:-11.07995 (0.00),W32:-11.27881 (0.00),W28:-11.69087 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11431 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[('could', 459), ('have', 452), ('felt', 275), (',', 250), ('elodie', 207), ('charis', 156), ('!', 155), ('and', 111), ('she', 87), ('you', 72)] | avgLoss/100: 746.0429553222656 |  | entropyBonus: -0.0 blend: 0.298 top windows: W24:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 100
2025-04-16 22:01:08 | 300 | LR0.00035 | logitMin:-44.7907 | logitMax:19.7278 | scheduledSampling:0.0000 | windowWeightsW4:2.12226 (0.51),W2:2.03586 (0.47),W8:-1.52220 (0.01),W12:-6.12940 (0.00),W16:-8.61918 (0.00),W20:-10.22761 (0.00),W24:-11.07918 (0.00),W32:-11.27804 (0.00),W28:-11.69011 (0.00) | judgeBiasW32:-0.00405 (0.11),W2:-0.00405 (0.11),W4:-0.00405 (0.11),W8:-0.00405 (0.11),W12:-0.00405 (0.11),W16:-0.00405 (0.11),W20:-0.00405 (0.11),W24:-0.00405 (0.11),W28:-0.00405 (0.11) | credibilityBiasW32:0.11430 (0.04),W28:0.11425 (0.04),W20:0.11366 (0.03),W16:0.11245 (0.02),W12:0.11180 (0.01),W24:0.11178 (0.01),W8:0.10956 (-0.01),W2:0.10806 (-0.02),W4:0.10415 (-0.06) | topTokens[('could', 686), ('have', 669), ('felt', 395), (',', 337), ('elodie', 284), ('!', 240), ('charis', 205), ('and', 152), ('.', 149), ('you', 112)] | avgLoss/100: 725.1203004455566 |  | entropyBonus: -0.0 blend: 0.298 top windows: W32:1.00,W2:0.00,W4:0.00,W8:0.00 | TUTOR.py 100
--- 2025-04-17 02:23:51 --- 
[babyllm] right, last time i got to step 0... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 0! what am i learning today?
[charis]
2025-04-17 02:25:20 | 100 | LR0.00035 | logitMin:-0.0382 | logitMax:0.0518 | scheduledSampling:0.0000 | topTokens[('a', 111), (',', 77), ('.', 74), ('it', 71), ('b', 56), ('as', 55), ('of', 52), ('and', 46), ('ss', 43), ('was', 41)] |  |  | TUTOR.py 100
--- 2025-04-17 02:41:42 --- 
[babyllm] right, last time i got to step 1... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 1! what am i learning today?
[charis]
2025-04-17 02:43:07 | 100 | LR0.00035 | logitMin:-0.0366 | logitMax:0.0661 | scheduledSampling:0.0000 | topTokens[('a', 103), (',', 77), ('it', 72), ('.', 59), ('as', 57), ('b', 46), ('of', 43), ('door', 42), ('and', 40), ('r', 38)] |  |  | TUTOR.py 100
2025-04-17 02:44:26 | 200 | LR0.00035 | logitMin:-0.0548 | logitMax:0.0518 | scheduledSampling:0.0000 | topTokens[(',', 233), ('a', 160), ('of', 121), ('it', 110), ('.', 99), ('and', 92), ('was', 83), ('the', 73), ('to', 65), ('door', 62)] |  |  | TUTOR.py 100
2025-04-17 02:45:49 | 300 | LR0.00035 | logitMin:-0.0672 | logitMax:0.0595 | scheduledSampling:0.0000 | topTokens[(',', 314), ('a', 284), ('of', 162), ('.', 147), ('it', 135), ('and', 126), ('was', 119), ('the', 79), ('to', 75), ('very', 75)] |  |  | TUTOR.py 100
2025-04-17 02:47:10 | 400 | LR0.00035 | logitMin:-0.0727 | logitMax:0.0357 | scheduledSampling:0.0000 | topTokens[(',', 429), ('a', 356), ('.', 189), ('of', 185), ('the', 160), ('was', 160), ('and', 158), ('it', 150), ('to', 89), ('that', 88)] |  |  | TUTOR.py 100
2025-04-17 02:48:36 | 500 | LR0.00035 | logitMin:-0.0860 | logitMax:0.0309 | scheduledSampling:0.0000 | topTokens[(',', 614), ('a', 419), ('of', 215), ('.', 214), ('the', 201), ('and', 194), ('it', 183), ('was', 164), ('to', 137), ('they', 131)] |  |  | TUTOR.py 100
2025-04-17 02:49:58 | 600 | LR0.00035 | logitMin:-0.0842 | logitMax:0.0263 | scheduledSampling:0.0000 | topTokens[(',', 723), ('a', 477), ('of', 295), ('.', 254), ('the', 252), ('and', 242), ('it', 220), ('was', 183), ('to', 141), ('they', 136)] |  |  | TUTOR.py 100
2025-04-17 02:51:19 | 700 | LR0.00035 | logitMin:-0.0913 | logitMax:0.0244 | scheduledSampling:0.0000 | topTokens[(',', 798), ('a', 522), ('of', 331), ('the', 259), ('.', 258), ('and', 246), ('it', 224), ('was', 184), ('they', 161), ('to', 145)] |  |  | TUTOR.py 100
2025-04-17 02:52:42 | 800 | LR0.00035 | logitMin:-0.1087 | logitMax:0.0102 | scheduledSampling:0.0000 | topTokens[(',', 891), ('a', 544), ('of', 388), ('the', 319), ('.', 297), ('and', 293), ('it', 244), ('was', 226), ('they', 178), ('that', 154)] |  |  | TUTOR.py 100
2025-04-17 02:54:03 | 900 | LR0.00035 | logitMin:-0.1119 | logitMax:0.0120 | scheduledSampling:0.0000 | topTokens[(',', 1056), ('a', 575), ('the', 407), ('of', 405), ('and', 333), ('.', 314), ('it', 269), ('ed', 257), ('was', 230), ('they', 180)] |  |  | TUTOR.py 100
2025-04-17 02:55:30 | 1000 | LR0.00035 | logitMin:-0.1111 | logitMax:0.0203 | scheduledSampling:0.0000 | topTokens[(',', 1187), ('a', 600), ('the', 457), ('of', 415), ('and', 357), ('.', 347), ('it', 276), ('ed', 260), ('was', 251), ('they', 209)] |  |  | TUTOR.py 100
2025-04-17 02:56:51 | 1100 | LR0.00035 | logitMin:-0.1114 | logitMax:0.0084 | scheduledSampling:0.0000 | topTokens[(',', 1342), ('a', 676), ('the', 516), ('of', 453), ('.', 393), ('and', 372), ('it', 297), ('was', 293), ('ed', 282), ('they', 265)] |  |  | TUTOR.py 100
2025-04-17 02:58:13 | 1200 | LR0.00035 | logitMin:-0.1138 | logitMax:0.0113 | scheduledSampling:0.0000 | topTokens[(',', 1479), ('a', 699), ('the', 528), ('of', 493), ('and', 438), ('.', 410), ('they', 347), ('was', 330), ('ed', 321), ('it', 301)] |  |  | TUTOR.py 100
2025-04-17 02:59:35 | 1300 | LR0.00035 | logitMin:-0.1190 | logitMax:0.0190 | scheduledSampling:0.0000 | topTokens[(',', 1577), ('a', 751), ('the', 577), ('of', 530), ('and', 460), ('.', 446), ('they', 353), ('was', 338), ('ed', 337), ('their', 317)] |  |  | TUTOR.py 100
2025-04-17 03:00:56 | 1400 | LR0.00035 | logitMin:-0.1397 | logitMax:0.0080 | scheduledSampling:0.0000 | topTokens[(',', 1729), ('a', 774), ('the', 638), ('of', 566), ('.', 490), ('and', 487), ('was', 364), ('they', 357), ('ed', 352), ('it', 340)] |  |  | TUTOR.py 100
2025-04-17 03:02:22 | 1500 | LR0.00035 | logitMin:-0.1342 | logitMax:0.0034 | scheduledSampling:0.0000 | topTokens[(',', 1835), ('a', 779), ('the', 715), ('of', 617), ('.', 527), ('and', 509), ('ed', 389), ('was', 383), ('they', 377), ('it', 362)] |  |  | TUTOR.py 100
2025-04-17 03:03:44 | 1600 | LR0.00035 | logitMin:-0.1248 | logitMax:0.0018 | scheduledSampling:0.0000 | topTokens[(',', 2019), ('the', 798), ('a', 784), ('of', 669), ('and', 543), ('.', 531), ('ed', 450), ('was', 391), ('they', 389), ('it', 363)] |  |  | TUTOR.py 100
2025-04-17 03:05:06 | 1700 | LR0.00035 | logitMin:-0.1466 | logitMax:0.0066 | scheduledSampling:0.0000 | topTokens[(',', 2115), ('the', 852), ('a', 810), ('of', 718), ('and', 589), ('.', 538), ('ed', 488), ('was', 451), ('they', 404), ('it', 395)] |  |  | TUTOR.py 100
2025-04-17 03:06:29 | 1800 | LR0.00035 | logitMin:-0.1304 | logitMax:0.0002 | scheduledSampling:0.0000 | topTokens[(',', 2265), ('a', 870), ('the', 860), ('of', 727), ('and', 650), ('ed', 556), ('.', 542), ('was', 473), ('to', 462), ('they', 423)] |  |  | TUTOR.py 100
2025-04-17 03:07:52 | 1900 | LR0.00035 | logitMin:-0.1855 | logitMax:0.0040 | scheduledSampling:0.0000 | topTokens[(',', 2363), ('a', 958), ('the', 888), ('of', 743), ('and', 683), ('ed', 608), ('.', 582), ('was', 503), ('to', 467), ('it', 438)] |  |  | TUTOR.py 100
2025-04-17 03:09:19 | 2000 | LR0.00035 | logitMin:-0.1507 | logitMax:0.0314 | scheduledSampling:0.0000 | topTokens[(',', 2445), ('a', 997), ('the', 891), ('of', 746), ('and', 700), ('.', 655), ('ed', 612), ('was', 550), ('to', 523), ('it', 512)] |  |  | TUTOR.py 100
2025-04-17 03:10:42 | 2100 | LR0.00035 | logitMin:-0.1325 | logitMax:-0.0081 | scheduledSampling:0.0000 | topTokens[(',', 2533), ('a', 1016), ('the', 891), ('.', 772), ('it', 768), ('of', 748), ('and', 704), ('ed', 613), ('was', 550), ('to', 523)] |  |  | TUTOR.py 100
2025-04-17 03:12:04 | 2200 | LR0.00035 | logitMin:-0.1743 | logitMax:-0.0269 | scheduledSampling:0.0000 | topTokens[(',', 2549), ('a', 1074), ('the', 935), ('.', 918), ('it', 788), ('of', 760), ('and', 730), ('ed', 618), ('was', 555), ('to', 530)] |  |  | TUTOR.py 100
2025-04-17 03:13:28 | 2300 | LR0.00035 | logitMin:-0.1379 | logitMax:0.0218 | scheduledSampling:0.0000 | topTokens[(',', 2602), ('a', 1104), ('.', 1003), ('it', 981), ('the', 938), ('of', 761), ('and', 741), ('i', 738), ('ed', 619), ('!', 591)] |  |  | TUTOR.py 100
[charis]--- 2025-04-17 03:16:15 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]
2025-04-17 03:17:42 | 100 | LR0.00035 | logitMin:-0.0388 | logitMax:0.0645 | scheduledSampling:0.0000 | topTokens[('a', 121), (',', 89), ('as', 68), ('it', 60), ('.', 59), ('and', 49), ('b', 41), ('to', 39), ('r', 32), ('ss', 32)] |  |  | TUTOR.py 100
2025-04-17 03:19:03 | 200 | LR0.00035 | logitMin:-0.0534 | logitMax:0.0538 | scheduledSampling:0.0000 | topTokens[(',', 222), ('a', 171), ('of', 132), ('it', 104), ('and', 104), ('.', 89), ('the', 84), ('as', 74), ('was', 74), ('to', 73)] |  |  | TUTOR.py 100
2025-04-17 03:20:25 | 300 | LR0.00035 | logitMin:-0.0731 | logitMax:0.0598 | scheduledSampling:0.0000 | topTokens[(',', 304), ('a', 265), ('of', 176), ('and', 139), ('.', 137), ('it', 120), ('was', 98), ('the', 88), ('to', 80), ('as', 74)] |  |  | TUTOR.py 100
2025-04-17 03:21:47 | 400 | LR0.00035 | logitMin:-0.0735 | logitMax:0.0389 | scheduledSampling:0.0000 | topTokens[(',', 418), ('a', 347), ('of', 200), ('.', 186), ('the', 182), ('and', 182), ('it', 135), ('was', 133), ('to', 102), ('you', 88)] |  |  | TUTOR.py 100
2025-04-17 03:23:13 | 500 | LR0.00035 | logitMin:-0.0812 | logitMax:0.0301 | scheduledSampling:0.0000 | topTokens[(',', 591), ('a', 432), ('of', 246), ('the', 230), ('and', 229), ('.', 215), ('it', 166), ('to', 158), ('was', 138), ('ed', 109)] |  |  | TUTOR.py 100
2025-04-17 03:24:35 | 600 | LR0.00035 | logitMin:-0.0881 | logitMax:0.0257 | scheduledSampling:0.0000 | topTokens[(',', 697), ('a', 497), ('of', 346), ('the', 279), ('and', 275), ('.', 252), ('it', 210), ('to', 163), ('was', 163), ('you', 112)] |  |  | TUTOR.py 100
2025-04-17 03:25:56 | 700 | LR0.00035 | logitMin:-0.0950 | logitMax:0.0288 | scheduledSampling:0.0000 | topTokens[(',', 762), ('a', 529), ('of', 372), ('the', 289), ('and', 275), ('.', 257), ('it', 216), ('to', 168), ('was', 164), ('ed', 145)] |  |  | TUTOR.py 100
2025-04-17 03:27:18 | 800 | LR0.00035 | logitMin:-0.1019 | logitMax:0.0154 | scheduledSampling:0.0000 | topTokens[(',', 867), ('a', 546), ('of', 423), ('the', 372), ('and', 309), ('.', 299), ('it', 239), ('was', 198), ('to', 171), ('ed', 161)] |  |  | TUTOR.py 100
2025-04-17 03:28:40 | 900 | LR0.00035 | logitMin:-0.1148 | logitMax:0.0153 | scheduledSampling:0.0000 | topTokens[(',', 1014), ('a', 579), ('the', 462), ('of', 444), ('and', 338), ('.', 306), ('ed', 262), ('it', 259), ('was', 199), ('to', 181)] |  |  | TUTOR.py 100
2025-04-17 03:30:04 | 1000 | LR0.00035 | logitMin:-0.1065 | logitMax:0.0242 | scheduledSampling:0.0000 | topTokens[(',', 1144), ('a', 601), ('the', 517), ('of', 451), ('and', 364), ('.', 340), ('ed', 269), ('it', 266), ('was', 221), ('to', 207)] |  |  | TUTOR.py 100
2025-04-17 03:31:26 | 1100 | LR0.00035 | logitMin:-0.1188 | logitMax:0.0107 | scheduledSampling:0.0000 | topTokens[(',', 1276), ('a', 670), ('the', 579), ('of', 494), ('.', 387), ('and', 382), ('ed', 291), ('it', 285), ('was', 268), ('they', 238)] |  |  | TUTOR.py 100
2025-04-17 03:32:47 | 1200 | LR0.00035 | logitMin:-0.1180 | logitMax:0.0084 | scheduledSampling:0.0000 | topTokens[(',', 1434), ('a', 688), ('the', 584), ('of', 528), ('and', 453), ('.', 406), ('ed', 329), ('they', 309), ('was', 301), ('it', 288)] |  |  | TUTOR.py 100
2025-04-17 03:34:08 | 1300 | LR0.00035 | logitMin:-0.1371 | logitMax:0.0154 | scheduledSampling:0.0000 | topTokens[(',', 1520), ('a', 751), ('the', 627), ('of', 567), ('and', 478), ('.', 447), ('ed', 343), ('they', 319), ('to', 316), ('was', 312)] |  |  | TUTOR.py 100
2025-04-17 03:35:30 | 1400 | LR0.00035 | logitMin:-0.1211 | logitMax:0.0132 | scheduledSampling:0.0000 | topTokens[(',', 1681), ('a', 781), ('the', 682), ('of', 604), ('and', 503), ('.', 480), ('ed', 364), ('to', 332), ('it', 331), ('was', 328)] |  |  | TUTOR.py 100
--- 2025-04-17 03:51:33 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]
2025-04-17 03:53:02 | 100 | LR0.00035 | logitMin:-0.0368 | logitMax:0.0648 | scheduledSampling:0.0000 | shortDecay:0.0068 | longDecay:0.0073 | topTokens[('a', 99), ('it', 74), ('as', 73), ('.', 70), (',', 63), ('of', 53), ('b', 47), ('and', 44), ('to', 38), ('mo', 37)] |  |  | TUTOR.py 100
2025-04-17 03:54:24 | 200 | LR0.00035 | logitMin:-0.0554 | logitMax:0.0524 | scheduledSampling:0.0000 | shortDecay:0.0069 | longDecay:0.0074 | topTokens[(',', 212), ('a', 176), ('of', 122), ('.', 104), ('it', 102), ('and', 96), ('the', 80), ('was', 79), ('as', 75), ('to', 72)] |  |  | TUTOR.py 100
2025-04-17 03:55:48 | 300 | LR0.00035 | logitMin:-0.0711 | logitMax:0.0561 | scheduledSampling:0.0000 | shortDecay:0.0069 | longDecay:0.0075 | topTokens[('a', 289), (',', 282), ('of', 156), ('.', 142), ('and', 136), ('it', 122), ('was', 98), ('the', 86), ('to', 80), ('as', 78)] |  |  | TUTOR.py 100
2025-04-17 03:57:10 | 400 | LR0.00035 | logitMin:-0.0782 | logitMax:0.0401 | scheduledSampling:0.0000 | shortDecay:0.0070 | longDecay:0.0075 | topTokens[(',', 406), ('a', 353), ('.', 192), ('of', 181), ('the', 177), ('and', 165), ('it', 141), ('was', 141), ('in', 104), ('that', 102)] |  |  | TUTOR.py 100
2025-04-17 03:58:36 | 500 | LR0.00035 | logitMin:-0.0859 | logitMax:0.0307 | scheduledSampling:0.0000 | shortDecay:0.0069 | longDecay:0.0075 | topTokens[(',', 605), ('a', 437), ('the', 226), ('.', 224), ('of', 215), ('and', 206), ('it', 175), ('was', 147), ('to', 133), ('in', 121)] |  |  | TUTOR.py 100
--- 2025-04-17 03:59:24 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]
2025-04-17 04:00:53 | 100 | LR0.00035 | logitMin:-0.0035 | logitMax:0.0067 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | topTokens[('a', 124), (',', 87), ('it', 73), ('.', 69), ('as', 66), ('b', 46), ('and', 45), ('of', 42), ('the', 39), ('r', 36)] |  |  | TUTOR.py 1000
2025-04-17 04:02:15 | 200 | LR0.00035 | logitMin:-0.0055 | logitMax:0.0056 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | topTokens[(',', 234), ('a', 199), ('of', 138), ('.', 116), ('and', 107), ('it', 104), ('the', 96), ('was', 78), ('as', 70), ('to', 56)] |  |  | TUTOR.py 1000
2025-04-17 04:03:36 | 300 | LR0.00035 | logitMin:-0.0066 | logitMax:0.0056 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | topTokens[(',', 310), ('a', 298), ('of', 169), ('.', 160), ('and', 142), ('it', 131), ('was', 108), ('the', 100), ('that', 76), ('as', 71)] |  |  | TUTOR.py 1000
2025-04-17 04:04:56 | 400 | LR0.00035 | logitMin:-0.0070 | logitMax:0.0039 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | topTokens[(',', 447), ('a', 377), ('.', 215), ('the', 210), ('of', 186), ('and', 182), ('it', 157), ('was', 133), ('in', 98), ('that', 96)] |  |  | TUTOR.py 1000
[charis]--- 2025-04-17 04:07:46 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]
2025-04-17 04:09:13 | 100 | LR0.00035 | logitMin:-0.0034 | logitMax:0.0066 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | topTokens[('a', 111), (',', 71), ('it', 68), ('.', 61), ('as', 59), ('and', 51), ('of', 43), ('to', 39), ('b', 37), ('the', 37)] |  |  | TUTOR.py 1000
2025-04-17 04:10:34 | 200 | LR0.00035 | logitMin:-0.0055 | logitMax:0.0055 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | topTokens[(',', 225), ('a', 193), ('of', 131), ('it', 110), ('and', 105), ('.', 97), ('the', 89), ('was', 83), ('to', 69), ('as', 66)] |  |  | TUTOR.py 1000
2025-04-17 04:11:55 | 300 | LR0.00035 | logitMin:-0.0072 | logitMax:0.0057 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | topTokens[(',', 314), ('a', 303), ('of', 167), ('.', 141), ('and', 139), ('it', 133), ('was', 107), ('the', 98), ('to', 82), ('that', 71)] |  |  | TUTOR.py 1000
2025-04-17 04:13:15 | 400 | LR0.00035 | logitMin:-0.0071 | logitMax:0.0039 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | topTokens[(',', 448), ('a', 379), ('the', 199), ('of', 195), ('and', 190), ('.', 189), ('it', 150), ('was', 150), ('to', 105), ('that', 95)] |  |  | TUTOR.py 1000
2025-04-17 04:14:41 | 500 | LR0.00035 | logitMin:-0.0077 | logitMax:0.0031 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | topTokens[(',', 625), ('a', 463), ('the', 245), ('of', 230), ('and', 219), ('.', 208), ('it', 183), ('was', 152), ('to', 148), ('they', 130)] |  |  | TUTOR.py 1000
--- 2025-04-17 04:15:44 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]
2025-04-17 04:17:12 | 100 | LR0.00035 | logitMin:-0.0039 | logitMax:0.0069 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | topTokens[(None, 1782), (tensor([[1396]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[52]], device='mps:0'), 1), (tensor([[82]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[421]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[174]], device='mps:0'), 1)] |  |  | TUTOR.py 1000
2025-04-17 04:18:34 | 200 | LR0.00035 | logitMin:-0.0056 | logitMax:0.0056 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | topTokens[(None, 3582), (tensor([[1396]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[52]], device='mps:0'), 1), (tensor([[82]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[421]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[174]], device='mps:0'), 1)] |  |  | TUTOR.py 1000
2025-04-17 04:19:55 | 300 | LR0.00035 | logitMin:-0.0068 | logitMax:0.0059 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | topTokens[(None, 5382), (tensor([[1396]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[52]], device='mps:0'), 1), (tensor([[82]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[421]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[174]], device='mps:0'), 1)] |  |  | TUTOR.py 1000
2025-04-17 04:21:17 | 400 | LR0.00035 | logitMin:-0.0079 | logitMax:0.0039 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | topTokens[(None, 7182), (tensor([[1396]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[52]], device='mps:0'), 1), (tensor([[82]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[421]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[174]], device='mps:0'), 1)] |  |  | TUTOR.py 1000
2025-04-17 04:22:43 | 500 | LR0.00035 | logitMin:-0.0081 | logitMax:0.0031 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | topTokens[(None, 8982), (tensor([[1396]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[52]], device='mps:0'), 1), (tensor([[82]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[421]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[174]], device='mps:0'), 1)] |  |  | TUTOR.py 1000
2025-04-17 04:24:05 | 600 | LR0.00035 | logitMin:-0.0089 | logitMax:0.0028 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | topTokens[(None, 10782), (tensor([[1396]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[52]], device='mps:0'), 1), (tensor([[82]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[421]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[174]], device='mps:0'), 1)] |  |  | TUTOR.py 1000
2025-04-17 04:25:26 | 700 | LR0.00035 | logitMin:-0.0095 | logitMax:0.0027 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | topTokens[(None, 12582), (tensor([[1396]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[52]], device='mps:0'), 1), (tensor([[82]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[421]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[174]], device='mps:0'), 1)] |  |  | TUTOR.py 1000
2025-04-17 04:26:49 | 800 | LR0.00035 | logitMin:-0.0110 | logitMax:0.0011 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | topTokens[(None, 14382), (tensor([[1396]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[52]], device='mps:0'), 1), (tensor([[82]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[421]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[174]], device='mps:0'), 1)] |  |  | TUTOR.py 1000
2025-04-17 04:28:11 | 900 | LR0.00035 | logitMin:-0.0113 | logitMax:0.0012 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | topTokens[(None, 16182), (tensor([[1396]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[52]], device='mps:0'), 1), (tensor([[82]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[421]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[174]], device='mps:0'), 1)] |  |  | TUTOR.py 1000
2025-04-17 04:29:35 | 1000 | LR0.00035 | logitMin:-0.0101 | logitMax:0.0022 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | topTokens[(None, 17982), (tensor([[1396]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[52]], device='mps:0'), 1), (tensor([[82]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[421]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[174]], device='mps:0'), 1)] |  |  | TUTOR.py 1000
2025-04-17 04:30:57 | 1100 | LR0.00035 | logitMin:-0.0117 | logitMax:0.0009 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | topTokens[(None, 19782), (tensor([[1396]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[52]], device='mps:0'), 1), (tensor([[82]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[421]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[174]], device='mps:0'), 1)] |  |  | TUTOR.py 1000
2025-04-17 04:32:19 | 1200 | LR0.00035 | logitMin:-0.0109 | logitMax:0.0011 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | topTokens[(None, 21582), (tensor([[1396]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[52]], device='mps:0'), 1), (tensor([[82]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[421]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[174]], device='mps:0'), 1)] |  |  | TUTOR.py 1000
[charis]--- 2025-04-17 04:40:26 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]
2025-04-17 04:41:58 | 100 | LR0.00035 | logitMin:-0.0034 | logitMax:0.0064 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | topTokens[(None, 1800), (tensor([[208]], device='mps:0'), 1), (tensor([[1084]], device='mps:0'), 1), (tensor([[107]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[107]], device='mps:0'), 1), (tensor([[52]], device='mps:0'), 1), (tensor([[174]], device='mps:0'), 1), (tensor([[138]], device='mps:0'), 1)] |  |  | TUTOR.py 1000
--- 2025-04-17 04:42:21 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 04:43:49 | 100 | LR0.00035 | logitMin:-0.0034 | logitMax:0.0064 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | topTokens[(None, 1800), (tensor([[838]], device='mps:0'), 1), (tensor([[75]], device='mps:0'), 1), (tensor([[953]], device='mps:0'), 1), (tensor([[52]], device='mps:0'), 1), (tensor([[257]], device='mps:0'), 1), (tensor([[52]], device='mps:0'), 1), (tensor([[52]], device='mps:0'), 1), (tensor([[12]], device='mps:0'), 1), (tensor([[52]], device='mps:0'), 1)] |  |  | TUTOR.py 1000
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]
2025-04-17 04:48:42 | 100 | LR0.00035 | logitMin:-0.0034 | logitMax:0.0064 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | topTokens[('a', 108), (',', 78), ('it', 76), ('as', 63), ('.', 60), ('and', 48), ('b', 40), ('to', 40), ('r', 38), ('of', 35)] |  |  | TUTOR.py 1000
2025-04-17 04:50:02 | 200 | LR0.00035 | logitMin:-0.0052 | logitMax:0.0052 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | topTokens[(',', 220), ('a', 179), ('of', 124), ('it', 106), ('.', 104), ('the', 92), ('and', 89), ('was', 85), ('as', 70), ('to', 68)] |  |  | TUTOR.py 1000
2025-04-17 04:51:23 | 300 | LR0.00035 | logitMin:-0.0070 | logitMax:0.0054 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | topTokens[(',', 306), ('a', 290), ('of', 168), ('.', 147), ('it', 130), ('and', 121), ('was', 113), ('the', 95), ('to', 89), ('as', 73)] |  |  | TUTOR.py 1000
2025-04-17 04:52:45 | 400 | LR0.00035 | logitMin:-0.0075 | logitMax:0.0039 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | topTokens[(',', 438), ('a', 371), ('.', 208), ('of', 191), ('the', 187), ('and', 156), ('it', 146), ('was', 144), ('to', 105), ('that', 93)] |  |  | TUTOR.py 1000
2025-04-17 04:54:11 | 500 | LR0.00035 | logitMin:-0.0083 | logitMax:0.0028 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | topTokens[(',', 618), ('a', 451), ('of', 238), ('.', 231), ('the', 230), ('and', 200), ('it', 185), ('to', 149), ('was', 147), ('they', 144)] |  |  | TUTOR.py 1000
2025-04-17 04:55:34 | 600 | LR0.00035 | logitMin:-0.0082 | logitMax:0.0024 | scheduledSampling:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | topTokens[(',', 713), ('a', 498), ('of', 321), ('the', 269), ('.', 254), ('and', 246), ('it', 215), ('was', 168), ('to', 156), ('they', 152)] |  |  | TUTOR.py 1000
[charis]--- 2025-04-17 05:04:05 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]
2025-04-17 05:05:31 | 100 | LR0.00035 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | topTokens[('a', 106), (',', 78), ('it', 73), ('.', 69), ('as', 67), ('of', 52), ('and', 45), ('b', 40), ('to', 37), ('ss', 36)] |  |  | TUTOR.py 1000
2025-04-17 05:06:52 | 200 | LR0.00035 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | topTokens[(',', 225), ('a', 179), ('of', 134), ('.', 116), ('it', 100), ('and', 95), ('was', 76), ('the', 73), ('as', 70), ('to', 64)] |  |  | TUTOR.py 1000
2025-04-17 05:08:13 | 300 | LR0.00035 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | topTokens[(',', 318), ('a', 290), ('of', 166), ('.', 147), ('and', 138), ('it', 124), ('was', 93), ('the', 78), ('to', 72), ('as', 71)] |  |  | TUTOR.py 1000
2025-04-17 05:09:35 | 400 | LR0.00035 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | topTokens[(',', 453), ('a', 373), ('.', 200), ('of', 190), ('and', 178), ('the', 165), ('it', 148), ('was', 127), ('to', 90), ('that', 87)] |  |  | TUTOR.py 1000
--- 2025-04-17 05:09:54 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]
2025-04-17 05:11:22 | 100 | LR0.00035 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | topTokens[('a', 103), ('it', 75), (',', 74), ('as', 73), ('.', 55), ('door', 45), ('of', 42), ('and', 41), ('b', 38), ('to', 34)] |  |  | TUTOR.py 1000
2025-04-17 05:12:42 | 200 | LR0.00035 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | topTokens[(',', 223), ('a', 180), ('of', 148), ('it', 100), ('and', 94), ('.', 89), ('as', 88), ('the', 77), ('to', 69), ('was', 67)] |  |  | TUTOR.py 1000
--- 2025-04-17 05:21:10 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]
2025-04-17 05:22:37 | 100 | LR0.00035 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | topTokens[('a', 115), (',', 89), ('.', 70), ('it', 68), ('as', 56), ('and', 53), ('b', 40), ('r', 40), ('door', 39), ('to', 37)] |  |  | TUTOR.py 1000
2025-04-17 05:23:59 | 200 | LR0.00035 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | topTokens[(',', 218), ('a', 165), ('of', 118), ('.', 104), ('it', 103), ('and', 95), ('the', 78), ('was', 68), ('as', 64), ('to', 62)] |  |  | TUTOR.py 1000
2025-04-17 05:25:20 | 300 | LR0.00035 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | topTokens[(',', 314), ('a', 263), ('of', 153), ('.', 146), ('and', 132), ('it', 117), ('was', 92), ('the', 86), ('very', 76), ('that', 75)] |  |  | TUTOR.py 1000
[charis]--- 2025-04-17 05:43:39 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]
2025-04-17 05:47:12 | 100 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:0.0003 | n_weightNormMax:0.0003 | n_weightNormMin:0.0004 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | windowWeightsW28:1.00445 (0.11),W24:1.00309 (0.11),W2:1.00146 (0.11),W8:1.00043 (0.11),W20:0.99950 (0.11),W12:0.99829 (0.11),W4:0.99766 (0.11),W32:0.99729 (0.11),W16:0.99606 (0.11) | judgeBiasW32:-0.00429 (0.11),W2:-0.00429 (0.11),W4:-0.00429 (0.11),W8:-0.00429 (0.11),W12:-0.00429 (0.11),W16:-0.00429 (0.11),W20:-0.00429 (0.11),W24:-0.00429 (0.11),W28:-0.00429 (0.11) | credibilityBiasW28:0.11154 (0.00),W24:0.11139 (0.00),W2:0.11135 (0.00),W12:0.11127 (0.00),W8:0.11123 (0.00),W20:0.11102 (-0.00),W4:0.11081 (-0.00),W32:0.11074 (-0.00),W16:0.11065 (-0.00) | topTokens[('it', 136), (',', 122), ('a', 110), ('of', 86), ('.', 72), ('and', 63), ('b', 62), ('the', 56), ('be', 53), ('door', 41)] |  | entropyBonus: -0.0 blend: 0.496 top windows: W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 1000
--- 2025-04-17 05:48:30 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]
2025-04-17 05:52:24 | 100 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:0.0003 | n_weightNormMax:0.0003 | n_weightNormMin:0.0004 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | windowWeightsW2:1.00602 (0.11),W8:1.00399 (0.11),W28:1.00210 (0.11),W32:1.00207 (0.11),W12:1.00077 (0.11),W24:1.00036 (0.11),W4:0.99981 (0.11),W16:0.99787 (0.11),W20:0.99545 (0.11) | judgeBiasW32:0.00605 (0.11),W2:0.00605 (0.11),W4:0.00605 (0.11),W8:0.00605 (0.11),W12:0.00605 (0.11),W16:0.00605 (0.11),W20:0.00605 (0.11),W24:0.00605 (0.11),W28:0.00605 (0.11) | credibilityBiasW8:0.11156 (0.00),W28:0.11135 (0.00),W32:0.11135 (0.00),W24:0.11116 (0.00),W2:0.11113 (0.00),W4:0.11110 (-0.00),W12:0.11088 (-0.00),W16:0.11088 (-0.00),W20:0.11061 (-0.00) | topTokens[('a', 141), (',', 126), ('it', 118), ('.', 100), ('as', 81), ('to', 78), ('and', 74), ('door', 67), ('ss', 63), ('mo', 53)] |  | entropyBonus: -0.0 blend: 0.502 top windows: W24:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 1000
2025-04-17 05:56:23 | 200 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:0.0004 | n_weightNormMax:0.0003 | n_weightNormMin:0.0004 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | windowWeightsW2:1.00976 (0.11),W28:1.00615 (0.11),W12:1.00455 (0.11),W8:1.00396 (0.11),W24:1.00034 (0.11),W4:0.99978 (0.11),W32:0.99794 (0.11),W16:0.99582 (0.11),W20:0.99546 (0.11) | judgeBiasW32:0.00983 (0.11),W2:0.00983 (0.11),W4:0.00983 (0.11),W8:0.00983 (0.11),W12:0.00983 (0.11),W16:0.00983 (0.11),W20:0.00983 (0.11),W24:0.00983 (0.11),W28:0.00983 (0.11) | credibilityBiasW28:0.11183 (0.01),W8:0.11159 (0.00),W24:0.11119 (0.00),W2:0.11115 (0.00),W4:0.11112 (-0.00),W32:0.11092 (-0.00),W12:0.11091 (-0.00),W20:0.11064 (-0.00),W16:0.11064 (-0.00) | topTokens[(',', 285), ('a', 221), ('it', 197), ('door', 131), ('of', 129), ('made', 127), ('and', 114), ('.', 109), ('to', 91), ('as', 91)] |  | entropyBonus: -0.0 blend: 0.498 top windows: W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 1000
--- 2025-04-17 05:58:05 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 06:01:41 | 100 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:0.0003 | n_weightNormMax:0.0003 | n_weightNormMin:0.0004 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | windowWeightsW28:1.00339 (0.11),W20:1.00207 (0.11),W8:1.00207 (0.11),W12:1.00204 (0.11),W4:0.99786 (0.11),W32:0.99786 (0.11),W16:0.99786 (0.11),W24:0.99786 (0.11),W2:0.99520 (0.11) | judgeBiasW32:0.00299 (0.11),W2:0.00299 (0.11),W4:0.00299 (0.11),W8:0.00299 (0.11),W12:0.00299 (0.11),W16:0.00299 (0.11),W20:0.00299 (0.11),W24:0.00299 (0.11),W28:0.00299 (0.11) | credibilityBiasW28:0.11153 (0.00),W20:0.11139 (0.00),W8:0.11139 (0.00),W12:0.11138 (0.00),W4:0.11092 (-0.00),W32:0.11092 (-0.00),W24:0.11092 (-0.00),W16:0.11092 (-0.00),W2:0.11063 (-0.00) | topTokens[('a', 149), ('it', 85), (',', 84), ('ss', 72), ('mo', 61), ('door', 58), ('.', 54), ('of', 47), ('as', 47), ('and', 46)] |  | entropyBonus: 1.9272772960121484e-31 blend: 0.502 top windows: W28:1.00,W24:0.00,W32:0.00,W2:0.00 | TUTOR.py 1000
--- 2025-04-17 06:04:53 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 06:07:27 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 06:09:30 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 06:13:10 | 100 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | windowWeightsW4:1.00374 (0.11),W20:1.00323 (0.11),W12:1.00308 (0.11),W32:1.00330 (0.11),W28:1.00162 (0.11),W2:1.00144 (0.11),W24:1.00148 (0.11),W16:0.99952 (0.11),W8:0.99786 (0.11) | judgeBiasW32:0.00115 (0.11),W2:0.00115 (0.11),W4:0.00115 (0.11),W8:0.00115 (0.11),W12:0.00115 (0.11),W16:0.00115 (0.11),W20:0.00115 (0.11),W24:0.00115 (0.11),W28:0.00115 (0.11) | credibilityBiasW32:0.11138 (0.00),W20:0.11135 (0.00),W12:0.11129 (0.00),W28:0.11128 (0.00),W24:0.11117 (0.00),W4:0.11112 (0.00),W2:0.11110 (0.00),W8:0.11071 (-0.00),W16:0.11060 (-0.00) | topTokens[('it', 128), ('a', 99), (',', 80), ('as', 70), ('ss', 64), ('door', 62), ('b', 50), ('to', 50), ('used', 48), ('.', 42)] |  | entropyBonus: -0.0 blend: 0.501 top windows: W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 1000
--- 2025-04-17 06:16:35 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 06:20:06 | 100 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | windowWeightsW28:1.00579 (0.11),W16:1.00361 (0.11),W12:1.00314 (0.11),W2:1.00347 (0.11),W24:1.00274 (0.11),W20:1.00204 (0.11),W32:1.00020 (0.11),W4:0.99823 (0.11),W8:0.99678 (0.11) | judgeBiasW32:0.00282 (0.11),W2:0.00282 (0.11),W4:0.00282 (0.11),W8:0.00282 (0.11),W12:0.00282 (0.11),W16:0.00282 (0.11),W20:0.00282 (0.11),W24:0.00282 (0.11),W28:0.00282 (0.11) | credibilityBiasW24:0.11152 (0.00),W12:0.11151 (0.00),W2:0.11146 (0.00),W28:0.11143 (0.00),W16:0.11133 (0.00),W4:0.11087 (-0.00),W20:0.11083 (-0.00),W8:0.11061 (-0.00),W32:0.11045 (-0.01) | topTokens[(',', 146), ('a', 124), ('and', 90), ('it', 82), ('to', 81), ('.', 77), ('be', 75), ('as', 73), ('ss', 72), ('mo', 70)] |  | entropyBonus: 0.009314139373600483 blend: 0.501 top windows: W12:1.00,W28:0.00,W16:0.00,W32:0.00 | TUTOR.py 1000
--- 2025-04-17 06:23:34 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 06:27:18 | 100 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:7.1039 | windowWeightsW20:1.00476 (0.11),W24:1.00469 (0.11),W28:1.00223 (0.11),W4:1.00046 (0.11),W12:0.99951 (0.11),W32:0.99859 (0.11),W8:0.99848 (0.11),W2:0.99522 (0.11),W16:0.99344 (0.11) | judgeBiasW32:-0.00148 (0.11),W2:-0.00148 (0.11),W4:-0.00148 (0.11),W8:-0.00148 (0.11),W12:-0.00148 (0.11),W16:-0.00148 (0.11),W20:-0.00148 (0.11),W24:-0.00148 (0.11),W28:-0.00148 (0.11) | credibilityBiasW8:0.11163 (0.00),W20:0.11163 (0.00),W28:0.11134 (0.00),W24:0.11133 (0.00),W12:0.11117 (0.00),W32:0.11093 (-0.00),W4:0.11086 (-0.00),W2:0.11056 (-0.00),W16:0.11055 (-0.00) | topTokens[('as', 75), ('to', 65), (',', 63), ('it', 63), ('b', 51), ('was', 50), ('ark', 39), ('a', 39), ('ss', 37), ('of', 35)] |  | entropyBonus: 8.533005328115143e-34 blend: 0.497 top windows: W24:1.00,W28:0.00,W32:0.00,W2:0.00 | TUTOR.py 1000
2025-04-17 06:30:47 | 200 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:15.6257 | windowWeightsW20:1.00463 (0.11),W32:1.00268 (0.11),W24:1.00130 (0.11),W12:0.99946 (0.11),W28:0.99808 (0.11),W4:0.99706 (0.11),W8:0.99509 (0.11),W2:0.99508 (0.11),W16:0.99324 (0.11) | judgeBiasW32:-0.00485 (0.11),W2:-0.00485 (0.11),W4:-0.00485 (0.11),W8:-0.00485 (0.11),W12:-0.00485 (0.11),W16:-0.00485 (0.11),W20:-0.00485 (0.11),W24:-0.00485 (0.11),W28:-0.00485 (0.11) | credibilityBiasW8:0.11164 (0.00),W20:0.11163 (0.00),W32:0.11139 (0.00),W24:0.11133 (0.00),W12:0.11117 (0.00),W28:0.11088 (-0.00),W4:0.11085 (-0.00),W2:0.11056 (-0.00),W16:0.11055 (-0.00) | topTokens[(',', 198), ('it', 160), ('.', 123), ('a', 113), ('and', 104), ('to', 94), ('of', 85), ('was', 83), ('mo', 82), ('as', 78)] |  | entropyBonus: -0.0 blend: 0.492 top windows: W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 1000
2025-04-17 06:34:22 | 300 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0001 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:7.3004 | windowWeightsW20:1.00457 (0.11),W32:1.00265 (0.11),W24:1.00057 (0.11),W12:0.99941 (0.11),W28:0.99800 (0.11),W2:0.99648 (0.11),W4:0.99634 (0.11),W8:0.99436 (0.11),W16:0.99318 (0.11) | judgeBiasW32:-0.00553 (0.11),W2:-0.00553 (0.11),W4:-0.00553 (0.11),W8:-0.00553 (0.11),W12:-0.00553 (0.11),W16:-0.00553 (0.11),W20:-0.00553 (0.11),W24:-0.00553 (0.11),W28:-0.00553 (0.11) | credibilityBiasW8:0.11162 (0.00),W20:0.11162 (0.00),W32:0.11138 (0.00),W24:0.11131 (0.00),W12:0.11116 (0.00),W28:0.11086 (-0.00),W4:0.11084 (-0.00),W2:0.11070 (-0.00),W16:0.11053 (-0.00) | topTokens[(',', 258), ('a', 241), ('it', 160), ('.', 146), ('of', 128), ('was', 113), ('to', 112), ('and', 104), ('ss', 93), ('the', 93)] |  | entropyBonus: -0.0 blend: 0.491 top windows: W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
--- 2025-04-17 06:35:52 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 06:38:53 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 06:42:25 | 100 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:34.8038 | windowWeightsW20:1.00290 (0.11),W16:1.00206 (0.11),W4:1.00205 (0.11),W24:1.00196 (0.11),W28:1.00181 (0.11),W32:1.00123 (0.11),W12:0.99973 (0.11),W8:0.99932 (0.11),W2:0.99786 (0.11) | judgeBiasW32:-0.00294 (0.11),W2:-0.00294 (0.11),W4:-0.00294 (0.11),W8:-0.00294 (0.11),W12:-0.00294 (0.11),W16:-0.00294 (0.11),W20:-0.00294 (0.11),W24:-0.00294 (0.11),W28:-0.00294 (0.11) | credibilityBiasW20:0.11128 (0.00),W24:0.11119 (0.00),W32:0.11119 (0.00),W4:0.11119 (0.00),W16:0.11119 (0.00),W28:0.11119 (0.00),W12:0.11119 (0.00),W8:0.11088 (-0.00),W2:0.11072 (-0.00) | topTokens[('a', 139), ('it', 116), (',', 104), ('to', 68), ('mo', 65), ('as', 58), ('b', 57), ('.', 56), ('door', 55), ('of', 49)] | avgLoss/100: 34.80381393432617 |  | entropyBonus: -0.0 blend: 0.497 top windows: W24:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 1000
--- 2025-04-17 06:44:44 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 06:48:24 | 100 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:129.6835 | windowWeightsW4:1.00598 (0.11),W12:1.00386 (0.11),W8:1.00109 (0.11),W32:1.00096 (0.11),W2:1.00059 (0.11),W16:0.99949 (0.11),W24:0.99745 (0.11),W28:0.99731 (0.11),W20:0.99446 (0.11) | judgeBiasW32:0.00226 (0.11),W2:0.00226 (0.11),W4:0.00226 (0.11),W8:0.00226 (0.11),W12:0.00226 (0.11),W16:0.00226 (0.11),W20:0.00226 (0.11),W24:0.00226 (0.11),W28:0.00226 (0.11) | credibilityBiasW4:0.11210 (0.01),W32:0.11133 (0.00),W12:0.11131 (0.00),W8:0.11099 (-0.00),W2:0.11098 (-0.00),W24:0.11095 (-0.00),W28:0.11093 (-0.00),W16:0.11079 (-0.00),W20:0.11062 (-0.01) | topTokens[('a', 115), (',', 91), ('it', 69), ('b', 67), ('door', 58), ('and', 57), ('ark', 55), ('of', 54), ('.', 52), ('the', 52)] | avgLoss/100: 129.68350219726562 |  | entropyBonus: -0.0 blend: 0.502 top windows: W28:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 1000
2025-04-17 06:51:56 | 200 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:297.7158 | windowWeightsW4:1.00971 (0.11),W8:1.00490 (0.11),W2:1.00437 (0.11),W12:1.00393 (0.11),W16:1.00199 (0.11),W32:1.00000 (0.11),W20:0.99816 (0.11),W28:0.99736 (0.11),W24:0.99732 (0.11) | judgeBiasW32:0.00610 (0.11),W2:0.00610 (0.11),W4:0.00610 (0.11),W8:0.00610 (0.11),W12:0.00610 (0.11),W16:0.00610 (0.11),W20:0.00610 (0.11),W24:0.00610 (0.11),W28:0.00610 (0.11) | credibilityBiasW4:0.11208 (0.01),W12:0.11128 (0.00),W32:0.11119 (0.00),W20:0.11100 (-0.00),W8:0.11095 (-0.00),W2:0.11094 (-0.00),W24:0.11091 (-0.00),W28:0.11090 (-0.00),W16:0.11076 (-0.00) | topTokens[(',', 242), ('a', 223), ('of', 143), ('it', 118), ('the', 113), ('and', 100), ('to', 79), ('.', 76), ('was', 75), ('door', 72)] | avgLoss/100: 297.7157897949219 |  | entropyBonus: -0.0 blend: 0.499 top windows: W32:1.00,W2:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
--- 2025-04-17 06:53:00 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 06:56:40 | 100 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:11.7888 | windowWeightsW4:1.00164 (0.11),W12:1.00150 (0.11),W2:1.00149 (0.11),W32:1.00019 (0.11),W28:0.99922 (0.11),W20:0.99915 (0.11),W8:0.99839 (0.11),W24:0.99819 (0.11),W16:0.99757 (0.11) | judgeBiasW32:-0.00157 (0.11),W2:-0.00157 (0.11),W4:-0.00157 (0.11),W8:-0.00157 (0.11),W12:-0.00157 (0.11),W16:-0.00157 (0.11),W20:-0.00157 (0.11),W24:-0.00157 (0.11),W28:-0.00157 (0.11) | credibilityBiasW4:0.11142 (0.00),W12:0.11138 (0.00),W2:0.11138 (0.00),W32:0.11117 (0.00),W8:0.11113 (-0.00),W28:0.11106 (-0.00),W24:0.11092 (-0.00),W20:0.11086 (-0.00),W16:0.11068 (-0.00) | topTokens[('ss', 176), ('as', 93), ('a', 81), (',', 78), ('it', 57), ('.', 52), ('r', 50), ('b', 49), ('mo', 47), ('and', 41)] | avgLoss/100: 11.788771073818207 |  | entropyBonus: -0.0 blend: 0.499 top windows: W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 07:00:12 | 200 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:9.7295 | windowWeightsW4:1.00096 (0.11),W12:1.00082 (0.11),W2:1.00081 (0.11),W32:1.00015 (0.11),W28:0.99940 (0.11),W20:0.99908 (0.11),W8:0.99772 (0.11),W24:0.99751 (0.11),W16:0.99665 (0.11) | judgeBiasW32:-0.00221 (0.11),W2:-0.00221 (0.11),W4:-0.00221 (0.11),W8:-0.00221 (0.11),W12:-0.00221 (0.11),W16:-0.00221 (0.11),W20:-0.00221 (0.11),W24:-0.00221 (0.11),W28:-0.00221 (0.11) | credibilityBiasW4:0.11142 (0.00),W12:0.11139 (0.00),W2:0.11139 (0.00),W32:0.11118 (0.00),W8:0.11114 (-0.00),W28:0.11110 (-0.00),W24:0.11092 (-0.00),W20:0.11086 (-0.00),W16:0.11059 (-0.01) | topTokens[('ss', 176), (',', 175), ('a', 150), ('of', 135), ('.', 109), ('and', 104), ('as', 104), ('the', 89), ('it', 77), ('door', 51)] | avgLoss/100: 9.729470710754395 |  | entropyBonus: -0.0 blend: 0.499 top windows: W32:1.00,W2:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 07:03:41 | 300 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:8.0449 | windowWeightsW2:1.00938 (0.11),W32:1.00541 (0.11),W12:1.00273 (0.11),W8:1.00289 (0.11),W24:1.00269 (0.11),W4:1.00002 (0.11),W20:0.99906 (0.11),W16:0.99681 (0.11),W28:0.99435 (0.11) | judgeBiasW32:0.00300 (0.11),W2:0.00300 (0.11),W4:0.00300 (0.11),W8:0.00300 (0.11),W12:0.00300 (0.11),W16:0.00300 (0.11),W20:0.00300 (0.11),W24:0.00300 (0.11),W28:0.00300 (0.11) | credibilityBiasW2:0.11211 (0.01),W32:0.11173 (0.01),W8:0.11160 (0.00),W24:0.11147 (0.00),W20:0.11082 (-0.00),W4:0.11079 (-0.00),W16:0.11057 (-0.00),W28:0.11050 (-0.01),W12:0.11039 (-0.01) | topTokens[(',', 258), ('a', 222), ('ss', 193), ('of', 137), ('.', 135), ('as', 119), ('and', 110), ('the', 106), ('it', 87), ('to', 80)] | avgLoss/100: 8.044944796562195 |  | entropyBonus: 1.3437414319745762e-15 blend: 0.495 top windows: W28:1.00,W32:0.00,W24:0.00,W2:0.00 | TUTOR.py 1000
--- 2025-04-17 07:04:15 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 07:08:34 | 100 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:11.4706 | windowWeightsW24:1.00391 (0.11),W32:1.00201 (0.11),W20:0.99981 (0.11),W12:0.99702 (0.11),W8:0.99652 (0.11),W28:0.99585 (0.11),W4:0.99453 (0.11),W2:0.99450 (0.11),W16:0.99276 (0.11) | judgeBiasW32:-0.00540 (0.11),W2:-0.00540 (0.11),W4:-0.00540 (0.11),W8:-0.00540 (0.11),W12:-0.00540 (0.11),W16:-0.00540 (0.11),W20:-0.00540 (0.11),W24:-0.00540 (0.11),W28:-0.00540 (0.11) | credibilityBiasW24:0.11155 (0.00),W32:0.11134 (0.00),W8:0.11134 (0.00),W12:0.11134 (0.00),W20:0.11110 (-0.00),W4:0.11091 (-0.00),W2:0.11087 (-0.00),W16:0.11087 (-0.00),W28:0.11066 (-0.00) | topTokens[('a', 170), ('it', 137), (',', 103), ('and', 95), ('door', 89), ('as', 69), ('to', 64), ('of', 48), ('b', 43), ('the', 42)] | avgLoss/100: 11.470579028129578 |  | entropyBonus: -0.0 blend: 0.499 top windows: W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 1000
--- 2025-04-17 07:09:54 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:10:34 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:11:35 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:12:07 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 07:16:15 | 100 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:8.1715 | windowWeightsW28:1.00215 (0.11),W4:1.00065 (0.11),W8:0.99919 (0.11),W20:0.99812 (0.11),W2:0.99806 (0.11),W24:0.99704 (0.11),W12:0.99301 (0.11),W16:0.99218 (0.11),W32:0.98976 (0.11) | judgeBiasW32:-0.00418 (0.11),W2:-0.00418 (0.11),W4:-0.00418 (0.11),W8:-0.00418 (0.11),W12:-0.00418 (0.11),W16:-0.00418 (0.11),W20:-0.00418 (0.11),W24:-0.00418 (0.11),W28:-0.00418 (0.11) | credibilityBiasW28:0.00370 (0.11),W24:0.00077 (0.11),W4:0.00074 (0.11),W20:-0.00002 (0.11),W8:-0.00026 (0.11),W2:-0.00075 (0.11),W12:-0.00330 (0.11),W16:-0.00668 (0.11),W32:-0.00902 (0.11) | topTokens[('a', 108), (',', 105), ('.', 94), ('ss', 92), ('it', 83), ('as', 71), ('of', 56), ('door', 56), ('and', 50), ('to', 43)] | avgLoss/100: 8.171509747505189 |  | entropyBonus: -0.0 blend: 0.499 top windows: W28:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 1000
2025-04-17 07:20:37 | 200 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0001 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:5.5033 | windowWeightsW24:1.00291 (0.11),W4:1.00058 (0.11),W8:0.99902 (0.11),W20:0.99801 (0.11),W2:0.99798 (0.11),W32:0.99761 (0.11),W28:0.99383 (0.11),W12:0.99225 (0.11),W16:0.99211 (0.11) | judgeBiasW32:-0.00487 (0.11),W2:-0.00487 (0.11),W4:-0.00487 (0.11),W8:-0.00487 (0.11),W12:-0.00487 (0.11),W16:-0.00487 (0.11),W20:-0.00487 (0.11),W24:-0.00487 (0.11),W28:-0.00487 (0.11) | credibilityBiasW24:0.00688 (0.11),W4:0.00074 (0.11),W20:-0.00006 (0.11),W8:-0.00023 (0.11),W2:-0.00075 (0.11),W32:-0.00105 (0.11),W12:-0.00330 (0.11),W28:-0.00457 (0.11),W16:-0.00668 (0.11) | topTokens[(',', 245), ('a', 214), ('of', 133), ('.', 131), ('it', 111), ('and', 97), ('ss', 92), ('door', 81), ('as', 80), ('the', 73)] | avgLoss/100: 5.503335902690887 |  | entropyBonus: -0.0 blend: 0.500 top windows: W32:1.00,W2:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
--- 2025-04-17 07:21:02 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 07:25:17 | 100 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:17.1120 | windowWeightsW2:1.00599 (0.11),W16:1.00487 (0.11),W28:1.00450 (0.11),W12:1.00360 (0.11),W24:1.00360 (0.11),W20:1.00302 (0.11),W8:0.99955 (0.11),W32:0.99944 (0.11),W4:0.99917 (0.11) | judgeBiasW32:0.00367 (0.11),W2:0.00367 (0.11),W4:0.00367 (0.11),W8:0.00367 (0.11),W12:0.00367 (0.11),W16:0.00367 (0.11),W20:0.00367 (0.11),W24:0.00367 (0.11),W28:0.00367 (0.11) | credibilityBiasW2:0.00504 (0.11),W28:0.00351 (0.11),W16:0.00202 (0.11),W24:0.00146 (0.11),W20:0.00081 (0.11),W12:-0.00071 (0.11),W4:-0.00244 (0.11),W32:-0.00285 (0.11),W8:-0.00543 (0.11) | topTokens[('a', 113), ('it', 96), (',', 86), ('mo', 72), ('as', 71), ('to', 66), ('and', 61), ('.', 55), ('ss', 48), ('the', 45)] | avgLoss/100: 17.112048678398132 |  | entropyBonus: -0.0 blend: 0.504 top windows: W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 1000
--- 2025-04-17 07:26:44 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:29:33 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:30:10 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:30:57 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:35:04 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 07:39:16 | 100 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:16.0484 | windowWeightsW28:1.00641 (0.11),W16:1.00555 (0.11),W24:1.00449 (0.11),W4:1.00285 (0.11),W12:1.00277 (0.11),W32:0.99943 (0.11),W8:0.99789 (0.11),W20:0.99598 (0.11),W2:0.99443 (0.11) | judgeBiasW32:0.00284 (0.11),W2:0.00284 (0.11),W4:0.00284 (0.11),W8:0.00284 (0.11),W12:0.00284 (0.11),W16:0.00284 (0.11),W20:0.00284 (0.11),W24:0.00284 (0.11),W28:0.00284 (0.11) | credibilityBiasW28:0.00648 (0.11),W4:0.00241 (0.11),W16:0.00241 (0.11),W24:0.00240 (0.11),W32:-0.00051 (0.11),W20:-0.00104 (0.11),W12:-0.00237 (0.11),W8:-0.00240 (0.11),W2:-0.00604 (0.11) | topTokens[(',', 125), ('and', 84), ('a', 83), ('to', 64), ('it', 61), ('ss', 60), ('of', 54), ('used', 50), ('.', 49), ('as', 48)] | avgLoss/100: 16.04841863155365 |  | entropyBonus: -0.0 blend: 0.496 top windows: W28:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 1000
--- 2025-04-17 07:39:36 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:41:15 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:41:59 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:42:33 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:43:40 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:44:51 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:47:54 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:48:28 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:49:10 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:50:03 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:51:01 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:51:48 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:52:54 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 07:53:43 | 100 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:0.0000 | n_biasesStd:0.0000 | n_biasesMin:0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:7.4488 | windowWeightsW32:1.00000 (0.11),W2:1.00000 (0.11),W4:1.00000 (0.11),W8:1.00000 (0.11),W12:1.00000 (0.11),W16:1.00000 (0.11),W20:1.00000 (0.11),W24:1.00000 (0.11),W28:1.00000 (0.11) | judgeBiasW32:0.00000 (0.11),W2:0.00000 (0.11),W4:0.00000 (0.11),W8:0.00000 (0.11),W12:0.00000 (0.11),W16:0.00000 (0.11),W20:0.00000 (0.11),W24:0.00000 (0.11),W28:0.00000 (0.11) | credibilityBiasW32:0.00000 (0.11),W2:0.00000 (0.11),W4:0.00000 (0.11),W8:0.00000 (0.11),W12:0.00000 (0.11),W16:0.00000 (0.11),W20:0.00000 (0.11),W24:0.00000 (0.11),W28:0.00000 (0.11) | topTokens[('still', 6), ('art', 5), ('th', 5), ('illy', 5), ('hell', 4), ('upset', 4), ('us', 4), ('(', 4), ('half', 4), ('again', 4)] | avgLoss/100: 7.44879259109497 |  | entropyBonus: 2.194667339324951 blend: 0.500 top windows: W4:0.13,W2:0.12,W8:0.12,W12:0.11 | TUTOR.py 1000
--- 2025-04-17 07:54:10 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:57:46 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:58:49 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:00:13 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:01:15 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:01:45 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:03:21 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:03:46 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 08:08:01 | 100 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:6.9802 | windowWeightsW4:1.00270 (0.11),W32:1.00257 (0.11),W28:1.00115 (0.11),W20:1.00112 (0.11),W24:1.00024 (0.11),W8:0.99918 (0.11),W16:0.99868 (0.11),W12:0.99733 (0.11),W2:0.99715 (0.11) | judgeBiasW2:0.00301 (0.11),W12:0.00301 (0.11),W16:0.00301 (0.11),W20:0.00301 (0.11),W8:0.00301 (0.11),W28:0.00301 (0.11),W32:0.00301 (0.11),W24:0.00301 (0.11),W4:0.00301 (0.11) | credibilityBiasW32:0.00322 (0.11),W4:0.00277 (0.11),W8:0.00223 (0.11),W20:0.00114 (0.11),W28:0.00086 (0.11),W24:0.00062 (0.11),W16:-0.00124 (0.11),W12:-0.00263 (0.11),W2:-0.00277 (0.11) | topTokens[(',', 115), ('a', 113), ('it', 88), ('and', 67), ('of', 67), ('as', 58), ('door', 53), ('b', 50), ('.', 48), ('used', 48)] | avgLoss/100: 6.980235598087311 |  | entropyBonus: -0.0 blend: 0.500 top windows: W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 1000
--- 2025-04-17 08:09:15 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:09:52 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:10:12 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:12:02 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:14:58 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:16:03 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:16:45 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:17:12 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:18:09 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:19:00 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:20:46 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 08:24:47 | 100 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:7.7023 | windowWeightsW24:1.00282 (0.11),W32:1.00282 (0.11),W2:1.00115 (0.11),W4:0.99978 (0.11),W8:0.99959 (0.11),W28:0.99709 (0.11),W16:0.99706 (0.11),W20:0.99705 (0.11),W12:0.99506 (0.11) | judgeBiasW32:0.00325 (0.11),W24:0.00325 (0.11),W2:0.00325 (0.11),W4:0.00324 (0.11),W12:0.00324 (0.11),W8:0.00324 (0.11),W16:0.00324 (0.11),W20:0.00324 (0.11),W28:0.00324 (0.11) | credibilityBiasW8:0.00417 (0.11),W20:0.00288 (0.11),W16:0.00288 (0.11),W28:0.00288 (0.11),W2:0.00172 (0.11),W12:0.00042 (0.11),W24:-0.00288 (0.11),W32:-0.00288 (0.11),W4:-0.00347 (0.11) | topTokens[('a', 111), (',', 103), ('.', 82), ('it', 77), ('b', 66), ('the', 61), ('as', 61), ('door', 56), ('and', 56), ('of', 50)] | avgLoss/100: 7.702295207977295 |  | entropyBonus: -0.0 blend: 0.499 top windows: W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 08:28:43 | 200 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:9.5438 | windowWeightsW2:1.00417 (0.11),W32:1.00270 (0.11),W24:1.00267 (0.11),W8:0.99887 (0.11),W16:0.99695 (0.11),W20:0.99691 (0.11),W28:0.99661 (0.11),W4:0.99615 (0.11),W12:0.99498 (0.11) | judgeBiasW12:0.00127 (0.11),W4:0.00127 (0.11),W20:0.00126 (0.11),W28:0.00126 (0.11),W16:0.00126 (0.11),W8:0.00126 (0.11),W2:0.00126 (0.11),W32:0.00126 (0.11),W24:0.00126 (0.11) | credibilityBiasW2:0.00710 (0.11),W8:0.00336 (0.11),W20:0.00288 (0.11),W28:0.00288 (0.11),W16:0.00288 (0.11),W12:0.00042 (0.11),W4:-0.00285 (0.11),W24:-0.00288 (0.11),W32:-0.00288 (0.11) | topTokens[(',', 298), ('a', 208), ('of', 139), ('the', 132), ('.', 109), ('and', 109), ('it', 106), ('was', 94), ('door', 71), ('b', 71)] | avgLoss/100: 9.543778381347657 |  | entropyBonus: -0.0 blend: 0.498 top windows: W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 08:32:45 | 300 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0001 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:8.2937 | windowWeightsW28:1.00784 (0.11),W2:1.00410 (0.11),W24:1.00261 (0.11),W8:0.99914 (0.11),W16:0.99689 (0.11),W20:0.99685 (0.11),W4:0.99608 (0.11),W32:0.99532 (0.11),W12:0.99453 (0.11) | judgeBiasW12:0.00205 (0.11),W4:0.00205 (0.11),W20:0.00205 (0.11),W16:0.00205 (0.11),W28:0.00205 (0.11),W2:0.00205 (0.11),W8:0.00204 (0.11),W32:0.00204 (0.11),W24:0.00204 (0.11) | credibilityBiasW2:0.00710 (0.11),W20:0.00288 (0.11),W16:0.00288 (0.11),W12:0.00262 (0.11),W8:0.00117 (0.11),W28:0.00062 (0.11),W32:-0.00266 (0.11),W4:-0.00285 (0.11),W24:-0.00288 (0.11) | topTokens[(',', 383), ('a', 310), ('of', 192), ('.', 157), ('and', 137), ('the', 132), ('it', 125), ('was', 122), ('door', 71), ('b', 71)] | avgLoss/100: 8.293664894104005 |  | entropyBonus: -0.0 blend: 0.497 top windows: W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
--- 2025-04-17 08:35:23 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:36:08 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:39:01 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 08:43:01 | 100 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:7.8970 | windowWeightsW32:1.00645 (0.11),W8:1.00523 (0.11),W24:1.00506 (0.11),W12:1.00077 (0.11),W20:0.99922 (0.11),W16:0.99609 (0.11),W28:0.99375 (0.11),W2:0.99271 (0.11),W4:0.99271 (0.11) | judgeBiasW20:0.00074 (0.11),W12:0.00074 (0.11),W4:0.00074 (0.11),W2:0.00074 (0.11),W28:0.00074 (0.11),W24:0.00074 (0.11),W16:0.00074 (0.11),W8:0.00074 (0.11),W32:0.00074 (0.11) | credibilityBiasW2:0.00671 (0.11),W20:0.00602 (0.11),W16:0.00053 (0.11),W24:0.00052 (0.11),W8:-0.00002 (0.11),W12:-0.00023 (0.11),W28:-0.00211 (0.11),W4:-0.00257 (0.11),W32:-0.00755 (0.11) | topTokens[('.', 277), ('t', 124), ("'", 119), ('e', 118), ('a', 107), ('love', 104), ('you', 100), ('im', 97), ('i', 92), ('je', 90)] | avgLoss/100: 7.896995778083801 |  | entropyBonus: -0.0 blend: 0.501 top windows: W28:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 1000
2025-04-17 08:47:18 | 200 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:13.3628 | windowWeightsW32:1.01170 (0.11),W8:1.00494 (0.11),W12:1.00069 (0.11),W16:1.00049 (0.11),W20:0.99915 (0.11),W24:0.99809 (0.11),W28:0.99368 (0.11),W4:0.99264 (0.11),W2:0.99204 (0.11) | judgeBiasW20:0.00082 (0.11),W12:0.00082 (0.11),W24:0.00082 (0.11),W4:0.00082 (0.11),W28:0.00082 (0.11),W2:0.00082 (0.11),W8:0.00082 (0.11),W16:0.00082 (0.11),W32:0.00082 (0.11) | credibilityBiasW2:0.00731 (0.11),W20:0.00602 (0.11),W24:0.00131 (0.11),W8:0.00004 (0.11),W12:-0.00023 (0.11),W16:-0.00110 (0.11),W28:-0.00211 (0.11),W32:-0.00231 (0.11),W4:-0.00257 (0.11) | topTokens[('.', 656), ('e', 263), ('a', 261), ("'", 259), ('im', 252), ('t', 244), ('je', 232), ('you', 175), ('i', 166), ('love', 154)] | avgLoss/100: 13.362775120735169 |  | entropyBonus: 1.8446676477990032e-11 blend: 0.500 top windows: W16:1.00,W12:0.00,W32:0.00,W2:0.00 | TUTOR.py 1000
2025-04-17 08:51:32 | 300 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:29.1086 | windowWeightsW32:1.01864 (0.11),W8:1.00487 (0.11),W12:1.00062 (0.11),W16:1.00041 (0.11),W24:0.99802 (0.11),W28:0.99547 (0.11),W4:0.99256 (0.11),W20:0.99206 (0.11),W2:0.99197 (0.11) | judgeBiasW32:0.00577 (0.11),W16:0.00576 (0.11),W8:0.00575 (0.11),W12:0.00575 (0.11),W28:0.00574 (0.11),W20:0.00574 (0.11),W24:0.00574 (0.11),W4:0.00574 (0.11),W2:0.00574 (0.11) | credibilityBiasW20:0.01304 (0.11),W2:0.00731 (0.11),W24:0.00131 (0.11),W8:0.00004 (0.11),W12:-0.00023 (0.11),W16:-0.00111 (0.11),W28:-0.00211 (0.11),W4:-0.00257 (0.11),W32:-0.00933 (0.11) | topTokens[('.', 837), ('a', 437), ('t', 426), ('im', 417), ('e', 417), ("'", 405), ('je', 363), ('you', 250), ('love', 232), ('i', 219)] | avgLoss/100: 29.10858597755432 |  | entropyBonus: -0.0 blend: 0.496 top windows: W32:1.00,W2:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 08:55:40 | 400 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:44.2413 | windowWeightsW32:1.01857 (0.11),W8:1.00480 (0.11),W12:1.00055 (0.11),W16:1.00034 (0.11),W24:0.99795 (0.11),W28:0.99540 (0.11),W4:0.99249 (0.11),W20:0.99199 (0.11),W2:0.99189 (0.11) | judgeBiasW32:0.00577 (0.11),W16:0.00576 (0.11),W8:0.00575 (0.11),W12:0.00575 (0.11),W28:0.00574 (0.11),W20:0.00574 (0.11),W24:0.00574 (0.11),W4:0.00574 (0.11),W2:0.00573 (0.11) | credibilityBiasW20:0.01304 (0.11),W2:0.00731 (0.11),W24:0.00131 (0.11),W8:0.00004 (0.11),W12:-0.00023 (0.11),W16:-0.00110 (0.11),W28:-0.00211 (0.11),W4:-0.00257 (0.11),W32:-0.00933 (0.11) | topTokens[('.', 997), ('t', 604), ('e', 546), ('je', 536), ('a', 526), ('im', 522), ("'", 498), ('you', 321), ('love', 314), ('i', 290)] | avgLoss/100: 44.241317176818846 |  | entropyBonus: -0.0 blend: 0.496 top windows: W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 08:59:52 | 500 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0001 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:73.8664 | windowWeightsW32:1.01850 (0.11),W8:1.00472 (0.11),W12:1.00048 (0.11),W16:1.00027 (0.11),W24:0.99787 (0.11),W28:0.99533 (0.11),W4:0.99242 (0.11),W20:0.99192 (0.11),W2:0.99161 (0.11) | judgeBiasW32:0.00577 (0.11),W16:0.00576 (0.11),W8:0.00575 (0.11),W12:0.00575 (0.11),W28:0.00574 (0.11),W20:0.00574 (0.11),W24:0.00574 (0.11),W4:0.00574 (0.11),W2:0.00574 (0.11) | credibilityBiasW20:0.01304 (0.11),W2:0.00737 (0.11),W24:0.00131 (0.11),W8:0.00004 (0.11),W12:-0.00023 (0.11),W16:-0.00110 (0.11),W28:-0.00211 (0.11),W4:-0.00257 (0.11),W32:-0.00934 (0.11) | topTokens[('.', 1304), ('t', 781), ('e', 666), ('im', 654), ('a', 650), ("'", 625), ('je', 608), ('you', 501), ('love', 465), ('i', 439)] | avgLoss/100: 73.86639661788941 |  | entropyBonus: -0.0 blend: 0.496 top windows: W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
--- 2025-04-17 09:00:45 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:02:44 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:04:05 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:05:07 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:05:56 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:08:21 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:11:55 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:14:25 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:15:18 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 09:18:41 | 100 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:5.7178 | windowWeightsW8:1.00524 (0.11),W24:1.00498 (0.11),W12:1.00302 (0.11),W16:1.00104 (0.11),W32:1.00002 (0.11),W2:0.99784 (0.11),W20:0.99627 (0.11),W28:0.99348 (0.11),W4:0.99267 (0.11) | judgeBiasW24:0.00648 (0.11),W8:0.00647 (0.11),W32:0.00647 (0.11),W2:0.00647 (0.11),W16:0.00647 (0.11),W20:0.00647 (0.11),W12:0.00647 (0.11),W4:0.00647 (0.11),W28:0.00647 (0.11) | credibilityBiasW24:0.00964 (0.11),W8:0.00618 (0.11),W16:0.00223 (0.11),W12:0.00157 (0.11),W32:-0.00304 (0.11),W2:-0.00374 (0.11),W20:-0.00407 (0.11),W28:-0.00560 (0.11),W4:-0.00746 (0.11) | topTokens[('.', 240), ('t', 146), ('a', 142), ('im', 120), ('love', 97), ("'", 94), ('for', 92), ('i', 88), ('e', 84), ('t', 77)] | avgLoss/100: 5.717782020568848 |  | top windows: W4:1.00,W28:0.00,W12:0.00,W16:0.00 | TUTOR.py 1000
2025-04-17 09:22:09 | 200 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:6.8292 | windowWeightsW12:1.00534 (0.11),W8:1.00384 (0.11),W16:1.00293 (0.11),W32:1.00139 (0.11),W24:0.99943 (0.11),W20:0.99885 (0.11),W2:0.99845 (0.11),W28:0.99759 (0.11),W4:0.98984 (0.11) | judgeBiasW4:0.00430 (0.11),W24:0.00430 (0.11),W2:0.00429 (0.11),W28:0.00429 (0.11),W20:0.00429 (0.11),W32:0.00429 (0.11),W8:0.00429 (0.11),W16:0.00429 (0.11),W12:0.00428 (0.11) | credibilityBiasW24:0.00840 (0.11),W12:0.00377 (0.11),W2:0.00319 (0.11),W16:0.00311 (0.11),W8:0.00221 (0.11),W32:-0.00146 (0.11),W20:-0.00148 (0.11),W28:-0.00884 (0.11),W4:-0.01023 (0.11) | topTokens[('.', 628), ('t', 285), ('im', 258), ('a', 258), ('je', 221), ("'", 207), ('e', 172), ('love', 171), ('t', 119), ('i', 117)] | avgLoss/100: 6.829227924346924 |  | top windows: W8:1.00,W16:0.00,W12:0.00,W32:0.00 | TUTOR.py 1000
--- 2025-04-17 09:23:18 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:23:59 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 09:27:23 | 100 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:9.0977 | windowWeightsW8:1.00528 (0.11),W32:1.00323 (0.11),W24:1.00130 (0.11),W20:0.99936 (0.11),W28:0.99883 (0.11),W4:0.99789 (0.11),W16:0.99765 (0.11),W12:0.99688 (0.11),W2:0.99531 (0.11) | judgeBiasW8:0.00654 (0.11),W32:0.00654 (0.11),W24:0.00654 (0.11),W28:0.00654 (0.11),W20:0.00654 (0.11),W2:0.00654 (0.11),W4:0.00654 (0.11),W16:0.00654 (0.11),W12:0.00654 (0.11) | credibilityBiasW28:0.00463 (0.11),W20:0.00310 (0.11),W16:0.00264 (0.11),W12:0.00176 (0.11),W2:0.00052 (0.11),W8:-0.00001 (0.11),W32:-0.00044 (0.11),W4:-0.00223 (0.11),W24:-0.00432 (0.11) | topTokens[('i', 244), ('it', 241), ('.', 197), ('!', 137), ('our', 67), ('s', 54), ('did', 42), ('happy', 35), ('am', 33), ('know', 25)] | avgLoss/100: 9.097689628601074 |  | top windows: W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 09:31:01 | 200 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:7.6992 | windowWeightsW8:1.00525 (0.11),W32:1.00319 (0.11),W24:1.00127 (0.11),W20:0.99932 (0.11),W28:0.99879 (0.11),W4:0.99827 (0.11),W16:0.99766 (0.11),W12:0.99683 (0.11),W2:0.99526 (0.11) | judgeBiasW8:0.00656 (0.11),W32:0.00656 (0.11),W24:0.00656 (0.11),W28:0.00656 (0.11),W20:0.00656 (0.11),W4:0.00656 (0.11),W2:0.00656 (0.11),W16:0.00656 (0.11),W12:0.00656 (0.11) | credibilityBiasW28:0.00464 (0.11),W20:0.00310 (0.11),W16:0.00259 (0.11),W12:0.00179 (0.11),W2:0.00054 (0.11),W8:-0.00003 (0.11),W32:-0.00044 (0.11),W4:-0.00295 (0.11),W24:-0.00433 (0.11) | topTokens[('i', 478), ('it', 415), ('.', 318), ('!', 266), (',', 159), ('our', 99), ('you', 93), ('know', 76), ('baby', 76), ('je', 74)] | avgLoss/100: 7.699154853820801 |  | top windows: W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 09:34:53 | 300 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:9.4244 | windowWeightsW32:1.01232 (0.11),W8:1.00503 (0.11),W4:1.00354 (0.11),W20:0.99928 (0.11),W16:0.99772 (0.11),W12:0.99679 (0.11),W24:0.99623 (0.11),W2:0.99522 (0.11),W28:0.98978 (0.11) | judgeBiasW32:0.00760 (0.11),W8:0.00760 (0.11),W4:0.00760 (0.11),W20:0.00760 (0.11),W16:0.00760 (0.11),W12:0.00759 (0.11),W2:0.00759 (0.11),W24:0.00759 (0.11),W28:0.00759 (0.11) | credibilityBiasW28:0.00966 (0.11),W20:0.00310 (0.11),W16:0.00252 (0.11),W12:0.00183 (0.11),W4:0.00067 (0.11),W2:0.00054 (0.11),W24:-0.00160 (0.11),W8:-0.00452 (0.11),W32:-0.00892 (0.11) | topTokens[('i', 578), ('.', 536), ('it', 453), ('!', 346), ('t', 206), (',', 202), ('a', 171), ('you', 169), ('e', 161), ('im', 150)] | avgLoss/100: 9.42440414428711 |  | top windows: W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 09:38:21 | 400 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:8.5244 | windowWeightsW32:1.01253 (0.11),W8:1.00497 (0.11),W20:1.00083 (0.11),W2:0.99942 (0.11),W4:0.99821 (0.11),W24:0.99809 (0.11),W12:0.99676 (0.11),W16:0.99162 (0.11),W28:0.98932 (0.11) | judgeBiasW28:0.00624 (0.11),W16:0.00623 (0.11),W8:0.00623 (0.11),W24:0.00623 (0.11),W12:0.00623 (0.11),W4:0.00623 (0.11),W32:0.00622 (0.11),W2:0.00622 (0.11),W20:0.00622 (0.11) | credibilityBiasW28:0.01011 (0.11),W16:0.00839 (0.11),W2:0.00606 (0.11),W12:0.00183 (0.11),W24:-0.00015 (0.11),W4:-0.00180 (0.11),W20:-0.00238 (0.11),W8:-0.00518 (0.11),W32:-0.00936 (0.11) | topTokens[('.', 754), ('i', 621), ('it', 488), ('t', 406), ('!', 402), ('e', 314), ('a', 297), ('im', 285), ("'", 282), ('je', 258)] | avgLoss/100: 8.52438735961914 |  | top windows: W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 1000
--- 2025-04-17 09:39:20 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:39:54 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 09:43:18 | 100 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:6.3348 | windowWeightsW2:1.00355 (0.11),W20:1.00217 (0.11),W24:1.00216 (0.11),W28:1.00095 (0.11),W4:0.99971 (0.11),W12:0.99740 (0.11),W32:0.99708 (0.11),W16:0.99692 (0.11),W8:0.99598 (0.11) | judgeBiasW32:0.00203 (0.11),W2:0.00203 (0.11),W20:0.00203 (0.11),W12:0.00203 (0.11),W4:0.00203 (0.11),W16:0.00203 (0.11),W24:0.00203 (0.11),W8:0.00203 (0.11),W28:0.00203 (0.11) | credibilityBiasW16:0.00599 (0.11),W2:0.00286 (0.11),W28:0.00105 (0.11),W4:0.00048 (0.11),W8:0.00015 (0.11),W20:-0.00148 (0.11),W24:-0.00204 (0.11),W32:-0.00373 (0.11),W12:-0.00624 (0.11) | topTokens[(',', 151), ('t', 143), ('a', 137), ('im', 121), ('je', 111), ("'", 111), ('.', 111), ('e', 98), ('our', 83), ('for', 72)] | avgLoss/100: 6.334812641143799 |  | top windows: W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 1000
--- 2025-04-17 09:48:09 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:49:10 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:49:35 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:52:12 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:54:59 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:57:21 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:58:10 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 10:01:31 | 100 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:7.4348 | windowWeightsW2:1.00252 (0.11),W12:1.00081 (0.11),W24:1.00055 (0.11),W4:0.99925 (0.11),W32:0.99814 (0.11),W28:0.99634 (0.11),W20:0.99626 (0.11),W16:0.99520 (0.11),W8:0.99474 (0.11) | judgeBiasW24:0.00308 (0.11),W32:0.00308 (0.11),W2:0.00308 (0.11),W28:0.00308 (0.11),W8:0.00308 (0.11),W16:0.00308 (0.11),W20:0.00308 (0.11),W4:0.00308 (0.11),W12:0.00308 (0.11) | credibilityBiasW12:0.00159 (0.11),W4:-0.00014 (0.11),W2:-0.00031 (0.11),W8:-0.00088 (0.11),W32:-0.00110 (0.11),W24:-0.00115 (0.11),W28:-0.00145 (0.11),W16:-0.00360 (0.11),W20:-0.00411 (0.11) | topTokens[('t', 185), (',', 142), ('e', 128), ('a', 110), ('im', 105), ("'", 92), ('je', 91), ('our', 89), ('.', 82), ('s', 58)] | avgLoss/100: 7.434751987457275 |  | top windows: W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
--- 2025-04-17 10:02:28 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 10:05:56 | 100 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:5.7394 | windowWeightsW8:1.00122 (0.11),W32:1.00116 (0.11),W2:1.00072 (0.11),W12:1.00015 (0.11),W20:0.99982 (0.11),W4:0.99978 (0.11),W28:0.99939 (0.11),W24:0.99832 (0.11),W16:0.99788 (0.11) | judgeBiasW8:0.00270 (0.11),W28:0.00270 (0.11),W16:0.00270 (0.11),W24:0.00270 (0.11),W32:0.00270 (0.11),W2:0.00270 (0.11),W4:0.00270 (0.11),W20:0.00270 (0.11),W12:0.00270 (0.11) | credibilityBiasW24:0.00218 (0.11),W16:0.00210 (0.11),W2:0.00177 (0.11),W28:0.00141 (0.11),W12:0.00057 (0.11),W4:0.00019 (0.11),W20:0.00013 (0.11),W32:-0.00321 (0.11),W8:-0.00460 (0.11) | topTokens[('t', 166), (',', 165), ('.', 113), ('e', 112), ('for', 102), ('our', 94), ("'", 86), ('a', 84), ('je', 80), ('im', 75)] | avgLoss/100: 5.739397048950195 |  | top windows: W12:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 1000
2025-04-17 10:09:35 | 200 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:8.0157 | windowWeightsW20:1.00471 (0.11),W2:1.00070 (0.11),W32:1.00055 (0.11),W12:1.00011 (0.11),W24:0.99964 (0.11),W4:0.99830 (0.11),W8:0.99738 (0.11),W28:0.99705 (0.11),W16:0.99686 (0.11) | judgeBiasW20:-0.00020 (0.11),W28:-0.00020 (0.11),W32:-0.00020 (0.11),W4:-0.00020 (0.11),W12:-0.00020 (0.11),W16:-0.00020 (0.11),W24:-0.00020 (0.11),W2:-0.00020 (0.11),W8:-0.00020 (0.11) | credibilityBiasW28:0.00500 (0.11),W16:0.00296 (0.11),W2:0.00175 (0.11),W4:0.00067 (0.11),W12:0.00059 (0.11),W24:-0.00008 (0.11),W32:-0.00101 (0.11),W8:-0.00105 (0.11),W20:-0.00402 (0.11) | topTokens[('.', 403), ('t', 313), ('e', 206), (',', 198), ('a', 189), ('je', 164), ("'", 149), ('for', 145), ('im', 144), ('love', 140)] | avgLoss/100: 8.0156888961792 |  | top windows: W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 10:13:00 | 300 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:7.4141 | windowWeightsW24:1.00507 (0.11),W20:1.00496 (0.11),W16:1.00438 (0.11),W32:1.00269 (0.11),W2:1.00067 (0.11),W12:1.00008 (0.11),W8:0.99713 (0.11),W4:0.99670 (0.11),W28:0.98810 (0.11) | judgeBiasW28:-0.00178 (0.11),W32:-0.00179 (0.11),W8:-0.00179 (0.11),W4:-0.00179 (0.11),W12:-0.00179 (0.11),W2:-0.00179 (0.11),W20:-0.00180 (0.11),W16:-0.00180 (0.11),W24:-0.00180 (0.11) | credibilityBiasW16:0.00588 (0.11),W2:0.00175 (0.11),W4:0.00112 (0.11),W32:0.00097 (0.11),W12:0.00058 (0.11),W24:0.00020 (0.11),W28:0.00020 (0.11),W8:-0.00087 (0.11),W20:-0.00427 (0.11) | topTokens[('.', 485), ('t', 437), (',', 298), ('a', 287), ('e', 283), ('je', 266), ("'", 258), ('i', 242), ('you', 239), ('!', 230)] | avgLoss/100: 7.414144515991211 |  | top windows: W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 10:16:24 | 400 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:9.7533 | windowWeightsW24:1.00507 (0.11),W20:1.00493 (0.11),W16:1.00451 (0.11),W32:1.00308 (0.11),W2:1.00063 (0.11),W8:1.00018 (0.11),W4:0.99661 (0.11),W12:0.99501 (0.11),W28:0.98776 (0.11) | judgeBiasW28:-0.00184 (0.11),W32:-0.00185 (0.11),W8:-0.00185 (0.11),W4:-0.00185 (0.11),W12:-0.00185 (0.11),W2:-0.00186 (0.11),W20:-0.00186 (0.11),W16:-0.00186 (0.11),W24:-0.00186 (0.11) | credibilityBiasW16:0.00604 (0.11),W12:0.00449 (0.11),W2:0.00175 (0.11),W32:0.00128 (0.11),W4:0.00113 (0.11),W24:0.00021 (0.11),W28:-0.00011 (0.11),W8:-0.00262 (0.11),W20:-0.00427 (0.11) | topTokens[('.', 646), ('t', 539), ('i', 442), ('a', 440), ('je', 397), (',', 380), ('e', 372), ("'", 346), ('you', 330), ('im', 317)] | avgLoss/100: 9.753270149230957 |  | top windows: W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 10:20:02 | 500 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0001 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:12.7543 | windowWeightsW24:1.00505 (0.11),W20:1.00489 (0.11),W16:1.00447 (0.11),W32:1.00305 (0.11),W2:1.00060 (0.11),W8:1.00015 (0.11),W4:0.99641 (0.11),W12:0.99497 (0.11),W28:0.98772 (0.11) | judgeBiasW28:-0.00184 (0.11),W32:-0.00185 (0.11),W8:-0.00185 (0.11),W4:-0.00185 (0.11),W12:-0.00185 (0.11),W2:-0.00185 (0.11),W20:-0.00186 (0.11),W16:-0.00186 (0.11),W24:-0.00186 (0.11) | credibilityBiasW16:0.00604 (0.11),W12:0.00449 (0.11),W2:0.00175 (0.11),W32:0.00128 (0.11),W4:0.00110 (0.11),W24:0.00022 (0.11),W28:-0.00011 (0.11),W8:-0.00262 (0.11),W20:-0.00427 (0.11) | topTokens[('.', 918), ('t', 628), ('je', 503), ('a', 497), ('e', 494), ("'", 491), ('i', 488), (',', 428), ('you', 428), ('im', 414)] | avgLoss/100: 12.754295349121094 |  | top windows: W16:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 1000
2025-04-17 10:23:35 | 600 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0001 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:13.2962 | windowWeightsW32:1.01232 (0.11),W2:1.00715 (0.11),W24:1.00500 (0.11),W16:1.00444 (0.11),W8:1.00011 (0.11),W20:0.99774 (0.11),W4:0.99637 (0.11),W12:0.98823 (0.11),W28:0.98369 (0.11) | judgeBiasW32:-0.00139 (0.11),W28:-0.00139 (0.11),W8:-0.00140 (0.11),W4:-0.00140 (0.11),W2:-0.00140 (0.11),W12:-0.00140 (0.11),W16:-0.00141 (0.11),W24:-0.00141 (0.11),W20:-0.00142 (0.11) | credibilityBiasW12:0.00687 (0.11),W32:0.00617 (0.11),W16:0.00604 (0.11),W4:0.00110 (0.11),W24:0.00023 (0.11),W28:-0.00012 (0.11),W2:-0.00050 (0.11),W8:-0.00262 (0.11),W20:-0.01005 (0.11) | topTokens[('.', 1075), ('t', 757), ('a', 570), ('i', 565), ('e', 558), ('je', 554), ("'", 541), ('you', 510), (',', 486), ('im', 480)] | avgLoss/100: 13.296221733093262 |  | top windows: W32:1.00,W2:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 10:27:10 | 700 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0001 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:11.1961 | windowWeightsW32:1.01280 (0.11),W2:1.00754 (0.11),W24:1.00496 (0.11),W16:1.00440 (0.11),W8:1.00007 (0.11),W20:0.99770 (0.11),W4:0.99705 (0.11),W12:0.98760 (0.11),W28:0.98321 (0.11) | judgeBiasW32:-0.00137 (0.11),W28:-0.00138 (0.11),W8:-0.00138 (0.11),W4:-0.00138 (0.11),W12:-0.00139 (0.11),W2:-0.00139 (0.11),W16:-0.00139 (0.11),W24:-0.00140 (0.11),W20:-0.00140 (0.11) | credibilityBiasW12:0.00709 (0.11),W2:0.00620 (0.11),W32:0.00618 (0.11),W16:0.00604 (0.11),W24:0.00023 (0.11),W28:-0.00012 (0.11),W8:-0.00262 (0.11),W4:-0.00540 (0.11),W20:-0.01005 (0.11) | topTokens[('.', 1381), ('t', 876), ('je', 691), ('a', 663), ('e', 631), ("'", 626), ('i', 620), ('im', 588), ('you', 543), (',', 515)] | avgLoss/100: 11.196087837219238 |  | top windows: W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
--- 2025-04-17 10:27:24 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 10:30:50 | 100 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:7.7236 | windowWeightsW2:1.00407 (0.11),W20:1.00364 (0.11),W24:1.00218 (0.11),W28:1.00113 (0.11),W32:1.00001 (0.11),W16:0.99924 (0.11),W4:0.99647 (0.11),W8:0.99602 (0.11),W12:0.99594 (0.11) | judgeBiasW2:0.00393 (0.11),W20:0.00393 (0.11),W32:0.00393 (0.11),W24:0.00393 (0.11),W16:0.00393 (0.11),W28:0.00393 (0.11),W12:0.00393 (0.11),W8:0.00393 (0.11),W4:0.00393 (0.11) | credibilityBiasW2:0.00434 (0.11),W12:0.00348 (0.11),W24:0.00345 (0.11),W32:0.00165 (0.11),W20:0.00017 (0.11),W8:-0.00125 (0.11),W28:-0.00176 (0.11),W16:-0.00342 (0.11),W4:-0.00506 (0.11) | topTokens[('.', 230), ('and', 168), ('im', 106), ('e', 106), ('t', 106), ('a', 103), ('je', 100), ("'", 90), ('s', 55), ('our', 51)] | avgLoss/100: 7.7235798835754395 |  | top windows: W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 10:34:12 | 200 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:9.6178 | windowWeightsW2:1.00266 (0.11),W28:1.00097 (0.11),W32:1.00035 (0.11),W24:1.00029 (0.11),W4:0.99998 (0.11),W20:0.99895 (0.11),W16:0.99805 (0.11),W8:0.99758 (0.11),W12:0.99576 (0.11) | judgeBiasW8:0.00049 (0.11),W16:0.00049 (0.11),W12:0.00049 (0.11),W28:0.00049 (0.11),W4:0.00049 (0.11),W20:0.00048 (0.11),W2:0.00048 (0.11),W32:0.00048 (0.11),W24:0.00048 (0.11) | credibilityBiasW24:0.00560 (0.11),W32:0.00432 (0.11),W8:0.00373 (0.11),W12:0.00163 (0.11),W2:0.00148 (0.11),W28:-0.00274 (0.11),W20:-0.00465 (0.11),W4:-0.00495 (0.11),W16:-0.00644 (0.11) | topTokens[('.', 495), ('t', 229), ('and', 224), ('im', 217), ('je', 217), ('a', 209), ("'", 201), ('e', 186), ('our', 94), ('s', 79)] | avgLoss/100: 9.617778778076172 |  | top windows: W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 1000
2025-04-17 10:37:42 | 300 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0000 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:8.9897 | windowWeightsW8:1.00527 (0.11),W28:1.00285 (0.11),W2:1.00262 (0.11),W32:1.00044 (0.11),W4:1.00020 (0.11),W24:1.00012 (0.11),W12:0.99571 (0.11),W20:0.99356 (0.11),W16:0.99094 (0.11) | judgeBiasW8:0.00001 (0.11),W16:0.00001 (0.11),W12:0.00001 (0.11),W20:0.00000 (0.11),W28:0.00000 (0.11),W4:0.00000 (0.11),W2:-0.00000 (0.11),W32:-0.00000 (0.11),W24:-0.00001 (0.11) | credibilityBiasW8:0.00626 (0.11),W24:0.00584 (0.11),W32:0.00434 (0.11),W12:0.00156 (0.11),W2:0.00147 (0.11),W28:0.00111 (0.11),W4:-0.00481 (0.11),W16:-0.00962 (0.11),W20:-0.00975 (0.11) | topTokens[('.', 690), ('t', 310), ('im', 302), ('a', 300), ('e', 292), ('je', 283), ("'", 278), ('and', 262), ('!', 144), ('you', 138)] | avgLoss/100: 8.98965072631836 |  | top windows: W2:1.00,W4:0.00,W32:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 10:41:13 | 400 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0001 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:9.9756 | windowWeightsW4:1.00605 (0.11),W8:1.00529 (0.11),W28:1.00281 (0.11),W32:1.00041 (0.11),W24:1.00008 (0.11),W20:0.99717 (0.11),W2:0.99658 (0.11),W12:0.99347 (0.11),W16:0.99083 (0.11) | judgeBiasW8:0.00027 (0.11),W12:0.00026 (0.11),W16:0.00026 (0.11),W28:0.00026 (0.11),W4:0.00026 (0.11),W20:0.00025 (0.11),W2:0.00025 (0.11),W32:0.00025 (0.11),W24:0.00025 (0.11) | credibilityBiasW8:0.00627 (0.11),W24:0.00584 (0.11),W32:0.00434 (0.11),W28:0.00112 (0.11),W2:0.00080 (0.11),W4:-0.00407 (0.11),W12:-0.00415 (0.11),W20:-0.00587 (0.11),W16:-0.00964 (0.11) | topTokens[('.', 809), ('a', 326), ('im', 319), ('t', 316), ('e', 308), ('and', 292), ('je', 291), ("'", 286), ('!', 197), ('our', 192)] | avgLoss/100: 9.975600242614746 |  | top windows: W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 10:44:38 | 500 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0001 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:8.6498 | windowWeightsW4:1.00880 (0.11),W8:1.00525 (0.11),W28:1.00278 (0.11),W32:1.00038 (0.11),W24:1.00005 (0.11),W20:0.99714 (0.11),W2:0.99365 (0.11),W12:0.99344 (0.11),W16:0.99079 (0.11) | judgeBiasW8:0.00034 (0.11),W12:0.00034 (0.11),W16:0.00034 (0.11),W28:0.00034 (0.11),W4:0.00033 (0.11),W20:0.00033 (0.11),W2:0.00033 (0.11),W32:0.00033 (0.11),W24:0.00033 (0.11) | credibilityBiasW8:0.00627 (0.11),W24:0.00584 (0.11),W32:0.00434 (0.11),W28:0.00112 (0.11),W4:-0.00062 (0.11),W2:-0.00231 (0.11),W12:-0.00415 (0.11),W20:-0.00587 (0.11),W16:-0.00964 (0.11) | topTokens[('.', 941), ('e', 377), ('a', 354), ('im', 349), ('je', 349), ('t', 346), (',', 340), ("'", 322), ('and', 300), ('our', 214)] | avgLoss/100: 8.6498384475708 |  | top windows: W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 1000
2025-04-17 10:48:02 | 600 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0000 | n_biasesStd:0.0000 | n_biasesMin:-0.0001 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:13.7741 | windowWeightsW4:1.00911 (0.11),W8:1.00900 (0.11),W28:1.00274 (0.11),W32:1.00034 (0.11),W24:1.00001 (0.11),W20:0.99710 (0.11),W2:0.99325 (0.11),W16:0.99075 (0.11),W12:0.99022 (0.11) | judgeBiasW8:-0.00002 (0.11),W16:-0.00002 (0.11),W12:-0.00002 (0.11),W28:-0.00002 (0.11),W20:-0.00002 (0.11),W2:-0.00002 (0.11),W4:-0.00003 (0.11),W32:-0.00003 (0.11),W24:-0.00003 (0.11) | credibilityBiasW8:0.00588 (0.11),W24:0.00584 (0.11),W32:0.00434 (0.11),W28:0.00112 (0.11),W4:-0.00038 (0.11),W2:-0.00253 (0.11),W12:-0.00345 (0.11),W20:-0.00587 (0.11),W16:-0.00964 (0.11) | topTokens[('.', 1120), (',', 536), ('e', 416), ('je', 398), ('a', 395), ('t', 395), ("'", 388), ('im', 371), ('!', 312), ('and', 300)] | avgLoss/100: 13.774052619934082 |  | top windows: W8:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 1000
2025-04-17 10:51:24 | 700 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0001 | n_biasesStd:0.0000 | n_biasesMin:-0.0001 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0007 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:13.1068 | windowWeightsW8:1.01409 (0.11),W24:1.00738 (0.11),W4:1.00356 (0.11),W32:1.00031 (0.11),W20:0.99707 (0.11),W28:0.99640 (0.11),W2:0.99610 (0.11),W16:0.99072 (0.11),W12:0.98954 (0.11) | judgeBiasW8:0.00089 (0.11),W4:0.00087 (0.11),W16:0.00087 (0.11),W12:0.00087 (0.11),W24:0.00087 (0.11),W28:0.00087 (0.11),W32:0.00086 (0.11),W20:0.00086 (0.11),W2:0.00086 (0.11) | credibilityBiasW24:0.00749 (0.11),W4:0.00497 (0.11),W32:0.00434 (0.11),W8:0.00191 (0.11),W28:-0.00066 (0.11),W2:-0.00239 (0.11),W12:-0.00331 (0.11),W20:-0.00587 (0.11),W16:-0.00964 (0.11) | topTokens[('.', 1364), (',', 573), ('t', 532), ('je', 486), ("'", 477), ('e', 471), ('a', 448), ('im', 435), ('!', 391), ('and', 300)] | avgLoss/100: 13.106780052185059 |  | top windows: W28:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 1000
2025-04-17 10:54:46 | 800 | LR0.00035 | n_weightMean:0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0001 | n_biasesStd:0.0000 | n_biasesMin:-0.0001 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:21.7417 | windowWeightsW8:1.01449 (0.11),W24:1.00742 (0.11),W32:1.00027 (0.11),W2:1.00027 (0.11),W4:0.99928 (0.11),W20:0.99703 (0.11),W28:0.99630 (0.11),W16:0.99068 (0.11),W12:0.98950 (0.11) | judgeBiasW8:0.00145 (0.11),W4:0.00143 (0.11),W24:0.00143 (0.11),W32:0.00142 (0.11),W12:0.00142 (0.11),W28:0.00142 (0.11),W16:0.00142 (0.11),W20:0.00142 (0.11),W2:0.00141 (0.11) | credibilityBiasW24:0.00751 (0.11),W4:0.00536 (0.11),W32:0.00434 (0.11),W8:0.00152 (0.11),W28:-0.00068 (0.11),W2:-0.00218 (0.11),W12:-0.00331 (0.11),W20:-0.00587 (0.11),W16:-0.00964 (0.11) | topTokens[('.', 1489), (',', 672), ('t', 598), ('a', 594), ("'", 557), ('e', 546), ('je', 543), ('im', 535), ('!', 392), ('you', 323)] | avgLoss/100: 21.741722106933594 |  | top windows: W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 10:58:11 | 900 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0001 | n_biasesStd:0.0000 | n_biasesMin:-0.0001 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:10.8160 | windowWeightsW8:1.01445 (0.11),W24:1.00739 (0.11),W32:1.00024 (0.11),W2:1.00023 (0.11),W4:0.99925 (0.11),W20:0.99700 (0.11),W28:0.99627 (0.11),W16:0.99065 (0.11),W12:0.98946 (0.11) | judgeBiasW8:0.00145 (0.11),W4:0.00143 (0.11),W24:0.00143 (0.11),W32:0.00142 (0.11),W12:0.00142 (0.11),W28:0.00142 (0.11),W16:0.00142 (0.11),W20:0.00142 (0.11),W2:0.00141 (0.11) | credibilityBiasW24:0.00751 (0.11),W4:0.00536 (0.11),W32:0.00434 (0.11),W8:0.00152 (0.11),W28:-0.00068 (0.11),W2:-0.00218 (0.11),W12:-0.00331 (0.11),W20:-0.00587 (0.11),W16:-0.00964 (0.11) | topTokens[('.', 1626), (',', 942), ('t', 607), ('a', 594), ("'", 565), ('e', 563), ('je', 562), ('im', 535), ('!', 393), ('the', 350)] | avgLoss/100: 10.815962791442871 |  | top windows: W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 11:01:37 | 1000 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0001 | n_biasesStd:0.0000 | n_biasesMin:-0.0001 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:8.4437 | windowWeightsW8:1.01442 (0.11),W24:1.00735 (0.11),W32:1.00311 (0.11),W2:1.00019 (0.11),W4:0.99921 (0.11),W20:0.99696 (0.11),W28:0.99342 (0.11),W16:0.99061 (0.11),W12:0.98943 (0.11) | judgeBiasW8:0.00159 (0.11),W4:0.00156 (0.11),W24:0.00156 (0.11),W32:0.00155 (0.11),W28:0.00155 (0.11),W12:0.00155 (0.11),W20:0.00155 (0.11),W16:0.00155 (0.11),W2:0.00154 (0.11) | credibilityBiasW24:0.00751 (0.11),W4:0.00536 (0.11),W32:0.00435 (0.11),W8:0.00152 (0.11),W28:-0.00069 (0.11),W2:-0.00218 (0.11),W12:-0.00331 (0.11),W20:-0.00587 (0.11),W16:-0.00964 (0.11) | topTokens[('.', 1775), (',', 1137), ('t', 611), ('a', 594), ("'", 565), ('e', 563), ('je', 562), ('im', 535), ('!', 395), ('the', 389)] | avgLoss/100: 8.443739891052246 |  | top windows: W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 11:04:58 | 1100 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0001 | n_biasesStd:0.0000 | n_biasesMin:-0.0001 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:10.0236 | windowWeightsW8:1.01438 (0.11),W32:1.00728 (0.11),W24:1.00184 (0.11),W2:0.99994 (0.11),W4:0.99917 (0.11),W12:0.99718 (0.11),W20:0.99692 (0.11),W16:0.99212 (0.11),W28:0.98865 (0.11) | judgeBiasW28:0.00003 (0.11),W4:0.00002 (0.11),W8:0.00002 (0.11),W16:0.00002 (0.11),W24:0.00002 (0.11),W20:0.00001 (0.11),W12:0.00000 (0.11),W2:0.00000 (0.11),W32:-0.00001 (0.11) | credibilityBiasW32:0.01170 (0.11),W24:0.00901 (0.11),W4:0.00536 (0.11),W2:0.00481 (0.11),W8:0.00152 (0.11),W28:-0.00478 (0.11),W20:-0.00587 (0.11),W12:-0.00993 (0.11),W16:-0.01540 (0.11) | topTokens[('.', 1873), (',', 1264), ('t', 613), ('a', 599), ("'", 566), ('e', 565), ('je', 563), ('im', 535), ('!', 422), ('the', 398)] | avgLoss/100: 10.0236177444458 |  | top windows: W32:1.00,W2:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 11:08:20 | 1200 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0001 | n_biasesStd:0.0000 | n_biasesMin:-0.0001 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:8.9838 | windowWeightsW8:1.01415 (0.11),W32:1.00718 (0.11),W24:1.00186 (0.11),W2:0.99989 (0.11),W4:0.99920 (0.11),W12:0.99714 (0.11),W20:0.99689 (0.11),W16:0.99212 (0.11),W28:0.98864 (0.11) | judgeBiasW28:-0.00186 (0.11),W16:-0.00188 (0.11),W20:-0.00189 (0.11),W4:-0.00189 (0.11),W24:-0.00190 (0.11),W2:-0.00190 (0.11),W12:-0.00191 (0.11),W8:-0.00192 (0.11),W32:-0.00193 (0.11) | credibilityBiasW32:0.01203 (0.11),W24:0.00884 (0.11),W2:0.00498 (0.11),W8:0.00379 (0.11),W4:0.00236 (0.11),W28:-0.00496 (0.11),W20:-0.00587 (0.11),W12:-0.00993 (0.11),W16:-0.01554 (0.11) | topTokens[('.', 1977), (',', 1378), ('t', 630), ('a', 599), ('e', 567), ("'", 566), ('je', 563), ('im', 536), ('the', 431), ('!', 423)] | avgLoss/100: 8.983778953552246 |  | top windows: W16:1.00,W28:0.00,W32:0.00,W2:0.00 | TUTOR.py 1000
2025-04-17 11:11:42 | 1300 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0001 | n_biasesStd:0.0000 | n_biasesMin:-0.0002 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:12.9340 | windowWeightsW8:1.01411 (0.11),W32:1.00715 (0.11),W24:1.00183 (0.11),W2:0.99981 (0.11),W4:0.99922 (0.11),W12:0.99711 (0.11),W20:0.99685 (0.11),W16:0.99208 (0.11),W28:0.98860 (0.11) | judgeBiasW28:-0.00186 (0.11),W16:-0.00188 (0.11),W20:-0.00189 (0.11),W4:-0.00189 (0.11),W24:-0.00190 (0.11),W2:-0.00190 (0.11),W12:-0.00191 (0.11),W8:-0.00192 (0.11),W32:-0.00193 (0.11) | credibilityBiasW32:0.01203 (0.11),W24:0.00884 (0.11),W2:0.00539 (0.11),W8:0.00379 (0.11),W4:0.00190 (0.11),W28:-0.00496 (0.11),W20:-0.00587 (0.11),W12:-0.00993 (0.11),W16:-0.01554 (0.11) | topTokens[('.', 1984), (',', 1761), ('t', 655), ('e', 609), ('a', 599), ("'", 569), ('je', 564), ('im', 537), ('the', 492), ('!', 423)] | avgLoss/100: 12.934016227722168 |  | top windows: W2:1.00,W32:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 11:15:03 | 1400 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0001 | n_biasesStd:0.0000 | n_biasesMin:-0.0002 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:9.0896 | windowWeightsW8:1.01281 (0.11),W32:1.00673 (0.11),W24:1.00179 (0.11),W2:1.00025 (0.11),W4:0.99958 (0.11),W12:0.99707 (0.11),W20:0.99682 (0.11),W16:0.99205 (0.11),W28:0.98857 (0.11) | judgeBiasW28:-0.00309 (0.11),W16:-0.00312 (0.11),W20:-0.00313 (0.11),W4:-0.00314 (0.11),W24:-0.00315 (0.11),W2:-0.00315 (0.11),W12:-0.00315 (0.11),W32:-0.00319 (0.11),W8:-0.00319 (0.11) | credibilityBiasW32:0.01151 (0.11),W24:0.00884 (0.11),W8:0.00652 (0.11),W2:0.00598 (0.11),W4:-0.00159 (0.11),W28:-0.00496 (0.11),W20:-0.00587 (0.11),W12:-0.00993 (0.11),W16:-0.01554 (0.11) | topTokens[('.', 2024), (',', 1980), ('t', 655), ('e', 650), ('a', 599), ('the', 595), ("'", 569), ('je', 564), ('im', 537), ('!', 423)] | avgLoss/100: 9.089622497558594 |  | top windows: W28:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 1000
2025-04-17 11:18:29 | 1500 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0001 | n_biasesStd:0.0000 | n_biasesMin:-0.0002 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:9.4670 | windowWeightsW8:1.01582 (0.11),W32:1.00669 (0.11),W2:0.99941 (0.11),W4:0.99923 (0.11),W12:0.99704 (0.11),W20:0.99678 (0.11),W24:0.99628 (0.11),W16:0.99201 (0.11),W28:0.99185 (0.11) | judgeBiasW28:-0.00343 (0.11),W16:-0.00346 (0.11),W20:-0.00348 (0.11),W4:-0.00349 (0.11),W2:-0.00349 (0.11),W24:-0.00350 (0.11),W12:-0.00350 (0.11),W32:-0.00354 (0.11),W8:-0.00354 (0.11) | credibilityBiasW24:0.01374 (0.11),W32:0.01151 (0.11),W2:0.00674 (0.11),W4:0.00427 (0.11),W8:0.00101 (0.11),W20:-0.00587 (0.11),W12:-0.00993 (0.11),W28:-0.01075 (0.11),W16:-0.01554 (0.11) | topTokens[(',', 2126), ('.', 2064), ('t', 705), ('e', 661), ('a', 620), ('the', 614), ('!', 585), ("'", 572), ('je', 564), ('im', 540)] | avgLoss/100: 9.466957092285156 |  | top windows: W32:1.00,W2:0.00,W4:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 11:21:50 | 1600 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0001 | n_biasesStd:0.0000 | n_biasesMin:-0.0002 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:18.6561 | windowWeightsW8:1.01579 (0.11),W32:1.00665 (0.11),W2:1.00068 (0.11),W4:0.99790 (0.11),W12:0.99700 (0.11),W20:0.99675 (0.11),W24:0.99624 (0.11),W16:0.99198 (0.11),W28:0.99181 (0.11) | judgeBiasW28:-0.00358 (0.11),W16:-0.00361 (0.11),W20:-0.00362 (0.11),W4:-0.00363 (0.11),W2:-0.00364 (0.11),W24:-0.00364 (0.11),W12:-0.00365 (0.11),W32:-0.00369 (0.11),W8:-0.00369 (0.11) | credibilityBiasW24:0.01374 (0.11),W32:0.01151 (0.11),W2:0.00645 (0.11),W4:0.00449 (0.11),W8:0.00101 (0.11),W20:-0.00587 (0.11),W12:-0.00993 (0.11),W28:-0.01075 (0.11),W16:-0.01554 (0.11) | topTokens[(',', 2245), ('.', 2213), ('t', 777), ('e', 686), ('a', 667), ("'", 623), ('je', 620), ('the', 614), ('im', 610), ('!', 585)] | avgLoss/100: 18.656103134155273 |  | top windows: W4:1.00,W32:0.00,W2:0.00,W8:0.00 | TUTOR.py 1000
2025-04-17 11:25:12 | 1700 | LR0.00035 | n_weightMean:-0.0000 | n_weightStd:0.0000 | n_weightMin:-0.0001 | n_weightMax:0.0001 | n_biasesMean:-0.0001 | n_biasesStd:0.0000 | n_biasesMin:-0.0002 | n_biasesMax:-0.0000 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:0.0010 | INN_cerebellumStd:0.0000 | INN_credibilityBias:<tensor[torch.Size([9])]> | INN_credibilityBiasSoft:<tensor[torch.Size([9])]> | INN_credibilityBiasMean:-0.0000 | INN_credibilityBiasStd:0.0000 | INN_judgeBias:<tensor[torch.Size([9])]> | INN_judgeBiasSoft:<tensor[torch.Size([9])]> | INN_judgeBiasMean:-0.0000 | INN_judgeBiasStd:0.0000 | shortDecay:0.0007 | longDecay:0.0008 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:11.3205 | windowWeightsW8:1.01575 (0.11),W32:1.00461 (0.11),W28:1.00036 (0.11),W2:0.99871 (0.11),W4:0.99787 (0.11),W12:0.99697 (0.11),W20:0.99671 (0.11),W16:0.99194 (0.11),W24:0.98890 (0.11) | judgeBiasW28:-0.00589 (0.11),W16:-0.00591 (0.11),W20:-0.00593 (0.11),W24:-0.00595 (0.11),W4:-0.00596 (0.11),W2:-0.00596 (0.11),W12:-0.00597 (0.11),W32:-0.00603 (0.11),W8:-0.00605 (0.11) | credibilityBiasW24:0.01669 (0.11),W2:0.00890 (0.11),W32:0.00667 (0.11),W4:0.00449 (0.11),W8:0.00101 (0.11),W20:-0.00587 (0.11),W12:-0.00993 (0.11),W28:-0.01153 (0.11),W16:-0.01554 (0.11) | topTokens[(',', 2412), ('.', 2213), ('t', 777), ('e', 698), ('the', 687), ('a', 669), ('!', 653), ("'", 643), ('je', 624), ('im', 614)] | avgLoss/100: 11.320483207702637 |  | top windows: W28:1.00,W32:0.00,W2:0.00,W4:0.00 | TUTOR.py 1000
--- 2025-04-17 21:09:09 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:09:50 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:12:56 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:14:29 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]2025-04-17 21:14:53 | 100 | LR0.00035 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:4.7450 | topTokens[('.', 186), ('je', 115), ('t', 114), ("'", 97), ('a', 95), ('e', 95), ('im', 94), ('i', 66), ('and', 55), ('you', 55)] | avgLoss/100: 4.745010852813721 |  |  | TUTOR.py 1000
2025-04-17 21:15:20 | 200 | LR0.00035 | logitMin:0.0000 | logitMax:0.0000 | scheduledSampling:0.0000 | loss:0.0000 | gradNorm:0.0000 | tokenCount:0.0000 | avgLoss:4.7068 | topTokens[('.', 356), ('t', 228), ('je', 226), ('a', 226), ("'", 225), ('e', 220), ('im', 206), ('and', 115), (',', 110), ('you', 108)] | avgLoss/100: 4.706754207611084 |  |  | TUTOR.py 1000
--- 2025-04-17 21:15:32 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]