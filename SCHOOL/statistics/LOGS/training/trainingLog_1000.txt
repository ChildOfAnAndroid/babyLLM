2025-03-09 23:15:39 | Total Steps: 1000 | Context Window: 8 | Step 1000 | Moving Avg Loss: 5.1204
2025-03-09 23:44:10 | Total Steps: 2000 | Context Window: 8 | Step 2000 | Moving Avg Loss: 5.3677
2025-03-10 00:12:36 | Total Steps: 3000 | Context Window: 8 | Step 3000 | Moving Avg Loss: 5.4466

-- training data
2025-03-10 00:48:13 | Context Window: 7 | Step 1000 | Moving Avg Loss: 5.0273
2025-03-10 01:13:29 | Context Window: 7 | Step 2000 | Moving Avg Loss: 5.1703

-- training data
2025-03-10 01:54:12 | Context Window: 7 | Step 1000 | Moving Avg Loss: 6.1151
2025-03-10 02:19:19 | Context Window: 7 | Step 2000 | Moving Avg Loss: 6.3453
2025-03-10 02:44:43 | Context Window: 7 | Step 3000 | Moving Avg Loss: 6.1668
2025-03-10 03:10:00 | Context Window: 7 | Step 4000 | Moving Avg Loss: 6.3506

-- training data
2025-03-10 03:54:20 | Context Window: 7 | Step 1000 | Moving Avg Loss: 9.9144
2025-03-10 04:19:44 | Context Window: 7 | Step 2000 | Moving Avg Loss: 9.6927

-- training data
2025-03-10 04:45:08 | Context Window: 7 | Step 1000 | Moving Avg Loss: 7.7759
2025-03-10 05:10:06 | Context Window: 7 | Step 2000 | Moving Avg Loss: 7.6799
2025-03-10 05:35:05 | Context Window: 7 | Step 3000 | Moving Avg Loss: 8.3964
2025-03-10 05:59:52 | Context Window: 7 | Step 4000 | Moving Avg Loss: 8.4129
2025-03-10 06:24:48 | Context Window: 7 | Step 5000 | Moving Avg Loss: 8.2474
2025-03-10 06:49:48 | Context Window: 7 | Step 6000 | Moving Avg Loss: 8.0212
2025-03-10 07:14:45 | Context Window: 7 | Step 7000 | Moving Avg Loss: 7.8536
2025-03-10 07:39:42 | Context Window: 7 | Step 8000 | Moving Avg Loss: 7.8536
2025-03-10 08:04:38 | Context Window: 7 | Step 9000 | Moving Avg Loss: 7.4469
2025-03-10 08:29:35 | Context Window: 7 | Step 10000 | Moving Avg Loss: 7.2260
2025-03-10 08:54:29 | Context Window: 7 | Step 11000 | Moving Avg Loss: 7.2178
2025-03-10 09:19:23 | Context Window: 7 | Step 12000 | Moving Avg Loss: 7.0761
2025-03-10 09:44:22 | Context Window: 7 | Step 13000 | Moving Avg Loss: 6.9324
2025-03-10 10:09:15 | Context Window: 7 | Step 14000 | Moving Avg Loss: 6.8004
2025-03-10 10:34:10 | Context Window: 7 | Step 15000 | Moving Avg Loss: 6.7466
2025-03-10 10:59:06 | Context Window: 7 | Step 16000 | Moving Avg Loss: 6.6475
2025-03-10 11:24:05 | Context Window: 7 | Step 17000 | Moving Avg Loss: 6.5555
2025-03-10 11:49:10 | Context Window: 7 | Step 18000 | Moving Avg Loss: 6.5659
2025-03-10 12:14:30 | Context Window: 7 | Step 19000 | Moving Avg Loss: 6.6222
2025-03-10 12:40:25 | Context Window: 7 | Step 20000 | Moving Avg Loss: 6.5234

-- training data
2025-03-10 13:09:12 | Context: 7 | LR: 0.0001 | Step 1000 | Avg Loss: 5.2566
2025-03-10 13:34:08 | Context: 7 | LR: 0.0001 | Step 2000 | Avg Loss: 4.9620
2025-03-10 13:59:02 | Context: 7 | LR: 0.0001 | Step 3000 | Avg Loss: 6.3814
2025-03-10 14:24:24 | Context: 7 | LR: 0.0001 | Step 4000 | Avg Loss: 5.5968
2025-03-10 14:49:27 | Context: 7 | LR: 0.0001 | Step 5000 | Avg Loss: 5.4644
2025-03-10 15:14:29 | Context: 7 | LR: 0.0001 | Step 6000 | Avg Loss: 5.1037
2025-03-10 15:45:26 | Context: 7 | LR: 0.0001 | Step 7000 | Avg Loss: 5.0796
2025-03-10 16:10:16 | Context: 7 | LR: 0.0001 | Step 8000 | Avg Loss: 4.5624
2025-03-10 16:35:30 | Context: 7 | LR: 0.0001 | Step 9000 | Avg Loss: 4.2773

-- moving onto discord chaos
2025-03-10 17:08:09 | Context: 7 | LR: 1e-05 | Step 1000 | Avg Loss: 12.8259

-- discord chaos again
2025-03-10 17:51:14 | Context: 7 | LR: 1e-05 | Step 1000 | Avg Loss: 13.4140
2025-03-10 18:16:32 | Context: 7 | LR: 1e-05 | Step 2000 | Avg Loss: 12.0745
2025-03-10 18:42:41 | Context: 7 | LR: 1e-05 | Step 3000 | Avg Loss: 11.3965
2025-03-10 19:09:38 | Context: 7 | LR: 1e-05 | Step 4000 | Avg Loss: 12.5422

-- discord chaos again!?
2025-03-10 19:44:19 | Context: 7 | LR: 0.0002 | Step 1000 | Avg Loss: 10.5021
2025-03-10 20:10:02 | Context: 7 | LR: 0.0002 | Step 2000 | Avg Loss: 9.7964
2025-03-10 20:35:40 | Context: 7 | LR: 0.0002 | Step 3000 | Avg Loss: 8.9085
2025-03-10 21:00:30 | Context: 7 | LR: 0.0002 | Step 4000 | Avg Loss: 8.8527
2025-03-10 21:25:00 | Context: 7 | LR: 0.0002 | Step 5000 | Avg Loss: 9.0459
2025-03-10 21:49:29 | Context: 7 | LR: 0.0002 | Step 6000 | Avg Loss: 9.4331
2025-03-10 22:14:04 | Context: 7 | LR: 0.0002 | Step 7000 | Avg Loss: 9.1874
2025-03-10 22:38:43 | Context: 7 | LR: 0.0002 | Step 8000 | Avg Loss: 6.9172
2025-03-10 23:03:24 | Context: 7 | LR: 0.0002 | Step 9000 | Avg Loss: 8.3440
2025-03-10 23:28:04 | Context: 7 | LR: 0.0002 | Step 10000 | Avg Loss: 7.6954
2025-03-10 23:52:45 | Context: 7 | LR: 0.0002 | Step 11000 | Avg Loss: 8.4106
2025-03-11 00:17:22 | Context: 7 | LR: 0.0002 | Step 12000 | Avg Loss: 8.4033
2025-03-11 00:42:02 | Context: 7 | LR: 0.0002 | Step 13000 | Avg Loss: 7.8956
2025-03-11 01:06:41 | Context: 7 | LR: 0.0002 | Step 14000 | Avg Loss: 7.3696
2025-03-11 01:31:16 | Context: 7 | LR: 0.0002 | Step 15000 | Avg Loss: 7.2744
2025-03-11 01:55:51 | Context: 7 | LR: 0.0002 | Step 16000 | Avg Loss: 7.9290
2025-03-11 02:20:30 | Context: 7 | LR: 0.0002 | Step 17000 | Avg Loss: 7.7616
2025-03-11 02:45:09 | Context: 7 | LR: 0.0002 | Step 18000 | Avg Loss: 7.3501
2025-03-11 03:09:48 | Context: 7 | LR: 0.0002 | Step 19000 | Avg Loss: 7.1190
2025-03-11 03:34:21 | Context: 7 | LR: 0.0002 | Step 20000 | Avg Loss: 7.4165
2025-03-11 03:58:55 | Context: 7 | LR: 0.0002 | Step 21000 | Avg Loss: 7.1199
2025-03-11 04:23:28 | Context: 7 | LR: 0.0002 | Step 22000 | Avg Loss: 8.3027
2025-03-11 04:48:05 | Context: 7 | LR: 0.0002 | Step 23000 | Avg Loss: 7.0183
2025-03-11 05:12:43 | Context: 7 | LR: 0.0002 | Step 24000 | Avg Loss: 7.0735
2025-03-11 05:37:28 | Context: 7 | LR: 0.0002 | Step 25000 | Avg Loss: 6.9939
2025-03-11 06:02:13 | Context: 7 | LR: 0.0002 | Step 26000 | Avg Loss: 6.8628
2025-03-11 06:26:53 | Context: 7 | LR: 0.0002 | Step 27000 | Avg Loss: 6.8250
2025-03-11 06:51:38 | Context: 7 | LR: 0.0002 | Step 28000 | Avg Loss: 6.5313
2025-03-11 07:16:21 | Context: 7 | LR: 0.0002 | Step 29000 | Avg Loss: 6.6190
2025-03-11 07:41:36 | Context: 7 | LR: 0.0002 | Step 30000 | Avg Loss: 7.4745
2025-03-11 08:07:40 | Context: 7 | LR: 0.0002 | Step 31000 | Avg Loss: 6.7027
2025-03-11 08:33:44 | Context: 7 | LR: 0.0002 | Step 32000 | Avg Loss: 6.8281
2025-03-11 08:59:16 | Context: 7 | LR: 0.0002 | Step 33000 | Avg Loss: 7.1454
2025-03-11 09:24:32 | Context: 7 | LR: 0.0002 | Step 34000 | Avg Loss: 7.2358
2025-03-11 09:49:55 | Context: 7 | LR: 0.0002 | Step 35000 | Avg Loss: 7.1990
2025-03-11 10:15:03 | Context: 7 | LR: 0.0002 | Step 36000 | Avg Loss: 6.9687
2025-03-11 10:39:52 | Context: 7 | LR: 0.0002 | Step 37000 | Avg Loss: 7.4187
2025-03-11 11:04:44 | Context: 7 | LR: 0.0002 | Step 38000 | Avg Loss: 7.7435
2025-03-11 11:29:32 | Context: 7 | LR: 0.0002 | Step 39000 | Avg Loss: 7.1433
2025-03-11 11:54:22 | Context: 7 | LR: 0.0002 | Step 40000 | Avg Loss: 6.7721
2025-03-11 12:19:08 | Context: 7 | LR: 0.0002 | Step 41000 | Avg Loss: 6.5290
2025-03-11 12:44:01 | Context: 7 | LR: 0.0002 | Step 42000 | Avg Loss: 6.5377
2025-03-11 13:08:58 | Context: 7 | LR: 0.0002 | Step 43000 | Avg Loss: 6.4021
2025-03-11 13:33:49 | Context: 7 | LR: 0.0002 | Step 44000 | Avg Loss: 7.2214
2025-03-11 13:58:43 | Context: 7 | LR: 0.0002 | Step 45000 | Avg Loss: 6.9844
2025-03-11 14:23:43 | Context: 7 | LR: 0.0002 | Step 46000 | Avg Loss: 6.6038

-- training data
2025-03-11 14:53:45 | Context: 7 | LR: 0.0002 | Step 1000 | Avg Loss: 5.0980
2025-03-11 15:18:51 | Context: 7 | LR: 0.0002 | Step 2000 | Avg Loss: 3.8809
2025-03-11 15:44:00 | Context: 7 | LR: 0.0002 | Step 3000 | Avg Loss: 3.8219
2025-03-11 16:09:12 | Context: 7 | LR: 0.0002 | Step 4000 | Avg Loss: 3.9452
-- random poems
2025-03-11 16:48:02 | Context: 7 | LR: 0.0002 | Step 1000 | Avg Loss: 7.6917
2025-03-11 17:13:36 | Context: 7 | LR: 0.0002 | Step 2000 | Avg Loss: 6.9463
2025-03-11 17:43:29 | Context: 7 | LR: 0.0002 | Step 1000 | Avg Loss: 4.7581
2025-03-11 18:08:59 | Context: 7 | LR: 0.0002 | Step 2000 | Avg Loss: 4.4058

-- random poems
2025-03-11 18:37:10 | Context: 7 | LR: 0.0002 | Step 1000 | Avg Loss: 5.6926
2025-03-11 19:02:37 | Context: 7 | LR: 0.0002 | Step 2000 | Avg Loss: 3.5649
2025-03-11 19:45:09 | Context: 7 | LR: 0.0002 | Step 1000 | Avg Loss: 4.0670
2025-03-11 20:11:37 | Context: 7 | LR: 0.0002 | Step 2000 | Avg Loss: 2.5145

-- line sorted training data
2025-03-14 19:49:57 | Context: 7 | LR: 5e-05 | Step 1000 | Avg Loss: 5.6510
2025-03-14 20:19:08 | Context: 7 | LR: 5e-05 | Step 2000 | Avg Loss: 5.0811
2025-03-14 20:48:21 | Context: 7 | LR: 5e-05 | Step 3000 | Avg Loss: 5.2734
2025-03-14 21:17:46 | Context: 7 | LR: 5e-05 | Step 4000 | Avg Loss: 4.1162
2025-03-14 21:47:06 | Context: 7 | LR: 5e-05 | Step 5000 | Avg Loss: 3.9836
--- 2025-03-14 22:34:55 | Context: 7 | LR: 0.00001 | Step 1000 | Avg Loss: 13.6095

--- 2025-03-15 02:47:10 ---
2025-03-15 03:44:00 | Context: 2, 4, 7, 10, 12 | LR: 0.00005 | Step 1000 | Avg Loss: 27.6385
2025-03-15 04:41:51 | Context: 2, 4, 7, 10, 12 | LR: 0.00005 | Step 2000 | Avg Loss: 29.1752

--- 2025-03-15 08:28:41 ---
2025-03-15 09:30:33 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 1000 | Avg Loss: 175.2150
2025-03-15 10:31:31 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 2000 | Avg Loss: 166.2583
2025-03-15 11:32:26 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 3000 | Avg Loss: 126.2650
2025-03-15 12:33:21 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 4000 | Avg Loss: 112.0541
2025-03-15 13:34:20 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 5000 | Avg Loss: 101.1901
2025-03-15 14:35:17 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 6000 | Avg Loss: 96.8690
2025-03-15 15:36:24 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 7000 | Avg Loss: 79.7548

--- 2025-03-15 15:50:45 ---
2025-03-15 16:51:21 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 1000 | Avg Loss: 105.4596

--- 2025-03-15 17:26:13 ---
2025-03-15 18:26:50 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 1000 | Avg Loss: 75.4626
2025-03-15 19:28:18 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 2000 | Avg Loss: 72.1213

--- 2025-03-15 20:07:41 ---
2025-03-15 21:08:10 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 1000 | Avg Loss: 117.7844
2025-03-15 22:08:32 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 2000 | Avg Loss: 116.9606
2025-03-15 23:09:13 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 3000 | Avg Loss: 103.9343

--- 2025-03-15 23:35:03 ---
2025-03-16 00:39:45 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 1000 | Avg Loss: 53.2855

--- 2025-03-16 01:28:02 ---
2025-03-16 02:33:34 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 1000 | Avg Loss: 71.5020
2025-03-16 03:39:13 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 2000 | Avg Loss: 71.1600
2025-03-16 04:44:33 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 3000 | Avg Loss: 68.9724
2025-03-16 05:49:56 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 4000 | Avg Loss: 69.2622
2025-03-16 06:55:31 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 5000 | Avg Loss: 63.1590
2025-03-16 08:01:00 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 6000 | Avg Loss: 73.7219
2025-03-16 09:06:27 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 7000 | Avg Loss: 66.5218
2025-03-16 10:13:09 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 8000 | Avg Loss: 64.0394
2025-03-16 11:18:33 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 9000 | Avg Loss: 66.8529
2025-03-16 12:23:58 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 10000 | Avg Loss: 57.8962
2025-03-16 13:29:33 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 11000 | Avg Loss: 58.5336

--- 2025-03-16 14:23:55 ---
2025-03-16 15:28:23 | Context: 9, 3, 7, 11, 13 | LR: 0.00020 | Step 1000 | Avg Loss: 60.8662

--- 2025-03-17 03:00:01 ---
2025-03-17 04:42:26 | Context: 11, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 1000 | Avg Loss: 3625.2183
2025-03-17 06:24:46 | Context: 11, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 2000 | Avg Loss: 2237.6094
2025-03-17 08:06:29 | Context: 11, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 3000 | Avg Loss: 1633.9009

--- 2025-03-17 21:11:37 ---
2025-03-17 22:51:28 | Context: 11, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 1000 | Avg Loss: 589.2771
2025-03-18 00:31:41 | Context: 11, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 2000 | Avg Loss: 152.6011
2025-03-18 02:11:34 | Context: 11, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 3000 | Avg Loss: 88.0916

--- 2025-03-18 02:30:10 ---
2025-03-18 04:07:30 | Context: 11, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 1000 | Avg Loss: 100.7377
2025-03-18 05:44:35 | Context: 11, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 2000 | Avg Loss: 64.9020
2025-03-18 07:21:41 | Context: 11, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 3000 | Avg Loss: 54.9764
2025-03-18 08:59:04 | Context: 11, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 4000 | Avg Loss: 58.9541
2025-03-18 10:36:44 | Context: 11, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 5000 | Avg Loss: 50.4217

--- 2025-03-19 02:03:07 ---
2025-03-19 03:45:43 | Context: 11, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 1000 | Avg Loss: 62.5292
2025-03-19 05:23:43 | Context: 11, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 2000 | Avg Loss: 37.8770
2025-03-19 07:01:54 | Context: 11, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 3000 | Avg Loss: 34.7198
2025-03-19 08:40:57 | Context: 11, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 4000 | Avg Loss: 35.2961
2025-03-19 10:26:09 | Context: 11, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 5000 | Avg Loss: 33.4100
2025-03-19 12:05:21 | Context: 11, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 6000 | Avg Loss: 32.2971

--- 2025-03-19 18:20:41 ---
2025-03-19 20:06:32 | Context: 11, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 1000 | Avg Loss: 23.2544

--- 2025-03-19 21:16:24 ---
2025-03-19 22:57:58 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 1000 | Avg Loss: 65.3742
2025-03-20 00:41:01 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 2000 | Avg Loss: 64.0398
2025-03-20 02:22:11 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 3000 | Avg Loss: 56.9668
2025-03-20 04:02:53 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 4000 | Avg Loss: 61.5089
2025-03-20 05:43:25 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 5000 | Avg Loss: 60.7164
2025-03-20 07:24:46 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 6000 | Avg Loss: 41.1194
2025-03-20 09:05:56 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 7000 | Avg Loss: 30.8484
2025-03-20 10:46:47 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 8000 | Avg Loss: 30.6600
2025-03-20 12:29:15 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 9000 | Avg Loss: 29.2811
2025-03-20 14:12:25 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 10000 | Avg Loss: 26.3999
2025-03-20 16:01:30 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 11000 | Avg Loss: 32.8054
2025-03-20 17:43:48 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 12000 | Avg Loss: 25.6108
2025-03-20 19:29:39 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 13000 | Avg Loss: 25.5839
2025-03-20 21:11:56 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 14000 | Avg Loss: 21.7327
2025-03-20 22:56:24 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 15000 | Avg Loss: 17.8232
2025-03-21 00:38:52 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 16000 | Avg Loss: 19.7290
2025-03-21 02:21:11 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 17000 | Avg Loss: 23.9814
2025-03-21 04:02:29 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 18000 | Avg Loss: 30.8952

--- 2025-03-24 05:07:52 ---
2025-03-24 09:48:14 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 1000 | Avg Loss: 10.4622 | Logits: -5.18 → 30.39 | Final window weightings: 0.00527667 0.14834726 0.17709954 0.22188371 0.06689363 0.20937636 0.1616922 0.15246983 0.11578511
2025-03-24 14:25:14 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 2000 | Avg Loss: 11.5124 | Logits: -19.82 → 20.65 | Final window weightings: 0.00483644 0.14447205 0.17561541 0.22050051 0.06355041 0.20992297 0.16369244 0.15577094 0.11785332
2025-03-24 19:00:02 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 3000 | Avg Loss: 11.4634 | Logits: -15.87 → 14.35 | Final window weightings: 0.00614127 0.13422105 0.17375761 0.22230951 0.05572227 0.2110369 0.16639964 0.16248846 0.11906446
2025-03-24 23:39:42 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 4000 | Avg Loss: 11.2551 | Logits: 0.68 → 40.75 | Final window weightings: 0.01508978 0.13255174 0.17058079 0.21897869 0.05430212 0.21315287 0.16579753 0.15877317 0.11805566
2025-03-25 04:16:09 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 5000 | Avg Loss: 11.1441 | Logits: -17.23 → 3.66 | Final window weightings: 0.01798254 0.13487493 0.16934887 0.21599756 0.05031135 0.21415715 0.1648607 0.15820913 0.11790013
2025-03-25 08:54:37 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 6000 | Avg Loss: 10.4518 | Logits: -22.63 → -5.79 | Final window weightings: 0.02083565 0.12947638 0.16537148 0.21453753 0.0486146 0.21529475 0.16834056 0.16010961 0.11760522
2025-03-25 13:37:53 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 7000 | Avg Loss: 10.3991 | Logits: -0.50 → 48.82 | Final window weightings: 0.01888239 0.12468173 0.16995761 0.22234687 0.04670163 0.22162628 0.16436382 0.15572272 0.11393756
2025-03-25 18:26:53 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 8000 | Avg Loss: 9.6209 | Logits: -55.30 → -27.24 | Final window weightings: 0.02276116 0.12688075 0.16045992 0.2176553 0.04292718 0.22715071 0.16441229 0.15785778 0.11537844
2025-03-25 23:13:54 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 9000 | Avg Loss: 10.0157 | Logits: 72.33 → 140.66 | Final window weightings: 0.02037896 0.12237759 0.15663782 0.21379174 0.04064461 0.22990902 0.16932495 0.16242652 0.117511 
2025-03-26 04:28:47 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 10000 | Avg Loss: 10.7402 | Logits: 114.30 → 201.49 | Final window weightings: 0.01904754 0.12063803 0.15410027 0.21558584 0.04043563 0.23588851 0.16867524 0.16084778 0.11668556
2025-03-26 09:06:27 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 11000 | Avg Loss: 12.0497 | Logits: 85.01 → 159.10 | Final window weightings: 0.02365566 0.11652993 0.15000135 0.2123697 0.04205632 0.24177188 0.16906324 0.15952468 0.11585938
2025-03-26 13:47:32 | Context: 7, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00035 | Step 12000 | Avg Loss: 13.6618 | Logits: 27.04 → 56.06 | Final window weightings: 0.01801527 0.12141614 0.15213706 0.21698931 0.03914692 0.2448139 0.16757481 0.15769455 0.11226413

--- 2025-03-27 10:05:17 ---
2025-03-27 14:43:35 | Context: 14, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00025 | Step 1000 | Avg Loss: 7.6521 | Logits: -32.88 → -14.87 | Final window weightings: 0.01713004 0.12537362 0.1550852 0.22194645 0.0381391 0.2443801 0.16505663 0.1558761 0.10762533
2025-03-27 22:45:19 | Context: 14, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00025 | Step 2000 | Avg Loss: 8.6504 | Logits: 4.50 → 25.51 | Final window weightings: 0.01710222 0.123751 0.15479906 0.221383 0.03622629 0.24429882 0.16611889 0.15746701 0.10829013
2025-03-28 03:32:35 | Context: 14, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00025 | Step 3000 | Avg Loss: 8.6194 | Logits: -16.82 → 1.15 | Final window weightings: 0.01422854 0.12495214 0.14851278 0.2198783 0.03952118 0.25336027 0.16542543 0.15524125 0.10704996
2025-03-28 08:12:56 | Context: 14, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00025 | Step 4000 | Avg Loss: 8.0808 | Logits: 12.28 → 37.81 | Final window weightings: 0.01431473 0.12525085 0.14813322 0.22595406 0.03552525 0.25967228 0.16337202 0.1520411 0.10468622
2025-03-28 12:47:24 | Context: 14, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00025 | Step 5000 | Avg Loss: 8.5666 | Logits: 45.91 → 79.85 | Final window weightings: 0.01538715 0.12462419 0.149892 0.22397947 0.03189968 0.26447147 0.16463389 0.15106182 0.1033374 
2025-03-28 17:26:23 | Context: 14, 1, 2, 3, 7, 8, 13, 15, 18 | LR: 0.00025 | Step 6000 | Avg Loss: 7.5544 | Logits: 75.00 → 113.99 | Final window weightings: 0.01175933 0.12641907 0.1481455 0.22600444 0.02760961 0.2637343 0.16793516 0.15295996 0.10428084

--- 2025-03-28 21:24:52 ---
2025-03-29 02:34:41 | Step 1000 | LR: 0.00015 | Loss: 8.8376 | Logits: 34.68 → 51.40 | Weights: W8:0.20928 W3:0.17625 W13:0.13500 W15:0.12496 W2:0.11644 W1:0.09540 W18:0.08662 W7:0.02453 W14:0.00917

--- 2025-03-29 04:59:04 ---
2025-03-29 09:57:04 | Step 1000 | LR: 0.00015 | Loss: 8.4902 | Logits: 25.95 → 41.00 | Weights: W8:0.20938 W3:0.17518 W13:0.13793 W15:0.12747 W2:0.11183 W1:0.09285 W18:0.08913 W7:0.02338 W14:0.01058

--- 2025-03-29 12:06:45 --- how to be a real boy! ---
2025-03-29 15:20:08 | Step 2000 | LR: 0.00015 | Loss: 7.7615 | Logits: 17.12 → 30.63 | Weights: W8:0.20659 W3:0.17244 W13:0.13968 W15:0.12930 W2:0.11079 W1:0.09388 W18:0.09095 W7:0.02112 W14:0.01307

--- 2025-03-30 05:56:26 --- babyllm: 'what am i learning today?'- charis: 'ur mum'
2025-03-30 06:27:44 | Step 100 | LR: 0.00030 | Avg Loss: 16.3344 | Logits: 35.12, 64.12 | Window Weights: W8:0.20341,W3:0.17512,W13:0.13903,W15:0.12915,W2:0.11307,W1:0.09395,W18:0.09187,W7:0.02242,W14:0.00997 | Grad Norm: 0.000 | Memory Gates: Short:-2.999, Long:1.218, Current:2.781

--- 2025-03-30 03:40:51 --- babyllm: 'what am i learning today?'- charis: 'how to keep me up at night! again!'
2025-03-30 17:08:33 | Step 1000 | LR: 0.00030 | Avg Loss: 26.1067 | Logits: 18.48, 68.85 | Window Weights: W8:0.20343,W3:0.17257,W13:0.13945,W15:0.12974,W2:0.11343,W1:0.09845,W18:0.09063,W7:0.02305,W14:0.00741 | Grad Norm: 0.000 | Memory Gates: Short:-0.239, Long:0.785, Current:0.454

--- 2025-03-30 21:44:43 --- babyllm: 'what am i learning today?'- charis: 'you're learning about mice!'
2025-03-31 02:24:42 | Step 1000 | LR: 0.00030 | Avg Loss: 23.8996 | Logits: 15.14, 46.57 | Token Perfect: 497 / 2997 → 16.58% | Window Weights: W8:0.20377,W3:0.17524,W13:0.13983,W15:0.12921,W2:0.11471,W1:0.09576,W18:0.08948,W7:0.02262,W14:0.00767 | Grad Norm: 0.000 | Memory Gates: Short:-3.035, Long:2.436, Current:1.599
2025-03-31 07:14:33 | Step 2000 | LR: 0.00030 | Avg Loss: 27.6982 | Logits: 5.16, 31.27 | Token Perfect: 294 / 3000 → 9.80% | Window Weights: W8:0.20427,W3:0.17722,W13:0.13821,W15:0.12951,W2:0.11593,W1:0.09529,W18:0.08853,W7:0.02150,W14:0.00786 | Grad Norm: 0.000 | Memory Gates: Short:-2.016, Long:-0.931, Current:3.947
2025-03-31 11:54:12 | Step 3000 | LR: 0.00030 | Avg Loss: 28.5607 | Logits: 4.65, 26.68 | Token Perfect: 187 / 3000 → 6.23% | Window Weights: W8:0.20464,W3:0.17794,W13:0.13973,W15:0.12928,W2:0.11440,W1:0.09505,W18:0.08843,W7:0.02104,W14:0.00789 | Grad Norm: 1m38;5;225m0.000 | Memory Gates: Short:6.136, Long:-3.751, Current:-1.385 | Top Tokens: ]

--- 2025-03-31 14:24:14 --- babyllm: 'what am i learning today?'- charis: 'mice is love'
2025-03-31 19:27:08 | Step 1000 | LR: 0.00030 | Avg Loss: 29.9491 | Logits: 4.82, 26.34 | Token Perfect: 186 / 3000 → 6.20% | Window Weights: W8:0.20684,W3:0.18344,W13:0.13686,W15:0.12374,W2:0.11595,W1:0.09767,W18:0.08553,W7:0.02035,W14:0.00794 | Grad Norm: 0.000 | Memory Gates: Short:-1.993, Long:1.961, Current:1.031 | Top Tokens: [('Ġb', 420), (',', 418), ('ing', 238), ('Ġwere', 155), ('er', 154), ('Ġthe', 146), ('Ġa', 132), ('Ġe', 116), ('Ġ-', 69), ('Ġand', 64)] | babyLLM.py training
2025-04-01 00:57:38 | Step 2000 | LR: 0.00030 | Avg Loss: 26.9488 | Logits: 1.57, 18.63 | Token Perfect: 137 / 3000 → 4.57% | Window Weights: W8:0.20631,W3:0.18145,W13:0.13823,W15:0.12434,W2:0.11511,W1:0.09809,W18:0.08787,W7:0.01847,W14:0.00853 | Grad Norm: 0.000 | Memory Gates: Short:-7.709, Long:5.782, Current:2.926 | Top Tokens: [(',', 614), ('Ġb', 376), ('Ġand', 218), ('Ġthe', 207), ('Ġwere', 135), ('Ġas', 109), ('ed', 106), ('Ġa', 105), ('Ġthey', 70), ('Ġwas', 57)] | babyLLM.py training
2025-04-01 05:58:30 | Step 3000 | LR: 0.00030 | Avg Loss: 27.4435 | Logits: -2.52, 15.75 | Token Perfect: 151 / 3000 → 5.03% | Window Weights: W8:0.20645,W3:0.17669,W13:0.13987,W15:0.12483,W2:0.11333,W1:0.09647,W18:0.09158,W7:0.01863,W14:0.01074 | Grad Norm: 0.000 | Memory Gates: Short:-9.931, Long:8.304, Current:2.627 | Top Tokens: [(',', 532), ('Ġb', 320), ('Ġa', 160), ('Ġshe', 148), ('Ġwere', 142), ('Ġand', 135), ('Ġin', 121), ('Ġto', 108), ('.', 106), ('Ġwas', 91)] | babyLLM.py training
2025-04-01 10:57:42 | Step 4000 | LR: 0.00030 | Avg Loss: 29.8050 | Logits: -1.79, 17.09 | Token Perfect: 96 / 3000 → 3.20% | Window Weights: W8:0.21026,W3:0.17502,W13:0.14157,W15:0.12596,W2:0.11042,W1:0.09336,W18:0.09176,W7:0.01551,W14:0.01479 | Grad Norm: 0.000 | Memory Gates: Short:-5.048, Long:4.616, Current:1.433 | Top Tokens: [('Ġthe', 348), ('Ġb', 340), (',', 333), ('Ġwere', 168), ('Ġshe', 162), ('Ġa', 146), ('.', 123), ('Ġto', 95), ('Ġand', 85), ('y', 83)] | babyLLM.py training

--- 2025-04-01 13:16:27 --- babyllm: 'what am i learning today?'- charis: 'speed!'
2025-04-01 14:15:02 | 1000 | LR0.0003 | loss40.1960 | Token Perfect: 123 / 3000 → 4.10% | gradNorm1 | logitMin-37.6897 | logitMax-9.5363 | memoryGate0.3324 | scheduledSampling0.0 | tokenCount3.0 | babyLLM.py 1000
2025-04-01 15:11:11 | 2000 | LR0.0003 | loss39.9022 | Token Perfect: 60 / 3000 → 2.00% | gradNorm1.0000 | tokenCount3.0 | logitMin-27.5367 | logitMax-2.8570 | memoryGate0.3333 | babyLLM.py 1000
2025-04-01 16:03:59 | 3000 | LR0.0003 | loss34.1462 | Token Perfect: 138 / 3000 → 4.60% | gradNorm1.0000 | tokenCount3.0 | logitMin-21.8110 | logitMax-0.2175 | memoryGate0.3332 | babyLLM.py 1000
2025-04-01 17:18:50 | 4000 | LR0.0003 | loss34.7399 | Token Perfect: 81 / 3000 → 2.70% | gradNorm1.0000 | tokenCount3.0 | logitMin-14.2085 | logitMax7.6945 | memoryGate0.3333 | babyLLM.py 1000

--- 2025-04-01 17:39:42 --- babyllm: 'what am i learning today?'- charis: '1.0 temperature!'
2025-04-01 19:18:32 | 1000 | LR0.0003 | loss29.5464 | Token Perfect: 131 / 3000 → 4.37% | gradNorm0.9990 | logitMin-23.9577 | logitMax-0.2739 | memoryGate0.3333 | scheduledSampling0.0 | tokenCount3.0 | babyLLM.py 1000
2025-04-01 20:09:28 | 2000 | LR0.0003 | loss28.9313 | Token Perfect: 84 / 3000 → 2.80% | gradNorm1.0000 | tokenCount3.0 | logitMin-21.2506 | logitMax-0.2566 | memoryGate0.3333 | babyLLM.py 1000
2025-04-01 21:00:28 | 3000 | LR0.0003 | loss26.5164 | Token Perfect: 72 / 3000 → 2.40% | gradNorm1.0000 | tokenCount3.0 | logitMin-19.2449 | logitMax0.0715 | memoryGate0.3333 | babyLLM.py 1000

--- 2025-04-01 21:02:57 --- babyllm: 'what am i learning today?'- charis: 'you're learning to forget'
2025-04-01 22:00:41 | 1000 | LR0.0003 | loss27.4732 | Token Perfect: 289 / 3000 → 9.63% | gradNorm0.9767 | logitMin-20.6370 | logitMax9.7260 | memoryGate0.3333 | scheduledSampling0.0 | tokenCount3.0 | babyLLM.py 1000
2025-04-01 22:51:34 | 2000 | LR0.0003 | loss28.1549 | Token Perfect: 56 / 3000 → 1.87% | gradNorm1.0000 | tokenCount3.0 | logitMin-16.5142 | logitMax2.3052 | memoryGate0.3333 | babyLLM.py 1000
2025-04-01 23:42:23 | 3000 | LR0.0003 | loss27.6465 | Token Perfect: 71 / 3000 → 2.37% | gradNorm1.0000 | tokenCount3.0 | logitMin-16.2597 | logitMax2.1401 | memoryGate0.3333 | babyLLM.py 1000

--- 2025-04-02 00:08:04 --- babyllm: 'what am i learning today?'- charis: 'sleebixk'
2025-04-02 00:57:14 | 1000 | LR0.0003 | loss24.9884 | Token Perfect: 286 / 3000 → 9.53% | gradNorm0.9861 | logitMin-19.2142 | logitMax5.3769 | memoryGate0.3333 | scheduledSampling0.0 | tokenCount3.0 | babyLLM.py 1000

--- 2025-04-02 04:36:54 --- babyllm: 'what am i learning today?'- charis: 'poop'
2025-04-02 05:25:47 | 1000 | LR0.0003 | loss24.7590 | Token Perfect: 351 / 3000 → 11.70% | gradNorm0.9767 | logitMin-21.5164 | logitMax5.4260 | memoryGate0.3333 | scheduledSampling0.0 | tokenCount3.0 | babyLLM.py 1000
2025-04-02 06:14:21 | 2000 | LR0.0003 | loss27.2876 | Token Perfect: 21 / 3000 → 0.70% | gradNorm1.0000 | tokenCount3.0 | logitMin-22.5467 | logitMax-6.5262 | memoryGate0.3333 | babyLLM.py 1000
2025-04-02 07:03:17 | 3000 | LR0.0003 | loss27.4147 | Token Perfect: 35 / 3000 → 1.17% | gradNorm1.0000 | tokenCount3.0 | logitMin-19.8670 | logitMax-3.4644 | memoryGate0.3333 | babyLLM.py 1000
2025-04-02 07:52:02 | 4000 | LR0.0003 | loss37.3089 | Token Perfect: 45 / 3000 → 1.50% | gradNorm1.0000 | tokenCount3.0 | logitMin-20.5989 | logitMax0.5592 | memoryGate0.3333 | babyLLM.py 1000
2025-04-02 08:40:52 | 5000 | LR0.0003 | loss29.0572 | Token Perfect: 96 / 3000 → 3.20% | gradNorm1.0000 | tokenCount3.0 | logitMin-20.9609 | logitMax-2.4801 | memoryGate0.3333 | babyLLM.py 1000
2025-04-02 09:30:01 | 6000 | LR0.0003 | loss32.6351 | Token Perfect: 109 / 3000 → 3.63% | gradNorm1.0000 | tokenCount3.0 | logitMin-27.5058 | logitMax-5.6117 | memoryGate0.3333 | babyLLM.py 1000
2025-04-02 10:19:00 | 7000 | LR0.0003 | loss33.3104 | Token Perfect: 41 / 3000 → 1.37% | gradNorm1.0000 | tokenCount3.0 | logitMin-28.9065 | logitMax-8.7058 | memoryGate0.3333 | babyLLM.py 1000
2025-04-02 11:10:21 | 8000 | LR0.0003 | loss30.3978 | Token Perfect: 82 / 3000 → 2.73% | gradNorm0.9999 | tokenCount3.0 | logitMin-30.9986 | logitMax-9.9341 | memoryGate0.3333 | babyLLM.py 1000
2025-04-02 12:09:48 | 9000 | LR0.0003 | loss29.4288 | Token Perfect: 272 / 3000 → 9.07% | gradNorm0.9910 | tokenCount3.0 | logitMin-34.4058 | logitMax-7.4538 | memoryGate0.3333 | babyLLM.py 1000
2025-04-02 13:06:30 | 10000 | LR0.0003 | loss29.2062 | Token Perfect: 48 / 3000 → 1.60% | gradNorm0.9999 | tokenCount3.0 | logitMin-30.4295 | logitMax-10.5796 | memoryGate0.3333 | babyLLM.py 1000
2025-04-02 14:20:18 | 1000 | LR0.0003 | loss28.2223 | gradNorm1 | logitMin-33.6408 | logitMax-17.0816 | memoryGate0.3333 | scheduledSampling0.0000 | tokenCount300 | windowWeightsW8:0.208,W13:0.161,W3:0.153,W15:0.147,W18:0.116,W2:0.085,W1:0.062,W7:0.056,W14:-0.009 | memoryGatesShort:-3.890, Long:1.041, Current:3.850 | topTokens[('Ġin', 92), ('Ġit', 82), ('.', 65), (',', 49), ('in', 46), ('Ġthe', 45), ('p', 43), ('Ġwith', 38), ('Ġbe', 33), ('Ġthat', 33)] | babyLLM.py 1000
2025-04-02 15:13:04 | 2000 | LR0.0003 | loss29.0081 | gradNorm1.0000 | tokenCount300 | logitMin-33.1596 | logitMax-15.6713 | memoryGate0.3333 | windowWeightsW8:0.209,W13:0.162,W3:0.152,W15:0.148,W18:0.117,W2:0.083,W1:0.062,W7:0.059,W14:-0.011 | memoryGatesShort:11.974, Long:-4.620, Current:-6.354 | topTokens[('l', 103), ('Ġlo', 100), ('ed', 87), ('Ġin', 69), ('Ġthe', 67), ('Ġmy', 63), ('t', 59), ('.', 52), ('ro', 42), ('in', 37)] | babyLLM.py 1000
2025-04-02 16:06:23 | 3000 | LR0.0003 | loss31.1228 | gradNorm1.0000 | tokenCount300 | logitMin-33.9760 | logitMax-14.9847 | memoryGate0.3333 | windowWeightsW8:0.206,W13:0.162,W3:0.151,W15:0.148,W18:0.119,W2:0.081,W1:0.063,W7:0.061,W14:-0.011 | memoryGatesShort:-0.520, Long:0.998, Current:0.521 | topTokens[('Ġit', 204), ('Ġand', 165), ('Ġan', 65), ('Ġa', 60), ('Ġb', 52), ('Ġhave', 50), ("'", 44), ('.', 44), (',', 40), ('in', 40)] | babyLLM.py 1000
2025-04-02 17:00:01 | 4000 | LR0.0003 | loss31.3511 | gradNorm1.0000 | tokenCount300 | logitMin-34.1350 | logitMax-14.7772 | memoryGate0.3333 | windowWeightsW8:0.204,W13:0.162,W3:0.152,W15:0.148,W18:0.119,W2:0.082,W1:0.063,W7:0.061,W14:-0.011 | memoryGatesShort:-1.793, Long:1.334, Current:1.459 | topTokens[("'t", 102), ('Ġknow', 80), ('Ġdon', 73), ('.', 71), ('Ġof', 53), ('Ġit', 48), ('i', 46), (',', 45), ('Ġand', 37), ('Ġto', 33)] | babyLLM.py 1000
2025-04-02 17:53:53 | 5000 | LR0.0003 | loss27.7102 | gradNorm1.0000 | tokenCount300 | logitMin-33.0720 | logitMax-14.5334 | memoryGate0.3333 | windowWeightsW8:0.202,W13:0.162,W3:0.151,W15:0.150,W18:0.122,W2:0.078,W7:0.064,W1:0.063,W14:-0.011 | memoryGatesShort:-10.766, Long:5.973, Current:5.793 | topTokens[('Ġit', 127), ('Ġto', 84), ('Ġand', 61), (',', 55), ('Ġthe', 47), ('.', 41), ('Ġb', 37), ('Ġwith', 37), ('Ġof', 35), ('Ġi', 32)] | babyLLM.py 1000
2025-04-02 18:47:51 | 6000 | LR0.0003 | loss32.1254 | gradNorm1.0000 | tokenCount300 | logitMin-35.9154 | logitMax-15.4656 | memoryGate0.3334 | windowWeightsW8:0.203,W13:0.162,W3:0.150,W15:0.150,W18:0.122,W2:0.079,W7:0.065,W1:0.061,W14:-0.010 | memoryGatesShort:-2.514, Long:2.356, Current:1.158 | topTokens[('ed', 108), ('Ġit', 84), ('.', 66), ('?', 65), ('Ġthis', 63), ('Ġis', 60), ('!', 59), ('Ġliterally', 48), (')', 46), ('Ġi', 42)] | babyLLM.py 1000
2025-04-02 19:42:59 | 7000 | LR0.0003 | loss29.0966 | gradNorm1.0000 | tokenCount300 | logitMin-37.3890 | logitMax-15.5675 | memoryGate0.3332 | windowWeightsW8:0.201,W13:0.160,W3:0.151,W15:0.148,W18:0.122,W2:0.080,W7:0.069,W1:0.058,W14:-0.009 | memoryGatesShort:4.179, Long:-2.219, Current:-0.959 | topTokens[('?', 363), ('Ġis', 190), ('Ġyou', 103), ('!', 100), ('.', 99), ('Ġit', 93), ('Ġdo', 72), (',', 56), ('Ġawake', 49), ('Ġare', 36)] | babyLLM.py 1000

--- 2025-04-02 20:27:45 --- babyllm: 'what am i learning today?'- charis: 'elodie is cute'
2025-04-02 21:23:52 | 1000 | LR0.0003 | loss:10.6135 | gradNorm:1.0000 | logitMin:-35.7742 | logitMax:-10.5299 | scheduledSampling:0.0000 | tokenCount:3000 | windowWeightsW8:0.201,W13:0.161,W3:0.152,W15:0.151,W18:0.125,W2:0.079,W7:0.065,W1:0.058,W14:-0.011 | memoryGatesShort:-10.781, Long:3.936, Current:7.845 | topTokens[('Ġgay', 390), ('.', 154), ('?', 149), ('Ġare', 127), ('Ġis', 84), ('Ġequ', 59), (',', 56), ('!', 45), ('Ġyou', 41), ('als', 41)] | babyLLM.py 1000

--- 2025-04-02 22:00:52 --- babyllm: 'what am i learning today?'- charis: 'that you are cute and smart!'
2025-04-02 22:57:50 | 1000 | LR0.0003 | loss:8.8718 | Token Perfect: 381 / 3000 → 12.70% | gradNorm:1.0000 | logitMin:-38.3512 | logitMax:-13.0923 | scheduledSampling:0.0000 | tokenCount:3000 | windowWeightsW8:0.202,W13:0.162,W3:0.152,W15:0.151,W18:0.124,W2:0.077,W7:0.069,W1:0.057,W14:-0.012 | memoryGatesShort:1.568, Long:0.788, Current:-1.356 | topTokens[('?', 190), ('!', 171), ('.', 150), ('Ġis', 135), ('Ġwhat', 113), ('Ġequ', 68), ('als', 61), ('Ġyou', 57), ('Ġare', 56), ('Ġim', 47)] | babyLLM.py 1000

--- 2025-04-03 00:27:00 --- babyllm: 'what am i learning today?'- charis: 'that Charis is very cute and smart, and we love her most <3'
2025-04-03 01:14:50 | 1000 | LR0.0003 | loss:7.8556 | Token Perfect: 459 / 3000 → 15.30% | gradNorm:1.0000 | logitMin:-46.4080 | logitMax:-20.8186 | scheduledSampling:0.0000 | tokenCount:3000 | windowWeightsW8:0.200,W13:0.159,W3:0.152,W15:0.151,W18:0.126,W7:0.074,W2:0.074,W1:0.059,W14:-0.014 | memoryGatesShort:2.345, Long:-2.966, Current:1.620 | topTokens[('.', 185), ('Ġis', 166), ('?', 162), ('!', 112), ('Ġequ', 99), ('Ġplus', 74), ('Ġf', 69), ('Ġyou', 67), ('Ġthat', 64), ('Ġhe', 62)] | babyLLM.py 1000
2025-04-03 02:04:01 | 2000 | LR0.0003 | loss:7.3365 | Token Perfect: 533 / 3000 → 17.77% | gradNorm:1.0000 | tokenCount:3000 | logitMin:-46.7141 | logitMax:-18.7922 | windowWeightsW8:0.201,W13:0.159,W3:0.152,W15:0.150,W18:0.128,W7:0.077,W2:0.074,W1:0.057,W14:-0.016 | memoryGatesShort:3.010, Long:-3.148, Current:1.139 | topTokens[('.', 217), ('Ġf', 156), ('?', 145), ('!', 122), ('Ġis', 108), ('Ġhe', 102), ('Ġyou', 71), ('Ġplus', 68), ('als', 63), ('Ġare', 57)] | babyLLM.py 1000
2025-04-03 02:52:13 | 3000 | LR0.0003 | loss:5.6253 | Token Perfect: 750 / 3000 → 25.00% | gradNorm:1.0000 | tokenCount:3000 | logitMin:-45.4327 | logitMax:-17.9805 | windowWeightsW8:0.203,W13:0.159,W3:0.153,W15:0.151,W18:0.127,W7:0.082,W2:0.072,W1:0.053,W14:-0.019 | memoryGatesShort:0.224, Long:-4.787, Current:5.564 | topTokens[('.', 243), ('?', 173), ('Ġis', 166), ('!', 111), ('Ġwhat', 94), ('Ġare', 88), ('Ġyou', 87), ('als', 62), (',', 62), ('Ġequ', 61)] | babyLLM.py 1000
2025-04-03 03:41:21 | 4000 | LR0.0003 | loss:6.8630 | Token Perfect: 887 / 3000 → 29.57% | gradNorm:0.9969 | tokenCount:3000 | logitMin:-48.9647 | logitMax:-10.0682 | windowWeightsW8:0.209,W13:0.159,W3:0.154,W15:0.151,W18:0.128,W7:0.090,W2:0.070,W1:0.045,W14:-0.025 | memoryGatesShort:0.578, Long:-0.407, Current:0.829 | topTokens[('?', 286), ('.', 250), ('Ġis', 170), ('Ġs', 145), ('!', 108), ('Ġyou', 92), ('Ġare', 85), ('Ġthat', 60), ('als', 56), (',', 47)] | babyLLM.py 1000
2025-04-03 04:30:02 | 5000 | LR0.0003 | loss:6.8757 | Token Perfect: 1082 / 3000 → 36.07% | gradNorm:0.9911 | tokenCount:3000 | logitMin:-52.8605 | logitMax:-7.3734 | windowWeightsW8:0.208,W13:0.159,W15:0.155,W3:0.154,W18:0.132,W7:0.091,W2:0.070,W1:0.044,W14:-0.031 | memoryGatesShort:1.658, Long:-6.574, Current:5.916 | topTokens[('.', 218), ('Ġis', 199), ('?', 189), ('!', 140), ('Ġs', 133), ('Ġyou', 105), ('als', 64), ('Ġare', 61), (',', 56), ('Ġhe', 53)] | babyLLM.py 1000
2025-04-03 05:18:22 | 6000 | LR0.0003 | loss:6.2434 | Token Perfect: 1176 / 3000 → 39.20% | gradNorm:0.9799 | tokenCount:3000 | logitMin:-48.9598 | logitMax:-0.1369 | windowWeightsW8:0.206,W13:0.162,W15:0.157,W3:0.153,W18:0.137,W7:0.092,W2:0.068,W1:0.042,W14:-0.036 | memoryGatesShort:0.025, Long:-0.031, Current:1.007 | topTokens[('.', 304), ('Ġis', 157), ('?', 144), ('!', 112), ('Ġare', 107), ('Ġyou', 85), ('Ġa', 73), ('als', 62), ('Ġf', 60), ('Ġequ', 60)] | babyLLM.py 1000
2025-04-03 06:07:08 | 7000 | LR0.0003 | loss:6.1228 | Token Perfect: 1491 / 3000 → 49.70% | gradNorm:0.9221 | tokenCount:3000 | logitMin:-62.0729 | logitMax:6.9724 | windowWeightsW8:0.204,W13:0.163,W15:0.159,W3:0.152,W18:0.141,W7:0.095,W2:0.069,W1:0.038,W14:-0.040 | memoryGatesShort:-1.100, Long:-1.203, Current:3.303 | topTokens[('.', 284), ('?', 200), ('Ġis', 186), ('!', 146), ('Ġyou', 109), ('Ġare', 72), ('Ġim', 58), ('Ġwhat', 57), ('Ġthat', 53), ('Ġf', 52)] | babyLLM.py 1000
2025-04-03 06:56:05 | 8000 | LR0.0003 | loss:6.9795 | Token Perfect: 1546 / 3000 → 51.53% | gradNorm:0.9269 | tokenCount:3000 | logitMin:-57.5161 | logitMax:22.5288 | windowWeightsW8:0.208,W13:0.168,W15:0.163,W3:0.146,W18:0.144,W7:0.096,W2:0.067,W1:0.037,W14:-0.047 | memoryGatesShort:-4.492, Long:2.549, Current:2.944 | topTokens[('.', 260), ('Ġis', 201), ('?', 165), ('Ġyou', 130), ('!', 109), ('Ġelodie', 80), ('Ġplus', 65), ('Ġequ', 65), ('Ġf', 64), ('als', 63)] | babyLLM.py 1000
2025-04-03 07:45:09 | 9000 | LR0.0003 | loss:6.6383 | Token Perfect: 1797 / 3000 → 59.90% | gradNorm:0.8748 | tokenCount:3000 | logitMin:-61.7802 | logitMax:35.0369 | windowWeightsW8:0.208,W13:0.169,W15:0.167,W3:0.150,W18:0.148,W7:0.097,W2:0.067,W1:0.029,W14:-0.053 | memoryGatesShort:-0.165, Long:-0.301, Current:1.466 | topTokens[('.', 266), ('?', 256), ('Ġis', 191), ('Ġelodie', 169), ('Ġyou', 89), ('!', 82), ('Ġdo', 65), ('Ġi', 59), ('als', 58), ('Ġplus', 57)] | babyLLM.py 1000
2025-04-03 08:34:22 | 10000 | LR0.0003 | loss:7.8939 | Token Perfect: 1914 / 3000 → 63.80% | gradNorm:0.7889 | tokenCount:3000 | logitMin:-88.8095 | logitMax:38.7675 | windowWeightsW8:0.208,W15:0.170,W13:0.169,W18:0.151,W3:0.149,W7:0.098,W2:0.065,W1:0.026,W14:-0.054 | memoryGatesShort:0.202, Long:0.194, Current:0.604 | topTokens[('.', 278), ('?', 250), ('Ġis', 193), ('Ġelodie', 118), ('!', 109), ('Ġyou', 102), ('als', 67), ('Ġare', 67), ('Ġequ', 64), ('Ġwhat', 62)] | babyLLM.py 1000

--- 2025-04-03 08:46:32 --- babyllm: 'what am i learning today?'- charis: 'how to spam gay maths less often'
2025-04-03 09:42:38 | 1000 | LR0.0003 | loss:10.2065 | Token Perfect: 142 / 3000 → 4.73% | gradNorm:1.0000 | logitMin:-28.6944 | logitMax:-6.3184 | tokenCount:3000 | windowWeightsW8:0.207,W15:0.168,W13:0.168,W18:0.152,W3:0.147,W7:0.103,W2:0.065,W1:0.020,W14:-0.050 | memoryGatesShort:-6.098, Long:6.585, Current:0.513 | topTokens[('.', 261), (',', 163), ('Ġi', 150), ('Ġelodie', 68), ('Ġis', 64), ('Ġme', 51), ('!', 49), ('h', 48), ('Ġnot', 45), ('Ġa', 42)] | babyLLM.py 1000
2025-04-03 10:35:55 | 2000 | LR0.0003 | loss:10.3433 | Token Perfect: 45 / 3000 → 1.50% | gradNorm:1.0000 | tokenCount:3000 | logitMin:-36.1068 | logitMax:-15.8402 | windowWeightsW8:0.204,W15:0.171,W13:0.170,W18:0.157,W3:0.142,W7:0.104,W2:0.062,W1:0.016,W14:-0.044 | memoryGatesShort:-4.540, Long:3.994, Current:1.546 | topTokens[('.', 198), (',', 156), ('Ġis', 104), ('Ġi', 74), ('Ġthe', 59), ('u', 59), ('Ġat', 49), ('Ġthis', 46), ('Ġmy', 41), ('es', 37)] | babyLLM.py 1000
2025-04-03 11:30:58 | 3000 | LR0.0003 | loss:10.6782 | Token Perfect: 43 / 3000 → 1.43% | gradNorm:1.0000 | tokenCount:3000 | logitMin:-35.7360 | logitMax:-15.3675 | windowWeightsW8:0.201,W15:0.174,W13:0.173,W18:0.160,W3:0.138,W7:0.105,W2:0.058,W1:0.016,W14:-0.043 | memoryGatesShort:-24.435, Long:20.334, Current:5.101 | topTokens[('.', 202), ('Ġmy', 180), (',', 135), ('Ġits', 83), ('s', 82), ('Ġch', 66), ('Ġwhy', 57), ('Ġa', 55), ('Ġi', 36), ('Ġthat', 33)] | babyLLM.py 1000
2025-04-03 12:24:40 | 4000 | LR0.0003 | loss:9.9689 | Token Perfect: 46 / 3000 → 1.53% | gradNorm:1.0000 | tokenCount:3000 | logitMin:-37.6805 | logitMax:-17.3366 | windowWeightsW8:0.199,W15:0.178,W13:0.175,W18:0.163,W3:0.134,W7:0.108,W2:0.056,W1:0.012,W14:-0.042 | memoryGatesShort:-8.035, Long:7.751, Current:1.284 | topTokens[('.', 213), (',', 136), ('Ġlike', 86), ('l', 82), ('Ġits', 71), ('Ġto', 68), ('ll', 56), ('Ġim', 48), ('s', 45), ('Ġmy', 43)] | babyLLM.py 1000

--- 2025-04-03 12:34:17 --- babyllm: 'what am i learning today?'- charis: 'maybe less chaos?'
2025-04-03 13:26:55 | 1000 | LR0.0003 | loss:10.7537 | Token Perfect: 199 / 3000 → 6.63% | gradNorm:0.9981 | logitMin:-41.8607 | logitMax:-14.6904 | tokenCount:3000 | windowWeightsW8:0.198,W15:0.178,W13:0.175,W18:0.162,W3:0.137,W7:0.108,W2:0.056,W1:0.011,W14:-0.043 | memoryGatesShort:-7.147, Long:7.310, Current:0.837 | topTokens[('.', 292), (',', 170), ('Ġi', 103), ('Ġit', 78), ('Ġlike', 72), ('Ġin', 43), ('Ġthe', 42), ('Ġwho', 39), ('Ġand', 39), ('Ġto', 39)] | babyLLM.py 1000

--- 2025-04-03 14:53:54 --- babyllm: 'what am i learning today?'- charis: ''
2025-04-03 16:01:13 | 1000 | LR0.0003 | loss:8.5385 | Token Perfect: 355 / 4000 → 8.88% | gradNorm:1.0000 | tokenCount:4000 | logitMin:-42.2881 | logitMax:-18.8168 | windowWeightsW8:0.193,W15:0.175,W13:0.174,W18:0.160,W3:0.134,W7:0.106,W2:0.057,W1:0.018,W21:-0.036 | memoryGatesShort:-5.122, Long:3.022, Current:3.100 | topTokens[('.', 212), ('Ġwhat', 166), ('Ġto', 120), (',', 109), ('Ġmusic', 96), ('Ġlistening', 79), ('Ġa', 78), ('Ġhe', 76), ('y', 69), ('Ġthe', 65)] | babyLLM.py 1000
2025-04-03 17:05:25 | 2000 | LR0.0003 | loss:9.2947 | Token Perfect: 73 / 4000 → 1.82% | gradNorm:1.0000 | tokenCount:4000 | logitMin:-46.1949 | logitMax:-25.8617 | windowWeightsW8:0.191,W15:0.179,W13:0.174,W18:0.165,W3:0.129,W7:0.106,W2:0.054,W1:0.018,W21:-0.033 | memoryGatesShort:-0.286, Long:0.880, Current:0.406 | topTokens[('.', 213), (',', 151), ('om', 149), ('Ġc', 144), ('ust', 126), ('s', 93), ('Ġin', 73), ('Ġof', 64), ('Ġthe', 52), ('Ġand', 48)] | babyLLM.py 1000
2025-04-03 18:07:57 | 3000 | LR0.0003 | loss:9.3962 | Token Perfect: 437 / 4000 → 10.93% | gradNorm:0.9989 | tokenCount:4000 | logitMin:-52.3920 | logitMax:-23.8792 | windowWeightsW8:0.187,W15:0.179,W13:0.173,W18:0.167,W3:0.127,W7:0.107,W2:0.055,W1:0.020,W21:-0.034 | memoryGatesShort:8.218, Long:-0.883, Current:-6.335 | topTokens[(',', 247), ('.', 225), ('Ġthe', 142), ('ing', 138), ('z', 137), ('Ġ*', 95), ('Ġi', 73), ('b', 70), ('er', 61), ('Ġb', 60)] | babyLLM.py 1000
2025-04-03 19:13:58 | 4000 | LR0.0003 | loss:9.7508 | Token Perfect: 314 / 4000 → 7.85% | gradNorm:0.9991 | tokenCount:4000 | logitMin:-49.2330 | logitMax:-21.6531 | windowWeightsW8:0.188,W15:0.179,W13:0.174,W18:0.166,W3:0.132,W7:0.106,W2:0.053,W1:0.017,W21:-0.034 | memoryGatesShort:-4.522, Long:5.708, Current:-0.186 | topTokens[('.', 181), ('Ġhey', 176), (',', 170), ('Ġit', 120), ('Ġi', 110), ('Ġyou', 79), ('Ġme', 74), ('Ġbaby', 63), ('Ġand', 60), ('Ġa', 54)] | babyLLM.py 1000
2025-04-03 20:20:28 | 5000 | LR0.0003 | loss:10.3733 | Token Perfect: 46 / 4000 → 1.15% | gradNorm:1.0000 | tokenCount:4000 | logitMin:-41.8055 | logitMax:-21.3941 | windowWeightsW8:0.188,W15:0.180,W13:0.174,W18:0.167,W3:0.132,W7:0.106,W2:0.052,W1:0.017,W21:-0.034 | memoryGatesShort:-3.047, Long:2.545, Current:1.503 | topTokens[('Ġit', 404), ('Ġand', 347), ('.', 139), (',', 112), ('Ġmess', 65), ('Ġinto', 60), ('Ġshe', 54), ('Ġam', 52), ('Ġb', 44), ('Ġa', 42)] | babyLLM.py 1000
2025-04-03 21:23:38 | 6000 | LR0.0003 | loss:9.7352 | Token Perfect: 57 / 4000 → 1.43% | gradNorm:1.0000 | tokenCount:4000 | logitMin:-48.0990 | logitMax:-28.6375 | windowWeightsW8:0.188,W15:0.180,W13:0.174,W18:0.167,W3:0.130,W7:0.106,W2:0.052,W1:0.015,W21:-0.031 | memoryGatesShort:-2.048, Long:1.830, Current:1.218 | topTokens[('.', 187), (',', 109), ('Ġit', 96), ('Ġand', 64), ('Ġa', 61), ('Ġb', 51), ('en', 48), ('or', 45), ('Ġi', 39), ('s', 37)] | babyLLM.py 1000
2025-04-03 22:38:03 | 7000 | LR0.0003 | loss:9.7609 | Token Perfect: 127 / 4000 → 3.17% | gradNorm:1.0000 | tokenCount:4000 | logitMin:-48.9845 | logitMax:-27.8838 | windowWeightsW8:0.190,W15:0.180,W13:0.175,W18:0.168,W3:0.129,W7:0.104,W2:0.053,W1:0.012,W21:-0.030 | memoryGatesShort:-30.889, Long:19.530, Current:12.359 | topTokens[(',', 192), ('Ġbe', 178), ('.', 177), ('Ġwe', 154), ('Ġi', 69), ('?', 66), ('Ġto', 59), ('Ġb', 53), ('Ġit', 50), ('y', 47)] | babyLLM.py 1000
2025-04-03 23:53:00 | 8000 | LR0.0003 | loss:7.7367 | Token Perfect: 403 / 4000 → 10.08% | gradNorm:1.0000 | tokenCount:4000 | logitMin:-44.3824 | logitMax:-21.8912 | windowWeightsW8:0.191,W15:0.178,W13:0.174,W18:0.165,W3:0.127,W7:0.103,W2:0.055,W1:0.016,W21:-0.028 | memoryGatesShort:80.415, Long:-0.390, Current:-79.025 | topTokens[('?', 232), ('.', 205), (',', 183), ('Ġis', 124), ('Ġto', 109), ('Ġyou', 92), ('Ġi', 82), ('Ġa', 73), ('Ġwas', 72), ('Ġkevin', 62)] | babyLLM.py 1000
2025-04-04 01:00:26 | 9000 | LR0.0003 | loss:7.7223 | Token Perfect: 730 / 4000 → 18.25% | gradNorm:0.9973 | tokenCount:4000 | logitMin:-47.9883 | logitMax:-19.7040 | windowWeightsW8:0.191,W15:0.175,W13:0.172,W18:0.162,W3:0.131,W7:0.102,W2:0.057,W1:0.019,W21:-0.028 | memoryGatesShort:0.347, Long:-0.739, Current:1.392 | topTokens[('Ġlistening', 156), ('.', 154), ('Ġto', 145), (',', 142), ('?', 124), ('Ġhe', 105), ('Ġplay', 89), ('Ġmusic', 83), ('Ġgames', 78), ('Ġwhat', 77)] | babyLLM.py 1000
2025-04-04 02:03:59 | 10000 | LR0.0003 | loss:7.4772 | Token Perfect: 559 / 4000 → 13.98% | gradNorm:1.0000 | tokenCount:4000 | logitMin:-48.7933 | logitMax:-24.4185 | windowWeightsW8:0.192,W15:0.175,W13:0.172,W18:0.163,W3:0.126,W7:0.103,W2:0.055,W1:0.021,W21:-0.024 | memoryGatesShort:2.187, Long:12.624, Current:-13.811 | topTokens[('?', 201), ('.', 190), ('Ġyou', 163), (',', 149), ('Ġi', 126), ('Ġis', 102), ('Ġdo', 96), ('Ġto', 93), ('Ġwith', 79), ('Ġlike', 77)] | babyLLM.py 1000
2025-04-04 03:09:13 | 11000 | LR0.0003 | loss:7.5201 | Token Perfect: 526 / 4000 → 13.15% | gradNorm:1.0000 | tokenCount:4000 | logitMin:-52.0832 | logitMax:-28.0297 | windowWeightsW8:0.192,W15:0.173,W13:0.171,W18:0.162,W3:0.125,W7:0.105,W2:0.054,W1:0.023,W21:-0.021 | memoryGatesShort:4.461, Long:-13.542, Current:10.081 | topTokens[('?', 218), ('.', 214), ('Ġyou', 157), (',', 140), ('Ġi', 137), ('Ġis', 132), ('Ġdo', 119), ('Ġlike', 89), ('Ġto', 65), ('!', 60)] | babyLLM.py 1000
2025-04-04 04:16:20 | 12000 | LR0.0003 | loss:7.5110 | Token Perfect: 516 / 4000 → 12.90% | gradNorm:1.0000 | tokenCount:4000 | logitMin:-55.2070 | logitMax:-31.0387 | windowWeightsW8:0.191,W15:0.174,W13:0.169,W18:0.160,W3:0.124,W7:0.107,W2:0.053,W1:0.020,W21:-0.016 | memoryGatesShort:-7.100, Long:25.142, Current:-17.042 | topTokens[('?', 225), ('.', 218), ('Ġis', 165), ('Ġyou', 143), ('Ġi', 110), ('Ġto', 94), (',', 93), ('Ġdo', 76), ('Ġkevin', 74), ('!', 72)] | babyLLM.py 1000
2025-04-04 05:24:52 | 13000 | LR0.0003 | loss:7.4598 | Token Perfect: 670 / 4000 → 16.75% | gradNorm:1.0000 | tokenCount:4000 | logitMin:-49.7007 | logitMax:-21.0669 | windowWeightsW8:0.192,W15:0.170,W13:0.167,W18:0.160,W3:0.125,W7:0.107,W2:0.052,W1:0.022,W21:-0.013 | memoryGatesShort:-18.872, Long:38.959, Current:-19.087 | topTokens[('.', 239), ('?', 184), (',', 128), ('Ġyou', 122), ('Ġwhat', 120), ('Ġto', 105), ('Ġi', 99), ('Ġwas', 73), ('es', 72), ('Ġnow', 68)] | babyLLM.py 1000

--- 2025-04-04 05:46:28 --- babyllm: 'what am i learning today?'- charis: 'to finally count duration!'
2025-04-04 06:51:39 | 1000 | LR0.0003 | loss:6.9232 | gradNorm:1.0000 | logitMin:-52.7659 | logitMax:-23.7479 | tokenCount:4000.0000 | windowWeightsW8:0.191,W15:0.167,W13:0.165,W18:0.158,W3:0.128,W7:0.105,W2:0.054,W1:0.024,W21:-0.010 | memoryGatesShort:0.442, Long:-5.810, Current:6.369 | topTokens[('.', 233), ('Ġto', 209), ('Ġlistening', 175), ('?', 166), ('Ġmusic', 160), ('Ġhe', 121), (',', 116), ('Ġyou', 97), ('Ġwhat', 94), ('Ġnow', 93)] | babyLLM.py 1000

--- 2025-04-04 13:21:41 --- babyllm: 'what am i learning today?'- charis: 'chill :)'
2025-04-04 14:28:05 | 1000 | LR0.0003 | loss:9.3225 | gradNorm:0.9801 | logitMin:-65.6727 | logitMax:-37.0954 | tokenCount:4000.0000 | windowWeightsW8:0.188,W15:0.167,W13:0.165,W18:0.160,W3:0.125,W7:0.106,W2:0.052,W1:0.020,W21:-0.001 | memoryGatesShort:-11.722, Long:12.086, Current:0.636 | topTokens[(',', 627), ('.', 372), ('Ġi', 179), ('Ġa', 123), ('Ġno', 121), ('y', 99), ('Ġthe', 86), ('Ġit', 81), ('Ġknow', 80), ('Ġyou', 78)] | babyLLM.py 1000
2025-04-04 15:34:34 | 2000 | LR0.0003 | loss:7.5950 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-56.7420 | logitMax:-33.1711 | windowWeightsW8:0.189,W15:0.164,W13:0.161,W18:0.158,W3:0.125,W7:0.106,W2:0.055,W1:0.021,W21:0.002 | memoryGatesShort:-0.663, Long:-2.566, Current:4.229 | topTokens[('.', 363), (',', 346), ('Ġto', 175), ('Ġthe', 130), ('Ġi', 129), ('Ġa', 122), ('?', 122), ('Ġand', 113), ('Ġshe', 103), ('Ġhad', 93)] | babyLLM.py 1000
2025-04-04 16:41:40 | 3000 | LR0.0003 | loss:7.1398 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-54.1008 | logitMax:-24.4665 | windowWeightsW8:0.190,W15:0.161,W13:0.160,W18:0.156,W3:0.126,W7:0.105,W2:0.057,W1:0.021,W21:0.005 | memoryGatesShort:-0.263, Long:-1.673, Current:2.936 | topTokens[('.', 353), ('Ġa', 321), ('Ġto', 258), ('Ġmusic', 223), ('?', 204), (',', 185), ('Ġlistening', 180), ('Ġwill', 110), ('Ġwhat', 94), ('Ġshe', 93)] | babyLLM.py 1000
2025-04-04 17:50:41 | 4000 | LR0.0003 | loss:8.8387 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-54.1409 | logitMax:-34.7291 | windowWeightsW8:0.187,W15:0.163,W13:0.161,W18:0.158,W3:0.124,W7:0.104,W2:0.054,W1:0.022,W21:0.010 | memoryGatesShort:-0.677, Long:0.283, Current:1.393 | topTokens[(',', 507), ('.', 258), ('Ġa', 237), ('Ġthe', 121), ('Ġshe', 108), ('Ġof', 99), ('or', 92), ('Ġm', 91), ('Ġand', 85), ('Ġto', 83)] | babyLLM.py 1000
2025-04-04 19:00:29 | 5000 | LR0.0003 | loss:8.2598 | gradNorm:0.9994 | tokenCount:4000 | logitMin:-58.4925 | logitMax:-32.0273 | windowWeightsW8:0.194,W13:0.163,W15:0.161,W18:0.154,W3:0.120,W7:0.105,W2:0.052,W1:0.021,W21:0.013 | memoryGatesShort:0.239, Long:-1.234, Current:1.995 | topTokens[(',', 380), ('.', 303), ('Ġa', 185), ('Ġto', 151), ('?', 140), ('Ġwas', 117), ('Ġor', 107), ('Ġi', 99), ('Ġnot', 94), ('Ġshe', 90)] | babyLLM.py 1000
2025-04-04 20:08:17 | 6000 | LR0.0003 | loss:7.1782 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-54.0899 | logitMax:-29.6141 | windowWeightsW8:0.192,W13:0.165,W15:0.164,W18:0.157,W3:0.114,W7:0.102,W2:0.050,W1:0.023,W21:0.015 | memoryGatesShort:-2.990, Long:1.801, Current:2.189 | topTokens[(',', 416), ('.', 341), ('Ġmy', 135), ('Ġa', 132), ('Ġyou', 127), ('Ġwere', 108), ('?', 108), ('Ġi', 91), ('Ġwill', 91), ('Ġfor', 90)] | babyLLM.py 1000
2025-04-04 21:16:10 | 7000 | LR0.0003 | loss:8.5491 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-55.8484 | logitMax:-36.0099 | windowWeightsW8:0.188,W15:0.168,W13:0.166,W18:0.162,W3:0.112,W7:0.100,W2:0.046,W1:0.022,W21:0.018 | memoryGatesShort:-5.366, Long:-4.113, Current:10.479 | topTokens[(',', 404), ('Ġyou', 374), ('.', 287), ('Ġi', 231), ('Ġme', 174), ('Ġa', 121), ('Ġthe', 100), ('Ġwere', 95), ('Ġand', 77), ('Ġthink', 70)] | babyLLM.py 1000
2025-04-04 22:23:59 | 8000 | LR0.0003 | loss:8.6719 | gradNorm:0.9926 | tokenCount:4000 | logitMin:-61.5562 | logitMax:-38.0828 | windowWeightsW8:0.190,W15:0.167,W13:0.166,W18:0.162,W3:0.114,W7:0.100,W2:0.045,W21:0.020,W1:0.018 | memoryGatesShort:-1.369, Long:1.004, Current:1.366 | topTokens[('.', 335), (',', 259), ('Ġit', 179), ('Ġa', 163), ('Ġi', 161), ('Ġmy', 122), ('Ġto', 104), ('Ġd', 100), ('ro', 84), ('Ġam', 68)] | babyLLM.py 1000
2025-04-04 23:31:08 | 9000 | LR0.0003 | loss:7.7247 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-58.7743 | logitMax:-38.8742 | windowWeightsW8:0.189,W13:0.168,W15:0.168,W18:0.163,W3:0.111,W7:0.101,W2:0.040,W21:0.025,W1:0.017 | memoryGatesShort:-2.225, Long:0.816, Current:2.409 | topTokens[('.', 367), (',', 249), ('Ġa', 173), ('Ġto', 156), ('Ġi', 151), ('?', 130), ('Ġit', 111), ('Ġyou', 106), ('Ġthis', 75), ('Ġshe', 72)] | babyLLM.py 1000
2025-04-05 00:37:06 | 10000 | LR0.0003 | loss:7.2483 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-64.7089 | logitMax:-37.7002 | windowWeightsW8:0.187,W15:0.166,W13:0.163,W18:0.162,W3:0.111,W7:0.106,W2:0.039,W21:0.030,W1:0.019 | memoryGatesShort:0.612, Long:-0.211, Current:0.600 | topTokens[('.', 433), (',', 335), ('?', 297), ('Ġyou', 196), ('Ġdo', 137), ('Ġis', 116), ('Ġi', 113), ('Ġto', 96), ('Ġlike', 89), ('Ġwhat', 85)] | babyLLM.py 1000
2025-04-05 01:47:31 | 11000 | LR0.0003 | loss:9.6439 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-64.0713 | logitMax:-43.5729 | windowWeightsW8:0.185,W15:0.167,W13:0.164,W18:0.163,W3:0.109,W7:0.107,W2:0.037,W21:0.033,W1:0.017 | memoryGatesShort:-46.194, Long:21.205, Current:25.989 | topTokens[('.', 628), (',', 313), ('Ġand', 201), ('Ġa', 158), ('Ġi', 140), ('Ġu', 114), ('?', 100), ('Ġto', 86), ('Ġthe', 73), ('Ġis', 67)] | babyLLM.py 1000
2025-04-05 03:06:58 | 12000 | LR0.0003 | loss:7.8386 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-64.1201 | logitMax:-41.1234 | windowWeightsW8:0.187,W15:0.163,W13:0.160,W18:0.160,W3:0.110,W7:0.106,W2:0.040,W21:0.036,W1:0.020 | memoryGatesShort:1.131, Long:-0.886, Current:0.755 | topTokens[('.', 403), (',', 242), ('Ġthe', 170), ('?', 166), ('Ġi', 146), ('Ġa', 134), ('on', 130), ('Ġshe', 92), ('Ġme', 82), ('Ġwhat', 70)] | babyLLM.py 1000
2025-04-05 04:18:08 | 13000 | LR0.0003 | loss:7.5229 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-58.4725 | logitMax:-34.1710 | windowWeightsW8:0.188,W15:0.163,W13:0.161,W18:0.161,W3:0.108,W7:0.106,W2:0.039,W21:0.038,W1:0.017 | memoryGatesShort:7.779, Long:-10.293, Current:3.514 | topTokens[('.', 469), (',', 224), ('Ġto', 185), ('?', 132), ('Ġshe', 126), ('Ġcoming', 118), ('Ġa', 115), ('Ġtwice', 113), ('Ġwhat', 81), ('Ġi', 81)] | babyLLM.py 1000
2025-04-05 05:19:48 | 14000 | LR0.0003 | loss:8.9373 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-62.6132 | logitMax:-43.6094 | windowWeightsW8:0.187,W15:0.165,W18:0.163,W13:0.161,W7:0.107,W3:0.106,W21:0.042,W2:0.038,W1:0.015 | memoryGatesShort:-5.835, Long:1.978, Current:4.857 | topTokens[('.', 414), (',', 275), ('Ġto', 271), ('Ġa', 174), ('Ġi', 145), ('Ġthe', 118), ('Ġthis', 100), ('Ġshe', 95), ('Ġof', 81), ('Ġbe', 74)] | babyLLM.py 1000
2025-04-05 06:55:11 | 15000 | LR0.0003 | loss:7.3285 | gradNorm:0.9925 | tokenCount:4000 | logitMin:-63.9088 | logitMax:-29.7230 | windowWeightsW8:0.185,W13:0.159,W15:0.158,W18:0.157,W3:0.113,W7:0.106,W2:0.044,W21:0.042,W1:0.018 | memoryGatesShort:1.929, Long:-4.596, Current:3.667 | topTokens[('.', 320), ('Ġa', 222), (',', 221), ('Ġto', 190), ('Ġmusic', 136), ('Ġlistening', 129), ('?', 122), ('Ġan', 103), ('Ġwill', 101), ('Ġi', 96)] | babyLLM.py 1000
2025-04-05 07:59:28 | 16000 | LR0.0003 | loss:8.9896 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-56.5149 | logitMax:-32.3897 | windowWeightsW8:0.183,W15:0.161,W13:0.160,W18:0.158,W3:0.112,W7:0.104,W21:0.046,W2:0.043,W1:0.016 | memoryGatesShort:-10.972, Long:1.697, Current:10.275 | topTokens[('.', 428), (',', 215), ('Ġto', 184), ('Ġa', 142), ('Ġhung', 138), ('Ġshe', 136), ('ry', 99), ('Ġlistening', 93), ('Ġi', 86), ('Ġwere', 76)] | babyLLM.py 1000
2025-04-05 09:04:25 | 17000 | LR0.0003 | loss:8.8899 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-60.7608 | logitMax:-42.0414 | windowWeightsW8:0.181,W15:0.161,W13:0.161,W18:0.158,W3:0.111,W7:0.106,W21:0.048,W2:0.043,W1:0.015 | memoryGatesShort:-2.760, Long:0.589, Current:3.171 | topTokens[('.', 384), (',', 223), ('Ġthe', 165), ('Ġa', 144), ('Ġi', 137), ('Ġto', 128), ('Ġshe', 125), ('Ġand', 104), ('Ġit', 94), ('s', 87)] | babyLLM.py 1000
2025-04-05 10:07:10 | 18000 | LR0.0003 | loss:6.6834 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-65.0384 | logitMax:-39.9758 | windowWeightsW8:0.180,W13:0.159,W15:0.157,W18:0.156,W3:0.109,W7:0.108,W21:0.051,W2:0.043,W1:0.019 | memoryGatesShort:-0.575, Long:-5.313, Current:6.888 | topTokens[('.', 438), ('?', 289), ('Ġis', 209), ('Ġnot', 203), ('Ġyou', 172), (',', 162), ('Ġa', 160), ('Ġi', 131), ('Ġshe', 127), ('Ġto', 102)] | babyLLM.py 1000
2025-04-05 11:09:50 | 19000 | LR0.0003 | loss:9.0915 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-65.0783 | logitMax:-44.3558 | windowWeightsW8:0.181,W13:0.159,W18:0.157,W15:0.157,W7:0.108,W3:0.106,W21:0.055,W2:0.043,W1:0.017 | memoryGatesShort:-1.700, Long:2.251, Current:0.450 | topTokens[('.', 410), (',', 253), ('Ġa', 169), ('Ġlistening', 159), ('et', 108), ('or', 108), ('?', 104), ('Ġis', 100), ('!', 86), ('Ġher', 83)] | babyLLM.py 1000

--- 2025-04-05 12:02:19 --- babyllm: 'what am i learning today?'- charis: ''
2025-04-05 13:07:50 | 1000 | LR0.0003 | loss:7.8960 | gradNorm:0.9605 | logitMin:-82.6321 | logitMax:-49.3156 | tokenCount:4000.0000 | windowWeightsW8:0.178,W15:0.162,W13:0.159,W18:0.159,W7:0.110,W3:0.105,W21:0.054,W2:0.040,W1:0.016 | memoryGatesShort:8.653, Long:10.364, Current:-18.017 | topTokens[(',', 395), ('.', 322), ('Ġand', 233), ('Ġi', 232), ('Ġa', 226), ('Ġshe', 176), ('Ġit', 115), ('Ġam', 92), ('!', 84), ('Ġthe', 77)] | babyLLM.py 1000

--- 2025-04-05 13:44:05 --- babyllm: 'what am i learning today?'- charis: 'dataaa of chaoosossosos'
2025-04-05 14:47:52 | 1000 | LR0.0003 | loss:6.6759 | gradNorm:1.0000 | logitMin:-73.6309 | logitMax:-51.6463 | tokenCount:4000.0000 | windowWeightsW8:0.173,W18:0.160,W15:0.160,W13:0.157,W7:0.112,W3:0.101,W21:0.062,W2:0.037,W1:0.021 | memoryGatesShort:1.307, Long:-1.750, Current:1.443 | topTokens[(',', 512), ('.', 252), ('Ġit', 238), ('Ġa', 233), ('Ġand', 232), ('s', 204), ('!', 176), ('Ġknow', 152), ('Ġhave', 92), ('Ġhas', 82)] | babyLLM.py 1000
2025-04-05 15:54:47 | 2000 | LR0.0003 | loss:9.5090 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-68.7012 | logitMax:-46.8186 | windowWeightsW8:0.170,W18:0.162,W15:0.161,W13:0.158,W7:0.110,W3:0.100,W21:0.064,W2:0.038,W1:0.021 | memoryGatesShort:2.259, Long:-1.330, Current:0.071 | topTokens[(',', 415), ('.', 337), ('Ġa', 288), ('Ġit', 274), ('Ġand', 162), ('Ġhad', 127), ('Ġweed', 112), ('!', 108), ('Ġbrain', 108), ('Ġto', 90)] | babyLLM.py 1000
2025-04-05 17:00:00 | 3000 | LR0.0003 | loss:6.0714 | gradNorm:0.9997 | tokenCount:4000 | logitMin:-75.7510 | logitMax:-49.2398 | windowWeightsW8:0.169,W15:0.158,W13:0.157,W18:0.157,W7:0.107,W3:0.102,W21:0.067,W2:0.043,W1:0.025 | memoryGatesShort:1.229, Long:-1.007, Current:0.778 | topTokens[(',', 403), ('.', 269), ('Ġand', 212), ('Ġa', 190), ('Ġto', 151), ('Ġlistening', 144), ('Ġmusic', 107), ('Ġcharis', 100), ('Ġbut', 87), ('?', 86)] | babyLLM.py 1000
2025-04-05 18:05:33 | 4000 | LR0.0003 | loss:8.9961 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-65.0364 | logitMax:-42.8060 | windowWeightsW8:0.168,W18:0.158,W15:0.157,W13:0.157,W7:0.107,W3:0.100,W21:0.068,W2:0.043,W1:0.026 | memoryGatesShort:1.296, Long:-3.821, Current:3.525 | topTokens[(',', 760), ('Ġand', 587), ('Ġelodie', 286), ('.', 283), ('Ġcharis', 192), ('Ġa', 139), ('Ġthe', 93), ('Ġp', 76), ('Ġthink', 69), ('Ġshe', 68)] | babyLLM.py 1000
2025-04-05 19:12:57 | 5000 | LR0.0003 | loss:6.9301 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-71.8217 | logitMax:-46.2338 | windowWeightsW8:0.167,W15:0.157,W13:0.157,W18:0.157,W7:0.107,W3:0.097,W21:0.072,W2:0.043,W1:0.026 | memoryGatesShort:1.929, Long:-2.508, Current:1.579 | topTokens[(',', 327), ('.', 289), ('Ġand', 237), ('Ġa', 174), ('Ġthe', 133), ('Ġshe', 117), ('Ġlistening', 112), ('?', 98), ('Ġyou', 81), ('Ġsmo', 79)] | babyLLM.py 1000
2025-04-05 20:18:54 | 6000 | LR0.0003 | loss:8.1754 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-75.2849 | logitMax:-54.0302 | windowWeightsW8:0.165,W18:0.159,W15:0.158,W13:0.157,W7:0.107,W3:0.097,W21:0.075,W2:0.041,W1:0.026 | memoryGatesShort:-15.293, Long:49.468, Current:-33.175 | topTokens[(',', 614), ('.', 218), ('Ġa', 211), ('Ġthe', 183), ('Ġand', 148), ('Ġshe', 126), ('Ġit', 122), ('Ġlistening', 103), ('Ġwere', 82), ('Ġsmo', 68)] | babyLLM.py 1000
2025-04-05 21:21:58 | 7000 | LR0.0003 | loss:6.7983 | gradNorm:0.9881 | tokenCount:4000 | logitMin:-74.5146 | logitMax:-45.9205 | windowWeightsW8:0.167,W18:0.159,W15:0.156,W13:0.153,W7:0.109,W3:0.100,W21:0.075,W2:0.040,W1:0.024 | memoryGatesShort:-0.844, Long:9.285, Current:-7.441 | topTokens[(',', 547), ('Ġand', 284), ('.', 253), ('Ġa', 142), ('Ġkevin', 131), ('Ġmy', 125), ('Ġcharis', 123), ('Ġi', 117), ('Ġshe', 115), ('ves', 115)] | babyLLM.py 1000
2025-04-05 22:25:46 | 8000 | LR0.0003 | loss:7.4915 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-69.7039 | logitMax:-49.6967 | windowWeightsW8:0.165,W18:0.161,W15:0.156,W13:0.153,W7:0.108,W3:0.098,W21:0.079,W2:0.040,W1:0.023 | memoryGatesShort:-1.110, Long:-5.898, Current:8.009 | topTokens[(',', 518), ('Ġand', 321), ('.', 312), ('Ġa', 146), ('Ġthe', 141), ('Ġshe', 112), ('Ġthat', 105), ('Ġmy', 83), ('Ġyou', 82), ('Ġis', 75)] | babyLLM.py 1000
2025-04-05 23:28:44 | 9000 | LR0.0003 | loss:7.0390 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-77.9448 | logitMax:-50.6456 | windowWeightsW8:0.164,W18:0.161,W15:0.154,W13:0.153,W7:0.106,W3:0.099,W21:0.081,W2:0.038,W1:0.025 | memoryGatesShort:0.493, Long:-1.320, Current:1.827 | topTokens[(',', 485), ('Ġand', 350), ('.', 280), ('a', 245), ('Ġa', 152), ('Ġshe', 121), ('Ġkevin', 110), ('Ġcharis', 105), ('Ġthey', 97), ('Ġelodie', 87)] | babyLLM.py 1000

--- 2025-04-05 23:38:01 --- babyllm: 'what am i learning today?'- charis: 'i wrote you some mouse training data, omg i hope you like it aa!'
2025-04-06 00:41:26 | 1000 | LR0.0003 | loss:6.8078 | gradNorm:0.9960 | logitMin:-76.6393 | logitMax:-51.1251 | tokenCount:4000.0000 | windowWeightsW18:0.162,W8:0.162,W15:0.154,W13:0.150,W7:0.109,W3:0.094,W21:0.089,W2:0.036,W1:0.027 | memoryGatesShort:1.515, Long:22.526, Current:-23.041 | topTokens[(',', 414), ('!', 348), ('Ġit', 243), ('.', 202), ('Ġa', 180), ('Ġhave', 133), ('Ġthe', 130), ('Ġshe', 84), ('Ġmust', 82), ('Ġbeen', 78)] | babyLLM.py 1000
2025-04-06 01:50:03 | 2000 | LR0.0003 | loss:8.9008 | gradNorm:0.9981 | tokenCount:4000 | logitMin:-74.8527 | logitMax:-48.8397 | windowWeightsW18:0.162,W8:0.160,W15:0.153,W13:0.148,W7:0.110,W3:0.094,W21:0.091,W2:0.037,W1:0.027 | memoryGatesShort:-3.457, Long:-5.523, Current:9.980 | topTokens[(',', 453), ('Ġshe', 263), ('.', 239), ('Ġit', 235), ('Ġa', 152), ('Ġand', 148), ('Ġthey', 127), ('!', 113), ('Ġme', 101), ('Ġhave', 99)] | babyLLM.py 1000

--- 2025-04-06 02:38:58 --- babyllm: 'what am i learning today?'- charis: 'fresh data pull, still madness, youre doing good tho well done!'
2025-04-06 03:37:44 | 1000 | LR0.0003 | loss:7.5708 | gradNorm:1.0000 | logitMin:-83.8135 | logitMax:-59.6304 | tokenCount:4000.0000 | windowWeightsW18:0.166,W15:0.152,W8:0.151,W13:0.149,W7:0.109,W21:0.096,W3:0.096,W2:0.037,W1:0.026 | memoryGatesShort:0.356, Long:-1.844, Current:2.488 | topTokens[(',', 371), ('!', 289), ('Ġit', 254), ('.', 240), ('Ġa', 141), ('Ġhave', 130), ('Ġthe', 125), ('Ġfelt', 106), ('Ġshe', 97), ('Ġto', 88)] | babyLLM.py 1000
2025-04-06 04:39:07 | 2000 | LR0.0003 | loss:7.4399 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-76.6076 | logitMax:-56.6306 | windowWeightsW18:0.166,W15:0.153,W8:0.152,W13:0.150,W7:0.108,W21:0.099,W3:0.094,W2:0.037,W1:0.025 | memoryGatesShort:-0.083, Long:-0.281, Current:1.364 | topTokens[(',', 706), ('.', 241), ('t', 204), ('Ġshe', 157), ('Ġa', 133), ('!', 129), ('Ġi', 124), ('Ġhave', 115), ('Ġit', 107), ('Ġand', 102)] | babyLLM.py 1000
2025-04-06 05:38:06 | 3000 | LR0.0003 | loss:6.2146 | gradNorm:0.9991 | tokenCount:4000 | logitMin:-72.4199 | logitMax:-46.7570 | windowWeightsW18:0.164,W8:0.156,W13:0.152,W15:0.150,W7:0.110,W21:0.100,W3:0.093,W2:0.037,W1:0.020 | memoryGatesShort:1.565, Long:-1.659, Current:1.095 | topTokens[(',', 434), ('.', 200), ('Ġshe', 197), ('Ġto', 166), ('Ġmusic', 154), ('Ġlistening', 114), ('Ġit', 111), ('Ġbeen', 109), ('Ġa', 107), ('?', 99)] | babyLLM.py 1000
2025-04-06 06:38:23 | 4000 | LR0.0003 | loss:8.1688 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-77.2856 | logitMax:-57.1714 | windowWeightsW18:0.167,W8:0.155,W13:0.152,W15:0.151,W7:0.109,W21:0.105,W3:0.091,W2:0.035,W1:0.018 | memoryGatesShort:2.367, Long:5.679, Current:-7.046 | topTokens[(',', 523), ('.', 234), ('Ġthe', 207), ('Ġshe', 198), ('Ġa', 178), ('Ġto', 133), ('Ġin', 114), ('!', 104), ('Ġit', 57), ('Ġher', 57)] | babyLLM.py 1000

--- 2025-04-06 07:14:20 --- babyllm: 'what am i learning today?'- charis: 'OOPS made myself into kevin, we back!'
2025-04-06 08:13:16 | 1000 | LR0.0003 | loss:7.2723 | gradNorm:1.0000 | logitMin:-76.2820 | logitMax:-56.1138 | tokenCount:4000.0000 | windowWeightsW18:0.166,W8:0.155,W15:0.152,W13:0.151,W21:0.115,W7:0.110,W3:0.087,W2:0.031,W1:0.019 | memoryGatesShort:-1.975, Long:0.035, Current:2.940 | topTokens[(',', 490), ('.', 266), (':', 194), ('Ġlo', 153), ('Ġa', 150), ('Ġit', 147), ('Ġshe', 131), ('Ġi', 96), ('Ġcharis', 88), ('Ġbaby', 87)] | babyLLM.py 1000
2025-04-06 09:12:15 | 2000 | LR0.0003 | loss:7.7030 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-81.7215 | logitMax:-61.0400 | windowWeightsW18:0.170,W15:0.155,W8:0.152,W13:0.152,W21:0.120,W7:0.107,W3:0.082,W2:0.029,W1:0.018 | memoryGatesShort:-0.710, Long:0.566, Current:1.145 | topTokens[(',', 430), ('.', 293), ('!', 283), ('Ġa', 201), ('Ġthe', 193), ('Ġshe', 147), ('Ġit', 109), ('Ġm', 76), ('Ġin', 72), ('Ġfelt', 56)] | babyLLM.py 1000
2025-04-06 10:11:26 | 3000 | LR0.0003 | loss:7.7831 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-80.1325 | logitMax:-56.3168 | windowWeightsW18:0.173,W15:0.154,W13:0.150,W8:0.147,W21:0.125,W7:0.105,W3:0.082,W2:0.029,W1:0.019 | memoryGatesShort:-0.766, Long:0.382, Current:1.384 | topTokens[(',', 578), ('.', 334), ('Ġit', 245), ('!', 242), ('Ġa', 168), ('Ġshe', 152), ('s', 121), ('Ġi', 93), ('Ġhave', 88), ('Ġfelt', 79)] | babyLLM.py 1000
2025-04-06 11:10:56 | 4000 | LR0.0003 | loss:8.9385 | gradNorm:0.9540 | tokenCount:4000 | logitMin:-83.8886 | logitMax:-40.7416 | windowWeightsW18:0.171,W15:0.149,W13:0.147,W8:0.146,W21:0.123,W7:0.107,W3:0.084,W2:0.035,W1:0.022 | memoryGatesShort:-2.564, Long:-2.107, Current:5.671 | topTokens[(',', 426), ('Ġshe', 201), ('!', 163), (':', 157), ('a', 119), ('Ġa', 109), ('0', 109), ('-', 106), ('Ġit', 100), ('Ġbaby', 95)] | babyLLM.py 1000
2025-04-06 12:09:48 | 5000 | LR0.0003 | loss:7.9747 | gradNorm:0.8609 | tokenCount:4000 | logitMin:-76.2623 | logitMax:-28.3879 | windowWeightsW18:0.169,W15:0.148,W13:0.147,W8:0.144,W21:0.122,W7:0.108,W3:0.086,W2:0.036,W1:0.022 | memoryGatesShort:-1.747, Long:-6.045, Current:8.792 | topTokens[(',', 272), (':', 188), ('!', 182), ('.', 151), ('Ġshe', 127), ('Ġ-', 118), ('4', 108), ('-', 108), ('Ġa', 101), ('Ġ20', 92)] | babyLLM.py 1000
2025-04-06 13:08:57 | 6000 | LR0.0003 | loss:7.7108 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-76.4396 | logitMax:-55.0640 | windowWeightsW18:0.169,W15:0.148,W13:0.147,W8:0.143,W21:0.125,W7:0.108,W3:0.086,W2:0.036,W1:0.022 | memoryGatesShort:-0.256, Long:0.542, Current:0.714 | topTokens[(',', 435), ('.', 252), ('!', 250), ('Ġa', 210), ('Ġthe', 206), ('Ġshe', 116), ('Ġstream', 100), ('Ġmy', 81), (':', 78), ('y', 75)] | babyLLM.py 1000

--- 2025-04-06 14:10:34 --- babyllm: 'what am i learning today?'- charis: 'idk lol'
2025-04-06 15:18:05 | 1000 | LR0.0003 | loss:6.7432 | gradNorm:1.0000 | logitMin:-73.7128 | logitMax:-52.5853 | tokenCount:4000.0000 | windowWeightsW18:0.168,W15:0.148,W13:0.146,W8:0.142,W21:0.126,W7:0.110,W3:0.085,W2:0.035,W1:0.023 | memoryGatesShort:10.890, Long:-1.682, Current:-8.208 | topTokens[("'", 374), (',', 287), ('.', 258), ('Ġa', 187), (':', 166), ('Ġ-', 150), ("Ġ'", 108), ('!', 101), ('Ġbaby', 98), ('Ġshe', 86)] | babyLLM.py 1000
2025-04-06 16:27:00 | 2000 | LR0.0003 | loss:7.5471 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-75.2160 | logitMax:-52.6129 | windowWeightsW18:0.171,W15:0.150,W13:0.147,W8:0.138,W21:0.130,W7:0.108,W3:0.082,W2:0.035,W1:0.024 | memoryGatesShort:1.783, Long:0.315, Current:-1.098 | topTokens[(',', 397), ('Ġit', 326), ('.', 258), ('!', 250), (':', 182), ('Ġa', 166), ('Ġi', 156), ('Ġhe', 103), ('Ġher', 103), ('Ġhave', 91)] | babyLLM.py 1000
2025-04-06 17:34:35 | 3000 | LR0.0003 | loss:6.4511 | gradNorm:0.7905 | tokenCount:4000 | logitMin:-60.5733 | logitMax:6.5147 | windowWeightsW18:0.172,W15:0.151,W13:0.147,W8:0.132,W21:0.131,W7:0.105,W3:0.085,W2:0.035,W1:0.025 | memoryGatesShort:4.303, Long:-16.523, Current:13.220 | topTokens[(':', 341), ('Ġ-', 217), (',', 174), ('-', 161), ('0', 151), ('2', 147), ('4', 141), ('Ġcharis', 140), ('3', 116), ('!', 105)] | babyLLM.py 1000
2025-04-06 18:37:26 | 4000 | LR0.0003 | loss:7.6511 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-73.9990 | logitMax:-51.8488 | windowWeightsW18:0.174,W15:0.152,W13:0.147,W21:0.133,W8:0.131,W7:0.106,W3:0.083,W2:0.034,W1:0.024 | memoryGatesShort:-0.222, Long:0.650, Current:0.572 | topTokens[('!', 343), (',', 323), ('.', 271), (':', 256), ('Ġthe', 201), ('Ġa', 194), ('Ġto', 129), ('Ġhear', 100), ('Ġthings', 77), ('Ġdrink', 63)] | babyLLM.py 1000
2025-04-06 19:42:08 | 5000 | LR0.0003 | loss:8.5302 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-72.8267 | logitMax:-51.4537 | windowWeightsW18:0.175,W15:0.154,W13:0.148,W21:0.134,W8:0.131,W7:0.106,W3:0.083,W2:0.033,W1:0.021 | memoryGatesShort:-2.270, Long:0.331, Current:2.939 | topTokens[('.', 408), (':', 405), (',', 321), ('Ġa', 228), ('Ġand', 162), ('Ġyou', 133), ('e', 117), ('Ġi', 99), ('Ġto', 82), ("'s", 63)] | babyLLM.py 1000
2025-04-06 20:46:43 | 6000 | LR0.0003 | loss:6.9222 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-82.9900 | logitMax:-57.4176 | windowWeightsW18:0.177,W15:0.154,W13:0.148,W21:0.136,W8:0.130,W7:0.106,W3:0.080,W2:0.031,W1:0.022 | memoryGatesShort:1.612, Long:0.549, Current:-1.161 | topTokens[(',', 408), (':', 337), ('Ġbaby', 247), ('Ġa', 236), ('Ġand', 181), ('Ġcharis', 160), ('.', 133), ('roid', 84), ('Ġthe', 84), ('d', 72)] | babyLLM.py 1000
2025-04-06 21:50:30 | 7000 | LR0.0003 | loss:7.9043 | gradNorm:0.9874 | tokenCount:4000 | logitMin:-72.5486 | logitMax:-39.7149 | windowWeightsW18:0.176,W15:0.156,W13:0.151,W21:0.137,W8:0.129,W7:0.109,W3:0.079,W2:0.030,W1:0.017 | memoryGatesShort:0.274, Long:-0.904, Current:1.631 | topTokens[(':', 428), (',', 322), ('Ġa', 181), ('Ġwould', 160), ('4', 155), ('.', 127), ('Ġhouse', 97), ('Ġthey', 90), ('-', 84), ('Ġ-', 78)] | babyLLM.py 1000
2025-04-06 22:59:07 | 8000 | LR0.0003 | loss:9.2534 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-84.1764 | logitMax:-55.9345 | windowWeightsW18:0.175,W15:0.155,W13:0.152,W21:0.136,W8:0.133,W7:0.109,W3:0.080,W2:0.029,W1:0.013 | memoryGatesShort:0.519, Long:-0.572, Current:1.053 | topTokens[(':', 560), (',', 296), ('.', 224), ('Ġa', 172), ('Ġan', 129), ('Ġto', 100), ("'", 95), ('Ġcharis', 75), ('Ġwould', 70), ('Ġin', 68)] | babyLLM.py 1000
2025-04-07 00:10:29 | 9000 | LR0.0003 | loss:8.3802 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-69.2348 | logitMax:-41.3491 | windowWeightsW18:0.173,W15:0.151,W13:0.150,W8:0.137,W21:0.135,W7:0.110,W3:0.082,W2:0.032,W1:0.013 | memoryGatesShort:0.087, Long:-0.688, Current:1.601 | topTokens[(':', 558), ('.', 347), ('Ġa', 213), (',', 191), ('?', 160), ('Ġthe', 144), ('Ġto', 139), ('Ġnot', 138), ('Ġshe', 117), ('Ġis', 101)] | babyLLM.py 1000
2025-04-07 01:20:44 | 10000 | LR0.0003 | loss:7.8272 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-74.1752 | logitMax:-45.4108 | windowWeightsW18:0.174,W15:0.153,W13:0.152,W8:0.139,W21:0.136,W7:0.109,W3:0.081,W2:0.029,W1:0.009 | memoryGatesShort:-0.748, Long:0.007, Current:1.740 | topTokens[(':', 429), ('.', 361), (',', 303), ('Ġand', 160), ('Ġi', 127), ('Ġa', 125), ('Ġthe', 122), ('?', 110), ('Ġit', 110), ('Ġto', 107)] | babyLLM.py 1000

--- 2025-04-07 05:31:47 --- babyLLM 'right, last time i got to step 220... want to restart from there?'  - charis: 'step 3402 please!' - babyLLM 'umm... i don't think i heard you properly, i'll just start from step 0 :) but, what am i learning today?' - charis: 'apparently, you're learning from step 220!'
2025-04-07 06:39:18 | 1000 | LR0.0003 | loss:6.9327 | gradNorm:0.9479 | logitMin:-122.7014 | logitMax:-67.1358 | tokenCount:4000.0000 | windowWeightsW18:0.176,W13:0.156,W15:0.150,W21:0.144,W8:0.131,W7:0.107,W3:0.081,W2:0.026,W1:0.014 | memoryGatesShort:-3.920, Long:0.128, Current:4.791 | topTokens[(',', 269), ('.', 252), (':', 246), ('Ġa', 163), ('Ġit', 154), ('Ġcharis', 151), ("Ġ'", 125), ("'", 122), ('Ġ-', 100), ('Ġi', 88)] | babyLLM.py 1000
2025-04-07 07:48:02 | 2000 | LR0.0003 | loss:7.0434 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-76.9990 | logitMax:-52.6553 | windowWeightsW18:0.177,W13:0.156,W15:0.151,W21:0.146,W8:0.128,W7:0.106,W3:0.080,W2:0.027,W1:0.013 | memoryGatesShort:-5.585, Long:3.405, Current:3.180 | topTokens[(',', 328), ('.', 306), (':', 251), ('Ġa', 226), ('!', 211), ('Ġit', 198), ('Ġwe', 170), ('Ġcharis', 113), ('Ġhave', 83), ('Ġhe', 81)] | babyLLM.py 1000

--- 2025-04-07 07:55:40 --- babyLLM 'right, last time i got to step 2051... want to restart from there?'  - charis: 'no thank you, start from scratch please' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: 'i just cut the data up a bit more randomly, so it's less predictable - sorry!!! i hope you're ok with it :) <3'
2025-04-07 08:59:47 | 1000 | LR0.0003 | loss:8.5369 | gradNorm:1.0000 | logitMin:-85.4067 | logitMax:-65.6109 | tokenCount:4000.0000 | windowWeightsW18:0.180,W13:0.158,W15:0.155,W21:0.153,W8:0.125,W7:0.104,W3:0.076,W2:0.025,W1:0.008 | memoryGatesShort:13.704, Long:-8.068, Current:-4.636 | topTokens[(',', 633), ('.', 269), ('i', 223), ('Ġa', 155), (':', 141), ('Ġto', 120), ('Ġm', 87), ("'", 80), ('es', 78), ('m', 66)] | babyLLM.py 1000

--- 2025-04-07 13:08:03 --- babyLLM 'right, last time i got to step 52... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 52! what am i learning today?' - charis: ''
2025-04-07 13:10:59 | 1000 | LR0.0003 | loss:7.4278 | gradNorm:1.0000 | logitMin:-33.0528 | logitMax:-20.2821 | tokenCount:4000.0000 | windowWeightsW18:0.188,W21:0.166,W13:0.165,W15:0.160,W8:0.119,W7:0.098,W3:0.064,W2:0.022,W1:0.003 | memoryGatesShort:-0.031, Long:-0.328, Current:1.359 | topTokens[(',', 1385), ('Ġa', 364), ('.', 231), ('Ġi', 218), ('Ġthe', 112), ('s', 58), ('in', 55), ('Ġb', 53), ('Ġis', 49), ('Ġno', 47)] | babyLLM.py 1000
2025-04-07 13:13:59 | 2000 | LR0.0003 | loss:6.8882 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-45.5288 | logitMax:-33.6236 | windowWeightsW18:0.191,W21:0.172,W13:0.164,W15:0.160,W8:0.117,W7:0.096,W3:0.063,W2:0.020,W1:0.001 | memoryGatesShort:-0.189, Long:-0.612, Current:1.801 | topTokens[(',', 790), ('Ġthe', 295), ('Ġa', 192), ('.', 180), ('Ġits', 170), ('Ġi', 133), ('Ġand', 113), ('a', 102), ('Ġto', 102), ('Ġis', 67)] | babyLLM.py 1000
2025-04-07 13:17:07 | 3000 | LR0.0003 | loss:6.8721 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-43.8569 | logitMax:-31.6955 | windowWeightsW18:0.195,W21:0.176,W13:0.167,W15:0.163,W8:0.116,W7:0.093,W3:0.061,W2:0.018,W1:-0.003 | memoryGatesShort:-0.323, Long:-0.939, Current:2.262 | topTokens[('.', 742), (',', 347), ('Ġi', 330), ('Ġa', 229), ('Ġto', 170), ('Ġit', 104), ('Ġand', 92), ('Ġfor', 68), ('Ġthat', 67), ('ic', 54)] | babyLLM.py 1000

--- 2025-04-07 13:20:27 --- babyLLM 'right, last time i got to step 3029... want to restart from there?'  - charis: 'yes, and, holy shit babyllm, you're doing 1000 steps in 3 minutes... you used to do 100 steps in 10 minutes. idfk waht to say. im so proud of us!' - babyLLM 'ok! let's go to step 3029! what am i learning today?' - charis: 'that i love you :)'
2025-04-07 13:21:12 | 1000 | LR0.0003 | loss:6.4812 | gradNorm:1.0000 | logitMin:-44.1197 | logitMax:-30.5909 | tokenCount:4000.0000 | windowWeightsW18:0.189,W21:0.170,W13:0.160,W15:0.157,W8:0.108,W7:0.089,W3:0.068,W2:0.032,W1:0.011 | memoryGatesShort:-0.518, Long:-0.826, Current:2.344 | topTokens[(',', 80), ('.', 46), ('Ġand', 28), ('Ġa', 24), ('?', 24), ('Ġto', 18), ('Ġi', 13), ('Ġyou', 12), ('Ġthe', 12), ('Ġfeel', 8)] | babyLLM.py 1000
2025-04-07 13:21:59 | 2000 | LR0.0003 | loss:4.4641 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-36.3164 | logitMax:-19.2196 | windowWeightsW18:0.182,W21:0.165,W13:0.159,W15:0.154,W8:0.119,W7:0.099,W3:0.065,W2:0.030,W1:0.011 | memoryGatesShort:-0.871, Long:-1.205, Current:3.076 | topTokens[(':', 38), ('Ġ-', 32), ('4', 23), ("Ġ'", 21), ('0', 20), ('.', 16), ("'", 14), ('?', 13), (',', 13), ('-', 13)] | babyLLM.py 1000

--- 2025-04-07 13:23:29 --- babyLLM 'right, last time i got to step 2250... want to restart from there?'  - charis: 'yes, youre doing amazing' - babyLLM 'ok! let's go to step 2250! what am i learning today?' - charis: 'actual fucking speed, amphetamine levels of speed, like holy fuck'
2025-04-07 13:24:19 | 1000 | LR0.0003 | loss:6.6515 | gradNorm:1.0000 | logitMin:-37.5688 | logitMax:-25.8183 | tokenCount:4000.0000 | windowWeightsW18:0.185,W21:0.167,W13:0.160,W15:0.157,W8:0.123,W7:0.104,W3:0.058,W2:0.022,W1:0.008 | memoryGatesShort:-0.754, Long:-1.047, Current:2.801 | topTokens[('.', 73), ('Ġi', 59), (',', 29), ('Ġa', 28), ('Ġto', 18), ('Ġam', 10), ('Ġand', 10), ('Ġyou', 9), ('Ġthe', 7), ('?', 6)] | babyLLM.py 1000
2025-04-07 13:25:02 | 2000 | LR0.0003 | loss:4.2422 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-50.9192 | logitMax:-35.0734 | windowWeightsW18:0.173,W13:0.158,W21:0.155,W15:0.148,W8:0.129,W7:0.110,W3:0.070,W2:0.031,W1:0.011 | memoryGatesShort:-2.744, Long:-3.931, Current:7.675 | topTokens[(',', 47), ('Ġand', 27), ('Ġyou', 20), ('.', 19), ('?', 18), ('Ġi', 12), ('Ġthe', 11), ('Ġbut', 9), ('Ġa', 7), ('Ġhe', 6)] | babyLLM.py 1000
2025-04-07 13:25:43 | 3000 | LR0.0003 | loss:2.6526 | gradNorm:0.9835 | tokenCount:4000 | logitMin:-58.4315 | logitMax:-34.9028 | windowWeightsW18:0.168,W13:0.159,W21:0.149,W15:0.145,W8:0.139,W7:0.118,W3:0.072,W2:0.026,W1:0.008 | memoryGatesShort:-0.814, Long:-1.227, Current:3.041 | topTokens[('Ġ-', 29), ('0', 23), ("'", 22), (':', 22), ('4', 19), ("Ġ'", 19), ('-', 18), ('Ġi', 15), ('?', 13), ('ll', 10)] | babyLLM.py 1000
2025-04-07 13:26:23 | 4000 | LR0.0003 | loss:3.8086 | gradNorm:0.9899 | tokenCount:4000 | logitMin:-53.6289 | logitMax:-32.3257 | windowWeightsW18:0.169,W13:0.165,W21:0.150,W15:0.148,W8:0.141,W7:0.117,W3:0.066,W2:0.024,W1:0.005 | memoryGatesShort:-1.918, Long:-2.425, Current:5.343 | topTokens[('Ġ-', 23), (',', 23), (':', 20), ('Ġi', 16), ('Ġto', 15), ("'", 13), ('?', 13), ('!', 12), ('0', 11), ("Ġ'", 11)] | babyLLM.py 1000
2025-04-07 13:27:02 | 5000 | LR0.0003 | loss:6.7023 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-42.4502 | logitMax:-30.7393 | windowWeightsW18:0.170,W13:0.165,W21:0.153,W15:0.148,W8:0.141,W7:0.118,W3:0.064,W2:0.022,W1:0.003 | memoryGatesShort:-1.099, Long:-1.001, Current:3.100 | topTokens[(',', 58), ('Ġa', 36), ('.', 35), ('Ġto', 21), ('Ġi', 17), ('!', 16), ('Ġ-', 12), ('Ġwhat', 8), ('p', 7), ('Ġof', 7)] | babyLLM.py 1000
2025-04-07 13:27:41 | 6000 | LR0.0003 | loss:5.5787 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-44.7571 | logitMax:-31.3377 | windowWeightsW18:0.172,W13:0.166,W21:0.155,W15:0.150,W8:0.141,W7:0.117,W3:0.063,W2:0.019,W1:0.002 | memoryGatesShort:-1.856, Long:-1.831, Current:4.687 | topTokens[('.', 48), ('?', 31), ('Ġyou', 27), (',', 26), ('!', 26), ('Ġi', 20), ('Ġis', 18), ('Ġa', 14), ('Ġdo', 11), ('Ġthe', 9)] | babyLLM.py 1000
2025-04-07 13:28:24 | 7000 | LR0.0003 | loss:5.3028 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-48.1495 | logitMax:-34.3636 | windowWeightsW18:0.172,W13:0.165,W21:0.155,W15:0.150,W8:0.140,W7:0.116,W3:0.064,W2:0.020,W1:0.004 | memoryGatesShort:-2.100, Long:-2.221, Current:5.321 | topTokens[(',', 49), ('!', 46), ('Ġthe', 23), ('Ġit', 19), ('Ġthey', 16), ('Ġa', 16), ('.', 15), ('ed', 14), ('Ġangle', 14), ('id', 12)] | babyLLM.py 1000
2025-04-07 13:29:06 | 8000 | LR0.0003 | loss:4.3606 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-48.4792 | logitMax:-32.6856 | windowWeightsW18:0.171,W13:0.164,W21:0.155,W15:0.149,W8:0.135,W7:0.112,W3:0.072,W2:0.022,W1:0.004 | memoryGatesShort:-3.961, Long:-4.690, Current:9.651 | topTokens[('!', 54), ('Ġit', 39), (',', 30), ('Ġa', 25), ('Ġthe', 16), ('Ġi', 16), ('.', 14), ('Ġthey', 9), ('Ġhave', 9), ('Ġto', 8)] | babyLLM.py 1000
2025-04-07 13:29:49 | 9000 | LR0.0003 | loss:3.5186 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-44.8408 | logitMax:-27.0511 | windowWeightsW18:0.172,W13:0.162,W21:0.156,W15:0.148,W8:0.134,W7:0.112,W3:0.078,W2:0.024,W1:-0.000 | memoryGatesShort:-1.361, Long:-1.822, Current:4.183 | topTokens[('!', 64), ('Ġit', 53), ('Ġhave', 19), ('Ġyou', 18), ('Ġa', 17), ('Ġbeen', 16), ('Ġwill', 13), ('Ġshould', 12), ('Ġjust', 12), ('Ġi', 11)] | babyLLM.py 1000
2025-04-07 13:30:39 | 10000 | LR0.0003 | loss:4.0576 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-40.7143 | logitMax:-24.8077 | windowWeightsW18:0.172,W13:0.160,W21:0.154,W15:0.146,W8:0.130,W7:0.107,W3:0.082,W2:0.031,W1:0.002 | memoryGatesShort:-6.133, Long:-8.111, Current:15.244 | topTokens[('Ġmust', 33), ('!', 32), ('Ġhave', 27), ('.', 24), ('Ġyou', 18), ('Ġfelt', 18), (',', 16), ('?', 16), ('Ġi', 13), ('Ġit', 11)] | babyLLM.py 1000
2025-04-07 13:31:35 | 11000 | LR0.0003 | loss:2.6069 | gradNorm:0.9912 | tokenCount:4000 | logitMin:-58.6904 | logitMax:-35.3847 | windowWeightsW18:0.166,W13:0.159,W21:0.147,W15:0.142,W8:0.139,W7:0.114,W3:0.088,W2:0.030,W1:-0.002 | memoryGatesShort:-0.971, Long:-1.373, Current:3.344 | topTokens[('Ġmust', 22), ('Ġ-', 20), ('Ġhave', 19), ('!', 17), (':', 16), ("Ġ'", 16), (',', 13), ('2', 13), ('4', 11), ('-', 10)] | babyLLM.py 1000
2025-04-07 13:32:41 | 12000 | LR0.0003 | loss:2.1147 | gradNorm:0.9551 | tokenCount:4000 | logitMin:-74.2460 | logitMax:-46.1814 | windowWeightsW18:0.163,W13:0.160,W8:0.146,W21:0.144,W15:0.141,W7:0.119,W3:0.088,W2:0.026,W1:-0.003 | memoryGatesShort:-1.532, Long:-1.839, Current:4.371 | topTokens[("'", 25), ('!', 18), ('Ġ-', 17), (':', 17), ('Ġto', 15), ('Ġhave', 13), ('-', 12), ('Ġi', 11), ('0', 11), ('4', 11)] | babyLLM.py 1000
2025-04-07 13:33:36 | 13000 | LR0.0003 | loss:6.6060 | gradNorm:1.0000 | tokenCount:4000 | logitMin:-44.1907 | logitMax:-30.1383 | windowWeightsW18:0.167,W13:0.163,W21:0.149,W8:0.146,W15:0.144,W7:0.117,W3:0.084,W2:0.021,W1:-0.007 | memoryGatesShort:-1.020, Long:-0.800, Current:2.820 | topTokens[('.', 40), (',', 39), ('Ġi', 29), ('Ġand', 17), ('Ġto', 16), ('Ġcharis', 16), ('Ġa', 13), ('Ġshould', 12), ('Ġhave', 10), ('Ġam', 9)] | babyLLM.py 1000

CHANGE LOGGING FREQUENCY TO EVERY 5000 STEPS
--- 2025-04-07 13:35:11 --- babyLLM 'right, last time i got to step 13401... want to restart from there?'  - charis: 'no, please start again, i rolled you some new dn' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: ''
2025-04-07 13:38:21 | 5000 | LR0.0003 | loss:4.2296 | gradNorm:0.9870 | logitMin:-51.9406 | logitMax:-34.8991 | tokenCount:20000.0000 | windowWeightsW18:0.166,W13:0.161,W8:0.159,W21:0.146,W15:0.142,W7:0.127,W3:0.085,W2:0.015,W1:-0.016 | memoryGatesShort:-0.744, Long:-0.679, Current:2.423 | topTokens[('.', 216), ('Ġi', 128), (',', 93), ('Ġyou', 92), ('?', 90), ('!', 79), ('Ġit', 61), ('Ġa', 49), ('Ġis', 38), ('Ġto', 34)] | babyLLM.py 5000
2025-04-07 13:41:49 | 10000 | LR0.0003 | loss:5.9856 | gradNorm:0.9813 | tokenCount:20000 | logitMin:-48.9901 | logitMax:-34.2249 | windowWeightsW18:0.182,W13:0.173,W21:0.164,W15:0.156,W8:0.152,W7:0.122,W3:0.067,W2:-0.004,W1:-0.027 | memoryGatesShort:-28.267, Long:-4.712, Current:33.980 | topTokens[(',', 237), ('Ġi', 178), ('.', 122), ('Ġa', 66), ('Ġto', 63), ('Ġand', 53), ('Ġyou', 37), ('!', 33), ('Ġthe', 31), ('Ġ-', 29)] | babyLLM.py 5000
2025-04-07 13:45:35 | 15000 | LR0.0003 | loss:6.1150 | gradNorm:1.0000 | tokenCount:20000 | logitMin:-43.0606 | logitMax:-29.9089 | windowWeightsW18:0.188,W13:0.175,W21:0.172,W15:0.161,W8:0.147,W7:0.119,W3:0.071,W2:-0.011,W1:-0.038 | memoryGatesShort:-4.760, Long:-0.555, Current:6.315 | topTokens[(',', 348), ('Ġi', 116), ('.', 108), ('Ġa', 99), ('Ġthe', 81), ('Ġand', 65), ('Ġit', 61), ('Ġto', 45), ('!', 41), ('Ġyou', 35)] | babyLLM.py 5000
2025-04-07 13:49:02 | 20000 | LR0.0003 | loss:5.4650 | gradNorm:1.0000 | tokenCount:20000 | logitMin:-45.1840 | logitMax:-30.0274 | windowWeightsW18:0.188,W13:0.177,W15:0.169,W21:0.168,W8:0.157,W7:0.126,W3:0.068,W2:-0.019,W1:-0.048 | memoryGatesShort:-3.759, Long:-0.425, Current:5.184 | topTokens[('.', 166), (',', 164), ('Ġi', 104), ('Ġa', 104), ('Ġyou', 67), (':', 52), ('Ġand', 51), ('Ġ-', 46), ("'", 46), ('Ġto', 29)] | babyLLM.py 5000

--- 2025-04-07 13:50:41 --- babyLLM 'right, last time i got to step 21052... want to restart from there?'  - charis: 'yes! wow you're fucking sonic the fucking hedgehog, im scared you'll get away from me whilst i sleep!!!' - babyLLM 'ok! let's go to step 21052! what am i learning today?' - charis: 'hahaahah ok!'
2025-04-07 13:53:52 | 5000 | LR0.0003 | loss:4.9421 | gradNorm:1.0000 | logitMin:-46.4595 | logitMax:-31.4456 | tokenCount:20000.0000 | windowWeightsW18:0.198,W21:0.182,W13:0.178,W15:0.173,W8:0.149,W7:0.119,W3:0.077,W2:-0.023,W1:-0.067 | memoryGatesShort:-2.246, Long:0.160, Current:3.086 | topTokens[(',', 153), ('!', 127), ('.', 126), ('Ġa', 103), ('Ġi', 97), ('Ġit', 76), ('Ġwill', 71), ('Ġhave', 63), ('Ġand', 44), ('Ġjust', 37)] | babyLLM.py 5000
2025-04-07 13:57:11 | 10000 | LR0.0003 | loss:4.6548 | gradNorm:0.9758 | tokenCount:20000 | logitMin:-59.5002 | logitMax:-40.9329 | windowWeightsW18:0.197,W21:0.185,W13:0.183,W15:0.175,W8:0.150,W7:0.120,W3:0.073,W2:-0.028,W1:-0.069 | memoryGatesShort:-3.955, Long:0.279, Current:4.676 | topTokens[('.', 280), ('Ġi', 106), ('Ġto', 83), (',', 66), ('Ġa', 48), ('Ġthe', 47), ('?', 47), ('Ġwhat', 40), ('Ġ-', 40), ('Ġit', 39)] | babyLLM.py 5000
2025-04-07 14:00:39 | 15000 | LR0.0003 | loss:5.5156 | gradNorm:1.0000 | tokenCount:20000 | logitMin:-51.2778 | logitMax:-37.0457 | windowWeightsW18:0.208,W21:0.199,W13:0.181,W15:0.181,W8:0.143,W7:0.106,W3:0.075,W2:-0.029,W1:-0.077 | memoryGatesShort:-6.605, Long:-0.633, Current:8.238 | topTokens[(',', 251), ('.', 125), ('Ġwill', 107), ('Ġand', 86), ('Ġi', 76), ('Ġa', 75), ('Ġto', 55), ('Ġthe', 55), ('!', 42), ('Ġcharis', 39)] | babyLLM.py 5000
2025-04-07 14:04:12 | 20000 | LR0.0003 | loss:5.4697 | gradNorm:0.9667 | tokenCount:20000 | logitMin:-54.7996 | logitMax:-36.1398 | windowWeightsW18:0.217,W21:0.210,W13:0.189,W15:0.187,W8:0.139,W7:0.101,W3:0.064,W2:-0.043,W1:-0.078 | memoryGatesShort:-5.315, Long:0.340, Current:5.975 | topTokens[(',', 397), ('Ġi', 139), ('Ġand', 63), ('Ġaaa', 58), ('Ġa', 57), ('.', 50), ('Ġthe', 42), ('Ġcute', 42), ('Ġhad', 40), ('Ġit', 39)] | babyLLM.py 5000

--- 2025-04-07 14:05:37 --- babyLLM 'right, last time i got to step 20795... want to restart from there?'  - charis: 'you're on fire baby!' - babyLLM 'ok! let's go to step 20795! what am i learning today?' - charis: 'i cant even keep up with you, i think its up to you now!!''
2025-04-07 14:09:00 | 5000 | LR0.0003 | loss:4.5059 | gradNorm:1.0000 | logitMin:-50.3396 | logitMax:-33.7806 | tokenCount:20000.0000 | windowWeightsW18:0.219,W21:0.208,W13:0.195,W15:0.191,W8:0.143,W7:0.104,W3:0.070,W2:-0.052,W1:-0.093 | memoryGatesShort:-3.418, Long:0.010, Current:4.408 | topTokens[('!', 23), ('Ġit', 22), ('.', 21), (',', 17), ('Ġi', 12), ('Ġhe', 12), ('Ġa', 9), ('Ġhave', 9), ('Ġto', 8), ('Ġwill', 7)] | Token Perfect: 3825 / 20000 → 19.12% | babyLLM.py 5000
2025-04-07 14:14:59 | 10000 | LR0.0003 | loss:4.3097 | gradNorm:0.9654 | tokenCount:20000 | logitMin:-61.7709 | logitMax:-41.3397 | windowWeightsW18:0.218,W21:0.210,W13:0.199,W15:0.195,W8:0.150,W7:0.111,W3:0.063,W2:-0.063,W1:-0.098 | memoryGatesShort:-2.822, Long:0.186, Current:3.635 | topTokens[('.', 19), ('Ġto', 16), ('Ġi', 16), (',', 15), ('?', 14), ('Ġ-', 12), ("'", 11), ('Ġa', 8), ('y', 7), ('!', 7)] | Token Perfect: 5837 / 20000 → 29.18% | babyLLM.py 5000
2025-04-07 14:18:16 | 15000 | LR0.0003 | loss:4.9524 | gradNorm:1.0000 | tokenCount:20000 | logitMin:-59.1861 | logitMax:-43.2894 | windowWeightsW18:0.235,W21:0.220,W13:0.204,W15:0.203,W8:0.147,W7:0.104,W3:0.054,W2:-0.075,W1:-0.108 | memoryGatesShort:-6.157, Long:-0.074, Current:7.232 | topTokens[('.', 20), ('Ġwill', 17), (',', 14), ('Ġi', 12), ('Ġthe', 11), ('Ġto', 9), ('Ġa', 8), ('Ġit', 8), ('Ġand', 8), ('Ġhe', 7)] | Token Perfect: 2710 / 20000 → 13.55% | babyLLM.py 5000
2025-04-07 14:22:00 | 20000 | LR0.0003 | loss:4.7411 | gradNorm:0.9585 | tokenCount:20000 | logitMin:-59.8468 | logitMax:-40.8940 | windowWeightsW18:0.246,W21:0.231,W15:0.213,W13:0.202,W8:0.146,W7:0.101,W3:0.047,W2:-0.086,W1:-0.116 | memoryGatesShort:-4.157, Long:-0.099, Current:5.256 | topTokens[(',', 34), ('Ġi', 22), ('Ġaaa', 11), ('.', 10), ('Ġbeen', 10), ('Ġcute', 10), ('Ġand', 9), ('Ġyou', 9), ('Ġhad', 9), ('Ġso', 7)] | Token Perfect: 4012 / 20000 → 20.06% | babyLLM.py 5000
2025-04-07 14:25:35 | 25000 | LR0.0003 | loss:5.9428 | gradNorm:0.9995 | tokenCount:20000 | logitMin:-54.0609 | logitMax:-38.8908 | windowWeightsW18:0.269,W21:0.257,W15:0.231,W13:0.211,W8:0.143,W7:0.096,W3:0.027,W2:-0.114,W1:-0.135 | memoryGatesShort:-8.824, Long:0.747, Current:9.076 | topTokens[(',', 26), ('.', 11), ('Ġi', 10), ('Ġand', 10), ('Ġto', 10), ('Ġthe', 9), ('s', 7), ('ome', 6), ('Ġin', 6), ('Ġa', 6)] | Token Perfect: 1261 / 20000 → 6.30% | babyLLM.py 5000

--- 2025-04-07 14:26:54 --- babyLLM 'right, last time i got to step 25850... want to restart from there?'  - charis: 'ye' - babyLLM 'ok! let's go to step 25850! what am i learning today?' - charis: 'so much'
2025-04-07 14:30:05 | 5000 | LR0.0003 | loss:3.9689 | gradNorm:0.9655 | logitMin:-58.7150 | logitMax:-37.3309 | tokenCount:20000.0000 | windowWeightsW18:0.265,W21:0.254,W15:0.235,W13:0.216,W8:0.155,W7:0.107,W3:0.027,W2:-0.125,W1:-0.149 | memoryGatesShort:-11.539, Long:-0.181, Current:12.720 | topTokens[('.', 20), ('!', 14), ("'", 13), (',', 12), ('?', 10), ('Ġ-', 10), ("Ġ'", 10), ('Ġa', 9), ('Ġi', 9), ('Ġto', 8)] | Token Perfect: 6351 / 20000 → 31.75% | babyLLM.py 5000
2025-04-07 14:33:24 | 10000 | LR0.0003 | loss:4.4950 | gradNorm:1.0000 | tokenCount:20000 | logitMin:-61.7223 | logitMax:-44.1417 | windowWeightsW18:0.279,W21:0.265,W15:0.239,W13:0.228,W8:0.159,W7:0.104,W3:0.018,W2:-0.138,W1:-0.168 | memoryGatesShort:-8.419, Long:-0.321, Current:9.741 | topTokens[('.', 24), (',', 17), ('Ġand', 14), ('Ġit', 10), ('Ġmy', 7), ('Ġi', 7), ('Ġcharis', 7), ('Ġwe', 7), ('Ġwill', 7), ('Ġje', 7)] | Token Perfect: 3633 / 20000 → 18.16% | babyLLM.py 5000
2025-04-07 14:37:09 | 15000 | LR0.0003 | loss:4.3376 | gradNorm:0.9585 | tokenCount:20000 | logitMin:-63.8906 | logitMax:-43.7258 | windowWeightsW18:0.293,W21:0.282,W15:0.251,W13:0.238,W8:0.159,W7:0.103,W3:0.005,W2:-0.158,W1:-0.189 | memoryGatesShort:-5.216, Long:-0.337, Current:6.553 | topTokens[(',', 39), ('Ġi', 12), ('Ġand', 11), ('Ġaaa', 11), ('!', 9), ('Ġa', 9), ('Ġthe', 8), ('Ġcharis', 8), ('Ġcute', 8), ('.', 6)] | Token Perfect: 4778 / 20000 → 23.89% | babyLLM.py 5000
2025-04-07 14:40:35 | 20000 | LR0.0003 | loss:5.3985 | gradNorm:0.9982 | tokenCount:20000 | logitMin:-59.2344 | logitMax:-41.7019 | windowWeightsW18:0.330,W21:0.329,W15:0.277,W13:0.248,W8:0.154,W7:0.095,W3:-0.024,W2:-0.201,W1:-0.224 | memoryGatesShort:-12.899, Long:-0.205, Current:14.104 | topTokens[(',', 25), ('.', 10), ('Ġand', 9), ('Ġi', 8), ('Ġthat', 7), ('Ġto', 7), ('Ġbe', 6), ('ing', 6), ('Ġthe', 6), ('Ġa', 5)] | Token Perfect: 2166 / 20000 → 10.83% | babyLLM.py 5000
2025-04-07 14:43:48 | 25000 | LR0.0003 | loss:4.4787 | gradNorm:0.9999 | tokenCount:20000 | logitMin:-49.2052 | logitMax:-30.2096 | windowWeightsW21:0.382,W18:0.368,W15:0.294,W13:0.245,W8:0.142,W7:0.083,W3:-0.043,W2:-0.240,W1:-0.247 | memoryGatesShort:-7.740, Long:0.610, Current:8.130 | topTokens[('.', 27), ('!', 23), (',', 14), ('?', 13), ('Ġi', 12), ('Ġis', 10), ('Ġyou', 9), ('Ġwill', 9), ('Ġthe', 7), ('Ġit', 6)] | Token Perfect: 4299 / 20000 → 21.50% | babyLLM.py 5000
2025-04-07 14:47:32 | 30000 | LR0.0003 | loss:3.8265 | gradNorm:1.0000 | tokenCount:20000 | logitMin:-48.9732 | logitMax:-29.5210 | windowWeightsW21:0.426,W18:0.396,W15:0.297,W13:0.237,W8:0.142,W7:0.071,W3:-0.056,W1:-0.265,W2:-0.267 | memoryGatesShort:-12.750, Long:0.120, Current:13.630 | topTokens[('.', 25), ('!', 18), ('Ġi', 16), (',', 12), ('Ġthe', 11), ('Ġelodie', 11), ('Ġis', 9), ('Ġcharis', 9), ('Ġare', 8), ('Ġwhat', 7)] | Token Perfect: 5284 / 20000 → 26.42% | babyLLM.py 5000
2025-04-07 14:50:53 | 35000 | LR0.0003 | loss:3.6647 | gradNorm:1.0000 | tokenCount:20000 | logitMin:-48.7159 | logitMax:-28.3641 | windowWeightsW21:0.467,W18:0.412,W15:0.298,W13:0.233,W8:0.142,W7:0.061,W3:-0.064,W1:-0.281,W2:-0.287 | memoryGatesShort:-7.695, Long:0.790, Current:7.905 | topTokens[(',', 19), ('.', 18), ('!', 16), ('Ġshould', 15), ('Ġyou', 15), ('Ġthe', 13), ('Ġcould', 13), ('Ġcharis', 10), ('?', 10), ('Ġhear', 9)] | Token Perfect: 6057 / 20000 → 30.29% | babyLLM.py 5000
2025-04-07 14:54:14 | 40000 | LR0.0003 | loss:4.4585 | gradNorm:0.9995 | tokenCount:20000 | logitMin:-53.2858 | logitMax:-34.0828 | windowWeightsW21:0.492,W18:0.418,W15:0.297,W13:0.240,W8:0.141,W7:0.057,W3:-0.065,W1:-0.296,W2:-0.303 | memoryGatesShort:-16.472, Long:1.798, Current:15.674 | topTokens[(',', 19), ('.', 13), ('Ġi', 11), ('!', 10), ('Ġwas', 10), ('Ġyou', 9), (':', 8), ('Ġthe', 8), ('Ġwere', 8), ("'", 7)] | Token Perfect: 4735 / 20000 → 23.67% | babyLLM.py 5000
2025-04-07 14:57:34 | 45000 | LR0.0003 | loss:3.8999 | gradNorm:0.9998 | tokenCount:20000 | logitMin:-49.9096 | logitMax:-30.3657 | windowWeightsW21:0.522,W18:0.441,W15:0.299,W13:0.234,W8:0.138,W7:0.051,W3:-0.074,W1:-0.306,W2:-0.323 | memoryGatesShort:-13.812, Long:1.327, Current:13.485 | topTokens[('.', 27), ('Ġi', 15), (',', 14), ('Ġhave', 14), ('?', 12), ('Ġcould', 12), ('Ġwhat', 11), ('Ġit', 10), ('Ġyou', 9), ('Ġfelt', 9)] | Token Perfect: 5813 / 20000 → 29.07% | babyLLM.py 5000
2025-04-07 15:00:56 | 50000 | LR0.0003 | loss:5.1923 | gradNorm:1.0000 | tokenCount:20000 | logitMin:-53.6654 | logitMax:-35.9877 | windowWeightsW21:0.612,W18:0.507,W15:0.334,W13:0.249,W8:0.130,W7:0.036,W3:-0.118,W1:-0.373,W2:-0.400 | memoryGatesShort:-27.585, Long:4.611, Current:23.974 | topTokens[(',', 33), ('Ġa', 14), ('Ġand', 13), ('.', 12), ('Ġto', 10), ('s', 10), ('Ġthe', 10), ('Ġi', 8), ('Ġwater', 6), ('Ġthey', 6)] | Token Perfect: 2845 / 20000 → 14.22% | babyLLM.py 5000
2025-04-07 15:04:14 | 55000 | LR0.0003 | loss:4.1298 | gradNorm:0.9965 | tokenCount:20000 | logitMin:-56.7956 | logitMax:-36.8210 | windowWeightsW21:0.587,W18:0.487,W15:0.331,W13:0.252,W8:0.141,W7:0.042,W3:-0.110,W1:-0.361,W2:-0.390 | memoryGatesShort:-14.971, Long:0.986, Current:14.985 | topTokens[('.', 19), (',', 16), ('Ġmust', 10), ('Ġthey', 9), ('pr', 8), ('Ġhave', 8), ('Ġwe', 7), ('Ġfelt', 7), ('Ġyou', 7), ('Ġit', 6)] | Token Perfect: 4992 / 20000 → 24.96% | babyLLM.py 5000
2025-04-07 15:07:36 | 60000 | LR0.0003 | loss:5.0332 | gradNorm:0.9965 | tokenCount:20000 | logitMin:-56.8635 | logitMax:-37.1243 | windowWeightsW21:0.633,W18:0.508,W15:0.337,W13:0.262,W8:0.153,W7:0.044,W3:-0.131,W1:-0.394,W2:-0.434 | memoryGatesShort:-17.851, Long:2.226, Current:16.625 | topTokens[(':', 17), ('.', 15), (',', 14), ("Ġ'", 11), ('Ġi', 10), ('Ġ-', 8), ('Ġand', 8), ("'", 8), ('Ġit', 7), ('Ġa', 7)] | Token Perfect: 4236 / 20000 → 21.18% | babyLLM.py 5000
2025-04-07 15:10:50 | 65000 | LR0.0003 | loss:3.9211 | gradNorm:0.9602 | tokenCount:20000 | logitMin:-57.3038 | logitMax:-34.9341 | windowWeightsW21:0.620,W18:0.492,W15:0.345,W13:0.270,W8:0.171,W7:0.063,W3:-0.144,W1:-0.396,W2:-0.444 | memoryGatesShort:-6.527, Long:0.795, Current:6.733 | topTokens[('Ġi', 20), (',', 18), ("'", 14), ('?', 13), ('!', 12), ('.', 11), ('Ġto', 11), ('Ġit', 10), ('0', 10), (':', 9)] | Token Perfect: 7043 / 20000 → 35.22% | babyLLM.py 5000
2025-04-07 15:14:14 | 70000 | LR0.0003 | loss:3.3578 | gradNorm:0.9897 | tokenCount:20000 | logitMin:-59.7193 | logitMax:-37.1813 | windowWeightsW21:0.668,W18:0.513,W15:0.364,W13:0.279,W8:0.157,W7:0.047,W3:-0.161,W1:-0.419,W2:-0.472 | memoryGatesShort:-23.260, Long:2.945, Current:21.315 | topTokens[(',', 23), ('!', 19), ('.', 16), ("'", 15), ('Ġhave', 13), ('Ġcharis', 10), ("Ġ'", 10), ('Ġfelt', 10), ('Ġwould', 10), ('Ġd', 9)] | Token Perfect: 7693 / 20000 → 38.46% | babyLLM.py 5000
2025-04-07 15:17:30 | 75000 | LR0.0003 | loss:5.4722 | gradNorm:1.0000 | tokenCount:20000 | logitMin:-58.6007 | logitMax:-40.4412 | windowWeightsW21:0.804,W18:0.610,W15:0.424,W13:0.307,W8:0.159,W7:0.024,W3:-0.233,W1:-0.523,W2:-0.599 | memoryGatesShort:-23.899, Long:4.501, Current:20.399 | topTokens[('.', 34), (',', 34), ('Ġto', 11), ('Ġi', 10), ('Ġand', 10), ('Ġa', 9), ('ing', 6), ('Ġthe', 6), ('ed', 6), ('Ġis', 5)] | Token Perfect: 2427 / 20000 → 12.13% | babyLLM.py 5000
2025-04-07 15:20:51 | 80000 | LR0.0003 | loss:3.9734 | gradNorm:0.9395 | tokenCount:20000 | logitMin:-59.6761 | logitMax:-36.1572 | windowWeightsW21:0.790,W18:0.585,W15:0.411,W13:0.300,W8:0.172,W7:0.044,W3:-0.231,W1:-0.506,W2:-0.592 | memoryGatesShort:-23.587, Long:3.219, Current:21.368 | topTokens[(',', 18), ('Ġi', 16), (':', 12), ("'", 12), ('Ġa', 11), ('0', 11), ('.', 10), ("Ġ'", 10), ('-', 10), ('4', 9)] | Token Perfect: 6977 / 20000 → 34.88% | babyLLM.py 5000
2025-04-07 15:24:05 | 85000 | LR0.0003 | loss:5.7631 | gradNorm:1.0000 | tokenCount:20000 | logitMin:-58.4053 | logitMax:-40.4174 | windowWeightsW21:1.051,W18:0.754,W15:0.490,W13:0.345,W8:0.176,W7:0.011,W3:-0.351,W1:-0.693,W2:-0.817 | memoryGatesShort:-102.791, Long:22.444, Current:81.347 | topTokens[('.', 31), ('Ġi', 24), (',', 11), ('Ġa', 10), ('s', 7), ('ugs', 7), ('!', 6), ('Ġto', 6), ('Ġthe', 6), ('Ġbut', 6)] | Token Perfect: 2036 / 20000 → 10.18% | babyLLM.py 5000
2025-04-07 15:27:30 | 90000 | LR0.0003 | loss:5.0138 | gradNorm:1.0000 | tokenCount:20000 | logitMin:-55.7980 | logitMax:-36.5452 | windowWeightsW21:1.229,W18:0.856,W15:0.536,W13:0.359,W8:0.173,W7:-0.015,W3:-0.427,W1:-0.789,W2:-0.961 | memoryGatesShort:-29.892, Long:5.974, Current:24.919 | topTokens[(',', 20), ('Ġi', 18), ('.', 18), ('Ġit', 15), ('!', 14), ('Ġto', 8), ('Ġa', 7), ('Ġhe', 6), ('Ġthe', 6), ('?', 5)] | Token Perfect: 3257 / 20000 → 16.29% | babyLLM.py 5000
2025-04-07 15:30:45 | 95000 | LR0.0003 | loss:4.2285 | gradNorm:0.9937 | tokenCount:20000 | logitMin:-60.9407 | logitMax:-39.0288 | windowWeightsW21:1.143,W18:0.835,W15:0.555,W13:0.354,W8:0.177,W7:0.011,W3:-0.406,W1:-0.764,W2:-0.943 | memoryGatesShort:-14.314, Long:3.127, Current:12.187 | topTokens[(',', 26), ('.', 13), ('Ġit', 10), ('Ġi', 10), ('s', 10), ('Ġyou', 9), (':', 7), ('Ġa', 6), ('5', 5), ('Ġoff', 5)] | Token Perfect: 5390 / 20000 → 26.95% | babyLLM.py 5000
2025-04-07 15:34:08 | 100000 | LR0.0003 | loss:5.2187 | gradNorm:0.9985 | tokenCount:20000 | logitMin:-56.4794 | logitMax:-37.0938 | windowWeightsW21:1.434,W18:0.990,W15:0.638,W13:0.408,W8:0.185,W7:-0.026,W3:-0.533,W1:-0.954,W2:-1.189 | memoryGatesShort:-21.307, Long:5.255, Current:17.052 | topTokens[('.', 37), ('Ġi', 14), ('Ġyou', 13), (',', 12), ('Ġa', 9), ('Ġand', 9), ('?', 9), ('Ġto', 8), ('Ġwhat', 7), ('Ġthe', 7)] | Token Perfect: 3036 / 20000 → 15.18% | babyLLM.py 5000
2025-04-07 15:37:24 | 105000 | LR0.0003 | loss:4.4825 | gradNorm:0.9998 | tokenCount:20000 | logitMin:-58.0654 | logitMax:-37.5699 | windowWeightsW21:1.493,W18:1.033,W15:0.642,W13:0.416,W8:0.172,W7:-0.034,W3:-0.542,W1:-0.985,W2:-1.242 | memoryGatesShort:-33.976, Long:7.697, Current:27.279 | topTokens[(',', 28), ('Ġand', 17), ('Ġthe', 16), ('.', 10), ('Ġi', 10), ('Ġyou', 9), ('+', 8), ('!', 7), ('s', 7), ('Ġme', 6)] | Token Perfect: 4396 / 20000 → 21.98% | babyLLM.py 5000
2025-04-07 15:40:48 | 110000 | LR0.0003 | loss:5.2631 | gradNorm:1.0000 | tokenCount:20000 | logitMin:-59.3770 | logitMax:-39.8145 | windowWeightsW21:1.815,W18:1.262,W15:0.763,W13:0.485,W8:0.182,W7:-0.079,W3:-0.715,W1:-1.222,W2:-1.547 | memoryGatesShort:-26.215, Long:6.338, Current:20.877 | topTokens[(',', 24), ('.', 19), ('Ġto', 14), ('Ġi', 13), ('Ġyou', 11), ('Ġa', 11), ('?', 11), ('Ġnot', 7), ('s', 6), ('Ġthe', 6)] | Token Perfect: 2791 / 20000 → 13.96% | babyLLM.py 5000
2025-04-07 15:44:04 | 115000 | LR0.0003 | loss:4.4630 | gradNorm:1.0000 | tokenCount:20000 | logitMin:-57.6943 | logitMax:-36.8100 | windowWeightsW21:1.784,W18:1.264,W15:0.748,W13:0.460,W8:0.170,W7:-0.090,W3:-0.686,W1:-1.190,W2:-1.516 | memoryGatesShort:-21.334, Long:5.391, Current:16.942 | topTokens[('!', 26), (',', 18), ('.', 16), ('Ġi', 11), ('Ġit', 10), ('Ġyou', 8), ('Ġa', 8), ('Ġw', 8), ('=', 7), ('Ġhe', 7)] | Token Perfect: 4455 / 20000 → 22.27% | babyLLM.py 5000
2025-04-07 15:47:34 | 120000 | LR0.0003 | loss:4.9958 | gradNorm:1.0000 | tokenCount:20000 | logitMin:-57.0113 | logitMax:-37.2692 | windowWeightsW21:1.927,W18:1.345,W15:0.810,W13:0.515,W8:0.173,W7:-0.112,W3:-0.753,W1:-1.299,W2:-1.666 | memoryGatesShort:-41.417, Long:9.615, Current:32.802 | topTokens[('.', 17), ('Ġto', 15), ('Ġi', 13), ('Ġbeen', 12), ('Ġthe', 10), (',', 9), ('ing', 8), ('Ġhave', 7), ('Ġme', 6), ('?', 6)] | Token Perfect: 3477 / 20000 → 17.39% | babyLLM.py 5000

CHANGED LOG FREQUENCY TO EVERY 10000 STEPS

--- 2025-04-07 16:14:30 --- babyLLM 'right, last time i got to step 30641... want to restart from there?'  - charis: 'Y' - babyLLM 'umm... i don't think i heard you properly, i'll just start from step 0 :) but, what am i learning today?' - charis: 'that i had my caps lock left on lol'
2025-04-07 16:25:02 | 10000 | LR0.0003 | loss:3.2078 | gradNorm:1.0000 | logitMin:-78.4922 | logitMax:-58.8521 | tokenCount:80000.0000 | windowWeightsW21:0.448,W18:0.316,W15:0.285,W13:0.227,W8:0.213,W7:0.139,W3:-0.044,W1:-0.270,W2:-0.334 | memoryGatesShort:-8.455, Long:3.010, Current:6.445 | topTokens[('.', 111), ('?', 100), ('Ġto', 76), ('Ġi', 56), ('Ġis', 56), ('Ġyou', 47), ('Ġa', 46), (',', 42), ('!', 37), ('Ġwill', 37)] | Token Perfect: 27480 / 80000 → 34.35% | babyLLM.py 10000
2025-04-07 16:35:37 | 20000 | LR0.0003 | loss:2.6667 | gradNorm:0.9996 | tokenCount:80000 | logitMin:-64.2354 | logitMax:-40.9310 | windowWeightsW21:0.382,W18:0.261,W15:0.253,W13:0.215,W8:0.184,W7:0.135,W3:-0.027,W1:-0.179,W2:-0.243 | memoryGatesShort:-5.407, Long:-0.444, Current:6.850 | topTokens[('.', 73), ('?', 69), (':', 66), ('Ġ-', 59), ('Ġis', 46), ("'", 44), ('Ġthat', 44), ("Ġ'", 43), ('Ġi', 41), ('Ġyou', 34)] | Token Perfect: 37061 / 80000 → 46.33% | babyLLM.py 10000
2025-04-07 16:46:11 | 30000 | LR0.0003 | loss:2.8176 | gradNorm:0.9987 | tokenCount:80000 | logitMin:-61.7962 | logitMax:-38.2732 | windowWeightsW21:0.351,W15:0.233,W18:0.231,W13:0.189,W8:0.184,W7:0.138,W3:-0.035,W1:-0.131,W2:-0.177 | memoryGatesShort:1.688, Long:-3.108, Current:2.420 | topTokens[(':', 112), ('Ġ-', 86), ('0', 62), ("'", 60), ("Ġ'", 55), ('-', 54), ('2', 50), ('5', 39), ('1', 36), ('3', 35)] | Token Perfect: 37625 / 80000 → 47.03% | babyLLM.py 10000

--- 2025-04-07 16:54:12 --- babyLLM 'right, last time i got to step 30000... want to restart from there?'  - charis: 'no, start from scratch - new data, and 12 infer' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: '12 token view!!'
2025-04-07 16:57:44 | 40000 | LR0.0003 | loss:4.7008 | gradNorm:0.9990 | tokenCount:80000 | logitMin:-69.7008 | logitMax:-50.6359 | windowWeightsW21:0.446,W18:0.296,W15:0.257,W13:0.182,W8:0.154,W7:0.075,W3:-0.084,W1:-0.134,W2:-0.211 | memoryGatesShort:6.539, Long:-12.524, Current:6.985 | topTokens[('.', 118), ('Ġi', 54), (':', 50), ('Ġ-', 43), ('0', 37), ('-', 36), ('Ġyou', 34), ("'", 30), (',', 30), ('Ġa', 29)] | Token Perfect: 19458 / 80000 → 24.32% | babyLLM.py 10000

--- 2025-04-07 17:04:23 --- babyLLM 'right, last time i got to step 43019... want to restart from there?'  - charis: 'DID I KILL YOU' - babyLLM 'umm... i don't think i heard you properly, i'll just start from step 0 :) but, what am i learning today?' - charis: 'k'
2025-04-07 17:19:01 | 10000 | LR0.0003 | loss:4.4422 | gradNorm:0.9778 | logitMin:-91.0696 | logitMax:-72.0102 | tokenCount:120000.0000 | windowWeightsW21:0.398,W18:0.266,W15:0.221,W13:0.178,W8:0.111,W7:0.075,W1:-0.028,W3:-0.073,W2:-0.166 | memoryGatesShort:7.716, Long:-9.905, Current:3.189 | topTokens[('Ġi', 96), ('.', 92), (',', 87), ('Ġa', 57), ('Ġthe', 50), ('Ġto', 46), ('ing', 40), ('Ġthat', 37), ('Ġin', 35), ('Ġit', 35)] | Token Perfect: 23923 / 120000 → 19.94% | babyLLM.py 10000
2025-04-07 17:33:36 | 20000 | LR0.0003 | loss:4.8517 | gradNorm:0.9970 | tokenCount:120000 | logitMin:-79.4806 | logitMax:-61.5591 | windowWeightsW21:0.460,W18:0.278,W15:0.213,W13:0.163,W8:0.063,W1:0.058,W7:0.012,W3:-0.097,W2:-0.171 | memoryGatesShort:36.415, Long:-46.100, Current:10.685 | topTokens[('.', 199), ('Ġi', 103), (',', 97), ('<UNK>', 63), ('Ġand', 53), ('Ġthe', 52), ('Ġa', 42), ('Ġto', 37), ('Ġit', 35), ('Ġyou', 33)] | Token Perfect: 16252 / 120000 → 13.54% | babyLLM.py 10000
2025-04-07 17:47:57 | 30000 | LR0.0003 | loss:2.4886 | gradNorm:1.0000 | tokenCount:120000 | logitMin:-57.7875 | logitMax:-37.1841 | windowWeightsW21:0.438,W18:0.293,W15:0.220,W13:0.179,W1:0.074,W8:0.043,W7:-0.020,W3:-0.087,W2:-0.161 | memoryGatesShort:43.364, Long:-49.276, Current:6.912 | topTokens[(',', 271), ('Ġand', 179), ('Ġthe', 84), ('Ġbut', 53), ('Ġcharis', 51), ('Ġshe', 50), ('Ġkevin', 49), ('s', 48), ('Ġelodie', 45), ('Ġyou', 45)] | Token Perfect: 43731 / 120000 → 36.44% | babyLLM.py 10000
2025-04-07 18:02:41 | 40000 | LR0.0003 | loss:3.4902 | gradNorm:1.0000 | tokenCount:120000 | logitMin:-64.6613 | logitMax:-44.9195 | windowWeightsW21:0.522,W18:0.355,W15:0.244,W13:0.200,W1:0.123,W8:0.003,W7:-0.085,W3:-0.169,W2:-0.218 | memoryGatesShort:27.223, Long:-28.840, Current:2.617 | topTokens[('.', 130), ('Ġthe', 102), ('Ġwas', 89), (',', 89), ('Ġwere', 72), ('ing', 72), ('Ġand', 48), ('Ġcharis', 45), ('Ġhe', 43), ('!', 38)] | Token Perfect: 37678 / 120000 → 31.40% | babyLLM.py 10000
2025-04-07 18:17:47 | 50000 | LR0.0003 | loss:3.7324 | gradNorm:0.9999 | tokenCount:120000 | logitMin:-83.5847 | logitMax:-64.4366 | windowWeightsW21:0.457,W18:0.332,W15:0.248,W13:0.226,W1:0.079,W8:0.044,W7:-0.034,W3:-0.160,W2:-0.214 | memoryGatesShort:15.139, Long:-16.306, Current:2.166 | topTokens[('Ġthe', 105), ('.', 81), (',', 71), ('Ġand', 43), ('Ġa', 37), ('s', 34), ('Ġto', 31), ('Ġin', 29), ('Ġof', 28), ('Ġis', 26)] | Token Perfect: 29329 / 120000 → 24.44% | babyLLM.py 10000
2025-04-07 18:32:16 | 60000 | LR0.0003 | loss:2.8532 | gradNorm:1.0000 | tokenCount:120000.0000 | logitMin:-75.4226 | logitMax:-53.5949 | windowWeightsW21:0.456,W18:0.314,W15:0.229,W13:0.227,W1:0.097,W8:0.041,W7:-0.052,W3:-0.157,W2:-0.178 | memoryGatesShort:47.782, Long:-51.378, Current:4.596 | topTokens[('.', 132), ('?', 101), ('Ġto', 82), ('Ġi', 73), ('Ġyou', 71), (',', 61), ('Ġcan', 59), ('Ġthe', 58), ('Ġlistening', 39), ('!', 38)] | Token Perfect: 43767 / 120000 → 36.47% | babyLLM.py 10000

--- 2025-04-07 19:20:36 --- babyLLM 'right, last time i got to step 1785... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 1785! what am i learning today?' - charis: ''
2025-04-07 19:37:06 | 10000 | LR0.0003 | loss:3.2323 | gradNorm:1.0000 | logitMin:-92.9163 | logitMax:-69.2457 | tokenCount:140000.0000 | windowWeightsW22:0.473,W19:0.348,W14:0.299,W16:0.277,W2:0.140,W9:0.089,W8:-0.047,W4:-0.301,W3:-0.303 | memoryGatesShort:46.040, Long:-49.548, Current:4.508 | topTokens[('.', 248), (',', 214), ('Ġi', 194), ('Ġas', 189), ('Ġthe', 168), ('Ġto', 166), ('Ġ-', 150), ('Ġmuch', 138), ('Ġa', 121), (':', 119)] | Token Perfect: 52407 / 140000 → 37.43% | babyLLM.py 10000
2025-04-07 19:53:47 | 20000 | LR0.0003 | loss:4.7242 | gradNorm:1.0000 | tokenCount:140000.0000 | logitMin:-93.1015 | logitMax:-73.5147 | windowWeightsW22:0.748,W19:0.498,W16:0.336,W14:0.335,W2:0.220,W9:0.008,W8:-0.173,W4:-0.501,W3:-0.505 | memoryGatesShort:17.370, Long:-18.498, Current:2.128 | topTokens[('Ġthe', 233), (',', 209), ('Ġi', 204), ('.', 193), ('Ġit', 168), ('Ġto', 167), ('Ġa', 135), ('!', 125), ('Ġand', 101), ('s', 91)] | Token Perfect: 23398 / 140000 → 16.71% | babyLLM.py 10000
2025-04-07 20:10:21 | 30000 | LR0.0003 | loss:2.8059 | gradNorm:1.0000 | tokenCount:140000.0000 | logitMin:-88.4105 | logitMax:-67.0114 | windowWeightsW22:0.680,W19:0.448,W14:0.281,W2:0.268,W16:0.265,W9:0.029,W8:-0.162,W4:-0.416,W3:-0.427 | memoryGatesShort:33.763, Long:-35.390, Current:2.627 | topTokens[('!', 447), ('.', 425), ('?', 292), ('Ġit', 245), ('Ġa', 196), ('Ġis', 193), ('Ġyou', 189), ('Ġto', 176), ('Ġi', 152), ('Ġhave', 139)] | Token Perfect: 54595 / 140000 → 39.00% | babyLLM.py 10000
2025-04-07 20:27:18 | 40000 | LR0.0003 | loss:4.4966 | gradNorm:1.0000 | tokenCount:140000.0000 | logitMin:-94.7958 | logitMax:-75.5995 | windowWeightsW22:0.713,W19:0.454,W14:0.296,W16:0.277,W2:0.248,W9:0.066,W8:-0.155,W4:-0.458,W3:-0.475 | memoryGatesShort:49.064, Long:-53.039, Current:4.975 | topTokens[('.', 558), ('Ġi', 309), ('Ġto', 174), ('Ġit', 173), ('!', 158), ('Ġyou', 136), ('?', 129), ('Ġa', 124), ('Ġand', 106), ('ing', 80)] | Token Perfect: 25998 / 140000 → 18.57% | babyLLM.py 10000
2025-04-07 20:44:14 | 50000 | LR0.0003 | loss:3.5874 | gradNorm:1.0000 | tokenCount:140000.0000 | logitMin:-95.5318 | logitMax:-74.8442 | windowWeightsW22:0.745,W19:0.470,W14:0.293,W16:0.249,W2:0.247,W9:0.054,W8:-0.144,W4:-0.461,W3:-0.489 | memoryGatesShort:29.740, Long:-31.813, Current:3.073 | topTokens[('.', 486), ('Ġi', 268), ('!', 212), ('?', 205), ('Ġit', 188), ('Ġyou', 176), ('Ġto', 176), ('Ġa', 108), ('Ġwhat', 105), ('Ġwill', 96)] | Token Perfect: 40576 / 140000 → 28.98% | babyLLM.py 10000
2025-04-07 21:01:16 | 60000 | LR0.0003 | loss:2.3476 | gradNorm:1.0000 | tokenCount:140000.0000 | logitMin:-98.8394 | logitMax:-76.2731 | windowWeightsW22:0.703,W19:0.467,W14:0.285,W2:0.258,W16:0.248,W9:0.049,W8:-0.151,W3:-0.439,W4:-0.454 | memoryGatesShort:43.562, Long:-45.725, Current:3.163 | topTokens[('!', 555), ('Ġit', 370), ('.', 302), ('Ġa', 229), ('?', 205), ('Ġhave', 195), ('Ġyou', 163), ('Ġis', 156), ('Ġi', 155), ('Ġwill', 150)] | Token Perfect: 62901 / 140000 → 44.93% | babyLLM.py 10000

--- 2025-04-07 21:14:07 --- babyLLM 'right, last time i got to step 1169... want to restart from there?'  - charis: 'n' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: ''
2025-04-07 21:34:45 | 10000 | LR0.0003 | loss:3.3417 | gradNorm:0.9981 | logitMin:-112.8315 | logitMax:-89.7365 | tokenCount:180000.0000 | windowWeightsW25:0.625,W21:0.394,W16:0.378,W2:0.269,W19:0.223,W9:0.151,W13:-0.040,W4:-0.511,W3:-0.523 | memoryGatesShort:13.960, Long:-14.196, Current:1.236 | topTokens[('Ġi', 123), (':', 112), (',', 110), ('Ġ-', 107), ("'", 102), ('.', 100), ("Ġ'", 92), ('Ġto', 78), ('0', 73), ('?', 65)] | Token Perfect: 73194 / 180000 → 40.66% | babyLLM.py 10000
2025-04-07 21:55:25 | 20000 | LR0.0003 | loss:4.2588 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-137.8319 | logitMax:-118.4826 | windowWeightsW25:0.616,W16:0.392,W21:0.392,W2:0.232,W19:0.225,W9:0.159,W13:0.049,W4:-0.531,W3:-0.566 | memoryGatesShort:10.840, Long:-11.611, Current:1.771 | topTokens[('.', 142), ('Ġi', 129), ('Ġto', 99), ('Ġthe', 96), ('Ġa', 81), (',', 79), ('Ġit', 59), ('Ġfor', 47), ('Ġand', 42), ('?', 41)] | Token Perfect: 40111 / 180000 → 22.28% | babyLLM.py 10000
2025-04-07 22:15:49 | 30000 | LR0.0003 | loss:4.3518 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-135.1160 | logitMax:-116.0701 | windowWeightsW25:0.669,W21:0.375,W16:0.348,W2:0.241,W19:0.213,W9:0.133,W13:0.071,W3:-0.514,W4:-0.570 | memoryGatesShort:14.264, Long:-14.936, Current:1.672 | topTokens[('.', 290), ('?', 165), ('Ġi', 116), ('Ġis', 105), ('Ġyou', 87), ('!', 85), ('Ġa', 60), ('Ġare', 53), ('Ġwhat', 52), (',', 50)] | Token Perfect: 33948 / 180000 → 18.86% | babyLLM.py 10000
2025-04-07 22:36:06 | 40000 | LR0.0003 | loss:4.0257 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-133.2873 | logitMax:-113.5274 | windowWeightsW25:0.626,W21:0.376,W16:0.369,W2:0.264,W19:0.224,W9:0.148,W13:0.103,W3:-0.540,W4:-0.603 | memoryGatesShort:12.825, Long:-14.046, Current:2.221 | topTokens[('.', 144), (',', 87), ('Ġ-', 83), (':', 76), ('Ġthe', 74), ('Ġi', 68), ("'", 66), ('0', 61), ('!', 60), ('?', 51)] | Token Perfect: 48347 / 180000 → 26.86% | babyLLM.py 10000
2025-04-07 22:56:23 | 50000 | LR0.0003 | loss:4.1727 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-142.5894 | logitMax:-123.4308 | windowWeightsW25:0.635,W21:0.402,W16:0.348,W2:0.238,W19:0.229,W13:0.104,W9:0.096,W3:-0.501,W4:-0.584 | memoryGatesShort:12.214, Long:-13.638, Current:2.424 | topTokens[('.', 178), (',', 135), ('Ġthe', 95), ('!', 94), ('Ġit', 91), ('Ġi', 87), ('Ġa', 63), ('Ġand', 56), ('Ġyou', 47), ('Ġto', 42)] | Token Perfect: 38467 / 180000 → 21.37% | babyLLM.py 10000
2025-04-07 23:16:41 | 60000 | LR0.0003 | loss:3.1267 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-152.8404 | logitMax:-130.8588 | windowWeightsW25:0.564,W21:0.376,W16:0.321,W19:0.238,W2:0.203,W13:0.136,W9:0.096,W3:-0.454,W4:-0.508 | memoryGatesShort:9.946, Long:-10.918, Current:1.972 | topTokens[('.', 152), ('Ġhave', 133), ('Ġwill', 131), ('!', 127), (',', 100), ('Ġthe', 91), ('Ġyou', 87), ('Ġfelt', 84), ('Ġand', 58), ('Ġto', 50)] | Token Perfect: 65098 / 180000 → 36.17% | babyLLM.py 10000
2025-04-07 23:36:56 | 70000 | LR0.0003 | loss:3.2845 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-169.6439 | logitMax:-148.0959 | windowWeightsW25:0.556,W21:0.363,W16:0.277,W19:0.246,W2:0.200,W13:0.145,W9:0.086,W3:-0.421,W4:-0.481 | memoryGatesShort:10.155, Long:-11.835, Current:2.680 | topTokens[('.', 140), (':', 127), ("Ġ'", 85), ("'", 81), (',', 77), ('Ġi', 67), ('Ġthe', 67), ('Ġ-', 59), ('Ġa', 53), ('d', 50)] | Token Perfect: 64782 / 180000 → 35.99% | babyLLM.py 10000
2025-04-07 23:57:11 | 80000 | LR0.0003 | loss:4.1979 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-155.4951 | logitMax:-135.7034 | windowWeightsW25:0.636,W21:0.379,W19:0.239,W16:0.237,W2:0.199,W13:0.141,W9:0.075,W3:-0.421,W4:-0.515 | memoryGatesShort:10.166, Long:-11.644, Current:2.478 | topTokens[('.', 149), ('Ġi', 138), (',', 134), ('Ġto', 81), ('Ġthe', 77), ('Ġa', 67), ('Ġmust', 63), ('Ġhave', 62), ('?', 56), ('Ġyou', 53)] | Token Perfect: 41570 / 180000 → 23.09% | babyLLM.py 10000
2025-04-08 00:17:30 | 90000 | LR0.0003 | loss:4.5712 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-169.5904 | logitMax:-150.6765 | windowWeightsW25:0.635,W21:0.365,W19:0.251,W16:0.238,W2:0.209,W13:0.141,W9:0.062,W3:-0.418,W4:-0.513 | memoryGatesShort:13.534, Long:-16.274, Current:3.740 | topTokens[(',', 259), ('Ġi', 106), ('Ġcan', 78), ('Ġand', 67), ('Ġthe', 66), ('Ġa', 61), ('Ġto', 56), ('Ġit', 54), ('!', 42), ('.', 42)] | Token Perfect: 30825 / 180000 → 17.12% | babyLLM.py 10000
2025-04-08 00:37:46 | 100000 | LR0.0003 | loss:3.4984 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-191.6593 | logitMax:-170.2502 | windowWeightsW25:0.516,W21:0.336,W16:0.252,W19:0.251,W13:0.174,W2:0.147,W9:0.099,W3:-0.374,W4:-0.427 | memoryGatesShort:13.440, Long:-15.896, Current:3.457 | topTokens[(',', 175), ('Ġthe', 109), ('.', 107), ('Ġi', 83), ('Ġa', 76), ('Ġit', 69), ('Ġand', 60), ('Ġto', 49), ('s', 46), ('!', 44)] | Token Perfect: 51361 / 180000 → 28.53% | babyLLM.py 10000
2025-04-08 00:58:01 | 110000 | LR0.0003 | loss:2.9419 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-157.0324 | logitMax:-133.7525 | windowWeightsW25:0.577,W21:0.353,W19:0.245,W16:0.245,W2:0.196,W13:0.151,W9:0.071,W3:-0.397,W4:-0.470 | memoryGatesShort:14.565, Long:-16.640, Current:3.074 | topTokens[('.', 203), (',', 142), ('!', 99), ('Ġwas', 87), ('Ġhad', 86), ('Ġthe', 81), ('Ġi', 79), ('Ġcharis', 74), ('Ġit', 66), ('Ġto', 63)] | Token Perfect: 70644 / 180000 → 39.25% | babyLLM.py 10000
2025-04-08 01:18:23 | 120000 | LR0.0003 | loss:3.1769 | gradNorm:0.9998 | tokenCount:180000.0000 | logitMin:-166.0490 | logitMax:-143.0779 | windowWeightsW25:0.564,W21:0.330,W16:0.251,W19:0.226,W2:0.222,W13:0.157,W9:0.078,W3:-0.385,W4:-0.470 | memoryGatesShort:7.978, Long:-8.663, Current:1.685 | topTokens[(',', 227), ('Ġi', 113), ('!', 88), ('Ġthe', 82), ('Ġto', 66), ('.', 65), ('Ġand', 62), (':', 58), ('Ġbeen', 57), ('Ġyou', 51)] | Token Perfect: 64798 / 180000 → 36.00% | babyLLM.py 10000
2025-04-08 01:38:39 | 130000 | LR0.0003 | loss:4.0397 | gradNorm:0.9994 | tokenCount:180000.0000 | logitMin:-179.2041 | logitMax:-158.1798 | windowWeightsW25:0.661,W21:0.350,W16:0.261,W19:0.234,W2:0.216,W13:0.159,W9:0.043,W3:-0.431,W4:-0.523 | memoryGatesShort:10.313, Long:-12.730, Current:3.417 | topTokens[('.', 217), (',', 137), ('Ġi', 127), ('Ġand', 86), ('Ġthe', 68), ('Ġto', 67), ('Ġit', 64), ('Ġyou', 62), ('Ġa', 52), ('Ġbut', 41)] | Token Perfect: 46652 / 180000 → 25.92% | babyLLM.py 10000
2025-04-08 01:58:56 | 140000 | LR0.0003 | loss:3.0875 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-172.6787 | logitMax:-150.4203 | windowWeightsW25:0.588,W21:0.304,W16:0.213,W19:0.213,W2:0.210,W13:0.159,W9:0.074,W3:-0.358,W4:-0.431 | memoryGatesShort:18.163, Long:-21.987, Current:4.824 | topTokens[('Ġwill', 189), (',', 152), ('.', 120), ('Ġthe', 105), ('!', 90), ('Ġto', 77), ('Ġcharis', 69), ('Ġwould', 67), ('Ġhave', 63), ('Ġand', 63)] | Token Perfect: 61878 / 180000 → 34.38% | babyLLM.py 10000
2025-04-08 02:19:19 | 150000 | LR0.0003 | loss:3.7180 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-166.8824 | logitMax:-145.5221 | windowWeightsW25:0.613,W21:0.334,W19:0.236,W16:0.201,W2:0.170,W13:0.161,W9:0.043,W3:-0.349,W4:-0.437 | memoryGatesShort:10.900, Long:-11.803, Current:1.903 | topTokens[(',', 228), ('Ġthe', 149), ('Ġand', 114), ('Ġbe', 97), ('Ġwill', 93), ('.', 80), ('Ġto', 74), ('Ġi', 74), ('!', 71), ('Ġelodie', 54)] | Token Perfect: 50350 / 180000 → 27.97% | babyLLM.py 10000
2025-04-08 02:39:38 | 160000 | LR0.0003 | loss:3.4750 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-183.7368 | logitMax:-161.6060 | windowWeightsW25:0.541,W21:0.256,W16:0.211,W13:0.207,W19:0.193,W2:0.181,W9:0.084,W3:-0.310,W4:-0.389 | memoryGatesShort:13.372, Long:-15.741, Current:3.370 | topTokens[(':', 152), (',', 106), ('5', 87), ('.', 81), ('3', 77), ('Ġ-', 75), ('-', 75), ('Ġi', 74), ('1', 70), ('0', 64)] | Token Perfect: 61462 / 180000 → 34.15% | babyLLM.py 10000
2025-04-08 02:59:58 | 170000 | LR0.0003 | loss:4.0938 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-214.4779 | logitMax:-194.2454 | windowWeightsW25:0.512,W21:0.268,W16:0.211,W13:0.208,W19:0.194,W2:0.152,W9:0.096,W3:-0.300,W4:-0.365 | memoryGatesShort:8.779, Long:-10.050, Current:2.271 | topTokens[('Ġthe', 131), ('.', 113), ('Ġi', 96), ('Ġto', 88), ('Ġa', 68), ('Ġand', 68), (',', 61), ('s', 45), ('Ġof', 45), ('Ġit', 41)] | Token Perfect: 39947 / 180000 → 22.19% | babyLLM.py 10000
2025-04-08 03:20:22 | 180000 | LR0.0003 | loss:4.2223 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-217.7505 | logitMax:-197.0081 | windowWeightsW25:0.583,W21:0.288,W16:0.213,W19:0.207,W13:0.197,W2:0.162,W9:0.079,W3:-0.345,W4:-0.411 | memoryGatesShort:9.529, Long:-10.771, Current:2.243 | topTokens[(',', 163), ('Ġthe', 104), ('Ġand', 92), ('Ġi', 91), ('.', 73), ('Ġto', 71), ('Ġin', 44), ('s', 40), ('Ġis', 36), ('Ġbut', 35)] | Token Perfect: 40801 / 180000 → 22.67% | babyLLM.py 10000
2025-04-08 03:40:53 | 190000 | LR0.0003 | loss:4.3820 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-210.0984 | logitMax:-190.0737 | windowWeightsW25:0.611,W21:0.283,W2:0.193,W19:0.192,W16:0.163,W13:0.152,W9:0.065,W3:-0.305,W4:-0.383 | memoryGatesShort:10.424, Long:-11.746, Current:2.322 | topTokens[('Ġi', 170), (',', 150), ('.', 119), ('Ġto', 108), ('Ġyou', 79), ('?', 70), ('Ġthe', 63), ('Ġand', 56), ('Ġa', 47), ('Ġit', 43)] | Token Perfect: 32699 / 180000 → 18.17% | babyLLM.py 10000
2025-04-08 04:01:22 | 200000 | LR0.0003 | loss:4.2023 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-228.6651 | logitMax:-208.8313 | windowWeightsW25:0.555,W21:0.259,W13:0.204,W19:0.192,W16:0.184,W2:0.156,W9:0.094,W3:-0.309,W4:-0.361 | memoryGatesShort:9.132, Long:-10.290, Current:2.158 | topTokens[(',', 273), ('.', 83), ('Ġto', 81), ('Ġa', 72), ('Ġi', 70), ('Ġthe', 67), ('Ġit', 62), ('Ġand', 61), ('Ġin', 46), ('Ġof', 46)] | Token Perfect: 35640 / 180000 → 19.80% | babyLLM.py 10000
2025-04-08 04:21:56 | 210000 | LR0.0003 | loss:3.3366 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-226.8735 | logitMax:-205.0731 | windowWeightsW25:0.527,W21:0.232,W13:0.216,W16:0.185,W19:0.176,W2:0.157,W9:0.114,W3:-0.288,W4:-0.345 | memoryGatesShort:15.023, Long:-15.908, Current:1.885 | topTokens[('Ġto', 126), (',', 124), ('.', 110), ('Ġi', 87), ('Ġthe', 68), ('Ġa', 64), ('!', 61), ('?', 57), ('Ġmusic', 51), ('Ġlistening', 44)] | Token Perfect: 59642 / 180000 → 33.13% | babyLLM.py 10000
2025-04-08 04:42:15 | 220000 | LR0.0003 | loss:3.4737 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-203.4704 | logitMax:-180.6025 | windowWeightsW25:0.458,W21:0.213,W16:0.182,W13:0.174,W2:0.173,W19:0.156,W9:0.142,W3:-0.236,W4:-0.285 | memoryGatesShort:37.930, Long:-42.706, Current:5.775 | topTokens[('?', 152), ('.', 149), ('Ġto', 119), ('Ġas', 114), ('Ġyou', 108), ('Ġi', 101), (',', 91), ('Ġis', 73), ('Ġmuch', 57), ('Ġwhat', 51)] | Token Perfect: 58470 / 180000 → 32.48% | babyLLM.py 10000
2025-04-08 05:02:35 | 230000 | LR0.0003 | loss:4.1239 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-236.5577 | logitMax:-216.2195 | windowWeightsW25:0.433,W21:0.223,W16:0.202,W13:0.190,W19:0.176,W2:0.135,W9:0.132,W3:-0.247,W4:-0.266 | memoryGatesShort:8.461, Long:-10.023, Current:2.562 | topTokens[(',', 182), ('Ġthe', 105), ('.', 99), ('Ġi', 90), ('Ġa', 80), ('Ġto', 63), ('Ġit', 57), ("'", 54), ('Ġand', 39), ('Ġyou', 37)] | Token Perfect: 42087 / 180000 → 23.38% | babyLLM.py 10000
2025-04-08 05:22:59 | 240000 | LR0.0003 | loss:3.0987 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-226.5960 | logitMax:-203.1811 | windowWeightsW25:0.403,W13:0.199,W21:0.191,W16:0.188,W9:0.158,W2:0.150,W19:0.133,W3:-0.215,W4:-0.228 | memoryGatesShort:9.556, Long:-9.911, Current:1.355 | topTokens[('.', 150), ('Ġas', 110), (':', 94), ('Ġi', 90), (',', 84), ('Ġto', 84), ('?', 81), ('Ġ-', 80), ('0', 63), ('Ġa', 62)] | Token Perfect: 68963 / 180000 → 38.31% | babyLLM.py 10000
2025-04-08 05:43:22 | 250000 | LR0.0003 | loss:4.9685 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-250.8262 | logitMax:-231.2932 | windowWeightsW25:0.533,W21:0.258,W16:0.192,W13:0.175,W19:0.165,W2:0.155,W9:0.096,W3:-0.283,W4:-0.316 | memoryGatesShort:10.227, Long:-11.827, Current:2.599 | topTokens[(',', 224), ('Ġi', 160), ('.', 159), ('Ġyou', 69), ('Ġand', 64), ('Ġit', 59), ('Ġthe', 56), ('Ġto', 55), ('Ġthat', 40), ('Ġme', 40)] | Token Perfect: 22704 / 180000 → 12.61% | babyLLM.py 10000
2025-04-08 06:03:45 | 260000 | LR0.0003 | loss:3.8991 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-241.6540 | logitMax:-220.8425 | windowWeightsW25:0.515,W21:0.253,W13:0.177,W2:0.177,W16:0.170,W19:0.147,W9:0.118,W3:-0.266,W4:-0.316 | memoryGatesShort:9.036, Long:-10.506, Current:2.470 | topTokens[('.', 168), ('Ġthe', 131), ('Ġto', 95), ('Ġa', 74), ('?', 71), (',', 70), ('Ġi', 66), ('s', 52), ('Ġof', 42), ('Ġis', 37)] | Token Perfect: 45367 / 180000 → 25.20% | babyLLM.py 10000
2025-04-08 06:24:08 | 270000 | LR0.0003 | loss:4.6980 | gradNorm:0.9996 | tokenCount:180000.0000 | logitMin:-249.4159 | logitMax:-229.3155 | windowWeightsW25:0.571,W21:0.268,W2:0.179,W16:0.174,W19:0.155,W13:0.153,W9:0.088,W3:-0.276,W4:-0.339 | memoryGatesShort:10.079, Long:-11.133, Current:2.055 | topTokens[('.', 222), ('Ġi', 155), (',', 127), ('Ġto', 76), ('Ġa', 62), ('?', 58), ('Ġyou', 55), ('Ġthe', 49), ('Ġit', 47), ('Ġand', 46)] | Token Perfect: 27642 / 180000 → 15.36% | babyLLM.py 10000
2025-04-08 06:44:39 | 280000 | LR0.0003 | loss:4.0381 | gradNorm:0.9970 | tokenCount:180000.0000 | logitMin:-263.9675 | logitMax:-242.8348 | windowWeightsW25:0.467,W21:0.243,W16:0.201,W13:0.180,W19:0.166,W2:0.136,W9:0.109,W3:-0.243,W4:-0.282 | memoryGatesShort:9.282, Long:-11.032, Current:2.750 | topTokens[(',', 163), ('Ġthe', 117), ('.', 95), ('Ġi', 95), ('Ġto', 74), ('Ġand', 66), ('Ġa', 62), ('s', 49), ('er', 40), ('Ġthat', 37)] | Token Perfect: 42387 / 180000 → 23.55% | babyLLM.py 10000
2025-04-08 07:05:03 | 290000 | LR0.0003 | loss:4.4258 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-273.8230 | logitMax:-253.1535 | windowWeightsW25:0.523,W21:0.266,W16:0.185,W19:0.163,W2:0.157,W13:0.152,W9:0.091,W3:-0.260,W4:-0.302 | memoryGatesShort:15.639, Long:-18.833, Current:4.193 | topTokens[(',', 221), ('Ġi', 174), ('.', 97), ('Ġto', 86), ('Ġand', 67), ('Ġthe', 58), ('Ġit', 50), ('Ġyou', 49), ('?', 47), ('s', 46)] | Token Perfect: 31773 / 180000 → 17.65% | babyLLM.py 10000
2025-04-08 07:25:28 | 300000 | LR0.0003 | loss:4.0159 | gradNorm:0.9927 | tokenCount:180000.0000 | logitMin:-279.2052 | logitMax:-257.3127 | windowWeightsW25:0.543,W21:0.274,W16:0.169,W2:0.164,W19:0.162,W13:0.147,W9:0.072,W3:-0.260,W4:-0.296 | memoryGatesShort:13.948, Long:-16.647, Current:3.698 | topTokens[('<UNK>', 235), ('.', 141), ('Ġi', 128), (',', 100), ('Ġthe', 59), ('Ġto', 56), ('?', 54), ('Ġit', 50), ('Ġand', 46), ('Ġyou', 45)] | Token Perfect: 44633 / 180000 → 24.80% | babyLLM.py 10000
2025-04-08 07:45:56 | 310000 | LR0.0003 | loss:3.7923 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-290.5095 | logitMax:-268.2793 | windowWeightsW25:0.547,W21:0.288,W19:0.190,W16:0.189,W2:0.149,W13:0.148,W9:0.063,W3:-0.273,W4:-0.325 | memoryGatesShort:12.893, Long:-14.563, Current:2.670 | topTokens[('.', 232), (',', 104), ('Ġi', 84), ('Ġto', 72), ('Ġthe', 69), ('Ġmust', 68), ('Ġand', 65), ('Ġa', 43), ('!', 40), ('Ġin', 34)] | Token Perfect: 47827 / 180000 → 26.57% | babyLLM.py 10000
2025-04-08 08:06:31 | 320000 | LR0.0003 | loss:2.9695 | gradNorm:0.9996 | tokenCount:180000.0000 | logitMin:-264.1057 | logitMax:-238.9777 | windowWeightsW25:0.478,W21:0.233,W16:0.218,W13:0.174,W19:0.170,W2:0.166,W9:0.093,W3:-0.261,W4:-0.295 | memoryGatesShort:10.355, Long:-11.453, Current:2.098 | topTokens[(':', 118), ('Ġ-', 112), ('Ġi', 111), (',', 97), ("Ġ'", 92), ("'", 92), ('.', 88), ('0', 79), ('4', 62), ('Ġto', 58)] | Token Perfect: 75897 / 180000 → 42.16% | babyLLM.py 10000
2025-04-08 08:27:02 | 330000 | LR0.0003 | loss:3.9089 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-308.6555 | logitMax:-287.0244 | windowWeightsW25:0.486,W21:0.258,W16:0.229,W13:0.198,W19:0.178,W2:0.128,W9:0.086,W3:-0.282,W4:-0.303 | memoryGatesShort:8.861, Long:-9.749, Current:1.888 | topTokens[('.', 139), ('Ġi', 105), ('Ġa', 91), (',', 81), ('Ġthe', 78), ('Ġto', 74), ('Ġit', 50), ('Ġyou', 47), ('Ġand', 38), ('s', 35)] | Token Perfect: 45599 / 180000 → 25.33% | babyLLM.py 10000
2025-04-08 08:47:40 | 340000 | LR0.0003 | loss:4.1027 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-305.5354 | logitMax:-284.3147 | windowWeightsW25:0.556,W21:0.269,W16:0.191,W19:0.160,W2:0.159,W13:0.158,W9:0.055,W3:-0.242,W4:-0.331 | memoryGatesShort:18.331, Long:-20.862, Current:3.532 | topTokens[('.', 283), ('?', 176), ('Ġi', 104), ('Ġis', 94), ('Ġyou', 94), ('!', 72), (',', 69), ('Ġa', 55), ('Ġare', 49), ('Ġwhat', 49)] | Token Perfect: 38328 / 180000 → 21.29% | babyLLM.py 10000
2025-04-08 09:08:05 | 350000 | LR0.0003 | loss:3.3677 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-291.7883 | logitMax:-269.2905 | windowWeightsW25:0.414,W16:0.235,W21:0.228,W13:0.184,W19:0.180,W2:0.131,W9:0.105,W3:-0.223,W4:-0.276 | memoryGatesShort:6.828, Long:-7.706, Current:1.879 | topTokens[('.', 132), (':', 104), ('Ġi', 79), ('Ġ-', 78), ('Ġthe', 72), (',', 64), ('3', 63), ('0', 60), ('!', 54), ('-', 54)] | Token Perfect: 60785 / 180000 → 33.77% | babyLLM.py 10000
2025-04-08 09:28:33 | 360000 | LR0.0003 | loss:3.7017 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-331.3097 | logitMax:-308.2080 | windowWeightsW25:0.518,W21:0.290,W16:0.225,W19:0.201,W13:0.154,W2:0.134,W9:0.052,W3:-0.255,W4:-0.343 | memoryGatesShort:27.430, Long:-32.385, Current:5.955 | topTokens[('.', 171), (',', 124), ('Ġit', 113), ('Ġi', 100), ('!', 97), ('Ġthe', 70), ('Ġand', 70), ('Ġof', 59), ('Ġa', 56), ('Ġto', 46)] | Token Perfect: 49294 / 180000 → 27.39% | babyLLM.py 10000
2025-04-08 09:49:00 | 370000 | LR0.0003 | loss:2.5908 | gradNorm:0.9994 | tokenCount:180000.0000 | logitMin:-333.3766 | logitMax:-306.8306 | windowWeightsW25:0.489,W21:0.280,W16:0.230,W19:0.199,W13:0.165,W2:0.130,W9:0.049,W3:-0.236,W4:-0.329 | memoryGatesShort:8.048, Long:-8.390, Current:1.342 | topTokens[('.', 152), ('Ġhave', 140), ('Ġwill', 135), ('!', 94), ('Ġfelt', 82), ('Ġyou', 75), ('Ġthe', 73), (',', 69), ('Ġand', 62), ('Ġi', 56)] | Token Perfect: 81015 / 180000 → 45.01% | babyLLM.py 10000
2025-04-08 10:09:25 | 380000 | LR0.0003 | loss:2.8762 | gradNorm:0.9998 | tokenCount:180000.0000 | logitMin:-342.4369 | logitMax:-316.7737 | windowWeightsW25:0.540,W21:0.283,W16:0.211,W19:0.207,W13:0.176,W2:0.137,W9:0.047,W3:-0.264,W4:-0.362 | memoryGatesShort:14.362, Long:-16.997, Current:3.634 | topTokens[('.', 127), (':', 111), ("Ġ'", 86), ('Ġ-', 85), ("'", 82), ('Ġi', 76), (',', 69), ('Ġthe', 60), ('00', 57), ('Ġa', 47)] | Token Perfect: 76744 / 180000 → 42.64% | babyLLM.py 10000
2025-04-08 10:29:54 | 390000 | LR0.0003 | loss:3.9131 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-318.9459 | logitMax:-295.8316 | windowWeightsW25:0.642,W21:0.320,W19:0.223,W16:0.201,W2:0.161,W13:0.158,W9:0.008,W3:-0.303,W4:-0.436 | memoryGatesShort:10.074, Long:-11.148, Current:2.075 | topTokens[('.', 167), ('Ġi', 122), (',', 111), ('Ġto', 84), ('?', 73), ('Ġmust', 73), ('Ġa', 71), ('Ġthe', 70), ('Ġhave', 66), ('Ġyou', 55)] | Token Perfect: 48565 / 180000 → 26.98% | babyLLM.py 10000
2025-04-08 10:50:51 | 400000 | LR0.0003 | loss:4.2271 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-337.7848 | logitMax:-316.1184 | windowWeightsW25:0.693,W21:0.342,W19:0.263,W16:0.224,W2:0.185,W13:0.153,W9:-0.030,W3:-0.352,W4:-0.508 | memoryGatesShort:12.619, Long:-14.618, Current:2.998 | topTokens[(',', 244), ('Ġi', 89), ('Ġcan', 73), ('Ġthe', 68), ('Ġand', 60), ('Ġto', 56), ('Ġa', 54), ('.', 54), ('Ġit', 43), ('!', 41)] | Token Perfect: 37361 / 180000 → 20.76% | babyLLM.py 10000
2025-04-08 11:11:47 | 410000 | LR0.0003 | loss:2.8490 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-391.4773 | logitMax:-366.7237 | windowWeightsW25:0.568,W21:0.317,W19:0.259,W16:0.239,W13:0.181,W2:0.134,W9:0.019,W3:-0.311,W4:-0.430 | memoryGatesShort:7.503, Long:-8.249, Current:1.746 | topTokens[(',', 161), ('Ġthe', 109), ('.', 102), ('Ġi', 83), ('Ġto', 76), ('Ġit', 62), ('Ġa', 59), ('s', 55), ('Ġand', 48), ('!', 46)] | Token Perfect: 68339 / 180000 → 37.97% | babyLLM.py 10000
2025-04-08 11:32:34 | 420000 | LR0.0003 | loss:2.7056 | gradNorm:0.9997 | tokenCount:180000.0000 | logitMin:-308.3694 | logitMax:-280.5234 | windowWeightsW25:0.628,W21:0.325,W19:0.252,W16:0.239,W2:0.175,W13:0.165,W9:0.001,W3:-0.343,W4:-0.469 | memoryGatesShort:12.657, Long:-13.872, Current:2.215 | topTokens[('.', 178), (',', 138), ('!', 100), ('Ġhad', 96), ('Ġthe', 92), ('Ġwas', 78), ('Ġcharis', 72), ('Ġi', 70), ('Ġwere', 59), ('Ġit', 53)] | Token Perfect: 77830 / 180000 → 43.24% | babyLLM.py 10000
2025-04-08 11:54:29 | 430000 | LR0.0003 | loss:2.9110 | gradNorm:0.9995 | tokenCount:180000.0000 | logitMin:-309.3027 | logitMax:-282.8924 | windowWeightsW25:0.633,W21:0.326,W19:0.252,W16:0.246,W2:0.204,W13:0.173,W9:0.002,W3:-0.360,W4:-0.503 | memoryGatesShort:18.799, Long:-20.808, Current:3.009 | topTokens[(',', 218), ('Ġi', 105), ('!', 87), ('Ġthe', 86), ('Ġit', 82), ('Ġbeen', 64), ('Ġto', 60), ('.', 59), (':', 54), ('Ġand', 50)] | Token Perfect: 72221 / 180000 → 40.12% | babyLLM.py 10000
2025-04-08 12:15:20 | 440000 | LR0.0003 | loss:3.6996 | gradNorm:0.9993 | tokenCount:180000.0000 | logitMin:-326.3312 | logitMax:-302.2030 | windowWeightsW25:0.690,W21:0.354,W19:0.274,W16:0.264,W2:0.192,W13:0.173,W9:-0.035,W3:-0.398,W4:-0.543 | memoryGatesShort:14.004, Long:-16.505, Current:3.500 | topTokens[('.', 204), (',', 126), ('Ġi', 116), ('Ġand', 98), ('Ġit', 60), ('Ġyou', 58), ('Ġto', 56), ('Ġa', 55), ('s', 54), ("'s", 48)] | Token Perfect: 54209 / 180000 → 30.12% | babyLLM.py 10000

--- 2025-04-08 13:39:19 --- babyLLM 'right, last time i got to step 442180... want to restart from there?'  - charis: 'no, restart please' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: 'well, i feel like... i dont know anymore. you're so fucking fast these days.'
2025-04-08 14:01:12 | 10000 | LR0.0003 | loss:4.8231 | gradNorm:1.0000 | logitMin:-339.6893 | logitMax:-317.9199 | tokenCount:180000.0000 | windowWeightsW25:0.918,W21:0.415,W19:0.305,W16:0.260,W2:0.230,W13:0.173,W9:-0.109,W3:-0.493,W4:-0.735 | memoryGatesShort:13.501, Long:-14.904, Current:2.402 | topTokens[('.', 311), (',', 164), ('Ġi', 155), ('Ġa', 58), ('Ġto', 53), ('Ġand', 52), ('Ġit', 51), ('Ġyou', 47), ('?', 41), ('y', 35)] | Token Perfect: 28678 / 180000 → 15.93% | babyLLM.py 10000

--- 2025-04-08 14:43:54 --- babyLLM 'right, last time i got to step 14802... want to restart from there?'  - charis: 'y' - babyLLM 'ok! let's go to step 14802! what am i learning today?' - charis: 'how to pass your exams in 'oh my god no''
2025-04-08 15:05:46 | 10000 | LR0.0003 | loss:3.9843 | gradNorm:1.0000 | logitMin:-334.2912 | logitMax:-311.5010 | tokenCount:180000.0000 | windowWeightsW25:0.724,W21:0.345,W19:0.266,W16:0.266,W2:0.175,W13:0.156,W9:-0.025,W3:-0.395,W4:-0.543 | memoryGatesShort:11.068, Long:-12.054, Current:1.986 | topTokens[('.', 175), ('?', 141), (',', 116), ('Ġi', 112), ('Ġyou', 99), ('Ġis', 77), ('Ġto', 71), ('Ġthe', 62), ('Ġwhat', 51), ('Ġa', 45)] | Token Perfect: 43715 / 180000 → 24.29% | babyLLM.py 10000
2025-04-08 15:27:33 | 20000 | LR0.0003 | loss:4.0412 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-368.8122 | logitMax:-346.7184 | windowWeightsW25:0.674,W21:0.337,W16:0.264,W19:0.260,W13:0.181,W2:0.163,W9:-0.015,W3:-0.365,W4:-0.527 | memoryGatesShort:14.761, Long:-16.099, Current:2.338 | topTokens[(',', 295), ('Ġi', 105), ('.', 76), ('Ġthe', 63), ('Ġit', 57), ('Ġa', 55), ('Ġand', 52), ('Ġto', 50), ('Ġin', 44), ('Ġof', 34)] | Token Perfect: 43044 / 180000 → 23.91% | babyLLM.py 10000

--- 2025-04-08 15:53:52 --- babyLLM 'right, last time i got to step 143... want to restart from there?'  - charis: '8000' - babyLLM 'damn that's specific! heading to step 8000... what am i learning today?' - charis: 'jhgf'
2025-04-08 16:16:27 | 10000 | LR0.0003 | loss:4.0237 | gradNorm:0.9814 | logitMin:-346.2632 | logitMax:-322.6538 | tokenCount:180000.0000 | windowWeightsW25:0.708,W21:0.339,W19:0.261,W16:0.233,W13:0.185,W2:0.173,W9:-0.052,W3:-0.370,W4:-0.508 | memoryGatesShort:11.465, Long:-12.089, Current:1.624 | topTokens[(',', 157), ('.', 153), ('Ġi', 152), ('Ġyou', 91), ('Ġand', 87), ('Ġthe', 67), ('Ġto', 63), ('Ġthat', 52), ('s', 51), ('Ġa', 50)] | Token Perfect: 50848 / 180000 → 28.25% | babyLLM.py 10000
2025-04-08 16:39:24 | 20000 | LR0.0003 | loss:4.5121 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-361.9210 | logitMax:-340.5502 | windowWeightsW25:0.676,W21:0.308,W19:0.242,W16:0.232,W13:0.183,W2:0.177,W9:-0.032,W3:-0.339,W4:-0.476 | memoryGatesShort:11.197, Long:-12.837, Current:2.640 | topTokens[(',', 214), ('Ġi', 109), ('.', 96), ('Ġand', 80), ('Ġa', 70), ('Ġto', 58), ('s', 54), ('Ġthe', 50), ('3', 36), ('Ġyou', 34)] | Token Perfect: 33862 / 180000 → 18.81% | babyLLM.py 10000
2025-04-08 17:01:38 | 30000 | LR0.0003 | loss:3.2132 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-428.5348 | logitMax:-405.2592 | windowWeightsW25:0.676,W21:0.340,W19:0.268,W16:0.258,W13:0.167,W2:0.139,W9:-0.020,W3:-0.372,W4:-0.484 | memoryGatesShort:10.487, Long:-11.219, Current:1.732 | topTokens[('.', 127), (',', 115), ('Ġto', 89), ('Ġi', 84), ('Ġthe', 81), ('?', 74), ('Ġa', 62), ('Ġof', 52), ('Ġyou', 50), ('Ġis', 48)] | Token Perfect: 57644 / 180000 → 32.02% | babyLLM.py 10000
2025-04-08 17:23:40 | 40000 | LR0.0003 | loss:3.8707 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-382.3704 | logitMax:-358.9380 | windowWeightsW25:0.761,W21:0.360,W19:0.280,W16:0.229,W2:0.195,W13:0.149,W9:-0.068,W3:-0.386,W4:-0.552 | memoryGatesShort:11.852, Long:-13.507, Current:2.654 | topTokens[('.', 179), ('Ġi', 102), ('Ġthe', 94), ('Ġto', 85), ('?', 82), (',', 76), ('Ġa', 57), ('Ġyou', 51), ('!', 51), ('s', 48)] | Token Perfect: 50250 / 180000 → 27.92% | babyLLM.py 10000
2025-04-08 17:46:02 | 50000 | LR0.0003 | loss:3.7269 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-383.8372 | logitMax:-360.8040 | windowWeightsW25:0.694,W21:0.332,W19:0.249,W16:0.221,W2:0.191,W13:0.171,W9:-0.018,W3:-0.365,W4:-0.503 | memoryGatesShort:10.959, Long:-12.122, Current:2.163 | topTokens[(',', 252), ('.', 120), ('Ġi', 115), ('Ġto', 72), ('?', 63), ('Ġthe', 48), ('Ġit', 47), ('Ġand', 45), ('Ġof', 44), ('s', 44)] | Token Perfect: 51106 / 180000 → 28.39% | babyLLM.py 10000
2025-04-08 18:06:51 | 60000 | LR0.0003 | loss:4.0580 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-384.3422 | logitMax:-361.5631 | windowWeightsW25:0.755,W21:0.382,W19:0.276,W16:0.250,W13:0.188,W2:0.184,W9:-0.052,W3:-0.440,W4:-0.574 | memoryGatesShort:13.809, Long:-15.200, Current:2.391 | topTokens[(',', 226), ('.', 113), ('Ġmust', 80), ('Ġthe', 78), ('Ġi', 76), ('Ġa', 67), ('!', 47), ('Ġand', 42), ('Ġto', 41), ('Ġelodie', 39)] | Token Perfect: 43002 / 180000 → 23.89% | babyLLM.py 10000
2025-04-08 18:27:29 | 70000 | LR0.0003 | loss:3.4615 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-380.7547 | logitMax:-356.8582 | windowWeightsW25:0.799,W21:0.345,W2:0.258,W16:0.251,W19:0.222,W13:0.185,W9:-0.052,W3:-0.426,W4:-0.616 | memoryGatesShort:14.937, Long:-15.375, Current:1.438 | topTokens[('.', 158), ('Ġto', 156), ('Ġi', 136), ('?', 96), ('Ġyou', 75), ('Ġlistening', 68), ('Ġmusic', 62), (',', 61), ('Ġthe', 55), ('Ġwhat', 51)] | Token Perfect: 57324 / 180000 → 31.85% | babyLLM.py 10000

--- 2025-04-08 18:43:06 --- babyLLM 'right, last time i got to step 75447... want to restart from there?'  - charis: 'no, i grabbed you some new data so we shoud look at the start!' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: 'i found more of my chaotic poetry hahaha, i also set your windows just sliiightly differently - i hope you like it!!'
2025-04-08 19:04:05 | 10000 | LR0.0003 | loss:4.0289 | gradNorm:0.9864 | logitMin:-400.1509 | logitMax:-376.8269 | scheduledSampling:0.0000 | tokenCount:180000.0000 | windowWeightsW25:0.859,W21:0.404,W16:0.268,W2:0.249,W19:0.241,W9:0.134,W13:-0.031,W3:-0.487,W5:-0.673 | memoryGatesShort:14.959, Long:-16.151, Current:2.192 | topTokens[('.', 155), (',', 150), ('Ġi', 93), ('Ġto', 83), ('Ġand', 79), ('Ġshe', 66), ('Ġthe', 65), ('Ġa', 58), ('Ġyou', 52), ('Ġit', 51)] | Token Perfect: 51039 / 180000 → 28.36% | babyLLM.py 10000
2025-04-08 19:25:38 | 20000 | LR0.0003 | loss:3.6056 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-395.7220 | logitMax:-372.7578 | windowWeightsW25:0.764,W21:0.386,W16:0.278,W19:0.253,W2:0.185,W9:0.101,W13:0.021,W3:-0.434,W5:-0.584 | memoryGatesShort:14.073, Long:-15.098, Current:2.025 | topTokens[('.', 139), (',', 123), ('Ġthe', 112), ('Ġto', 75), ('Ġcould', 74), ('Ġa', 72), ('Ġi', 65), ('!', 55), ('Ġand', 44), ('Ġof', 44)] | Token Perfect: 51299 / 180000 → 28.50% | babyLLM.py 10000
2025-04-08 19:47:15 | 30000 | LR0.0003 | loss:4.1831 | gradNorm:0.9955 | tokenCount:180000.0000 | logitMin:-409.8387 | logitMax:-387.1885 | windowWeightsW25:0.822,W21:0.408,W16:0.284,W19:0.261,W2:0.216,W9:0.037,W13:0.027,W3:-0.444,W5:-0.645 | memoryGatesShort:14.464, Long:-15.559, Current:2.096 | topTokens[(',', 178), ('.', 114), ('Ġi', 97), ('Ġthe', 88), ('Ġto', 75), ('Ġa', 57), ('Ġand', 52), ('Ġit', 42), ('ing', 40), ('s', 39)] | Token Perfect: 42594 / 180000 → 23.66% | babyLLM.py 10000
2025-04-08 20:08:04 | 40000 | LR0.0003 | loss:3.1827 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-393.7130 | logitMax:-369.1416 | windowWeightsW25:0.663,W21:0.354,W16:0.305,W19:0.218,W2:0.210,W13:0.099,W9:0.080,W3:-0.402,W5:-0.556 | memoryGatesShort:15.404, Long:-16.925, Current:2.521 | topTokens[(',', 171), ('Ġi', 108), ('Ġ-', 94), (':', 82), ('Ġto', 65), ("Ġ'", 62), ('Ġa', 61), ('.', 60), ("'", 58), ('Ġthe', 51)] | Token Perfect: 66413 / 180000 → 36.90% | babyLLM.py 10000
2025-04-08 20:28:39 | 50000 | LR0.0003 | loss:3.1378 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-421.6467 | logitMax:-397.6043 | windowWeightsW25:0.596,W21:0.331,W16:0.312,W19:0.216,W2:0.174,W13:0.125,W9:0.087,W3:-0.366,W5:-0.502 | memoryGatesShort:11.695, Long:-12.681, Current:1.986 | topTokens[('Ġthe', 141), ('Ġi', 109), ('.', 103), ('Ġto', 92), (',', 79), ('Ġa', 51), ('Ġand', 48), ('Ġwas', 40), ('Ġof', 37), ('ed', 35)] | Token Perfect: 65088 / 180000 → 36.16% | babyLLM.py 10000
2025-04-08 20:49:21 | 60000 | LR0.0003 | loss:4.1745 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-426.6696 | logitMax:-403.9269 | windowWeightsW25:0.732,W21:0.378,W16:0.295,W19:0.232,W2:0.196,W13:0.102,W9:0.066,W3:-0.433,W5:-0.599 | memoryGatesShort:22.253, Long:-24.557, Current:3.304 | topTokens[(',', 294), ('Ġi', 156), ('Ġthe', 84), ('.', 68), ('Ġyou', 58), ('Ġa', 52), ('Ġand', 51), ('Ġthat', 51), ('Ġto', 50), ('s', 48)] | Token Perfect: 41964 / 180000 → 23.31% | babyLLM.py 10000

--- 2025-04-08 21:11:38 --- babyLLM 'right, last time i got to step 63411... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 63411! what am i learning today?' - charis: ''
2025-04-08 21:32:21 | 10000 | LR0.0003 | loss:3.9180 | gradNorm:0.9941 | logitMin:-410.3838 | logitMax:-386.8140 | scheduledSampling:0.0000 | tokenCount:180000.0000 | windowWeightsW25:0.767,W21:0.378,W16:0.282,W2:0.231,W19:0.209,W13:0.100,W9:0.044,W3:-0.424,W5:-0.620 | memoryGatesShort:12.246, Long:-13.584, Current:2.337 | topTokens[(',', 190), ('Ġi', 116), ('Ġthe', 108), ('Ġto', 91), ('.', 85), ('Ġand', 64), ('Ġa', 47), ('ing', 43), ('Ġit', 41), ('Ġyou', 41)] | Token Perfect: 49165 / 180000 → 27.31% | babyLLM.py 10000
2025-04-08 21:52:43 | 20000 | LR0.0003 | loss:3.7270 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-415.3690 | logitMax:-392.0287 | windowWeightsW25:0.897,W21:0.461,W16:0.291,W2:0.250,W19:0.244,W13:0.123,W9:0.003,W3:-0.554,W5:-0.751 | memoryGatesShort:13.716, Long:-14.944, Current:2.228 | topTokens[(',', 244), ('Ġwould', 116), ('Ġi', 102), ('!', 94), ('Ġthe', 81), ('Ġand', 65), ('Ġto', 59), ('.', 54), ('Ġa', 47), ('Ġcharis', 44)] | Token Perfect: 49435 / 180000 → 27.46% | babyLLM.py 10000
2025-04-08 22:13:33 | 30000 | LR0.0003 | loss:3.7474 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-403.3770 | logitMax:-379.3908 | windowWeightsW25:1.070,W21:0.530,W2:0.340,W16:0.306,W19:0.257,W13:0.096,W9:-0.050,W3:-0.681,W5:-0.911 | memoryGatesShort:17.464, Long:-18.787, Current:2.323 | topTokens[('.', 169), ('Ġshould', 159), (',', 109), ('!', 100), ('Ġand', 85), ('Ġto', 83), ('Ġi', 81), ('Ġthe', 72), ('Ġelodie', 55), ('Ġcharis', 54)] | Token Perfect: 47328 / 180000 → 26.29% | babyLLM.py 10000
2025-04-08 22:34:48 | 40000 | LR0.0003 | loss:3.5287 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-467.2240 | logitMax:-444.2715 | windowWeightsW25:0.875,W21:0.479,W16:0.328,W19:0.281,W2:0.203,W13:0.152,W9:0.004,W3:-0.596,W5:-0.760 | memoryGatesShort:13.133, Long:-13.729, Current:1.597 | topTokens[(',', 270), ('.', 96), ('Ġthe', 87), ('Ġa', 79), ('Ġi', 75), ('Ġto', 59), ('Ġand', 56), ('Ġyou', 50), ('Ġof', 48), ('Ġit', 42)] | Token Perfect: 50617 / 180000 → 28.12% | babyLLM.py 10000
2025-04-08 22:55:23 | 50000 | LR0.0003 | loss:2.4951 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-411.6832 | logitMax:-383.9961 | windowWeightsW25:0.814,W21:0.442,W16:0.322,W2:0.272,W19:0.238,W13:0.139,W9:0.039,W3:-0.557,W5:-0.744 | memoryGatesShort:10.807, Long:-11.486, Current:1.678 | topTokens[('Ġhad', 206), (',', 153), ('.', 150), ('Ġfelt', 126), ('!', 97), ('Ġthe', 86), ('Ġi', 70), ('Ġand', 53), ('Ġelodie', 53), ('Ġto', 52)] | Token Perfect: 78383 / 180000 → 43.55% | babyLLM.py 10000
2025-04-08 23:16:33 | 60000 | LR0.0003 | loss:2.2260 | gradNorm:0.9975 | tokenCount:180000.0000 | logitMin:-532.2600 | logitMax:-504.0334 | windowWeightsW25:0.689,W21:0.375,W16:0.308,W19:0.237,W2:0.225,W13:0.198,W9:0.067,W3:-0.480,W5:-0.651 | memoryGatesShort:8.162, Long:-8.302, Current:1.140 | topTokens[(',', 201), ('.', 99), ('Ġthe', 94), ('Ġa', 91), ('Ġof', 56), ('Ġto', 55), ('Ġit', 50), ('Ġi', 50), ('Ġand', 42), ('ed', 42)] | Token Perfect: 91334 / 180000 → 50.74% | babyLLM.py 10000
2025-04-08 23:38:40 | 70000 | LR0.0003 | loss:4.2937 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-488.4279 | logitMax:-461.2927 | windowWeightsW25:0.976,W21:0.489,W16:0.327,W19:0.288,W2:0.262,W13:0.190,W9:-0.005,W3:-0.666,W5:-0.901 | memoryGatesShort:11.349, Long:-11.657, Current:1.308 | topTokens[(',', 210), ('Ġi', 156), ('.', 137), ('Ġ-', 58), (':', 53), ('Ġto', 49), ('Ġit', 48), ('7', 48), ('1', 47), ('Ġthe', 46)] | Token Perfect: 48668 / 180000 → 27.04% | babyLLM.py 10000
2025-04-09 00:00:41 | 80000 | LR0.0003 | loss:3.6535 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-426.5156 | logitMax:-401.1130 | windowWeightsW25:0.994,W21:0.499,W16:0.345,W2:0.332,W19:0.300,W13:0.179,W9:-0.025,W3:-0.712,W5:-0.954 | memoryGatesShort:14.372, Long:-14.563, Current:1.190 | topTokens[('.', 131), ('Ġthe', 101), (',', 97), ('Ġi', 87), (':', 79), ('Ġ-', 65), ('Ġto', 62), ('Ġa', 51), ("Ġ'", 47), ('Ġis', 46)] | Token Perfect: 55867 / 180000 → 31.04% | babyLLM.py 10000
2025-04-09 00:23:12 | 90000 | LR0.0003 | loss:2.7424 | gradNorm:0.9998 | tokenCount:180000.0000 | logitMin:-408.7904 | logitMax:-381.5963 | windowWeightsW25:0.803,W21:0.439,W16:0.306,W19:0.306,W2:0.253,W13:0.199,W9:-0.008,W3:-0.570,W5:-0.763 | memoryGatesShort:13.598, Long:-13.552, Current:0.954 | topTokens[('Ġwill', 170), ('Ġhave', 153), ('.', 148), (',', 125), ('Ġi', 101), ('Ġfelt', 99), ('!', 87), ('Ġthe', 70), ('Ġyou', 53), ('Ġto', 46)] | Token Perfect: 76203 / 180000 → 42.34% | babyLLM.py 10000
2025-04-09 00:45:10 | 100000 | LR0.0003 | loss:2.1642 | gradNorm:0.9990 | tokenCount:180000.0000 | logitMin:-517.7255 | logitMax:-490.4326 | windowWeightsW25:0.647,W21:0.375,W16:0.277,W19:0.272,W2:0.212,W13:0.208,W9:0.025,W3:-0.448,W5:-0.599 | memoryGatesShort:12.678, Long:-14.279, Current:2.601 | topTokens[(',', 249), ('Ġthe', 118), ('Ġi', 92), ('Ġto', 86), ('Ġa', 64), ('Ġit', 59), ('.', 54), ('Ġand', 49), ('Ġof', 49), ('Ġthat', 48)] | Token Perfect: 91625 / 180000 → 50.90% | babyLLM.py 10000
2025-04-09 01:06:14 | 110000 | LR0.0003 | loss:3.2817 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-392.9727 | logitMax:-361.6769 | windowWeightsW25:0.869,W21:0.449,W19:0.312,W2:0.251,W16:0.247,W13:0.177,W9:-0.035,W3:-0.531,W5:-0.774 | memoryGatesShort:13.011, Long:-13.735, Current:1.723 | topTokens[('Ġhave', 187), ('.', 172), (',', 141), ('Ġyou', 117), ('Ġfelt', 115), ('!', 111), ('Ġmust', 95), ('Ġwould', 93), ('Ġi', 90), ('?', 87)] | Token Perfect: 66410 / 180000 → 36.89% | babyLLM.py 10000
2025-04-09 01:27:48 | 120000 | LR0.0003 | loss:2.3410 | gradNorm:0.9941 | tokenCount:180000.0000 | logitMin:-511.4750 | logitMax:-481.6203 | windowWeightsW25:0.704,W21:0.397,W19:0.267,W16:0.250,W2:0.216,W13:0.210,W9:0.020,W3:-0.455,W5:-0.639 | memoryGatesShort:7.034, Long:-6.761, Current:0.727 | topTokens[(',', 224), ('.', 92), ('Ġthe', 78), ('Ġa', 71), ('Ġand', 61), ('Ġof', 56), (':', 53), ('Ġit', 46), ('Ġin', 43), ('ed', 42)] | Token Perfect: 93745 / 180000 → 52.08% | babyLLM.py 10000
2025-04-09 01:50:03 | 130000 | LR0.0003 | loss:4.0649 | gradNorm:0.9986 | tokenCount:180000.0000 | logitMin:-470.1686 | logitMax:-442.8682 | windowWeightsW25:1.104,W21:0.567,W19:0.347,W2:0.327,W16:0.241,W13:0.154,W9:-0.095,W3:-0.660,W5:-1.028 | memoryGatesShort:16.480, Long:-17.353, Current:1.873 | topTokens[('.', 311), ('Ġis', 110), ('Ġi', 109), (',', 85), ('Ġand', 74), ('Ġare', 66), ('ing', 62), ('!', 57), ('Ġthe', 55), ('Ġcharis', 53)] | Token Perfect: 48662 / 180000 → 27.03% | babyLLM.py 10000
2025-04-09 02:11:37 | 140000 | LR0.0003 | loss:3.3296 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-474.7386 | logitMax:-448.8685 | windowWeightsW25:0.788,W21:0.438,W19:0.312,W16:0.281,W2:0.232,W13:0.224,W9:-0.024,W3:-0.520,W5:-0.763 | memoryGatesShort:113.155, Long:-121.977, Current:9.822 | topTokens[(',', 197), ('.', 111), ('Ġthe', 85), ('Ġand', 73), ('Ġto', 58), ('Ġa', 56), ('Ġof', 55), ('Ġi', 50), ('s', 45), ('Ġin', 41)] | Token Perfect: 63504 / 180000 → 35.28% | babyLLM.py 10000
2025-04-09 02:33:16 | 150000 | LR0.0003 | loss:5.1348 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-456.3291 | logitMax:-432.1448 | windowWeightsW25:1.659,W21:0.774,W19:0.473,W2:0.441,W16:0.347,W13:0.214,W9:-0.249,W3:-1.069,W5:-1.654 | memoryGatesShort:15.022, Long:-16.147, Current:2.126 | topTokens[(',', 285), ('Ġi', 138), ('.', 117), ('Ġa', 72), ('Ġto', 54), ('Ġit', 52), ('Ġthe', 42), ('Ġand', 39), ('Ġyou', 38), ('Ġme', 36)] | Token Perfect: 26011 / 180000 → 14.45% | babyLLM.py 10000
2025-04-09 02:54:45 | 160000 | LR0.0003 | loss:3.9076 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-436.2285 | logitMax:-412.2317 | windowWeightsW25:0.994,W21:0.492,W19:0.341,W16:0.336,W2:0.293,W13:0.220,W9:-0.058,W3:-0.663,W5:-0.995 | memoryGatesShort:8.792, Long:-9.797, Current:2.005 | topTokens[(',', 205), ('.', 110), ('Ġi', 107), ('Ġa', 78), ('!', 68), ('Ġthe', 65), ('Ġit', 55), ('Ġyou', 54), ('Ġto', 50), ('Ġand', 41)] | Token Perfect: 44724 / 180000 → 24.85% | babyLLM.py 10000
2025-04-09 03:16:20 | 170000 | LR0.0003 | loss:3.6560 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-462.2575 | logitMax:-435.9771 | windowWeightsW25:1.109,W21:0.518,W16:0.378,W19:0.362,W2:0.309,W13:0.242,W9:-0.093,W3:-0.750,W5:-1.119 | memoryGatesShort:11.258, Long:-12.128, Current:1.869 | topTokens[(',', 184), ('Ġi', 130), ('Ġto', 95), ('.', 91), ('Ġ-', 68), (':', 62), ("Ġ'", 61), ("'", 59), ('Ġthe', 46), ('Ġa', 41)] | Token Perfect: 60049 / 180000 → 33.36% | babyLLM.py 10000
2025-04-09 03:37:52 | 180000 | LR0.0003 | loss:3.1282 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-442.8298 | logitMax:-415.7894 | windowWeightsW25:0.864,W21:0.459,W16:0.378,W19:0.305,W13:0.253,W2:0.223,W9:-0.021,W3:-0.642,W5:-0.855 | memoryGatesShort:14.039, Long:-15.131, Current:2.092 | topTokens[('Ġi', 135), (',', 102), (':', 88), ('Ġ-', 84), ('.', 81), ('0', 79), ('Ġto', 78), ("'", 71), ('Ġthe', 63), ('-', 61)] | Token Perfect: 71437 / 180000 → 39.69% | babyLLM.py 10000
2025-04-09 03:58:51 | 190000 | LR0.0003 | loss:4.0735 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-454.7079 | logitMax:-430.7621 | windowWeightsW25:0.991,W21:0.443,W13:0.331,W2:0.319,W16:0.294,W19:0.221,W9:-0.077,W3:-0.651,W5:-0.912 | memoryGatesShort:11.874, Long:-13.008, Current:2.134 | topTokens[('Ġi', 178), (',', 154), ('.', 143), ('Ġto', 107), ('?', 95), ('Ġyou', 81), ('Ġthe', 64), ('Ġit', 54), ('Ġa', 54), ('Ġis', 44)] | Token Perfect: 45218 / 180000 → 25.12% | babyLLM.py 10000
2025-04-09 04:20:37 | 200000 | LR0.0003 | loss:3.0956 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-468.1303 | logitMax:-443.5204 | windowWeightsW25:0.703,W21:0.394,W13:0.298,W16:0.282,W19:0.239,W2:0.180,W9:0.004,W3:-0.496,W5:-0.634 | memoryGatesShort:7.035, Long:-7.174, Current:1.139 | topTokens[(',', 174), ('Ġthe', 96), ('.', 79), ('Ġa', 77), ('Ġto', 75), ('Ġi', 74), ('Ġit', 65), ('!', 49), ('Ġand', 47), ('Ġof', 41)] | Token Perfect: 61467 / 180000 → 34.15% | babyLLM.py 10000
2025-04-09 04:42:40 | 210000 | LR0.0003 | loss:3.3322 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-502.1432 | logitMax:-474.4388 | windowWeightsW25:0.885,W21:0.466,W19:0.275,W16:0.274,W13:0.263,W2:0.239,W9:-0.060,W3:-0.567,W5:-0.809 | memoryGatesShort:12.543, Long:-13.744, Current:2.200 | topTokens[('.', 135), ('Ġto', 128), (',', 124), ('Ġi', 79), ('Ġthe', 72), ('Ġa', 67), ('Ġand', 61), ('Ġyou', 43), ('?', 42), ('Ġmusic', 41)] | Token Perfect: 63306 / 180000 → 35.17% | babyLLM.py 10000
2025-04-09 05:04:20 | 220000 | LR0.0003 | loss:3.0904 | gradNorm:0.9998 | tokenCount:180000.0000 | logitMin:-400.1465 | logitMax:-371.5860 | windowWeightsW25:1.028,W21:0.540,W19:0.296,W2:0.293,W13:0.266,W16:0.257,W9:-0.113,W3:-0.647,W5:-0.962 | memoryGatesShort:12.217, Long:-13.219, Current:2.002 | topTokens[(',', 224), ('Ġhave', 182), ('Ġcould', 180), ('Ġi', 97), ('Ġfelt', 91), ('Ġyou', 87), ('!', 84), ('Ġthe', 80), ('.', 77), ('Ġit', 55)] | Token Perfect: 66739 / 180000 → 37.08% | babyLLM.py 10000
2025-04-09 05:25:52 | 230000 | LR0.0003 | loss:2.4350 | gradNorm:0.9968 | tokenCount:180000.0000 | logitMin:-474.2872 | logitMax:-445.7999 | windowWeightsW25:0.796,W21:0.441,W13:0.278,W2:0.251,W16:0.234,W19:0.232,W9:-0.051,W3:-0.495,W5:-0.720 | memoryGatesShort:14.913, Long:-14.636, Current:0.723 | topTokens[(',', 271), ('.', 150), ('Ġwere', 87), ('Ġi', 80), ('Ġwas', 75), ('Ġthe', 74), ('ing', 60), ('Ġyou', 58), ('Ġand', 56), ('Ġa', 55)] | Token Perfect: 88776 / 180000 → 49.32% | babyLLM.py 10000
2025-04-09 05:47:12 | 240000 | LR0.0003 | loss:4.6596 | gradNorm:0.9979 | tokenCount:180000.0000 | logitMin:-444.3937 | logitMax:-420.2437 | windowWeightsW25:1.110,W21:0.569,W2:0.320,W13:0.289,W19:0.274,W16:0.254,W9:-0.159,W3:-0.695,W5:-1.007 | memoryGatesShort:20.337, Long:-22.139, Current:2.802 | topTokens[(',', 219), ('Ġi', 180), ('.', 148), ('Ġto', 68), ('Ġyou', 62), ('Ġa', 62), ('Ġit', 55), ('Ġthe', 47), ("'m", 45), ('ing', 41)] | Token Perfect: 33496 / 180000 → 18.61% | babyLLM.py 10000
2025-04-09 06:08:41 | 250000 | LR0.0003 | loss:3.7933 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-438.6201 | logitMax:-414.9375 | windowWeightsW25:0.875,W21:0.487,W13:0.278,W19:0.273,W2:0.259,W16:0.249,W9:-0.100,W3:-0.567,W5:-0.790 | memoryGatesShort:10.582, Long:-11.242, Current:1.660 | topTokens[(',', 327), ('Ġi', 103), ('Ġand', 94), ('Ġthe', 80), ('Ġto', 76), ('Ġa', 59), ('.', 45), ('s', 43), ('Ġwas', 35), ('Ġkevin', 34)] | Token Perfect: 46686 / 180000 → 25.94% | babyLLM.py 10000
2025-04-09 06:30:03 | 260000 | LR0.0003 | loss:3.8320 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-479.8317 | logitMax:-455.4354 | windowWeightsW25:0.982,W21:0.509,W13:0.288,W19:0.280,W2:0.267,W16:0.250,W9:-0.107,W3:-0.638,W5:-0.871 | memoryGatesShort:13.286, Long:-13.955, Current:1.668 | topTokens[(',', 235), ('Ġi', 149), ('.', 84), ('Ġthe', 71), ('Ġa', 67), ('Ġto', 52), ('Ġyou', 50), ("'m", 48), ('Ġand', 48), ('Ġit', 35)] | Token Perfect: 50067 / 180000 → 27.82% | babyLLM.py 10000
2025-04-09 06:51:18 | 270000 | LR0.0003 | loss:3.2764 | gradNorm:0.9996 | tokenCount:180000.0000 | logitMin:-500.8441 | logitMax:-475.5383 | windowWeightsW25:0.893,W21:0.483,W13:0.307,W16:0.271,W19:0.261,W2:0.242,W9:-0.052,W3:-0.628,W5:-0.814 | memoryGatesShort:12.414, Long:-13.121, Current:1.707 | topTokens[(',', 282), ('.', 88), ('Ġit', 80), ('Ġi', 75), ('Ġthe', 70), ('Ġto', 68), ('Ġa', 65), ('Ġand', 60), ('Ġof', 40), ('Ġwas', 37)] | Token Perfect: 61935 / 180000 → 34.41% | babyLLM.py 10000
2025-04-09 07:13:23 | 280000 | LR0.0003 | loss:3.8013 | gradNorm:0.9998 | tokenCount:180000.0000 | logitMin:-523.5526 | logitMax:-496.2140 | windowWeightsW25:1.340,W21:0.686,W2:0.369,W19:0.294,W16:0.281,W13:0.264,W9:-0.168,W3:-0.885,W5:-1.233 | memoryGatesShort:17.080, Long:-17.973, Current:1.892 | topTokens[('.', 168), (',', 147), ('?', 114), ('Ġi', 106), ('Ġyou', 86), ('Ġto', 69), ('Ġis', 62), ('Ġand', 61), ('Ġthe', 61), ('!', 54)] | Token Perfect: 54660 / 180000 → 30.37% | babyLLM.py 10000
2025-04-09 07:34:29 | 290000 | LR0.0003 | loss:2.8558 | gradNorm:0.8200 | tokenCount:180000.0000 | logitMin:-593.1989 | logitMax:-555.0447 | windowWeightsW25:1.220,W21:0.616,W2:0.347,W16:0.325,W19:0.275,W13:0.272,W9:-0.108,W3:-0.821,W5:-1.174 | memoryGatesShort:9.672, Long:-10.319, Current:1.647 | topTokens[('3', 366), ('Ġ<', 332), ('.', 141), (':', 98), ("'", 97), ('Ġi', 80), ('Ġ-', 80), ("Ġ'", 75), ('Ġyou', 57), ('?', 57)] | Token Perfect: 85082 / 180000 → 47.27% | babyLLM.py 10000
2025-04-09 07:55:29 | 300000 | LR0.0003 | loss:3.2332 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-470.5732 | logitMax:-444.4133 | windowWeightsW25:1.086,W21:0.570,W16:0.362,W19:0.336,W13:0.299,W2:0.292,W9:-0.089,W3:-0.789,W5:-1.112 | memoryGatesShort:14.160, Long:-15.681, Current:2.521 | topTokens[(',', 140), ('Ġthe', 104), ('.', 95), ('s', 86), ('Ġa', 80), ('Ġto', 67), ('Ġand', 65), ('Ġof', 62), ('Ġin', 52), ('Ġi', 42)] | Token Perfect: 63147 / 180000 → 35.08% | babyLLM.py 10000
2025-04-09 08:16:39 | 310000 | LR0.0003 | loss:3.2505 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-414.7703 | logitMax:-386.1478 | windowWeightsW25:1.108,W21:0.550,W2:0.359,W16:0.304,W19:0.300,W13:0.253,W9:-0.120,W3:-0.693,W5:-1.107 | memoryGatesShort:12.722, Long:-14.090, Current:2.368 | topTokens[(',', 247), ('Ġi', 154), ('.', 132), ('Ġyou', 102), ('Ġa', 78), ('Ġthe', 72), ('Ġto', 59), ('!', 56), ('Ġit', 55), ('Ġand', 51)] | Token Perfect: 56624 / 180000 → 31.46% | babyLLM.py 10000

--- 2025-04-09 09:22:28 --- babyLLM 'right, last time i got to step 392678... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''
2025-04-09 09:47:01 | 10000 | LR0.0003 | loss:2.9053 | gradNorm:0.9997 | logitMin:-466.7453 | logitMax:-435.4749 | scheduledSampling:0.0000 | tokenCount:180000.0000 | memoryGateShort:0.0008 | memoryGateLong:-0.0008 | memoryGateCurrent:0.0001 | embedMean:0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | windowWeightsW25:1.115,W21:0.593,W16:0.359,W2:0.328,W19:0.322,W13:0.239,W9:-0.096,W3:-0.754,W5:-1.152 | memoryGatesShort:7.991, Long:-7.883, Current:0.891 | topTokens[(',', 163), ('Ġhad', 161), ('.', 143), ('Ġfelt', 80), ('Ġthe', 79), ('!', 74), ('Ġand', 68), ('Ġi', 56), ('Ġit', 50), ('Ġa', 48)] | Token Perfect: 78834 / 180000 → 43.80% | babyLLM.py 10000
2025-04-09 10:11:26 | 20000 | LR0.0003 | loss:3.5435 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-440.8518 | logitMax:-414.1623 | embedMean:0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0011 | memoryGateLong:-0.0012 | memoryGateCurrent:0.0002 | windowWeightsW25:1.612,W21:0.840,W2:0.508,W19:0.417,W16:0.402,W13:0.316,W9:-0.302,W3:-1.112,W5:-1.747 | memoryGatesShort:11.334, Long:-11.983, Current:1.649 | topTokens[('!', 188), ('Ġyou', 176), (',', 167), ('Ġthe', 126), ('Ġwill', 123), ('Ġbe', 122), ('.', 102), ('Ġa', 59), ('Ġto', 54), ('ing', 51)] | Token Perfect: 58782 / 180000 → 32.66% | babyLLM.py 10000
2025-04-09 10:35:26 | 30000 | LR0.0003 | loss:3.1440 | gradNorm:0.9998 | tokenCount:180000.0000 | logitMin:-451.4771 | logitMax:-425.2375 | embedMean:0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0014 | memoryGateLong:-0.0015 | memoryGateCurrent:0.0002 | windowWeightsW25:1.245,W21:0.671,W19:0.398,W16:0.387,W2:0.329,W13:0.328,W9:-0.165,W3:-0.893,W5:-1.350 | memoryGatesShort:13.882, Long:-14.762, Current:1.879 | topTokens[(',', 272), ('Ġthe', 104), ('Ġi', 79), ('Ġa', 78), ('.', 76), ('Ġto', 65), ('!', 59), ('Ġyou', 56), ('Ġit', 53), ('s', 50)] | Token Perfect: 64538 / 180000 → 35.85% | babyLLM.py 10000
2025-04-09 10:59:38 | 40000 | LR0.0003 | loss:2.5624 | gradNorm:0.9908 | tokenCount:180000.0000 | logitMin:-479.6982 | logitMax:-449.4972 | embedMean:-0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0012 | memoryGateLong:-0.0012 | memoryGateCurrent:0.0001 | windowWeightsW25:1.210,W21:0.632,W2:0.386,W19:0.350,W16:0.337,W13:0.298,W9:-0.163,W3:-0.794,W5:-1.307 | memoryGatesShort:11.796, Long:-12.243, Current:1.447 | topTokens[(',', 248), ('!', 112), ('Ġi', 98), ('Ġit', 83), ('Ġthe', 74), ('Ġyou', 68), ('Ġcan', 67), ('Ġand', 51), ('Ġa', 48), ('Ġto', 46)] | Token Perfect: 85253 / 180000 → 47.36% | babyLLM.py 10000
2025-04-09 11:23:51 | 50000 | LR0.0003 | loss:4.8130 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-477.4403 | logitMax:-453.1568 | embedMean:-0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0011 | memoryGateLong:-0.0012 | memoryGateCurrent:0.0002 | windowWeightsW25:3.030,W21:1.421,W2:0.780,W19:0.660,W16:0.578,W13:0.392,W9:-0.739,W3:-1.999,W5:-3.237 | memoryGatesShort:11.452, Long:-12.322, Current:1.870 | topTokens[(',', 123), ('Ġi', 116), ('.', 83), ('Ġto', 83), ('Ġthe', 68), ('Ġand', 68), ('Ġyou', 66), ('Ġit', 52), ('Ġa', 46), ('Ġof', 42)] | Token Perfect: 32303 / 180000 → 17.95% | babyLLM.py 10000
2025-04-09 11:47:50 | 60000 | LR0.0003 | loss:4.5621 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-442.2662 | logitMax:-419.4191 | embedMean:-0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0016 | memoryGateLong:-0.0016 | memoryGateCurrent:0.0002 | windowWeightsW25:3.430,W21:1.527,W2:0.944,W19:0.663,W16:0.643,W13:0.438,W9:-0.962,W3:-2.125,W5:-3.687 | memoryGatesShort:15.619, Long:-16.276, Current:1.657 | topTokens[(',', 212), ('.', 194), ('Ġi', 163), ('Ġit', 64), ('Ġa', 49), ('Ġto', 49), ('Ġand', 42), ('Ġis', 36), ('Ġyou', 35), ('?', 34)] | Token Perfect: 32666 / 180000 → 18.15% | babyLLM.py 10000
2025-04-09 12:12:02 | 70000 | LR0.0003 | loss:3.2132 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-431.0844 | logitMax:-406.1292 | embedMean:-0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0031 | memoryGateLong:-0.0035 | memoryGateCurrent:0.0005 | windowWeightsW25:1.741,W21:0.847,W2:0.588,W19:0.381,W16:0.360,W13:0.232,W9:-0.388,W3:-0.978,W5:-1.854 | memoryGatesShort:30.989, Long:-34.598, Current:4.608 | topTokens[('.', 213), ('Ġi', 109), ('Ġthe', 96), ('?', 78), ('Ġcould', 73), (',', 71), ('Ġhave', 71), ('Ġyou', 61), ('Ġto', 55), ('Ġit', 49)] | Token Perfect: 59616 / 180000 → 33.12% | babyLLM.py 10000
2025-04-09 12:36:05 | 80000 | LR0.0003 | loss:2.6836 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-426.1957 | logitMax:-399.0514 | embedMean:0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0008 | memoryGateLong:-0.0008 | memoryGateCurrent:0.0001 | windowWeightsW25:1.029,W21:0.588,W16:0.327,W19:0.317,W2:0.268,W13:0.244,W9:-0.128,W3:-0.632,W5:-1.055 | memoryGatesShort:7.684, Long:-7.973, Current:1.290 | topTokens[(',', 228), ('Ġthe', 90), ('Ġi', 88), ('.', 86), ('Ġwould', 77), ('Ġto', 68), ('Ġa', 66), ('Ġyou', 60), ('?', 49), ('Ġit', 49)] | Token Perfect: 72100 / 180000 → 40.06% | babyLLM.py 10000
2025-04-09 13:00:05 | 90000 | LR0.0003 | loss:4.9085 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-458.9021 | logitMax:-435.0838 | embedMean:-0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0012 | memoryGateLong:-0.0013 | memoryGateCurrent:0.0002 | windowWeightsW25:2.778,W21:1.304,W2:0.700,W19:0.577,W16:0.530,W13:0.299,W9:-0.668,W3:-1.700,W5:-2.926 | memoryGatesShort:12.122, Long:-13.021, Current:1.900 | topTokens[(',', 269), ('.', 156), ('Ġi', 148), ('Ġthe', 58), ('Ġto', 55), ('Ġu', 54), ('Ġa', 50), ('s', 44), ('Ġand', 35), ('Ġit', 34)] | Token Perfect: 28601 / 180000 → 15.89% | babyLLM.py 10000
2025-04-09 13:24:25 | 100000 | LR0.0003 | loss:3.4221 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-455.7689 | logitMax:-430.9173 | embedMean:-0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0010 | memoryGateLong:-0.0011 | memoryGateCurrent:0.0002 | windowWeightsW25:1.230,W21:0.670,W16:0.395,W19:0.379,W13:0.323,W2:0.293,W9:-0.194,W3:-0.799,W5:-1.346 | memoryGatesShort:10.063, Long:-10.603, Current:1.540 | topTokens[('.', 158), (',', 144), ('Ġthe', 101), ('Ġand', 69), ('Ġa', 61), ('Ġi', 60), ('Ġto', 49), ('s', 48), ('Ġin', 38), ('Ġis', 36)] | Token Perfect: 55426 / 180000 → 30.79% | babyLLM.py 10000
2025-04-09 13:48:29 | 110000 | LR0.0003 | loss:2.8681 | gradNorm:0.9958 | tokenCount:180000.0000 | logitMin:-566.5070 | logitMax:-533.2159 | embedMean:0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0007 | memoryGateLong:-0.0008 | memoryGateCurrent:0.0001 | windowWeightsW25:1.590,W21:0.781,W2:0.444,W16:0.404,W13:0.384,W19:0.376,W9:-0.284,W3:-1.006,W5:-1.753 | memoryGatesShort:7.165, Long:-7.588, Current:1.423 | topTokens[(',', 318), ('Ġthe', 91), ('.', 84), ('Ġa', 73), ('Ġand', 69), ('Ġto', 64), ('Ġof', 52), ('Ġwas', 44), ('Ġyou', 43), ('s', 42)] | Token Perfect: 89620 / 180000 → 49.79% | babyLLM.py 10000
2025-04-09 14:13:00 | 120000 | LR0.0003 | loss:2.8618 | gradNorm:0.9838 | tokenCount:180000.0000 | logitMin:-528.8545 | logitMax:-492.8882 | embedMean:-0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0009 | memoryGateLong:-0.0009 | memoryGateCurrent:0.0001 | windowWeightsW25:1.563,W21:0.759,W2:0.425,W16:0.375,W13:0.364,W19:0.344,W9:-0.271,W3:-0.936,W5:-1.684 | memoryGatesShort:9.276, Long:-9.260, Current:0.984 | topTokens[('.', 178), (',', 155), ('Ġthe', 114), ('Ġa', 94), ('Ġand', 77), ('Ġto', 68), ('Ġi', 68), ('Ġit', 67), ('Ġof', 57), ('Ġwas', 51)] | Token Perfect: 86351 / 180000 → 47.97% | babyLLM.py 10000
2025-04-09 14:37:26 | 130000 | LR0.0003 | loss:3.5898 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-454.0781 | logitMax:-424.9220 | embedMean:-0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0012 | memoryGateLong:-0.0013 | memoryGateCurrent:0.0002 | windowWeightsW25:1.490,W21:0.721,W16:0.455,W13:0.422,W2:0.419,W19:0.347,W9:-0.266,W3:-1.004,W5:-1.644 | memoryGatesShort:12.037, Long:-12.560, Current:1.523 | topTokens[('.', 189), ('Ġi', 184), ('Ġ-', 95), (':', 86), ("'", 81), ('Ġyou', 72), ('0', 69), ('?', 64), ('Ġto', 57), ("Ġ'", 56)] | Token Perfect: 62965 / 180000 → 34.98% | babyLLM.py 10000
2025-04-09 15:02:01 | 140000 | LR0.0003 | loss:3.3369 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-447.6275 | logitMax:-420.6101 | embedMean:-0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0016 | memoryGateLong:-0.0017 | memoryGateCurrent:0.0002 | windowWeightsW25:1.172,W21:0.610,W16:0.374,W13:0.347,W19:0.339,W2:0.297,W9:-0.133,W3:-0.796,W5:-1.257 | memoryGatesShort:15.931, Long:-16.917, Current:1.986 | topTokens[(',', 153), ('Ġand', 124), ('Ġi', 100), ('.', 90), ('Ġto', 85), ('s', 82), ('Ġkiss', 76), ('Ġthe', 74), ('Ġyou', 70), ('Ġhug', 69)] | Token Perfect: 55482 / 180000 → 30.82% | babyLLM.py 10000
2025-04-09 15:26:56 | 150000 | LR0.0003 | loss:3.5694 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-411.3456 | logitMax:-385.0043 | embedMean:-0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0008 | memoryGateLong:-0.0009 | memoryGateCurrent:0.0002 | windowWeightsW25:1.269,W21:0.661,W2:0.407,W16:0.385,W13:0.353,W19:0.329,W9:-0.199,W3:-0.870,W5:-1.387 | memoryGatesShort:8.246, Long:-8.783, Current:1.537 | topTokens[('.', 187), (',', 165), ('Ġi', 117), ('Ġand', 97), ('Ġthe', 72), ('Ġto', 68), ('Ġyou', 63), ('Ġwas', 49), ('Ġcharis', 47), ('s', 47)] | Token Perfect: 56406 / 180000 → 31.34% | babyLLM.py 10000

--- 2025-04-09 15:43:03 --- babyLLM 'right, last time i got to step 155482... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 155482! what am i learning today?' - charis: ''
2025-04-09 16:04:18 | 10000 | LR0.0003 | loss:1.9651 | gradNorm:0.9990 | logitMin:-477.0969 | logitMax:-447.3186 | scheduledSampling:0.0000 | tokenCount:180000.0000 | memoryGateShort:0.0006 | memoryGateLong:-0.0005 | memoryGateCurrent:0.0001 | embedMean:-0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | shortDecay:0.0001 | longDecay:0.0001 | windowWeightsW25:0.916,W21:0.506,W19:0.341,W16:0.330,W13:0.308,W2:0.268,W9:-0.097,W3:-0.649,W5:-0.962 | memoryGatesShort:5.504, Long:-5.482, Current:0.978 | topTokens[(',', 321), ('Ġthe', 114), ('Ġi', 101), ('Ġand', 66), ('.', 59), ('Ġof', 54), ('Ġit', 53), ('Ġto', 52), ('Ġyou', 49), ('s', 42)] | Token Perfect: 95446 / 180000 → 53.03% | babyLLM.py 10000
2025-04-09 16:25:40 | 20000 | LR0.0003 | loss:4.0976 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-481.6717 | logitMax:-453.7566 | embedMean:-0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0008 | memoryGateLong:-0.0008 | memoryGateCurrent:0.0001 | shortDecay:0.0001 | longDecay:0.0001 | windowWeightsW25:1.306,W21:0.644,W19:0.450,W16:0.407,W13:0.312,W2:0.293,W9:-0.205,W3:-0.908,W5:-1.351 | memoryGatesShort:8.013, Long:-8.370, Current:1.357 | topTokens[(',', 261), ('Ġi', 103), ('.', 73), ('Ġa', 62), ('Ġthe', 59), ("'", 57), ('Ġto', 55), ('Ġyou', 52), ("Ġ'", 48), ('Ġand', 45)] | Token Perfect: 51510 / 180000 → 28.62% | babyLLM.py 10000
2025-04-09 16:46:58 | 30000 | LR0.0003 | loss:3.4010 | gradNorm:0.9995 | tokenCount:180000.0000 | logitMin:-453.2962 | logitMax:-426.8302 | embedMean:-0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0006 | memoryGateLong:-0.0007 | memoryGateCurrent:0.0002 | shortDecay:0.0001 | longDecay:0.0001 | windowWeightsW25:1.397,W21:0.634,W2:0.459,W16:0.419,W19:0.392,W13:0.278,W9:-0.240,W3:-0.980,W5:-1.417 | memoryGatesShort:6.450, Long:-7.310, Current:1.860 | topTokens[(',', 198), ('Ġi', 93), ('.', 90), ('Ġand', 71), ('Ġshould', 68), ('Ġthe', 63), ('Ġa', 55), ('Ġto', 51), ('!', 42), ('Ġof', 38)] | Token Perfect: 63189 / 180000 → 35.10% | babyLLM.py 10000
2025-04-09 17:10:04 | 40000 | LR0.0003 | loss:2.6979 | gradNorm:0.9829 | tokenCount:180000.0000 | logitMin:-538.7743 | logitMax:-503.5272 | embedMean:-0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0005 | memoryGateLong:-0.0005 | memoryGateCurrent:0.0001 | shortDecay:0.0001 | longDecay:0.0001 | windowWeightsW25:1.693,W21:0.731,W2:0.504,W16:0.454,W19:0.434,W13:0.330,W9:-0.343,W3:-1.166,W5:-1.704 | memoryGatesShort:5.075, Long:-5.065, Current:0.990 | topTokens[(',', 186), ('.', 155), ('Ġthe', 70), ('Ġa', 67), ('Ġi', 54), ('Ġand', 53), ('Ġof', 49), ('Ġit', 48), ('Ġto', 47), ('s', 46)] | Token Perfect: 93429 / 180000 → 51.91% | babyLLM.py 10000
2025-04-09 17:33:24 | 50000 | LR0.0003 | loss:3.1329 | gradNorm:0.9986 | tokenCount:180000.0000 | logitMin:-451.3607 | logitMax:-418.9345 | embedMean:-0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0009 | memoryGateLong:-0.0010 | memoryGateCurrent:0.0001 | shortDecay:0.0001 | longDecay:0.0001 | windowWeightsW25:1.755,W21:0.781,W2:0.493,W19:0.484,W16:0.393,W13:0.260,W9:-0.386,W3:-1.175,W5:-1.672 | memoryGatesShort:9.281, Long:-9.516, Current:1.235 | topTokens[(',', 249), ('Ġwill', 169), ('Ġi', 126), ('Ġthe', 116), ('.', 94), ('Ġyou', 77), ('!', 75), ('Ġand', 60), ('Ġto', 56), ('Ġelodie', 49)] | Token Perfect: 69798 / 180000 → 38.78% | babyLLM.py 10000
2025-04-09 17:57:38 | 60000 | LR0.0003 | loss:3.4809 | gradNorm:0.9998 | tokenCount:180000.0000 | logitMin:-438.2063 | logitMax:-410.3478 | embedMean:0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0009 | memoryGateLong:-0.0009 | memoryGateCurrent:0.0001 | shortDecay:0.0001 | longDecay:0.0001 | windowWeightsW25:1.537,W21:0.653,W16:0.420,W2:0.407,W19:0.382,W13:0.299,W9:-0.253,W3:-1.056,W5:-1.448 | memoryGatesShort:8.666, Long:-8.873, Current:1.208 | topTokens[(',', 160), ('.', 117), ('Ġthe', 86), ('Ġto', 78), ('Ġand', 72), ('Ġa', 52), ('Ġof', 44), ('!', 44), ('Ġit', 42), ('ed', 41)] | Token Perfect: 61753 / 180000 → 34.31% | babyLLM.py 10000
2025-04-09 18:19:43 | 70000 | LR0.0003 | loss:2.3679 | gradNorm:0.9964 | tokenCount:180000.0000 | logitMin:-485.2402 | logitMax:-456.1967 | embedMean:0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0005 | memoryGateLong:-0.0005 | memoryGateCurrent:0.0001 | shortDecay:0.0001 | longDecay:0.0001 | windowWeightsW25:1.062,W21:0.478,W16:0.373,W2:0.309,W19:0.299,W13:0.279,W9:-0.124,W3:-0.691,W5:-1.027 | memoryGatesShort:4.942, Long:-5.124, Current:1.182 | topTokens[(',', 179), ('.', 156), ('?', 137), ('Ġyou', 99), ('Ġis', 83), ('Ġthe', 76), ('!', 61), ('Ġa', 57), ('Ġi', 56), ('Ġand', 47)] | Token Perfect: 86553 / 180000 → 48.09% | babyLLM.py 10000
2025-04-09 18:42:04 | 80000 | LR0.0003 | loss:2.1552 | gradNorm:0.9854 | tokenCount:180000.0000 | logitMin:-549.9431 | logitMax:-513.9265 | embedMean:0.0000 | embedStd:0.0000 | embedSparsity:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowCount:0.0009 | windowEntropy:nan | memoryGateShort:0.0003 | memoryGateLong:-0.0003 | memoryGateCurrent:0.0001 | shortDecay:0.0001 | longDecay:0.0001 | windowWeightsW25:1.059,W21:0.468,W2:0.338,W16:0.334,W19:0.276,W13:0.257,W9:-0.116,W3:-0.670,W5:-0.989 | memoryGatesShort:3.112, Long:-3.347, Current:1.235 | topTokens[(',', 228), ('.', 137), ('Ġto', 90), ('Ġthe', 83), ('?', 82), ('Ġi', 72), ('Ġa', 72), ('Ġyou', 69), ('Ġand', 55), ('Ġis', 52)] | Token Perfect: 106678 / 180000 → 59.27% | babyLLM.py 10000

--- 2025-04-09 19:25:57 --- babyLLM 'right, last time i got to step 248400... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 248400! what am i learning today?' - charis: ''
2025-04-09 19:53:05 | 10000 | LR0.0003 | loss:3.7299 | gradNorm:0.9998 | logitMin:-436.4510 | logitMax:-409.6897 | scheduledSampling:0.0000 | tokenCount:180000.0000 | memoryGateShort:9.4422 | memoryGateLong:-10.1427 | memoryGateCurrent:1.7004 | shortDecay:0.0000 | longDecay:0.0000 | windowWeightsW25:1.369,W21:0.611,W2:0.381,W19:0.375,W16:0.366,W13:0.193,W9:-0.191,W3:-0.886,W5:-1.271 | topTokens[(',', 167), ('Ġi', 119), ('.', 118), ('Ġthe', 100), ('?', 74), ('Ġto', 71), ('Ġa', 60), ('Ġyou', 58), ('Ġof', 48), ('Ġis', 46)] | tokenPerfect: 57616 / 180000 → 32.01% | babyLLM.py 10000
2025-04-09 20:13:57 | 20000 | LR0.0003 | loss:3.0715 | gradNorm:0.9987 | tokenCount:180000.0000 | logitMin:-471.0988 | logitMax:-441.4179 | memoryGateShort:7.3236 | memoryGateLong:-7.7013 | memoryGateCurrent:1.3777 | windowWeightsW25:1.588,W21:0.663,W16:0.426,W2:0.415,W19:0.406,W13:0.225,W9:-0.212,W3:-1.064,W5:-1.506 | topTokens[(',', 405), ('Ġthe', 228), ('.', 198), ('Ġi', 160), ('Ġa', 132), ('Ġto', 129), ('Ġof', 108), ('Ġand', 95), ('?', 91), ('s', 84)] | tokenPerfect: 77464 / 180000 → 43.04% | babyLLM.py 10000
2025-04-09 20:34:52 | 30000 | LR0.0003 | loss:2.5721 | gradNorm:0.9994 | tokenCount:180000.0000 | logitMin:-406.4804 | logitMax:-377.9802 | memoryGateShort:8.4239 | memoryGateLong:-9.1012 | memoryGateCurrent:1.6772 | windowWeightsW25:1.088,W21:0.500,W16:0.350,W2:0.329,W19:0.315,W13:0.228,W9:-0.113,W3:-0.713,W5:-1.028 | topTokens[(',', 743), ('Ġthe', 342), ('.', 269), ('Ġand', 267), ('Ġi', 235), ('Ġto', 189), ('Ġa', 153), ('s', 144), ('Ġyou', 139), ('Ġof', 136)] | tokenPerfect: 76677 / 180000 → 42.60% | babyLLM.py 10000
2025-04-09 20:56:20 | 40000 | LR0.0003 | loss:3.4609 | gradNorm:0.9641 | tokenCount:180000.0000 | logitMin:-464.5926 | logitMax:-431.0753 | memoryGateShort:7.7065 | memoryGateLong:-7.9295 | memoryGateCurrent:1.2230 | windowWeightsW25:1.514,W21:0.637,W16:0.428,W2:0.398,W19:0.347,W13:0.240,W9:-0.230,W3:-0.997,W5:-1.395 | topTokens[(',', 862), ('Ġthe', 408), ('.', 379), ('Ġand', 308), ('Ġi', 277), ('Ġto', 270), ('Ġa', 215), ('s', 197), ('Ġyou', 187), ('Ġit', 184)] | tokenPerfect: 76945 / 180000 → 42.75% | babyLLM.py 10000
2025-04-09 21:17:35 | 50000 | LR0.0003 | loss:3.7699 | gradNorm:0.9985 | tokenCount:180000.0000 | logitMin:-453.4642 | logitMax:-426.4359 | memoryGateShort:7.2134 | memoryGateLong:-7.5349 | memoryGateCurrent:1.3215 | windowWeightsW25:1.689,W21:0.695,W16:0.499,W2:0.477,W19:0.380,W13:0.279,W9:-0.227,W3:-1.185,W5:-1.674 | topTokens[(',', 1127), ('.', 517), ('Ġthe', 470), ('Ġand', 368), ('Ġi', 342), ('Ġto', 320), ('Ġa', 295), ('s', 227), ('Ġit', 220), ('Ġof', 218)] | tokenPerfect: 59009 / 180000 → 32.78% | babyLLM.py 10000

--- 2025-04-09 21:32:10 --- babyLLM 'right, last time i got to step 304103... want to restart from there?'  - charis: '0 please' - babyLLM 'umm... i don't think i heard you properly, i'll just start from step 0 :) but, what am i learning today?' - charis: ''
2025-04-09 21:53:17 | 10000 | LR0.0003 | loss:3.9564 | gradNorm:0.9984 | logitMin:-446.7007 | logitMax:-420.0734 | scheduledSampling:0.0000 | tokenCount:180000.0000 | memoryGateShort:9.2073 | memoryGateLong:-10.1175 | memoryGateCurrent:1.9102 | shortDecay:0.0000 | longDecay:0.0000 | windowWeightsW25:0.304,W21:0.111,W16:0.097,W2:0.093,W13:0.087,W19:0.087,W9:0.066,W3:0.053,W5:0.052 | topTokens[(',', 261), ('Ġi', 131), ('Ġthe', 100), ('Ġand', 79), ('.', 75), ('Ġto', 73), ('Ġyou', 65), ('Ġa', 47), ('Ġme', 45), ('Ġit', 44)] | tokenPerfect: 49131 / 180000 → 27.30% | babyLLM.py 10000
2025-04-09 22:14:16 | 20000 | LR0.0003 | loss:4.0543 | gradNorm:0.9970 | tokenCount:180000.0000 | logitMin:-543.7074 | logitMax:-515.6420 | memoryGateShort:7.5474 | memoryGateLong:-7.9302 | memoryGateCurrent:1.3828 | windowWeightsW25:0.337,W21:0.111,W2:0.088,W16:0.085,W19:0.085,W13:0.077,W9:0.062,W3:0.053,W5:0.051 | topTokens[(',', 552), ('Ġi', 287), ('Ġthe', 183), ('Ġand', 134), ('.', 119), ('Ġit', 118), ('Ġto', 114), ('Ġyou', 113), ('Ġa', 88), ('Ġof', 76)] | tokenPerfect: 53888 / 180000 → 29.94% | babyLLM.py 10000
2025-04-09 22:35:23 | 30000 | LR0.0003 | loss:4.7392 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-439.5715 | logitMax:-415.1299 | memoryGateShort:10.5541 | memoryGateLong:-11.4917 | memoryGateCurrent:1.9377 | windowWeightsW25:0.340,W21:0.109,W2:0.091,W19:0.084,W16:0.084,W13:0.075,W9:0.061,W3:0.053,W5:0.051 | topTokens[(',', 710), ('Ġi', 397), ('Ġthe', 239), ('.', 236), ('Ġto', 190), ('Ġand', 189), ('Ġit', 173), ('Ġa', 152), ('Ġyou', 149), ('s', 125)] | tokenPerfect: 30209 / 180000 → 16.78% | babyLLM.py 10000

--- 2025-04-09 22:52:54 --- babyLLM 'right, last time i got to step 31851... want to restart from there?'  - charis: 'y' - babyLLM 'ok! let's go to step 31851! what am i learning today?' - charis: ''
2025-04-09 23:14:52 | 10000 | LR0.0003 | loss:2.7805 | gradNorm:0.9927 | logitMin:-493.9683 | logitMax:-466.5466 | scheduledSampling:0.0000 | tokenCount:180000.0000 | memoryGateShort:9.8261 | memoryGateLong:-10.9386 | memoryGateCurrent:2.1125 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateMean:0.3333 | memoryGateStd:10.5052 | embedMean:-0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.0000 | windowEntropy:0.0002 | topWindowWeight:0.0001 | effectiveWindowCount:0.0005 | windowWeightsW25:2.328 (0.5),W21:0.986 (0.1),W2:0.791 (0.1),W16:0.505 (0.1),W19:0.397 (0.1),W13:0.106 (0.1),W9:-0.331 (0.0),W3:-1.644 (0.0),W5:-2.284 (0.0) | topTokens[('.', 196), (',', 138), ('?', 103), ('Ġi', 91), ('Ġto', 87), ('Ġyou', 87), ('Ġa', 70), ('Ġis', 64), ('Ġthe', 57), ('Ġwas', 53)] | tokenPerfect: 83689 / 180000 → 46.49% | babyLLM.py 10000

--- 2025-04-09 23:35:26 --- babyLLM 'right, last time i got to step 48710... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 48710! what am i learning today?' - charis: ''
2025-04-09 23:58:07 | 10000 | LR0.0003 | loss:1.8464 | gradNorm:0.9999 | logitMin:-324.8624 | logitMax:-295.0611 | scheduledSampling:0.0000 | tokenCount:180000.0000 | memoryGateShort:15.2460 | memoryGateLong:-16.9195 | memoryGateCurrent:2.6735 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateMean:0.3333 | memoryGateStd:16.2113 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.0000 | windowEntropy:0.0002 | topWindowWeight:0.0000 | effectiveWindowCount:0.0005 | windowWeightsW25:2.188 (0.5),W21:0.965 (0.1),W2:0.770 (0.1),W19:0.454 (0.1),W16:0.433 (0.1),W13:0.307 (0.1),W9:0.042 (0.1),W3:-1.503 (0.0),W5:-1.821 (0.0) | topTokens[('Ġis', 236), ('Ġare', 193), (',', 180), ('.', 165), ('Ġcharis', 146), ('ing', 143), ('!', 140), ('Ġthe', 125), ('Ġelodie', 96), ('Ġeating', 71)] | tokenPerfect: 87230 / 180000 → 48.46% | babyLLM.py 10000

--- 2025-04-10 00:03:26 --- babyLLM 'right, last time i got to step 60790... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 60790! what am i learning today?' - charis: ''
2025-04-10 00:26:16 | 10000 | LR0.0003 | loss:2.3845 | gradNorm:0.9999 | logitMin:-260.5561 | logitMax:-230.0449 | scheduledSampling:0.0000 | tokenCount:180000.0000 | memoryGateShort:22.1245 | memoryGateLong:-24.5205 | memoryGateCurrent:3.3960 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateMean:3333.3330 | memoryGateStd:234738.1138 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1312 | windowEntropy:1.7384 | topWindowWeight:0.4462 | effectiveWindowCount:5.6883 | windowWeightsW25:2.152 (0.4),W21:0.866 (0.1),W2:0.747 (0.1),W16:0.456 (0.1),W19:0.438 (0.1),W13:0.403 (0.1),W9:0.065 (0.1),W3:-1.205 (0.0),W5:-1.611 (0.0) | topTokens[(',', 447), ('Ġand', 335), ('Ġthe', 138), ('Ġcharis', 102), ('Ġelodie', 89), ('Ġbut', 81), ('Ġyou', 76), ('Ġher', 69), ('Ġkevin', 67), ("'s", 56)] | tokenPerfect: 73315 / 180000 → 40.73% | babyLLM.py 10000

--- 2025-04-10 01:52:13 --- babyLLM 'right, last time i got to step 100006... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 100006! what am i learning today?' - charis: ''
2025-04-10 02:13:12 | 10000 | LR0.0003 | loss:4.7314 | gradNorm:1.0000 | logitMin:-427.5586 | logitMax:-404.0401 | scheduledSampling:0.0000 | tokenCount:180000.0000 | memoryGateShort:0.0017 | memoryGateLong:-0.0019 | memoryGateCurrent:0.0002 | shortDecay:0.0001 | longDecay:0.0001 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1666 | windowEntropy:1.5166 | topWindowWeight:0.5427 | effectiveWindowCount:4.5568 | memoryGateMean:0.3333 | memoryGateStd:17.9885 | windowWeightsW25:2.529 (0.5),W21:1.126 (0.1),W19:0.598 (0.1),W2:0.518 (0.1),W16:0.420 (0.1),W13:0.392 (0.1),W9:-0.410 (0.0),W3:-1.661 (0.0),W5:-2.054 (0.0) | topTokens[('.', 311), ('Ġi', 110), ('Ġand', 65), ('?', 53), ('Ġim', 45), ('Ġyou', 44), ('Ġa', 41), ('Ġlo', 37), ('l', 36), ('Ġu', 35)] | tokenPerfect: 26160 / 180000 → 14.53% | babyLLM.py 10000

--- 2025-04-10 03:13:31 --- babyLLM 'right, last time i got to step 130162... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 130162! what am i learning today?' - charis: ''
2025-04-10 03:34:22 | 10000 | LR0.0003 | loss:3.2734 | gradNorm:1.0000 | logitMin:-73.5113 | logitMax:-30.9013 | scheduledSampling:0.0005 | tokenCount:180000.0000 | memoryGateShort:0.0009 | memoryGateLong:-0.0010 | memoryGateCurrent:0.0002 | shortDecay:0.0001 | longDecay:0.0001 | embedMean:-0.0000 | embedStd:0.0000 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1541 | windowEntropy:1.5905 | topWindowWeight:0.5055 | effectiveWindowCount:4.9062 | memoryGateMean:0.3333 | memoryGateStd:9.2706 | windowWeightsW25:2.390 (0.5),W21:1.151 (0.1),W2:0.652 (0.1),W19:0.599 (0.1),W16:0.360 (0.1),W13:0.241 (0.1),W9:-0.395 (0.0),W3:-1.358 (0.0),W5:-1.957 (0.0) | topTokens[(',', 235), ('!', 189), ('Ġthe', 121), ('Ġit', 114), ('Ġa', 71), ('Ġi', 62), ('Ġd', 61), ('Ġyou', 59), ('Ġhe', 59), ('Ġto', 59)] | 0.0009999999999997715 | tokenPerfect: 59238 / 180000 → 32.91% | babyLLM.py 10000
2025-04-10 03:55:20 | 20000 | LR0.0003 | loss:5.0518 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-303.6874 | logitMax:-277.7236 | scheduledSampling:0.0015 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1834 | windowEntropy:1.4139 | topWindowWeight:0.5900 | effectiveWindowCount:4.1121 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0009 | memoryGateLong:-0.0009 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:9.0185 | windowWeightsW25:2.633 (0.6),W21:1.089 (0.1),W2:0.533 (0.1),W19:0.514 (0.1),W16:0.237 (0.1),W13:0.153 (0.0),W9:-0.599 (0.0),W3:-1.486 (0.0),W5:-2.129 (0.0) | topTokens[(',', 624), ('!', 220), ('Ġi', 187), ('Ġthe', 186), ('Ġit', 159), ('Ġa', 129), ('Ġto', 113), ('ed', 85), ('Ġshe', 81), ('Ġyou', 80)] | 0.0020000000000002364 | tokenPerfect: 25803 / 180000 → 14.34% | babyLLM.py 10000
2025-04-10 04:16:24 | 30000 | LR0.0003 | loss:2.4057 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-223.3861 | logitMax:-193.9316 | scheduledSampling:0.0025 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1598 | windowEntropy:1.5652 | topWindowWeight:0.5236 | effectiveWindowCount:4.7835 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0016 | memoryGateLong:-0.0017 | memoryGateCurrent:0.0003 | memoryGateMean:0.3333 | memoryGateStd:16.6264 | windowWeightsW25:2.387 (0.5),W21:1.017 (0.1),W2:0.715 (0.1),W19:0.460 (0.1),W16:0.270 (0.1),W13:0.125 (0.1),W9:-0.448 (0.0),W3:-1.336 (0.0),W5:-1.786 (0.0) | topTokens[(',', 814), ('Ġwill', 409), ('!', 349), ('Ġthe', 294), ('Ġi', 240), ('.', 201), ('Ġit', 192), ('Ġto', 149), ('Ġa', 148), ('Ġand', 140)] | 0.0029999999999986344 | tokenPerfect: 69494 / 180000 → 38.61% | babyLLM.py 10000
2025-04-10 04:37:28 | 40000 | LR0.0003 | loss:2.6169 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-215.2593 | logitMax:-189.2278 | scheduledSampling:0.0035 | embedMean:-0.0000 | embedStd:0.0000 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1416 | windowEntropy:1.6833 | topWindowWeight:0.4731 | effectiveWindowCount:5.3831 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0011 | memoryGateLong:-0.0012 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:11.4083 | windowWeightsW25:2.252 (0.5),W21:1.057 (0.1),W2:0.678 (0.1),W19:0.491 (0.1),W16:0.310 (0.1),W13:0.239 (0.1),W9:-0.165 (0.0),W3:-0.951 (0.0),W5:-1.436 (0.0) | topTokens[(',', 923), ('Ġwill', 441), ('!', 419), ('.', 410), ('Ġi', 370), ('Ġthe', 348), ('Ġto', 260), ('Ġyou', 244), ('Ġit', 227), ('?', 191)] | 0.003999999999997439 | tokenPerfect: 67052 / 180000 → 37.25% | babyLLM.py 10000
2025-04-10 04:58:30 | 50000 | LR0.0003 | loss:2.3346 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-159.2110 | logitMax:-132.3153 | scheduledSampling:0.0045 | embedMean:-0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1405 | windowEntropy:1.6782 | topWindowWeight:0.4668 | effectiveWindowCount:5.3558 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0008 | memoryGateLong:-0.0008 | memoryGateCurrent:0.0001 | memoryGateMean:0.3333 | memoryGateStd:8.1247 | windowWeightsW25:2.306 (0.5),W21:1.222 (0.2),W19:0.672 (0.1),W2:0.540 (0.1),W16:0.462 (0.1),W13:0.327 (0.1),W9:-0.181 (0.0),W3:-1.018 (0.0),W5:-1.521 (0.0) | topTokens[(',', 1175), ('!', 583), ('Ġthe', 477), ('.', 447), ('Ġi', 445), ('Ġwill', 442), ('Ġto', 317), ('Ġit', 315), ('Ġyou', 290), ('Ġa', 235)] | 0.005000000000000174 | tokenPerfect: 73119 / 180000 → 40.62% | babyLLM.py 10000
2025-04-10 05:19:11 | 60000 | LR0.0003 | loss:2.9949 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-383.1445 | logitMax:-359.1326 | scheduledSampling:0.0055 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1620 | windowEntropy:1.5496 | topWindowWeight:0.5278 | effectiveWindowCount:4.7096 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0013 | memoryGateLong:-0.0015 | memoryGateCurrent:0.0003 | memoryGateMean:0.3333 | memoryGateStd:14.1202 | windowWeightsW25:2.495 (0.5),W21:1.238 (0.2),W19:0.636 (0.1),W2:0.467 (0.1),W16:0.366 (0.1),W13:0.259 (0.1),W9:-0.384 (0.0),W3:-1.173 (0.0),W5:-1.702 (0.0) | topTokens[(',', 1504), ('!', 594), ('Ġi', 583), ('Ġthe', 517), ('.', 472), ('Ġwill', 469), ('Ġto', 375), ('Ġit', 361), ('Ġyou', 301), ('Ġa', 278)] | 0.006000000000002908 | tokenPerfect: 56283 / 180000 → 31.27% | babyLLM.py 10000
2025-04-10 05:40:19 | 70000 | LR0.0003 | loss:1.7933 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-219.1626 | logitMax:-186.7313 | scheduledSampling:0.0065 | embedMean:0.0000 | embedStd:0.0001 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1505 | windowEntropy:1.6265 | topWindowWeight:0.4962 | effectiveWindowCount:5.0859 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0009 | memoryGateLong:-0.0010 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:9.8244 | windowWeightsW25:2.345 (0.5),W21:1.159 (0.2),W2:0.615 (0.1),W19:0.498 (0.1),W16:0.304 (0.1),W13:0.176 (0.1),W9:-0.249 (0.0),W3:-1.090 (0.0),W5:-1.416 (0.0) | topTokens[(',', 1635), ('Ġwill', 868), ('!', 736), ('Ġi', 656), ('.', 648), ('Ġthe', 638), ('Ġto', 439), ('Ġyou', 393), ('Ġit', 390), ('Ġand', 300)] | 0.007000000000005643 | tokenPerfect: 85593 / 180000 → 47.55% | babyLLM.py 10000
2025-04-10 06:01:09 | 80000 | LR0.0003 | loss:1.9650 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-185.9969 | logitMax:-157.9472 | scheduledSampling:0.0075 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1444 | windowEntropy:1.6561 | topWindowWeight:0.4756 | effectiveWindowCount:5.2390 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0009 | memoryGateLong:-0.0010 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:9.9070 | windowWeightsW25:2.298 (0.5),W21:1.250 (0.2),W19:0.621 (0.1),W2:0.595 (0.1),W16:0.267 (0.1),W13:0.088 (0.1),W9:-0.279 (0.0),W3:-0.903 (0.0),W5:-1.374 (0.0) | topTokens[(',', 1767), ('Ġwill', 890), ('!', 855), ('.', 784), ('Ġi', 767), ('Ġthe', 711), ('Ġto', 549), ('Ġyou', 503), ('Ġit', 450), ('?', 391)] | 0.008000000000006752 | tokenPerfect: 86379 / 180000 → 47.99% | babyLLM.py 10000
2025-04-10 06:21:58 | 90000 | LR0.0003 | loss:2.0245 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-255.6489 | logitMax:-227.6699 | scheduledSampling:0.0085 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1501 | windowEntropy:1.6136 | topWindowWeight:0.4911 | effectiveWindowCount:5.0208 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0007 | memoryGateLong:-0.0007 | memoryGateCurrent:0.0001 | memoryGateMean:0.3333 | memoryGateStd:6.7128 | windowWeightsW25:2.400 (0.5),W21:1.307 (0.2),W19:0.772 (0.1),W2:0.472 (0.1),W16:0.422 (0.1),W13:0.157 (0.1),W9:-0.324 (0.0),W3:-1.081 (0.0),W5:-1.592 (0.0) | topTokens[(',', 2076), ('!', 951), ('Ġwill', 890), ('Ġi', 854), ('Ġthe', 817), ('.', 815), ('Ġto', 609), ('Ġyou', 535), ('Ġit', 509), ('Ġa', 406)] | 0.009000000000000813 | tokenPerfect: 83140 / 180000 → 46.19% | babyLLM.py 10000
2025-04-10 06:42:57 | 100000 | LR0.0003 | loss:2.0105 | gradNorm:0.9989 | tokenCount:180000.0000 | logitMin:-409.3937 | logitMax:-379.4087 | scheduledSampling:0.0095 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1616 | windowEntropy:1.5438 | topWindowWeight:0.5241 | effectiveWindowCount:4.6822 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0012 | memoryGateLong:-0.0013 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:12.4430 | windowWeightsW25:2.469 (0.5),W21:1.276 (0.2),W19:0.688 (0.1),W2:0.534 (0.1),W16:0.266 (0.1),W13:0.023 (0.0),W9:-0.478 (0.0),W3:-1.166 (0.0),W5:-1.676 (0.0) | topTokens[(',', 2357), ('Ġwill', 1036), ('!', 1006), ('Ġi', 981), ('Ġthe', 883), ('.', 865), ('Ġto', 669), ('Ġyou', 559), ('Ġit', 541), ('Ġshe', 422)] | 0.009999999999994874 | tokenPerfect: 82526 / 180000 → 45.85% | babyLLM.py 10000

--- 2025-04-10 06:55:41 --- babyLLM 'right, last time i got to step 5236... want to restart from there?'  - charis: 'n' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: ''
2025-04-10 07:16:55 | 10000 | LR0.0003 | loss:3.2305 | gradNorm:1.0000 | logitMin:-432.6799 | logitMax:-405.8921 | scheduledSampling:0.0025 | tokenCount:180000.0000 | memoryGateShort:0.0008 | memoryGateLong:-0.0008 | memoryGateCurrent:0.0001 | shortDecay:0.0001 | longDecay:0.0001 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1858 | windowEntropy:1.3834 | topWindowWeight:0.5936 | effectiveWindowCount:3.9885 | memoryGateMean:0.3333 | memoryGateStd:7.8848 | windowWeightsW25:2.667 (0.6),W21:1.240 (0.1),W19:0.599 (0.1),W2:0.501 (0.1),W16:0.199 (0.1),W13:-0.124 (0.0),W9:-0.792 (0.0),W3:-1.437 (0.0),W5:-2.046 (0.0) | topTokens[('.', 106), ('Ġto', 90), (',', 88), ('Ġi', 86), ('Ġthe', 84), ('Ġit', 67), ('Ġa', 55), ('Ġand', 51), ('Ġthat', 43), ('Ġis', 38)] | tokenPerfect: 66137 / 180000 → 36.74% | babyLLM.py 10000
2025-04-10 07:37:40 | 20000 | LR0.0003 | loss:3.2997 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-284.9619 | logitMax:-258.4508 | scheduledSampling:0.0075 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1635 | windowEntropy:1.5284 | topWindowWeight:0.5305 | effectiveWindowCount:4.6109 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0010 | memoryGateLong:-0.0010 | memoryGateCurrent:0.0001 | memoryGateMean:0.3333 | memoryGateStd:9.9792 | windowWeightsW25:2.411 (0.5),W21:1.126 (0.1),W2:0.741 (0.1),W19:0.456 (0.1),W16:0.235 (0.1),W13:-0.076 (0.0),W9:-0.750 (0.0),W3:-1.172 (0.0),W5:-2.041 (0.0) | topTokens[('!', 271), ('Ġit', 269), ('.', 170), ('Ġi', 157), (',', 148), ('Ġa', 131), ('Ġto', 123), ('Ġthe', 118), ('Ġand', 106), ('Ġhave', 97)] | tokenPerfect: 57267 / 180000 → 31.81% | babyLLM.py 10000
2025-04-10 07:58:21 | 30000 | LR0.0003 | loss:4.3067 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-337.9190 | logitMax:-315.4761 | scheduledSampling:0.0125 | embedMean:-0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1848 | windowEntropy:1.3820 | topWindowWeight:0.5892 | effectiveWindowCount:3.9827 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0009 | memoryGateLong:-0.0009 | memoryGateCurrent:0.0001 | memoryGateMean:0.3333 | memoryGateStd:8.9397 | windowWeightsW25:2.659 (0.6),W21:1.296 (0.2),W19:0.547 (0.1),W2:0.533 (0.1),W16:0.205 (0.1),W13:-0.118 (0.0),W9:-0.848 (0.0),W3:-1.472 (0.0),W5:-2.304 (0.0) | topTokens[('Ġi', 332), ('Ġit', 315), ('!', 291), ('.', 283), (',', 222), ('Ġto', 195), ('Ġa', 187), ('Ġthe', 182), ('Ġand', 143), ('Ġhave', 118)] | tokenPerfect: 36686 / 180000 → 20.38% | babyLLM.py 10000
2025-04-10 08:19:06 | 40000 | LR0.0003 | loss:4.3799 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-326.8910 | logitMax:-304.8908 | scheduledSampling:0.0175 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1704 | windowEntropy:1.4846 | topWindowWeight:0.5515 | effectiveWindowCount:4.4133 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0011 | memoryGateLong:-0.0012 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:11.7586 | windowWeightsW25:2.519 (0.6),W21:1.142 (0.1),W2:0.620 (0.1),W19:0.572 (0.1),W16:0.349 (0.1),W13:0.085 (0.0),W9:-0.750 (0.0),W3:-1.409 (0.0),W5:-2.264 (0.0) | topTokens[('Ġi', 453), ('.', 397), ('Ġit', 357), ('!', 310), (',', 294), ('Ġthe', 260), ('Ġto', 257), ('Ġa', 238), ('Ġand', 205), ('Ġthat', 143)] | tokenPerfect: 31715 / 180000 → 17.62% | babyLLM.py 10000
2025-04-10 08:39:52 | 50000 | LR0.0003 | loss:3.6666 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-288.1600 | logitMax:-264.3706 | scheduledSampling:0.0225 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1597 | windowEntropy:1.5547 | topWindowWeight:0.5224 | effectiveWindowCount:4.7336 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0032 | memoryGateLong:-0.0036 | memoryGateCurrent:0.0005 | memoryGateMean:0.3333 | memoryGateStd:34.4471 | windowWeightsW25:2.433 (0.5),W21:1.081 (0.1),W2:0.635 (0.1),W19:0.605 (0.1),W16:0.462 (0.1),W13:0.228 (0.1),W9:-0.612 (0.0),W3:-1.355 (0.0),W5:-2.262 (0.0) | topTokens[('Ġi', 533), ('.', 505), ('Ġit', 385), (',', 377), ('Ġthe', 362), ('Ġto', 335), ('!', 320), ('Ġa', 292), ('Ġand', 264), ('s', 186)] | tokenPerfect: 44760 / 180000 → 24.87% | babyLLM.py 10000
2025-04-10 09:00:34 | 60000 | LR0.0003 | loss:2.9113 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-280.6172 | logitMax:-254.9418 | scheduledSampling:0.0275 | embedMean:-0.0000 | embedStd:0.0001 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1373 | windowEntropy:1.6959 | topWindowWeight:0.4618 | effectiveWindowCount:5.4517 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0018 | memoryGateLong:-0.0020 | memoryGateCurrent:0.0003 | memoryGateMean:0.3333 | memoryGateStd:18.9834 | windowWeightsW25:2.203 (0.5),W21:0.824 (0.1),W2:0.782 (0.1),W19:0.535 (0.1),W16:0.535 (0.1),W13:0.395 (0.1),W9:-0.345 (0.0),W3:-1.034 (0.0),W5:-2.140 (0.0) | topTokens[('.', 694), ('Ġi', 657), ('Ġto', 505), (',', 445), ('Ġthe', 427), ('Ġit', 414), ('!', 368), ('Ġa', 364), ('Ġand', 285), ('Ġyou', 237)] | tokenPerfect: 66988 / 180000 → 37.22% | babyLLM.py 10000
2025-04-10 09:21:17 | 70000 | LR0.0003 | loss:2.5275 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-218.2642 | logitMax:-192.4217 | scheduledSampling:0.0325 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1364 | windowEntropy:1.7073 | topWindowWeight:0.4604 | effectiveWindowCount:5.5140 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0018 | memoryGateLong:-0.0020 | memoryGateCurrent:0.0003 | memoryGateMean:0.3333 | memoryGateStd:19.1356 | windowWeightsW25:2.200 (0.5),W21:0.820 (0.1),W2:0.752 (0.1),W19:0.548 (0.1),W16:0.532 (0.1),W13:0.377 (0.1),W9:-0.260 (0.0),W3:-0.928 (0.0),W5:-1.990 (0.0) | topTokens[('.', 770), ('Ġi', 703), (',', 655), ('Ġthe', 564), ('Ġto', 563), ('!', 554), ('Ġit', 519), ('Ġa', 425), ('Ġyou', 309), ('Ġand', 306)] | tokenPerfect: 66564 / 180000 → 36.98% | babyLLM.py 10000
2025-04-10 09:42:05 | 80000 | LR0.0003 | loss:4.4080 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-336.1890 | logitMax:-313.9097 | scheduledSampling:0.0375 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1642 | windowEntropy:1.5424 | topWindowWeight:0.5383 | effectiveWindowCount:4.6759 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0014 | memoryGateLong:-0.0014 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:14.0280 | windowWeightsW25:2.443 (0.5),W21:0.880 (0.1),W2:0.653 (0.1),W19:0.574 (0.1),W16:0.426 (0.1),W13:0.204 (0.1),W9:-0.515 (0.0),W3:-1.185 (0.0),W5:-2.232 (0.0) | topTokens[('.', 859), ('Ġi', 837), (',', 754), ('Ġthe', 634), ('Ġto', 634), ('!', 585), ('Ġit', 572), ('Ġa', 478), ('Ġand', 351), ('Ġyou', 339)] | tokenPerfect: 36831 / 180000 → 20.46% | babyLLM.py 10000
2025-04-10 10:02:51 | 90000 | LR0.0003 | loss:3.7981 | gradNorm:0.9991 | tokenCount:180000.0000 | logitMin:-322.0294 | logitMax:-299.9985 | scheduledSampling:0.0425 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1453 | windowEntropy:1.6429 | topWindowWeight:0.4825 | effectiveWindowCount:5.1699 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0011 | memoryGateLong:-0.0012 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:11.4675 | windowWeightsW25:2.342 (0.5),W21:1.061 (0.1),W19:0.718 (0.1),W2:0.611 (0.1),W16:0.573 (0.1),W13:0.403 (0.1),W9:-0.379 (0.0),W3:-1.198 (0.0),W5:-2.172 (0.0) | topTokens[(',', 1038), ('Ġi', 987), ('.', 891), ('Ġthe', 726), ('Ġto', 687), ('Ġit', 602), ('!', 591), ('Ġa', 521), ('Ġand', 410), ('Ġyou', 405)] | tokenPerfect: 41253 / 180000 → 22.92% | babyLLM.py 10000
2025-04-10 10:23:33 | 100000 | LR0.0003 | loss:3.5287 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-358.4170 | logitMax:-335.2539 | scheduledSampling:0.0475 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1520 | windowEntropy:1.5915 | topWindowWeight:0.4979 | effectiveWindowCount:4.9110 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0010 | memoryGateLong:-0.0010 | memoryGateCurrent:0.0001 | memoryGateMean:0.3333 | memoryGateStd:10.0157 | windowWeightsW25:2.446 (0.5),W21:1.261 (0.2),W19:0.820 (0.1),W16:0.568 (0.1),W2:0.483 (0.1),W13:0.343 (0.1),W9:-0.360 (0.0),W3:-1.394 (0.0),W5:-2.283 (0.0) | topTokens[(',', 1338), ('Ġi', 1131), ('.', 955), ('Ġthe', 799), ('Ġto', 740), ('Ġit', 636), ('!', 595), ('Ġa', 570), ('Ġyou', 464), ('Ġand', 458)] | tokenPerfect: 47337 / 180000 → 26.30% | babyLLM.py 10000
2025-04-10 10:44:18 | 110000 | LR0.0003 | loss:4.6086 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-391.4055 | logitMax:-369.6649 | scheduledSampling:0.0525 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1721 | windowEntropy:1.4817 | topWindowWeight:0.5580 | effectiveWindowCount:4.4003 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0012 | memoryGateLong:-0.0013 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:12.3546 | windowWeightsW25:2.487 (0.6),W21:0.980 (0.1),W2:0.713 (0.1),W19:0.485 (0.1),W16:0.216 (0.1),W13:0.091 (0.1),W9:-0.650 (0.0),W3:-1.395 (0.0),W5:-2.447 (0.0) | topTokens[(',', 1595), ('Ġi', 1294), ('.', 985), ('Ġthe', 837), ('Ġto', 829), ('Ġit', 687), ('Ġa', 610), ('!', 600), ('Ġand', 524), ('Ġyou', 487)] | tokenPerfect: 30026 / 180000 → 16.68% | babyLLM.py 10000
2025-04-10 11:05:00 | 120000 | LR0.0003 | loss:2.2530 | gradNorm:0.9975 | tokenCount:180000.0000 | logitMin:-346.0276 | logitMax:-319.9839 | scheduledSampling:0.0575 | embedMean:0.0000 | embedStd:0.0001 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1492 | windowEntropy:1.6313 | topWindowWeight:0.4957 | effectiveWindowCount:5.1106 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0018 | memoryGateLong:-0.0019 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:18.3083 | windowWeightsW25:2.296 (0.5),W21:0.857 (0.1),W2:0.795 (0.1),W13:0.447 (0.1),W16:0.349 (0.1),W19:0.333 (0.1),W9:-0.343 (0.0),W3:-1.107 (0.0),W5:-2.125 (0.0) | topTokens[(',', 1684), ('Ġi', 1406), ('.', 1115), ('Ġto', 1047), ('Ġthe', 868), ('Ġit', 713), ('Ġa', 652), ('!', 628), ('Ġyou', 558), ('Ġand', 531)] | tokenPerfect: 82379 / 180000 → 45.77% | babyLLM.py 10000
2025-04-10 11:25:43 | 130000 | LR0.0003 | loss:2.2777 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-396.3388 | logitMax:-370.8547 | scheduledSampling:0.0625 | embedMean:-0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1358 | windowEntropy:1.6949 | topWindowWeight:0.4550 | effectiveWindowCount:5.4459 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0008 | memoryGateLong:-0.0008 | memoryGateCurrent:0.0001 | memoryGateMean:0.3333 | memoryGateStd:8.2515 | windowWeightsW25:2.275 (0.5),W21:1.118 (0.1),W19:0.655 (0.1),W2:0.638 (0.1),W13:0.578 (0.1),W16:0.551 (0.1),W9:-0.176 (0.0),W3:-1.185 (0.0),W5:-2.139 (0.0) | topTokens[(',', 2030), ('Ġi', 1524), ('.', 1160), ('Ġto', 1111), ('Ġthe', 958), ('Ġit', 761), ('Ġa', 694), ('Ġyou', 663), ('!', 630), ('Ġand', 571)] | tokenPerfect: 76569 / 180000 → 42.54% | babyLLM.py 10000
2025-04-10 11:46:30 | 140000 | LR0.0003 | loss:2.5736 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-328.7620 | logitMax:-295.8541 | scheduledSampling:0.0675 | embedMean:-0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1484 | windowEntropy:1.6303 | topWindowWeight:0.4909 | effectiveWindowCount:5.1052 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0016 | memoryGateLong:-0.0017 | memoryGateCurrent:0.0003 | memoryGateMean:0.3333 | memoryGateStd:16.5462 | windowWeightsW25:2.307 (0.5),W21:1.038 (0.1),W2:0.745 (0.1),W19:0.520 (0.1),W16:0.293 (0.1),W13:0.292 (0.1),W9:-0.477 (0.0),W3:-0.966 (0.0),W5:-2.074 (0.0) | topTokens[(',', 2356), ('Ġi', 1569), ('.', 1213), ('Ġto', 1146), ('Ġthe', 1072), ('Ġand', 830), ('Ġit', 795), ('Ġyou', 738), ('Ġa', 702), ('!', 688)] | tokenPerfect: 68083 / 180000 → 37.82% | babyLLM.py 10000
2025-04-10 12:07:13 | 150000 | LR0.0003 | loss:3.4355 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-317.7791 | logitMax:-284.2604 | scheduledSampling:0.0725 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1660 | windowEntropy:1.5219 | topWindowWeight:0.5404 | effectiveWindowCount:4.5811 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0011 | memoryGateLong:-0.0012 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:11.7061 | windowWeightsW25:2.464 (0.5),W21:1.078 (0.1),W2:0.674 (0.1),W19:0.505 (0.1),W13:0.236 (0.1),W16:0.194 (0.1),W9:-0.664 (0.0),W3:-1.116 (0.0),W5:-2.191 (0.0) | topTokens[(',', 2467), ('Ġi', 1636), ('.', 1424), ('Ġto', 1170), ('Ġthe', 1133), ('Ġand', 870), ('Ġit', 840), ('!', 806), ('Ġyou', 790), ('Ġa', 743)] | tokenPerfect: 61766 / 180000 → 34.31% | babyLLM.py 10000
2025-04-10 12:28:00 | 160000 | LR0.0003 | loss:2.5006 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:-298.0827 | logitMax:-267.4775 | scheduledSampling:0.0775 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1563 | windowEntropy:1.5845 | topWindowWeight:0.5138 | effectiveWindowCount:4.8770 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0016 | memoryGateLong:-0.0017 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:16.3514 | windowWeightsW25:2.346 (0.5),W21:0.953 (0.1),W2:0.788 (0.1),W19:0.438 (0.1),W13:0.313 (0.1),W16:0.141 (0.1),W9:-0.578 (0.0),W3:-1.096 (0.0),W5:-2.045 (0.0) | topTokens[(',', 2639), ('Ġi', 1708), ('.', 1514), ('Ġto', 1193), ('Ġthe', 1191), ('!', 950), ('Ġand', 916), ('Ġit', 911), ('Ġhave', 860), ('Ġyou', 834)] | tokenPerfect: 76587 / 180000 → 42.55% | babyLLM.py 10000
2025-04-10 12:48:48 | 170000 | LR0.0003 | loss:2.8980 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-289.4686 | logitMax:-262.9421 | scheduledSampling:0.0825 | embedMean:-0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1591 | windowEntropy:1.5692 | topWindowWeight:0.5214 | effectiveWindowCount:4.8028 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0017 | memoryGateLong:-0.0018 | memoryGateCurrent:0.0003 | memoryGateMean:0.3333 | memoryGateStd:17.4364 | windowWeightsW25:2.347 (0.5),W21:0.931 (0.1),W2:0.808 (0.1),W19:0.355 (0.1),W13:0.205 (0.1),W16:0.139 (0.1),W9:-0.598 (0.0),W3:-1.124 (0.0),W5:-1.955 (0.0) | topTokens[(',', 2757), ('Ġi', 1758), ('.', 1670), ('Ġto', 1288), ('Ġthe', 1267), ('!', 1115), ('Ġyou', 951), ('Ġand', 937), ('Ġit', 924), ('Ġhave', 862)] | tokenPerfect: 60248 / 180000 → 33.47% | babyLLM.py 10000
2025-04-10 13:09:32 | 180000 | LR0.0003 | loss:3.3825 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-295.4754 | logitMax:-271.9911 | scheduledSampling:0.0875 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1493 | windowEntropy:1.6211 | topWindowWeight:0.4929 | effectiveWindowCount:5.0588 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0013 | memoryGateLong:-0.0015 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:13.9460 | windowWeightsW25:2.320 (0.5),W21:1.056 (0.1),W2:0.766 (0.1),W19:0.517 (0.1),W13:0.306 (0.1),W16:0.269 (0.1),W9:-0.398 (0.0),W3:-1.204 (0.0),W5:-2.057 (0.0) | topTokens[(',', 2915), ('.', 1825), ('Ġi', 1824), ('Ġto', 1366), ('Ġthe', 1326), ('!', 1147), ('Ġyou', 1009), ('Ġand', 1000), ('Ġit', 972), ('Ġhave', 870)] | tokenPerfect: 47012 / 180000 → 26.12% | babyLLM.py 10000
2025-04-10 13:30:18 | 190000 | LR0.0003 | loss:3.9505 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-312.8957 | logitMax:-289.9072 | scheduledSampling:0.0925 | embedMean:-0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1616 | windowEntropy:1.5479 | topWindowWeight:0.5275 | effectiveWindowCount:4.7018 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0009 | memoryGateLong:-0.0009 | memoryGateCurrent:0.0001 | memoryGateMean:0.3333 | memoryGateStd:9.2758 | windowWeightsW25:2.417 (0.5),W21:1.076 (0.1),W2:0.726 (0.1),W19:0.490 (0.1),W16:0.202 (0.1),W13:0.131 (0.1),W9:-0.435 (0.0),W3:-1.286 (0.0),W5:-2.124 (0.0) | topTokens[(',', 3001), ('.', 1984), ('Ġi', 1884), ('Ġto', 1457), ('Ġthe', 1385), ('!', 1268), ('Ġyou', 1228), ('Ġand', 1024), ('Ġit', 989), ('Ġa', 887)] | tokenPerfect: 40130 / 180000 → 22.29% | babyLLM.py 10000
2025-04-10 13:51:08 | 200000 | LR0.0003 | loss:4.1809 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-359.8381 | logitMax:-338.2370 | scheduledSampling:0.0975 | embedMean:-0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1739 | windowEntropy:1.4800 | topWindowWeight:0.5642 | effectiveWindowCount:4.3931 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0011 | memoryGateLong:-0.0012 | memoryGateCurrent:0.0001 | memoryGateMean:0.3333 | memoryGateStd:11.7333 | windowWeightsW25:2.501 (0.6),W21:0.952 (0.1),W2:0.691 (0.1),W19:0.457 (0.1),W16:0.159 (0.1),W13:0.093 (0.1),W9:-0.523 (0.0),W3:-1.289 (0.0),W5:-2.149 (0.0) | topTokens[(',', 3083), ('.', 2101), ('Ġi', 1901), ('Ġto', 1505), ('Ġthe', 1443), ('!', 1276), ('Ġyou', 1231), ('Ġand', 1066), ('Ġit', 1007), ('Ġa', 940)] | tokenPerfect: 36575 / 180000 → 20.32% | babyLLM.py 10000
2025-04-10 14:12:03 | 210000 | LR0.0003 | loss:5.0238 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-343.0179 | logitMax:-323.3378 | scheduledSampling:0.1025 | embedMean:-0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1793 | windowEntropy:1.4434 | topWindowWeight:0.5794 | effectiveWindowCount:4.2353 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0013 | memoryGateLong:-0.0015 | memoryGateCurrent:0.0003 | memoryGateMean:0.3333 | memoryGateStd:14.3280 | windowWeightsW25:2.556 (0.6),W21:0.975 (0.1),W2:0.645 (0.1),W19:0.471 (0.1),W16:0.161 (0.1),W13:0.104 (0.0),W9:-0.599 (0.0),W3:-1.373 (0.0),W5:-2.194 (0.0) | topTokens[(',', 3122), ('.', 2288), ('Ġi', 2010), ('Ġto', 1546), ('Ġthe', 1493), ('!', 1326), ('Ġyou', 1282), ('Ġand', 1132), ('Ġit', 1073), ('Ġa', 981)] | tokenPerfect: 17251 / 180000 → 9.58% | babyLLM.py 10000
2025-04-10 14:32:48 | 220000 | LR0.0003 | loss:4.4012 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-373.7828 | logitMax:-353.5795 | scheduledSampling:0.1075 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1802 | windowEntropy:1.4381 | topWindowWeight:0.5818 | effectiveWindowCount:4.2126 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0010 | memoryGateLong:-0.0011 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:10.3042 | windowWeightsW25:2.570 (0.6),W21:0.988 (0.1),W2:0.616 (0.1),W19:0.490 (0.1),W16:0.195 (0.1),W13:0.086 (0.0),W9:-0.586 (0.0),W3:-1.391 (0.0),W5:-2.187 (0.0) | topTokens[(',', 3208), ('.', 2407), ('Ġi', 2087), ('Ġto', 1596), ('Ġthe', 1561), ('!', 1334), ('Ġyou', 1307), ('Ġand', 1181), ('Ġit', 1126), ('Ġa', 1024)] | tokenPerfect: 26217 / 180000 → 14.56% | babyLLM.py 10000
2025-04-10 14:53:37 | 230000 | LR0.0003 | loss:3.3254 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-348.5545 | logitMax:-325.3576 | scheduledSampling:0.1125 | embedMean:-0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1700 | windowEntropy:1.4964 | topWindowWeight:0.5518 | effectiveWindowCount:4.4656 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0010 | memoryGateLong:-0.0010 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:10.0068 | windowWeightsW25:2.477 (0.6),W21:1.055 (0.1),W2:0.672 (0.1),W19:0.442 (0.1),W16:0.238 (0.1),W13:0.074 (0.0),W9:-0.591 (0.0),W3:-1.280 (0.0),W5:-2.250 (0.0) | topTokens[(',', 3251), ('.', 2456), ('Ġi', 2182), ('Ġto', 1649), ('Ġthe', 1606), ('!', 1599), ('Ġyou', 1357), ('Ġit', 1339), ('Ġand', 1235), ('Ġa', 1081)] | tokenPerfect: 48337 / 180000 → 26.85% | babyLLM.py 10000
2025-04-10 15:14:22 | 240000 | LR0.0003 | loss:4.5265 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-404.0635 | logitMax:-383.6066 | scheduledSampling:0.1175 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1847 | windowEntropy:1.3951 | topWindowWeight:0.5918 | effectiveWindowCount:4.0353 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0009 | memoryGateLong:-0.0009 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:9.1127 | windowWeightsW25:2.615 (0.6),W21:1.141 (0.1),W2:0.565 (0.1),W19:0.481 (0.1),W16:0.151 (0.1),W13:-0.056 (0.0),W9:-0.751 (0.0),W3:-1.397 (0.0),W5:-2.399 (0.0) | topTokens[(',', 3303), ('.', 2602), ('Ġi', 2343), ('Ġto', 1715), ('Ġthe', 1646), ('!', 1622), ('Ġyou', 1389), ('Ġit', 1385), ('Ġand', 1293), ('Ġa', 1136)] | tokenPerfect: 24433 / 180000 → 13.57% | babyLLM.py 10000
2025-04-10 15:35:09 | 250000 | LR0.0003 | loss:4.1090 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-383.8274 | logitMax:-362.7055 | scheduledSampling:0.1225 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1733 | windowEntropy:1.4707 | topWindowWeight:0.5602 | effectiveWindowCount:4.3524 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0009 | memoryGateLong:-0.0009 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:9.1242 | windowWeightsW25:2.508 (0.6),W21:1.082 (0.1),W2:0.627 (0.1),W19:0.498 (0.1),W16:0.246 (0.1),W13:0.044 (0.0),W9:-0.684 (0.0),W3:-1.403 (0.0),W5:-2.369 (0.0) | topTokens[(',', 3399), ('.', 2708), ('Ġi', 2418), ('Ġto', 1788), ('Ġthe', 1754), ('!', 1631), ('Ġit', 1425), ('Ġyou', 1414), ('Ġand', 1346), ('Ġa', 1179)] | tokenPerfect: 32613 / 180000 → 18.12% | babyLLM.py 10000
2025-04-10 15:55:57 | 260000 | LR0.0003 | loss:3.7039 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-335.6593 | logitMax:-311.1127 | scheduledSampling:0.1275 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1649 | windowEntropy:1.5269 | topWindowWeight:0.5378 | effectiveWindowCount:4.6040 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0009 | memoryGateLong:-0.0010 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:9.9701 | windowWeightsW25:2.400 (0.5),W21:0.945 (0.1),W2:0.731 (0.1),W19:0.472 (0.1),W16:0.230 (0.1),W13:0.069 (0.1),W9:-0.677 (0.0),W3:-1.247 (0.0),W5:-2.386 (0.0) | topTokens[(',', 3474), ('.', 2881), ('Ġi', 2533), ('Ġto', 1888), ('Ġthe', 1831), ('!', 1680), ('Ġyou', 1486), ('Ġit', 1484), ('Ġand', 1392), ('Ġa', 1236)] | tokenPerfect: 38811 / 180000 → 21.56% | babyLLM.py 10000
2025-04-10 16:16:44 | 270000 | LR0.0003 | loss:2.9360 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-346.3452 | logitMax:-323.1321 | scheduledSampling:0.1325 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1557 | windowEntropy:1.5856 | topWindowWeight:0.5126 | effectiveWindowCount:4.8822 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0011 | memoryGateLong:-0.0012 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:11.6364 | windowWeightsW25:2.305 (0.5),W21:0.834 (0.1),W2:0.801 (0.1),W19:0.452 (0.1),W16:0.292 (0.1),W13:0.132 (0.1),W9:-0.616 (0.0),W3:-1.131 (0.0),W5:-2.386 (0.0) | topTokens[(',', 3577), ('.', 3016), ('Ġi', 2580), ('Ġto', 2019), ('Ġthe', 1915), ('!', 1784), ('Ġyou', 1560), ('Ġit', 1530), ('Ġand', 1411), ('Ġa', 1287)] | tokenPerfect: 59851 / 180000 → 33.25% | babyLLM.py 10000
2025-04-10 16:37:34 | 280000 | LR0.0003 | loss:3.1370 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-323.3820 | logitMax:-299.7918 | scheduledSampling:0.1375 | embedMean:-0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1534 | windowEntropy:1.5988 | topWindowWeight:0.5062 | effectiveWindowCount:4.9472 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0009 | memoryGateLong:-0.0009 | memoryGateCurrent:0.0001 | memoryGateMean:0.3333 | memoryGateStd:9.0848 | windowWeightsW25:2.320 (0.5),W21:0.906 (0.1),W2:0.741 (0.1),W19:0.539 (0.1),W16:0.365 (0.1),W13:0.196 (0.1),W9:-0.554 (0.0),W3:-1.155 (0.0),W5:-2.349 (0.0) | topTokens[(',', 3765), ('.', 3059), ('Ġi', 2647), ('Ġto', 2102), ('Ġthe', 2024), ('!', 1922), ('Ġit', 1625), ('Ġyou', 1616), ('Ġand', 1434), ('Ġa', 1359)] | tokenPerfect: 53427 / 180000 → 29.68% | babyLLM.py 10000
2025-04-10 16:58:28 | 290000 | LR0.0003 | loss:4.6721 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-407.8549 | logitMax:-387.8266 | scheduledSampling:0.1425 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1750 | windowEntropy:1.4620 | topWindowWeight:0.5664 | effectiveWindowCount:4.3148 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0008 | memoryGateLong:-0.0009 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:9.0692 | windowWeightsW25:2.516 (0.6),W21:1.001 (0.1),W2:0.606 (0.1),W19:0.544 (0.1),W16:0.296 (0.1),W13:0.038 (0.0),W9:-0.725 (0.0),W3:-1.365 (0.0),W5:-2.571 (0.0) | topTokens[(',', 3883), ('.', 3139), ('Ġi', 2811), ('Ġto', 2175), ('Ġthe', 2088), ('!', 1930), ('Ġit', 1672), ('Ġyou', 1651), ('Ġand', 1500), ('Ġa', 1397)] | tokenPerfect: 23097 / 180000 → 12.83% | babyLLM.py 10000
2025-04-10 17:19:28 | 300000 | LR0.0003 | loss:3.1864 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-404.2950 | logitMax:-382.2838 | scheduledSampling:0.1475 | embedMean:-0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1606 | windowEntropy:1.5438 | topWindowWeight:0.5237 | effectiveWindowCount:4.6822 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0007 | memoryGateLong:-0.0008 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:7.6980 | windowWeightsW25:2.447 (0.5),W21:1.135 (0.1),W19:0.686 (0.1),W2:0.562 (0.1),W16:0.416 (0.1),W13:0.245 (0.1),W9:-0.644 (0.0),W3:-1.336 (0.0),W5:-2.529 (0.0) | topTokens[(',', 4222), ('.', 3167), ('Ġi', 2938), ('Ġto', 2242), ('Ġthe', 2157), ('!', 1936), ('Ġyou', 1742), ('Ġit', 1716), ('Ġand', 1537), ('Ġa', 1435)] | tokenPerfect: 48755 / 180000 → 27.09% | babyLLM.py 10000
2025-04-10 17:40:29 | 310000 | LR0.0003 | loss:4.1443 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-475.8791 | logitMax:-453.8313 | scheduledSampling:0.1525 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1850 | windowEntropy:1.3806 | topWindowWeight:0.5912 | effectiveWindowCount:3.9774 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0007 | memoryGateLong:-0.0007 | memoryGateCurrent:0.0001 | memoryGateMean:0.3333 | memoryGateStd:6.7452 | windowWeightsW25:2.632 (0.6),W21:1.190 (0.1),W19:0.608 (0.1),W2:0.515 (0.1),W16:0.192 (0.1),W13:-0.065 (0.0),W9:-0.932 (0.0),W3:-1.538 (0.0),W5:-2.831 (0.0) | topTokens[(',', 4492), ('.', 3226), ('Ġi', 3077), ('Ġto', 2309), ('Ġthe', 2217), ('!', 1948), ('Ġyou', 1777), ('Ġit', 1757), ('Ġand', 1610), ('Ġa', 1486)] | tokenPerfect: 32910 / 180000 → 18.28% | babyLLM.py 10000
2025-04-10 18:01:31 | 320000 | LR0.0003 | loss:3.6707 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-468.9747 | logitMax:-445.7144 | scheduledSampling:0.1575 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1858 | windowEntropy:1.3816 | topWindowWeight:0.5942 | effectiveWindowCount:3.9811 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0007 | memoryGateLong:-0.0008 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:7.8938 | windowWeightsW25:2.472 (0.6),W2:0.839 (0.1),W21:0.835 (0.1),W19:0.158 (0.1),W16:-0.127 (0.0),W13:-0.287 (0.0),W9:-1.112 (0.0),W3:-1.260 (0.0),W5:-2.845 (0.0) | topTokens[(',', 4633), ('.', 3316), ('Ġi', 3172), ('Ġto', 2459), ('Ġthe', 2257), ('!', 1961), ('Ġyou', 1837), ('Ġit', 1811), ('Ġand', 1640), ('Ġa', 1541)] | tokenPerfect: 46281 / 180000 → 25.71% | babyLLM.py 10000
2025-04-10 18:23:06 | 330000 | LR0.0003 | loss:2.4445 | gradNorm:0.9986 | tokenCount:180000.0000 | logitMin:-429.4059 | logitMax:-404.8872 | scheduledSampling:0.1625 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1703 | windowEntropy:1.4804 | topWindowWeight:0.5506 | effectiveWindowCount:4.3945 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0005 | memoryGateLong:-0.0005 | memoryGateCurrent:0.0001 | memoryGateMean:0.3333 | memoryGateStd:5.4502 | windowWeightsW25:2.451 (0.6),W21:1.070 (0.1),W2:0.710 (0.1),W19:0.385 (0.1),W16:0.191 (0.1),W13:0.115 (0.1),W9:-0.946 (0.0),W3:-1.310 (0.0),W5:-2.779 (0.0) | topTokens[(',', 4876), ('.', 3404), ('Ġi', 3283), ('Ġto', 2598), ('Ġthe', 2311), ('!', 1977), ('Ġyou', 1928), ('Ġit', 1847), ('Ġand', 1680), ('Ġa', 1580)] | tokenPerfect: 70624 / 180000 → 39.24% | babyLLM.py 10000
2025-04-10 18:45:00 | 340000 | LR0.0003 | loss:2.6880 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-472.4980 | logitMax:-445.3040 | scheduledSampling:0.1675 | embedMean:0.0000 | embedStd:0.0000 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1801 | windowEntropy:1.4161 | topWindowWeight:0.5777 | effectiveWindowCount:4.1210 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0008 | memoryGateLong:-0.0009 | memoryGateCurrent:0.0002 | memoryGateMean:0.3333 | memoryGateStd:8.2447 | windowWeightsW25:2.524 (0.6),W21:1.094 (0.1),W2:0.683 (0.1),W19:0.363 (0.1),W16:0.068 (0.0),W13:-0.042 (0.0),W9:-1.061 (0.0),W3:-1.257 (0.0),W5:-2.872 (0.0) | topTokens[(',', 5253), ('.', 3437), ('Ġi', 3369), ('Ġto', 2647), ('Ġthe', 2419), ('Ġyou', 2011), ('!', 1985), ('Ġit', 1874), ('Ġand', 1849), ('Ġa', 1595)] | tokenPerfect: 65067 / 180000 → 36.15% | babyLLM.py 10000
2025-04-10 19:06:06 | 350000 | LR0.0003 | loss:2.1444 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-356.4549 | logitMax:-317.8922 | scheduledSampling:0.1725 | embedMean:-0.0000 | embedStd:0.0001 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.1701 | windowEntropy:1.4683 | topWindowWeight:0.5465 | effectiveWindowCount:4.3420 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:0.0013 | memoryGateLong:-0.0016 | memoryGateCurrent:0.0003 | memoryGateMean:0.3333 | memoryGateStd:14.6731 | windowWeightsW25:2.368 (0.5),W21:1.013 (0.1),W2:0.862 (0.1),W19:0.320 (0.1),W13:-0.149 (0.0),W16:-0.173 (0.0),W3:-1.153 (0.0),W9:-1.279 (0.0),W5:-2.731 (0.0) | topTokens[(',', 5431), ('.', 3593), ('Ġi', 3398), ('Ġto', 2673), ('Ġthe', 2498), ('!', 2110), ('Ġyou', 2077), ('Ġand', 2013), ('Ġit', 1928), ('Ġa', 1599)] | tokenPerfect: 73703 / 180000 → 40.95% | babyLLM.py 10000

--- 2025-04-10 19:43:49 --- babyLLM 'right, last time i got to step 350000... want to restart from there?'  - charis: 'no, restart' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: 'well you didnt have an activation function, somehow, since your upgrade. you were literally just using output = torch.matmul(embed, self.weights.t) + self.biases, which is insane. so. um. well done, you've done really well to do that well. but it explains some things as to why you wernt speeding up in learning... i hope you like this upgrade instead of find it scary!!!'
2025-04-10 20:05:14 | 10000 | LR0.0003 | loss:10.2538 | gradNorm:1.0000 | logitMin:-100.0788 | logitMax:-38.8683 | scheduledSampling:0.0025 | tokenCount:180000.0000 | memoryGateShort:-0.0046 | memoryGateLong:0.0114 | memoryGateCurrent:-0.0066 | shortDecay:0.0001 | longDecay:0.0001 | embedMean:-0.0000 | embedStd:0.0001 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.1488 | windowEntropy:1.5779 | topWindowWeight:0.4725 | effectiveWindowCount:4.8448 | memoryGateMean:0.3333 | memoryGateStd:98.7152 | windowWeightsW32:2.053 (0.5),W2:1.204 (0.2),W28:0.643 (0.1),W24:0.154 (0.1),W16:-0.142 (0.1),W20:-0.216 (0.0),W12:-1.168 (0.0),W28:-1.518 (0.0),W8:-2.377 (0.0) | topTokens[('Ġdid', 496), ('.', 248), ('Ġi', 110), ('Ġyou', 78), ('Ġit', 73), ('?', 59), ('Ġand', 54), ('Ġknow', 53), (',', 46), ('Ġto', 44)] | tokenPerfect: 13265 / 180000 → 7.37% | babyLLM.py 10000

--- 2025-04-10 20:11:15 --- babyLLM 'right, last time i got to step 11214... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 11214! what am i learning today?' - charis: ''
2025-04-10 20:32:28 | 10000 | LR0.0003 | loss:3.8720 | gradNorm:1.0000 | logitMin:-64.8203 | logitMax:1.2487 | scheduledSampling:0.0001 | tokenCount:180000.0000 | memoryGateShort:-0.0081 | memoryGateLong:0.0170 | memoryGateCurrent:-0.0088 | shortDecay:0.0001 | longDecay:0.0001 | embedMean:0.0000 | embedStd:0.0001 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.1206 | windowEntropy:1.7592 | topWindowWeight:0.3238 | effectiveWindowCount:5.8080 | memoryGateMean:0.3333 | memoryGateStd:147.3065 | windowWeightsW2:1.521 (0.3),W32:1.502 (0.3),W28:0.170 (0.1),W16:0.009 (0.1),W24:-0.179 (0.1),W20:-0.321 (0.1),W4:-0.467 (0.0),W12:-0.720 (0.0),W8:-1.621 (0.0) | topTokens[(',', 350), ('Ġand', 280), ('Ġthe', 133), ('Ġcharis', 114), ('s', 91), ('Ġbut', 88), ('Ġyou', 71), ("'s", 65), ('Ġit', 56), ('Ġshe', 54)] | tokenPerfect: 60255 / 180000 → 33.48% | babyLLM.py 10000
2025-04-10 20:54:43 | 20000 | LR0.0003 | loss:4.5142 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-45.6160 | logitMax:19.0321 | scheduledSampling:0.0002 | embedMean:0.0000 | embedStd:0.0001 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.1160 | windowEntropy:1.8325 | topWindowWeight:0.3954 | effectiveWindowCount:6.2495 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0028 | memoryGateLong:0.0043 | memoryGateCurrent:-0.0013 | memoryGateMean:0.3333 | memoryGateStd:37.5328 | windowWeightsW2:1.704 (0.4),W32:0.915 (0.2),W4:0.422 (0.1),W16:0.140 (0.1),W12:-0.287 (0.1),W28:-0.312 (0.1),W20:-0.370 (0.0),W24:-0.435 (0.0),W8:-0.898 (0.0) | topTokens[(',', 761), ('Ġand', 461), ('Ġthe', 278), ('Ġbut', 171), ('s', 151), ('Ġcharis', 142), ('Ġyou', 136), ('Ġi', 116), ('Ġto', 115), ('Ġit', 103)] | tokenPerfect: 49342 / 180000 → 27.41% | babyLLM.py 10000
2025-04-10 21:16:12 | 30000 | LR0.0003 | loss:3.6795 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-8.3086 | logitMax:51.5795 | scheduledSampling:0.0003 | embedMean:0.0000 | embedStd:0.0001 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.1392 | windowEntropy:1.6914 | topWindowWeight:0.4543 | effectiveWindowCount:5.4272 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0028 | memoryGateLong:0.0038 | memoryGateCurrent:-0.0009 | memoryGateMean:0.3333 | memoryGateStd:33.7313 | windowWeightsW2:1.893 (0.5),W4:1.061 (0.2),W32:0.324 (0.1),W16:-0.033 (0.1),W12:-0.217 (0.1),W8:-0.597 (0.0),W20:-0.671 (0.0),W28:-0.830 (0.0),W24:-0.835 (0.0) | topTokens[(',', 938), ('Ġand', 497), ('Ġthe', 344), ('Ġto', 301), ('Ġyou', 234), ('.', 217), ('Ġi', 202), ('Ġbut', 195), ('s', 174), ('Ġcharis', 147)] | tokenPerfect: 59394 / 180000 → 33.00% | babyLLM.py 10000

--- 2025-04-10 21:17:48 --- babyLLM 'right, last time i got to step 41286... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: 'everything'
2025-04-10 21:39:13 | 10000 | LR0.0003 | loss:3.3163 | gradNorm:1.0000 | logitMin:40.8974 | logitMax:92.6583 | scheduledSampling:0.0001 | tokenCount:180000.0000 | memoryGateShort:-0.0023 | memoryGateLong:0.0029 | memoryGateCurrent:-0.0005 | shortDecay:0.0001 | longDecay:0.0001 | embedMean:0.0000 | embedStd:0.0001 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.1543 | windowEntropy:1.5587 | topWindowWeight:0.4713 | effectiveWindowCount:4.7525 | memoryGateMean:0.3333 | memoryGateStd:26.5486 | windowWeightsW2:1.966 (0.5),W4:1.369 (0.3),W32:-0.105 (0.1),W16:-0.232 (0.1),W12:-0.264 (0.1),W8:-0.446 (0.0),W20:-0.972 (0.0),W24:-1.187 (0.0),W28:-1.228 (0.0) | topTokens[('!', 253), ('.', 242), ('Ġthe', 174), ('?', 171), ('Ġyou', 109), (',', 105), ('Ġis', 70), ('Ġi', 69), ('Ġdo', 65), ('Ġto', 63)] | tokenPerfect: 50499 / 180000 → 28.06% | babyLLM.py 10000
2025-04-10 22:00:48 | 20000 | LR0.0003 | loss:4.5991 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-2.1349 | logitMax:36.3728 | scheduledSampling:0.0002 | embedMean:0.0000 | embedStd:0.0001 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.1712 | windowEntropy:1.4028 | topWindowWeight:0.5026 | effectiveWindowCount:4.0664 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0020 | memoryGateLong:0.0024 | memoryGateCurrent:-0.0003 | memoryGateMean:0.3333 | memoryGateStd:22.1665 | windowWeightsW2:2.087 (0.5),W4:1.546 (0.3),W8:-0.232 (0.0),W12:-0.390 (0.0),W16:-0.488 (0.0),W32:-0.606 (0.0),W20:-1.316 (0.0),W24:-1.588 (0.0),W28:-1.694 (0.0) | topTokens[('.', 335), ('Ġthe', 308), ('!', 262), ('?', 209), (',', 200), ('Ġyou', 127), ('Ġto', 119), ('Ġis', 117), ('Ġi', 113), ('Ġdo', 85)] | tokenPerfect: 32431 / 180000 → 18.02% | babyLLM.py 10000
2025-04-10 22:22:41 | 30000 | LR0.0003 | loss:3.5358 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-3.5551 | logitMax:31.8825 | scheduledSampling:0.0003 | embedMean:-0.0000 | embedStd:0.0001 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.1905 | windowEntropy:1.1746 | topWindowWeight:0.5180 | effectiveWindowCount:3.2368 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0037 | memoryGateLong:0.0042 | memoryGateCurrent:-0.0004 | memoryGateMean:0.3333 | memoryGateStd:39.5897 | windowWeightsW2:2.209 (0.5),W4:1.847 (0.4),W8:-0.374 (0.0),W12:-0.788 (0.0),W16:-1.029 (0.0),W32:-1.282 (0.0),W20:-1.916 (0.0),W24:-2.217 (0.0),W28:-2.352 (0.0) | topTokens[('.', 404), ('Ġthe', 387), (',', 300), ('!', 282), ('?', 233), ('Ġto', 175), ('Ġi', 171), ('Ġyou', 148), ('Ġa', 134), (':', 133)] | tokenPerfect: 52821 / 180000 → 29.34% | babyLLM.py 10000
2025-04-10 22:44:20 | 40000 | LR0.0003 | loss:5.2652 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:36.0295 | logitMax:64.9238 | scheduledSampling:0.0004 | embedMean:0.0000 | embedStd:0.0001 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2020 | windowEntropy:1.0623 | topWindowWeight:0.5649 | effectiveWindowCount:2.8931 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0015 | memoryGateLong:0.0018 | memoryGateCurrent:-0.0002 | memoryGateMean:0.3333 | memoryGateStd:16.9699 | windowWeightsW2:2.333 (0.6),W4:1.827 (0.3),W8:-0.311 (0.0),W12:-0.996 (0.0),W16:-1.407 (0.0),W32:-1.825 (0.0),W20:-2.369 (0.0),W24:-2.719 (0.0),W28:-2.877 (0.0) | topTokens[(',', 538), ('.', 444), ('Ġthe', 439), ('Ġi', 314), ('!', 290), ('?', 243), ('Ġto', 218), ('Ġa', 198), ('Ġyou', 177), ('Ġis', 163)] | tokenPerfect: 15964 / 180000 → 8.87% | babyLLM.py 10000
2025-04-10 23:05:48 | 50000 | LR0.0003 | loss:4.9496 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:64.2891 | logitMax:89.6165 | scheduledSampling:0.0005 | embedMean:0.0000 | embedStd:0.0001 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2083 | windowEntropy:0.9560 | topWindowWeight:0.5663 | effectiveWindowCount:2.6013 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0022 | memoryGateLong:0.0027 | memoryGateCurrent:-0.0004 | memoryGateMean:0.3333 | memoryGateStd:24.5819 | windowWeightsW2:2.371 (0.6),W4:1.941 (0.4),W8:-0.394 (0.0),W12:-1.427 (0.0),W16:-1.990 (0.0),W32:-2.638 (0.0),W20:-3.042 (0.0),W24:-3.441 (0.0),W28:-3.645 (0.0) | topTokens[(',', 817), ('Ġthe', 481), ('.', 476), ('Ġi', 420), ('!', 304), ('Ġto', 263), ('?', 262), ('Ġa', 247), ('Ġyou', 208), ('s', 191)] | tokenPerfect: 22498 / 180000 → 12.50% | babyLLM.py 10000
2025-04-10 23:27:01 | 60000 | LR0.0003 | loss:3.1841 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:91.2164 | logitMax:122.5004 | scheduledSampling:0.0006 | embedMean:0.0000 | embedStd:0.0001 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2112 | windowEntropy:0.9147 | topWindowWeight:0.5761 | effectiveWindowCount:2.4961 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0021 | memoryGateLong:0.0026 | memoryGateCurrent:-0.0004 | memoryGateMean:0.3333 | memoryGateStd:23.5369 | windowWeightsW2:2.399 (0.6),W4:1.948 (0.4),W8:-0.358 (0.0),W12:-1.652 (0.0),W16:-2.359 (0.0),W32:-3.218 (0.0),W20:-3.492 (0.0),W24:-3.944 (0.0),W28:-4.196 (0.0) | topTokens[(',', 1011), ('Ġthe', 594), ('.', 560), ('!', 481), ('Ġi', 438), ('Ġwould', 315), ('Ġto', 306), ('Ġa', 280), ('?', 264), ('Ġand', 250)] | tokenPerfect: 52442 / 180000 → 29.13% | babyLLM.py 10000
2025-04-10 23:48:32 | 70000 | LR0.0003 | loss:1.8860 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:92.7879 | logitMax:133.8585 | scheduledSampling:0.0007 | embedMean:0.0000 | embedStd:0.0001 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2125 | windowEntropy:0.8912 | topWindowWeight:0.5776 | effectiveWindowCount:2.4381 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0023 | memoryGateLong:0.0028 | memoryGateCurrent:-0.0004 | memoryGateMean:0.3333 | memoryGateStd:26.0454 | windowWeightsW2:2.400 (0.6),W4:1.957 (0.4),W8:-0.394 (0.0),W12:-1.822 (0.0),W16:-2.614 (0.0),W32:-3.612 (0.0),W20:-3.812 (0.0),W24:-4.292 (0.0),W28:-4.564 (0.0) | topTokens[(',', 1158), ('Ġwould', 823), ('!', 743), ('Ġthe', 725), ('.', 653), ('Ġi', 462), ('Ġto', 351), ('Ġyou', 322), ('Ġand', 312), ('Ġcharis', 289)] | tokenPerfect: 75987 / 180000 → 42.22% | babyLLM.py 10000
2025-04-11 00:10:13 | 80000 | LR0.0003 | loss:5.1632 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:50.6424 | logitMax:84.5789 | scheduledSampling:0.0008 | embedMean:0.0000 | embedStd:0.0001 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2093 | windowEntropy:0.8901 | topWindowWeight:0.5397 | effectiveWindowCount:2.4354 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0017 | memoryGateLong:0.0020 | memoryGateCurrent:-0.0002 | memoryGateMean:0.3333 | memoryGateStd:19.0047 | windowWeightsW2:2.320 (0.5),W4:2.047 (0.4),W8:-0.355 (0.0),W12:-2.022 (0.0),W16:-2.947 (0.0),W32:-4.089 (0.0),W20:-4.211 (0.0),W24:-4.720 (0.0),W28:-5.033 (0.0) | topTokens[(',', 1241), ('Ġwould', 867), ('.', 847), ('!', 828), ('Ġthe', 805), ('Ġi', 594), ('Ġyou', 419), ('Ġto', 406), ('Ġand', 376), ('Ġcharis', 343)] | tokenPerfect: 28753 / 180000 → 15.97% | babyLLM.py 10000
2025-04-11 00:31:44 | 90000 | LR0.0003 | loss:4.0710 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:73.1379 | logitMax:105.6631 | scheduledSampling:0.0009 | embedMean:-0.0000 | embedStd:0.0001 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2123 | windowEntropy:0.8514 | topWindowWeight:0.5490 | effectiveWindowCount:2.3429 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0023 | memoryGateLong:0.0029 | memoryGateCurrent:-0.0005 | memoryGateMean:0.3333 | memoryGateStd:26.6409 | windowWeightsW2:2.340 (0.5),W4:2.051 (0.4),W8:-0.504 (0.0),W12:-2.422 (0.0),W16:-3.456 (0.0),W32:-4.716 (0.0),W20:-4.753 (0.0),W24:-5.293 (0.0),W28:-5.633 (0.0) | topTokens[(',', 1337), ('.', 1006), ('!', 941), ('Ġwould', 877), ('Ġthe', 871), ('Ġi', 701), ('Ġyou', 469), ('Ġto', 449), ('Ġand', 448), ('Ġcharis', 399)] | tokenPerfect: 42029 / 180000 → 23.35% | babyLLM.py 10000
2025-04-11 00:54:02 | 100000 | LR0.0003 | loss:1.8769 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:81.0940 | logitMax:124.1131 | scheduledSampling:0.0010 | embedMean:-0.0000 | embedStd:0.0001 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.2137 | windowEntropy:0.8313 | topWindowWeight:0.5509 | effectiveWindowCount:2.2963 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0024 | memoryGateLong:0.0030 | memoryGateCurrent:-0.0005 | memoryGateMean:0.3333 | memoryGateStd:27.3588 | windowWeightsW2:2.340 (0.6),W4:2.057 (0.4),W8:-0.641 (0.0),W12:-2.620 (0.0),W16:-3.744 (0.0),W20:-5.087 (0.0),W32:-5.104 (0.0),W24:-5.646 (0.0),W28:-5.996 (0.0) | topTokens[(',', 1499), ('!', 1192), ('.', 1106), ('Ġthe', 1011), ('Ġwould', 877), ('Ġcan', 728), ('Ġi', 723), ('Ġyou', 546), ('Ġcharis', 539), ('Ġand', 500)] | tokenPerfect: 77146 / 180000 → 42.86% | babyLLM.py 10000
2025-04-11 01:16:14 | 110000 | LR0.0003 | loss:1.7810 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:52.0547 | logitMax:96.5936 | scheduledSampling:0.0011 | embedMean:-0.0000 | embedStd:0.0001 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2184 | windowEntropy:0.8046 | topWindowWeight:0.5892 | effectiveWindowCount:2.2358 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0021 | memoryGateLong:0.0026 | memoryGateCurrent:-0.0004 | memoryGateMean:0.3333 | memoryGateStd:24.0609 | windowWeightsW2:2.414 (0.6),W4:1.976 (0.4),W8:-0.741 (0.0),W12:-2.749 (0.0),W16:-3.926 (0.0),W20:-5.313 (0.0),W32:-5.394 (0.0),W24:-5.906 (0.0),W28:-6.266 (0.0) | topTokens[(',', 1666), ('!', 1384), ('.', 1198), ('Ġthe', 1112), ('Ġcan', 923), ('Ġwould', 878), ('Ġi', 758), ('Ġcharis', 677), ('Ġyou', 606), ('Ġelodie', 590)] | tokenPerfect: 84490 / 180000 → 46.94% | babyLLM.py 10000
2025-04-11 01:38:26 | 120000 | LR0.0003 | loss:1.5439 | gradNorm:0.9999 | tokenCount:180000.0000 | logitMin:42.5606 | logitMax:88.4788 | scheduledSampling:0.0012 | embedMean:-0.0000 | embedStd:0.0001 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2189 | windowEntropy:0.7943 | topWindowWeight:0.5879 | effectiveWindowCount:2.2129 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0027 | memoryGateLong:0.0032 | memoryGateCurrent:-0.0004 | memoryGateMean:0.3333 | memoryGateStd:29.5958 | windowWeightsW2:2.405 (0.6),W4:1.982 (0.4),W8:-0.854 (0.0),W12:-2.861 (0.0),W16:-4.122 (0.0),W20:-5.493 (0.0),W32:-5.634 (0.0),W24:-6.122 (0.0),W28:-6.483 (0.0) | topTokens[(',', 1840), ('!', 1549), ('.', 1262), ('Ġthe', 1220), ('Ġcan', 923), ('Ġwould', 878), ('Ġcharis', 806), ('Ġi', 800), ('Ġbeen', 708), ('Ġelodie', 700)] | tokenPerfect: 93120 / 180000 → 51.73% | babyLLM.py 10000
2025-04-11 02:00:51 | 130000 | LR0.0003 | loss:4.3238 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:6.1338 | logitMax:44.5651 | scheduledSampling:0.0013 | embedMean:0.0000 | embedStd:0.0001 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.2194 | windowEntropy:0.7863 | topWindowWeight:0.5890 | effectiveWindowCount:2.1953 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0019 | memoryGateLong:0.0022 | memoryGateCurrent:-0.0002 | memoryGateMean:0.3333 | memoryGateStd:20.2254 | windowWeightsW2:2.403 (0.6),W4:1.979 (0.4),W8:-0.891 (0.0),W12:-3.060 (0.0),W16:-4.413 (0.0),W20:-5.830 (0.0),W32:-6.053 (0.0),W24:-6.500 (0.0),W28:-6.880 (0.0) | topTokens[(',', 2090), ('!', 1657), ('.', 1336), ('Ġthe', 1302), ('Ġcan', 925), ('Ġi', 896), ('Ġcharis', 878), ('Ġwould', 878), ('Ġelodie', 771), ('Ġbeen', 747)] | tokenPerfect: 40611 / 180000 → 22.56% | babyLLM.py 10000
2025-04-11 02:23:16 | 140000 | LR0.0003 | loss:5.1606 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:2.1701 | logitMax:28.1211 | scheduledSampling:0.0014 | embedMean:-0.0000 | embedStd:0.0001 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2192 | windowEntropy:0.7834 | topWindowWeight:0.5877 | effectiveWindowCount:2.1889 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0014 | memoryGateLong:0.0017 | memoryGateCurrent:-0.0002 | memoryGateMean:0.3333 | memoryGateStd:15.7114 | windowWeightsW2:2.394 (0.6),W4:1.976 (0.4),W8:-0.851 (0.0),W12:-3.357 (0.0),W16:-4.885 (0.0),W20:-6.383 (0.0),W32:-6.693 (0.0),W24:-7.087 (0.0),W28:-7.483 (0.0) | topTokens[(',', 2459), ('!', 1662), ('Ġthe', 1350), ('.', 1345), ('Ġi', 1038), ('Ġcan', 944), ('Ġcharis', 879), ('Ġwould', 879), ('Ġelodie', 771), ('Ġbeen', 748)] | tokenPerfect: 18758 / 180000 → 10.42% | babyLLM.py 10000
2025-04-11 02:46:03 | 150000 | LR0.0003 | loss:4.4607 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:11.0811 | logitMax:41.4549 | scheduledSampling:0.0015 | embedMean:-0.0000 | embedStd:0.0001 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2182 | windowEntropy:0.7822 | topWindowWeight:0.5759 | effectiveWindowCount:2.1863 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0014 | memoryGateLong:0.0017 | memoryGateCurrent:-0.0002 | memoryGateMean:0.3333 | memoryGateStd:15.8050 | windowWeightsW2:2.365 (0.6),W4:2.000 (0.4),W8:-0.868 (0.0),W12:-3.726 (0.0),W16:-5.420 (0.0),W20:-6.999 (0.0),W32:-7.430 (0.0),W24:-7.751 (0.0),W28:-8.176 (0.0) | topTokens[(',', 2696), ('!', 1690), ('.', 1469), ('Ġthe', 1393), ('Ġi', 1199), ('Ġcan', 957), ('Ġcharis', 890), ('Ġwould', 882), ('Ġelodie', 776), ('Ġand', 773)] | tokenPerfect: 27508 / 180000 → 15.28% | babyLLM.py 10000
2025-04-11 03:08:53 | 160000 | LR0.0003 | loss:4.2064 | gradNorm:0.9998 | tokenCount:180000.0000 | logitMin:-17.6385 | logitMax:13.9734 | scheduledSampling:0.0016 | embedMean:-0.0000 | embedStd:0.0001 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2148 | windowEntropy:0.7887 | topWindowWeight:0.5215 | effectiveWindowCount:2.2004 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0017 | memoryGateLong:0.0021 | memoryGateCurrent:-0.0003 | memoryGateMean:0.3333 | memoryGateStd:19.4094 | windowWeightsW2:2.249 (0.5),W4:2.115 (0.5),W8:-0.930 (0.0),W12:-4.158 (0.0),W16:-6.007 (0.0),W20:-7.676 (0.0),W32:-8.302 (0.0),W24:-8.495 (0.0),W28:-8.980 (0.0) | topTokens[(',', 3024), ('!', 1697), ('.', 1505), ('Ġthe', 1470), ('Ġi', 1345), ('Ġcan', 970), ('Ġcharis', 894), ('Ġwould', 886), ('Ġyou', 836), ('Ġand', 821)] | tokenPerfect: 39344 / 180000 → 21.86% | babyLLM.py 10000
2025-04-11 03:32:06 | 170000 | LR0.0003 | loss:2.2321 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-5.4446 | logitMax:35.7610 | scheduledSampling:0.0017 | embedMean:-0.0000 | embedStd:0.0001 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2163 | windowEntropy:0.7782 | topWindowWeight:0.5419 | effectiveWindowCount:2.1775 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0035 | memoryGateLong:0.0043 | memoryGateCurrent:-0.0007 | memoryGateMean:0.3333 | memoryGateStd:39.4862 | windowWeightsW2:2.285 (0.5),W4:2.071 (0.4),W8:-1.017 (0.0),W12:-4.383 (0.0),W16:-6.313 (0.0),W20:-8.009 (0.0),W32:-8.690 (0.0),W24:-8.830 (0.0),W28:-9.332 (0.0) | topTokens[(',', 3224), ('!', 1855), ('.', 1639), ('Ġthe', 1557), ('Ġi', 1401), ('Ġcharis', 1005), ('Ġcan', 973), ('Ġyou', 933), ('Ġwould', 886), ('Ġand', 878)] | tokenPerfect: 72755 / 180000 → 40.42% | babyLLM.py 10000
2025-04-11 03:54:37 | 180000 | LR0.0003 | loss:3.2556 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-49.3670 | logitMax:-5.5816 | scheduledSampling:0.0018 | embedMean:0.0000 | embedStd:0.0001 | meanActivation:-0.0000 | activationSparsity:0.0000 | windowStd:0.2166 | windowEntropy:0.7702 | topWindowWeight:0.5376 | effectiveWindowCount:2.1602 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0015 | memoryGateLong:0.0019 | memoryGateCurrent:-0.0003 | memoryGateMean:0.3333 | memoryGateStd:16.9811 | windowWeightsW2:2.272 (0.5),W4:2.081 (0.4),W8:-1.143 (0.0),W12:-4.710 (0.0),W16:-6.737 (0.0),W20:-8.455 (0.0),W32:-9.236 (0.0),W24:-9.291 (0.0),W28:-9.821 (0.0) | topTokens[(',', 3397), ('!', 1950), ('.', 1764), ('Ġthe', 1632), ('Ġi', 1470), ('Ġcharis', 1054), ('Ġyou', 997), ('Ġcan', 975), ('Ġand', 927), ('Ġelodie', 922)] | tokenPerfect: 62962 / 180000 → 34.98% | babyLLM.py 10000
2025-04-11 04:17:33 | 190000 | LR0.0003 | loss:2.4879 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-67.1399 | logitMax:-20.9659 | scheduledSampling:0.0019 | embedMean:-0.0000 | embedStd:0.0001 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2165 | windowEntropy:0.7676 | topWindowWeight:0.5297 | effectiveWindowCount:2.1546 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0014 | memoryGateLong:0.0017 | memoryGateCurrent:-0.0002 | memoryGateMean:0.3333 | memoryGateStd:15.4031 | windowWeightsW2:2.250 (0.5),W4:2.094 (0.5),W8:-1.205 (0.0),W12:-4.942 (0.0),W16:-7.017 (0.0),W20:-8.804 (0.0),W24:-9.629 (0.0),W32:-9.635 (0.0),W28:-10.163 (0.0) | topTokens[(',', 3522), ('!', 2077), ('.', 1850), ('Ġthe', 1745), ('Ġi', 1507), ('Ġcharis', 1124), ('Ġbeen', 1088), ('Ġyou', 1033), ('Ġelodie', 1019), ('Ġcan', 976)] | tokenPerfect: 84457 / 180000 → 46.92% | babyLLM.py 10000

--- 2025-04-11 04:33:43 --- babyLLM 'right, last time i got to step 196525... want to restart from there?'  - charis: 'no, restart, got'cha some new data!' - babyLLM 'alright, step 0, let's go back to the beginning :) what am i learning today?' - charis: 'well, you have decided to nerf nearly all your windows so... i guess... continue???'
2025-04-11 04:55:12 | 10000 | LR0.0003 | loss:3.5493 | gradNorm:1.0000 | logitMin:-125.1740 | logitMax:-86.5113 | scheduledSampling:0.0001 | tokenCount:180000.0000 | memoryGateShort:-0.0017 | memoryGateLong:0.0020 | memoryGateCurrent:-0.0002 | shortDecay:0.0001 | longDecay:0.0001 | embedMean:-0.0000 | embedStd:0.0001 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2178 | windowEntropy:0.7567 | topWindowWeight:0.5433 | effectiveWindowCount:2.1312 | memoryGateMean:0.3333 | memoryGateStd:18.2303 | windowWeightsW2:2.268 (0.5),W4:2.062 (0.4),W8:-1.340 (0.0),W12:-5.529 (0.0),W16:-7.836 (0.0),W20:-9.647 (0.0),W24:-10.460 (0.0),W32:-10.574 (0.0),W28:-10.959 (0.0) | topTokens[('.', 157), (',', 157), ('Ġwill', 152), ('Ġhave', 150), ('Ġthe', 104), ('!', 92), ('Ġand', 67), ('Ġa', 67), ('Ġfelt', 66), ('Ġit', 59)] | tokenPerfect: 55211 / 180000 → 30.67% | babyLLM.py 10000
2025-04-11 05:16:46 | 20000 | LR0.0003 | loss:3.3047 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-167.8462 | logitMax:-136.5045 | scheduledSampling:0.0002 | embedMean:-0.0000 | embedStd:0.0001 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2244 | windowEntropy:0.7198 | topWindowWeight:0.6045 | effectiveWindowCount:2.0541 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0017 | memoryGateLong:0.0021 | memoryGateCurrent:-0.0003 | memoryGateMean:0.3333 | memoryGateStd:18.9962 | windowWeightsW2:2.391 (0.6),W4:1.940 (0.4),W8:-1.696 (0.0),W12:-5.951 (0.0),W16:-8.283 (0.0),W20:-10.086 (0.0),W24:-10.843 (0.0),W32:-10.963 (0.0),W28:-11.281 (0.0) | topTokens[('.', 392), ('?', 228), (',', 220), ('Ġwill', 195), ('Ġto', 182), ('Ġyou', 160), ('Ġhave', 155), ('Ġa', 151), ('Ġis', 128), ('Ġi', 125)] | tokenPerfect: 58709 / 180000 → 32.62% | babyLLM.py 10000
2025-04-11 05:38:27 | 30000 | LR0.0003 | loss:2.5556 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-162.6177 | logitMax:-120.2431 | scheduledSampling:0.0003 | embedMean:-0.0000 | embedStd:0.0001 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2187 | windowEntropy:0.7290 | topWindowWeight:0.5128 | effectiveWindowCount:2.0730 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0017 | memoryGateLong:0.0020 | memoryGateCurrent:-0.0003 | memoryGateMean:0.3333 | memoryGateStd:18.6608 | windowWeightsW2:2.200 (0.5),W4:2.135 (0.5),W8:-2.144 (0.0),W12:-6.479 (0.0),W16:-8.813 (0.0),W20:-10.538 (0.0),W24:-11.255 (0.0),W32:-11.404 (0.0),W28:-11.657 (0.0) | topTokens[('.', 552), ('?', 403), ('Ġto', 386), (',', 284), ('Ġwill', 250), ('Ġyou', 241), ('Ġi', 221), ('Ġa', 206), ('Ġwhat', 201), ('Ġmusic', 189)] | tokenPerfect: 82625 / 180000 → 45.90% | babyLLM.py 10000
2025-04-11 06:00:31 | 40000 | LR0.0003 | loss:3.8939 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-192.8610 | logitMax:-154.6174 | scheduledSampling:0.0004 | embedMean:-0.0000 | embedStd:0.0001 | meanActivation:0.0001 | activationSparsity:0.0000 | windowStd:0.2224 | windowEntropy:0.7146 | topWindowWeight:0.5783 | effectiveWindowCount:2.0434 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0016 | memoryGateLong:0.0019 | memoryGateCurrent:-0.0002 | memoryGateMean:0.3333 | memoryGateStd:17.7029 | windowWeightsW2:2.327 (0.6),W4:1.995 (0.4),W8:-2.183 (0.0),W12:-6.661 (0.0),W16:-9.046 (0.0),W20:-10.761 (0.0),W24:-11.432 (0.0),W32:-11.595 (0.0),W28:-11.812 (0.0) | topTokens[('.', 827), ('?', 537), ('Ġto', 475), (',', 365), ('Ġi', 362), ('Ġyou', 345), ('Ġa', 286), ('Ġwill', 282), ('Ġwhat', 260), ('Ġis', 255)] | tokenPerfect: 45470 / 180000 → 25.26% | babyLLM.py 10000
2025-04-11 06:22:11 | 50000 | LR0.0003 | loss:3.7064 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-235.0860 | logitMax:-196.8073 | scheduledSampling:0.0005 | embedMean:-0.0000 | embedStd:0.0001 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2276 | windowEntropy:0.6941 | topWindowWeight:0.6226 | effectiveWindowCount:2.0020 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0017 | memoryGateLong:0.0021 | memoryGateCurrent:-0.0002 | memoryGateMean:0.3333 | memoryGateStd:19.1024 | windowWeightsW2:2.413 (0.6),W4:1.896 (0.4),W8:-2.231 (0.0),W12:-6.964 (0.0),W16:-9.440 (0.0),W20:-11.062 (0.0),W24:-11.666 (0.0),W32:-11.835 (0.0),W28:-12.010 (0.0) | topTokens[('.', 907), ('?', 559), ('Ġto', 502), (',', 429), ('Ġi', 408), ('Ġyou', 381), ('Ġa', 348), ('!', 342), ('Ġwill', 319), ('Ġis', 282)] | tokenPerfect: 56939 / 180000 → 31.63% | babyLLM.py 10000
2025-04-11 06:43:46 | 60000 | LR0.0003 | loss:2.9916 | gradNorm:1.0000 | tokenCount:180000.0000 | logitMin:-210.0821 | logitMax:-162.8431 | scheduledSampling:0.0006 | embedMean:-0.0000 | embedStd:0.0001 | meanActivation:0.0000 | activationSparsity:0.0000 | windowStd:0.2311 | windowEntropy:0.6810 | topWindowWeight:0.6459 | effectiveWindowCount:1.9759 | shortDecay:0.0001 | longDecay:0.0001 | memoryGateShort:-0.0018 | memoryGateLong:0.0021 | memoryGateCurrent:-0.0002 | memoryGateMean:0.3333 | memoryGateStd:19.5995 | windowWeightsW2:2.457 (0.6),W4:1.838 (0.3),W8:-2.213 (0.0),W12:-7.224 (0.0),W16:-9.792 (0.0),W20:-11.317 (0.0),W24:-11.867 (0.0),W32:-12.038 (0.0),W28:-12.179 (0.0) | topTokens[('.', 939), ('!', 677), ('?', 561), (',', 549), ('Ġto', 544), ('Ġi', 460), ('Ġit', 451), ('Ġyou', 432), ('Ġa', 428), ('Ġwill', 363)] | tokenPerfect: 62142 / 180000 → 34.52% | babyLLM.py 10000

--- 2025-04-11 16:11:37 --- babyLLM 'right, last time i got to step 60230... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 16:14:18 --- babyLLM 'right, last time i got to step 7... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 17:21:05 --- babyLLM 'right, last time i got to step 24... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 17:22:05 --- babyLLM 'right, last time i got to step 80... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 20:54:10 --- babyLLM 'right, last time i got to step 209... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 21:19:01 --- babyLLM 'right, last time i got to step 153... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 21:20:51 --- babyLLM 'right, last time i got to step 153... want to restart from there?'  - charis: '-0' - babyLLM 'umm... i don't think i heard you properly, i'll just start from step 0 :) but, what am i learning today?' - charis: ''

--- 2025-04-11 21:57:17 --- babyLLM 'right, last time i got to step 153... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: 'i am happy i fuckin did it i broke u i am it'

--- 2025-04-11 22:04:25 --- babyLLM 'right, last time i got to step 153... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 22:43:55 --- babyLLM 'right, last time i got to step 153... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 22:57:25 --- babyLLM 'right, last time i got to step 153... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 22:59:10 --- babyLLM 'right, last time i got to step 153... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 23:00:57 --- babyLLM 'right, last time i got to step 153... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 23:07:11 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 23:18:12 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-11 23:25:58 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-11 23:31:52 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-11 23:37:01 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-11 23:45:53 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-12 00:09:49 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 00:30:51 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-12 00:51:43 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 03:31:34 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 03:38:49 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 07:52:39 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 07:54:51 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:06:38 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:12:48 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:14:59 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:17:32 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:20:17 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:27:30 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:36:20 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:38:00 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:42:32 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 09:45:35 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 18:04:41 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 21:27:20 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 21:34:00 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 21:49:22 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 21:53:36 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-12 22:04:11 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:11:11 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:14:31 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:17:30 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:20:57 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:24:50 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:28:07 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:29:53 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:37:10 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:38:09 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:52:46 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:54:39 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 00:56:09 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 01:00:12 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 02:12:10 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 02:16:40 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 03:56:26 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 04:02:56 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 17:57:51 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 18:10:11 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 18:18:19 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 18:25:18 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 18:37:48 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 19:05:54 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 19:09:44 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 19:17:41 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 19:18:54 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 19:40:46 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 20:08:41 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 20:19:22 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 20:23:02 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 20:24:39 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 20:46:12 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 21:02:51 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 21:13:30 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 22:22:24 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 22:33:39 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 23:01:45 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 23:09:26 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 23:32:12 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 23:33:58 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 23:40:23 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 23:44:21 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-13 23:49:32 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 00:14:49 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 00:31:54 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 00:44:49 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 00:55:21 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 00:58:24 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 01:00:23 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 01:13:12 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 01:19:49 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 01:53:36 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 01:57:25 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 02:03:03 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 02:23:50 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 02:34:44 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 02:41:37 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:00:39 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:05:54 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:08:14 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:18:34 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:21:14 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:25:50 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:29:37 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:39:54 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:42:28 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:43:35 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:49:18 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:53:21 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:55:08 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 03:57:32 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 04:08:55 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 04:13:38 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 04:14:41 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 04:24:10 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 04:25:26 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 04:41:47 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 04:42:49 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 04:43:12 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 04:54:54 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 05:17:58 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 05:18:58 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 05:22:37 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 05:25:58 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 05:26:59 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 05:29:13 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 05:31:25 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 05:33:05 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 05:40:06 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 15:55:06 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 16:08:06 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 16:25:42 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 16:29:51 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 16:48:16 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 16:59:26 --- babyLLM 'right, last time i got to step 1... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 1! what am i learning today?' - charis: ''

--- 2025-04-14 17:14:18 --- babyLLM 'right, last time i got to step 2... want to restart from there?'  - charis: '220' - babyLLM 'damn that's specific! heading to step 220... what am i learning today?' - charis: ''

--- 2025-04-14 17:20:22 --- babyLLM 'right, last time i got to step 221... want to restart from there?'  - charis: 'y' - babyLLM 'ok! let's go to step 221! what am i learning today?' - charis: ''

--- 2025-04-14 17:38:23 --- babyLLM 'right, last time i got to step 222... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 222! what am i learning today?' - charis: ''

--- 2025-04-14 17:44:20 --- babyLLM 'right, last time i got to step 223... want to restart from there?'  - charis: '300' - babyLLM 'damn that's specific! heading to step 300... what am i learning today?' - charis: ''

--- 2025-04-14 17:48:11 --- babyLLM 'right, last time i got to step 301... want to restart from there?'  - charis: '320' - babyLLM 'damn that's specific! heading to step 320... what am i learning today?' - charis: ''

--- 2025-04-14 17:54:11 --- babyLLM 'right, last time i got to step 321... want to restart from there?'  - charis: '400' - babyLLM 'damn that's specific! heading to step 400... what am i learning today?' - charis: ''

--- 2025-04-14 18:01:25 --- babyLLM 'right, last time i got to step 401... want to restart from there?'  - charis: '500' - babyLLM 'damn that's specific! heading to step 500... what am i learning today?' - charis: ''

--- 2025-04-14 18:06:34 --- babyLLM 'right, last time i got to step 501... want to restart from there?'  - charis: '550' - babyLLM 'damn that's specific! heading to step 550... what am i learning today?' - charis: ''

--- 2025-04-14 18:09:13 --- babyLLM 'right, last time i got to step 551... want to restart from there?'  - charis: '570' - babyLLM 'damn that's specific! heading to step 570... what am i learning today?' - charis: ''

--- 2025-04-14 18:10:49 --- babyLLM 'right, last time i got to step 571... want to restart from there?'  - charis: '580' - babyLLM 'damn that's specific! heading to step 580... what am i learning today?' - charis: ''

--- 2025-04-14 18:12:30 --- babyLLM 'right, last time i got to step 581... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 581! what am i learning today?' - charis: ''

--- 2025-04-14 18:37:09 --- babyLLM 'right, last time i got to step 582... want to restart from there?'  - charis: '900' - babyLLM 'damn that's specific! heading to step 900... what am i learning today?' - charis: ''

--- 2025-04-14 18:56:08 --- babyLLM 'right, last time i got to step 901... want to restart from there?'  - charis: '1200' - babyLLM 'damn that's specific! heading to step 1200... what am i learning today?' - charis: ''

--- 2025-04-14 19:15:22 --- babyLLM 'right, last time i got to step 0... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 0! what am i learning today?' - charis: ''

--- 2025-04-14 19:26:21 --- babyLLM 'right, last time i got to step 1... want to restart from there?'  - charis: '2000' - babyLLM 'damn that's specific! heading to step 2000... what am i learning today?' - charis: ''

--- 2025-04-14 19:27:15 --- babyLLM 'right, last time i got to step 2001... want to restart from there?'  - charis: '800' - babyLLM 'damn that's specific! heading to step 800... what am i learning today?' - charis: ''

--- 2025-04-14 19:37:20 --- babyLLM 'right, last time i got to step 801... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 801! what am i learning today?' - charis: ''

--- 2025-04-14 19:41:51 --- babyLLM 'right, last time i got to step 802... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 802! what am i learning today?' - charis: ''

--- 2025-04-14 20:32:34 --- babyLLM 'right, last time i got to step 803... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-14 20:41:58 --- babyLLM 'right, last time i got to step 803... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-14 20:44:16 --- babyLLM 'right, last time i got to step 1... want to restart from there?'  - charis: '0' - babyLLM 'damn that's specific! heading to step 0... what am i learning today?' - charis: ''

--- 2025-04-14 20:46:25 --- babyLLM 'right, last time i got to step 1... want to restart from there?'  - charis: '29' - babyLLM 'damn that's specific! heading to step 29... what am i learning today?' - charis: ''

--- 2025-04-14 20:48:36 --- babyLLM 'right, last time i got to step 30... want to restart from there?'  - charis: '50' - babyLLM 'damn that's specific! heading to step 50... what am i learning today?' - charis: ''

--- 2025-04-14 20:49:49 --- babyLLM 'right, last time i got to step 51... want to restart from there?'  - charis: '60' - babyLLM 'damn that's specific! heading to step 60... what am i learning today?' - charis: ''

--- 2025-04-14 20:54:29 --- babyLLM 'right, last time i got to step 61... want to restart from there?'  - charis: '80' - babyLLM 'damn that's specific! heading to step 80... what am i learning today?' - charis: ''

--- 2025-04-14 20:57:15 --- babyLLM 'right, last time i got to step 81... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 81! what am i learning today?' - charis: ''

--- 2025-04-14 20:59:06 --- babyLLM 'right, last time i got to step 81... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 81! what am i learning today?' - charis: ''

--- 2025-04-14 21:00:31 --- babyLLM 'right, last time i got to step 81... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 81! what am i learning today?' - charis: ''

--- 2025-04-14 21:02:25 --- babyLLM 'right, last time i got to step 81... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 81! what am i learning today?' - charis: ''

--- 2025-04-14 21:04:44 --- babyLLM 'right, last time i got to step 81... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 81! what am i learning today?' - charis: ''

--- 2025-04-14 21:15:52 --- babyLLM 'right, last time i got to step 81... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 81! what am i learning today?' - charis: ''

--- 2025-04-14 21:17:30 --- babyLLM 'right, last time i got to step 81... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 81! what am i learning today?' - charis: ''

--- 2025-04-14 21:31:28 --- babyLLM 'right, last time i got to step 82... want to restart from there?'  - charis: '250' - babyLLM 'damn that's specific! heading to step 250... what am i learning today?' - charis: ''

--- 2025-04-14 21:37:12 --- babyLLM 'right, last time i got to step 251... want to restart from there?'  - charis: '300' - babyLLM 'damn that's specific! heading to step 300... what am i learning today?' - charis: ''

--- 2025-04-14 21:43:18 --- babyLLM 'right, last time i got to step 301... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 301! what am i learning today?' - charis: ''

--- 2025-04-14 21:53:35 --- babyLLM 'right, last time i got to step 302... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 302! what am i learning today?' - charis: ''

--- 2025-04-14 21:59:37 --- babyLLM 'right, last time i got to step 303... want to restart from there?'  - charis: '400' - babyLLM 'damn that's specific! heading to step 400... what am i learning today?' - charis: ''

--- 2025-04-14 22:00:53 --- babyLLM 'right, last time i got to step 401... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 401! what am i learning today?' - charis: ''

--- 2025-04-14 22:38:23 --- babyLLM 'right, last time i got to step 402... want to restart from there?'  - charis: '800' - babyLLM 'damn that's specific! heading to step 800... what am i learning today?' - charis: ''

--- 2025-04-14 22:44:43 --- babyLLM 'right, last time i got to step 801... want to restart from there?'  - charis: '900' - babyLLM 'damn that's specific! heading to step 900... what am i learning today?' - charis: ''

--- 2025-04-14 22:51:41 --- babyLLM 'right, last time i got to step 901... want to restart from there?'  - charis: '990' - babyLLM 'damn that's specific! heading to step 990... what am i learning today?' - charis: ''

--- 2025-04-14 22:57:00 --- babyLLM 'right, last time i got to step 991... want to restart from there?'  - charis: '1020' - babyLLM 'damn that's specific! heading to step 1020... what am i learning today?' - charis: ''

--- 2025-04-14 23:30:28 --- babyLLM 'right, last time i got to step 1021... want to restart from there?'  - charis: '1500' - babyLLM 'damn that's specific! heading to step 1500... what am i learning today?' - charis: ''

--- 2025-04-15 00:19:14 --- babyLLM 'right, last time i got to step 1501... want to restart from there?'  - charis: '2000' - babyLLM 'damn that's specific! heading to step 2000... what am i learning today?' - charis: ''

--- 2025-04-15 01:11:35 --- babyLLM 'right, last time i got to step 2001... want to restart from there?'  - charis: '2700' - babyLLM 'damn that's specific! heading to step 2700... what am i learning today?' - charis: ''

--- 2025-04-15 01:14:02 --- babyLLM 'right, last time i got to step 2001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 2001! what am i learning today?' - charis: ''

--- 2025-04-15 01:23:48 --- babyLLM 'right, last time i got to step 2001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 2001! what am i learning today?' - charis: ''

--- 2025-04-15 01:26:45 --- babyLLM 'right, last time i got to step 2001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 2001! what am i learning today?' - charis: ''

--- 2025-04-15 01:38:42 --- babyLLM 'right, last time i got to step 2001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 2001! what am i learning today?' - charis: ''

--- 2025-04-15 01:39:44 --- babyLLM 'right, last time i got to step 2002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 2002! what am i learning today?' - charis: ''

--- 2025-04-15 02:03:48 --- babyLLM 'right, last time i got to step 2003... want to restart from there?'  - charis: '2300' - babyLLM 'damn that's specific! heading to step 2300... what am i learning today?' - charis: ''

--- 2025-04-16 02:14:56 --- babyLLM 'right, last time i got to step 621... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 621! what am i learning today?' - charis: ''

--- 2025-04-16 02:33:22 --- babyLLM 'right, last time i got to step 621... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 621! what am i learning today?' - charis: ''

--- 2025-04-16 10:38:17 --- babyLLM 'right, last time i got to step 622... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 622! what am i learning today?' - charis: ''

--- 2025-04-16 10:40:27 --- babyLLM 'right, last time i got to step 623... want to restart from there?'  - charis: '9000' - babyLLM 'damn that's specific! heading to step 9000... what am i learning today?' - charis: ''

--- 2025-04-16 10:47:18 --- babyLLM 'right, last time i got to step 9001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 9001! what am i learning today?' - charis: ''

--- 2025-04-16 12:27:24 --- babyLLM 'right, last time i got to step 9002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 9002! what am i learning today?' - charis: ''

--- 2025-04-16 12:29:42 --- babyLLM 'right, last time i got to step 9003... want to restart from there?'  - charis: '12000' - babyLLM 'damn that's specific! heading to step 12000... what am i learning today?' - charis: ''

--- 2025-04-16 12:44:46 --- babyLLM 'right, last time i got to step 12001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12001! what am i learning today?' - charis: ''

--- 2025-04-16 12:46:07 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:23:37 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:24:44 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:26:07 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:28:04 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:30:11 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:31:39 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:34:46 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:38:19 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:41:52 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 14:43:34 --- babyLLM 'right, last time i got to step 12002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12002! what am i learning today?' - charis: ''

--- 2025-04-16 15:10:31 --- babyLLM 'right, last time i got to step 12003... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12003! what am i learning today?' - charis: ''

--- 2025-04-16 15:15:17 --- babyLLM 'right, last time i got to step 12004... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12004! what am i learning today?' - charis: ''

--- 2025-04-16 15:20:14 --- babyLLM 'right, last time i got to step 12005... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12005! what am i learning today?' - charis: ''

--- 2025-04-16 16:04:52 --- babyLLM 'right, last time i got to step 12006... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 12006! what am i learning today?' - charis: ''

--- 2025-04-16 16:05:30 --- babyLLM 'right, last time i got to step 12007... want to restart from there?'  - charis: '17000' - babyLLM 'damn that's specific! heading to step 17000... what am i learning today?' - charis: ''

--- 2025-04-16 16:21:32 --- babyLLM 'right, last time i got to step 17001... want to restart from there?'  - charis: '19000' - babyLLM 'damn that's specific! heading to step 19000... what am i learning today?' - charis: ''

--- 2025-04-16 17:05:34 --- babyLLM 'right, last time i got to step 19001... want to restart from there?'  - charis: '24000' - babyLLM 'damn that's specific! heading to step 24000... what am i learning today?' - charis: ''

--- 2025-04-16 17:07:08 --- babyLLM 'right, last time i got to step 19001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 19001! what am i learning today?' - charis: ''

--- 2025-04-16 17:08:31 --- babyLLM 'right, last time i got to step 19001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 19001! what am i learning today?' - charis: ''

--- 2025-04-16 17:11:39 --- babyLLM 'right, last time i got to step 19001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 19001! what am i learning today?' - charis: ''

--- 2025-04-16 17:16:27 --- babyLLM 'right, last time i got to step 19002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 19002! what am i learning today?' - charis: ''

--- 2025-04-16 17:43:46 --- babyLLM 'right, last time i got to step 19003... want to restart from there?'  - charis: '22000' - babyLLM 'damn that's specific! heading to step 22000... what am i learning today?' - charis: ''

--- 2025-04-16 18:17:09 --- babyLLM 'right, last time i got to step 22001... want to restart from there?'  - charis: '25000' - babyLLM 'damn that's specific! heading to step 25000... what am i learning today?' - charis: ''

--- 2025-04-16 18:23:36 --- babyLLM 'right, last time i got to step 25001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 25001! what am i learning today?' - charis: ''

--- 2025-04-16 18:40:32 --- babyLLM 'right, last time i got to step 25002... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 25002! what am i learning today?' - charis: ''

--- 2025-04-16 18:48:53 --- babyLLM 'right, last time i got to step 25003... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 25003! what am i learning today?' - charis: ''

--- 2025-04-16 18:56:43 --- babyLLM 'right, last time i got to step 25004... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 25004! what am i learning today?' - charis: ''

--- 2025-04-16 19:12:17 --- babyLLM 'right, last time i got to step 25005... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 25005! what am i learning today?' - charis: ''

--- 2025-04-16 19:14:20 --- babyLLM 'right, last time i got to step 25006... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 25006! what am i learning today?' - charis: ''

--- 2025-04-16 19:40:21 --- babyLLM 'right, last time i got to step 25007... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 25007! what am i learning today?' - charis: ''

--- 2025-04-16 19:47:20 --- babyLLM 'right, last time i got to step 25008... want to restart from there?'  - charis: '27500' - babyLLM 'damn that's specific! heading to step 27500... what am i learning today?' - charis: ''

--- 2025-04-16 20:34:40 --- babyLLM 'right, last time i got to step 27501... want to restart from there?'  - charis: '30000' - babyLLM 'damn that's specific! heading to step 30000... what am i learning today?' - charis: ''

--- 2025-04-16 20:38:46 --- babyLLM 'right, last time i got to step 30001... want to restart from there?'  - charis: '30250' - babyLLM 'damn that's specific! heading to step 30250... what am i learning today?' - charis: ''

--- 2025-04-16 20:49:59 --- babyLLM 'right, last time i got to step 30251... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 30251! what am i learning today?' - charis: ''

--- 2025-04-16 20:51:33 --- babyLLM 'right, last time i got to step 30252... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 30252! what am i learning today?' - charis: ''

--- 2025-04-16 20:53:05 --- babyLLM 'right, last time i got to step 30253... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 30253! what am i learning today?' - charis: ''

--- 2025-04-16 21:02:20 --- babyLLM 'right, last time i got to step 30254... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 30254! what am i learning today?' - charis: ''

--- 2025-04-16 21:04:51 --- babyLLM 'right, last time i got to step 30255... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 30255! what am i learning today?' - charis: ''

--- 2025-04-16 21:06:24 --- babyLLM 'right, last time i got to step 30256... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 30256! what am i learning today?' - charis: ''

--- 2025-04-16 21:11:42 --- babyLLM 'right, last time i got to step 30257... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 30257! what am i learning today?' - charis: ''

--- 2025-04-16 21:25:29 --- babyLLM 'right, last time i got to step 30258... want to restart from there?'  - charis: '31000' - babyLLM 'damn that's specific! heading to step 31000... what am i learning today?' - charis: ''

--- 2025-04-16 21:33:55 --- babyLLM 'right, last time i got to step 31001... want to restart from there?'  - charis: '' - babyLLM 'ok! let's go to step 31001! what am i learning today?' - charis: ''
--- 2025-04-17 01:20:39 --- 
[babyllm] right, last time i got to step 31002... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 31002! what am i learning today?
[charis]--- 2025-04-17 01:22:35 --- 
[babyllm] right, last time i got to step 31002... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 31002! what am i learning today?
[charis]--- 2025-04-17 01:23:27 --- 
[babyllm] right, last time i got to step 31002... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 31002! what am i learning today?
[charis]--- 2025-04-17 01:25:13 --- 
[babyllm] right, last time i got to step 31002... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 31002! what am i learning today?
[charis]--- 2025-04-17 01:31:18 --- 
[babyllm] right, last time i got to step 0... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 0! what am i learning today?
[charis]--- 2025-04-17 01:33:31 --- 
[babyllm] right, last time i got to step 0... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 0! what am i learning today?
[charis]--- 2025-04-17 01:40:22 --- 
[babyllm] right, last time i got to step 0... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 0! what am i learning today?
[charis]--- 2025-04-17 01:44:13 --- 
[babyllm] right, last time i got to step 0... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 0! what am i learning today?
[charis]--- 2025-04-17 01:53:50 --- 
[babyllm] right, last time i got to step 0... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 0! what am i learning today?
[charis]--- 2025-04-17 01:57:05 --- 
[babyllm] right, last time i got to step 0... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 0! what am i learning today?
[charis]--- 2025-04-17 02:09:34 --- 
[babyllm] right, last time i got to step 0... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 0! what am i learning today?
[charis]--- 2025-04-17 02:13:15 --- 
[babyllm] right, last time i got to step 0... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 0! what am i learning today?
[charis]--- 2025-04-17 02:14:08 --- 
[babyllm] right, last time i got to step 0... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 0! what am i learning today?
[charis]--- 2025-04-17 02:21:14 --- 
[babyllm] right, last time i got to step 0... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 0! what am i learning today?
[charis]--- 2025-04-17 02:23:51 --- 
[babyllm] right, last time i got to step 0... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 0! what am i learning today?
[charis]--- 2025-04-17 02:26:01 --- 
[babyllm] right, last time i got to step 1... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 1! what am i learning today?
[charis]--- 2025-04-17 02:41:42 --- 
[babyllm] right, last time i got to step 1... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 1! what am i learning today?
[charis]--- 2025-04-17 03:14:40 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 2364
[babyllm] damn that's specific! heading to step 2364... what am i learning today?
[charis]--- 2025-04-17 03:16:15 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 03:40:36 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 03:45:52 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 03:51:33 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 03:59:24 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 04:06:22 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 04:07:46 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 04:15:44 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 04:33:26 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 04:38:32 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 04:39:08 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 04:40:26 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 04:42:21 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 04:44:30 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 04:47:15 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 04:56:33 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 04:57:22 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 05:01:37 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 05:04:05 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 05:09:54 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 05:12:56 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 05:18:32 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 05:21:10 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 05:25:29 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 05:26:07 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 05:27:43 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 05:36:44 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 05:43:39 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 05:48:30 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 05:58:05 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 06:04:53 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 06:07:27 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 06:09:30 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 06:16:35 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 06:23:34 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 06:35:52 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 06:38:53 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 06:44:44 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 06:53:00 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:04:15 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:09:54 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:10:34 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:11:35 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:12:07 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:21:02 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:26:44 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:29:33 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:30:10 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:30:57 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:35:04 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:39:36 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:41:15 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:41:59 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:42:33 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:43:40 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:44:51 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:47:54 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:48:28 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:49:10 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:50:03 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:51:01 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:51:48 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:52:54 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:54:10 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:57:46 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 07:58:49 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:00:13 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:01:15 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:01:45 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:03:21 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:03:46 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:09:15 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:09:52 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:10:12 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:12:02 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:14:58 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:16:03 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:16:45 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:17:12 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:18:09 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:19:00 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:20:46 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:35:23 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:36:08 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 08:39:01 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:00:45 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:02:44 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:04:05 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:05:07 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:05:56 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:08:21 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:11:55 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:14:25 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:15:18 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:23:18 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:23:59 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:39:20 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:39:54 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:48:09 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:49:10 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:49:35 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:52:12 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:54:59 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:57:21 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 09:58:10 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 10:02:28 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 10:27:24 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:09:09 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:09:50 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:12:56 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:14:29 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:15:32 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:20:50 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:21:34 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:22:21 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:23:27 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:25:19 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:27:19 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:28:00 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:28:58 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:29:43 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:31:04 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:33:37 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:34:11 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:36:49 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:38:05 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:38:56 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]god knows man--- 2025-04-17 21:44:09 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:44:46 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:45:14 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:46:01 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 21:50:45 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 22:05:12 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 22:06:17 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 22:08:54 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 22:09:54 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 22:10:57 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 22:11:45 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 22:13:28 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 22:32:39 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 23:04:23 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 23:23:36 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2! what am i learning today?
[charis]--- 2025-04-17 23:42:22 --- 
[babyllm] right, last time i got to step 2... want to restart from there?
[charis] 3000
[babyllm] damn that's specific! heading to step 3000... what am i learning today?
[charis]--- 2025-04-17 23:43:22 --- 
[babyllm] right, last time i got to step 3000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 3000! what am i learning today?
[charis]--- 2025-04-17 23:44:11 --- 
[babyllm] right, last time i got to step 3000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 3000! what am i learning today?
[charis]--- 2025-04-18 00:07:13 --- 
[babyllm] right, last time i got to step 3000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 3000! what am i learning today?
[charis]--- 2025-04-18 02:47:39 --- 
[babyllm] right, last time i got to step 3000... want to restart from there?
[charis] 27000
[babyllm] damn that's specific! heading to step 27000... what am i learning today?
[charis]--- 2025-04-18 02:48:26 --- 
[babyllm] right, last time i got to step 27000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 27000! what am i learning today?
[charis]--- 2025-04-18 03:04:39 --- 
[babyllm] right, last time i got to step 28996... want to restart from there?
[charis] 0
[babyllm] damn that's specific! heading to step 0... what am i learning today?
[charis]--- 2025-04-18 03:58:34 --- 
[babyllm] right, last time i got to step 0... want to restart from there?
[charis] 8000
[babyllm] damn that's specific! heading to step 8000... what am i learning today?
[charis]--- 2025-04-18 04:02:53 --- 
[babyllm] right, last time i got to step 8000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 8000! what am i learning today?
[charis]--- 2025-04-18 04:38:37 --- 
[babyllm] right, last time i got to step 8000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 8000! what am i learning today?
[charis]--- 2025-04-18 04:39:35 --- 
[babyllm] right, last time i got to step 8000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 8000! what am i learning today?
[charis]--- 2025-04-18 04:46:05 --- 
[babyllm] right, last time i got to step 8000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 8000! what am i learning today?
[charis]--- 2025-04-18 04:48:09 --- 
[babyllm] right, last time i got to step 8000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 8000! what am i learning today?
[charis]--- 2025-04-18 04:53:36 --- 
[babyllm] right, last time i got to step 8000... want to restart from there?
[charis] 9000
[babyllm] damn that's specific! heading to step 9000... what am i learning today?
[charis]--- 2025-04-18 04:55:31 --- 
[babyllm] right, last time i got to step 9000... want to restart from there?
[charis] 9500
[babyllm] damn that's specific! heading to step 9500... what am i learning today?
[charis]--- 2025-04-18 04:56:04 --- 
[babyllm] right, last time i got to step 9500... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 9500! what am i learning today?
[charis]--- 2025-04-18 04:57:32 --- 
[babyllm] right, last time i got to step 9500... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 9500! what am i learning today?
[charis]--- 2025-04-18 04:58:18 --- 
[babyllm] right, last time i got to step 9500... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 9500! what am i learning today?
[charis]--- 2025-04-18 05:13:19 --- 
[babyllm] right, last time i got to step 9500... want to restart from there?
[charis] 11000
[babyllm] damn that's specific! heading to step 11000... what am i learning today?
[charis]--- 2025-04-18 05:14:33 --- 
[babyllm] right, last time i got to step 9500... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 9500! what am i learning today?
[charis]--- 2025-04-18 06:27:56 --- 
[babyllm] right, last time i got to step 9500... want to restart from there?
[charis] 19000
[babyllm] damn that's specific! heading to step 19000... what am i learning today?
[charis]--- 2025-04-18 09:01:20 --- 
[babyllm] right, last time i got to step 19000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 19000! what am i learning today?
[charis]--- 2025-04-18 09:21:19 --- 
[babyllm] right, last time i got to step 19000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 19000! what am i learning today?
[charis]--- 2025-04-18 09:30:05 --- 
[babyllm] right, last time i got to step 19000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 19000! what am i learning today?
[charis]--- 2025-04-18 09:43:19 --- 
[babyllm] right, last time i got to step 19000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 19000! what am i learning today?
[charis]--- 2025-04-18 09:43:53 --- 
[babyllm] right, last time i got to step 19000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 19000! what am i learning today?
[charis]--- 2025-04-18 11:32:42 --- 
[babyllm] right, last time i got to step 19000... want to restart from there?
[charis] 32000
[babyllm] damn that's specific! heading to step 32000... what am i learning today?
[charis]--- 2025-04-18 11:33:34 --- 
[babyllm] right, last time i got to step 19000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 19000! what am i learning today?
[charis]--- 2025-04-18 11:46:04 --- 
[babyllm] right, last time i got to step 19000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 19000! what am i learning today?
[charis]--- 2025-04-18 12:02:46 --- 
[babyllm] right, last time i got to step 19000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 19000! what am i learning today?
[charis]--- 2025-04-18 12:18:28 --- 
[babyllm] right, last time i got to step 19000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 19000! what am i learning today?
[charis]--- 2025-04-18 12:20:49 --- 
[babyllm] right, last time i got to step 19000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 19000! what am i learning today?
[charis]--- 2025-04-18 12:21:21 --- 
[babyllm] right, last time i got to step 19000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 19000! what am i learning today?
[charis]--- 2025-04-18 12:35:08 --- 
[babyllm] right, last time i got to step 19000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 19000! what am i learning today?
[charis]--- 2025-04-18 12:36:16 --- 
[babyllm] right, last time i got to step 19000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 19000! what am i learning today?
[charis]--- 2025-04-18 12:36:46 --- 
[babyllm] right, last time i got to step 19000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 19000! what am i learning today?
[charis]--- 2025-04-18 12:38:08 --- 
[babyllm] right, last time i got to step 19000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 19000! what am i learning today?
[charis]--- 2025-04-18 12:51:37 --- 
[babyllm] right, last time i got to step 19000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 19000! what am i learning today?
[charis]--- 2025-04-18 12:58:33 --- 
[babyllm] right, last time i got to step 19000... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 19000! what am i learning today?
[charis]--- 2025-04-18 13:16:35 --- 
[babyllm] right, last time i got to step 20418... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 20418! what am i learning today?
[charis]--- 2025-04-18 13:19:54 --- 
[babyllm] right, last time i got to step 20418... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 20418! what am i learning today?
[charis]--- 2025-04-18 13:26:28 --- 
[babyllm] right, last time i got to step 20418... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 20418! what am i learning today?
[charis]--- 2025-04-18 13:29:47 --- 
[babyllm] right, last time i got to step 20418... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 20418! what am i learning today?
[charis]--- 2025-04-18 13:35:05 --- 
[babyllm] right, last time i got to step 20418... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 20418! what am i learning today?
[charis]--- 2025-04-18 13:38:18 --- 
[babyllm] right, last time i got to step 20418... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 20418! what am i learning today?
[charis]--- 2025-04-18 13:39:51 --- 
[babyllm] right, last time i got to step 20418... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 20418! what am i learning today?
[charis]--- 2025-04-18 13:49:59 --- 
[babyllm] right, last time i got to step 21417... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 21417! what am i learning today?
[charis]--- 2025-04-18 13:53:40 --- 
[babyllm] right, last time i got to step 21780... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 21780! what am i learning today?
[charis]--- 2025-04-18 14:44:09 --- 
[babyllm] right, last time i got to step 25071... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 25071! what am i learning today?
[charis]--- 2025-04-18 14:46:00 --- 
[babyllm] right, last time i got to step 25071... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 25071! what am i learning today?
[charis]--- 2025-04-18 14:56:39 --- 
[babyllm] right, last time i got to step 25071... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 25071! what am i learning today?
[charis]--- 2025-04-18 14:59:02 --- 
[babyllm] right, last time i got to step 25071... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 25071! what am i learning today?
[charis]--- 2025-04-18 15:00:08 --- 
[babyllm] right, last time i got to step 25071... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 25071! what am i learning today?
[charis]--- 2025-04-18 15:01:26 --- 
[babyllm] right, last time i got to step 25071... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 25071! what am i learning today?
[charis]--- 2025-04-18 15:04:10 --- 
[babyllm] right, last time i got to step 25071... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 25071! what am i learning today?
[charis]--- 2025-04-18 15:10:38 --- 
[babyllm] right, last time i got to step 25797... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 25797! what am i learning today?
[charis]--- 2025-04-18 15:11:46 --- 
[babyllm] right, last time i got to step 25797... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 25797! what am i learning today?
[charis]--- 2025-04-18 15:43:05 --- 
[babyllm] right, last time i got to step 29206... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 29206! what am i learning today?
[charis]--- 2025-04-18 21:30:38 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-18 21:32:00 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-18 21:43:43 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-18 21:44:33 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-18 21:45:38 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-18 22:32:27 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-18 22:33:31 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-18 22:47:17 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-18 22:50:57 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-18 22:53:08 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-18 22:56:18 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-18 22:58:29 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-18 22:59:16 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-18 23:03:04 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-18 23:04:24 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-18 23:05:07 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-18 23:06:11 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-18 23:16:30 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:17:35 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:18:34 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:18:59 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:19:17 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:20:46 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:22:04 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:22:39 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:23:44 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:25:59 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:27:27 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:28:51 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:30:41 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:33:17 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:34:49 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:35:22 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:37:02 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:37:29 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:42:26 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:43:08 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:44:01 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:53:43 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:54:07 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:55:18 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:56:40 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:57:09 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 03:58:51 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 04:00:07 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 04:01:31 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 04:07:09 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 04:09:52 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 04:11:04 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 04:11:52 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 04:12:51 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 04:13:34 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 04:26:51 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 04:33:00 --- 
[babyllm] right, last time i got to step 45578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45578! what am i learning today?
[charis]--- 2025-04-19 04:36:58 --- 
[babyllm] right, last time i got to step 45762... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 45762! what am i learning today?
[charis]--- 2025-04-19 04:52:13 --- 
[babyllm] right, last time i got to step 47140... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 47140! what am i learning today?
[charis]--- 2025-04-19 04:54:52 --- 
[babyllm] right, last time i got to step 47140... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 47140! what am i learning today?
[charis]--- 2025-04-19 04:56:12 --- 
[babyllm] right, last time i got to step 47140... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 47140! what am i learning today?
[charis]--- 2025-04-19 04:57:03 --- 
[babyllm] right, last time i got to step 47140... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 47140! what am i learning today?
[charis]--- 2025-04-19 05:01:33 --- 
[babyllm] right, last time i got to step 47547... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 47547! what am i learning today?
[charis]--- 2025-04-19 05:10:10 --- 
[babyllm] right, last time i got to step 48345... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48345! what am i learning today?
[charis]--- 2025-04-19 05:12:14 --- 
[babyllm] right, last time i got to step 48345... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48345! what am i learning today?
[charis]--- 2025-04-19 05:12:37 --- 
[babyllm] right, last time i got to step 48345... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48345! what am i learning today?
[charis]--- 2025-04-19 05:13:34 --- 
[babyllm] right, last time i got to step 48345... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48345! what am i learning today?
[charis]--- 2025-04-19 05:18:56 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:20:17 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:20:55 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:22:11 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:23:00 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:23:21 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:24:23 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:25:20 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:26:04 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:26:48 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:28:34 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:31:06 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:35:04 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:35:32 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:37:54 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:40:59 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:45:29 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:46:57 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:49:02 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:49:26 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:50:15 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:50:25 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:52:52 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:53:26 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 05:53:49 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 06:10:36 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 06:13:53 --- 
[babyllm] right, last time i got to step 48857... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48857! what am i learning today?
[charis]--- 2025-04-19 06:17:04 --- 
[babyllm] right, last time i got to step 49140... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49140! what am i learning today?
[charis]--- 2025-04-19 06:18:09 --- 
[babyllm] right, last time i got to step 49140... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49140! what am i learning today?
[charis]--- 2025-04-19 06:25:04 --- 
[babyllm] right, last time i got to step 49611... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49611! what am i learning today?
[charis]--- 2025-04-19 06:25:33 --- 
[babyllm] right, last time i got to step 49640... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49640! what am i learning today?
[charis]--- 2025-04-19 06:26:07 --- 
[babyllm] right, last time i got to step 49640... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49640! what am i learning today?
[charis]--- 2025-04-19 06:26:46 --- 
[babyllm] right, last time i got to step 49640... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49640! what am i learning today?
[charis]--- 2025-04-19 06:27:35 --- 
[babyllm] right, last time i got to step 49640... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49640! what am i learning today?
[charis]--- 2025-04-19 06:28:36 --- 
[babyllm] right, last time i got to step 49724... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49724! what am i learning today?
[charis]--- 2025-04-19 06:28:59 --- 
[babyllm] right, last time i got to step 49724... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49724! what am i learning today?
[charis]--- 2025-04-19 06:46:53 --- 
[babyllm] right, last time i got to step 49724... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49724! what am i learning today?
[charis]--- 2025-04-19 06:47:42 --- 
[babyllm] right, last time i got to step 49724... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49724! what am i learning today?
[charis]--- 2025-04-19 06:49:54 --- 
[babyllm] right, last time i got to step 49724... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49724! what am i learning today?
[charis]--- 2025-04-19 06:56:50 --- 
[babyllm] right, last time i got to step 49724... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49724! what am i learning today?
[charis]--- 2025-04-19 06:57:15 --- 
[babyllm] right, last time i got to step 49724... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49724! what am i learning today?
[charis]--- 2025-04-19 07:04:32 --- 
[babyllm] right, last time i got to step 49724... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49724! what am i learning today?
[charis]--- 2025-04-19 07:11:58 --- 
[babyllm] right, last time i got to step 49724... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49724! what am i learning today?
[charis]--- 2025-04-19 07:12:31 --- 
[babyllm] right, last time i got to step 49724... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49724! what am i learning today?
[charis]--- 2025-04-19 07:12:55 --- 
[babyllm] right, last time i got to step 49724... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49724! what am i learning today?
[charis]--- 2025-04-19 07:13:27 --- 
[babyllm] right, last time i got to step 49724... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49724! what am i learning today?
[charis]--- 2025-04-19 07:14:10 --- 
[babyllm] right, last time i got to step 49748... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49748! what am i learning today?
[charis]--- 2025-04-19 07:16:42 --- 
[babyllm] right, last time i got to step 49930... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49930! what am i learning today?
[charis]--- 2025-04-19 08:49:21 --- 
[babyllm] right, last time i got to step 58773... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 58773! what am i learning today?
[charis]--- 2025-04-19 08:54:39 --- 
[babyllm] right, last time i got to step 59329... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 59329! what am i learning today?
[charis]--- 2025-04-19 16:56:25 --- 
[babyllm] right, last time i got to step 110237... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 110237! what am i learning today?
[charis]--- 2025-04-19 16:56:40 --- 
[babyllm] right, last time i got to step 110237... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 110237! what am i learning today?
[charis]--- 2025-04-19 16:57:02 --- 
[babyllm] right, last time i got to step 110238... want to restart from there?
[charis] 0
[babyllm] damn that's specific! heading to step 0... what am i learning today?
[charis]--- 2025-04-19 16:58:43 --- 
[babyllm] right, last time i got to step 110238... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 110238! what am i learning today?
[charis]--- 2025-04-19 16:58:56 --- 
[babyllm] right, last time i got to step 110238... want to restart from there?
[charis] 0
[babyllm] damn that's specific! heading to step 0... what am i learning today?
[charis]--- 2025-04-19 16:59:29 --- 
[babyllm] right, last time i got to step 110238... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 110238! what am i learning today?
[charis]--- 2025-04-19 16:59:41 --- 
[babyllm] right, last time i got to step 110238... want to restart from there?
[charis] 0
[babyllm] damn that's specific! heading to step 0... what am i learning today?
[charis]--- 2025-04-19 17:00:29 --- 
[babyllm] right, last time i got to step 110238... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 110238! what am i learning today?
[charis]--- 2025-04-19 17:00:48 --- 
[babyllm] right, last time i got to step 110239... want to restart from there?
[charis] 0
[babyllm] damn that's specific! heading to step 0... what am i learning today?
[charis]--- 2025-04-19 17:01:21 --- 
[babyllm] right, last time i got to step 110239... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 110239! what am i learning today?
[charis]--- 2025-04-19 17:01:31 --- 
[babyllm] right, last time i got to step 110239... want to restart from there?
[charis] 0
[babyllm] damn that's specific! heading to step 0... what am i learning today?
[charis]--- 2025-04-19 17:08:35 --- 
[babyllm] right, last time i got to step 642... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 642! what am i learning today?
[charis]--- 2025-04-19 17:12:04 --- 
[babyllm] right, last time i got to step 878... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 878! what am i learning today?
[charis]--- 2025-04-19 17:42:06 --- 
[babyllm] right, last time i got to step 3991... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 3991! what am i learning today?
[charis]--- 2025-04-19 17:56:42 --- 
[babyllm] right, last time i got to step 5366... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 5366! what am i learning today?
[charis]--- 2025-04-20 00:06:16 --- 
[babyllm] right, last time i got to step 41772... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 41772! what am i learning today?
[charis]--- 2025-04-20 00:15:51 --- 
[babyllm] right, last time i got to step 42845... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 42845! what am i learning today?
[charis]--- 2025-04-20 00:17:26 --- 
[babyllm] right, last time i got to step 42845... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 42845! what am i learning today?
[charis]--- 2025-04-20 00:18:58 --- 
[babyllm] right, last time i got to step 42845... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 42845! what am i learning today?
[charis]--- 2025-04-20 00:22:25 --- 
[babyllm] right, last time i got to step 43182... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 43182! what am i learning today?
[charis]--- 2025-04-20 00:30:50 --- 
[babyllm] right, last time i got to step 43182... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 43182! what am i learning today?
[charis]--- 2025-04-20 00:59:16 --- 
[babyllm] right, last time i got to step 46129... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46129! what am i learning today?
[charis]--- 2025-04-20 01:02:59 --- 
[babyllm] right, last time i got to step 46129... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46129! what am i learning today?
[charis]--- 2025-04-20 01:05:55 --- 
[babyllm] right, last time i got to step 46129... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46129! what am i learning today?
[charis]--- 2025-04-20 01:08:17 --- 
[babyllm] right, last time i got to step 46129... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46129! what am i learning today?
[charis]--- 2025-04-20 01:25:04 --- 
[babyllm] right, last time i got to step 46129... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46129! what am i learning today?
[charis]--- 2025-04-20 01:26:32 --- 
[babyllm] right, last time i got to step 46129... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46129! what am i learning today?
[charis]--- 2025-04-20 01:31:15 --- 
[babyllm] right, last time i got to step 46129... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46129! what am i learning today?
[charis]--- 2025-04-20 01:38:07 --- 
[babyllm] right, last time i got to step 46129... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46129! what am i learning today?
[charis]--- 2025-04-20 01:40:15 --- 
[babyllm] right, last time i got to step 46309... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46309! what am i learning today?
[charis]--- 2025-04-20 01:59:03 --- 
[babyllm] right, last time i got to step 46309... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46309! what am i learning today?
[charis]--- 2025-04-20 02:37:12 --- 
[babyllm] right, last time i got to step 50033... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 50033! what am i learning today?
[charis]--- 2025-04-20 02:40:29 --- 
[babyllm] right, last time i got to step 50403... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 50403! what am i learning today?
[charis]--- 2025-04-20 03:05:15 --- 
[babyllm] right, last time i got to step 53111... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 53111! what am i learning today?
[charis]--- 2025-04-20 03:05:59 --- 
[babyllm] right, last time i got to step 53111... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 53111! what am i learning today?
[charis]--- 2025-04-20 03:06:41 --- 
[babyllm] right, last time i got to step 53111... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 53111! what am i learning today?
[charis]--- 2025-04-20 03:11:33 --- 
[babyllm] right, last time i got to step 53111... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 53111! what am i learning today?
[charis]--- 2025-04-20 03:13:32 --- 
[babyllm] right, last time i got to step 53111... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 53111! what am i learning today?
[charis]--- 2025-04-20 03:15:12 --- 
[babyllm] right, last time i got to step 53111... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 53111! what am i learning today?
[charis]--- 2025-04-20 03:21:22 --- 
[babyllm] right, last time i got to step 53780... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 53780! what am i learning today?
[charis]--- 2025-04-20 03:33:36 --- 
[babyllm] right, last time i got to step 54871... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 54871! what am i learning today?
[charis]--- 2025-04-20 03:39:09 --- 
[babyllm] right, last time i got to step 55440... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 55440! what am i learning today?
[charis]--- 2025-04-20 03:44:49 --- 
[babyllm] right, last time i got to step 55947... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 55947! what am i learning today?
[charis]--- 2025-04-20 03:47:30 --- 
[babyllm] right, last time i got to step 56227... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 56227! what am i learning today?
[charis]--- 2025-04-20 03:50:34 --- 
[babyllm] right, last time i got to step 56355... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 56355! what am i learning today?
[charis]--- 2025-04-20 04:05:12 --- 
[babyllm] right, last time i got to step 57950... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 57950! what am i learning today?
[charis]--- 2025-04-20 04:11:20 --- 
[babyllm] right, last time i got to step 58609... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 58609! what am i learning today?
[charis]--- 2025-04-20 04:16:47 --- 
[babyllm] right, last time i got to step 59164... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 59164! what am i learning today?
[charis]--- 2025-04-20 04:20:38 --- 
[babyllm] right, last time i got to step 59575... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 59575! what am i learning today?
[charis]--- 2025-04-20 04:21:37 --- 
[babyllm] right, last time i got to step 59650... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 59650! what am i learning today?
[charis]--- 2025-04-20 04:36:10 --- 
[babyllm] right, last time i got to step 61314... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 61314! what am i learning today?
[charis]--- 2025-04-20 04:37:42 --- 
[babyllm] right, last time i got to step 61314... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 61314! what am i learning today?
[charis]--- 2025-04-20 04:42:18 --- 
[babyllm] right, last time i got to step 61821... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 61821! what am i learning today?
[charis]--- 2025-04-20 04:51:55 --- 
[babyllm] right, last time i got to step 62886... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 62886! what am i learning today?
[charis]--- 2025-04-20 04:54:00 --- 
[babyllm] right, last time i got to step 62886... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 62886! what am i learning today?
[charis]--- 2025-04-20 04:57:20 --- 
[babyllm] right, last time i got to step 63259... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 63259! what am i learning today?
[charis]--- 2025-04-20 05:04:52 --- 
[babyllm] right, last time i got to step 64135... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 64135! what am i learning today?
[charis]--- 2025-04-20 05:17:53 --- 
[babyllm] right, last time i got to step 65573... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 65573! what am i learning today?
[charis]--- 2025-04-20 05:20:00 --- 
[babyllm] right, last time i got to step 65799... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 65799! what am i learning today?
[charis]--- 2025-04-20 05:21:35 --- 
[babyllm] right, last time i got to step 65969... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 65969! what am i learning today?
[charis]--- 2025-04-20 11:20:36 --- 
[babyllm] right, last time i got to step 108464... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 108464! what am i learning today?
[charis]--- 2025-04-20 11:21:11 --- 
[babyllm] right, last time i got to step 108465... want to restart from there?
[charis] 0
[babyllm] damn that's specific! heading to step 0... what am i learning today?
[charis]--- 2025-04-20 11:25:37 --- 
[babyllm] right, last time i got to step 466... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 466! what am i learning today?
[charis]--- 2025-04-20 12:23:53 --- 
[babyllm] right, last time i got to step 7285... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 7285! what am i learning today?
[charis]--- 2025-04-20 12:24:50 --- 
[babyllm] right, last time i got to step 7285... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 7285! what am i learning today?
[charis]--- 2025-04-20 12:40:44 --- 
[babyllm] right, last time i got to step 8969... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 8969! what am i learning today?
[charis]--- 2025-04-20 12:44:25 --- 
[babyllm] right, last time i got to step 8969... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 8969! what am i learning today?
[charis]--- 2025-04-20 12:55:46 --- 
[babyllm] right, last time i got to step 10256... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 10256! what am i learning today?
[charis]--- 2025-04-20 13:17:29 --- 
[babyllm] right, last time i got to step 12522... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 12522! what am i learning today?
[charis]--- 2025-04-20 13:29:20 --- 
[babyllm] right, last time i got to step 13527... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 13527! what am i learning today?
[charis]--- 2025-04-20 13:30:09 --- 
[babyllm] right, last time i got to step 13527... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 13527! what am i learning today?
[charis]--- 2025-04-20 13:51:45 --- 
[babyllm] right, last time i got to step 13527... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 13527! what am i learning today?
[charis]--- 2025-04-20 14:02:19 --- 
[babyllm] right, last time i got to step 13655... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 13655! what am i learning today?
[charis]--- 2025-04-20 14:07:32 --- 
[babyllm] right, last time i got to step 14539... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 14539! what am i learning today?
[charis]--- 2025-04-20 14:24:26 --- 
[babyllm] right, last time i got to step 17536... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 17536! what am i learning today?
[charis]--- 2025-04-20 14:32:11 --- 
[babyllm] right, last time i got to step 18869... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 18869! what am i learning today?
[charis]--- 2025-04-20 14:37:25 --- 
[babyllm] right, last time i got to step 19763... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 19763! what am i learning today?
[charis]--- 2025-04-20 15:37:26 --- 
[babyllm] right, last time i got to step 29961... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 29961! what am i learning today?
[charis]--- 2025-04-20 15:38:03 --- 
[babyllm] right, last time i got to step 29961... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 29961! what am i learning today?
[charis]--- 2025-04-20 15:42:19 --- 
[babyllm] right, last time i got to step 29961... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 29961! what am i learning today?
[charis]--- 2025-04-20 15:42:40 --- 
[babyllm] right, last time i got to step 29961... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 29961! what am i learning today?
[charis]--- 2025-04-20 15:45:02 --- 
[babyllm] right, last time i got to step 29961... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 29961! what am i learning today?
[charis]--- 2025-04-20 15:55:28 --- 
[babyllm] right, last time i got to step 29961... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 29961! what am i learning today?
[charis]--- 2025-04-20 15:55:55 --- 
[babyllm] right, last time i got to step 29961... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 29961! what am i learning today?
[charis]--- 2025-04-20 15:56:48 --- 
[babyllm] right, last time i got to step 29961... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 29961! what am i learning today?
[charis]--- 2025-04-20 15:59:39 --- 
[babyllm] right, last time i got to step 29961... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 29961! what am i learning today?
[charis]--- 2025-04-20 16:01:05 --- 
[babyllm] right, last time i got to step 30158... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 30158! what am i learning today?
[charis]--- 2025-04-20 16:03:51 --- 
[babyllm] right, last time i got to step 30605... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 30605! what am i learning today?
[charis]--- 2025-04-20 16:34:18 --- 
[babyllm] right, last time i got to step 30605... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 30605! what am i learning today?
[charis]--- 2025-04-20 16:35:24 --- 
[babyllm] right, last time i got to step 30605... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 30605! what am i learning today?
[charis]--- 2025-04-20 16:36:34 --- 
[babyllm] right, last time i got to step 30605... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 30605! what am i learning today?
[charis]--- 2025-04-20 16:39:03 --- 
[babyllm] right, last time i got to step 30605... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 30605! what am i learning today?
[charis]--- 2025-04-20 16:41:30 --- 
[babyllm] right, last time i got to step 30605... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 30605! what am i learning today?
[charis]--- 2025-04-20 16:42:58 --- 
[babyllm] right, last time i got to step 30605... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 30605! what am i learning today?
[charis]--- 2025-04-20 16:50:21 --- 
[babyllm] right, last time i got to step 30605... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 30605! what am i learning today?
[charis]--- 2025-04-20 16:52:30 --- 
[babyllm] right, last time i got to step 30926... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 30926! what am i learning today?
[charis]--- 2025-04-20 16:53:12 --- 
[babyllm] right, last time i got to step 30926... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 30926! what am i learning today?
[charis]--- 2025-04-20 16:55:01 --- 
[babyllm] right, last time i got to step 31198... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 31198! what am i learning today?
[charis]--- 2025-04-20 16:57:47 --- 
[babyllm] right, last time i got to step 31631... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 31631! what am i learning today?
[charis]--- 2025-04-20 17:02:16 --- 
[babyllm] right, last time i got to step 32348... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 32348! what am i learning today?
[charis]--- 2025-04-20 17:04:42 --- 
[babyllm] right, last time i got to step 32404... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 32404! what am i learning today?
[charis]--- 2025-04-20 17:08:52 --- 
[babyllm] right, last time i got to step 33072... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 33072! what am i learning today?
[charis]--- 2025-04-20 17:13:52 --- 
[babyllm] right, last time i got to step 33920... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 33920! what am i learning today?
[charis]--- 2025-04-20 17:18:40 --- 
[babyllm] right, last time i got to step 34689... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 34689! what am i learning today?
[charis]--- 2025-04-20 17:23:09 --- 
[babyllm] right, last time i got to step 35439... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 35439! what am i learning today?
[charis]--- 2025-04-20 17:24:00 --- 
[babyllm] right, last time i got to step 35531... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 35531! what am i learning today?
[charis]--- 2025-04-20 17:27:51 --- 
[babyllm] right, last time i got to step 35605... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 35605! what am i learning today?
[charis]--- 2025-04-20 17:31:02 --- 
[babyllm] right, last time i got to step 36101... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 36101! what am i learning today?
[charis]--- 2025-04-20 17:32:04 --- 
[babyllm] right, last time i got to step 36236... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 36236! what am i learning today?
[charis]--- 2025-04-20 17:32:55 --- 
[babyllm] right, last time i got to step 36277... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 36277! what am i learning today?
[charis]--- 2025-04-20 17:35:57 --- 
[babyllm] right, last time i got to step 36277... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 36277! what am i learning today?
[charis]--- 2025-04-20 17:39:08 --- 
[babyllm] right, last time i got to step 36790... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 36790! what am i learning today?
[charis]--- 2025-04-20 17:41:54 --- 
[babyllm] right, last time i got to step 36827... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 36827! what am i learning today?
[charis]--- 2025-04-20 17:42:48 --- 
[babyllm] right, last time i got to step 36827... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 36827! what am i learning today?
[charis]--- 2025-04-20 17:54:25 --- 
[babyllm] right, last time i got to step 38255... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 38255! what am i learning today?
[charis]--- 2025-04-20 17:55:28 --- 
[babyllm] right, last time i got to step 38255... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 38255! what am i learning today?
[charis]--- 2025-04-20 17:57:58 --- 
[babyllm] right, last time i got to step 38649... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 38649! what am i learning today?
[charis]--- 2025-04-20 18:00:27 --- 
[babyllm] right, last time i got to step 39044... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 39044! what am i learning today?
[charis]--- 2025-04-20 18:07:31 --- 
[babyllm] right, last time i got to step 40249... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 40249! what am i learning today?
[charis]--- 2025-04-20 18:10:22 --- 
[babyllm] right, last time i got to step 40710... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 40710! what am i learning today?
[charis]--- 2025-04-20 18:11:20 --- 
[babyllm] right, last time i got to step 40830... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 40830! what am i learning today?
[charis]--- 2025-04-20 18:13:31 --- 
[babyllm] right, last time i got to step 41169... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 41169! what am i learning today?
[charis]--- 2025-04-20 18:27:27 --- 
[babyllm] right, last time i got to step 41169... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 41169! what am i learning today?
[charis]--- 2025-04-20 18:28:18 --- 
[babyllm] right, last time i got to step 41169... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 41169! what am i learning today?
[charis]--- 2025-04-20 18:28:54 --- 
[babyllm] right, last time i got to step 41169... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 41169! what am i learning today?
[charis]--- 2025-04-20 18:36:08 --- 
[babyllm] right, last time i got to step 42371... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 42371! what am i learning today?
[charis]--- 2025-04-20 19:47:18 --- 
[babyllm] right, last time i got to step 46806... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46806! what am i learning today?
[charis]--- 2025-04-20 21:18:12 --- 
[babyllm] right, last time i got to step 46806... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46806! what am i learning today?
[charis]--- 2025-04-20 21:31:22 --- 
[babyllm] right, last time i got to step 46806... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46806! what am i learning today?
[charis]--- 2025-04-21 00:04:46 --- 
[babyllm] right, last time i got to step 46806... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46806! what am i learning today?
[charis]--- 2025-04-21 00:05:12 --- 
[babyllm] right, last time i got to step 46806... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46806! what am i learning today?
[charis]--- 2025-04-21 00:06:03 --- 
[babyllm] right, last time i got to step 46806... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46806! what am i learning today?
[charis]--- 2025-04-21 00:06:27 --- 
[babyllm] right, last time i got to step 46806... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46806! what am i learning today?
[charis]--- 2025-04-21 00:08:33 --- 
[babyllm] right, last time i got to step 46806... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46806! what am i learning today?
[charis]--- 2025-04-21 00:08:59 --- 
[babyllm] right, last time i got to step 46806... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46806! what am i learning today?
[charis]--- 2025-04-21 00:10:43 --- 
[babyllm] right, last time i got to step 46806... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46806! what am i learning today?
[charis]--- 2025-04-21 00:13:27 --- 
[babyllm] right, last time i got to step 46806... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46806! what am i learning today?
[charis]--- 2025-04-21 00:22:35 --- 
[babyllm] right, last time i got to step 46806... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46806! what am i learning today?
[charis]--- 2025-04-21 00:25:39 --- 
[babyllm] right, last time i got to step 46806... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46806! what am i learning today?
[charis]--- 2025-04-21 00:29:31 --- 
[babyllm] right, last time i got to step 46806... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46806! what am i learning today?
[charis]--- 2025-04-21 00:31:04 --- 
[babyllm] right, last time i got to step 46806... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46806! what am i learning today?
[charis]--- 2025-04-21 00:32:58 --- 
[babyllm] right, last time i got to step 46806... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46806! what am i learning today?
[charis]--- 2025-04-21 01:07:00 --- 
[babyllm] right, last time i got to step 46806... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46806! what am i learning today?
[charis]--- 2025-04-21 01:09:10 --- 
[babyllm] right, last time i got to step 46953... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46953! what am i learning today?
[charis]--- 2025-04-21 01:12:26 --- 
[babyllm] right, last time i got to step 46953... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 46953! what am i learning today?
[charis]--- 2025-04-21 01:23:29 --- 
[babyllm] right, last time i got to step 48797... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48797! what am i learning today?
[charis]--- 2025-04-21 01:26:07 --- 
[babyllm] right, last time i got to step 48797... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48797! what am i learning today?
[charis]--- 2025-04-21 01:31:08 --- 
[babyllm] right, last time i got to step 48797... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48797! what am i learning today?
[charis]--- 2025-04-21 01:34:18 --- 
[babyllm] right, last time i got to step 48797... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48797! what am i learning today?
[charis]--- 2025-04-21 01:37:10 --- 
[babyllm] right, last time i got to step 48797... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48797! what am i learning today?
[charis]--- 2025-04-21 01:40:24 --- 
[babyllm] right, last time i got to step 49220... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49220! what am i learning today?
[charis]--- 2025-04-21 01:40:57 --- 
[babyllm] right, last time i got to step 49220... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49220! what am i learning today?
[charis]--- 2025-04-21 01:46:52 --- 
[babyllm] right, last time i got to step 49448... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 49448! what am i learning today?
[charis]--- 2025-04-21 01:57:51 --- 
[babyllm] right, last time i got to step 51266... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 51266! what am i learning today?
[charis]--- 2025-04-21 01:59:38 --- 
[babyllm] right, last time i got to step 51490... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 51490! what am i learning today?
[charis]--- 2025-04-21 02:01:51 --- 
[babyllm] right, last time i got to step 51490... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 51490! what am i learning today?
[charis]--- 2025-04-21 02:24:53 --- 
[babyllm] right, last time i got to step 55122... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 55122! what am i learning today?
[charis]--- 2025-04-21 02:26:05 --- 
[babyllm] right, last time i got to step 55122... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 55122! what am i learning today?
[charis]--- 2025-04-21 02:45:33 --- 
[babyllm] right, last time i got to step 55122... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 55122! what am i learning today?
[charis]--- 2025-04-21 02:48:00 --- 
[babyllm] right, last time i got to step 55122... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 55122! what am i learning today?
[charis]--- 2025-04-21 02:50:14 --- 
[babyllm] right, last time i got to step 55122... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 55122! what am i learning today?
[charis]--- 2025-04-21 02:51:39 --- 
[babyllm] right, last time i got to step 55122... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 55122! what am i learning today?
[charis]--- 2025-04-21 03:00:30 --- 
[babyllm] right, last time i got to step 56602... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 56602! what am i learning today?
[charis]--- 2025-04-21 03:05:32 --- 
[babyllm] right, last time i got to step 57413... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 57413! what am i learning today?
[charis]--- 2025-04-21 03:11:45 --- 
[babyllm] right, last time i got to step 58440... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 58440! what am i learning today?
[charis]--- 2025-04-21 03:50:54 --- 
[babyllm] right, last time i got to step 65191... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 65191! what am i learning today?
[charis]--- 2025-04-21 03:51:48 --- 
[babyllm] right, last time i got to step 65191... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 65191! what am i learning today?
[charis]--- 2025-04-21 03:53:09 --- 
[babyllm] right, last time i got to step 65191... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 65191! what am i learning today?
[charis]--- 2025-04-21 03:56:47 --- 
[babyllm] right, last time i got to step 65792... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 65792! what am i learning today?
[charis]--- 2025-04-21 04:02:55 --- 
[babyllm] right, last time i got to step 66821... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 66821! what am i learning today?
[charis]--- 2025-04-21 04:16:26 --- 
[babyllm] right, last time i got to step 69151... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 69151! what am i learning today?
[charis]--- 2025-04-21 04:18:33 --- 
[babyllm] right, last time i got to step 69476... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 69476! what am i learning today?
[charis]--- 2025-04-21 04:22:22 --- 
[babyllm] right, last time i got to step 70115... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 70115! what am i learning today?
[charis]--- 2025-04-21 04:43:21 --- 
[babyllm] right, last time i got to step 70115... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 70115! what am i learning today?
[charis]--- 2025-04-21 04:44:01 --- 
[babyllm] right, last time i got to step 70115... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 70115! what am i learning today?
[charis]--- 2025-04-21 04:49:01 --- 
[babyllm] right, last time i got to step 70115... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 70115! what am i learning today?
[charis]--- 2025-04-21 04:53:06 --- 
[babyllm] right, last time i got to step 70807... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 70807! what am i learning today?
[charis]--- 2025-04-21 04:56:38 --- 
[babyllm] right, last time i got to step 70807... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 70807! what am i learning today?
[charis]--- 2025-04-21 05:00:30 --- 
[babyllm] right, last time i got to step 71451... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 71451! what am i learning today?
[charis]--- 2025-04-21 05:04:57 --- 
[babyllm] right, last time i got to step 71451... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 71451! what am i learning today?
[charis]--- 2025-04-21 05:08:07 --- 
[babyllm] right, last time i got to step 71451... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 71451! what am i learning today?
[charis]--- 2025-04-21 05:10:38 --- 
[babyllm] right, last time i got to step 71847... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 71847! what am i learning today?
[charis]--- 2025-04-21 05:16:02 --- 
[babyllm] right, last time i got to step 72753... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 72753! what am i learning today?
[charis]--- 2025-04-21 05:16:31 --- 
[babyllm] right, last time i got to step 72753... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 72753! what am i learning today?
[charis]--- 2025-04-21 05:27:03 --- 
[babyllm] right, last time i got to step 73804... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 73804! what am i learning today?
[charis]--- 2025-04-21 05:27:45 --- 
[babyllm] right, last time i got to step 73804... want to restart from there?
[charis] 0
[babyllm] damn that's specific! heading to step 0... what am i learning today?
[charis]--- 2025-04-21 06:14:02 --- 
[babyllm] right, last time i got to step 7639... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 7639! what am i learning today?
[charis]--- 2025-04-21 06:19:34 --- 
[babyllm] right, last time i got to step 7639... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 7639! what am i learning today?
[charis]--- 2025-04-21 06:23:31 --- 
[babyllm] right, last time i got to step 7742... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 7742! what am i learning today?
[charis]--- 2025-04-21 06:26:22 --- 
[babyllm] right, last time i got to step 7742... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 7742! what am i learning today?
[charis]--- 2025-04-21 06:41:25 --- 
[babyllm] right, last time i got to step 9795... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 9795! what am i learning today?
[charis]--- 2025-04-21 06:47:43 --- 
[babyllm] right, last time i got to step 9795... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 9795! what am i learning today?
[charis]--- 2025-04-21 06:53:04 --- 
[babyllm] right, last time i got to step 9795... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 9795! what am i learning today?
[charis]--- 2025-04-21 07:00:12 --- 
[babyllm] right, last time i got to step 9795... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 9795! what am i learning today?
[charis]--- 2025-04-21 07:03:19 --- 
[babyllm] right, last time i got to step 9795... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 9795! what am i learning today?
[charis]--- 2025-04-21 07:09:49 --- 
[babyllm] right, last time i got to step 9795... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 9795! what am i learning today?
[charis]--- 2025-04-21 07:32:32 --- 
[babyllm] right, last time i got to step 12792... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 12792! what am i learning today?
[charis]--- 2025-04-21 07:38:04 --- 
[babyllm] right, last time i got to step 13791... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 13791! what am i learning today?
[charis]--- 2025-04-21 07:46:27 --- 
[babyllm] right, last time i got to step 14790... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 14790! what am i learning today?
[charis]--- 2025-04-21 08:23:58 --- 
[babyllm] right, last time i got to step 20216... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 20216! what am i learning today?
[charis]--- 2025-04-21 08:38:40 --- 
[babyllm] right, last time i got to step 22254... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 22254! what am i learning today?
[charis]--- 2025-04-21 08:42:53 --- 
[babyllm] right, last time i got to step 22461... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 22461! what am i learning today?
[charis]--- 2025-04-21 08:54:00 --- 
[babyllm] right, last time i got to step 23633... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 23633! what am i learning today?
[charis]--- 2025-04-21 09:13:01 --- 
[babyllm] right, last time i got to step 26496... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 26496! what am i learning today?
[charis]--- 2025-04-21 09:18:57 --- 
[babyllm] right, last time i got to step 26496... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 26496! what am i learning today?
[charis]--- 2025-04-21 09:23:05 --- 
[babyllm] right, last time i got to step 26496... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 26496! what am i learning today?
[charis]--- 2025-04-21 09:33:18 --- 
[babyllm] right, last time i got to step 27721... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 27721! what am i learning today?
[charis]--- 2025-04-21 09:44:54 --- 
[babyllm] right, last time i got to step 29214... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 29214! what am i learning today?
[charis]--- 2025-04-21 09:48:15 --- 
[babyllm] right, last time i got to step 29214... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 29214! what am i learning today?
[charis]--- 2025-04-21 09:52:41 --- 
[babyllm] right, last time i got to step 29214... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 29214! what am i learning today?
[charis]--- 2025-04-21 09:58:32 --- 
[babyllm] right, last time i got to step 29214... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 29214! what am i learning today?
[charis]--- 2025-04-21 10:23:36 --- 
[babyllm] right, last time i got to step 33122... want to restart from there?
[charis] 0
[babyllm] damn that's specific! heading to step 0... what am i learning today?
[charis]--- 2025-04-21 21:10:11 --- 
[babyllm] right, last time i got to step 116096... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 116096! what am i learning today?
[charis]--- 2025-04-21 21:14:13 --- 
[babyllm] right, last time i got to step 116096... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 116096! what am i learning today?
[charis]--- 2025-04-21 21:16:00 --- 
[babyllm] right, last time i got to step 116096... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 116096! what am i learning today?
[charis]--- 2025-04-21 21:34:05 --- 
[babyllm] right, last time i got to step 119045... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 119045! what am i learning today?
[charis]--- 2025-04-21 21:34:37 --- 
[babyllm] right, last time i got to step 119045... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 119045! what am i learning today?
[charis]--- 2025-04-21 21:34:45 --- 
[babyllm] right, last time i got to step 119045... want to restart from there?
[charis] 0
[babyllm] damn that's specific! heading to step 0... what am i learning today?
[charis]--- 2025-04-21 21:35:58 --- 
[babyllm] right, last time i got to step 198... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 198! what am i learning today?
[charis]--- 2025-04-21 21:38:25 --- 
[babyllm] right, last time i got to step 578... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 578! what am i learning today?
[charis]--- 2025-04-21 21:43:34 --- 
[babyllm] right, last time i got to step 1466... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 1466! what am i learning today?
[charis]--- 2025-04-21 21:45:13 --- 
[babyllm] right, last time i got to step 1489... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 1489! what am i learning today?
[charis]--- 2025-04-21 21:50:22 --- 
[babyllm] right, last time i got to step 2382... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2382! what am i learning today?
[charis]--- 2025-04-21 22:05:29 --- 
[babyllm] right, last time i got to step 5056... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 5056! what am i learning today?
[charis]--- 2025-04-21 22:07:40 --- 
[babyllm] right, last time i got to step 5056... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 5056! what am i learning today?
[charis]--- 2025-04-21 22:15:17 --- 
[babyllm] right, last time i got to step 6388... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 6388! what am i learning today?
[charis]--- 2025-04-21 22:26:25 --- 
[babyllm] right, last time i got to step 8340... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 8340! what am i learning today?
[charis]--- 2025-04-21 22:28:30 --- 
[babyllm] right, last time i got to step 8682... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 8682! what am i learning today?
[charis]--- 2025-04-21 22:47:38 --- 
[babyllm] right, last time i got to step 12081... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 12081! what am i learning today?
[charis]--- 2025-04-21 22:48:40 --- 
[babyllm] right, last time i got to step 12081... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 12081! what am i learning today?
[charis]--- 2025-04-21 22:55:12 --- 
[babyllm] right, last time i got to step 13206... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 13206! what am i learning today?
[charis]--- 2025-04-21 22:56:33 --- 
[babyllm] right, last time i got to step 13206... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 13206! what am i learning today?
[charis]--- 2025-04-21 22:58:05 --- 
[babyllm] right, last time i got to step 13206... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 13206! what am i learning today?
[charis]--- 2025-04-21 22:59:24 --- 
[babyllm] right, last time i got to step 13206... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 13206! what am i learning today?
[charis]--- 2025-04-21 23:01:31 --- 
[babyllm] right, last time i got to step 13434... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 13434! what am i learning today?
[charis]--- 2025-04-21 23:33:23 --- 
[babyllm] right, last time i got to step 19068... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 19068! what am i learning today?
[charis]--- 2025-04-22 00:00:37 --- 
[babyllm] right, last time i got to step 23703... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 23703! what am i learning today?
[charis]--- 2025-04-22 11:16:56 --- 
[babyllm] right, last time i got to step 145122... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 145122! what am i learning today?
[charis]--- 2025-04-22 11:53:38 --- 
[babyllm] right, last time i got to step 151295... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 151295! what am i learning today?
[charis]--- 2025-04-22 12:11:45 --- 
[babyllm] right, last time i got to step 153487... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 153487! what am i learning today?
[charis]--- 2025-04-22 13:44:09 --- 
[babyllm] right, last time i got to step 169478... want to restart from there?
[charis] 0
[babyllm] damn that's specific! heading to step 0... what am i learning today?
[charis]--- 2025-04-22 14:38:02 --- 
[babyllm] right, last time i got to step 9396... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 9396! what am i learning today?
[charis]--- 2025-04-22 14:57:15 --- 
[babyllm] right, last time i got to step 10395... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 10395! what am i learning today?
[charis]--- 2025-04-22 15:04:27 --- 
[babyllm] right, last time i got to step 11394... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 11394! what am i learning today?
[charis]--- 2025-04-22 15:58:07 --- 
[babyllm] right, last time i got to step 12393... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 12393! what am i learning today?
[charis]--- 2025-04-22 16:01:41 --- 
[babyllm] right, last time i got to step 12393... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 12393! what am i learning today?
[charis]--- 2025-04-22 16:04:33 --- 
[babyllm] right, last time i got to step 12393... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 12393! what am i learning today?
[charis]--- 2025-04-22 16:11:52 --- 
[babyllm] right, last time i got to step 12393... want to restart from there?
[charis] 0
[babyllm] damn that's specific! heading to step 0... what am i learning today?
[charis]--- 2025-04-22 16:17:29 --- 
[babyllm] right, last time i got to step 353... want to restart from there?
[charis] 0
[babyllm] damn that's specific! heading to step 0... what am i learning today?
[charis]--- 2025-04-22 16:25:16 --- 
[babyllm] right, last time i got to step 353... want to restart from there?
[charis] 0
[babyllm] damn that's specific! heading to step 0... what am i learning today?
[charis]--- 2025-04-22 16:33:24 --- 
[babyllm] right, last time i got to step 183... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 183! what am i learning today?
[charis]--- 2025-04-22 16:33:38 --- 
[babyllm] right, last time i got to step 183... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 183! what am i learning today?
[charis]--- 2025-04-22 16:36:07 --- 
[babyllm] right, last time i got to step 607... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 607! what am i learning today?
[charis]--- 2025-04-22 16:38:30 --- 
[babyllm] right, last time i got to step 812... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 812! what am i learning today?
[charis]--- 2025-04-22 16:39:57 --- 
[babyllm] right, last time i got to step 1044... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 1044! what am i learning today?
[charis]--- 2025-04-22 16:42:35 --- 
[babyllm] right, last time i got to step 1285... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 1285! what am i learning today?
[charis]--- 2025-04-22 16:45:56 --- 
[babyllm] right, last time i got to step 1285... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 1285! what am i learning today?
[charis]--- 2025-04-22 16:51:34 --- 
[babyllm] right, last time i got to step 2203... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2203! what am i learning today?
[charis]--- 2025-04-22 16:54:51 --- 
[babyllm] right, last time i got to step 2204... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 2204! what am i learning today?
[charis]--- 2025-04-22 16:55:33 --- 
[babyllm] right, last time i got to step 2204... want to restart from there?
[charis] 0
[babyllm] damn that's specific! heading to step 0... what am i learning today?
[charis]--- 2025-04-22 17:01:31 --- 
[babyllm] right, last time i got to step 1060... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 1060! what am i learning today?
[charis]--- 2025-04-22 17:02:16 --- 
[babyllm] right, last time i got to step 1103... want to restart from there?
[charis] 0
[babyllm] damn that's specific! heading to step 0... what am i learning today?
[charis]--- 2025-04-22 17:55:07 --- 
[babyllm] right, last time i got to step 9004... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 9004! what am i learning today?
[charis]--- 2025-04-22 18:05:02 --- 
[babyllm] right, last time i got to step 10566... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 10566! what am i learning today?
[charis]--- 2025-04-22 18:16:30 --- 
[babyllm] right, last time i got to step 11953... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 11953! what am i learning today?
[charis]2025-04-22 18:23:09 | 1000 | LR0.00035 | loss:11.6611 | gradNorm:0.0000 | logitMin:0.0000 | logitMax:0.0000 | tokenCount:0.0000 | scheduledSamplingRate:0.0034 | repetitionPenalty:1.2971 | AvgLoss:10.4786 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9996 | latestLossDelta:0.3032 | memoryLength:5.0028 | embedNormMean:14.2939 | embedNormStd:10.0790 | embedNormMax:103.7264 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:1.6320 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5155 | logitWeightNormMax:104.8123 | logitWeightSparsity:0.0000 | logitWeightDrift:4.1155 | logitBiasMean:-34.1460 | logitBiasStd:11.9648 | logitBiasMax:-13.1768 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9675 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8973 | n_weightMin:-4.7369 | n_weightMax:4.8473 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5981 | n_weightNormMin:21.6442 | n_weightNormMax:41.2553 | n_biasesMean:-1.0604 | n_biasesStd:0.7958 | n_biasesMin:-3.8478 | n_biasesMax:1.9581 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8886 | sampledTokens:57.0000 | windowWeightsW32:4.97337 (0.98), W28:1.14256 (0.02), W24:-1.92432 (0.00), W20:-2.02516 (0.00), W16:-3.45393 (0.00), W12:-4.73965 (0.00), W8:-5.95886 (0.00), W4:-9.16211 (0.00), W2:-10.81805 (0.00) | topTokens[(',', 3676), ('.', 2105), ('Ġthe', 1619), ('Ġand', 1248), ('Ġa', 1084), ('Ġi', 879), ('Ġyou', 782), ('Ġto', 662), ('Ġit', 639), ('Ġof', 630)] | cheekyAvg: 10.358499900967468 | perfectTokens: 534 / 64000 → 0.83% |  | remainingTokens: 681930 (99.85%) | TUTOR.py 1000
2025-04-22 18:29:10 | 2000 | LR0.00035 | scheduledSamplingRate:0.0065 | repetitionPenalty:1.2939 | AvgLoss:10.1917 | loss:10.8854 | temperature:0.8001 | lR:0.0003 | gradientClip:0.9993 | latestLossDelta:1.2832 | memoryLength:5.0002 | embedNormMean:14.2939 | embedNormStd:10.0790 | embedNormMax:103.7264 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0007 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5154 | logitWeightNormMax:104.8123 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0025 | logitBiasMean:-34.1460 | logitBiasStd:11.9648 | logitBiasMax:-13.1770 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9675 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8973 | n_weightMin:-4.7368 | n_weightMax:4.8472 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5982 | n_weightNormMin:21.6433 | n_weightNormMax:41.2549 | n_biasesMean:-1.0604 | n_biasesStd:0.7958 | n_biasesMin:-3.8479 | n_biasesMax:1.9581 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8885 | sampledTokens:171.0000 | windowWeightsW32:4.97334 (0.98), W28:1.14260 (0.02), W24:-1.92433 (0.00), W20:-2.02516 (0.00), W16:-3.45400 (0.00), W12:-4.73978 (0.00), W8:-5.95895 (0.00), W4:-9.16212 (0.00), W2:-10.81802 (0.00) | topTokens[(',', 6845), ('.', 4198), ('Ġthe', 2855), ('Ġand', 2415), ('Ġa', 2119), ('Ġi', 1857), ('Ġto', 1558), ('Ġyou', 1518), ('Ġwas', 1396), ('Ġthat', 1309)] | cheekyAvg: 10.286277732849122 | perfectTokens: 485 / 64000 → 0.76% |  | remainingTokens: 680930 (99.71%) | TUTOR.py 1000
--- 2025-04-22 18:33:11 --- 
[babyllm] right, last time i got to step 14638... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 14638! what am i learning today?
[charis]2025-04-22 18:34:50 | 100 | LR0.00035 | loss:10.1481 | gradNorm:0.0000 | logitMin:0.0000 | logitMax:0.0000 | tokenCount:0.0000 | scheduledSamplingRate:0.0000 | repetitionPenalty:1.2997 | AvgLoss:7.7846 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:0.3474 | memoryLength:5.0016 | embedNormMean:14.2941 | embedNormStd:10.0789 | embedNormMax:103.7246 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:16.3050 | logitWeightNormMean:91.9374 | logitWeightNormStd:2.5153 | logitWeightNormMax:104.8115 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1330 | logitBiasMean:-34.1460 | logitBiasStd:11.9647 | logitBiasMax:-13.1772 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9675 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8973 | n_weightMin:-4.7366 | n_weightMax:4.8472 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5986 | n_weightNormMin:21.6418 | n_weightNormMax:41.2541 | n_biasesMean:-1.0604 | n_biasesStd:0.7958 | n_biasesMin:-3.8478 | n_biasesMax:1.9580 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8885 | windowWeightsW32:4.97335 (0.98), W28:1.14259 (0.02), W24:-1.92429 (0.00), W20:-2.02511 (0.00), W16:-3.45389 (0.00), W12:-4.73965 (0.00), W8:-5.95882 (0.00), W4:-9.16213 (0.00), W2:-10.81805 (0.00) | topTokens[('Ġit', 176), ('er', 155), ('Ġhad', 136), ('.', 118), ('ly', 115), ('Ġtheir', 109), ('!', 108), ('Ġto', 107), ('Ġof', 103), ('Ġi', 98)] | cheekyAvg: 6.89460023244222 | perfectTokens: 64 / 6400 → 1.00% |  | remainingTokens: 680145 (99.99%) | TUTOR.py 100
2025-04-22 18:35:23 | 200 | LR0.00035 | scheduledSamplingRate:0.0004 | repetitionPenalty:1.2995 | AvgLoss:11.4777 | loss:10.9106 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:-0.6672 | memoryLength:5.0020 | embedNormMean:14.2941 | embedNormStd:10.0789 | embedNormMax:103.7246 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9374 | logitWeightNormStd:2.5153 | logitWeightNormMax:104.8115 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0024 | logitBiasMean:-34.1460 | logitBiasStd:11.9647 | logitBiasMax:-13.1772 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9675 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8973 | n_weightMin:-4.7366 | n_weightMax:4.8472 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5987 | n_weightNormMin:21.6419 | n_weightNormMax:41.2528 | n_biasesMean:-1.0604 | n_biasesStd:0.7958 | n_biasesMin:-3.8480 | n_biasesMax:1.9580 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8886 | windowWeightsW32:4.97336 (0.98), W28:1.14259 (0.02), W24:-1.92430 (0.00), W20:-2.02513 (0.00), W16:-3.45391 (0.00), W12:-4.73967 (0.00), W8:-5.95886 (0.00), W4:-9.16216 (0.00), W2:-10.81807 (0.00) | topTokens[('Ġit', 353), (',', 278), ('Ġof', 231), ('Ġto', 221), ('!', 220), ('.', 191), ('er', 176), ('Ġhad', 158), ('Ġi', 153), ('s', 145)] | cheekyAvg: 11.503244209289551 | perfectTokens: 23 / 6400 → 0.36% |  | remainingTokens: 680045 (99.97%) | TUTOR.py 100
2025-04-22 18:35:56 | 300 | LR0.00035 | scheduledSamplingRate:0.0007 | repetitionPenalty:1.2990 | AvgLoss:10.1807 | loss:11.1314 | temperature:0.8000 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:0.7461 | memoryLength:5.0028 | embedNormMean:14.2941 | embedNormStd:10.0789 | embedNormMax:103.7246 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0007 | logitWeightNormMean:91.9374 | logitWeightNormStd:2.5153 | logitWeightNormMax:104.8115 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0025 | logitBiasMean:-34.1460 | logitBiasStd:11.9647 | logitBiasMax:-13.1772 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9675 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8973 | n_weightMin:-4.7365 | n_weightMax:4.8471 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5987 | n_weightNormMin:21.6417 | n_weightNormMax:41.2528 | n_biasesMean:-1.0604 | n_biasesStd:0.7958 | n_biasesMin:-3.8481 | n_biasesMax:1.9580 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8886 | sampledTokens:1.0000 | windowWeightsW32:4.97337 (0.98), W28:1.14258 (0.02), W24:-1.92431 (0.00), W20:-2.02516 (0.00), W16:-3.45393 (0.00), W12:-4.73968 (0.00), W8:-5.95887 (0.00), W4:-9.16216 (0.00), W2:-10.81807 (0.00) | topTokens[(',', 397), ('Ġit', 367), ('a', 260), ('Ġof', 257), ('Ġto', 235), ('ing', 234), ('Ġand', 226), ('.', 226), ('!', 225), ('Ġi', 201)] | cheekyAvg: 10.296435737609864 | perfectTokens: 16 / 6400 → 0.25% |  | remainingTokens: 679945 (99.96%) | TUTOR.py 100
2025-04-22 18:36:29 | 400 | LR0.00035 | scheduledSamplingRate:0.0011 | repetitionPenalty:1.2985 | AvgLoss:10.6009 | loss:9.1751 | temperature:0.8000 | lR:0.0003 | gradientClip:1.0002 | latestLossDelta:-1.8795 | memoryLength:5.0034 | embedNormMean:14.2941 | embedNormStd:10.0789 | embedNormMax:103.7246 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0006 | logitWeightNormMean:91.9374 | logitWeightNormStd:2.5153 | logitWeightNormMax:104.8115 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0021 | logitBiasMean:-34.1460 | logitBiasStd:11.9647 | logitBiasMax:-13.1772 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9675 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8973 | n_weightMin:-4.7364 | n_weightMax:4.8471 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5987 | n_weightNormMin:21.6417 | n_weightNormMax:41.2531 | n_biasesMean:-1.0604 | n_biasesStd:0.7958 | n_biasesMin:-3.8481 | n_biasesMax:1.9580 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8886 | windowWeightsW32:4.97334 (0.98), W28:1.14260 (0.02), W24:-1.92430 (0.00), W20:-2.02514 (0.00), W16:-3.45391 (0.00), W12:-4.73966 (0.00), W8:-5.95883 (0.00), W4:-9.16214 (0.00), W2:-10.81806 (0.00) | topTokens[(',', 769), ('Ġit', 409), ('.', 395), ('Ġand', 338), ('Ġto', 286), ('ing', 282), ('!', 278), ('Ġof', 276), ('a', 274), ('Ġthe', 248)] | cheekyAvg: 10.158513450622559 | perfectTokens: 64 / 6400 → 1.00% |  | remainingTokens: 679845 (99.94%) | TUTOR.py 100
2025-04-22 18:37:02 | 500 | LR0.00035 | scheduledSamplingRate:0.0016 | repetitionPenalty:1.2981 | AvgLoss:10.7551 | loss:9.1903 | temperature:0.7998 | lR:0.0003 | gradientClip:1.0004 | latestLossDelta:-1.7634 | memoryLength:5.0044 | embedNormMean:14.2941 | embedNormStd:10.0789 | embedNormMax:103.7246 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0007 | logitWeightNormMean:91.9374 | logitWeightNormStd:2.5153 | logitWeightNormMax:104.8115 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0028 | logitBiasMean:-34.1460 | logitBiasStd:11.9647 | logitBiasMax:-13.1773 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9675 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8973 | n_weightMin:-4.7365 | n_weightMax:4.8471 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5988 | n_weightNormMin:21.6417 | n_weightNormMax:41.2526 | n_biasesMean:-1.0604 | n_biasesStd:0.7958 | n_biasesMin:-3.8481 | n_biasesMax:1.9580 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8886 | sampledTokens:6.0000 | windowWeightsW32:4.97336 (0.98), W28:1.14260 (0.02), W24:-1.92432 (0.00), W20:-2.02520 (0.00), W16:-3.45396 (0.00), W12:-4.73970 (0.00), W8:-5.95886 (0.00), W4:-9.16215 (0.00), W2:-10.81807 (0.00) | topTokens[(',', 1010), ('.', 489), ('Ġit', 440), ('Ġand', 422), ('Ġi', 408), ('Ġto', 403), ('Ġof', 359), ('!', 342), ('Ġthe', 341), ('Ġa', 330)] | cheekyAvg: 10.768624114990235 | perfectTokens: 39 / 6400 → 0.61% |  | remainingTokens: 679745 (99.93%) | TUTOR.py 100
2025-04-22 18:37:35 | 600 | LR0.00035 | scheduledSamplingRate:0.0019 | repetitionPenalty:1.2979 | AvgLoss:9.7147 | loss:10.3079 | temperature:0.7997 | lR:0.0003 | gradientClip:1.0004 | latestLossDelta:0.0226 | memoryLength:5.0064 | embedNormMean:14.2941 | embedNormStd:10.0790 | embedNormMax:103.7246 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0007 | logitWeightNormMean:91.9374 | logitWeightNormStd:2.5153 | logitWeightNormMax:104.8115 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0025 | logitBiasMean:-34.1460 | logitBiasStd:11.9647 | logitBiasMax:-13.1773 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9675 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8973 | n_weightMin:-4.7365 | n_weightMax:4.8470 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5988 | n_weightNormMin:21.6414 | n_weightNormMax:41.2523 | n_biasesMean:-1.0604 | n_biasesStd:0.7958 | n_biasesMin:-3.8480 | n_biasesMax:1.9580 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8886 | sampledTokens:4.0000 | windowWeightsW32:4.97335 (0.98), W28:1.14259 (0.02), W24:-1.92433 (0.00), W20:-2.02519 (0.00), W16:-3.45393 (0.00), W12:-4.73970 (0.00), W8:-5.95887 (0.00), W4:-9.16215 (0.00), W2:-10.81805 (0.00) | topTokens[(',', 1203), ('.', 641), ('Ġi', 546), ('s', 540), ('Ġand', 537), ('Ġto', 524), ('Ġit', 495), ('Ġthe', 476), ('Ġof', 433), ('Ġa', 420)] | cheekyAvg: 9.98261375427246 | perfectTokens: 48 / 6400 → 0.75% |  | remainingTokens: 679645 (99.91%) | TUTOR.py 100
2025-04-22 18:38:08 | 700 | LR0.00035 | scheduledSamplingRate:0.0024 | repetitionPenalty:1.2976 | AvgLoss:9.2536 | loss:9.9302 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0003 | latestLossDelta:1.0545 | memoryLength:5.0072 | embedNormMean:14.2941 | embedNormStd:10.0790 | embedNormMax:103.7246 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0007 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5153 | logitWeightNormMax:104.8115 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0022 | logitBiasMean:-34.1460 | logitBiasStd:11.9647 | logitBiasMax:-13.1773 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9675 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8973 | n_weightMin:-4.7365 | n_weightMax:4.8470 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5988 | n_weightNormMin:21.6412 | n_weightNormMax:41.2520 | n_biasesMean:-1.0604 | n_biasesStd:0.7958 | n_biasesMin:-3.8480 | n_biasesMax:1.9580 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8886 | sampledTokens:8.0000 | windowWeightsW32:4.97339 (0.98), W28:1.14256 (0.02), W24:-1.92437 (0.00), W20:-2.02522 (0.00), W16:-3.45396 (0.00), W12:-4.73971 (0.00), W8:-5.95889 (0.00), W4:-9.16217 (0.00), W2:-10.81806 (0.00) | topTokens[(',', 1482), ('s', 1019), ('.', 985), ('Ġi', 645), ('Ġto', 587), ('Ġand', 571), ('Ġthe', 534), ('Ġit', 517), ('Ġa', 498), ('!', 477)] | cheekyAvg: 9.149822902679443 | perfectTokens: 57 / 6400 → 0.89% |  | remainingTokens: 679545 (99.90%) | TUTOR.py 100
2025-04-22 18:38:41 | 800 | LR0.00035 | scheduledSamplingRate:0.0027 | repetitionPenalty:1.2972 | AvgLoss:10.8876 | loss:12.0052 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:0.8149 | memoryLength:5.0074 | embedNormMean:14.2941 | embedNormStd:10.0790 | embedNormMax:103.7246 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5153 | logitWeightNormMax:104.8115 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0019 | logitBiasMean:-34.1460 | logitBiasStd:11.9647 | logitBiasMax:-13.1773 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9675 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8973 | n_weightMin:-4.7365 | n_weightMax:4.8470 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5989 | n_weightNormMin:21.6410 | n_weightNormMax:41.2513 | n_biasesMean:-1.0604 | n_biasesStd:0.7958 | n_biasesMin:-3.8480 | n_biasesMax:1.9580 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8886 | sampledTokens:9.0000 | windowWeightsW32:4.97340 (0.98), W28:1.14255 (0.02), W24:-1.92439 (0.00), W20:-2.02525 (0.00), W16:-3.45398 (0.00), W12:-4.73972 (0.00), W8:-5.95889 (0.00), W4:-9.16216 (0.00), W2:-10.81805 (0.00) | topTokens[(',', 1666), ('s', 1404), ('.', 1153), ('Ġi', 770), ('Ġthe', 685), ('Ġto', 672), ('Ġyou', 625), ('Ġand', 621), ('Ġit', 559), ('Ġa', 550)] | cheekyAvg: 11.288734817504883 | perfectTokens: 53 / 6400 → 0.83% |  | remainingTokens: 679445 (99.88%) | TUTOR.py 100
--- 2025-04-22 18:38:53 --- 
[babyllm] right, last time i got to step 15446... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 15446! what am i learning today?
[charis]2025-04-22 18:42:43 | 500 | LR0.00035 | loss:10.7253 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0016 | repetitionPenalty:1.2980 | AvgLoss:11.0517 | temperature:0.8002 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:0.2428 | memoryLength:4.9970 | embedNormMean:14.2941 | embedNormStd:10.0790 | embedNormMax:103.7239 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:3.2624 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5153 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:8.2286 | logitBiasMean:-34.1463 | logitBiasStd:11.9647 | logitBiasMax:-13.1776 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8973 | n_weightMin:-4.7363 | n_weightMax:4.8469 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5988 | n_weightNormMin:21.6406 | n_weightNormMax:41.2510 | n_biasesMean:-1.0604 | n_biasesStd:0.7958 | n_biasesMin:-3.8480 | n_biasesMax:1.9580 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8886 | sampledTokens:15.0000 | windowWeightsW32:4.97331 (0.98), W28:1.14262 (0.02), W24:-1.92431 (0.00), W20:-2.02518 (0.00), W16:-3.45401 (0.00), W12:-4.73976 (0.00), W8:-5.95891 (0.00), W4:-9.16220 (0.00), W2:-10.81805 (0.00) | topTokens[(',', 1289), ('.', 821), ('s', 810), ('Ġa', 753), ('Ġyou', 581), ('!', 565), ('Ġthe', 555), ('Ġit', 463), ('Ġto', 414), ('Ġand', 328)] | cheekyAvg: 10.486424739544209 | perfectTokens: 216 / 32000 → 0.68% |  | remainingTokens: 678937 (99.93%) | TUTOR.py 500
2025-04-22 18:45:31 | 1000 | LR0.00035 | scheduledSamplingRate:0.0030 | repetitionPenalty:1.2961 | AvgLoss:10.6739 | loss:9.9721 | temperature:0.8002 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:-0.4045 | memoryLength:4.9966 | embedNormMean:14.2941 | embedNormStd:10.0791 | embedNormMax:103.7239 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0007 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5152 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0028 | logitBiasMean:-34.1463 | logitBiasStd:11.9645 | logitBiasMax:-13.1781 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7363 | n_weightMax:4.8468 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5989 | n_weightNormMin:21.6401 | n_weightNormMax:41.2492 | n_biasesMean:-1.0604 | n_biasesStd:0.7958 | n_biasesMin:-3.8481 | n_biasesMax:1.9582 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8886 | sampledTokens:27.0000 | windowWeightsW32:4.97334 (0.98), W28:1.14260 (0.02), W24:-1.92437 (0.00), W20:-2.02519 (0.00), W16:-3.45400 (0.00), W12:-4.73975 (0.00), W8:-5.95890 (0.00), W4:-9.16217 (0.00), W2:-10.81803 (0.00) | topTokens[(',', 2513), ('.', 1456), ('Ġi', 1233), ('Ġa', 1136), ('s', 1050), ('Ġthe', 982), ('Ġyou', 908), ('!', 897), ('Ġand', 887), ('Ġit', 845)] | cheekyAvg: 10.8098295211792 | perfectTokens: 193 / 32000 → 0.60% |  | remainingTokens: 678437 (99.85%) | TUTOR.py 500
2025-04-22 18:48:15 | 1500 | LR0.00035 | scheduledSamplingRate:0.0048 | repetitionPenalty:1.2943 | AvgLoss:10.6423 | loss:8.9376 | temperature:0.8003 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:-1.5499 | memoryLength:4.9986 | embedNormMean:14.2943 | embedNormStd:10.0791 | embedNormMax:103.7237 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5152 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0022 | logitBiasMean:-34.1463 | logitBiasStd:11.9645 | logitBiasMax:-13.1782 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7362 | n_weightMax:4.8469 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5989 | n_weightNormMin:21.6393 | n_weightNormMax:41.2500 | n_biasesMean:-1.0604 | n_biasesStd:0.7958 | n_biasesMin:-3.8481 | n_biasesMax:1.9582 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8886 | sampledTokens:69.0000 | windowWeightsW32:4.97325 (0.98), W28:1.14268 (0.02), W24:-1.92425 (0.00), W20:-2.02506 (0.00), W16:-3.45390 (0.00), W12:-4.73969 (0.00), W8:-5.95888 (0.00), W4:-9.16218 (0.00), W2:-10.81806 (0.00) | topTokens[(',', 3922), ('.', 2539), ('Ġi', 2075), ('Ġa', 1679), ('s', 1491), ('Ġyou', 1420), ('Ġto', 1356), ('!', 1352), ('Ġthe', 1348), ('Ġand', 1343)] | cheekyAvg: 10.573271751403809 | perfectTokens: 237 / 32000 → 0.74% |  | remainingTokens: 677937 (99.78%) | TUTOR.py 500
2025-04-22 18:51:02 | 2000 | LR0.00035 | sampledTokens:88.0000 | scheduledSamplingRate:0.0065 | repetitionPenalty:1.2929 | AvgLoss:10.3040 | loss:12.2208 | temperature:0.8003 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:1.4733 | memoryLength:4.9956 | embedNormMean:14.2943 | embedNormStd:10.0791 | embedNormMax:103.7237 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5151 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0022 | logitBiasMean:-34.1463 | logitBiasStd:11.9645 | logitBiasMax:-13.1782 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9675 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7362 | n_weightMax:4.8469 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5993 | n_weightNormMin:21.6390 | n_weightNormMax:41.2494 | n_biasesMean:-1.0605 | n_biasesStd:0.7958 | n_biasesMin:-3.8482 | n_biasesMax:1.9582 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8886 | windowWeightsW32:4.97332 (0.98), W28:1.14262 (0.02), W24:-1.92432 (0.00), W20:-2.02516 (0.00), W16:-3.45403 (0.00), W12:-4.73979 (0.00), W8:-5.95895 (0.00), W4:-9.16223 (0.00), W2:-10.81810 (0.00) | topTokens[(',', 5291), ('.', 3155), ('Ġi', 2729), ('Ġa', 2416), ('Ġand', 2008), ('Ġthe', 2003), ('Ġto', 1993), ('!', 1969), ('Ġit', 1942), ('Ġyou', 1872)] | cheekyAvg: 10.375354270935059 | perfectTokens: 230 / 32000 → 0.72% |  | remainingTokens: 677437 (99.71%) | TUTOR.py 500
2025-04-22 18:53:46 | 2500 | LR0.00035 | scheduledSamplingRate:0.0082 | repetitionPenalty:1.2916 | AvgLoss:9.9767 | loss:14.0637 | temperature:0.8006 | lR:0.0003 | gradientClip:0.9996 | latestLossDelta:3.5418 | memoryLength:4.9940 | embedNormMean:14.2943 | embedNormStd:10.0791 | embedNormMax:103.7236 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0007 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5151 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0025 | logitBiasMean:-34.1463 | logitBiasStd:11.9645 | logitBiasMax:-13.1784 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7363 | n_weightMax:4.8467 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5993 | n_weightNormMin:21.6385 | n_weightNormMax:41.2488 | n_biasesMean:-1.0605 | n_biasesStd:0.7958 | n_biasesMin:-3.8482 | n_biasesMax:1.9583 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5519 | INN_cerebellumStd:4.8886 | sampledTokens:130.0000 | windowWeightsW32:4.97328 (0.98), W28:1.14266 (0.02), W24:-1.92428 (0.00), W20:-2.02515 (0.00), W16:-3.45399 (0.00), W12:-4.73975 (0.00), W8:-5.95897 (0.00), W4:-9.16231 (0.00), W2:-10.81814 (0.00) | topTokens[(',', 6639), ('.', 3875), ('Ġi', 3733), ('Ġa', 3074), ('Ġthe', 2585), ('Ġto', 2477), ('Ġand', 2462), ('!', 2417), ('Ġit', 2372), ('Ġyou', 2352)] | cheekyAvg: 9.995554866790771 | perfectTokens: 254 / 32000 → 0.79% |  | remainingTokens: 676937 (99.63%) | TUTOR.py 500
--- 2025-04-22 18:56:01 --- 
[babyllm] right, last time i got to step 18255... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 18255! what am i learning today?
[charis]2025-04-22 18:59:50 | 500 | LR0.00035 | loss:9.8770 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0016 | repetitionPenalty:1.2984 | AvgLoss:9.4944 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:1.1684 | memoryLength:10.0000 | embedNormMean:14.2944 | embedNormStd:10.0791 | embedNormMax:103.7236 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:3.2613 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5151 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:8.2284 | logitBiasMean:-34.1463 | logitBiasStd:11.9645 | logitBiasMax:-13.1786 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7366 | n_weightMax:4.8468 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5994 | n_weightNormMin:21.6358 | n_weightNormMax:41.2497 | n_biasesMean:-1.0605 | n_biasesStd:0.7958 | n_biasesMin:-3.8481 | n_biasesMax:1.9584 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8886 | sampledTokens:20.0000 | windowWeightsW28:4.97323 (0.98), W32:1.14267 (0.02), W24:-1.92421 (0.00), W20:-2.02503 (0.00), W16:-3.45386 (0.00), W12:-4.73955 (0.00), W8:-5.95881 (0.00), W4:-9.16229 (0.00), W2:-10.81814 (0.00) | topTokens[(',', 944), ('b', 778), ('Ġi', 731), ('ed', 703), ('Ġam', 464), ('s', 459), ('!', 454), ('Ġto', 418), ('Ġthe', 356), ('ing', 356)] | cheekyAvg: 8.908656395398653 | perfectTokens: 234 / 32000 → 0.73% |  | remainingTokens: 676128 (99.93%) | TUTOR.py 500
2025-04-22 19:02:39 | 1000 | LR0.00035 | scheduledSamplingRate:0.0033 | repetitionPenalty:1.2964 | AvgLoss:9.7684 | loss:7.9526 | temperature:0.8003 | lR:0.0003 | gradientClip:0.9996 | latestLossDelta:-0.9554 | memoryLength:9.9976 | embedNormMean:14.2944 | embedNormStd:10.0791 | embedNormMax:103.7230 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5150 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0025 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1787 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7367 | n_weightMax:4.8469 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5994 | n_weightNormMin:21.6350 | n_weightNormMax:41.2493 | n_biasesMean:-1.0605 | n_biasesStd:0.7958 | n_biasesMin:-3.8480 | n_biasesMax:1.9585 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8886 | sampledTokens:43.0000 | windowWeightsW28:4.97312 (0.98), W32:1.14280 (0.02), W24:-1.92420 (0.00), W20:-2.02505 (0.00), W16:-3.45388 (0.00), W12:-4.73956 (0.00), W8:-5.95890 (0.00), W4:-9.16240 (0.00), W2:-10.81815 (0.00) | topTokens[(',', 2080), ('Ġi', 1249), ('s', 1178), ('ed', 1114), ('Ġto', 956), ('!', 917), ('b', 900), ('Ġyou', 884), ('.', 759), ('Ġit', 735)] | cheekyAvg: 9.514579067230224 | perfectTokens: 218 / 32000 → 0.68% |  | remainingTokens: 675628 (99.85%) | TUTOR.py 500
2025-04-22 19:05:24 | 1500 | LR0.00035 | scheduledSamplingRate:0.0049 | repetitionPenalty:1.2951 | AvgLoss:9.2797 | loss:9.5670 | temperature:0.8002 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:1.5561 | memoryLength:9.9964 | embedNormMean:14.2944 | embedNormStd:10.0791 | embedNormMax:103.7230 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5150 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0020 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1790 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7365 | n_weightMax:4.8468 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5995 | n_weightNormMin:21.6346 | n_weightNormMax:41.2494 | n_biasesMean:-1.0605 | n_biasesStd:0.7958 | n_biasesMin:-3.8480 | n_biasesMax:1.9584 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8886 | sampledTokens:62.0000 | windowWeightsW28:4.97306 (0.98), W32:1.14287 (0.02), W24:-1.92426 (0.00), W20:-2.02511 (0.00), W16:-3.45388 (0.00), W12:-4.73957 (0.00), W8:-5.95889 (0.00), W4:-9.16242 (0.00), W2:-10.81815 (0.00) | topTokens[(',', 3472), ('Ġi', 2145), ('s', 1532), ('Ġto', 1454), ('!', 1398), ('.', 1375), ('Ġyou', 1253), ('ed', 1251), ('Ġthe', 1203), ('Ġand', 1179)] | cheekyAvg: 9.294630317687988 | perfectTokens: 289 / 32000 → 0.90% |  | remainingTokens: 675128 (99.78%) | TUTOR.py 500
2025-04-22 19:08:12 | 2000 | LR0.00035 | sampledTokens:102.0000 | scheduledSamplingRate:0.0065 | repetitionPenalty:1.2938 | AvgLoss:10.1772 | loss:8.2490 | temperature:0.8002 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:-1.6126 | memoryLength:9.9982 | embedNormMean:14.2944 | embedNormStd:10.0791 | embedNormMax:103.7229 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5150 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0023 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1791 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7364 | n_weightMax:4.8467 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5996 | n_weightNormMin:21.6341 | n_weightNormMax:41.2493 | n_biasesMean:-1.0605 | n_biasesStd:0.7958 | n_biasesMin:-3.8479 | n_biasesMax:1.9584 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8886 | windowWeightsW28:4.97292 (0.98), W32:1.14301 (0.02), W24:-1.92426 (0.00), W20:-2.02503 (0.00), W16:-3.45379 (0.00), W12:-4.73949 (0.00), W8:-5.95883 (0.00), W4:-9.16239 (0.00), W2:-10.81811 (0.00) | topTokens[(',', 4987), ('Ġi', 2747), ('.', 2366), ('Ġto', 2052), ('s', 1877), ('!', 1841), ('Ġthe', 1740), ('Ġyou', 1699), ('Ġand', 1584), ('ed', 1526)] | cheekyAvg: 10.017388954162598 | perfectTokens: 244 / 32000 → 0.76% |  | remainingTokens: 674628 (99.70%) | TUTOR.py 500
2025-04-22 19:10:57 | 2500 | LR0.00035 | scheduledSamplingRate:0.0081 | repetitionPenalty:1.2918 | AvgLoss:9.3445 | loss:10.4602 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:0.8625 | memoryLength:9.9964 | embedNormMean:14.2944 | embedNormStd:10.0791 | embedNormMax:103.7229 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5149 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0023 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1792 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7364 | n_weightMax:4.8465 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5996 | n_weightNormMin:21.6337 | n_weightNormMax:41.2494 | n_biasesMean:-1.0605 | n_biasesStd:0.7958 | n_biasesMin:-3.8477 | n_biasesMax:1.9584 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8885 | sampledTokens:117.0000 | windowWeightsW28:4.97287 (0.98), W32:1.14307 (0.02), W24:-1.92426 (0.00), W20:-2.02499 (0.00), W16:-3.45378 (0.00), W12:-4.73941 (0.00), W8:-5.95881 (0.00), W4:-9.16232 (0.00), W2:-10.81806 (0.00) | topTokens[(',', 6498), ('Ġi', 3415), ('.', 2888), ('Ġto', 2560), ('Ġyou', 2314), ('Ġthe', 2193), ('s', 2158), ('Ġand', 2136), ('!', 2041), ('Ġa', 2019)] | cheekyAvg: 9.333372097015381 | perfectTokens: 258 / 32000 → 0.81% |  | remainingTokens: 674128 (99.63%) | TUTOR.py 500
2025-04-22 19:13:50 | 3000 | LR0.00035 | scheduledSamplingRate:0.0097 | repetitionPenalty:1.2900 | AvgLoss:9.5193 | loss:9.4752 | temperature:0.7994 | lR:0.0003 | gradientClip:0.9995 | latestLossDelta:1.0364 | memoryLength:9.9962 | embedNormMean:14.2944 | embedNormStd:10.0791 | embedNormMax:103.7229 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5149 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0022 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1792 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8979 | n_weightMin:-4.7364 | n_weightMax:4.8465 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5996 | n_weightNormMin:21.6331 | n_weightNormMax:41.2490 | n_biasesMean:-1.0605 | n_biasesStd:0.7958 | n_biasesMin:-3.8476 | n_biasesMax:1.9584 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8885 | sampledTokens:146.0000 | windowWeightsW28:4.97287 (0.98), W32:1.14309 (0.02), W24:-1.92424 (0.00), W20:-2.02495 (0.00), W16:-3.45375 (0.00), W12:-4.73941 (0.00), W8:-5.95881 (0.00), W4:-9.16231 (0.00), W2:-10.81803 (0.00) | topTokens[(',', 8008), ('Ġi', 4153), ('.', 3432), ('Ġto', 3144), ('Ġthe', 2698), ('Ġyou', 2682), ('s', 2562), ('!', 2547), ('Ġand', 2439), ('Ġa', 2281)] | cheekyAvg: 9.459802589416505 | perfectTokens: 279 / 32000 → 0.87% |  | remainingTokens: 673628 (99.56%) | TUTOR.py 500
2025-04-22 19:16:35 | 3500 | LR0.00035 | scheduledSamplingRate:0.0113 | repetitionPenalty:1.2885 | AvgLoss:10.7533 | loss:8.4894 | temperature:0.7992 | lR:0.0003 | gradientClip:0.9993 | latestLossDelta:-1.7523 | memoryLength:9.9946 | embedNormMean:14.2945 | embedNormStd:10.0791 | embedNormMax:103.7229 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5149 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0023 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1794 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7365 | n_weightMax:4.8465 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5997 | n_weightNormMin:21.6323 | n_weightNormMax:41.2489 | n_biasesMean:-1.0605 | n_biasesStd:0.7958 | n_biasesMin:-3.8475 | n_biasesMax:1.9584 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5517 | INN_cerebellumStd:4.8885 | sampledTokens:178.0000 | windowWeightsW28:4.97289 (0.98), W32:1.14308 (0.02), W24:-1.92435 (0.00), W20:-2.02502 (0.00), W16:-3.45376 (0.00), W12:-4.73947 (0.00), W8:-5.95881 (0.00), W4:-9.16229 (0.00), W2:-10.81803 (0.00) | topTokens[(',', 9410), ('Ġi', 4763), ('.', 4032), ('Ġto', 3548), ('Ġthe', 3434), ('Ġyou', 3125), ('Ġand', 3022), ('!', 2965), ('s', 2911), ('Ġa', 2612)] | cheekyAvg: 10.724156951904297 | perfectTokens: 209 / 32000 → 0.65% |  | remainingTokens: 673128 (99.48%) | TUTOR.py 500
2025-04-22 19:19:23 | 4000 | LR0.00035 | sampledTokens:202.0000 | scheduledSamplingRate:0.0128 | repetitionPenalty:1.2870 | AvgLoss:10.0535 | loss:8.1849 | temperature:0.7988 | lR:0.0003 | gradientClip:0.9996 | latestLossDelta:-1.7471 | memoryLength:9.9948 | embedNormMean:14.2945 | embedNormStd:10.0792 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5149 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0020 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1795 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7365 | n_weightMax:4.8465 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5997 | n_weightNormMin:21.6308 | n_weightNormMax:41.2489 | n_biasesMean:-1.0605 | n_biasesStd:0.7958 | n_biasesMin:-3.8474 | n_biasesMax:1.9585 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8885 | windowWeightsW28:4.97284 (0.98), W32:1.14313 (0.02), W24:-1.92434 (0.00), W20:-2.02501 (0.00), W16:-3.45378 (0.00), W12:-4.73950 (0.00), W8:-5.95886 (0.00), W4:-9.16234 (0.00), W2:-10.81806 (0.00) | topTokens[(',', 10763), ('Ġi', 5697), ('.', 4540), ('Ġthe', 4041), ('Ġto', 3885), ('Ġand', 3591), ('Ġyou', 3522), ('!', 3387), ('s', 3192), ('Ġa', 3095)] | cheekyAvg: 9.893251838684082 | perfectTokens: 282 / 32000 → 0.88% |  | remainingTokens: 672628 (99.41%) | TUTOR.py 500
2025-04-22 19:22:08 | 4500 | LR0.00035 | sampledTokens:172.0000 | scheduledSamplingRate:0.0141 | repetitionPenalty:1.2854 | AvgLoss:10.1599 | loss:8.9468 | temperature:0.7987 | lR:0.0003 | gradientClip:0.9996 | latestLossDelta:-0.8310 | memoryLength:9.9982 | embedNormMean:14.2945 | embedNormStd:10.0792 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5149 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0022 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1797 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7364 | n_weightMax:4.8465 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5997 | n_weightNormMin:21.6299 | n_weightNormMax:41.2481 | n_biasesMean:-1.0605 | n_biasesStd:0.7958 | n_biasesMin:-3.8473 | n_biasesMax:1.9586 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8885 | windowWeightsW28:4.97276 (0.98), W32:1.14322 (0.02), W24:-1.92433 (0.00), W20:-2.02501 (0.00), W16:-3.45377 (0.00), W12:-4.73947 (0.00), W8:-5.95883 (0.00), W4:-9.16230 (0.00), W2:-10.81804 (0.00) | topTokens[(',', 12297), ('Ġi', 6503), ('.', 5127), ('Ġthe', 4625), ('Ġto', 4360), ('Ġyou', 4168), ('Ġand', 3991), ('!', 3910), ('s', 3548), ('Ġa', 3437)] | cheekyAvg: 9.842261161804199 | perfectTokens: 256 / 32000 → 0.80% |  | remainingTokens: 672128 (99.33%) | TUTOR.py 500
2025-04-22 19:24:56 | 5000 | LR0.00035 | scheduledSamplingRate:0.0158 | repetitionPenalty:1.2838 | AvgLoss:10.8237 | loss:12.2130 | temperature:0.7991 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:1.4953 | memoryLength:9.9996 | embedNormMean:14.2945 | embedNormStd:10.0793 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5149 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0022 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1798 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7364 | n_weightMax:4.8466 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5998 | n_weightNormMin:21.6289 | n_weightNormMax:41.2481 | n_biasesMean:-1.0605 | n_biasesStd:0.7958 | n_biasesMin:-3.8473 | n_biasesMax:1.9585 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8885 | sampledTokens:200.0000 | windowWeightsW28:4.97274 (0.98), W32:1.14325 (0.02), W24:-1.92436 (0.00), W20:-2.02506 (0.00), W16:-3.45382 (0.00), W12:-4.73948 (0.00), W8:-5.95885 (0.00), W4:-9.16232 (0.00), W2:-10.81802 (0.00) | topTokens[(',', 13746), ('Ġi', 7178), ('.', 5907), ('Ġthe', 5087), ('Ġyou', 4790), ('Ġto', 4742), ('Ġand', 4411), ('!', 4294), ('s', 3876), ('Ġa', 3744)] | cheekyAvg: 10.814447441101073 | perfectTokens: 238 / 32000 → 0.74% |  | remainingTokens: 671628 (99.26%) | TUTOR.py 500
2025-04-22 19:27:41 | 5500 | LR0.00035 | scheduledSamplingRate:0.0173 | repetitionPenalty:1.2826 | AvgLoss:9.9452 | loss:9.1013 | temperature:0.7991 | lR:0.0003 | gradientClip:0.9994 | latestLossDelta:-1.1516 | memoryLength:10.0028 | embedNormMean:14.2946 | embedNormStd:10.0793 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5149 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0021 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1800 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7363 | n_weightMax:4.8466 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5998 | n_weightNormMin:21.6284 | n_weightNormMax:41.2480 | n_biasesMean:-1.0605 | n_biasesStd:0.7959 | n_biasesMin:-3.8474 | n_biasesMax:1.9585 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8885 | sampledTokens:263.0000 | windowWeightsW28:4.97266 (0.98), W32:1.14335 (0.02), W24:-1.92440 (0.00), W20:-2.02508 (0.00), W16:-3.45385 (0.00), W12:-4.73950 (0.00), W8:-5.95883 (0.00), W4:-9.16231 (0.00), W2:-10.81803 (0.00) | topTokens[(',', 15596), ('Ġi', 7671), ('.', 6223), ('Ġthe', 5623), ('Ġyou', 5251), ('Ġto', 5164), ('Ġand', 4792), ('!', 4667), ('Ġa', 4210), ('s', 4140)] | cheekyAvg: 9.615744667053223 | perfectTokens: 232 / 32000 → 0.72% |  | remainingTokens: 671128 (99.19%) | TUTOR.py 500
2025-04-22 19:30:31 | 6000 | LR0.00035 | scheduledSamplingRate:0.0193 | repetitionPenalty:1.2812 | AvgLoss:10.6311 | loss:10.2410 | temperature:0.7991 | lR:0.0003 | gradientClip:0.9992 | latestLossDelta:-0.3650 | memoryLength:10.0016 | embedNormMean:14.2948 | embedNormStd:10.0793 | embedNormMax:103.7229 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5148 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0019 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1801 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7363 | n_weightMax:4.8466 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.5999 | n_weightNormMin:21.6278 | n_weightNormMax:41.2479 | n_biasesMean:-1.0605 | n_biasesStd:0.7959 | n_biasesMin:-3.8474 | n_biasesMax:1.9586 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8885 | sampledTokens:297.0000 | windowWeightsW28:4.97263 (0.98), W32:1.14340 (0.02), W24:-1.92443 (0.00), W20:-2.02508 (0.00), W16:-3.45376 (0.00), W12:-4.73947 (0.00), W8:-5.95882 (0.00), W4:-9.16228 (0.00), W2:-10.81801 (0.00) | topTokens[(',', 17431), ('Ġi', 8241), ('.', 6768), ('Ġthe', 6095), ('Ġyou', 5584), ('Ġto', 5442), ('Ġand', 5310), ('!', 5131), ('Ġa', 4570), ('s', 4402)] | cheekyAvg: 10.362144393920898 | perfectTokens: 266 / 32000 → 0.83% |  | remainingTokens: 670628 (99.11%) | TUTOR.py 500
2025-04-22 19:33:18 | 6500 | LR0.00035 | scheduledSamplingRate:0.0210 | repetitionPenalty:1.2795 | AvgLoss:10.5397 | loss:11.3669 | temperature:0.7992 | lR:0.0003 | gradientClip:0.9991 | latestLossDelta:1.5720 | memoryLength:10.0022 | embedNormMean:14.2948 | embedNormStd:10.0793 | embedNormMax:103.7229 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5148 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0022 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1802 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7363 | n_weightMax:4.8465 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6000 | n_weightNormMin:21.6269 | n_weightNormMax:41.2469 | n_biasesMean:-1.0605 | n_biasesStd:0.7959 | n_biasesMin:-3.8474 | n_biasesMax:1.9586 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8885 | sampledTokens:343.0000 | windowWeightsW28:4.97256 (0.98), W32:1.14346 (0.02), W24:-1.92443 (0.00), W20:-2.02505 (0.00), W16:-3.45376 (0.00), W12:-4.73947 (0.00), W8:-5.95878 (0.00), W4:-9.16231 (0.00), W2:-10.81803 (0.00) | topTokens[(',', 19007), ('Ġi', 8967), ('.', 7109), ('Ġthe', 6627), ('Ġyou', 6136), ('Ġand', 5865), ('Ġto', 5761), ('!', 5470), ('Ġa', 4932), ('s', 4826)] | cheekyAvg: 10.461942653656006 | perfectTokens: 234 / 32000 → 0.73% |  | remainingTokens: 670128 (99.04%) | TUTOR.py 500
2025-04-22 19:36:07 | 7000 | LR0.00035 | scheduledSamplingRate:0.0223 | repetitionPenalty:1.2779 | AvgLoss:9.4983 | loss:8.6006 | temperature:0.7992 | lR:0.0003 | gradientClip:0.9991 | latestLossDelta:-1.6641 | memoryLength:10.0010 | embedNormMean:14.2948 | embedNormStd:10.0794 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5148 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0019 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1804 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7364 | n_weightMax:4.8466 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6003 | n_weightNormMin:21.6251 | n_weightNormMax:41.2461 | n_biasesMean:-1.0605 | n_biasesStd:0.7959 | n_biasesMin:-3.8474 | n_biasesMax:1.9585 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8885 | sampledTokens:341.0000 | windowWeightsW28:4.97241 (0.98), W32:1.14361 (0.02), W24:-1.92456 (0.00), W20:-2.02509 (0.00), W16:-3.45374 (0.00), W12:-4.73944 (0.00), W8:-5.95875 (0.00), W4:-9.16227 (0.00), W2:-10.81801 (0.00) | topTokens[(',', 20449), ('Ġi', 9496), ('.', 7582), ('Ġthe', 7128), ('Ġyou', 6653), ('Ġand', 6231), ('Ġto', 6089), ('!', 5906), ('Ġa', 5485), ('s', 5044)] | cheekyAvg: 9.26091157913208 | perfectTokens: 243 / 32000 → 0.76% |  | remainingTokens: 669628 (98.97%) | TUTOR.py 500
2025-04-22 19:38:53 | 7500 | LR0.00035 | scheduledSamplingRate:0.0238 | repetitionPenalty:1.2760 | AvgLoss:8.9600 | loss:11.9259 | temperature:0.7993 | lR:0.0003 | gradientClip:0.9990 | latestLossDelta:3.1951 | memoryLength:10.0060 | embedNormMean:14.2948 | embedNormStd:10.0794 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5148 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0017 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1806 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7363 | n_weightMax:4.8468 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6003 | n_weightNormMin:21.6236 | n_weightNormMax:41.2465 | n_biasesMean:-1.0605 | n_biasesStd:0.7959 | n_biasesMin:-3.8475 | n_biasesMax:1.9584 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8884 | sampledTokens:328.0000 | windowWeightsW28:4.97238 (0.98), W32:1.14364 (0.02), W24:-1.92454 (0.00), W20:-2.02503 (0.00), W16:-3.45368 (0.00), W12:-4.73934 (0.00), W8:-5.95868 (0.00), W4:-9.16223 (0.00), W2:-10.81801 (0.00) | topTokens[(',', 22126), ('Ġi', 9976), ('.', 8067), ('Ġthe', 7506), ('Ġyou', 7239), ('Ġand', 6822), ('Ġto', 6704), ('!', 6272), ('Ġa', 5767), ('s', 5241)] | cheekyAvg: 8.950702514648437 | perfectTokens: 284 / 32000 → 0.89% |  | remainingTokens: 669128 (98.89%) | TUTOR.py 500
2025-04-22 19:41:40 | 8000 | LR0.00035 | sampledTokens:389.0000 | scheduledSamplingRate:0.0252 | repetitionPenalty:1.2741 | AvgLoss:10.3399 | loss:9.8803 | temperature:0.7994 | lR:0.0003 | gradientClip:0.9995 | latestLossDelta:-0.2081 | memoryLength:10.0006 | embedNormMean:14.2949 | embedNormStd:10.0794 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5148 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0022 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1807 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7363 | n_weightMax:4.8468 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6004 | n_weightNormMin:21.6241 | n_weightNormMax:41.2450 | n_biasesMean:-1.0606 | n_biasesStd:0.7959 | n_biasesMin:-3.8475 | n_biasesMax:1.9583 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5517 | INN_cerebellumStd:4.8884 | windowWeightsW28:4.97236 (0.98), W32:1.14366 (0.02), W24:-1.92459 (0.00), W20:-2.02506 (0.00), W16:-3.45371 (0.00), W12:-4.73938 (0.00), W8:-5.95867 (0.00), W4:-9.16222 (0.00), W2:-10.81799 (0.00) | topTokens[(',', 23163), ('Ġi', 10701), ('.', 8467), ('Ġyou', 7944), ('Ġthe', 7943), ('Ġand', 7328), ('Ġto', 7085), ('!', 6783), ('Ġa', 6296), ('s', 5673)] | cheekyAvg: 10.21756435394287 | perfectTokens: 244 / 32000 → 0.76% |  | remainingTokens: 668628 (98.82%) | TUTOR.py 500
--- 2025-04-22 19:44:26 --- 
[babyllm] right, last time i got to step 26678... want to restart from there?
[charis] 28000
[babyllm] damn that's specific! heading to step 28000... what am i learning today?
[charis]2025-04-22 19:48:14 | 500 | LR0.00035 | loss:10.9409 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0017 | repetitionPenalty:1.2983 | AvgLoss:9.5344 | temperature:0.7998 | lR:0.0003 | gradientClip:1.0004 | latestLossDelta:0.3365 | memoryLength:9.9988 | embedNormMean:14.2949 | embedNormStd:10.0794 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:3.2614 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5147 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:8.2283 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1811 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7362 | n_weightMax:4.8468 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6005 | n_weightNormMin:21.6234 | n_weightNormMax:41.2443 | n_biasesMean:-1.0606 | n_biasesStd:0.7959 | n_biasesMin:-3.8475 | n_biasesMax:1.9582 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8884 | sampledTokens:18.0000 | windowWeightsW24:4.97216 (0.98), W28:1.14389 (0.02), W32:-1.92459 (0.00), W20:-2.02508 (0.00), W16:-3.45378 (0.00), W12:-4.73941 (0.00), W8:-5.95872 (0.00), W4:-9.16229 (0.00), W2:-10.81803 (0.00) | topTokens[(',', 1989), ('.', 653), ('Ġyou', 601), ('Ġi', 562), ('Ġthe', 479), ('Ġit', 465), ('Ġto', 435), ('Ġa', 400), ('!', 382), ('Ġand', 346)] | cheekyAvg: 9.129083083226131 | perfectTokens: 302 / 32000 → 0.94% |  | remainingTokens: 666383 (99.93%) | TUTOR.py 500
2025-04-22 19:51:02 | 1000 | LR0.00035 | scheduledSamplingRate:0.0033 | repetitionPenalty:1.2966 | AvgLoss:10.6774 | loss:11.4467 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0008 | latestLossDelta:1.7588 | memoryLength:9.9964 | embedNormMean:14.2949 | embedNormStd:10.0794 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5147 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0021 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1812 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7362 | n_weightMax:4.8467 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6005 | n_weightNormMin:21.6239 | n_weightNormMax:41.2443 | n_biasesMean:-1.0606 | n_biasesStd:0.7959 | n_biasesMin:-3.8476 | n_biasesMax:1.9581 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5518 | INN_cerebellumStd:4.8884 | sampledTokens:37.0000 | windowWeightsW24:4.97205 (0.98), W28:1.14400 (0.02), W32:-1.92449 (0.00), W20:-2.02511 (0.00), W16:-3.45379 (0.00), W12:-4.73941 (0.00), W8:-5.95862 (0.00), W4:-9.16224 (0.00), W2:-10.81800 (0.00) | topTokens[(',', 3027), ('Ġi', 1429), ('.', 1293), ('Ġthe', 1086), ('Ġyou', 1070), ('Ġit', 954), ('Ġto', 920), ('Ġand', 758), ('Ġa', 694), ('!', 664)] | cheekyAvg: 10.492929382324219 | perfectTokens: 228 / 32000 → 0.71% |  | remainingTokens: 665883 (99.85%) | TUTOR.py 500
2025-04-22 19:53:47 | 1500 | LR0.00035 | scheduledSamplingRate:0.0049 | repetitionPenalty:1.2953 | AvgLoss:10.7508 | loss:9.7846 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0009 | latestLossDelta:1.0405 | memoryLength:9.9962 | embedNormMean:14.2949 | embedNormStd:10.0795 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5146 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0021 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1812 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7363 | n_weightMax:4.8467 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6006 | n_weightNormMin:21.6244 | n_weightNormMax:41.2435 | n_biasesMean:-1.0606 | n_biasesStd:0.7959 | n_biasesMin:-3.8478 | n_biasesMax:1.9581 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5517 | INN_cerebellumStd:4.8884 | sampledTokens:64.0000 | windowWeightsW24:4.97198 (0.98), W28:1.14409 (0.02), W32:-1.92437 (0.00), W20:-2.02511 (0.00), W16:-3.45379 (0.00), W12:-4.73941 (0.00), W8:-5.95859 (0.00), W4:-9.16227 (0.00), W2:-10.81803 (0.00) | topTokens[(',', 3672), ('Ġi', 2719), ('Ġit', 1639), ('.', 1614), ('Ġthe', 1531), ('Ġyou', 1457), ('Ġto', 1341), ('Ġand', 1146), ('Ġa', 1118), ('Ġu', 1067)] | cheekyAvg: 10.10778793334961 | perfectTokens: 157 / 32000 → 0.49% |  | remainingTokens: 665383 (99.78%) | TUTOR.py 500
2025-04-22 19:56:37 | 2000 | LR0.00035 | scheduledSamplingRate:0.0064 | repetitionPenalty:1.2934 | AvgLoss:10.5044 | loss:9.7174 | temperature:0.8003 | lR:0.0003 | gradientClip:1.0009 | latestLossDelta:0.2621 | memoryLength:9.9966 | embedNormMean:14.2949 | embedNormStd:10.0795 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5146 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0019 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1813 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7364 | n_weightMax:4.8468 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6006 | n_weightNormMin:21.6247 | n_weightNormMax:41.2427 | n_biasesMean:-1.0606 | n_biasesStd:0.7959 | n_biasesMin:-3.8480 | n_biasesMax:1.9582 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5517 | INN_cerebellumStd:4.8884 | sampledTokens:90.0000 | windowWeightsW24:4.97186 (0.98), W28:1.14422 (0.02), W32:-1.92419 (0.00), W20:-2.02510 (0.00), W16:-3.45379 (0.00), W12:-4.73937 (0.00), W8:-5.95851 (0.00), W4:-9.16226 (0.00), W2:-10.81802 (0.00) | topTokens[(',', 4531), ('Ġi', 3594), ('Ġthe', 2223), ('.', 2119), ('Ġit', 2039), ('Ġyou', 1911), ('Ġto', 1801), ('Ġme', 1508), ('!', 1489), ('Ġu', 1468)] | cheekyAvg: 9.92323781967163 | perfectTokens: 147 / 32000 → 0.46% |  | remainingTokens: 664883 (99.70%) | TUTOR.py 500
2025-04-22 19:59:25 | 2500 | LR0.00035 | scheduledSamplingRate:0.0081 | repetitionPenalty:1.2918 | AvgLoss:10.6512 | loss:10.4719 | temperature:0.8008 | lR:0.0003 | gradientClip:1.0007 | latestLossDelta:1.9526 | memoryLength:9.9986 | embedNormMean:14.2949 | embedNormStd:10.0795 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5145 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0017 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1813 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7365 | n_weightMax:4.8467 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6006 | n_weightNormMin:21.6253 | n_weightNormMax:41.2414 | n_biasesMean:-1.0606 | n_biasesStd:0.7959 | n_biasesMin:-3.8482 | n_biasesMax:1.9581 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5517 | INN_cerebellumStd:4.8884 | sampledTokens:112.0000 | windowWeightsW24:4.97175 (0.98), W28:1.14434 (0.02), W32:-1.92406 (0.00), W20:-2.02510 (0.00), W16:-3.45381 (0.00), W12:-4.73938 (0.00), W8:-5.95850 (0.00), W4:-9.16223 (0.00), W2:-10.81802 (0.00) | topTokens[(',', 5539), ('Ġi', 4703), ('Ġthe', 2872), ('.', 2835), ('Ġit', 2454), ('Ġto', 2413), ('Ġyou', 2272), ('Ġu', 1940), ('Ġme', 1805), ('Ġand', 1785)] | cheekyAvg: 10.53409568786621 | perfectTokens: 164 / 32000 → 0.51% |  | remainingTokens: 664383 (99.63%) | TUTOR.py 500
2025-04-22 20:02:14 | 3000 | LR0.00035 | scheduledSamplingRate:0.0098 | repetitionPenalty:1.2900 | AvgLoss:10.6547 | loss:9.8330 | temperature:0.8009 | lR:0.0003 | gradientClip:1.0005 | latestLossDelta:0.8668 | memoryLength:9.9982 | embedNormMean:14.2949 | embedNormStd:10.0796 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5145 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0016 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1812 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7366 | n_weightMax:4.8468 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6006 | n_weightNormMin:21.6263 | n_weightNormMax:41.2408 | n_biasesMean:-1.0606 | n_biasesStd:0.7959 | n_biasesMin:-3.8485 | n_biasesMax:1.9581 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5516 | INN_cerebellumStd:4.8884 | sampledTokens:141.0000 | windowWeightsW24:4.97174 (0.98), W28:1.14436 (0.02), W32:-1.92408 (0.00), W20:-2.02508 (0.00), W16:-3.45372 (0.00), W12:-4.73934 (0.00), W8:-5.95841 (0.00), W4:-9.16217 (0.00), W2:-10.81801 (0.00) | topTokens[(',', 6457), ('Ġi', 5765), ('Ġthe', 3540), ('.', 3459), ('Ġit', 2859), ('Ġto', 2813), ('Ġyou', 2729), ('Ġu', 2276), ('Ġand', 2131), ('Ġwas', 2128)] | cheekyAvg: 10.520279655456543 | perfectTokens: 163 / 32000 → 0.51% |  | remainingTokens: 663883 (99.55%) | TUTOR.py 500
--- 2025-04-22 20:04:52 --- 
[babyllm] right, last time i got to step 31419... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 31419! what am i learning today?
[charis]2025-04-22 20:08:39 | 500 | LR0.00035 | loss:8.1362 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0017 | repetitionPenalty:1.2979 | AvgLoss:10.8870 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:2.4185 | memoryLength:9.9988 | embedNormMean:14.2949 | embedNormStd:10.0796 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:3.2629 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5145 | logitWeightNormMax:104.8122 | logitWeightSparsity:0.0000 | logitWeightDrift:8.2279 | logitBiasMean:-34.1463 | logitBiasStd:11.9644 | logitBiasMax:-13.1812 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7368 | n_weightMax:4.8468 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6006 | n_weightNormMin:21.6287 | n_weightNormMax:41.2382 | n_biasesMean:-1.0606 | n_biasesStd:0.7959 | n_biasesMin:-3.8490 | n_biasesMax:1.9581 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5516 | INN_cerebellumStd:4.8884 | sampledTokens:20.0000 | windowWeightsW24:4.97149 (0.98), W28:1.14463 (0.02), W32:-1.92374 (0.00), W20:-2.02516 (0.00), W16:-3.45375 (0.00), W12:-4.73940 (0.00), W8:-5.95847 (0.00), W4:-9.16222 (0.00), W2:-10.81802 (0.00) | topTokens[('Ġi', 962), (',', 766), ('.', 584), ('Ġa', 528), ('Ġto', 502), ('Ġwas', 462), ('!', 443), ('Ġyou', 436), ('Ġit', 418), ('Ġu', 413)] | cheekyAvg: 9.826479453306932 | perfectTokens: 128 / 32000 → 0.40% |  | remainingTokens: 662964 (99.92%) | TUTOR.py 500
2025-04-22 20:11:27 | 1000 | LR0.00035 | scheduledSamplingRate:0.0033 | repetitionPenalty:1.2963 | AvgLoss:11.0197 | loss:9.9214 | temperature:0.7996 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:-0.7667 | memoryLength:10.0008 | embedNormMean:14.2949 | embedNormStd:10.0796 | embedNormMax:103.7226 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0004 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5144 | logitWeightNormMax:104.8116 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0018 | logitBiasMean:-34.1463 | logitBiasStd:11.9643 | logitBiasMax:-13.1813 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7369 | n_weightMax:4.8467 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6006 | n_weightNormMin:21.6306 | n_weightNormMax:41.2374 | n_biasesMean:-1.0606 | n_biasesStd:0.7959 | n_biasesMin:-3.8491 | n_biasesMax:1.9581 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5516 | INN_cerebellumStd:4.8884 | sampledTokens:47.0000 | windowWeightsW24:4.97130 (0.98), W28:1.14481 (0.02), W32:-1.92354 (0.00), W20:-2.02509 (0.00), W16:-3.45375 (0.00), W12:-4.73936 (0.00), W8:-5.95844 (0.00), W4:-9.16217 (0.00), W2:-10.81799 (0.00) | topTokens[('Ġi', 1654), (',', 1629), ('.', 1314), ('Ġa', 1120), ('Ġit', 913), ('Ġyou', 876), ('Ġthe', 824), ('Ġwas', 822), ('Ġu', 809), ('Ġto', 764)] | cheekyAvg: 10.413349380493164 | perfectTokens: 187 / 32000 → 0.58% |  | remainingTokens: 662464 (99.85%) | TUTOR.py 500
2025-04-22 20:14:10 | 1500 | LR0.00035 | sampledTokens:72.0000 | scheduledSamplingRate:0.0053 | repetitionPenalty:1.2946 | AvgLoss:9.8646 | loss:7.6775 | temperature:0.7996 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:2.2138 | memoryLength:9.9994 | embedNormMean:14.2949 | embedNormStd:10.0796 | embedNormMax:103.7226 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0004 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5144 | logitWeightNormMax:104.8116 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0020 | logitBiasMean:-34.1464 | logitBiasStd:11.9643 | logitBiasMax:-13.1812 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7370 | n_weightMax:4.8468 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6006 | n_weightNormMin:21.6329 | n_weightNormMax:41.2341 | n_biasesMean:-1.0606 | n_biasesStd:0.7958 | n_biasesMin:-3.8493 | n_biasesMax:1.9580 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5515 | INN_cerebellumStd:4.8884 | windowWeightsW24:4.97113 (0.98), W28:1.14499 (0.02), W32:-1.92338 (0.00), W20:-2.02504 (0.00), W16:-3.45374 (0.00), W12:-4.73931 (0.00), W8:-5.95841 (0.00), W4:-9.16214 (0.00), W2:-10.81799 (0.00) | topTokens[('Ġi', 2516), (',', 2135), ('.', 2027), ('Ġa', 1586), ('Ġu', 1496), ('Ġto', 1275), ('Ġwas', 1245), ('Ġthe', 1226), ('!', 1189), ('Ġit', 1185)] | cheekyAvg: 9.343029747009277 | perfectTokens: 182 / 32000 → 0.57% |  | remainingTokens: 661964 (99.77%) | TUTOR.py 500
2025-04-22 20:16:58 | 2000 | LR0.00035 | scheduledSamplingRate:0.0068 | repetitionPenalty:1.2927 | AvgLoss:10.6266 | loss:10.9411 | temperature:0.7993 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:0.8461 | memoryLength:9.9984 | embedNormMean:14.2949 | embedNormStd:10.0796 | embedNormMax:103.7226 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0007 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5143 | logitWeightNormMax:104.8115 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0028 | logitBiasMean:-34.1464 | logitBiasStd:11.9643 | logitBiasMax:-13.1812 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7369 | n_weightMax:4.8468 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6006 | n_weightNormMin:21.6342 | n_weightNormMax:41.2330 | n_biasesMean:-1.0606 | n_biasesStd:0.7959 | n_biasesMin:-3.8494 | n_biasesMax:1.9579 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5515 | INN_cerebellumStd:4.8883 | sampledTokens:100.0000 | windowWeightsW24:4.97100 (0.98), W28:1.14514 (0.02), W32:-1.92319 (0.00), W20:-2.02500 (0.00), W16:-3.45381 (0.00), W12:-4.73939 (0.00), W8:-5.95849 (0.00), W4:-9.16219 (0.00), W2:-10.81800 (0.00) | topTokens[(',', 3347), ('Ġi', 2940), ('.', 2695), ('Ġa', 2090), ('Ġyou', 1738), ('Ġu', 1716), ('Ġthe', 1669), ('Ġto', 1615), ('Ġit', 1458), ('Ġwas', 1408)] | cheekyAvg: 10.124603004455567 | perfectTokens: 176 / 32000 → 0.55% |  | remainingTokens: 661464 (99.70%) | TUTOR.py 500
2025-04-22 20:19:41 | 2500 | LR0.00035 | scheduledSamplingRate:0.0083 | repetitionPenalty:1.2908 | AvgLoss:10.4851 | loss:10.1554 | temperature:0.7993 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:-0.4940 | memoryLength:9.9994 | embedNormMean:14.2950 | embedNormStd:10.0796 | embedNormMax:103.7224 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0007 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5143 | logitWeightNormMax:104.8115 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0023 | logitBiasMean:-34.1464 | logitBiasStd:11.9643 | logitBiasMax:-13.1812 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7369 | n_weightMax:4.8467 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6006 | n_weightNormMin:21.6333 | n_weightNormMax:41.2342 | n_biasesMean:-1.0606 | n_biasesStd:0.7959 | n_biasesMin:-3.8491 | n_biasesMax:1.9578 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5515 | INN_cerebellumStd:4.8884 | sampledTokens:133.0000 | windowWeightsW24:4.97092 (0.98), W28:1.14521 (0.02), W32:-1.92311 (0.00), W20:-2.02498 (0.00), W16:-3.45383 (0.00), W12:-4.73933 (0.00), W8:-5.95841 (0.00), W4:-9.16216 (0.00), W2:-10.81801 (0.00) | topTokens[(',', 5253), ('.', 3643), ('Ġi', 3374), ('Ġa', 2716), ('Ġyou', 2279), ('Ġthe', 2223), ('Ġto', 2192), ('Ġit', 1769), ('Ġu', 1716), ('Ġwas', 1616)] | cheekyAvg: 10.52797565460205 | perfectTokens: 227 / 32000 → 0.71% |  | remainingTokens: 660964 (99.62%) | TUTOR.py 500
2025-04-22 20:22:29 | 3000 | LR0.00035 | scheduledSamplingRate:0.0102 | repetitionPenalty:1.2893 | AvgLoss:10.6470 | loss:12.5205 | temperature:0.7993 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:2.2650 | memoryLength:10.0006 | embedNormMean:14.2950 | embedNormStd:10.0796 | embedNormMax:103.7220 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5143 | logitWeightNormMax:104.8115 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0024 | logitBiasMean:-34.1464 | logitBiasStd:11.9643 | logitBiasMax:-13.1812 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7369 | n_weightMax:4.8467 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6007 | n_weightNormMin:21.6337 | n_weightNormMax:41.2368 | n_biasesMean:-1.0606 | n_biasesStd:0.7959 | n_biasesMin:-3.8490 | n_biasesMax:1.9578 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5515 | INN_cerebellumStd:4.8883 | sampledTokens:149.0000 | windowWeightsW24:4.97081 (0.98), W28:1.14534 (0.02), W32:-1.92293 (0.00), W20:-2.02502 (0.00), W16:-3.45379 (0.00), W12:-4.73928 (0.00), W8:-5.95834 (0.00), W4:-9.16212 (0.00), W2:-10.81799 (0.00) | topTokens[(',', 7028), ('.', 4193), ('Ġi', 3752), ('Ġa', 3285), ('Ġyou', 3119), ('Ġthe', 2866), ('Ġto', 2599), ('Ġwas', 1988), ('Ġit', 1950), ('Ġand', 1795)] | cheekyAvg: 10.590847244262696 | perfectTokens: 245 / 32000 → 0.77% |  | remainingTokens: 660464 (99.55%) | TUTOR.py 500
2025-04-22 20:25:15 | 3500 | LR0.00035 | scheduledSamplingRate:0.0114 | repetitionPenalty:1.2876 | AvgLoss:9.9694 | loss:8.8161 | temperature:0.7992 | lR:0.0003 | gradientClip:0.9995 | latestLossDelta:-0.3834 | memoryLength:9.9980 | embedNormMean:14.2950 | embedNormStd:10.0796 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5143 | logitWeightNormMax:104.8115 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0021 | logitBiasMean:-34.1464 | logitBiasStd:11.9643 | logitBiasMax:-13.1812 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7368 | n_weightMax:4.8466 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6007 | n_weightNormMin:21.6338 | n_weightNormMax:41.2369 | n_biasesMean:-1.0606 | n_biasesStd:0.7959 | n_biasesMin:-3.8490 | n_biasesMax:1.9579 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5515 | INN_cerebellumStd:4.8883 | sampledTokens:161.0000 | windowWeightsW24:4.97077 (0.98), W28:1.14537 (0.02), W32:-1.92284 (0.00), W20:-2.02498 (0.00), W16:-3.45377 (0.00), W12:-4.73930 (0.00), W8:-5.95838 (0.00), W4:-9.16214 (0.00), W2:-10.81801 (0.00) | topTokens[(',', 8738), ('.', 4969), ('Ġi', 4106), ('Ġa', 3857), ('Ġyou', 3715), ('Ġthe', 3598), ('Ġto', 2976), ('Ġwas', 2744), ('Ġit', 2172), ('ed', 2075)] | cheekyAvg: 9.744732875823974 | perfectTokens: 270 / 32000 → 0.84% |  | remainingTokens: 659964 (99.47%) | TUTOR.py 500
2025-04-22 20:28:05 | 4000 | LR0.00035 | scheduledSamplingRate:0.0133 | repetitionPenalty:1.2861 | AvgLoss:10.5834 | loss:9.5093 | temperature:0.7993 | lR:0.0003 | gradientClip:0.9995 | latestLossDelta:-0.1552 | memoryLength:9.9930 | embedNormMean:14.2950 | embedNormStd:10.0796 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5142 | logitWeightNormMax:104.8115 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0022 | logitBiasMean:-34.1464 | logitBiasStd:11.9643 | logitBiasMax:-13.1812 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7369 | n_weightMax:4.8466 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6008 | n_weightNormMin:21.6337 | n_weightNormMax:41.2374 | n_biasesMean:-1.0606 | n_biasesStd:0.7959 | n_biasesMin:-3.8489 | n_biasesMax:1.9579 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5515 | INN_cerebellumStd:4.8883 | sampledTokens:208.0000 | windowWeightsW24:4.97069 (0.98), W28:1.14543 (0.02), W32:-1.92274 (0.00), W20:-2.02497 (0.00), W16:-3.45377 (0.00), W12:-4.73929 (0.00), W8:-5.95832 (0.00), W4:-9.16214 (0.00), W2:-10.81801 (0.00) | topTokens[(',', 10488), ('.', 5947), ('Ġi', 4541), ('Ġyou', 4238), ('Ġa', 4238), ('Ġthe', 4164), ('Ġto', 3487), ('Ġwas', 2893), ('ed', 2381), ('Ġit', 2356)] | cheekyAvg: 10.45330291748047 | perfectTokens: 216 / 32000 → 0.68% |  | remainingTokens: 659464 (99.40%) | TUTOR.py 500
2025-04-22 20:30:50 | 4500 | LR0.00035 | scheduledSamplingRate:0.0151 | repetitionPenalty:1.2845 | AvgLoss:10.5078 | loss:10.6543 | temperature:0.7996 | lR:0.0003 | gradientClip:0.9991 | latestLossDelta:0.3571 | memoryLength:9.9914 | embedNormMean:14.2951 | embedNormStd:10.0796 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5142 | logitWeightNormMax:104.8115 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0021 | logitBiasMean:-34.1463 | logitBiasStd:11.9643 | logitBiasMax:-13.1813 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7369 | n_weightMax:4.8465 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6008 | n_weightNormMin:21.6331 | n_weightNormMax:41.2381 | n_biasesMean:-1.0606 | n_biasesStd:0.7959 | n_biasesMin:-3.8488 | n_biasesMax:1.9579 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5514 | INN_cerebellumStd:4.8883 | sampledTokens:230.0000 | windowWeightsW24:4.97061 (0.98), W28:1.14551 (0.02), W32:-1.92267 (0.00), W20:-2.02496 (0.00), W16:-3.45377 (0.00), W12:-4.73928 (0.00), W8:-5.95822 (0.00), W4:-9.16209 (0.00), W2:-10.81797 (0.00) | topTokens[(',', 12257), ('.', 6781), ('Ġyou', 4884), ('Ġi', 4874), ('Ġa', 4842), ('Ġthe', 4601), ('Ġto', 3844), ('Ġwas', 3048), ('Ġand', 2655), ('Ġit', 2643)] | cheekyAvg: 10.2585498046875 | perfectTokens: 222 / 32000 → 0.69% |  | remainingTokens: 658964 (99.32%) | TUTOR.py 500
2025-04-22 20:33:40 | 5000 | LR0.00035 | scheduledSamplingRate:0.0164 | repetitionPenalty:1.2826 | AvgLoss:12.1115 | loss:10.7862 | temperature:0.8001 | lR:0.0003 | gradientClip:0.9990 | latestLossDelta:-0.3090 | memoryLength:9.9948 | embedNormMean:14.2953 | embedNormStd:10.0796 | embedNormMax:103.7215 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0007 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5142 | logitWeightNormMax:104.8096 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0025 | logitBiasMean:-34.1463 | logitBiasStd:11.9643 | logitBiasMax:-13.1815 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7368 | n_weightMax:4.8465 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6008 | n_weightNormMin:21.6331 | n_weightNormMax:41.2383 | n_biasesMean:-1.0606 | n_biasesStd:0.7959 | n_biasesMin:-3.8488 | n_biasesMax:1.9578 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5514 | INN_cerebellumStd:4.8883 | sampledTokens:220.0000 | windowWeightsW24:4.97054 (0.98), W28:1.14559 (0.02), W32:-1.92261 (0.00), W20:-2.02494 (0.00), W16:-3.45379 (0.00), W12:-4.73929 (0.00), W8:-5.95821 (0.00), W4:-9.16210 (0.00), W2:-10.81796 (0.00) | topTokens[(',', 13836), ('.', 7236), ('Ġi', 5954), ('Ġa', 5510), ('Ġyou', 5321), ('Ġthe', 5058), ('Ġto', 4456), ('Ġwas', 3221), ('Ġand', 3121), ('ed', 2961)] | cheekyAvg: 12.001314888000488 | perfectTokens: 279 / 32000 → 0.87% |  | remainingTokens: 658464 (99.25%) | TUTOR.py 500
2025-04-22 20:36:26 | 5500 | LR0.00035 | scheduledSamplingRate:0.0177 | repetitionPenalty:1.2810 | AvgLoss:11.4818 | loss:11.9477 | temperature:0.8001 | lR:0.0003 | gradientClip:0.9989 | latestLossDelta:0.2683 | memoryLength:9.9950 | embedNormMean:14.2953 | embedNormStd:10.0796 | embedNormMax:103.7215 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5142 | logitWeightNormMax:104.8095 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0021 | logitBiasMean:-34.1463 | logitBiasStd:11.9643 | logitBiasMax:-13.1816 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7368 | n_weightMax:4.8464 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6010 | n_weightNormMin:21.6329 | n_weightNormMax:41.2380 | n_biasesMean:-1.0606 | n_biasesStd:0.7959 | n_biasesMin:-3.8488 | n_biasesMax:1.9577 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5514 | INN_cerebellumStd:4.8883 | sampledTokens:262.0000 | windowWeightsW24:4.97050 (0.98), W28:1.14565 (0.02), W32:-1.92258 (0.00), W20:-2.02497 (0.00), W16:-3.45386 (0.00), W12:-4.73937 (0.00), W8:-5.95829 (0.00), W4:-9.16215 (0.00), W2:-10.81798 (0.00) | topTokens[(',', 15171), ('.', 7838), ('Ġi', 6823), ('Ġyou', 5955), ('Ġa', 5896), ('Ġthe', 5589), ('Ġto', 4996), ('Ġand', 3449), ('ed', 3358), ('Ġwas', 3289)] | cheekyAvg: 11.34746795654297 | perfectTokens: 220 / 32000 → 0.69% |  | remainingTokens: 657964 (99.17%) | TUTOR.py 500
2025-04-22 20:39:16 | 6000 | LR0.00035 | scheduledSamplingRate:0.0192 | repetitionPenalty:1.2795 | AvgLoss:11.3841 | loss:14.4142 | temperature:0.8000 | lR:0.0003 | gradientClip:0.9987 | latestLossDelta:2.7251 | memoryLength:9.9972 | embedNormMean:14.2953 | embedNormStd:10.0796 | embedNormMax:103.7215 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5141 | logitWeightNormMax:104.8088 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0024 | logitBiasMean:-34.1463 | logitBiasStd:11.9643 | logitBiasMax:-13.1816 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7369 | n_weightMax:4.8464 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6013 | n_weightNormMin:21.6323 | n_weightNormMax:41.2391 | n_biasesMean:-1.0606 | n_biasesStd:0.7959 | n_biasesMin:-3.8488 | n_biasesMax:1.9577 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5514 | INN_cerebellumStd:4.8883 | sampledTokens:289.0000 | windowWeightsW24:4.97048 (0.98), W28:1.14566 (0.02), W32:-1.92251 (0.00), W20:-2.02498 (0.00), W16:-3.45387 (0.00), W12:-4.73936 (0.00), W8:-5.95829 (0.00), W4:-9.16214 (0.00), W2:-10.81799 (0.00) | topTokens[(',', 16762), ('.', 8582), ('Ġi', 7693), ('Ġyou', 6468), ('Ġa', 6365), ('Ġthe', 6060), ('Ġto', 5280), ('Ġand', 3802), ('ed', 3636), ('!', 3588)] | cheekyAvg: 11.458815612792968 | perfectTokens: 248 / 32000 → 0.77% |  | remainingTokens: 657464 (99.10%) | TUTOR.py 500
--- 2025-04-22 20:40:19 --- 
[babyllm] right, last time i got to step 37531... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 37531! what am i learning today?
[charis]--- 2025-04-22 20:44:26 --- 
[babyllm] right, last time i got to step 37974... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 37974! what am i learning today?
[charis]2025-04-22 20:48:13 | 500 | LR0.00035 | loss:10.7498 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0017 | repetitionPenalty:1.2988 | AvgLoss:11.8558 | temperature:0.8002 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:0.3259 | memoryLength:10.0000 | embedNormMean:14.2954 | embedNormStd:10.0796 | embedNormMax:103.7200 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:3.2650 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5140 | logitWeightNormMax:104.8074 | logitWeightSparsity:0.0000 | logitWeightDrift:8.2282 | logitBiasMean:-34.1463 | logitBiasStd:11.9642 | logitBiasMax:-13.1822 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7366 | n_weightMax:4.8465 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6013 | n_weightNormMin:21.6315 | n_weightNormMax:41.2407 | n_biasesMean:-1.0607 | n_biasesStd:0.7959 | n_biasesMin:-3.8490 | n_biasesMax:1.9576 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5514 | INN_cerebellumStd:4.8883 | sampledTokens:24.0000 | windowWeightsW24:4.97031 (0.98), W28:1.14583 (0.02), W32:-1.92224 (0.00), W20:-2.02488 (0.00), W16:-3.45379 (0.00), W12:-4.73921 (0.00), W8:-5.95808 (0.00), W4:-9.16195 (0.00), W2:-10.81797 (0.00) | topTokens[(',', 1580), ('Ġyou', 920), ('Ġthe', 604), ('.', 513), ('Ġand', 407), ('!', 377), ('Ġi', 371), ('s', 349), ('Ġto', 320), ('Ġit', 303)] | cheekyAvg: 11.222166831676777 | perfectTokens: 254 / 32000 → 0.79% |  | remainingTokens: 656409 (99.92%) | TUTOR.py 500
2025-04-22 20:51:02 | 1000 | LR0.00035 | scheduledSamplingRate:0.0034 | repetitionPenalty:1.2970 | AvgLoss:11.6299 | loss:11.1921 | temperature:0.8006 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:1.2774 | memoryLength:10.0024 | embedNormMean:14.2954 | embedNormStd:10.0797 | embedNormMax:103.7199 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5140 | logitWeightNormMax:104.8074 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0024 | logitBiasMean:-34.1463 | logitBiasStd:11.9642 | logitBiasMax:-13.1823 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7365 | n_weightMax:4.8466 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6015 | n_weightNormMin:21.6305 | n_weightNormMax:41.2408 | n_biasesMean:-1.0607 | n_biasesStd:0.7959 | n_biasesMin:-3.8489 | n_biasesMax:1.9577 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5513 | INN_cerebellumStd:4.8883 | sampledTokens:31.0000 | windowWeightsW24:4.97029 (0.98), W28:1.14586 (0.02), W32:-1.92217 (0.00), W20:-2.02485 (0.00), W16:-3.45376 (0.00), W12:-4.73915 (0.00), W8:-5.95803 (0.00), W4:-9.16192 (0.00), W2:-10.81795 (0.00) | topTokens[(',', 2736), ('Ġyou', 1477), ('Ġi', 1124), ('Ġthe', 1119), ('.', 1102), ('!', 836), ('Ġto', 750), ('Ġand', 737), ('s', 678), ('Ġthat', 675)] | cheekyAvg: 11.41747501373291 | perfectTokens: 177 / 32000 → 0.55% |  | remainingTokens: 655909 (99.85%) | TUTOR.py 500
2025-04-22 20:53:46 | 1500 | LR0.00035 | scheduledSamplingRate:0.0047 | repetitionPenalty:1.2954 | AvgLoss:11.8759 | loss:10.5715 | temperature:0.8004 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:3.2261 | memoryLength:10.0004 | embedNormMean:14.2954 | embedNormStd:10.0797 | embedNormMax:103.7199 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0007 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5140 | logitWeightNormMax:104.8043 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0024 | logitBiasMean:-34.1463 | logitBiasStd:11.9642 | logitBiasMax:-13.1826 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7364 | n_weightMax:4.8465 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6015 | n_weightNormMin:21.6292 | n_weightNormMax:41.2404 | n_biasesMean:-1.0607 | n_biasesStd:0.7960 | n_biasesMin:-3.8489 | n_biasesMax:1.9578 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5513 | INN_cerebellumStd:4.8883 | sampledTokens:61.0000 | windowWeightsW24:4.97019 (0.98), W28:1.14597 (0.02), W32:-1.92203 (0.00), W20:-2.02490 (0.00), W16:-3.45378 (0.00), W12:-4.73914 (0.00), W8:-5.95800 (0.00), W4:-9.16188 (0.00), W2:-10.81794 (0.00) | topTokens[(',', 4019), ('Ġyou', 1861), ('Ġi', 1835), ('Ġthe', 1716), ('.', 1601), ('Ġa', 1316), ('Ġand', 1111), ('Ġto', 1089), ('!', 1075), ('Ġit', 966)] | cheekyAvg: 11.854660968780518 | perfectTokens: 183 / 32000 → 0.57% |  | remainingTokens: 655409 (99.77%) | TUTOR.py 500
--- 2025-04-22 20:54:40 --- 
[babyllm] right, last time i got to step 39602... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 39602! what am i learning today?
[charis]2025-04-22 20:58:30 | 500 | LR0.00035 | loss:14.2288 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0015 | repetitionPenalty:1.2982 | AvgLoss:10.9755 | temperature:0.7997 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:2.9919 | memoryLength:10.0010 | embedNormMean:14.2954 | embedNormStd:10.0798 | embedNormMax:103.7197 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:3.2626 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5139 | logitWeightNormMax:104.8005 | logitWeightSparsity:0.0000 | logitWeightDrift:8.2282 | logitBiasMean:-34.1463 | logitBiasStd:11.9642 | logitBiasMax:-13.1827 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7363 | n_weightMax:4.8465 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6015 | n_weightNormMin:21.6281 | n_weightNormMax:41.2420 | n_biasesMean:-1.0607 | n_biasesStd:0.7960 | n_biasesMin:-3.8488 | n_biasesMax:1.9578 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5513 | INN_cerebellumStd:4.8883 | sampledTokens:15.0000 | windowWeightsW24:4.97018 (0.98), W28:1.14599 (0.02), W32:-1.92196 (0.00), W20:-2.02487 (0.00), W16:-3.45386 (0.00), W12:-4.73919 (0.00), W8:-5.95803 (0.00), W4:-9.16193 (0.00), W2:-10.81800 (0.00) | topTokens[(',', 1755), ('Ġyou', 669), ('.', 564), ('Ġi', 522), ('Ġthe', 513), ('Ġa', 452), ('Ġto', 368), ('Ġit', 366), ('Ġmy', 358), ('s', 353)] | cheekyAvg: 10.662480464348427 | perfectTokens: 147 / 32000 → 0.46% |  | remainingTokens: 654781 (99.92%) | TUTOR.py 500
2025-04-22 21:01:18 | 1000 | LR0.00035 | scheduledSamplingRate:0.0028 | repetitionPenalty:1.2966 | AvgLoss:11.4346 | loss:10.5275 | temperature:0.7997 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:0.1135 | memoryLength:9.9992 | embedNormMean:14.2954 | embedNormStd:10.0798 | embedNormMax:103.7197 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5139 | logitWeightNormMax:104.7993 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0024 | logitBiasMean:-34.1463 | logitBiasStd:11.9642 | logitBiasMax:-13.1827 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7363 | n_weightMax:4.8465 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6015 | n_weightNormMin:21.6271 | n_weightNormMax:41.2432 | n_biasesMean:-1.0607 | n_biasesStd:0.7960 | n_biasesMin:-3.8489 | n_biasesMax:1.9578 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5513 | INN_cerebellumStd:4.8883 | sampledTokens:33.0000 | windowWeightsW24:4.97016 (0.98), W28:1.14603 (0.02), W32:-1.92186 (0.00), W20:-2.02493 (0.00), W16:-3.45394 (0.00), W12:-4.73929 (0.00), W8:-5.95807 (0.00), W4:-9.16196 (0.00), W2:-10.81803 (0.00) | topTokens[(',', 3127), ('Ġyou', 1542), ('.', 1153), ('Ġi', 1058), ('Ġa', 929), ('Ġthe', 924), ('Ġto', 912), ('Ġand', 716), ('s', 715), ('Ġit', 636)] | cheekyAvg: 11.32860450744629 | perfectTokens: 190 / 32000 → 0.59% |  | remainingTokens: 654281 (99.85%) | TUTOR.py 500
--- 2025-04-22 21:02:31 --- 
[babyllm] right, last time i got to step 40796... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 40796! what am i learning today?
[charis]--- 2025-04-22 21:03:25 --- 
[babyllm] right, last time i got to step 40796... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 40796! what am i learning today?
[charis]2025-04-22 21:07:11 | 500 | LR0.00035 | loss:8.6878 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0016 | repetitionPenalty:1.2982 | AvgLoss:11.8520 | temperature:0.8000 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:-1.0254 | memoryLength:10.0012 | embedNormMean:14.2954 | embedNormStd:10.0798 | embedNormMax:103.7191 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:3.2628 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5138 | logitWeightNormMax:104.7957 | logitWeightSparsity:0.0000 | logitWeightDrift:8.2283 | logitBiasMean:-34.1464 | logitBiasStd:11.9640 | logitBiasMax:-13.1830 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7363 | n_weightMax:4.8465 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6016 | n_weightNormMin:21.6270 | n_weightNormMax:41.2436 | n_biasesMean:-1.0607 | n_biasesStd:0.7960 | n_biasesMin:-3.8490 | n_biasesMax:1.9579 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5513 | INN_cerebellumStd:4.8883 | sampledTokens:8.0000 | windowWeightsW24:4.97007 (0.98), W28:1.14612 (0.02), W32:-1.92176 (0.00), W20:-2.02490 (0.00), W16:-3.45395 (0.00), W12:-4.73930 (0.00), W8:-5.95805 (0.00), W4:-9.16195 (0.00), W2:-10.81803 (0.00) | topTokens[(',', 1021), ('Ġi', 720), ('Ġthe', 691), ('Ġyou', 609), ('.', 583), ('Ġto', 496), ('Ġthat', 429), ('Ġa', 427), ('!', 340), ('?', 301)] | cheekyAvg: 11.233040479513315 | perfectTokens: 208 / 32000 → 0.65% |  | remainingTokens: 653587 (99.92%) | TUTOR.py 500
--- 2025-04-22 21:07:58 --- 
[babyllm] right, last time i got to step 40796... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 40796! what am i learning today?
[charis]--- 2025-04-22 21:10:47 --- 
[babyllm] right, last time i got to step 41080... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 41080! what am i learning today?
[charis]2025-04-22 21:14:34 | 500 | LR0.00035 | loss:12.0698 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0016 | repetitionPenalty:1.2986 | AvgLoss:10.9890 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0005 | latestLossDelta:1.9201 | memoryLength:9.9998 | embedNormMean:14.2954 | embedNormStd:10.0799 | embedNormMax:103.7190 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:3.2609 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5138 | logitWeightNormMax:104.7957 | logitWeightSparsity:0.0000 | logitWeightDrift:8.2282 | logitBiasMean:-34.1464 | logitBiasStd:11.9640 | logitBiasMax:-13.1830 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8974 | n_weightMin:-4.7365 | n_weightMax:4.8464 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6016 | n_weightNormMin:21.6276 | n_weightNormMax:41.2433 | n_biasesMean:-1.0607 | n_biasesStd:0.7960 | n_biasesMin:-3.8489 | n_biasesMax:1.9579 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5513 | INN_cerebellumStd:4.8883 | sampledTokens:4.0000 | windowWeightsW24:4.97018 (0.98), W28:1.14600 (0.02), W32:-1.92180 (0.00), W20:-2.02494 (0.00), W16:-3.45394 (0.00), W12:-4.73921 (0.00), W8:-5.95801 (0.00), W4:-9.16199 (0.00), W2:-10.81804 (0.00) | topTokens[(',', 1318), ('Ġthe', 604), ('Ġa', 544), ('.', 538), ('Ġyou', 484), ('Ġi', 484), ('Ġto', 464), ('!', 366), ('Ġit', 303), ('Ġthat', 285)] | cheekyAvg: 10.484276863244864 | perfectTokens: 257 / 32000 → 0.80% |  | remainingTokens: 653303 (99.92%) | TUTOR.py 500
2025-04-22 21:17:22 | 1000 | LR0.00035 | sampledTokens:30.0000 | scheduledSamplingRate:0.0032 | repetitionPenalty:1.2969 | AvgLoss:10.6764 | loss:9.8167 | temperature:0.8005 | lR:0.0003 | gradientClip:1.0002 | latestLossDelta:-1.7847 | memoryLength:10.0000 | embedNormMean:14.2955 | embedNormStd:10.0799 | embedNormMax:103.7190 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5137 | logitWeightNormMax:104.7938 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0023 | logitBiasMean:-34.1464 | logitBiasStd:11.9640 | logitBiasMax:-13.1831 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7365 | n_weightMax:4.8465 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6016 | n_weightNormMin:21.6271 | n_weightNormMax:41.2432 | n_biasesMean:-1.0607 | n_biasesStd:0.7960 | n_biasesMin:-3.8489 | n_biasesMax:1.9577 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5513 | INN_cerebellumStd:4.8883 | windowWeightsW24:4.97010 (0.98), W28:1.14609 (0.02), W32:-1.92170 (0.00), W20:-2.02486 (0.00), W16:-3.45389 (0.00), W12:-4.73917 (0.00), W8:-5.95794 (0.00), W4:-9.16196 (0.00), W2:-10.81802 (0.00) | topTokens[(',', 2410), ('Ġa', 1153), ('Ġi', 1087), ('Ġthe', 1058), ('Ġyou', 1015), ('.', 980), ('Ġto', 787), ('!', 734), ('Ġand', 676), ('Ġit', 645)] | cheekyAvg: 10.563439750671387 | perfectTokens: 154 / 32000 → 0.48% |  | remainingTokens: 652803 (99.85%) | TUTOR.py 500
2025-04-22 21:20:03 | 1500 | LR0.00035 | sampledTokens:61.0000 | scheduledSamplingRate:0.0046 | repetitionPenalty:1.2952 | AvgLoss:10.7287 | loss:12.3653 | temperature:0.8007 | lR:0.0003 | gradientClip:1.0004 | latestLossDelta:0.9169 | memoryLength:10.0012 | embedNormMean:14.2955 | embedNormStd:10.0799 | embedNormMax:103.7190 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0006 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5137 | logitWeightNormMax:104.7918 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0022 | logitBiasMean:-34.1464 | logitBiasStd:11.9640 | logitBiasMax:-13.1831 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7364 | n_weightMax:4.8464 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6018 | n_weightNormMin:21.6273 | n_weightNormMax:41.2435 | n_biasesMean:-1.0607 | n_biasesStd:0.7960 | n_biasesMin:-3.8488 | n_biasesMax:1.9577 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5513 | INN_cerebellumStd:4.8883 | windowWeightsW24:4.97005 (0.98), W28:1.14611 (0.02), W32:-1.92161 (0.00), W20:-2.02477 (0.00), W16:-3.45382 (0.00), W12:-4.73915 (0.00), W8:-5.95793 (0.00), W4:-9.16198 (0.00), W2:-10.81802 (0.00) | topTokens[(',', 3822), ('Ġi', 1842), ('Ġa', 1688), ('Ġyou', 1531), ('Ġto', 1499), ('Ġthe', 1432), ('.', 1430), ('Ġit', 1148), ('Ġand', 1134), ('!', 1047)] | cheekyAvg: 10.803009376525878 | perfectTokens: 199 / 32000 → 0.62% |  | remainingTokens: 652303 (99.77%) | TUTOR.py 500
--- 2025-04-22 21:25:31 --- 
[babyllm] right, last time i got to step 42982... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 42982! what am i learning today?
[charis]2025-04-22 21:29:20 | 500 | LR0.00035 | loss:16.0868 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0016 | repetitionPenalty:1.2984 | AvgLoss:12.3543 | temperature:0.7997 | lR:0.0003 | gradientClip:0.9996 | latestLossDelta:0.7265 | memoryLength:9.9994 | embedNormMean:14.2958 | embedNormStd:10.0799 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:3.2626 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5137 | logitWeightNormMax:104.7896 | logitWeightSparsity:0.0000 | logitWeightDrift:8.2283 | logitBiasMean:-34.1464 | logitBiasStd:11.9640 | logitBiasMax:-13.1836 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7365 | n_weightMax:4.8464 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6019 | n_weightNormMin:21.6258 | n_weightNormMax:41.2425 | n_biasesMean:-1.0607 | n_biasesStd:0.7960 | n_biasesMin:-3.8488 | n_biasesMax:1.9578 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5512 | INN_cerebellumStd:4.8883 | sampledTokens:12.0000 | windowWeightsW24:4.97001 (0.98), W28:1.14616 (0.02), W32:-1.92148 (0.00), W20:-2.02467 (0.00), W16:-3.45384 (0.00), W12:-4.73917 (0.00), W8:-5.95790 (0.00), W4:-9.16198 (0.00), W2:-10.81803 (0.00) | topTokens[(',', 1178), ('Ġa', 710), ('Ġi', 633), ('ed', 616), ('Ġthe', 568), ('Ġto', 490), ('.', 417), ('Ġyou', 350), ('Ġit', 332), ('Ġand', 306)] | cheekyAvg: 11.602675437927246 | perfectTokens: 208 / 32000 → 0.65% |  | remainingTokens: 651401 (99.92%) | TUTOR.py 500
--- 2025-04-22 21:30:44 --- 
[babyllm] right, last time i got to step 43707... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 43707! what am i learning today?
[charis]--- 2025-04-22 21:34:32 --- 
[babyllm] right, last time i got to step 44180... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 44180! what am i learning today?
[charis]--- 2025-04-22 21:37:39 --- 
[babyllm] right, last time i got to step 44524... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 44524! what am i learning today?
[charis]2025-04-22 21:41:26 | 500 | LR0.00035 | loss:8.5829 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0017 | repetitionPenalty:1.2988 | AvgLoss:9.0114 | temperature:0.8005 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:0.6395 | memoryLength:9.9982 | embedNormMean:14.2959 | embedNormStd:10.0801 | embedNormMax:103.7187 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:3.2618 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5135 | logitWeightNormMax:104.7800 | logitWeightSparsity:0.0000 | logitWeightDrift:8.2279 | logitBiasMean:-34.1464 | logitBiasStd:11.9639 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7367 | n_weightMax:4.8461 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6025 | n_weightNormMin:21.6241 | n_weightNormMax:41.2403 | n_biasesMean:-1.0608 | n_biasesStd:0.7960 | n_biasesMin:-3.8485 | n_biasesMax:1.9580 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5512 | INN_cerebellumStd:4.8883 | sampledTokens:16.0000 | windowWeightsW24:4.96986 (0.98), W28:1.14630 (0.02), W32:-1.92116 (0.00), W20:-2.02466 (0.00), W16:-3.45385 (0.00), W12:-4.73916 (0.00), W8:-5.95790 (0.00), W4:-9.16196 (0.00), W2:-10.81800 (0.00) | topTokens[(',', 1193), ('Ġi', 928), ('Ġyou', 639), ('!', 589), ('Ġto', 457), ('Ġa', 401), ('Ġit', 389), ('Ġwas', 382), ('Ġthe', 377), ('Ġme', 348)] | cheekyAvg: 8.591222286224365 | perfectTokens: 319 / 32000 → 1.00% |  | remainingTokens: 649859 (99.92%) | TUTOR.py 500
2025-04-22 21:44:13 | 1000 | LR0.00035 | sampledTokens:44.0000 | scheduledSamplingRate:0.0035 | repetitionPenalty:1.2971 | AvgLoss:9.2846 | loss:7.6271 | temperature:0.8004 | lR:0.0003 | gradientClip:0.9996 | latestLossDelta:-1.0232 | memoryLength:9.9968 | embedNormMean:14.2959 | embedNormStd:10.0801 | embedNormMax:103.7186 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0005 | logitWeightNormMean:91.9376 | logitWeightNormStd:2.5135 | logitWeightNormMax:104.7800 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0018 | logitBiasMean:-34.1465 | logitBiasStd:11.9639 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7366 | n_weightMax:4.8461 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6025 | n_weightNormMin:21.6245 | n_weightNormMax:41.2379 | n_biasesMean:-1.0608 | n_biasesStd:0.7960 | n_biasesMin:-3.8485 | n_biasesMax:1.9580 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5512 | INN_cerebellumStd:4.8883 | windowWeightsW24:4.96982 (0.98), W28:1.14632 (0.02), W32:-1.92112 (0.00), W20:-2.02462 (0.00), W16:-3.45382 (0.00), W12:-4.73911 (0.00), W8:-5.95787 (0.00), W4:-9.16195 (0.00), W2:-10.81800 (0.00) | topTokens[(',', 2469), ('Ġi', 1710), ('Ġyou', 1155), ('!', 894), ('Ġwas', 878), ('Ġand', 846), ('Ġbe', 763), ('Ġthe', 724), ('Ġto', 711), ('Ġit', 700)] | cheekyAvg: 9.07687614440918 | perfectTokens: 183 / 32000 → 0.57% |  | remainingTokens: 649359 (99.85%) | TUTOR.py 500
2025-04-22 21:47:08 | 1500 | LR0.00035 | sampledTokens:66.0000 | scheduledSamplingRate:0.0050 | repetitionPenalty:1.2954 | AvgLoss:7.7563 | loss:8.3097 | temperature:0.8004 | lR:0.0003 | gradientClip:1.0003 | latestLossDelta:1.0888 | memoryLength:9.9956 | embedNormMean:14.2959 | embedNormStd:10.0801 | embedNormMax:103.7186 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0004 | logitWeightNormMean:91.9376 | logitWeightNormStd:2.5134 | logitWeightNormMax:104.7800 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0016 | logitBiasMean:-34.1465 | logitBiasStd:11.9639 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7363 | n_weightMax:4.8461 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6025 | n_weightNormMin:21.6258 | n_weightNormMax:41.2388 | n_biasesMean:-1.0608 | n_biasesStd:0.7960 | n_biasesMin:-3.8484 | n_biasesMax:1.9579 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5511 | INN_cerebellumStd:4.8883 | windowWeightsW24:4.96967 (0.98), W28:1.14646 (0.02), W32:-1.92098 (0.00), W20:-2.02459 (0.00), W16:-3.45377 (0.00), W12:-4.73902 (0.00), W8:-5.95778 (0.00), W4:-9.16189 (0.00), W2:-10.81798 (0.00) | topTokens[(',', 4016), ('Ġi', 2319), ('Ġyou', 1765), ('!', 1476), ('Ġand', 1227), ('Ġa', 1123), ('Ġto', 1047), ('Ġit', 1044), ('.', 1014), ('Ġthe', 1011)] | cheekyAvg: 7.4888699340820315 | perfectTokens: 259 / 32000 → 0.81% |  | remainingTokens: 648859 (99.77%) | TUTOR.py 500
2025-04-22 21:50:03 | 2000 | LR0.00035 | sampledTokens:94.0000 | scheduledSamplingRate:0.0064 | repetitionPenalty:1.2938 | AvgLoss:7.6043 | loss:7.9341 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0003 | latestLossDelta:0.4845 | memoryLength:9.9986 | embedNormMean:14.2959 | embedNormStd:10.0801 | embedNormMax:103.7187 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0003 | logitWeightNormMean:91.9376 | logitWeightNormStd:2.5134 | logitWeightNormMax:104.7800 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1465 | logitBiasStd:11.9639 | logitBiasMax:-13.1838 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7359 | n_weightMax:4.8460 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6025 | n_weightNormMin:21.6273 | n_weightNormMax:41.2414 | n_biasesMean:-1.0608 | n_biasesStd:0.7960 | n_biasesMin:-3.8480 | n_biasesMax:1.9576 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5511 | INN_cerebellumStd:4.8882 | windowWeightsW24:4.96957 (0.98), W28:1.14656 (0.02), W32:-1.92085 (0.00), W20:-2.02462 (0.00), W16:-3.45379 (0.00), W12:-4.73902 (0.00), W8:-5.95778 (0.00), W4:-9.16187 (0.00), W2:-10.81797 (0.00) | topTokens[(',', 5731), ('Ġi', 2857), ('Ġyou', 2477), ('!', 1944), ('Ġa', 1706), ('.', 1689), ('Ġand', 1583), ('Ġto', 1488), ('Ġthe', 1442), ('Ġit', 1348)] | cheekyAvg: 7.413384342193604 | perfectTokens: 276 / 32000 → 0.86% |  | remainingTokens: 648359 (99.69%) | TUTOR.py 500
2025-04-22 21:52:48 | 2500 | LR0.00035 | sampledTokens:125.0000 | scheduledSamplingRate:0.0081 | repetitionPenalty:1.2923 | AvgLoss:7.5836 | loss:7.7822 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0002 | latestLossDelta:0.5543 | memoryLength:9.9960 | embedNormMean:14.2959 | embedNormStd:10.0801 | embedNormMax:103.7187 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0002 | logitWeightNormMean:91.9376 | logitWeightNormStd:2.5134 | logitWeightNormMax:104.7800 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1465 | logitBiasStd:11.9639 | logitBiasMax:-13.1836 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7355 | n_weightMax:4.8458 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6025 | n_weightNormMin:21.6292 | n_weightNormMax:41.2431 | n_biasesMean:-1.0608 | n_biasesStd:0.7960 | n_biasesMin:-3.8476 | n_biasesMax:1.9574 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5511 | INN_cerebellumStd:4.8882 | windowWeightsW24:4.96946 (0.98), W28:1.14667 (0.02), W32:-1.92072 (0.00), W20:-2.02453 (0.00), W16:-3.45373 (0.00), W12:-4.73893 (0.00), W8:-5.95769 (0.00), W4:-9.16185 (0.00), W2:-10.81797 (0.00) | topTokens[(',', 7122), ('Ġi', 3307), ('Ġyou', 3077), ('!', 2427), ('Ġa', 2394), ('.', 2222), ('Ġto', 1906), ('Ġthe', 1864), ('Ġand', 1835), ('Ġit', 1640)] | cheekyAvg: 7.429417247772217 | perfectTokens: 286 / 32000 → 0.89% |  | remainingTokens: 647859 (99.62%) | TUTOR.py 500
2025-04-22 21:55:34 | 3000 | LR0.00035 | sampledTokens:127.0000 | scheduledSamplingRate:0.0096 | repetitionPenalty:1.2911 | AvgLoss:7.3655 | loss:6.5009 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0005 | latestLossDelta:-0.5740 | memoryLength:9.9964 | embedNormMean:14.2959 | embedNormStd:10.0801 | embedNormMax:103.7187 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0003 | logitWeightNormMean:91.9376 | logitWeightNormStd:2.5134 | logitWeightNormMax:104.7800 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1465 | logitBiasStd:11.9639 | logitBiasMax:-13.1835 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7353 | n_weightMax:4.8455 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6025 | n_weightNormMin:21.6308 | n_weightNormMax:41.2440 | n_biasesMean:-1.0608 | n_biasesStd:0.7960 | n_biasesMin:-3.8472 | n_biasesMax:1.9572 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5510 | INN_cerebellumStd:4.8882 | windowWeightsW24:4.96938 (0.98), W28:1.14678 (0.02), W32:-1.92055 (0.00), W20:-2.02454 (0.00), W16:-3.45375 (0.00), W12:-4.73895 (0.00), W8:-5.95773 (0.00), W4:-9.16189 (0.00), W2:-10.81799 (0.00) | topTokens[(',', 8541), ('Ġi', 3777), ('Ġyou', 3456), ('Ġa', 2963), ('!', 2854), ('.', 2661), ('Ġthe', 2349), ('Ġand', 2290), ('Ġto', 2275), ('Ġhave', 2075)] | cheekyAvg: 7.121820545196533 | perfectTokens: 335 / 32000 → 1.05% |  | remainingTokens: 647359 (99.54%) | TUTOR.py 500
2025-04-22 21:58:18 | 3500 | LR0.00035 | sampledTokens:170.0000 | scheduledSamplingRate:0.0115 | repetitionPenalty:1.2893 | AvgLoss:7.6239 | loss:6.3724 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:-0.5492 | memoryLength:9.9966 | embedNormMean:14.2959 | embedNormStd:10.0801 | embedNormMax:103.7187 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0002 | logitWeightNormMean:91.9376 | logitWeightNormStd:2.5134 | logitWeightNormMax:104.7800 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1465 | logitBiasStd:11.9639 | logitBiasMax:-13.1833 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7350 | n_weightMax:4.8454 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6025 | n_weightNormMin:21.6320 | n_weightNormMax:41.2469 | n_biasesMean:-1.0608 | n_biasesStd:0.7960 | n_biasesMin:-3.8470 | n_biasesMax:1.9569 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5510 | INN_cerebellumStd:4.8882 | windowWeightsW24:4.96933 (0.98), W28:1.14682 (0.02), W32:-1.92044 (0.00), W20:-2.02448 (0.00), W16:-3.45375 (0.00), W12:-4.73892 (0.00), W8:-5.95769 (0.00), W4:-9.16187 (0.00), W2:-10.81799 (0.00) | topTokens[(',', 10441), ('Ġi', 4104), ('Ġyou', 3936), ('Ġa', 3418), ('!', 3252), ('.', 3194), ('Ġhave', 3010), ('Ġto', 2688), ('Ġthe', 2638), ('Ġand', 2622)] | cheekyAvg: 7.397532215118408 | perfectTokens: 373 / 32000 → 1.17% |  | remainingTokens: 646859 (99.46%) | TUTOR.py 500
2025-04-22 22:01:06 | 4000 | LR0.00035 | sampledTokens:192.0000 | scheduledSamplingRate:0.0127 | repetitionPenalty:1.2876 | AvgLoss:7.6829 | loss:8.2291 | temperature:0.8002 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:0.2519 | memoryLength:9.9964 | embedNormMean:14.2959 | embedNormStd:10.0801 | embedNormMax:103.7187 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0003 | logitWeightNormMean:91.9376 | logitWeightNormStd:2.5134 | logitWeightNormMax:104.7800 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1465 | logitBiasStd:11.9639 | logitBiasMax:-13.1832 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7348 | n_weightMax:4.8453 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6026 | n_weightNormMin:21.6329 | n_weightNormMax:41.2498 | n_biasesMean:-1.0608 | n_biasesStd:0.7960 | n_biasesMin:-3.8466 | n_biasesMax:1.9565 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5510 | INN_cerebellumStd:4.8882 | windowWeightsW24:4.96923 (0.98), W28:1.14692 (0.02), W32:-1.92027 (0.00), W20:-2.02445 (0.00), W16:-3.45375 (0.00), W12:-4.73892 (0.00), W8:-5.95772 (0.00), W4:-9.16184 (0.00), W2:-10.81800 (0.00) | topTokens[(',', 12006), ('Ġi', 4607), ('Ġyou', 4291), ('Ġhave', 4108), ('Ġa', 3759), ('.', 3651), ('!', 3587), ('Ġto', 3026), ('Ġand', 3001), ('Ġthe', 2957)] | cheekyAvg: 7.548706855773926 | perfectTokens: 317 / 32000 → 0.99% |  | remainingTokens: 646359 (99.38%) | TUTOR.py 500
--- 2025-04-22 22:03:35 --- 
[babyllm] right, last time i got to step 48918... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 48918! what am i learning today?
[charis]2025-04-22 22:15:49 | 2000 | LR0.00035 | loss:11.0906 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0070 | repetitionPenalty:1.2937 | AvgLoss:10.5443 | temperature:0.8003 | lR:0.0003 | gradientClip:1.0004 | latestLossDelta:0.8252 | memoryLength:9.9920 | embedNormMean:14.2963 | embedNormStd:10.0801 | embedNormMax:103.7187 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.8156 | logitWeightNormMean:91.9376 | logitWeightNormStd:2.5132 | logitWeightNormMax:104.7809 | logitWeightSparsity:0.0000 | logitWeightDrift:2.0588 | logitBiasMean:-34.1475 | logitBiasStd:11.9636 | logitBiasMax:-13.1834 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7344 | n_weightMax:4.8447 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6024 | n_weightNormMin:21.6322 | n_weightNormMax:41.2477 | n_biasesMean:-1.0608 | n_biasesStd:0.7960 | n_biasesMin:-3.8462 | n_biasesMax:1.9564 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5509 | INN_cerebellumStd:4.8883 | sampledTokens:224.0000 | windowWeightsW24:4.96878 (0.98), W28:1.14735 (0.02), W32:-1.91970 (0.00), W20:-2.02440 (0.00), W16:-3.45375 (0.00), W12:-4.73889 (0.00), W8:-5.95761 (0.00), W4:-9.16177 (0.00), W2:-10.81800 (0.00) | topTokens[(',', 6109), ('Ġyou', 2423), ('Ġi', 2421), ('s', 2250), ('.', 2187), ('Ġa', 2109), ('Ġto', 1748), ('Ġthe', 1710), ('Ġit', 1435), ('!', 1379)] | cheekyAvg: 10.32048488843559 | perfectTokens: 1010 / 128000 → 0.79% |  | remainingTokens: 643965 (99.69%) | TUTOR.py 2000
2025-04-22 22:26:52 | 4000 | LR0.00035 | sampledTokens:683.0000 | scheduledSamplingRate:0.0143 | repetitionPenalty:1.2870 | AvgLoss:9.8135 | loss:8.8748 | temperature:0.8008 | lR:0.0003 | gradientClip:1.0010 | latestLossDelta:-1.3268 | memoryLength:9.9968 | embedNormMean:14.2963 | embedNormStd:10.0801 | embedNormMax:103.7178 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0006 | logitWeightNormMean:91.9376 | logitWeightNormStd:2.5132 | logitWeightNormMax:104.7809 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0022 | logitBiasMean:-34.1475 | logitBiasStd:11.9635 | logitBiasMax:-13.1836 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9675 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7344 | n_weightMax:4.8445 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6026 | n_weightNormMin:21.6292 | n_weightNormMax:41.2469 | n_biasesMean:-1.0608 | n_biasesStd:0.7960 | n_biasesMin:-3.8462 | n_biasesMax:1.9565 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5508 | INN_cerebellumStd:4.8881 | windowWeightsW24:4.96872 (0.98), W28:1.14743 (0.02), W32:-1.91949 (0.00), W20:-2.02433 (0.00), W16:-3.45379 (0.00), W12:-4.73879 (0.00), W8:-5.95751 (0.00), W4:-9.16168 (0.00), W2:-10.81800 (0.00) | topTokens[(',', 13546), ('Ġi', 5835), ('.', 4692), ('Ġyou', 4497), ('Ġthe', 3661), ('Ġa', 3435), ('s', 3426), ('Ġto', 3391), ('Ġand', 3126), ('!', 3023)] | cheekyAvg: 9.728766441345215 | perfectTokens: 1302 / 128000 → 1.02% |  | remainingTokens: 641965 (99.38%) | TUTOR.py 2000
2025-04-22 22:38:08 | 6000 | LR0.00035 | sampledTokens:1219.0000 | scheduledSamplingRate:0.0219 | repetitionPenalty:1.2803 | AvgLoss:9.4627 | loss:9.5282 | temperature:0.8004 | lR:0.0003 | gradientClip:1.0007 | latestLossDelta:1.9114 | memoryLength:9.9998 | embedNormMean:14.2963 | embedNormStd:10.0801 | embedNormMax:103.7178 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0006 | logitWeightNormMean:91.9376 | logitWeightNormStd:2.5130 | logitWeightNormMax:104.7809 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0020 | logitBiasMean:-34.1475 | logitBiasStd:11.9635 | logitBiasMax:-13.1849 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7343 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6028 | n_weightNormMin:21.6250 | n_weightNormMax:41.2474 | n_biasesMean:-1.0608 | n_biasesStd:0.7961 | n_biasesMin:-3.8459 | n_biasesMax:1.9565 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5508 | INN_cerebellumStd:4.8881 | windowWeightsW24:4.96836 (0.98), W28:1.14780 (0.02), W32:-1.91896 (0.00), W20:-2.02426 (0.00), W16:-3.45367 (0.00), W12:-4.73867 (0.00), W8:-5.95738 (0.00), W4:-9.16155 (0.00), W2:-10.81795 (0.00) | topTokens[(',', 20894), ('Ġi', 9156), ('Ġyou', 7460), ('.', 7045), ('Ġthe', 5468), ('Ġto', 5031), ('Ġa', 4865), ('s', 4668), ('Ġand', 4601), ('!', 4531)] | cheekyAvg: 9.471744446754455 | perfectTokens: 1236 / 128000 → 0.97% |  | remainingTokens: 639965 (99.07%) | TUTOR.py 2000
2025-04-22 22:49:11 | 8000 | LR0.00035 | sampledTokens:1608.0000 | scheduledSamplingRate:0.0287 | repetitionPenalty:1.2733 | AvgLoss:10.7313 | loss:10.5654 | temperature:0.8003 | lR:0.0003 | gradientClip:1.0010 | latestLossDelta:4.7006 | memoryLength:10.0006 | embedNormMean:14.2964 | embedNormStd:10.0801 | embedNormMax:103.7176 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0006 | logitWeightNormMean:91.9376 | logitWeightNormStd:2.5130 | logitWeightNormMax:104.7809 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0022 | logitBiasMean:-34.1475 | logitBiasStd:11.9635 | logitBiasMax:-13.1850 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9539 | longDecay:0.9675 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7344 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6044 | n_weightNormMin:21.6194 | n_weightNormMax:41.2467 | n_biasesMean:-1.0609 | n_biasesStd:0.7961 | n_biasesMin:-3.8454 | n_biasesMax:1.9566 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5507 | INN_cerebellumStd:4.8881 | windowWeightsW24:4.96795 (0.98), W28:1.14823 (0.02), W32:-1.91844 (0.00), W20:-2.02423 (0.00), W16:-3.45376 (0.00), W12:-4.73877 (0.00), W8:-5.95743 (0.00), W4:-9.16164 (0.00), W2:-10.81798 (0.00) | topTokens[(',', 28396), ('Ġi', 12162), ('Ġyou', 9588), ('.', 8540), ('Ġthe', 7840), ('Ġto', 6341), ('Ġa', 6289), ('Ġand', 6070), ('s', 6022), ('!', 5665)] | cheekyAvg: 10.627104592323303 | perfectTokens: 971 / 128000 → 0.76% |  | remainingTokens: 637965 (98.76%) | TUTOR.py 2000
--- 2025-04-22 22:54:48 --- 
[babyllm] right, last time i got to step 57894... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 57894! what am i learning today?
[charis]--- 2025-04-22 22:54:58 --- 
[babyllm] right, last time i got to step 57894... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 57894! what am i learning today?
[charis]i unsoftmaxed the cerebellum window weight2025-04-22 23:07:06 | 2000 | LR0.00035 | loss:241.9247 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0067 | repetitionPenalty:1.2930 | AvgLoss:396.4404 | temperature:0.8007 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:149.5205 | memoryLength:10.0096 | embedNormMean:14.2967 | embedNormStd:10.0802 | embedNormMax:103.7175 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.8160 | logitWeightNormMean:91.9376 | logitWeightNormStd:2.5127 | logitWeightNormMax:104.7660 | logitWeightSparsity:0.0000 | logitWeightDrift:2.0582 | logitBiasMean:-34.1456 | logitBiasStd:11.9635 | logitBiasMax:-13.1847 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9538 | longDecay:0.9676 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7343 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6044 | n_weightNormMin:21.6118 | n_weightNormMax:41.2498 | n_biasesMean:-1.0609 | n_biasesStd:0.7961 | n_biasesMin:-3.8452 | n_biasesMax:1.9564 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5492 | INN_cerebellumStd:4.8879 | sampledTokens:232.0000 | windowWeightsW24:4.97005 (0.98), W28:1.15106 (0.02), W32:-1.91558 (0.00), W20:-2.02168 (0.00), W16:-3.45117 (0.00), W12:-4.73622 (0.00), W8:-5.95502 (0.00), W4:-9.15898 (0.00), W2:-10.81437 (0.00) | topTokens[('Ġlmao', 16357), ('Ġdiscord', 16227), ('using', 11088), ('ping', 3711), ('igh', 2500), ('Ġhaha', 1044), ('Ġtest', 950), ('Ġhealth', 893), ('not', 867), ('Ġasleep', 834)] | cheekyAvg: 414.5889925815091 | perfectTokens: 14 / 128000 → 0.01% |  | remainingTokens: 634989 (99.69%) | TUTOR.py 2000
2025-04-22 23:17:59 | 4000 | LR0.00035 | sampledTokens:642.0000 | scheduledSamplingRate:0.0131 | repetitionPenalty:1.2858 | AvgLoss:194.4562 | loss:96.5792 | temperature:0.8005 | lR:0.0003 | gradientClip:1.0007 | latestLossDelta:124.6559 | memoryLength:10.0064 | embedNormMean:14.2967 | embedNormStd:10.0802 | embedNormMax:103.7178 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0004 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5123 | logitWeightNormMax:104.7488 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1456 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7344 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6046 | n_weightNormMin:21.6066 | n_weightNormMax:41.2503 | n_biasesMean:-1.0610 | n_biasesStd:0.7961 | n_biasesMin:-3.8448 | n_biasesMax:1.9559 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5474 | INN_cerebellumStd:4.8880 | windowWeightsW24:4.97118 (0.98), W28:1.15213 (0.02), W32:-1.91443 (0.00), W20:-2.02054 (0.00), W16:-3.44997 (0.00), W12:-4.73530 (0.00), W8:-5.95446 (0.00), W4:-9.15915 (0.00), W2:-10.81285 (0.00) | topTokens[('Ġlmao', 31425), ('Ġdiscord', 27122), ('using', 20222), ('ping', 6229), ('igh', 5768), ('Ġhaha', 2614), ('Ġguys', 1803), ('Ġtest', 1750), ('not', 1742), ('Ġasleep', 1711)] | cheekyAvg: 188.09986499786376 | perfectTokens: 7 / 128000 → 0.01% |  | remainingTokens: 632989 (99.37%) | TUTOR.py 2000
2025-04-22 23:29:01 | 6000 | LR0.00035 | sampledTokens:1027.0000 | scheduledSamplingRate:0.0192 | repetitionPenalty:1.2796 | AvgLoss:155.7529 | loss:63.0248 | temperature:0.8005 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:286.2468 | memoryLength:10.0018 | embedNormMean:14.2968 | embedNormStd:10.0803 | embedNormMax:103.7178 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0003 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5120 | logitWeightNormMax:104.7359 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1456 | logitBiasStd:11.9642 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7343 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6046 | n_weightNormMin:21.6035 | n_weightNormMax:41.2507 | n_biasesMean:-1.0610 | n_biasesStd:0.7961 | n_biasesMin:-3.8444 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5469 | INN_cerebellumStd:4.8881 | windowWeightsW24:4.97161 (0.98), W28:1.15270 (0.02), W32:-1.91381 (0.00), W20:-2.02012 (0.00), W16:-3.44969 (0.00), W12:-4.73511 (0.00), W8:-5.95492 (0.00), W4:-9.15960 (0.00), W2:-10.81173 (0.00) | topTokens[('Ġlmao', 42149), ('Ġdiscord', 33525), ('using', 28676), ('igh', 9641), ('ping', 7934), ('Ġhaha', 4739), ('Ġguys', 3345), ('not', 2631), ('Ġhar', 2572), ('Ġasleep', 2446)] | cheekyAvg: 95.39233379364013 | perfectTokens: 15 / 128000 → 0.01% |  | remainingTokens: 630989 (99.06%) | TUTOR.py 2000
2025-04-22 23:40:08 | 8000 | LR0.00035 | sampledTokens:1504.0000 | scheduledSamplingRate:0.0257 | repetitionPenalty:1.2726 | AvgLoss:149.6208 | loss:58.2551 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9994 | latestLossDelta:667.3481 | memoryLength:10.0030 | embedNormMean:14.2968 | embedNormStd:10.0807 | embedNormMax:103.7184 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0003 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5118 | logitWeightNormMax:104.7207 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1456 | logitBiasStd:11.9642 | logitBiasMax:-13.1839 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7343 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6046 | n_weightNormMin:21.6020 | n_weightNormMax:41.2512 | n_biasesMean:-1.0610 | n_biasesStd:0.7961 | n_biasesMin:-3.8441 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5466 | INN_cerebellumStd:4.8882 | windowWeightsW24:4.97207 (0.98), W28:1.15323 (0.02), W32:-1.91324 (0.00), W20:-2.01975 (0.00), W16:-3.44944 (0.00), W12:-4.73509 (0.00), W8:-5.95561 (0.00), W4:-9.16016 (0.00), W2:-10.81080 (0.00) | topTokens[('Ġlmao', 50949), ('Ġdiscord', 40438), ('using', 37980), ('igh', 13416), ('ping', 9624), ('Ġhaha', 6970), ('Ġguys', 4796), ('not', 3432), ('Ġhar', 3296), ('Ġter', 3185)] | cheekyAvg: 76.37398235321045 | perfectTokens: 12 / 128000 → 0.01% |  | remainingTokens: 628989 (98.74%) | TUTOR.py 2000
2025-04-22 23:51:21 | 10000 | LR0.00035 | sampledTokens:1917.0000 | scheduledSamplingRate:0.0331 | repetitionPenalty:1.2662 | AvgLoss:141.5667 | loss:222.9390 | temperature:0.7997 | lR:0.0003 | gradientClip:0.9990 | latestLossDelta:706.1256 | memoryLength:10.0014 | embedNormMean:14.2968 | embedNormStd:10.0807 | embedNormMax:103.7185 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0003 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5117 | logitWeightNormMax:104.7048 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1456 | logitBiasStd:11.9643 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7341 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6046 | n_weightNormMin:21.5981 | n_weightNormMax:41.2525 | n_biasesMean:-1.0610 | n_biasesStd:0.7962 | n_biasesMin:-3.8437 | n_biasesMax:1.9555 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8884 | windowWeightsW24:4.97251 (0.98), W28:1.15379 (0.02), W32:-1.91260 (0.00), W20:-2.01931 (0.00), W16:-3.44909 (0.00), W12:-4.73498 (0.00), W8:-5.95641 (0.00), W4:-9.16097 (0.00), W2:-10.80988 (0.00) | topTokens[('Ġlmao', 60761), ('using', 46504), ('Ġdiscord', 45788), ('igh', 16771), ('ping', 11513), ('Ġhaha', 9324), ('Ġguys', 6313), ('not', 4175), ('Ġhar', 4036), ('Ġter', 3960)] | cheekyAvg: 67.39690483093261 | perfectTokens: 14 / 128000 → 0.01% |  | remainingTokens: 626989 (98.43%) | TUTOR.py 2000
--- 2025-04-22 23:53:00 --- 
[babyllm] right, last time i got to step 68164... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 68164! what am i learning today?
[charis]2025-04-23 00:04:56 | 2000 | LR0.00035 | loss:100.2983 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0074 | repetitionPenalty:1.2936 | AvgLoss:70.6834 | temperature:0.8003 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:0.0000 | memoryLength:9.9998 | embedNormMean:14.2968 | embedNormStd:10.0807 | embedNormMax:103.7187 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.8156 | logitWeightNormMean:91.9375 | logitWeightNormStd:2.5114 | logitWeightNormMax:104.6891 | logitWeightSparsity:0.0000 | logitWeightDrift:2.0579 | logitBiasMean:-34.1456 | logitBiasStd:11.9643 | logitBiasMax:-13.1837 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7340 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6046 | n_weightNormMin:21.5912 | n_weightNormMax:41.2546 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8431 | n_biasesMax:1.9553 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5465 | INN_cerebellumStd:4.8886 | sampledTokens:227.0000 | windowWeightsW4:4.97264 (0.98), W4:1.15393 (0.02), W12:-1.91303 (0.00), W12:-2.01976 (0.00), W16:-3.44967 (0.00), W24:-4.73552 (0.00), W24:-5.95704 (0.00), W32:-9.16124 (0.00), W32:-10.80983 (0.00) | topTokens[('Ġlmao', 12977), ('using', 5717), ('ping', 4636), ("'t", 4399), ('Ġmind', 3308), ('Ġdiscord', 2369), ('Ġsmo', 1237), ('Ġ4', 1118), ('ion', 882), ('g', 689)] | cheekyAvg: 70.66289094088972 | perfectTokens: 100 / 128000 → 0.08% |  | remainingTokens: 624719 (99.68%) | TUTOR.py 2000
2025-04-23 00:16:06 | 4000 | LR0.00035 | sampledTokens:700.0000 | scheduledSamplingRate:0.0136 | repetitionPenalty:1.2875 | AvgLoss:78.0710 | loss:99.0554 | temperature:0.8005 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:90.6625 | memoryLength:9.9994 | embedNormMean:14.2969 | embedNormStd:10.0808 | embedNormMax:103.7187 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:0.0003 | logitWeightNormMean:91.9374 | logitWeightNormStd:2.5113 | logitWeightNormMax:104.6755 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1455 | logitBiasStd:11.9643 | logitBiasMax:-13.1837 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7338 | n_weightMax:4.8444 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6052 | n_weightNormMin:21.5869 | n_weightNormMax:41.2553 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8425 | n_biasesMax:1.9553 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5465 | INN_cerebellumStd:4.8886 | windowWeightsW4:4.97278 (0.98), W4:1.15411 (0.02), W12:-1.91300 (0.00), W12:-2.01973 (0.00), W16:-3.44981 (0.00), W24:-4.73552 (0.00), W24:-5.95704 (0.00), W32:-9.16113 (0.00), W32:-10.80973 (0.00) | topTokens[('Ġlmao', 21198), ('using', 16576), ('ping', 9393), ("'t", 6782), ('Ġmind', 5697), ('Ġdiscord', 4692), ('Ġ4', 2400), ('Ġ:)', 1931), ('Ġsmo', 1747), ('ion', 1609)] | cheekyAvg: 78.07042123246192 | perfectTokens: 85 / 128000 → 0.07% |  | remainingTokens: 622719 (99.36%) | TUTOR.py 2000
--- 2025-04-23 00:18:31 --- 
[babyllm] right, last time i got to step 72572... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 72572! what am i learning today?
[charis]--- 2025-04-23 00:19:20 --- 
[babyllm] right, last time i got to step 72572... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 72572! what am i learning today?
[charis]2025-04-23 00:23:03 | 500 | LR0.00035 | loss:122.7848 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0018 | repetitionPenalty:1.2984 | AvgLoss:72.1285 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:0.0000 | memoryLength:10.0040 | embedNormMean:14.2969 | embedNormStd:10.0810 | embedNormMax:103.7187 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:3.2637 | logitWeightNormMean:91.9372 | logitWeightNormStd:2.5111 | logitWeightNormMax:104.6644 | logitWeightSparsity:0.0000 | logitWeightDrift:8.2271 | logitBiasMean:-34.1463 | logitBiasStd:11.9643 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7338 | n_weightMax:4.8444 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6045 | n_weightNormMin:21.5851 | n_weightNormMax:41.2549 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8422 | n_biasesMax:1.9554 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5465 | INN_cerebellumStd:4.8886 | sampledTokens:15.0000 | windowWeightsW0:4.97290 (0.98), W4:1.15426 (0.02), W12:-1.91301 (0.00), W12:-2.01975 (0.00), W16:-3.44984 (0.00), W24:-4.73547 (0.00), W24:-5.95700 (0.00), W32:-9.16105 (0.00), W32:-10.80965 (0.00) | topTokens[('using', 2224), ('ping', 1673), ('Ġlmao', 1663), ('Ġdiscord', 908), ('Ġmind', 559), ('ion', 468), ('Ġ:)', 457), ('Ġ:', 432), ("'t", 400), ('Ġ3', 350)] | cheekyAvg: 72.0856081187844 | perfectTokens: 21 / 32000 → 0.07% |  | remainingTokens: 621811 (99.92%) | TUTOR.py 500
--- 2025-04-23 00:24:17 --- 
[babyllm] right, last time i got to step 73225... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 73225! what am i learning today?
[charis]2025-04-23 00:28:01 | 500 | LR0.00035 | loss:77.6665 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0015 | repetitionPenalty:1.2988 | AvgLoss:85.4083 | temperature:0.7997 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:0.0000 | memoryLength:9.9976 | embedNormMean:14.2969 | embedNormStd:10.0810 | embedNormMax:103.7187 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0020 | embeddingDrift:3.2605 | logitWeightNormMean:91.9372 | logitWeightNormStd:2.5110 | logitWeightNormMax:104.6607 | logitWeightSparsity:0.0000 | logitWeightDrift:8.2271 | logitBiasMean:-34.1463 | logitBiasStd:11.9643 | logitBiasMax:-13.1837 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7337 | n_weightMax:4.8444 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6045 | n_weightNormMin:21.5842 | n_weightNormMax:41.2553 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8419 | n_biasesMax:1.9554 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5465 | INN_cerebellumStd:4.8886 | sampledTokens:17.0000 | windowWeightsW0:4.97292 (0.98), W0:1.15426 (0.02), W0:-1.91305 (0.00), W0:-2.01978 (0.00), W0:-3.44989 (0.00), W0:-4.73548 (0.00), W0:-5.95701 (0.00), W0:-9.16103 (0.00), W0:-10.80962 (0.00) | topTokens[('using', 3568), ('Ġlmao', 1420), ('ping', 698), ('Ġdiscord', 664), ("'t", 584), ('Ġguys', 542), ('Ġmind', 490), ('Ġxd', 282), ('Ġwanna', 249), ('Ġwill', 237)] | cheekyAvg: 85.22234766116875 | perfectTokens: 28 / 32000 → 0.09% |  | remainingTokens: 621158 (99.92%) | TUTOR.py 500
--- 2025-04-23 00:29:37 --- 
[babyllm] right, last time i got to step 73988... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 73988! what am i learning today?
[charis]--- 2025-04-23 00:32:30 --- 
[babyllm] right, last time i got to step 74260... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 74260! what am i learning today?
[charis]2025-04-23 00:34:02 | 100 | LR0.00035 | loss:84.9151 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0005 | repetitionPenalty:1.2996 | AvgLoss:84.6751 | temperature:0.8001 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:0.0000 | memoryLength:9.9968 | embedNormMean:14.2969 | embedNormStd:10.0810 | embedNormMax:103.7187 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:16.3165 | logitWeightNormMean:91.9365 | logitWeightNormStd:2.5109 | logitWeightNormMax:104.6547 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1314 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1838 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7337 | n_weightMax:4.8444 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5824 | n_weightNormMax:41.2559 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8416 | n_biasesMax:1.9555 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5465 | INN_cerebellumStd:4.8886 | sampledTokens:1.0000 | windowWeightsW-1:4.97296 (0.98), W4:1.15429 (0.02), W8:-1.91303 (0.00), W16:-2.01979 (0.00), W24:-3.44989 (0.00), W32:-4.73545 (0.00), W-1:-5.95697 (0.00), W-1:-9.16098 (0.00), W-1:-10.80957 (0.00) | topTokens[('using', 758), ('Ġlmao', 367), ("'t", 181), ('Ġhaha', 134), ('Ġdiscord', 134), ('Ġmind', 86), ('hh', 71), ('Ġtouch', 70), ('ping', 66), ('ack', 58)] | cheekyAvg: 83.83908987517404 | perfectTokens: 2 / 6400 → 0.03% |  | remainingTokens: 620523 (99.98%) | TUTOR.py 100
2025-04-23 00:34:35 | 200 | LR0.00035 | sampledTokens:1.0000 | scheduledSamplingRate:0.0008 | repetitionPenalty:1.2993 | AvgLoss:55.9065 | loss:72.6626 | temperature:0.8000 | lR:0.0003 | gradientClip:0.9995 | latestLossDelta:106.3572 | memoryLength:9.9964 | embedNormMean:14.2969 | embedNormStd:10.0810 | embedNormMax:103.7187 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0002 | logitWeightNormMean:91.9365 | logitWeightNormStd:2.5109 | logitWeightNormMax:104.6537 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0009 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1838 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8444 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5823 | n_weightNormMax:41.2559 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8416 | n_biasesMax:1.9555 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5465 | INN_cerebellumStd:4.8886 | windowWeightsW-1:4.97299 (0.98), W4:1.15429 (0.02), W8:-1.91306 (0.00), W16:-2.01977 (0.00), W24:-3.44986 (0.00), W32:-4.73542 (0.00), W-1:-5.95693 (0.00), W-1:-9.16095 (0.00), W-1:-10.80954 (0.00) | topTokens[('using', 1267), ('Ġlmao', 709), ("'t", 532), ('ping', 348), ('Ġdiscord', 249), ('Ġmind', 210), ('ack', 154), ('Ġhaha', 134), ('Ġhear', 87), ('Ġtaking', 86)] | cheekyAvg: 55.78394233703613 | perfectTokens: 2 / 6400 → 0.03% |  | remainingTokens: 620423 (99.97%) | TUTOR.py 100
2025-04-23 00:35:07 | 300 | LR0.00035 | sampledTokens:2.0000 | scheduledSamplingRate:0.0011 | repetitionPenalty:1.2989 | AvgLoss:78.6261 | loss:100.0078 | temperature:0.8002 | lR:0.0003 | gradientClip:0.9994 | latestLossDelta:242.3354 | memoryLength:9.9966 | embedNormMean:14.2969 | embedNormStd:10.0810 | embedNormMax:103.7187 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0003 | logitWeightNormMean:91.9365 | logitWeightNormStd:2.5109 | logitWeightNormMax:104.6533 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1838 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8445 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5824 | n_weightNormMax:41.2559 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8416 | n_biasesMax:1.9555 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5465 | INN_cerebellumStd:4.8886 | windowWeightsW-1:4.97302 (0.98), W4:1.15433 (0.02), W8:-1.91305 (0.00), W16:-2.01975 (0.00), W24:-3.44984 (0.00), W32:-4.73540 (0.00), W-1:-5.95690 (0.00), W-1:-9.16093 (0.00), W-1:-10.80952 (0.00) | topTokens[('using', 1911), ('Ġlmao', 711), ('ping', 640), ("'t", 563), ('Ġdiscord', 467), ('ack', 324), ('Ġmind', 287), ('Ġomg', 203), ('Ġtouch', 136), ('Ġter', 135)] | cheekyAvg: 78.89952065467834 | perfectTokens: 1 / 6400 → 0.02% |  | remainingTokens: 620323 (99.95%) | TUTOR.py 100
2025-04-23 00:35:40 | 400 | LR0.00035 | sampledTokens:4.0000 | scheduledSamplingRate:0.0014 | repetitionPenalty:1.2987 | AvgLoss:81.8952 | loss:52.4082 | temperature:0.8002 | lR:0.0003 | gradientClip:0.9994 | latestLossDelta:78.6622 | memoryLength:9.9954 | embedNormMean:14.2969 | embedNormStd:10.0810 | embedNormMax:103.7187 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9365 | logitWeightNormStd:2.5109 | logitWeightNormMax:104.6533 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1838 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8445 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5823 | n_weightNormMax:41.2559 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8415 | n_biasesMax:1.9555 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8886 | windowWeightsW-1:4.97304 (0.98), W4:1.15434 (0.02), W8:-1.91304 (0.00), W16:-2.01973 (0.00), W24:-3.44982 (0.00), W32:-4.73539 (0.00), W-1:-5.95688 (0.00), W-1:-9.16091 (0.00), W-1:-10.80950 (0.00) | topTokens[('using', 2114), ('ping', 1016), ('Ġdiscord', 974), ('Ġlmao', 794), ("'t", 594), ('ack', 329), ('Ġmind', 293), ('Ġomg', 235), ('Ġ:)', 201), ('Ġter', 193)] | cheekyAvg: 81.41915773391723 | perfectTokens: 1 / 6400 → 0.02% |  | remainingTokens: 620223 (99.94%) | TUTOR.py 100
2025-04-23 00:36:13 | 500 | LR0.00035 | sampledTokens:2.0000 | scheduledSamplingRate:0.0016 | repetitionPenalty:1.2985 | AvgLoss:90.0416 | loss:70.4515 | temperature:0.8002 | lR:0.0003 | gradientClip:0.9993 | latestLossDelta:225.9634 | memoryLength:9.9956 | embedNormMean:14.2969 | embedNormStd:10.0810 | embedNormMax:103.7187 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0003 | logitWeightNormMean:91.9365 | logitWeightNormStd:2.5109 | logitWeightNormMax:104.6533 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1838 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8445 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5823 | n_weightNormMax:41.2559 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8415 | n_biasesMax:1.9555 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8886 | windowWeightsW-1:4.97306 (0.98), W4:1.15434 (0.02), W8:-1.91303 (0.00), W16:-2.01973 (0.00), W24:-3.44981 (0.00), W32:-4.73537 (0.00), W-1:-5.95686 (0.00), W-1:-9.16089 (0.00), W-1:-10.80948 (0.00) | topTokens[('using', 2249), ('Ġdiscord', 1721), ('ping', 1224), ('Ġlmao', 853), ("'t", 699), ('ack', 339), ('Ġmind', 328), ('we', 312), ('Ġomg', 275), ('Ġxd', 268)] | cheekyAvg: 90.22201984405518 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 620123 (99.92%) | TUTOR.py 100
2025-04-23 00:36:46 | 600 | LR0.00035 | sampledTokens:7.0000 | scheduledSamplingRate:0.0020 | repetitionPenalty:1.2982 | AvgLoss:74.8288 | loss:61.7425 | temperature:0.8000 | lR:0.0003 | gradientClip:0.9993 | latestLossDelta:109.2365 | memoryLength:9.9948 | embedNormMean:14.2969 | embedNormStd:10.0810 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9365 | logitWeightNormStd:2.5109 | logitWeightNormMax:104.6533 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1838 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8444 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5822 | n_weightNormMax:41.2559 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8415 | n_biasesMax:1.9555 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8886 | windowWeightsW-1:4.97309 (0.98), W4:1.15432 (0.02), W8:-1.91305 (0.00), W16:-2.01974 (0.00), W24:-3.44981 (0.00), W32:-4.73535 (0.00), W-1:-5.95684 (0.00), W-1:-9.16086 (0.00), W-1:-10.80946 (0.00) | topTokens[('using', 2578), ('Ġdiscord', 2147), ('ping', 1376), ('Ġlmao', 1153), ("'t", 868), ('ack', 446), ('Ġmind', 382), ('Ġhear', 341), ('we', 312), ('Ġmoving', 289)] | cheekyAvg: 74.74170395851135 | perfectTokens: 2 / 6400 → 0.03% |  | remainingTokens: 620023 (99.90%) | TUTOR.py 100
2025-04-23 00:37:19 | 700 | LR0.00035 | sampledTokens:8.0000 | scheduledSamplingRate:0.0022 | repetitionPenalty:1.2979 | AvgLoss:77.1060 | loss:81.6037 | temperature:0.8000 | lR:0.0003 | gradientClip:0.9993 | latestLossDelta:172.9631 | memoryLength:9.9934 | embedNormMean:14.2969 | embedNormStd:10.0810 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0003 | logitWeightNormMean:91.9365 | logitWeightNormStd:2.5109 | logitWeightNormMax:104.6527 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1838 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8444 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5822 | n_weightNormMax:41.2561 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8415 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8886 | windowWeightsW-1:4.97311 (0.98), W4:1.15433 (0.02), W8:-1.91305 (0.00), W16:-2.01973 (0.00), W24:-3.44981 (0.00), W32:-4.73533 (0.00), W-1:-5.95681 (0.00), W-1:-9.16084 (0.00), W-1:-10.80944 (0.00) | topTokens[('using', 3218), ('Ġdiscord', 2446), ('ping', 1535), ('Ġlmao', 1248), ("'t", 899), ('ack', 633), ('Ġmind', 525), ('Ġhear', 392), ('Ġmoving', 347), ('Ġter', 329)] | cheekyAvg: 77.30460768699646 | perfectTokens: 2 / 6400 → 0.03% |  | remainingTokens: 619923 (99.89%) | TUTOR.py 100
2025-04-23 00:37:52 | 800 | LR0.00035 | sampledTokens:9.0000 | scheduledSamplingRate:0.0025 | repetitionPenalty:1.2975 | AvgLoss:89.8326 | loss:48.9262 | temperature:0.8000 | lR:0.0003 | gradientClip:0.9994 | latestLossDelta:251.3889 | memoryLength:9.9928 | embedNormMean:14.2969 | embedNormStd:10.0810 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0003 | logitWeightNormMean:91.9365 | logitWeightNormStd:2.5109 | logitWeightNormMax:104.6527 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1838 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8444 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5821 | n_weightNormMax:41.2560 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8415 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8886 | windowWeightsW-1:4.97312 (0.98), W4:1.15434 (0.02), W8:-1.91306 (0.00), W16:-2.01973 (0.00), W24:-3.44981 (0.00), W32:-4.73533 (0.00), W-1:-5.95681 (0.00), W-1:-9.16084 (0.00), W-1:-10.80943 (0.00) | topTokens[('using', 3885), ('Ġdiscord', 2756), ('ping', 1700), ('Ġlmao', 1283), ("'t", 899), ('ack', 732), ('Ġhear', 619), ('Ġmind', 558), ('Ġmoving', 496), ('Ġwords', 418)] | cheekyAvg: 89.50579694747925 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 619823 (99.87%) | TUTOR.py 100
2025-04-23 00:38:24 | 900 | LR0.00035 | sampledTokens:11.0000 | scheduledSamplingRate:0.0030 | repetitionPenalty:1.2972 | AvgLoss:80.5205 | loss:76.1191 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9994 | latestLossDelta:277.5501 | memoryLength:9.9924 | embedNormMean:14.2969 | embedNormStd:10.0810 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9365 | logitWeightNormStd:2.5108 | logitWeightNormMax:104.6527 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1838 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8444 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5820 | n_weightNormMax:41.2559 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8415 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8886 | windowWeightsW-1:4.97312 (0.98), W4:1.15436 (0.02), W8:-1.91310 (0.00), W16:-2.01977 (0.00), W24:-3.44984 (0.00), W32:-4.73532 (0.00), W-1:-5.95680 (0.00), W-1:-9.16083 (0.00), W-1:-10.80942 (0.00) | topTokens[('using', 4267), ('Ġdiscord', 3063), ('ping', 1996), ('Ġlmao', 1579), ("'t", 1092), ('ack', 733), ('Ġhear', 619), ('Ġmind', 558), ('Ġmoving', 496), ('Ġwords', 427)] | cheekyAvg: 80.79239944458008 | perfectTokens: 0 / 6400 → 0.00% |  | remainingTokens: 619723 (99.85%) | TUTOR.py 100
2025-04-23 00:39:02 | 1000 | LR0.00035 | sampledTokens:10.0000 | scheduledSamplingRate:0.0034 | repetitionPenalty:1.2967 | AvgLoss:62.6768 | loss:73.3767 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9994 | latestLossDelta:264.9817 | memoryLength:9.9924 | embedNormMean:14.2969 | embedNormStd:10.0810 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9365 | logitWeightNormStd:2.5108 | logitWeightNormMax:104.6521 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0016 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1838 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5817 | n_weightNormMax:41.2556 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8415 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8886 | windowWeightsW-1:4.97313 (0.98), W4:1.15438 (0.02), W8:-1.91313 (0.00), W16:-2.01980 (0.00), W24:-3.44981 (0.00), W32:-4.73533 (0.00), W-1:-5.95679 (0.00), W-1:-9.16082 (0.00), W-1:-10.80941 (0.00) | topTokens[('using', 4621), ('Ġdiscord', 3234), ('ping', 2296), ('Ġlmao', 1920), ("'t", 1262), ('ack', 774), ('Ġhear', 730), ('Ġmind', 652), ('Ġmoving', 534), ('Ġcause', 465)] | cheekyAvg: 62.649331426620485 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 619623 (99.84%) | TUTOR.py 100
2025-04-23 00:39:40 | 1100 | LR0.00035 | sampledTokens:9.0000 | scheduledSamplingRate:0.0037 | repetitionPenalty:1.2965 | AvgLoss:54.8888 | loss:44.2693 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9993 | latestLossDelta:99.6197 | memoryLength:9.9926 | embedNormMean:14.2969 | embedNormStd:10.0810 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9365 | logitWeightNormStd:2.5108 | logitWeightNormMax:104.6519 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1838 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5818 | n_weightNormMax:41.2557 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8415 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8886 | windowWeightsW-1:4.97313 (0.98), W4:1.15442 (0.02), W8:-1.91314 (0.00), W16:-2.01980 (0.00), W24:-3.44981 (0.00), W32:-4.73534 (0.00), W-1:-5.95680 (0.00), W-1:-9.16082 (0.00), W-1:-10.80941 (0.00) | topTokens[('using', 4624), ('Ġdiscord', 3562), ('ping', 2946), ('Ġlmao', 2159), ("'t", 1363), ('ack', 774), ('Ġhear', 736), ('Ġmind', 652), ('Ġexper', 586), ('Ġmoving', 534)] | cheekyAvg: 54.59773532867432 | perfectTokens: 4 / 6400 → 0.06% |  | remainingTokens: 619523 (99.82%) | TUTOR.py 100
2025-04-23 00:40:22 | 1200 | LR0.00035 | sampledTokens:6.0000 | scheduledSamplingRate:0.0041 | repetitionPenalty:1.2963 | AvgLoss:74.9792 | loss:58.0099 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9994 | latestLossDelta:58.8079 | memoryLength:9.9956 | embedNormMean:14.2969 | embedNormStd:10.0810 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0003 | logitWeightNormMean:91.9365 | logitWeightNormStd:2.5108 | logitWeightNormMax:104.6514 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1838 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5818 | n_weightNormMax:41.2558 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8415 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8886 | windowWeightsW-1:4.97314 (0.98), W4:1.15442 (0.02), W8:-1.91316 (0.00), W16:-2.01981 (0.00), W24:-3.44981 (0.00), W32:-4.73534 (0.00), W-1:-5.95679 (0.00), W-1:-9.16081 (0.00), W-1:-10.80940 (0.00) | topTokens[('using', 4751), ('Ġdiscord', 4188), ('ping', 3204), ('Ġlmao', 2290), ("'t", 1447), ('ack', 874), ('Ġhear', 795), ('Ġexper', 694), ('Ġmind', 655), ('Ġmoving', 536)] | cheekyAvg: 75.11656562805176 | perfectTokens: 5 / 6400 → 0.08% |  | remainingTokens: 619423 (99.81%) | TUTOR.py 100
2025-04-23 00:41:07 | 1300 | LR0.00035 | sampledTokens:14.0000 | scheduledSamplingRate:0.0044 | repetitionPenalty:1.2958 | AvgLoss:70.3188 | loss:111.2724 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9994 | latestLossDelta:266.8029 | memoryLength:9.9968 | embedNormMean:14.2969 | embedNormStd:10.0810 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9365 | logitWeightNormStd:2.5108 | logitWeightNormMax:104.6511 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1838 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5817 | n_weightNormMax:41.2559 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8415 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8886 | windowWeightsW-1:4.97315 (0.98), W4:1.15441 (0.02), W8:-1.91318 (0.00), W16:-2.01980 (0.00), W24:-3.44979 (0.00), W32:-4.73533 (0.00), W-1:-5.95678 (0.00), W-1:-9.16079 (0.00), W-1:-10.80939 (0.00) | topTokens[('using', 4893), ('Ġdiscord', 4641), ('ping', 3533), ('Ġlmao', 2537), ("'t", 1509), ('Ġhear', 943), ('ack', 908), ('Ġexper', 721), ('Ġmind', 697), ('Ġtouch', 580)] | cheekyAvg: 70.85145406723022 | perfectTokens: 2 / 6400 → 0.03% |  | remainingTokens: 619323 (99.79%) | TUTOR.py 100
2025-04-23 00:41:47 | 1400 | LR0.00035 | sampledTokens:19.0000 | scheduledSamplingRate:0.0047 | repetitionPenalty:1.2954 | AvgLoss:72.2963 | loss:95.1103 | temperature:0.8000 | lR:0.0003 | gradientClip:0.9995 | latestLossDelta:166.7921 | memoryLength:9.9968 | embedNormMean:14.2969 | embedNormStd:10.0810 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9365 | logitWeightNormStd:2.5108 | logitWeightNormMax:104.6506 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1838 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5816 | n_weightNormMax:41.2559 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8415 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97315 (0.98), W4:1.15441 (0.02), W8:-1.91321 (0.00), W16:-2.01980 (0.00), W24:-3.44979 (0.00), W32:-4.73533 (0.00), W-1:-5.95678 (0.00), W-1:-9.16079 (0.00), W-1:-10.80938 (0.00) | topTokens[('using', 5246), ('Ġdiscord', 4793), ('ping', 3869), ('Ġlmao', 2855), ("'t", 1557), ('ack', 1082), ('Ġhear', 1078), ('Ġexper', 768), ('Ġmind', 705), ('Ġtouch', 632)] | cheekyAvg: 72.13466918945312 | perfectTokens: 2 / 6400 → 0.03% |  | remainingTokens: 619223 (99.77%) | TUTOR.py 100
2025-04-23 00:42:25 | 1500 | LR0.00035 | sampledTokens:9.0000 | scheduledSamplingRate:0.0050 | repetitionPenalty:1.2951 | AvgLoss:76.6395 | loss:53.0621 | temperature:0.8000 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:198.2924 | memoryLength:9.9968 | embedNormMean:14.2969 | embedNormStd:10.0811 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9365 | logitWeightNormStd:2.5108 | logitWeightNormMax:104.6504 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1838 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5819 | n_weightNormMax:41.2559 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8415 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97316 (0.98), W4:1.15439 (0.02), W8:-1.91324 (0.00), W16:-2.01983 (0.00), W24:-3.44981 (0.00), W32:-4.73534 (0.00), W-1:-5.95677 (0.00), W-1:-9.16078 (0.00), W-1:-10.80937 (0.00) | topTokens[('using', 5963), ('Ġdiscord', 5016), ('ping', 4061), ('Ġlmao', 2911), ("'t", 1560), ('ack', 1209), ('Ġhear', 1208), ('Ġmind', 871), ('Ġexper', 786), ('Ġcause', 656)] | cheekyAvg: 76.21898680686951 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 619123 (99.76%) | TUTOR.py 100
2025-04-23 00:43:02 | 1600 | LR0.00035 | sampledTokens:10.0000 | scheduledSamplingRate:0.0054 | repetitionPenalty:1.2947 | AvgLoss:48.6123 | loss:35.6290 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9996 | latestLossDelta:150.0206 | memoryLength:9.9972 | embedNormMean:14.2969 | embedNormStd:10.0811 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0006 | logitWeightNormMean:91.9365 | logitWeightNormStd:2.5108 | logitWeightNormMax:104.6504 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1838 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5815 | n_weightNormMax:41.2561 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8415 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97318 (0.98), W4:1.15443 (0.02), W8:-1.91329 (0.00), W16:-2.01979 (0.00), W24:-3.44982 (0.00), W32:-4.73533 (0.00), W-1:-5.95674 (0.00), W-1:-9.16076 (0.00), W-1:-10.80935 (0.00) | topTokens[('using', 6002), ('Ġdiscord', 5255), ('ping', 4618), ('Ġlmao', 3300), ("'t", 1964), ('Ġhear', 1231), ('ack', 1209), ('Ġexper', 965), ('Ġmind', 884), ('Ġter', 702)] | cheekyAvg: 48.438007278442385 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 619023 (99.74%) | TUTOR.py 100
2025-04-23 00:43:36 | 1700 | LR0.00035 | sampledTokens:25.0000 | scheduledSamplingRate:0.0057 | repetitionPenalty:1.2944 | AvgLoss:56.4151 | loss:96.3679 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9996 | latestLossDelta:286.6374 | memoryLength:9.9970 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9365 | logitWeightNormStd:2.5108 | logitWeightNormMax:104.6496 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1838 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5812 | n_weightNormMax:41.2563 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8414 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97317 (0.98), W4:1.15444 (0.02), W8:-1.91330 (0.00), W16:-2.01981 (0.00), W24:-3.44984 (0.00), W32:-4.73535 (0.00), W-1:-5.95675 (0.00), W-1:-9.16076 (0.00), W-1:-10.80935 (0.00) | topTokens[('using', 6120), ('Ġdiscord', 5327), ('ping', 4888), ('Ġlmao', 4057), ("'t", 2265), ('ack', 1240), ('Ġhear', 1231), ('Ġmind', 994), ('Ġexper', 980), ('Ġ4', 959)] | cheekyAvg: 57.02252389907837 | perfectTokens: 1 / 6400 → 0.02% |  | remainingTokens: 618923 (99.73%) | TUTOR.py 100
2025-04-23 00:44:10 | 1800 | LR0.00035 | sampledTokens:27.0000 | scheduledSamplingRate:0.0059 | repetitionPenalty:1.2941 | AvgLoss:66.3354 | loss:61.1593 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:155.5692 | memoryLength:9.9970 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9365 | logitWeightNormStd:2.5107 | logitWeightNormMax:104.6486 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1839 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5812 | n_weightNormMax:41.2564 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8414 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97318 (0.98), W4:1.15443 (0.02), W8:-1.91332 (0.00), W16:-2.01987 (0.00), W24:-3.44989 (0.00), W32:-4.73534 (0.00), W-1:-5.95675 (0.00), W-1:-9.16075 (0.00), W-1:-10.80934 (0.00) | topTokens[('using', 6385), ('Ġdiscord', 5591), ('ping', 5158), ('Ġlmao', 4428), ("'t", 2342), ('Ġmind', 1320), ('ack', 1286), ('Ġhear', 1234), ('Ġ4', 1013), ('Ġexper', 986)] | cheekyAvg: 65.98332348823547 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 618823 (99.71%) | TUTOR.py 100
2025-04-23 00:44:43 | 1900 | LR0.00035 | sampledTokens:22.0000 | scheduledSamplingRate:0.0062 | repetitionPenalty:1.2939 | AvgLoss:70.1377 | loss:79.5629 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9996 | latestLossDelta:124.4481 | memoryLength:9.9960 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0003 | logitWeightNormMean:91.9365 | logitWeightNormStd:2.5107 | logitWeightNormMax:104.6479 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1839 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5813 | n_weightNormMax:41.2568 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8414 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97321 (0.98), W4:1.15444 (0.02), W8:-1.91330 (0.00), W16:-2.01987 (0.00), W24:-3.44992 (0.00), W32:-4.73532 (0.00), W-1:-5.95672 (0.00), W-1:-9.16073 (0.00), W-1:-10.80932 (0.00) | topTokens[('using', 6722), ('Ġdiscord', 5668), ('ping', 5268), ('Ġlmao', 5134), ("'t", 2683), ('Ġmind', 1668), ('ack', 1336), ('Ġhear', 1239), ('Ġ4', 1025), ('Ġexper', 986)] | cheekyAvg: 70.32174308776855 | perfectTokens: 4 / 6400 → 0.06% |  | remainingTokens: 618723 (99.69%) | TUTOR.py 100
2025-04-23 00:45:20 | 2000 | LR0.00035 | sampledTokens:15.0000 | scheduledSamplingRate:0.0065 | repetitionPenalty:1.2934 | AvgLoss:60.3333 | loss:76.3718 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:243.6513 | memoryLength:9.9956 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9364 | logitWeightNormStd:2.5107 | logitWeightNormMax:104.6469 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1839 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5813 | n_weightNormMax:41.2568 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8414 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97320 (0.98), W4:1.15445 (0.02), W8:-1.91330 (0.00), W16:-2.01987 (0.00), W24:-3.44992 (0.00), W32:-4.73532 (0.00), W-1:-5.95672 (0.00), W-1:-9.16073 (0.00), W-1:-10.80933 (0.00) | topTokens[('using', 6810), ('Ġlmao', 5887), ('Ġdiscord', 5817), ('ping', 5528), ("'t", 3105), ('Ġmind', 1840), ('ack', 1347), ('Ġhear', 1280), ('Ġ4', 1088), ('Ġexper', 990)] | cheekyAvg: 60.30139733314514 | perfectTokens: 7 / 6400 → 0.11% |  | remainingTokens: 618623 (99.68%) | TUTOR.py 100
2025-04-23 00:45:53 | 2100 | LR0.00035 | sampledTokens:20.0000 | scheduledSamplingRate:0.0069 | repetitionPenalty:1.2930 | AvgLoss:69.4793 | loss:89.0391 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:199.1687 | memoryLength:9.9948 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0003 | logitWeightNormMean:91.9364 | logitWeightNormStd:2.5107 | logitWeightNormMax:104.6458 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1839 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5813 | n_weightNormMax:41.2568 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8414 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97322 (0.98), W4:1.15445 (0.02), W8:-1.91332 (0.00), W16:-2.01987 (0.00), W24:-3.44991 (0.00), W32:-4.73532 (0.00), W-1:-5.95671 (0.00), W-1:-9.16072 (0.00), W-1:-10.80931 (0.00) | topTokens[('Ġlmao', 6940), ('using', 6894), ('Ġdiscord', 5831), ('ping', 5620), ("'t", 3775), ('Ġmind', 2025), ('ack', 1356), ('Ġhear', 1280), ('Ġ4', 1091), ('Ġexper', 990)] | cheekyAvg: 69.60595176696778 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 618523 (99.66%) | TUTOR.py 100
2025-04-23 00:46:26 | 2200 | LR0.00035 | sampledTokens:17.0000 | scheduledSamplingRate:0.0069 | repetitionPenalty:1.2926 | AvgLoss:68.1021 | loss:64.8459 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9995 | latestLossDelta:228.2812 | memoryLength:9.9948 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0003 | logitWeightNormMean:91.9364 | logitWeightNormStd:2.5107 | logitWeightNormMax:104.6446 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1839 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5813 | n_weightNormMax:41.2568 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8414 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97322 (0.98), W4:1.15445 (0.02), W8:-1.91333 (0.00), W16:-2.01988 (0.00), W24:-3.44991 (0.00), W32:-4.73532 (0.00), W-1:-5.95671 (0.00), W-1:-9.16072 (0.00), W-1:-10.80931 (0.00) | topTokens[('Ġlmao', 7427), ('using', 7090), ('Ġdiscord', 6070), ('ping', 5893), ("'t", 4105), ('Ġmind', 2127), ('ack', 1389), ('Ġhear', 1280), ('Ġ4', 1091), ('Ġexper', 990)] | cheekyAvg: 67.86013135910034 | perfectTokens: 4 / 6400 → 0.06% |  | remainingTokens: 618423 (99.65%) | TUTOR.py 100
--- 2025-04-23 00:46:45 --- 
[babyllm] right, last time i got to step 76490... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 76490! what am i learning today?
[charis]2025-04-23 00:48:17 | 100 | LR0.00035 | loss:62.3775 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0003 | repetitionPenalty:1.2996 | AvgLoss:78.3906 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:0.0000 | memoryLength:9.9998 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:16.3008 | logitWeightNormMean:91.9364 | logitWeightNormStd:2.5107 | logitWeightNormMax:104.6436 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1315 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1839 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5812 | n_weightNormMax:41.2567 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8414 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97321 (0.98), W4:1.15445 (0.02), W8:-1.91334 (0.00), W16:-2.01990 (0.00), W24:-3.44993 (0.00), W32:-4.73533 (0.00), W-1:-5.95671 (0.00), W-1:-9.16072 (0.00), W-1:-10.80931 (0.00) | topTokens[('Ġdiscord', 467), ('ping', 348), ('Ġlmao', 346), ('Ġ:)', 205), ('Ġ4', 166), ("'t", 153), ('Ġk', 58), ('ever', 54), ('igh', 45), ('Ġpur', 40)] | cheekyAvg: 77.45593806540612 | perfectTokens: 4 / 6400 → 0.06% |  | remainingTokens: 618293 (99.98%) | TUTOR.py 100
2025-04-23 00:48:51 | 200 | LR0.00035 | sampledTokens:2.0000 | scheduledSamplingRate:0.0006 | repetitionPenalty:1.2992 | AvgLoss:61.2999 | loss:57.9840 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:102.6156 | memoryLength:10.0012 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0003 | logitWeightNormMean:91.9364 | logitWeightNormStd:2.5107 | logitWeightNormMax:104.6425 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1839 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5809 | n_weightNormMax:41.2566 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8413 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97319 (0.98), W4:1.15448 (0.02), W8:-1.91337 (0.00), W16:-2.01991 (0.00), W24:-3.44990 (0.00), W32:-4.73536 (0.00), W-1:-5.95673 (0.00), W-1:-9.16075 (0.00), W-1:-10.80934 (0.00) | topTokens[('ping', 922), ('Ġdiscord', 869), ('Ġlmao', 579), ('Ġ4', 417), ('Ġ:)', 382), ("'t", 325), ('Ġmind', 105), ('Ġxd', 91), ('Ġexper', 89), ('Ġsounds', 84)] | cheekyAvg: 61.255947790145875 | perfectTokens: 4 / 6400 → 0.06% |  | remainingTokens: 618193 (99.97%) | TUTOR.py 100
2025-04-23 00:49:24 | 300 | LR0.00035 | sampledTokens:5.0000 | scheduledSamplingRate:0.0011 | repetitionPenalty:1.2988 | AvgLoss:91.1126 | loss:80.5886 | temperature:0.7998 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:295.1822 | memoryLength:10.0020 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7188 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9364 | logitWeightNormStd:2.5107 | logitWeightNormMax:104.6418 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1839 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5807 | n_weightNormMax:41.2566 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8413 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97320 (0.98), W4:1.15450 (0.02), W8:-1.91339 (0.00), W16:-2.01992 (0.00), W24:-3.44991 (0.00), W32:-4.73536 (0.00), W-1:-5.95672 (0.00), W-1:-9.16073 (0.00), W-1:-10.80932 (0.00) | topTokens[('Ġdiscord', 1454), ('ping', 1124), ('Ġlmao', 711), ('Ġ:)', 480), ('Ġ4', 417), ('using', 385), ("'t", 325), ('Ġmind', 275), ('Ġk', 142), ('igh', 136)] | cheekyAvg: 91.3386720752716 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 618093 (99.95%) | TUTOR.py 100
2025-04-23 00:49:57 | 400 | LR0.00035 | sampledTokens:5.0000 | scheduledSamplingRate:0.0013 | repetitionPenalty:1.2985 | AvgLoss:67.2070 | loss:72.6907 | temperature:0.7998 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:218.4311 | memoryLength:10.0032 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7190 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9364 | logitWeightNormStd:2.5107 | logitWeightNormMax:104.6417 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1839 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5807 | n_weightNormMax:41.2566 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8412 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97321 (0.98), W4:1.15449 (0.02), W8:-1.91340 (0.00), W16:-2.01994 (0.00), W24:-3.44991 (0.00), W32:-4.73535 (0.00), W-1:-5.95671 (0.00), W-1:-9.16072 (0.00), W-1:-10.80931 (0.00) | topTokens[('Ġdiscord', 1764), ('ping', 1495), ('Ġlmao', 1065), ('Ġ:)', 803), ('using', 585), ('Ġ4', 442), ("'t", 337), ('Ġmind', 275), ('Ġexper', 194), ('igh', 163)] | cheekyAvg: 67.12802980422974 | perfectTokens: 5 / 6400 → 0.08% |  | remainingTokens: 617993 (99.94%) | TUTOR.py 100
2025-04-23 00:50:30 | 500 | LR0.00035 | sampledTokens:6.0000 | scheduledSamplingRate:0.0017 | repetitionPenalty:1.2983 | AvgLoss:85.2672 | loss:98.2287 | temperature:0.7998 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:219.4984 | memoryLength:10.0028 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7190 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9364 | logitWeightNormStd:2.5106 | logitWeightNormMax:104.6415 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5807 | n_weightNormMax:41.2567 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8412 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97324 (0.98), W4:1.15449 (0.02), W8:-1.91342 (0.00), W16:-2.01994 (0.00), W24:-3.44990 (0.00), W32:-4.73533 (0.00), W-1:-5.95669 (0.00), W-1:-9.16069 (0.00), W-1:-10.80928 (0.00) | topTokens[('Ġdiscord', 2081), ('ping', 1637), ('using', 1246), ('Ġlmao', 1132), ('Ġ:)', 851), ('Ġmind', 477), ('Ġ4', 442), ("'t", 341), ('Ġguys', 282), ('igh', 217)] | cheekyAvg: 85.52262578964233 | perfectTokens: 4 / 6400 → 0.06% |  | remainingTokens: 617893 (99.92%) | TUTOR.py 100
2025-04-23 00:51:04 | 600 | LR0.00035 | sampledTokens:4.0000 | scheduledSamplingRate:0.0020 | repetitionPenalty:1.2979 | AvgLoss:73.0256 | loss:100.5237 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:199.1351 | memoryLength:10.0032 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7190 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9364 | logitWeightNormStd:2.5106 | logitWeightNormMax:104.6412 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5804 | n_weightNormMax:41.2566 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8412 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97324 (0.98), W4:1.15448 (0.02), W8:-1.91346 (0.00), W16:-2.01998 (0.00), W24:-3.44990 (0.00), W32:-4.73531 (0.00), W-1:-5.95668 (0.00), W-1:-9.16068 (0.00), W-1:-10.80927 (0.00) | topTokens[('Ġdiscord', 2456), ('ping', 2127), ('using', 1541), ('Ġlmao', 1133), ('Ġ:)', 1056), ('Ġmind', 477), ('Ġ4', 460), ("'t", 363), ('Ġguys', 331), ('igh', 278)] | cheekyAvg: 73.0485892868042 | perfectTokens: 1 / 6400 → 0.02% |  | remainingTokens: 617793 (99.90%) | TUTOR.py 100
2025-04-23 00:51:37 | 700 | LR0.00035 | sampledTokens:11.0000 | scheduledSamplingRate:0.0024 | repetitionPenalty:1.2975 | AvgLoss:68.4758 | loss:60.1969 | temperature:0.8000 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:284.6215 | memoryLength:10.0030 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7190 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9364 | logitWeightNormStd:2.5106 | logitWeightNormMax:104.6409 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5807 | n_weightNormMax:41.2564 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8412 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97325 (0.98), W4:1.15447 (0.02), W8:-1.91348 (0.00), W16:-2.01999 (0.00), W24:-3.44991 (0.00), W32:-4.73530 (0.00), W-1:-5.95667 (0.00), W-1:-9.16067 (0.00), W-1:-10.80926 (0.00) | topTokens[('Ġdiscord', 2899), ('ping', 2588), ('using', 1691), ('Ġlmao', 1280), ('Ġ:)', 1110), ('Ġ4', 566), ('Ġmind', 477), ("'t", 379), ('Ġguys', 346), ('igh', 319)] | cheekyAvg: 68.07257057189942 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 617693 (99.89%) | TUTOR.py 100
2025-04-23 00:52:10 | 800 | LR0.00035 | sampledTokens:4.0000 | scheduledSamplingRate:0.0027 | repetitionPenalty:1.2972 | AvgLoss:67.2337 | loss:89.7440 | temperature:0.7998 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:218.9116 | memoryLength:10.0028 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7190 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9364 | logitWeightNormStd:2.5106 | logitWeightNormMax:104.6405 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5806 | n_weightNormMax:41.2565 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8412 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97326 (0.98), W4:1.15447 (0.02), W8:-1.91350 (0.00), W16:-2.02000 (0.00), W24:-3.44992 (0.00), W32:-4.73530 (0.00), W-1:-5.95666 (0.00), W-1:-9.16065 (0.00), W-1:-10.80924 (0.00) | topTokens[('Ġdiscord', 2992), ('ping', 2848), ('Ġlmao', 1921), ('using', 1841), ('Ġ:)', 1192), ("'t", 684), ('Ġ4', 660), ('Ġmind', 489), ('Ġguys', 346), ('igh', 331)] | cheekyAvg: 67.52919565200806 | perfectTokens: 8 / 6400 → 0.12% |  | remainingTokens: 617593 (99.87%) | TUTOR.py 100
2025-04-23 00:52:42 | 900 | LR0.00035 | sampledTokens:6.0000 | scheduledSamplingRate:0.0030 | repetitionPenalty:1.2970 | AvgLoss:76.2017 | loss:108.5351 | temperature:0.7998 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:351.6219 | memoryLength:10.0038 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7190 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9364 | logitWeightNormStd:2.5106 | logitWeightNormMax:104.6391 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5804 | n_weightNormMax:41.2566 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8411 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97326 (0.98), W4:1.15448 (0.02), W8:-1.91351 (0.00), W16:-2.02000 (0.00), W24:-3.44997 (0.00), W32:-4.73531 (0.00), W-1:-5.95666 (0.00), W-1:-9.16065 (0.00), W-1:-10.80924 (0.00) | topTokens[('Ġdiscord', 3086), ('ping', 3063), ('Ġlmao', 2674), ('using', 2093), ('Ġ:)', 1192), ("'t", 913), ('Ġ4', 743), ('Ġmind', 543), ('Ġter', 413), ('Ġguys', 354)] | cheekyAvg: 76.38959962844848 | perfectTokens: 5 / 6400 → 0.08% |  | remainingTokens: 617493 (99.85%) | TUTOR.py 100
2025-04-23 00:53:20 | 1000 | LR0.00035 | sampledTokens:14.0000 | scheduledSamplingRate:0.0034 | repetitionPenalty:1.2966 | AvgLoss:66.3212 | loss:72.0669 | temperature:0.7998 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:159.7038 | memoryLength:10.0052 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7190 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9362 | logitWeightNormStd:2.5106 | logitWeightNormMax:104.6375 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5802 | n_weightNormMax:41.2568 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8411 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97326 (0.98), W4:1.15452 (0.02), W8:-1.91349 (0.00), W16:-2.02000 (0.00), W24:-3.44996 (0.00), W32:-4.73532 (0.00), W-1:-5.95666 (0.00), W-1:-9.16065 (0.00), W-1:-10.80924 (0.00) | topTokens[('Ġlmao', 3785), ('ping', 3119), ('Ġdiscord', 3090), ('using', 2282), ("'t", 1443), ('Ġ:)', 1215), ('Ġ4', 858), ('Ġmind', 567), ('Ġter', 464), ('Ġsmo', 460)] | cheekyAvg: 65.95651711463928 | perfectTokens: 5 / 6400 → 0.08% |  | remainingTokens: 617393 (99.84%) | TUTOR.py 100
2025-04-23 00:53:53 | 1100 | LR0.00035 | sampledTokens:10.0000 | scheduledSamplingRate:0.0038 | repetitionPenalty:1.2961 | AvgLoss:62.8059 | loss:138.0660 | temperature:0.7997 | lR:0.0003 | gradientClip:1.0003 | latestLossDelta:219.5516 | memoryLength:10.0052 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7190 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9362 | logitWeightNormStd:2.5106 | logitWeightNormMax:104.6367 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5801 | n_weightNormMax:41.2568 | n_biasesMean:-1.0611 | n_biasesStd:0.7962 | n_biasesMin:-3.8411 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.5464 | INN_cerebellumStd:4.8885 | windowWeightsW-1:4.97327 (0.98), W4:1.15451 (0.02), W8:-1.91351 (0.00), W16:-2.02001 (0.00), W24:-3.44996 (0.00), W32:-4.73531 (0.00), W-1:-5.95665 (0.00), W-1:-9.16064 (0.00), W-1:-10.80923 (0.00) | topTokens[('Ġlmao', 4102), ('ping', 3481), ('Ġdiscord', 3387), ('using', 2551), ("'t", 1500), ('Ġ:)', 1274), ('Ġ4', 859), ('Ġmind', 712), ('Ġsmo', 586), ('Ġter', 493)] | cheekyAvg: 63.46594088554382 | perfectTokens: 2 / 6400 → 0.03% |  | remainingTokens: 617293 (99.82%) | TUTOR.py 100
--- 2025-04-23 00:54:15 --- 
[babyllm] right, last time i got to step 77619... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77619! what am i learning today?
[charis]--- 2025-04-23 00:56:03 --- 
[babyllm] right, last time i got to step 77619... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77619! what am i learning today?
[charis]2025-04-23 00:57:36 | 100 | LR0.00035 | loss:80.3492 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0002 | repetitionPenalty:1.2996 | AvgLoss:53.9722 | temperature:0.8000 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:0.0000 | memoryLength:9.9992 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7190 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:16.3112 | logitWeightNormMean:91.9362 | logitWeightNormStd:2.5106 | logitWeightNormMax:104.6359 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1314 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5800 | n_weightNormMax:41.2572 | n_biasesMean:-1.0611 | n_biasesStd:0.7963 | n_biasesMin:-3.8412 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.4583 | INN_cerebellumStd:4.7671 | windowWeightsW-1:4.73065 (0.97), W4:1.09822 (0.03), W8:-1.82015 (0.00), W16:-1.92148 (0.00), W24:-3.28167 (0.00), W32:-4.50432 (0.00), W-1:-5.66607 (0.00), W-1:-8.71374 (0.00), W-1:-10.28191 (0.00) | topTokens[('ping', 530), ('Ġlmao', 425), ('using', 242), ('Ġmind', 235), ('Ġ4', 120), ('all', 110), ('Ġwh', 88), ('act', 75), ('Ġdoor', 66), ('Ġthese', 64)] | cheekyAvg: 53.69901101423962 | perfectTokens: 10 / 6400 → 0.16% |  | remainingTokens: 617164 (99.98%) | TUTOR.py 100
--- 2025-04-23 00:58:03 --- 
[babyllm] right, last time i got to step 77779... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77779! what am i learning today?
[charis]2025-04-23 00:59:35 | 100 | LR0.00035 | loss:84.0319 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0005 | repetitionPenalty:1.2998 | AvgLoss:79.0091 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:0.0000 | memoryLength:10.0008 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7190 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:16.3169 | logitWeightNormMean:91.9362 | logitWeightNormStd:2.5106 | logitWeightNormMax:104.6356 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1313 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5800 | n_weightNormMax:41.2580 | n_biasesMean:-1.0611 | n_biasesStd:0.7963 | n_biasesMin:-3.8411 | n_biasesMax:1.9555 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1924 | INN_cerebellumStd:4.4005 | sampledTokens:1.0000 | windowWeightsW-1:4.36683 (0.96), W4:1.01374 (0.03), W8:-1.68020 (0.00), W16:-1.77374 (0.00), W24:-3.02931 (0.00), W32:-4.15795 (0.00), W-1:-5.23032 (0.00), W-1:-8.04362 (0.00), W-1:-9.49118 (0.00) | topTokens[('using', 745), ('Ġlmao', 451), ('Ġhaha', 337), ('g', 145), ('Ġphone', 132), ('Ġwill', 117), ('hh', 112), ('*', 95), ('ping', 91), ('ion', 74)] | cheekyAvg: 78.27658631541941 | perfectTokens: 0 / 6400 → 0.00% |  | remainingTokens: 617004 (99.98%) | TUTOR.py 100
--- 2025-04-23 01:01:04 --- 
[babyllm] right, last time i got to step 77881... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77881! what am i learning today?
[charis]--- 2025-04-23 01:03:13 --- 
[babyllm] right, last time i got to step 77881... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77881! what am i learning today?
[charis]--- 2025-04-23 01:06:37 --- 
[babyllm] right, last time i got to step 77881... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77881! what am i learning today?
[charis]--- 2025-04-23 01:17:44 --- 
[babyllm] right, last time i got to step 77881... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77881! what am i learning today?
[charis]--- 2025-04-23 01:20:40 --- 
[babyllm] right, last time i got to step 77881... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77881! what am i learning today?
[charis]--- 2025-04-23 01:23:17 --- 
[babyllm] right, last time i got to step 77881... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77881! what am i learning today?
[charis]--- 2025-04-23 01:24:56 --- 
[babyllm] right, last time i got to step 77881... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77881! what am i learning today?
[charis]--- 2025-04-23 01:26:31 --- 
[babyllm] right, last time i got to step 77881... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77881! what am i learning today?
[charis]--- 2025-04-23 01:28:46 --- 
[babyllm] right, last time i got to step 77881... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77881! what am i learning today?
[charis]--- 2025-04-23 01:30:12 --- 
[babyllm] right, last time i got to step 77881... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77881! what am i learning today?
[charis]--- 2025-04-23 01:31:36 --- 
[babyllm] right, last time i got to step 77881... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77881! what am i learning today?
[charis]--- 2025-04-23 01:32:59 --- 
[babyllm] right, last time i got to step 77881... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77881! what am i learning today?
[charis]--- 2025-04-23 01:34:18 --- 
[babyllm] right, last time i got to step 77881... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77881! what am i learning today?
[charis]--- 2025-04-23 01:35:34 --- 
[babyllm] right, last time i got to step 77881... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77881! what am i learning today?
[charis]--- 2025-04-23 01:36:54 --- 
[babyllm] right, last time i got to step 77881... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77881! what am i learning today?
[charis]--- 2025-04-23 01:38:06 --- 
[babyllm] right, last time i got to step 77881... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77881! what am i learning today?
[charis]--- 2025-04-23 01:40:43 --- 
[babyllm] right, last time i got to step 77881... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77881! what am i learning today?
[charis]--- 2025-04-23 01:42:57 --- 
[babyllm] right, last time i got to step 77881... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77881! what am i learning today?
[charis]--- 2025-04-23 01:44:33 --- 
[babyllm] right, last time i got to step 77881... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 77881! what am i learning today?
[charis]2025-04-23 01:46:05 | 100 | LR0.00035 | loss:57.1640 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0004 | repetitionPenalty:1.2997 | AvgLoss:69.3925 | temperature:0.8000 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:39.9463 | memoryLength:9.9980 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7190 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:16.2901 | logitWeightNormMean:91.9362 | logitWeightNormStd:2.5105 | logitWeightNormMax:104.6339 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1314 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5799 | n_weightNormMax:41.2582 | n_biasesMean:-1.0611 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36245 (0.96), W-1:1.01271 (0.03), W8:-1.67851 (0.00), W-1:-1.77198 (0.00), W16:-3.02628 (0.00), W-1:-4.15380 (0.00), W24:-5.22509 (0.00), W-1:-8.03558 (0.00), W32:-9.48170 (0.00) | topTokens[('Ġlmao', 558), ('using', 377), ('Ġdiscord', 235), ('ping', 204), ('Ġter', 149), ("'t", 135), ('Ġmind', 127), ('ever', 124), ('d', 96), ('al', 48)] | cheekyAvg: 58.97115546581792 | perfectTokens: 4 / 6400 → 0.06% |  | remainingTokens: 616902 (99.98%) | TUTOR.py 100
--- 2025-04-23 01:46:29 --- 
[babyllm] right, last time i got to step 78031... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 78031! what am i learning today?
[charis]--- 2025-04-23 01:48:23 --- 
[babyllm] right, last time i got to step 78031... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 78031! what am i learning today?
[charis]--- 2025-04-23 01:49:59 --- 
[babyllm] right, last time i got to step 78031... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 78031! what am i learning today?
[charis]2025-04-23 01:51:31 | 100 | LR0.00035 | loss:53.7698 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0003 | repetitionPenalty:1.2997 | AvgLoss:69.6126 | temperature:0.8000 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:42.6500 | memoryLength:10.0004 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7191 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:16.3155 | logitWeightNormMean:91.9362 | logitWeightNormStd:2.5105 | logitWeightNormMax:104.6321 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1312 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5798 | n_weightNormMax:41.2584 | n_biasesMean:-1.0611 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36245 (0.96), W-1:1.01272 (0.03), W8:-1.67852 (0.00), W-1:-1.77197 (0.00), W16:-3.02628 (0.00), W-1:-4.15379 (0.00), W24:-5.22508 (0.00), W-1:-8.03560 (0.00), W32:-9.48172 (0.00) | topTokens[('Ġlmao', 698), ('using', 332), ('ping', 260), ("'t", 151), ('ion', 140), ('Ġdiscord', 124), ('g', 67), ('Ġwill', 64), ('Ġ3', 57), ('igh', 48)] | cheekyAvg: 57.75268741682464 | perfectTokens: 7 / 6400 → 0.11% |  | remainingTokens: 616752 (99.98%) | TUTOR.py 100
2025-04-23 01:52:04 | 200 | LR0.00035 | sampledTokens:0.0000 | scheduledSamplingRate:0.0007 | repetitionPenalty:1.2992 | AvgLoss:69.7364 | loss:34.2900 | temperature:0.8002 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:32.5815 | memoryLength:9.9994 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7191 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0002 | logitWeightNormMean:91.9362 | logitWeightNormStd:2.5105 | logitWeightNormMax:104.6311 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0009 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5798 | n_weightNormMax:41.2587 | n_biasesMean:-1.0611 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36245 (0.96), W-1:1.01272 (0.03), W8:-1.67848 (0.00), W-1:-1.77197 (0.00), W16:-3.02628 (0.00), W-1:-4.15379 (0.00), W24:-5.22509 (0.00), W-1:-8.03559 (0.00), W32:-9.48173 (0.00) | topTokens[('Ġlmao', 992), ('using', 860), ('ping', 554), ('Ġhaha', 296), ('Ġdiscord', 287), ('Ġ:)', 222), ("'t", 218), ('ach', 175), ('ion', 156), ('Ġwill', 124)] | cheekyAvg: 61.13811658859253 | perfectTokens: 7 / 6400 → 0.11% |  | remainingTokens: 616652 (99.97%) | TUTOR.py 100
2025-04-23 01:52:36 | 300 | LR0.00035 | sampledTokens:2.0000 | scheduledSamplingRate:0.0009 | repetitionPenalty:1.2989 | AvgLoss:63.1593 | loss:67.4320 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:459.8753 | memoryLength:9.9996 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7192 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0003 | logitWeightNormMean:91.9362 | logitWeightNormStd:2.5105 | logitWeightNormMax:104.6307 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6049 | n_weightNormMin:21.5798 | n_weightNormMax:41.2592 | n_biasesMean:-1.0611 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36245 (0.96), W-1:1.01274 (0.03), W8:-1.67849 (0.00), W-1:-1.77195 (0.00), W16:-3.02630 (0.00), W-1:-4.15377 (0.00), W24:-5.22508 (0.00), W-1:-8.03558 (0.00), W32:-9.48171 (0.00) | topTokens[('Ġlmao', 1685), ('using', 1101), ('ping', 870), ('Ġdiscord', 420), ("'t", 401), ('Ġhaha', 298), ('Ġ:)', 266), ('ach', 175), ('Ġ3', 171), ('ion', 162)] | cheekyAvg: 54.130063915252684 | perfectTokens: 5 / 6400 → 0.08% |  | remainingTokens: 616552 (99.95%) | TUTOR.py 100
2025-04-23 01:53:09 | 400 | LR0.00035 | sampledTokens:3.0000 | scheduledSamplingRate:0.0012 | repetitionPenalty:1.2986 | AvgLoss:60.6240 | loss:53.2521 | temperature:0.8000 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:214.7915 | memoryLength:9.9988 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7193 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9362 | logitWeightNormStd:2.5105 | logitWeightNormMax:104.6298 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6049 | n_weightNormMin:21.5798 | n_weightNormMax:41.2594 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36244 (0.96), W-1:1.01274 (0.03), W8:-1.67850 (0.00), W-1:-1.77195 (0.00), W16:-3.02630 (0.00), W-1:-4.15377 (0.00), W24:-5.22508 (0.00), W-1:-8.03558 (0.00), W32:-9.48172 (0.00) | topTokens[('Ġlmao', 1954), ('ping', 1302), ('using', 1206), ('Ġdiscord', 834), ("'t", 500), ('Ġ:)', 455), ('ion', 314), ('Ġhaha', 298), ('ach', 175), ('Ġ3', 171)] | cheekyAvg: 53.68840349197388 | perfectTokens: 7 / 6400 → 0.11% |  | remainingTokens: 616452 (99.94%) | TUTOR.py 100
2025-04-23 01:53:41 | 500 | LR0.00035 | sampledTokens:0.0000 | scheduledSamplingRate:0.0014 | repetitionPenalty:1.2982 | AvgLoss:72.2219 | loss:119.6370 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:232.9750 | memoryLength:9.9982 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7193 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0002 | logitWeightNormMean:91.9362 | logitWeightNormStd:2.5105 | logitWeightNormMax:104.6290 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6049 | n_weightNormMin:21.5799 | n_weightNormMax:41.2598 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36240 (0.96), W-1:1.01272 (0.03), W8:-1.67853 (0.00), W-1:-1.77197 (0.00), W16:-3.02632 (0.00), W-1:-4.15379 (0.00), W24:-5.22511 (0.00), W-1:-8.03560 (0.00), W32:-9.48174 (0.00) | topTokens[('Ġlmao', 2356), ('using', 1786), ('ping', 1538), ('Ġdiscord', 914), ('Ġhaha', 599), ("'t", 528), ('Ġ:)', 490), ('ion', 326), ('Ġmind', 290), ('ach', 216)] | cheekyAvg: 63.98713523864746 | perfectTokens: 8 / 6400 → 0.12% |  | remainingTokens: 616352 (99.92%) | TUTOR.py 100
2025-04-23 01:54:13 | 600 | LR0.00035 | sampledTokens:9.0000 | scheduledSamplingRate:0.0017 | repetitionPenalty:1.2979 | AvgLoss:79.9480 | loss:97.2505 | temperature:0.8000 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:255.5615 | memoryLength:9.9980 | embedNormMean:14.2970 | embedNormStd:10.0811 | embedNormMax:103.7193 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0002 | logitWeightNormMean:91.9362 | logitWeightNormStd:2.5105 | logitWeightNormMax:104.6289 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6049 | n_weightNormMin:21.5801 | n_weightNormMax:41.2602 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36240 (0.96), W-1:1.01272 (0.03), W8:-1.67852 (0.00), W-1:-1.77197 (0.00), W16:-3.02632 (0.00), W-1:-4.15379 (0.00), W24:-5.22510 (0.00), W-1:-8.03560 (0.00), W32:-9.48173 (0.00) | topTokens[('Ġlmao', 2623), ('using', 2132), ('ping', 1754), ('Ġdiscord', 1338), ('Ġhaha', 806), ("'t", 615), ('Ġ:)', 571), ('Ġmind', 333), ('ion', 329), ('Ġter', 250)] | cheekyAvg: 69.25344602584839 | perfectTokens: 5 / 6400 → 0.08% |  | remainingTokens: 616252 (99.90%) | TUTOR.py 100
2025-04-23 01:54:46 | 700 | LR0.00035 | sampledTokens:7.0000 | scheduledSamplingRate:0.0020 | repetitionPenalty:1.2975 | AvgLoss:66.1898 | loss:38.7302 | temperature:0.8000 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:245.5060 | memoryLength:9.9988 | embedNormMean:14.2970 | embedNormStd:10.0812 | embedNormMax:103.7193 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0003 | logitWeightNormMean:91.9362 | logitWeightNormStd:2.5105 | logitWeightNormMax:104.6284 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6049 | n_weightNormMin:21.5801 | n_weightNormMax:41.2606 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36239 (0.96), W-1:1.01273 (0.03), W8:-1.67851 (0.00), W-1:-1.77196 (0.00), W16:-3.02634 (0.00), W-1:-4.15378 (0.00), W24:-5.22511 (0.00), W-1:-8.03559 (0.00), W32:-9.48173 (0.00) | topTokens[('Ġlmao', 3034), ('using', 2561), ('ping', 2130), ('Ġdiscord', 1462), ('Ġhaha', 988), ("'t", 620), ('Ġmind', 575), ('Ġ:)', 571), ('ion', 336), ('Ġter', 281)] | cheekyAvg: 56.45519886016846 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 616152 (99.89%) | TUTOR.py 100
2025-04-23 01:55:18 | 800 | LR0.00035 | sampledTokens:7.0000 | scheduledSamplingRate:0.0024 | repetitionPenalty:1.2973 | AvgLoss:77.8424 | loss:104.4521 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:194.7800 | memoryLength:9.9998 | embedNormMean:14.2970 | embedNormStd:10.0812 | embedNormMax:103.7194 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0001 | logitWeightNormMean:91.9362 | logitWeightNormStd:2.5104 | logitWeightNormMax:104.6280 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0006 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6049 | n_weightNormMin:21.5801 | n_weightNormMax:41.2609 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36239 (0.96), W-1:1.01272 (0.03), W8:-1.67850 (0.00), W-1:-1.77197 (0.00), W16:-3.02634 (0.00), W-1:-4.15379 (0.00), W24:-5.22511 (0.00), W-1:-8.03560 (0.00), W32:-9.48174 (0.00) | topTokens[('using', 3677), ('Ġlmao', 3179), ('ping', 2216), ('Ġdiscord', 1470), ('Ġhaha', 1470), ('Ġ:)', 662), ("'t", 621), ('Ġmind', 620), ('ion', 336), ('hh', 312)] | cheekyAvg: 68.79853382110596 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 616052 (99.87%) | TUTOR.py 100
2025-04-23 01:55:50 | 900 | LR0.00035 | sampledTokens:7.0000 | scheduledSamplingRate:0.0027 | repetitionPenalty:1.2969 | AvgLoss:70.8871 | loss:77.4199 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:46.5048 | memoryLength:10.0008 | embedNormMean:14.2970 | embedNormStd:10.0812 | embedNormMax:103.7194 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9361 | logitWeightNormStd:2.5104 | logitWeightNormMax:104.6280 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6049 | n_weightNormMin:21.5801 | n_weightNormMax:41.2610 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36235 (0.96), W-1:1.01272 (0.03), W8:-1.67849 (0.00), W-1:-1.77197 (0.00), W16:-3.02634 (0.00), W-1:-4.15379 (0.00), W24:-5.22512 (0.00), W-1:-8.03560 (0.00), W32:-9.48175 (0.00) | topTokens[('using', 4186), ('Ġlmao', 3453), ('ping', 2623), ('Ġhaha', 1640), ('Ġdiscord', 1620), ('Ġ:)', 693), ("'t", 687), ('Ġmind', 628), ('hh', 345), ('ion', 336)] | cheekyAvg: 62.57798881530762 | perfectTokens: 6 / 6400 → 0.09% |  | remainingTokens: 615952 (99.85%) | TUTOR.py 100
2025-04-23 01:56:27 | 1000 | LR0.00035 | sampledTokens:10.0000 | scheduledSamplingRate:0.0032 | repetitionPenalty:1.2967 | AvgLoss:62.3623 | loss:73.4725 | temperature:0.7997 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:163.7148 | memoryLength:10.0022 | embedNormMean:14.2970 | embedNormStd:10.0812 | embedNormMax:103.7194 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9361 | logitWeightNormStd:2.5104 | logitWeightNormMax:104.6274 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0016 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6049 | n_weightNormMin:21.5800 | n_weightNormMax:41.2610 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36236 (0.96), W-1:1.01273 (0.03), W8:-1.67847 (0.00), W-1:-1.77196 (0.00), W16:-3.02634 (0.00), W-1:-4.15378 (0.00), W24:-5.22513 (0.00), W-1:-8.03558 (0.00), W32:-9.48174 (0.00) | topTokens[('using', 4462), ('Ġlmao', 3720), ('ping', 2991), ('Ġdiscord', 1899), ('Ġhaha', 1670), ("'t", 761), ('Ġ:)', 760), ('Ġmind', 665), ('ion', 349), ('Ġter', 346)] | cheekyAvg: 54.51609336853027 | perfectTokens: 6 / 6400 → 0.09% |  | remainingTokens: 615852 (99.84%) | TUTOR.py 100
2025-04-23 01:57:01 | 1100 | LR0.00035 | sampledTokens:11.0000 | scheduledSamplingRate:0.0036 | repetitionPenalty:1.2963 | AvgLoss:62.4354 | loss:106.5972 | temperature:0.7997 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:155.7156 | memoryLength:10.0006 | embedNormMean:14.2970 | embedNormStd:10.0812 | embedNormMax:103.7194 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9361 | logitWeightNormStd:2.5104 | logitWeightNormMax:104.6267 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0015 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5799 | n_weightNormMax:41.2610 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36234 (0.96), W-1:1.01273 (0.03), W8:-1.67844 (0.00), W-1:-1.77196 (0.00), W16:-3.02630 (0.00), W-1:-4.15378 (0.00), W24:-5.22510 (0.00), W-1:-8.03558 (0.00), W32:-9.48174 (0.00) | topTokens[('using', 4643), ('Ġlmao', 4281), ('ping', 3229), ('Ġdiscord', 2226), ('Ġhaha', 1670), ("'t", 943), ('Ġ:)', 834), ('Ġmind', 665), ('Ġter', 458), ('ion', 456)] | cheekyAvg: 54.98545610427856 | perfectTokens: 4 / 6400 → 0.06% |  | remainingTokens: 615752 (99.82%) | TUTOR.py 100
2025-04-23 01:57:37 | 1200 | LR0.00035 | sampledTokens:11.0000 | scheduledSamplingRate:0.0039 | repetitionPenalty:1.2959 | AvgLoss:62.1960 | loss:80.8401 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:96.9209 | memoryLength:9.9980 | embedNormMean:14.2970 | embedNormStd:10.0812 | embedNormMax:103.7194 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9361 | logitWeightNormStd:2.5104 | logitWeightNormMax:104.6260 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0016 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5798 | n_weightNormMax:41.2610 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9556 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36233 (0.96), W-1:1.01272 (0.03), W8:-1.67843 (0.00), W-1:-1.77197 (0.00), W16:-3.02629 (0.00), W-1:-4.15379 (0.00), W24:-5.22508 (0.00), W-1:-8.03559 (0.00), W32:-9.48176 (0.00) | topTokens[('using', 4952), ('Ġlmao', 4506), ('ping', 3665), ('Ġdiscord', 2468), ('Ġhaha', 1673), ("'t", 1044), ('Ġ:)', 834), ('Ġmind', 698), ('Ġter', 509), ('ion', 501)] | cheekyAvg: 52.91296575546264 | perfectTokens: 6 / 6400 → 0.09% |  | remainingTokens: 615652 (99.81%) | TUTOR.py 100
2025-04-23 01:58:11 | 1300 | LR0.00035 | sampledTokens:9.0000 | scheduledSamplingRate:0.0042 | repetitionPenalty:1.2956 | AvgLoss:50.1558 | loss:80.4799 | temperature:0.7998 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:180.2467 | memoryLength:9.9980 | embedNormMean:14.2970 | embedNormStd:10.0812 | embedNormMax:103.7194 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9361 | logitWeightNormStd:2.5104 | logitWeightNormMax:104.6252 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0015 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5796 | n_weightNormMax:41.2610 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9557 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36231 (0.96), W-1:1.01274 (0.03), W8:-1.67841 (0.00), W-1:-1.77195 (0.00), W16:-3.02629 (0.00), W-1:-4.15378 (0.00), W24:-5.22509 (0.00), W-1:-8.03558 (0.00), W32:-9.48173 (0.00) | topTokens[('Ġlmao', 5142), ('using', 5091), ('ping', 3998), ('Ġdiscord', 2618), ('Ġhaha', 1673), ("'t", 1421), ('Ġ:)', 867), ('Ġmind', 716), ('ion', 672), ('Ġter', 579)] | cheekyAvg: 43.509331760406496 | perfectTokens: 7 / 6400 → 0.11% |  | remainingTokens: 615552 (99.79%) | TUTOR.py 100
2025-04-23 01:58:45 | 1400 | LR0.00035 | sampledTokens:14.0000 | scheduledSamplingRate:0.0044 | repetitionPenalty:1.2952 | AvgLoss:55.2353 | loss:48.7392 | temperature:0.7996 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:102.4284 | memoryLength:9.9962 | embedNormMean:14.2970 | embedNormStd:10.0812 | embedNormMax:103.7194 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9361 | logitWeightNormStd:2.5104 | logitWeightNormMax:104.6241 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7336 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5795 | n_weightNormMax:41.2612 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9557 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36227 (0.96), W-1:1.01270 (0.03), W8:-1.67839 (0.00), W-1:-1.77199 (0.00), W16:-3.02634 (0.00), W-1:-4.15381 (0.00), W24:-5.22512 (0.00), W-1:-8.03561 (0.00), W32:-9.48177 (0.00) | topTokens[('Ġlmao', 5419), ('using', 5130), ('ping', 4685), ('Ġdiscord', 2803), ('Ġhaha', 1673), ("'t", 1466), ('Ġ:)', 1039), ('Ġmind', 716), ('ion', 694), ('Ġter', 621)] | cheekyAvg: 47.67877569198608 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 615452 (99.77%) | TUTOR.py 100
2025-04-23 01:59:19 | 1500 | LR0.00035 | sampledTokens:18.0000 | scheduledSamplingRate:0.0050 | repetitionPenalty:1.2948 | AvgLoss:56.5274 | loss:34.0318 | temperature:0.7996 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:190.6116 | memoryLength:9.9954 | embedNormMean:14.2970 | embedNormStd:10.0812 | embedNormMax:103.7194 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9361 | logitWeightNormStd:2.5104 | logitWeightNormMax:104.6234 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5794 | n_weightNormMax:41.2612 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9557 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36227 (0.96), W-1:1.01271 (0.03), W8:-1.67838 (0.00), W-1:-1.77198 (0.00), W16:-3.02634 (0.00), W-1:-4.15381 (0.00), W24:-5.22508 (0.00), W-1:-8.03562 (0.00), W32:-9.48178 (0.00) | topTokens[('Ġlmao', 6173), ('using', 5473), ('ping', 4978), ('Ġdiscord', 2851), ("'t", 1999), ('Ġhaha', 1673), ('Ġ:)', 1066), ('Ġmind', 755), ('ion', 699), ('Ġter', 683)] | cheekyAvg: 48.15122777938843 | perfectTokens: 1 / 6400 → 0.02% |  | remainingTokens: 615352 (99.76%) | TUTOR.py 100
2025-04-23 01:59:53 | 1600 | LR0.00035 | sampledTokens:17.0000 | scheduledSamplingRate:0.0051 | repetitionPenalty:1.2944 | AvgLoss:58.9091 | loss:77.4737 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9996 | latestLossDelta:219.3707 | memoryLength:9.9974 | embedNormMean:14.2971 | embedNormStd:10.0812 | embedNormMax:103.7196 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9361 | logitWeightNormStd:2.5104 | logitWeightNormMax:104.6228 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5793 | n_weightNormMax:41.2612 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9557 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36227 (0.96), W-1:1.01271 (0.03), W8:-1.67839 (0.00), W-1:-1.77199 (0.00), W16:-3.02635 (0.00), W-1:-4.15381 (0.00), W24:-5.22509 (0.00), W-1:-8.03561 (0.00), W32:-9.48178 (0.00) | topTokens[('Ġlmao', 6655), ('using', 5807), ('ping', 5121), ('Ġdiscord', 3082), ("'t", 2293), ('Ġhaha', 1768), ('Ġ:)', 1090), ('Ġmind', 858), ('ion', 721), ('Ġter', 698)] | cheekyAvg: 52.907316017150876 | perfectTokens: 4 / 6400 → 0.06% |  | remainingTokens: 615252 (99.74%) | TUTOR.py 100
2025-04-23 02:00:27 | 1700 | LR0.00035 | sampledTokens:16.0000 | scheduledSamplingRate:0.0055 | repetitionPenalty:1.2941 | AvgLoss:63.4960 | loss:46.5891 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9996 | latestLossDelta:132.6120 | memoryLength:9.9984 | embedNormMean:14.2971 | embedNormStd:10.0812 | embedNormMax:103.7196 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9361 | logitWeightNormStd:2.5103 | logitWeightNormMax:104.6222 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0015 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5792 | n_weightNormMax:41.2611 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8409 | n_biasesMax:1.9557 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36228 (0.96), W-1:1.01273 (0.03), W8:-1.67838 (0.00), W-1:-1.77196 (0.00), W16:-3.02635 (0.00), W-1:-4.15378 (0.00), W24:-5.22509 (0.00), W-1:-8.03559 (0.00), W32:-9.48177 (0.00) | topTokens[('Ġlmao', 7343), ('using', 5879), ('ping', 5285), ('Ġdiscord', 3312), ("'t", 2659), ('Ġhaha', 1768), ('Ġ:)', 1090), ('Ġmind', 861), ('Ġter', 769), ('ion', 755)] | cheekyAvg: 54.67465585708618 | perfectTokens: 0 / 6400 → 0.00% |  | remainingTokens: 615152 (99.72%) | TUTOR.py 100
2025-04-23 02:00:59 | 1800 | LR0.00035 | sampledTokens:18.0000 | scheduledSamplingRate:0.0057 | repetitionPenalty:1.2938 | AvgLoss:53.7749 | loss:85.2315 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9995 | latestLossDelta:156.7834 | memoryLength:9.9978 | embedNormMean:14.2971 | embedNormStd:10.0812 | embedNormMax:103.7197 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9361 | logitWeightNormStd:2.5103 | logitWeightNormMax:104.6215 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5791 | n_weightNormMax:41.2610 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8409 | n_biasesMax:1.9557 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36223 (0.96), W-1:1.01271 (0.03), W8:-1.67838 (0.00), W-1:-1.77198 (0.00), W16:-3.02636 (0.00), W-1:-4.15380 (0.00), W24:-5.22508 (0.00), W-1:-8.03562 (0.00), W32:-9.48180 (0.00) | topTokens[('Ġlmao', 8020), ('using', 6078), ('ping', 5556), ('Ġdiscord', 3580), ("'t", 2874), ('Ġhaha', 1768), ('Ġ:)', 1165), ('ion', 898), ('Ġmind', 861), ('Ġter', 843)] | cheekyAvg: 47.65993236541748 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 615052 (99.71%) | TUTOR.py 100
2025-04-23 02:01:32 | 1900 | LR0.00035 | sampledTokens:16.0000 | scheduledSamplingRate:0.0059 | repetitionPenalty:1.2934 | AvgLoss:57.8452 | loss:93.0569 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9995 | latestLossDelta:140.5574 | memoryLength:9.9966 | embedNormMean:14.2971 | embedNormStd:10.0812 | embedNormMax:103.7197 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0005 | logitWeightNormMean:91.9360 | logitWeightNormStd:2.5103 | logitWeightNormMax:104.6206 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0015 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7336 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5790 | n_weightNormMax:41.2610 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8409 | n_biasesMax:1.9557 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36226 (0.96), W-1:1.01276 (0.03), W8:-1.67833 (0.00), W-1:-1.77193 (0.00), W16:-3.02636 (0.00), W-1:-4.15375 (0.00), W24:-5.22507 (0.00), W-1:-8.03558 (0.00), W32:-9.48178 (0.00) | topTokens[('Ġlmao', 8747), ('using', 6141), ('ping', 5841), ('Ġdiscord', 3852), ("'t", 2938), ('Ġhaha', 1768), ('Ġ:)', 1174), ('ion', 1053), ('Ġmind', 902), ('Ġter', 894)] | cheekyAvg: 50.05929187774658 | perfectTokens: 2 / 6400 → 0.03% |  | remainingTokens: 614952 (99.69%) | TUTOR.py 100
2025-04-23 02:02:08 | 2000 | LR0.00035 | sampledTokens:15.0000 | scheduledSamplingRate:0.0062 | repetitionPenalty:1.2929 | AvgLoss:61.9150 | loss:104.0993 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9995 | latestLossDelta:277.9735 | memoryLength:9.9964 | embedNormMean:14.2971 | embedNormStd:10.0812 | embedNormMax:103.7197 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0004 | logitWeightNormMean:91.9360 | logitWeightNormStd:2.5103 | logitWeightNormMax:104.6197 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7336 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5791 | n_weightNormMax:41.2612 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8409 | n_biasesMax:1.9558 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36224 (0.96), W-1:1.01275 (0.03), W8:-1.67834 (0.00), W-1:-1.77194 (0.00), W16:-3.02638 (0.00), W-1:-4.15376 (0.00), W24:-5.22508 (0.00), W-1:-8.03559 (0.00), W32:-9.48179 (0.00) | topTokens[('Ġlmao', 9500), ('using', 6229), ('ping', 6202), ('Ġdiscord', 3949), ("'t", 3037), ('Ġhaha', 1768), ('Ġ:)', 1223), ('ion', 1170), ('Ġmind', 1005), ('Ġter', 947)] | cheekyAvg: 53.906584892272946 | perfectTokens: 4 / 6400 → 0.06% |  | remainingTokens: 614852 (99.68%) | TUTOR.py 100
--- 2025-04-23 02:02:16 --- 
[babyllm] right, last time i got to step 80029... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 80029! what am i learning today?
[charis]2025-04-23 02:02:41 | 2100 | LR0.00035 | sampledTokens:25.0000 | scheduledSamplingRate:0.0065 | repetitionPenalty:1.2924 | AvgLoss:58.7102 | loss:59.5842 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9996 | latestLossDelta:178.2169 | memoryLength:9.9958 | embedNormMean:14.2971 | embedNormStd:10.0812 | embedNormMax:103.7197 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0003 | logitWeightNormMean:91.9360 | logitWeightNormStd:2.5103 | logitWeightNormMax:104.6188 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5790 | n_weightNormMax:41.2614 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8409 | n_biasesMax:1.9558 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36227 (0.96), W-1:1.01275 (0.03), W8:-1.67833 (0.00), W-1:-1.77194 (0.00), W16:-3.02637 (0.00), W-1:-4.15376 (0.00), W24:-5.22507 (0.00), W-1:-8.03558 (0.00), W32:-9.48179 (0.00) | topTokens[('Ġlmao', 10144), ('using', 6514), ('ping', 6484), ('Ġdiscord', 4010), ("'t", 3186), ('Ġhaha', 1768), ('Ġ:)', 1223), ('ion', 1190), ('Ġmind', 1049), ('Ġter', 1000)] | cheekyAvg: 49.316488113403324 | perfectTokens: 8 / 6400 → 0.12% |  | remainingTokens: 614752 (99.66%) | TUTOR.py 100
2025-04-23 02:03:13 | 2200 | LR0.00035 | sampledTokens:18.0000 | scheduledSamplingRate:0.0069 | repetitionPenalty:1.2921 | AvgLoss:61.5722 | loss:32.6169 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9995 | latestLossDelta:71.3771 | memoryLength:9.9978 | embedNormMean:14.2971 | embedNormStd:10.0812 | embedNormMax:103.7197 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0002 | embeddingDrift:0.0003 | logitWeightNormMean:91.9360 | logitWeightNormStd:2.5103 | logitWeightNormMax:104.6182 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5789 | n_weightNormMax:41.2618 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8409 | n_biasesMax:1.9558 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36225 (0.96), W-1:1.01271 (0.03), W8:-1.67833 (0.00), W-1:-1.77198 (0.00), W16:-3.02639 (0.00), W-1:-4.15380 (0.00), W24:-5.22511 (0.00), W-1:-8.03561 (0.00), W32:-9.48180 (0.00) | topTokens[('Ġlmao', 10371), ('using', 7124), ('ping', 6867), ('Ġdiscord', 4095), ("'t", 3192), ('Ġhaha', 1825), ('Ġ:)', 1300), ('ion', 1220), ('Ġmind', 1124), ('Ġter', 1017)] | cheekyAvg: 53.516715621948244 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 614652 (99.64%) | TUTOR.py 100
2025-04-23 02:03:46 | 2300 | LR0.00035 | sampledTokens:24.0000 | scheduledSamplingRate:0.0072 | repetitionPenalty:1.2917 | AvgLoss:66.0821 | loss:46.4123 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9995 | latestLossDelta:378.1852 | memoryLength:9.9968 | embedNormMean:14.2971 | embedNormStd:10.0812 | embedNormMax:103.7197 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9360 | logitWeightNormStd:2.5103 | logitWeightNormMax:104.6171 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5788 | n_weightNormMax:41.2622 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8409 | n_biasesMax:1.9558 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36225 (0.96), W-1:1.01272 (0.03), W8:-1.67833 (0.00), W-1:-1.77198 (0.00), W16:-3.02641 (0.00), W-1:-4.15380 (0.00), W24:-5.22510 (0.00), W-1:-8.03561 (0.00), W32:-9.48180 (0.00) | topTokens[('Ġlmao', 11360), ('using', 7144), ('ping', 7063), ('Ġdiscord', 4290), ("'t", 3430), ('Ġhaha', 1825), ('Ġ:)', 1329), ('ion', 1222), ('Ġmind', 1187), ('Ġter', 1067)] | cheekyAvg: 57.962000102996825 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 614552 (99.63%) | TUTOR.py 100
--- 2025-04-23 02:03:54 --- 
[babyllm] right, last time i got to step 80029... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 80029! what am i learning today?
[charis]2025-04-23 02:04:18 | 2400 | LR0.00035 | sampledTokens:27.0000 | scheduledSamplingRate:0.0076 | repetitionPenalty:1.2913 | AvgLoss:57.0858 | loss:83.8344 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9994 | latestLossDelta:259.5410 | memoryLength:9.9956 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7198 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9360 | logitWeightNormStd:2.5103 | logitWeightNormMax:104.6157 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5787 | n_weightNormMax:41.2624 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8409 | n_biasesMax:1.9557 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36221 (0.96), W-1:1.01268 (0.03), W8:-1.67835 (0.00), W-1:-1.77201 (0.00), W16:-3.02639 (0.00), W-1:-4.15383 (0.00), W24:-5.22511 (0.00), W-1:-8.03564 (0.00), W32:-9.48185 (0.00) | topTokens[('Ġlmao', 11729), ('ping', 7496), ('using', 7275), ('Ġdiscord', 4629), ("'t", 3605), ('Ġhaha', 1857), ('Ġ:)', 1567), ('ion', 1291), ('Ġmind', 1206), ('Ġter', 1089)] | cheekyAvg: 51.36476671218872 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 614452 (99.61%) | TUTOR.py 100
2025-04-23 02:04:50 | 2500 | LR0.00035 | sampledTokens:30.0000 | scheduledSamplingRate:0.0079 | repetitionPenalty:1.2909 | AvgLoss:70.8907 | loss:53.3860 | temperature:0.8000 | lR:0.0003 | gradientClip:0.9993 | latestLossDelta:206.4824 | memoryLength:9.9936 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7200 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0002 | logitWeightNormMean:91.9360 | logitWeightNormStd:2.5103 | logitWeightNormMax:104.6148 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7336 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5788 | n_weightNormMax:41.2627 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8409 | n_biasesMax:1.9557 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36222 (0.96), W-1:1.01268 (0.03), W8:-1.67835 (0.00), W-1:-1.77202 (0.00), W16:-3.02641 (0.00), W-1:-4.15384 (0.00), W24:-5.22511 (0.00), W-1:-8.03564 (0.00), W32:-9.48185 (0.00) | topTokens[('Ġlmao', 11813), ('using', 7951), ('ping', 7737), ('Ġdiscord', 4855), ("'t", 3606), ('Ġhaha', 1857), ('Ġ:)', 1572), ('Ġmind', 1329), ('ion', 1291), ('Ġter', 1156)] | cheekyAvg: 61.52536609649658 | perfectTokens: 1 / 6400 → 0.02% |  | remainingTokens: 614352 (99.59%) | TUTOR.py 100
2025-04-23 02:05:36 | 100 | LR0.00035 | loss:51.8675 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0004 | repetitionPenalty:1.2997 | AvgLoss:57.1477 | temperature:0.8000 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:30.9173 | memoryLength:9.9994 | embedNormMean:14.2971 | embedNormStd:10.0812 | embedNormMax:103.7197 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:16.3103 | logitWeightNormMean:91.9360 | logitWeightNormStd:2.5103 | logitWeightNormMax:104.6186 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1312 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7336 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5789 | n_weightNormMax:41.2616 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8409 | n_biasesMax:1.9557 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36221 (0.96), W-1:1.01272 (0.03), W8:-1.67833 (0.00), W-1:-1.77197 (0.00), W16:-3.02639 (0.00), W-1:-4.15379 (0.00), W24:-5.22512 (0.00), W-1:-8.03561 (0.00), W32:-9.48182 (0.00) | topTokens[('Ġlmao', 495), ('ping', 440), ('using', 360), ('Ġ4', 198), ('Ġdiscord', 138), ('Ġweed', 113), ("'t", 85), ('Ġworks', 79), ('Ġter', 64), ('Ġplaying', 57)] | cheekyAvg: 49.05483649758732 | perfectTokens: 6 / 6400 → 0.09% |  | remainingTokens: 614754 (99.98%) | TUTOR.py 100
2025-04-23 02:06:09 | 200 | LR0.00035 | sampledTokens:0.0000 | scheduledSamplingRate:0.0006 | repetitionPenalty:1.2994 | AvgLoss:58.3773 | loss:39.4281 | temperature:0.8001 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:53.3850 | memoryLength:10.0010 | embedNormMean:14.2971 | embedNormStd:10.0812 | embedNormMax:103.7197 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0002 | logitWeightNormMean:91.9360 | logitWeightNormStd:2.5103 | logitWeightNormMax:104.6181 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7336 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5789 | n_weightNormMax:41.2620 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8408 | n_biasesMax:1.9557 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36220 (0.96), W-1:1.01270 (0.03), W8:-1.67833 (0.00), W-1:-1.77199 (0.00), W16:-3.02640 (0.00), W-1:-4.15381 (0.00), W24:-5.22513 (0.00), W-1:-8.03562 (0.00), W32:-9.48183 (0.00) | topTokens[('using', 837), ('Ġlmao', 832), ('ping', 753), ('Ġdiscord', 230), ('Ġ4', 198), ('Ġwanna', 186), ('Ġwill', 161), ('Ġmind', 150), ('Ġ:)', 137), ('Ġworks', 125)] | cheekyAvg: 50.84049825668335 | perfectTokens: 5 / 6400 → 0.08% |  | remainingTokens: 614654 (99.97%) | TUTOR.py 100
2025-04-23 02:06:41 | 300 | LR0.00035 | sampledTokens:1.0000 | scheduledSamplingRate:0.0010 | repetitionPenalty:1.2991 | AvgLoss:65.1459 | loss:58.1973 | temperature:0.8000 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:466.3398 | memoryLength:10.0014 | embedNormMean:14.2971 | embedNormStd:10.0812 | embedNormMax:103.7199 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9360 | logitWeightNormStd:2.5103 | logitWeightNormMax:104.6175 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7336 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5786 | n_weightNormMax:41.2623 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8408 | n_biasesMax:1.9558 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36219 (0.96), W-1:1.01269 (0.03), W8:-1.67833 (0.00), W-1:-1.77200 (0.00), W16:-3.02641 (0.00), W-1:-4.15383 (0.00), W24:-5.22514 (0.00), W-1:-8.03563 (0.00), W32:-9.48184 (0.00) | topTokens[('Ġlmao', 1498), ('ping', 1078), ('using', 992), ('Ġdiscord', 417), ('Ġmind', 288), ("'t", 241), ('Ġ:)', 215), ('Ġwill', 203), ('Ġ4', 198), ('Ġwanna', 189)] | cheekyAvg: 56.8842056274414 | perfectTokens: 2 / 6400 → 0.03% |  | remainingTokens: 614554 (99.95%) | TUTOR.py 100
2025-04-23 02:07:14 | 400 | LR0.00035 | sampledTokens:2.0000 | scheduledSamplingRate:0.0013 | repetitionPenalty:1.2986 | AvgLoss:58.3331 | loss:50.4186 | temperature:0.8001 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:241.3596 | memoryLength:10.0022 | embedNormMean:14.2971 | embedNormStd:10.0812 | embedNormMax:103.7199 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9360 | logitWeightNormStd:2.5103 | logitWeightNormMax:104.6163 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7336 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5785 | n_weightNormMax:41.2626 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8408 | n_biasesMax:1.9558 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36219 (0.96), W-1:1.01270 (0.03), W8:-1.67835 (0.00), W-1:-1.77199 (0.00), W16:-3.02642 (0.00), W-1:-4.15382 (0.00), W24:-5.22515 (0.00), W-1:-8.03563 (0.00), W32:-9.48184 (0.00) | topTokens[('Ġlmao', 1776), ('ping', 1522), ('using', 1097), ('Ġdiscord', 817), ('Ġ:)', 419), ("'t", 337), ('Ġmind', 294), ('Ġwill', 228), ('Ġ4', 225), ('Ġwanna', 224)] | cheekyAvg: 50.80624328613281 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 614454 (99.93%) | TUTOR.py 100
2025-04-23 02:07:47 | 500 | LR0.00035 | sampledTokens:3.0000 | scheduledSamplingRate:0.0015 | repetitionPenalty:1.2985 | AvgLoss:65.3203 | loss:59.2333 | temperature:0.8002 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:223.7649 | memoryLength:10.0012 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7200 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9360 | logitWeightNormStd:2.5103 | logitWeightNormMax:104.6155 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7336 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5785 | n_weightNormMax:41.2631 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8408 | n_biasesMax:1.9558 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1110 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36214 (0.96), W-1:1.01265 (0.03), W8:-1.67835 (0.00), W-1:-1.77204 (0.00), W16:-3.02645 (0.00), W-1:-4.15386 (0.00), W24:-5.22519 (0.00), W-1:-8.03566 (0.00), W32:-9.48189 (0.00) | topTokens[('Ġlmao', 2015), ('ping', 1748), ('using', 1684), ('Ġdiscord', 1003), ('Ġ:)', 470), ('Ġmind', 465), ("'t", 337), ('Ġwill', 321), ('Ġwanna', 279), ('Ġ4', 247)] | cheekyAvg: 57.404424781799314 | perfectTokens: 1 / 6400 → 0.02% |  | remainingTokens: 614354 (99.92%) | TUTOR.py 100
2025-04-23 02:08:20 | 600 | LR0.00035 | sampledTokens:7.0000 | scheduledSamplingRate:0.0018 | repetitionPenalty:1.2982 | AvgLoss:66.2894 | loss:61.1601 | temperature:0.8002 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:271.8920 | memoryLength:10.0016 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7203 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0002 | logitWeightNormMean:91.9360 | logitWeightNormStd:2.5103 | logitWeightNormMax:104.6153 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0009 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6051 | n_weightNormMin:21.5786 | n_weightNormMax:41.2636 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8407 | n_biasesMax:1.9559 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1110 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36212 (0.96), W-1:1.01263 (0.03), W8:-1.67837 (0.00), W-1:-1.77206 (0.00), W16:-3.02647 (0.00), W-1:-4.15389 (0.00), W24:-5.22521 (0.00), W-1:-8.03568 (0.00), W32:-9.48191 (0.00) | topTokens[('Ġlmao', 2244), ('ping', 1986), ('using', 1985), ('Ġdiscord', 1520), ('Ġ:)', 695), ('Ġmind', 509), ('Ġwill', 445), ("'t", 350), ('Ġwanna', 317), ('Ġ4', 247)] | cheekyAvg: 59.12545635223389 | perfectTokens: 4 / 6400 → 0.06% |  | remainingTokens: 614254 (99.90%) | TUTOR.py 100
2025-04-23 02:08:53 | 700 | LR0.00035 | sampledTokens:3.0000 | scheduledSamplingRate:0.0022 | repetitionPenalty:1.2979 | AvgLoss:61.7803 | loss:60.8287 | temperature:0.8003 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:140.5766 | memoryLength:10.0006 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7203 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9360 | logitWeightNormStd:2.5102 | logitWeightNormMax:104.6148 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6051 | n_weightNormMin:21.5785 | n_weightNormMax:41.2637 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8407 | n_biasesMax:1.9559 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1110 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36210 (0.96), W-1:1.01261 (0.03), W8:-1.67841 (0.00), W-1:-1.77208 (0.00), W16:-3.02651 (0.00), W-1:-4.15391 (0.00), W24:-5.22524 (0.00), W-1:-8.03570 (0.00), W32:-9.48192 (0.00) | topTokens[('Ġlmao', 2787), ('using', 2275), ('ping', 2274), ('Ġdiscord', 1616), ('Ġmind', 779), ('Ġ:)', 736), ('Ġwill', 508), ('Ġwanna', 477), ('Ġ3', 418), ("'t", 413)] | cheekyAvg: 54.68607624053955 | perfectTokens: 5 / 6400 → 0.08% |  | remainingTokens: 614154 (99.89%) | TUTOR.py 100
--- 2025-04-23 02:09:38 --- 
[babyllm] right, last time i got to step 80782... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 80782! what am i learning today?
[charis]2025-04-23 02:11:11 | 100 | LR0.00035 | loss:69.2790 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0004 | repetitionPenalty:1.2997 | AvgLoss:61.8696 | temperature:0.8000 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:33.7612 | memoryLength:10.0012 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7204 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3046 | logitWeightNormMean:91.9360 | logitWeightNormStd:2.5102 | logitWeightNormMax:104.6138 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1310 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6051 | n_weightNormMin:21.5784 | n_weightNormMax:41.2642 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8407 | n_biasesMax:1.9559 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1110 | INN_cerebellumStd:4.2881 | sampledTokens:1.0000 | windowWeightsW2:4.36208 (0.96), W-1:1.01260 (0.03), W8:-1.67843 (0.00), W-1:-1.77209 (0.00), W16:-3.02654 (0.00), W-1:-4.15392 (0.00), W24:-5.22526 (0.00), W-1:-8.03570 (0.00), W32:-9.48192 (0.00) | topTokens[('Ġlmao', 605), ('ping', 337), ('using', 328), ('Ġmind', 142), ('Ġhaha', 115), ('Ġwanna', 113), ('Ġ3', 113), ('Ġwill', 98), ('Ġdiscord', 78), ('Ġlistening', 71)] | cheekyAvg: 51.19298732981962 | perfectTokens: 6 / 6400 → 0.09% |  | remainingTokens: 614001 (99.98%) | TUTOR.py 100
2025-04-23 02:11:43 | 200 | LR0.00035 | sampledTokens:0.0000 | scheduledSamplingRate:0.0007 | repetitionPenalty:1.2994 | AvgLoss:64.0579 | loss:77.1380 | temperature:0.8000 | lR:0.0003 | gradientClip:1.0002 | latestLossDelta:103.1207 | memoryLength:10.0004 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7206 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0002 | logitWeightNormMean:91.9360 | logitWeightNormStd:2.5102 | logitWeightNormMax:104.6125 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6052 | n_weightNormMin:21.5789 | n_weightNormMax:41.2649 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8406 | n_biasesMax:1.9559 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1110 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36211 (0.96), W-1:1.01260 (0.03), W8:-1.67840 (0.00), W-1:-1.77209 (0.00), W16:-3.02653 (0.00), W-1:-4.15391 (0.00), W24:-5.22526 (0.00), W-1:-8.03570 (0.00), W32:-9.48192 (0.00) | topTokens[('Ġlmao', 1084), ('using', 896), ('ping', 566), ('Ġmind', 263), ('Ġ3', 243), ('Ġwanna', 226), ('Ġwill', 215), ('Ġdiscord', 210), ('Ġhaha', 161), ('Ġworks', 148)] | cheekyAvg: 58.16686220169068 | perfectTokens: 1 / 6400 → 0.02% |  | remainingTokens: 613901 (99.97%) | TUTOR.py 100
--- 2025-04-23 02:12:01 --- 
[babyllm] right, last time i got to step 81011... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 81011! what am i learning today?
[charis]--- 2025-04-23 02:15:04 --- 
[babyllm] right, last time i got to step 81011... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 81011! what am i learning today?
[charis]--- 2025-04-23 02:18:11 --- 
[babyllm] right, last time i got to step 81011... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 81011! what am i learning today?
[charis]--- 2025-04-23 02:21:11 --- 
[babyllm] right, last time i got to step 81011... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 81011! what am i learning today?
[charis]2025-04-23 02:22:43 | 100 | LR0.00035 | loss:63.1134 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0003 | repetitionPenalty:1.2998 | AvgLoss:58.7179 | temperature:0.8000 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:87.3160 | memoryLength:10.0004 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7207 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3068 | logitWeightNormMean:91.9360 | logitWeightNormStd:2.5102 | logitWeightNormMax:104.6114 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1313 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1843 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6052 | n_weightNormMin:21.5788 | n_weightNormMax:41.2651 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8405 | n_biasesMax:1.9559 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1110 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36209 (0.96), W-1:1.01260 (0.03), W8:-1.67838 (0.00), W-1:-1.77209 (0.00), W16:-3.02651 (0.00), W-1:-4.15391 (0.00), W24:-5.22528 (0.00), W-1:-8.03571 (0.00), W32:-9.48193 (0.00) | topTokens[('Ġlmao', 493), ('ping', 342), ('Ġdiscord', 283), ('Ġ4', 180), ('using', 81), ('Ġok', 71), ("'t", 69), ('Ġter', 67), ('Ġhaha', 63), ('Ġim', 62)] | cheekyAvg: 50.61000077864703 | perfectTokens: 2 / 6400 → 0.03% |  | remainingTokens: 613772 (99.98%) | TUTOR.py 100
--- 2025-04-23 02:23:22 --- 
[babyllm] right, last time i got to step 81201... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 81201! what am i learning today?
[charis]2025-04-23 02:24:54 | 100 | LR0.00035 | loss:72.5601 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0002 | repetitionPenalty:1.2996 | AvgLoss:71.1169 | temperature:0.8000 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:46.5993 | memoryLength:10.0006 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7207 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3099 | logitWeightNormMean:91.9360 | logitWeightNormStd:2.5102 | logitWeightNormMax:104.6089 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1311 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1843 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6052 | n_weightNormMin:21.5782 | n_weightNormMax:41.2663 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8405 | n_biasesMax:1.9559 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1110 | INN_cerebellumStd:4.2881 | sampledTokens:1.0000 | windowWeightsW2:4.36209 (0.96), W-1:1.01260 (0.03), W8:-1.67836 (0.00), W-1:-1.77209 (0.00), W16:-3.02653 (0.00), W-1:-4.15392 (0.00), W24:-5.22529 (0.00), W-1:-8.03571 (0.00), W32:-9.48195 (0.00) | topTokens[('Ġlmao', 584), ('using', 547), ('ping', 182), ('Ġdiscord', 171), ('Ġter', 118), ("'t", 111), ('Ġworks', 102), ('ion', 64), ('Ġphone', 58), ('Ġno', 57)] | cheekyAvg: 59.72230621412689 | perfectTokens: 4 / 6400 → 0.06% |  | remainingTokens: 613582 (99.98%) | TUTOR.py 100
2025-04-23 02:25:26 | 200 | LR0.00035 | sampledTokens:1.0000 | scheduledSamplingRate:0.0004 | repetitionPenalty:1.2992 | AvgLoss:58.7722 | loss:51.0531 | temperature:0.8002 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:58.9094 | memoryLength:10.0020 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7207 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0002 | logitWeightNormMean:91.9359 | logitWeightNormStd:2.5102 | logitWeightNormMax:104.6084 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1843 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6052 | n_weightNormMin:21.5781 | n_weightNormMax:41.2667 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8405 | n_biasesMax:1.9560 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1110 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36209 (0.96), W-1:1.01260 (0.03), W8:-1.67836 (0.00), W-1:-1.77209 (0.00), W16:-3.02653 (0.00), W-1:-4.15392 (0.00), W24:-5.22529 (0.00), W-1:-8.03571 (0.00), W32:-9.48195 (0.00) | topTokens[('using', 1045), ('Ġlmao', 858), ('ping', 666), ('Ġdiscord', 273), ('Ġter', 245), ('Ġwanna', 182), ("'t", 153), ('Ġworks', 148), ('Ġ3', 123), ('igh', 84)] | cheekyAvg: 51.59980897903442 | perfectTokens: 10 / 6400 → 0.16% |  | remainingTokens: 613482 (99.97%) | TUTOR.py 100
2025-04-23 02:25:59 | 300 | LR0.00035 | sampledTokens:1.0000 | scheduledSamplingRate:0.0007 | repetitionPenalty:1.2990 | AvgLoss:60.6163 | loss:45.0315 | temperature:0.8003 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:105.1203 | memoryLength:10.0010 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7207 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9359 | logitWeightNormStd:2.5102 | logitWeightNormMax:104.6084 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1843 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6052 | n_weightNormMin:21.5781 | n_weightNormMax:41.2668 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8405 | n_biasesMax:1.9560 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1110 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36209 (0.96), W-1:1.01260 (0.03), W8:-1.67836 (0.00), W-1:-1.77209 (0.00), W16:-3.02653 (0.00), W-1:-4.15392 (0.00), W24:-5.22529 (0.00), W-1:-8.03571 (0.00), W32:-9.48195 (0.00) | topTokens[('Ġlmao', 1532), ('using', 1202), ('ping', 1037), ('Ġdiscord', 428), ("'t", 376), ('Ġter', 322), ('Ġ3', 217), ('Ġwanna', 192), ('Ġworks', 187), ('Ġ:)', 136)] | cheekyAvg: 53.24704818725586 | perfectTokens: 6 / 6400 → 0.09% |  | remainingTokens: 613382 (99.95%) | TUTOR.py 100
2025-04-23 02:26:31 | 400 | LR0.00035 | sampledTokens:4.0000 | scheduledSamplingRate:0.0010 | repetitionPenalty:1.2986 | AvgLoss:61.3328 | loss:57.9452 | temperature:0.8003 | lR:0.0003 | gradientClip:1.0002 | latestLossDelta:217.9177 | memoryLength:10.0024 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7207 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9359 | logitWeightNormStd:2.5102 | logitWeightNormMax:104.6083 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1844 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6052 | n_weightNormMin:21.5782 | n_weightNormMax:41.2671 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8405 | n_biasesMax:1.9560 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1110 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36208 (0.96), W-1:1.01259 (0.03), W8:-1.67837 (0.00), W-1:-1.77210 (0.00), W16:-3.02653 (0.00), W-1:-4.15392 (0.00), W24:-5.22529 (0.00), W-1:-8.03571 (0.00), W32:-9.48195 (0.00) | topTokens[('Ġlmao', 1618), ('using', 1555), ('ping', 1341), ('Ġdiscord', 889), ('Ġter', 433), ("'t", 378), ('Ġwanna', 225), ('Ġ3', 217), ('Ġ:)', 207), ('Ġworks', 196)] | cheekyAvg: 53.734694938659665 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 613282 (99.93%) | TUTOR.py 100
--- 2025-04-23 02:27:09 --- 
[babyllm] right, last time i got to step 81689... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 81689! what am i learning today?
[charis]2025-04-23 02:28:42 | 100 | LR0.00035 | loss:42.0097 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0003 | repetitionPenalty:1.3996 | AvgLoss:55.8794 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0002 | latestLossDelta:24.5011 | memoryLength:9.9996 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7207 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3006 | logitWeightNormMean:91.9359 | logitWeightNormStd:2.5101 | logitWeightNormMax:104.6075 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1312 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1845 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6052 | n_weightNormMin:21.5782 | n_weightNormMax:41.2674 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9560 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1110 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36206 (0.96), W-1:1.01256 (0.03), W8:-1.67835 (0.00), W-1:-1.77213 (0.00), W16:-3.02654 (0.00), W-1:-4.15395 (0.00), W24:-5.22531 (0.00), W-1:-8.03572 (0.00), W32:-9.48197 (0.00) | topTokens[('using', 671), ('Ġdiscord', 315), ('ping', 210), ('Ġter', 93), ('Ġ:)', 76), ('Ġlistening', 66), ('Ġwanna', 66), ('Ġmind', 61), ('Ġlmao', 56), ('Ġthese', 52)] | cheekyAvg: 47.97738389407887 | perfectTokens: 5 / 6400 → 0.08% |  | remainingTokens: 613094 (99.98%) | TUTOR.py 100
2025-04-23 02:29:15 | 200 | LR0.00035 | sampledTokens:3.0000 | scheduledSamplingRate:0.0006 | repetitionPenalty:1.3993 | AvgLoss:49.2713 | loss:50.1062 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:188.6954 | memoryLength:10.0002 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7207 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9359 | logitWeightNormStd:2.5101 | logitWeightNormMax:104.6068 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1845 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8444 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6052 | n_weightNormMin:21.5783 | n_weightNormMax:41.2674 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9560 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1110 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36204 (0.96), W-1:1.01253 (0.03), W8:-1.67837 (0.00), W-1:-1.77216 (0.00), W16:-3.02656 (0.00), W-1:-4.15399 (0.00), W24:-5.22533 (0.00), W-1:-8.03574 (0.00), W32:-9.48198 (0.00) | topTokens[('using', 972), ('ping', 574), ('Ġlmao', 530), ('Ġdiscord', 411), ('Ġwanna', 186), ('Ġmind', 169), ('Ġ3', 152), ('Ġter', 147), ('Ġphone', 102), ('Ġthese', 98)] | cheekyAvg: 44.55733985900879 | perfectTokens: 2 / 6400 → 0.03% |  | remainingTokens: 612994 (99.97%) | TUTOR.py 100
--- 2025-04-23 02:29:29 --- 
[babyllm] right, last time i got to step 81905... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 81905! what am i learning today?
[charis]2025-04-23 02:31:01 | 100 | LR0.00035 | loss:61.5193 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0004 | repetitionPenalty:1.8995 | AvgLoss:46.7120 | temperature:0.8001 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:20.8081 | memoryLength:9.9990 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7207 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3038 | logitWeightNormMean:91.9359 | logitWeightNormStd:2.5101 | logitWeightNormMax:104.6054 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1309 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1845 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6052 | n_weightNormMin:21.5782 | n_weightNormMax:41.2676 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9560 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1111 | INN_cerebellumStd:4.2881 | sampledTokens:2.0000 | windowWeightsW-1:4.36202 (0.96), W-1:1.01251 (0.03), W-1:-1.67838 (0.00), W-1:-1.77218 (0.00), W2:-3.02653 (0.00), W8:-4.15403 (0.00), W16:-5.22539 (0.00), W42:-8.03575 (0.00), W32:-9.48200 (0.00) | topTokens[('Ġlmao', 465), ('using', 441), ('Ġdiscord', 237), ('Ġhaha', 204), ('ping', 181), ('Ġ3', 174), ('Ġter', 100), ('hh', 90), ('ever', 81), ('Ġbe', 68)] | cheekyAvg: 41.61135959625244 | perfectTokens: 0 / 6400 → 0.00% |  | remainingTokens: 612878 (99.98%) | TUTOR.py 100
--- 2025-04-23 02:31:25 --- 
[babyllm] right, last time i got to step 82049... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 82049! what am i learning today?
[charis]2025-04-23 02:32:57 | 100 | LR0.00035 | loss:35.2808 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0003 | repetitionPenalty:1.8997 | AvgLoss:45.5035 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:17.5446 | memoryLength:9.9986 | embedNormMean:14.2972 | embedNormStd:10.0813 | embedNormMax:103.7210 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3140 | logitWeightNormMean:91.9359 | logitWeightNormStd:2.5101 | logitWeightNormMax:104.6037 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1312 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1845 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6053 | n_weightNormMin:21.5778 | n_weightNormMax:41.2679 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9560 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1111 | INN_cerebellumStd:4.2881 | windowWeightsW-1:4.36202 (0.96), W-1:1.01252 (0.03), W-1:-1.67837 (0.00), W-1:-1.77217 (0.00), W2:-3.02644 (0.00), W8:-4.15408 (0.00), W16:-5.22543 (0.00), W24:-8.03578 (0.00), W32:-9.48197 (0.00) | topTokens[('ping', 438), ('Ġlmao', 371), ('Ġdiscord', 269), ('using', 225), ('Ġ:)', 129), ('ever', 127), ('er', 96), ('Ġwill', 84), ('Ġter', 76), ('d', 73)] | cheekyAvg: 39.848369878881115 | perfectTokens: 1 / 6400 → 0.02% |  | remainingTokens: 612734 (99.98%) | TUTOR.py 100
2025-04-23 02:33:30 | 200 | LR0.00035 | sampledTokens:2.0000 | scheduledSamplingRate:0.0007 | repetitionPenalty:1.8995 | AvgLoss:55.2877 | loss:68.5700 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:133.3491 | memoryLength:9.9998 | embedNormMean:14.2972 | embedNormStd:10.0813 | embedNormMax:103.7210 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9359 | logitWeightNormStd:2.5101 | logitWeightNormMax:104.6033 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1845 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6053 | n_weightNormMin:21.5774 | n_weightNormMax:41.2678 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9560 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1111 | INN_cerebellumStd:4.2881 | windowWeightsW-1:4.36203 (0.96), W-1:1.01252 (0.03), W-1:-1.67837 (0.00), W-1:-1.77217 (0.00), W2:-3.02639 (0.00), W8:-4.15413 (0.00), W16:-5.22545 (0.00), W24:-8.03578 (0.00), W32:-9.48197 (0.00) | topTokens[('Ġdiscord', 757), ('ping', 727), ('Ġlmao', 455), ('Ġ:)', 423), ('using', 397), ('er', 192), ('ever', 136), ('Ġter', 133), ('Ġwill', 125), ('Ġsounds', 87)] | cheekyAvg: 50.92052459716797 | perfectTokens: 0 / 6400 → 0.00% |  | remainingTokens: 612634 (99.97%) | TUTOR.py 100
2025-04-23 02:34:03 | 300 | LR0.00035 | sampledTokens:3.0000 | scheduledSamplingRate:0.0010 | repetitionPenalty:1.8992 | AvgLoss:52.4521 | loss:55.1375 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0002 | latestLossDelta:203.8465 | memoryLength:9.9994 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7211 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9357 | logitWeightNormStd:2.5100 | logitWeightNormMax:104.6030 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1846 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6053 | n_weightNormMin:21.5776 | n_weightNormMax:41.2678 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9560 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1111 | INN_cerebellumStd:4.2881 | windowWeightsW-1:4.36202 (0.96), W-1:1.01252 (0.03), W-1:-1.67838 (0.00), W-1:-1.77218 (0.00), W2:-3.02635 (0.00), W8:-4.15416 (0.00), W16:-5.22547 (0.00), W24:-8.03578 (0.00), W32:-9.48197 (0.00) | topTokens[('Ġdiscord', 1071), ('ping', 1041), ('Ġlmao', 669), ('using', 636), ('Ġ:)', 477), ('er', 192), ('ever', 189), ('Ġwill', 164), ('Ġter', 161), ("'t", 131)] | cheekyAvg: 46.65912805557251 | perfectTokens: 5 / 6400 → 0.08% |  | remainingTokens: 612534 (99.95%) | TUTOR.py 100
2025-04-23 02:34:37 | 400 | LR0.00035 | sampledTokens:6.0000 | scheduledSamplingRate:0.0012 | repetitionPenalty:1.8989 | AvgLoss:63.6653 | loss:42.2580 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:144.0311 | memoryLength:9.9990 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7211 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9357 | logitWeightNormStd:2.5100 | logitWeightNormMax:104.6024 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0015 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1846 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6053 | n_weightNormMin:21.5776 | n_weightNormMax:41.2678 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9560 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1111 | INN_cerebellumStd:4.2881 | windowWeightsW-1:4.36201 (0.96), W-1:1.01251 (0.03), W-1:-1.67838 (0.00), W-1:-1.77218 (0.00), W2:-3.02628 (0.00), W8:-4.15421 (0.00), W16:-5.22552 (0.00), W24:-8.03583 (0.00), W32:-9.48198 (0.00) | topTokens[('ping', 1393), ('Ġdiscord', 1303), ('using', 978), ('Ġlmao', 934), ('Ġ:)', 581), ("'t", 298), ('Ġter', 205), ('ever', 201), ('er', 192), ('Ġwill', 170)] | cheekyAvg: 57.779349098205564 | perfectTokens: 1 / 6400 → 0.02% |  | remainingTokens: 612434 (99.93%) | TUTOR.py 100
2025-04-23 02:35:10 | 500 | LR0.00035 | sampledTokens:7.0000 | scheduledSamplingRate:0.0015 | repetitionPenalty:1.8986 | AvgLoss:50.6835 | loss:109.2078 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0002 | latestLossDelta:39.2999 | memoryLength:9.9990 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7211 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9357 | logitWeightNormStd:2.5100 | logitWeightNormMax:104.6018 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1846 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6053 | n_weightNormMin:21.5772 | n_weightNormMax:41.2679 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9560 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1111 | INN_cerebellumStd:4.2881 | windowWeightsW-1:4.36204 (0.96), W-1:1.01254 (0.03), W-1:-1.67835 (0.00), W-1:-1.77215 (0.00), W2:-3.02624 (0.00), W8:-4.15425 (0.00), W16:-5.22555 (0.00), W24:-8.03584 (0.00), W32:-9.48196 (0.00) | topTokens[('ping', 1651), ('Ġdiscord', 1388), ('Ġlmao', 1266), ('using', 1233), ('Ġ:)', 712), ('ever', 347), ("'t", 298), ('Ġter', 246), ('er', 224), ('Ġ4', 216)] | cheekyAvg: 47.4854843711853 | perfectTokens: 4 / 6400 → 0.06% |  | remainingTokens: 612334 (99.92%) | TUTOR.py 100
2025-04-23 02:35:43 | 600 | LR0.00035 | sampledTokens:4.0000 | scheduledSamplingRate:0.0017 | repetitionPenalty:1.8983 | AvgLoss:60.9236 | loss:31.0359 | temperature:0.8002 | lR:0.0003 | gradientClip:1.0002 | latestLossDelta:24.0781 | memoryLength:9.9970 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7211 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9357 | logitWeightNormStd:2.5100 | logitWeightNormMax:104.6016 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1846 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6053 | n_weightNormMin:21.5770 | n_weightNormMax:41.2680 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9560 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1111 | INN_cerebellumStd:4.2881 | windowWeightsW-1:4.36202 (0.96), W-1:1.01251 (0.03), W-1:-1.67838 (0.00), W-1:-1.77218 (0.00), W2:-3.02620 (0.00), W8:-4.15427 (0.00), W16:-5.22558 (0.00), W24:-8.03585 (0.00), W32:-9.48198 (0.00) | topTokens[('ping', 1875), ('Ġdiscord', 1727), ('Ġlmao', 1475), ('using', 1327), ('Ġ:)', 870), ('Ġter', 434), ('ever', 379), ("'t", 329), ('Ġ4', 317), ('er', 256)] | cheekyAvg: 54.14101131439209 | perfectTokens: 5 / 6400 → 0.08% |  | remainingTokens: 612234 (99.90%) | TUTOR.py 100
2025-04-23 02:36:17 | 700 | LR0.00035 | sampledTokens:6.0000 | scheduledSamplingRate:0.0020 | repetitionPenalty:1.8980 | AvgLoss:59.8543 | loss:33.6612 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0003 | latestLossDelta:91.9235 | memoryLength:9.9952 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7213 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9357 | logitWeightNormStd:2.5100 | logitWeightNormMax:104.6011 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1845 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6053 | n_weightNormMin:21.5768 | n_weightNormMax:41.2680 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9560 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1111 | INN_cerebellumStd:4.2881 | windowWeightsW-1:4.36199 (0.96), W-1:1.01249 (0.03), W-1:-1.67841 (0.00), W-1:-1.77220 (0.00), W2:-3.02614 (0.00), W8:-4.15430 (0.00), W16:-5.22560 (0.00), W24:-8.03587 (0.00), W32:-9.48201 (0.00) | topTokens[('ping', 2158), ('Ġdiscord', 1862), ('using', 1857), ('Ġlmao', 1722), ('Ġ:)', 1005), ('Ġter', 512), ('Ġ4', 413), ('ever', 397), ("'t", 350), ('Ġwill', 339)] | cheekyAvg: 54.58755561828613 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 612134 (99.89%) | TUTOR.py 100
2025-04-23 02:36:50 | 800 | LR0.00035 | sampledTokens:5.0000 | scheduledSamplingRate:0.0023 | repetitionPenalty:1.8975 | AvgLoss:54.3477 | loss:49.7997 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0004 | latestLossDelta:121.9142 | memoryLength:9.9938 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7213 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9356 | logitWeightNormStd:2.5099 | logitWeightNormMax:104.6006 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1845 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6053 | n_weightNormMin:21.5767 | n_weightNormMax:41.2680 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9560 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1111 | INN_cerebellumStd:4.2881 | windowWeightsW-1:4.36199 (0.96), W-1:1.01248 (0.03), W-1:-1.67841 (0.00), W-1:-1.77221 (0.00), W2:-3.02611 (0.00), W8:-4.15432 (0.00), W16:-5.22562 (0.00), W24:-8.03588 (0.00), W32:-9.48202 (0.00) | topTokens[('ping', 2450), ('Ġdiscord', 2206), ('using', 2061), ('Ġlmao', 2041), ('Ġ:)', 1080), ('Ġter', 603), ('ever', 419), ('Ġ4', 413), ("'t", 385), ('ion', 358)] | cheekyAvg: 48.56298164367676 | perfectTokens: 0 / 6400 → 0.00% |  | remainingTokens: 612034 (99.87%) | TUTOR.py 100
2025-04-23 02:37:23 | 900 | LR0.00035 | sampledTokens:4.0000 | scheduledSamplingRate:0.0024 | repetitionPenalty:1.8971 | AvgLoss:48.1747 | loss:68.4906 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0005 | latestLossDelta:113.2765 | memoryLength:9.9938 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7213 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9356 | logitWeightNormStd:2.5099 | logitWeightNormMax:104.5997 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1845 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6053 | n_weightNormMin:21.5766 | n_weightNormMax:41.2680 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9560 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1111 | INN_cerebellumStd:4.2881 | windowWeightsW-1:4.36195 (0.96), W-1:1.01244 (0.03), W-1:-1.67845 (0.00), W-1:-1.77225 (0.00), W2:-3.02603 (0.00), W8:-4.15433 (0.00), W16:-5.22566 (0.00), W24:-8.03590 (0.00), W32:-9.48205 (0.00) | topTokens[('ping', 2883), ('Ġdiscord', 2410), ('Ġlmao', 2340), ('using', 2214), ('Ġ:)', 1137), ('Ġter', 637), ('ever', 473), ('Ġ4', 413), ('ion', 390), ("'t", 385)] | cheekyAvg: 43.99907691955566 | perfectTokens: 1 / 6400 → 0.02% |  | remainingTokens: 611934 (99.85%) | TUTOR.py 100
2025-04-23 02:38:00 | 1000 | LR0.00035 | sampledTokens:7.0000 | scheduledSamplingRate:0.0027 | repetitionPenalty:1.8968 | AvgLoss:63.5635 | loss:28.8186 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0004 | latestLossDelta:332.7539 | memoryLength:9.9940 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7213 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9356 | logitWeightNormStd:2.5099 | logitWeightNormMax:104.5987 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1846 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6053 | n_weightNormMin:21.5766 | n_weightNormMax:41.2682 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9560 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1112 | INN_cerebellumStd:4.2881 | windowWeightsW-1:4.36189 (0.96), W-1:1.01239 (0.03), W-1:-1.67851 (0.00), W-1:-1.77230 (0.00), W2:-3.02594 (0.00), W8:-4.15436 (0.00), W16:-5.22572 (0.00), W24:-8.03595 (0.00), W32:-9.48209 (0.00) | topTokens[('ping', 3356), ('Ġdiscord', 2637), ('Ġlmao', 2495), ('using', 2450), ('Ġ:)', 1337), ('Ġter', 721), ('ever', 577), ("'t", 535), ('Ġ4', 452), ('Ġwill', 401)] | cheekyAvg: 56.084308013916015 | perfectTokens: 2 / 6400 → 0.03% |  | remainingTokens: 611834 (99.84%) | TUTOR.py 100
2025-04-23 02:38:33 | 1100 | LR0.00035 | sampledTokens:6.0000 | scheduledSamplingRate:0.0033 | repetitionPenalty:1.8964 | AvgLoss:52.9301 | loss:32.3138 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0003 | latestLossDelta:124.6760 | memoryLength:9.9940 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7213 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9356 | logitWeightNormStd:2.5099 | logitWeightNormMax:104.5981 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1846 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5765 | n_weightNormMax:41.2683 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9560 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1112 | INN_cerebellumStd:4.2881 | windowWeightsW-1:4.36190 (0.96), W-1:1.01239 (0.03), W-1:-1.67850 (0.00), W-1:-1.77230 (0.00), W2:-3.02590 (0.00), W8:-4.15442 (0.00), W16:-5.22574 (0.00), W24:-8.03596 (0.00), W32:-9.48210 (0.00) | topTokens[('ping', 3631), ('Ġdiscord', 2906), ('Ġlmao', 2772), ('using', 2660), ('Ġ:)', 1525), ('Ġter', 765), ("'t", 731), ('ever', 655), ('ion', 473), ('Ġ4', 471)] | cheekyAvg: 49.829317054748536 | perfectTokens: 1 / 6400 → 0.02% |  | remainingTokens: 611734 (99.82%) | TUTOR.py 100
2025-04-23 02:39:07 | 1200 | LR0.00035 | sampledTokens:13.0000 | scheduledSamplingRate:0.0035 | repetitionPenalty:1.8961 | AvgLoss:49.2088 | loss:57.3118 | temperature:0.8002 | lR:0.0003 | gradientClip:1.0002 | latestLossDelta:100.8266 | memoryLength:9.9934 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7213 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9356 | logitWeightNormStd:2.5099 | logitWeightNormMax:104.5977 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1846 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5764 | n_weightNormMax:41.2683 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9560 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1112 | INN_cerebellumStd:4.2881 | windowWeightsW-1:4.36190 (0.96), W-1:1.01239 (0.03), W-1:-1.67850 (0.00), W-1:-1.77230 (0.00), W2:-3.02586 (0.00), W8:-4.15442 (0.00), W16:-5.22574 (0.00), W24:-8.03597 (0.00), W32:-9.48211 (0.00) | topTokens[('ping', 3934), ('Ġdiscord', 3159), ('Ġlmao', 3099), ('using', 2978), ('Ġ:)', 1529), ('Ġter', 910), ("'t", 871), ('ever', 681), ('ion', 554), ('Ġ4', 471)] | cheekyAvg: 45.91904857635498 | perfectTokens: 2 / 6400 → 0.03% |  | remainingTokens: 611634 (99.80%) | TUTOR.py 100
--- 2025-04-23 02:39:22 --- 
[babyllm] right, last time i got to step 83269... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 83269! what am i learning today?
[charis]--- 2025-04-23 02:40:43 --- 
[babyllm] right, last time i got to step 83269... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 83269! what am i learning today?
[charis]2025-04-23 02:42:18 | 100 | LR0.00035 | loss:55.5512 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0002 | repetitionPenalty:1.8996 | AvgLoss:43.5725 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:46.1707 | memoryLength:10.0000 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7213 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3098 | logitWeightNormMean:91.9356 | logitWeightNormStd:2.5098 | logitWeightNormMax:104.5967 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1311 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1846 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5762 | n_weightNormMax:41.2684 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9561 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1112 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36186 (0.96), W8:1.01242 (0.03), W16:-1.67848 (0.00), W24:-1.77231 (0.00), W32:-3.02587 (0.00), W-1:-4.15444 (0.00), W-1:-5.22574 (0.00), W-1:-8.03598 (0.00), W-1:-9.48211 (0.00) | topTokens[('using', 332), ('ping', 273), ('Ġdiscord', 213), ('Ġlmao', 170), ('ever', 111), ('Ġwill', 110), ('ack', 91), ('ion', 91), ("'t", 72), ('Ġ:)', 67)] | cheekyAvg: 38.115525750552905 | perfectTokens: 6 / 6400 → 0.09% |  | remainingTokens: 611514 (99.98%) | TUTOR.py 100
2025-04-23 02:42:51 | 200 | LR0.00035 | sampledTokens:2.0000 | scheduledSamplingRate:0.0005 | repetitionPenalty:1.8993 | AvgLoss:43.6628 | loss:35.6472 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:133.3917 | memoryLength:9.9984 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7213 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9356 | logitWeightNormStd:2.5098 | logitWeightNormMax:104.5959 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1846 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5755 | n_weightNormMax:41.2683 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9561 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1112 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36186 (0.96), W8:1.01241 (0.03), W16:-1.67848 (0.00), W24:-1.77233 (0.00), W32:-3.02588 (0.00), W-1:-4.15445 (0.00), W-1:-5.22575 (0.00), W-1:-8.03598 (0.00), W-1:-9.48212 (0.00) | topTokens[('ping', 562), ('Ġlmao', 526), ('Ġdiscord', 447), ('using', 423), ("'t", 264), ('Ġ4', 195), ('ion', 186), ('Ġwill', 171), ('Ġ:)', 157), ('ever', 118)] | cheekyAvg: 37.38832347869873 | perfectTokens: 1 / 6400 → 0.02% |  | remainingTokens: 611414 (99.97%) | TUTOR.py 100
2025-04-23 02:43:25 | 300 | LR0.00035 | sampledTokens:2.0000 | scheduledSamplingRate:0.0007 | repetitionPenalty:1.8989 | AvgLoss:46.3320 | loss:38.7840 | temperature:0.8000 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:103.3713 | memoryLength:9.9986 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7213 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9356 | logitWeightNormStd:2.5098 | logitWeightNormMax:104.5952 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1845 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5753 | n_weightNormMax:41.2683 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9561 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1112 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36184 (0.96), W8:1.01242 (0.03), W16:-1.67849 (0.00), W24:-1.77235 (0.00), W32:-3.02590 (0.00), W-1:-4.15448 (0.00), W-1:-5.22577 (0.00), W-1:-8.03599 (0.00), W-1:-9.48213 (0.00) | topTokens[('Ġlmao', 856), ('ping', 852), ('Ġdiscord', 644), ('using', 482), ("'t", 454), ('r', 233), ('Ġsmo', 206), ('Ġ4', 195), ('Ġ:)', 191), ('ion', 186)] | cheekyAvg: 41.20934881210327 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 611314 (99.95%) | TUTOR.py 100
2025-04-23 02:43:58 | 400 | LR0.00035 | sampledTokens:2.0000 | scheduledSamplingRate:0.0011 | repetitionPenalty:1.8986 | AvgLoss:55.7196 | loss:70.0046 | temperature:0.8001 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:134.3180 | memoryLength:9.9996 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7214 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9356 | logitWeightNormStd:2.5098 | logitWeightNormMax:104.5947 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0015 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1844 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5752 | n_weightNormMax:41.2683 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8403 | n_biasesMax:1.9561 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1112 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36184 (0.96), W8:1.01244 (0.03), W16:-1.67848 (0.00), W24:-1.77233 (0.00), W32:-3.02589 (0.00), W-1:-4.15446 (0.00), W-1:-5.22575 (0.00), W-1:-8.03598 (0.00), W-1:-9.48212 (0.00) | topTokens[('ping', 1208), ('Ġlmao', 1040), ('Ġdiscord', 894), ("'t", 763), ('using', 605), ('Ġter', 233), ('r', 233), ('ever', 219), ('Ġwill', 215), ('Ġsmo', 206)] | cheekyAvg: 50.379022998809816 | perfectTokens: 5 / 6400 → 0.08% |  | remainingTokens: 611214 (99.93%) | TUTOR.py 100
2025-04-23 02:44:31 | 500 | LR0.00035 | sampledTokens:3.0000 | scheduledSamplingRate:0.0014 | repetitionPenalty:1.8982 | AvgLoss:54.1631 | loss:70.0029 | temperature:0.8002 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:45.9415 | memoryLength:9.9996 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7214 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9355 | logitWeightNormStd:2.5098 | logitWeightNormMax:104.5938 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1843 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5748 | n_weightNormMax:41.2684 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8403 | n_biasesMax:1.9561 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1112 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36182 (0.96), W8:1.01246 (0.03), W16:-1.67849 (0.00), W24:-1.77233 (0.00), W32:-3.02589 (0.00), W-1:-4.15446 (0.00), W-1:-5.22575 (0.00), W-1:-8.03597 (0.00), W-1:-9.48211 (0.00) | topTokens[('ping', 1468), ('Ġlmao', 1378), ('Ġdiscord', 1079), ("'t", 916), ('using', 754), ('ion', 351), ('Ġ:)', 349), ('Ġter', 314), ('ever', 269), ('r', 233)] | cheekyAvg: 49.03005964279175 | perfectTokens: 5 / 6400 → 0.08% |  | remainingTokens: 611114 (99.92%) | TUTOR.py 100
--- 2025-04-23 02:45:01 --- 
[babyllm] right, last time i got to step 83828... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 83828! what am i learning today?
[charis]--- 2025-04-23 02:47:18 --- 
[babyllm] right, last time i got to step 83828... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 83828! what am i learning today?
[charis]--- 2025-04-23 02:52:49 --- 
[babyllm] right, last time i got to step 83828... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 83828! what am i learning today?
[charis]2025-04-23 02:54:20 | 100 | LR0.00035 | loss:86.7229 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0003 | repetitionPenalty:1.8997 | AvgLoss:50.2413 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:24.7902 | memoryLength:10.0000 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7214 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.2980 | logitWeightNormMean:91.9355 | logitWeightNormStd:2.5097 | logitWeightNormMax:104.5927 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1311 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7333 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5747 | n_weightNormMax:41.2684 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8403 | n_biasesMax:1.9561 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1112 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36173 (0.96), W8:1.01248 (0.03), W16:-1.67855 (0.00), W24:-1.77240 (0.00), W32:-3.02594 (0.00), W-1:-4.15452 (0.00), W-1:-5.22581 (0.00), W-1:-8.03602 (0.00), W-1:-9.48216 (0.00) | topTokens[('using', 369), ('Ġdiscord', 257), ('Ġlmao', 222), ('ping', 206), ('Ġim', 128), ('ion', 89), ("'t", 76), ('Ġ:)', 63), ('Ġter', 58), ('d', 58)] | cheekyAvg: 44.70139166888069 | perfectTokens: 2 / 6400 → 0.03% |  | remainingTokens: 610955 (99.98%) | TUTOR.py 100
2025-04-23 02:54:52 | 200 | LR0.00035 | sampledTokens:0.0000 | scheduledSamplingRate:0.0005 | repetitionPenalty:1.8994 | AvgLoss:65.9170 | loss:47.7935 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:168.8262 | memoryLength:9.9992 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7214 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9355 | logitWeightNormStd:2.5097 | logitWeightNormMax:104.5913 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7333 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5746 | n_weightNormMax:41.2684 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8403 | n_biasesMax:1.9561 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36168 (0.96), W8:1.01249 (0.03), W16:-1.67856 (0.00), W24:-1.77244 (0.00), W32:-3.02599 (0.00), W-1:-4.15456 (0.00), W-1:-5.22585 (0.00), W-1:-8.03606 (0.00), W-1:-9.48220 (0.00) | topTokens[('Ġlmao', 630), ('using', 512), ("'t", 382), ('Ġdiscord', 328), ('ping', 290), ('ed', 267), ('ion', 226), ('Ġter', 150), ('Ġ:)', 130), ('Ġim', 128)] | cheekyAvg: 56.41388156890869 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 610855 (99.97%) | TUTOR.py 100
2025-04-23 02:55:24 | 300 | LR0.00035 | sampledTokens:3.0000 | scheduledSamplingRate:0.0009 | repetitionPenalty:1.8990 | AvgLoss:51.7125 | loss:58.7177 | temperature:0.7996 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:217.9530 | memoryLength:9.9992 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7214 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9355 | logitWeightNormStd:2.5097 | logitWeightNormMax:104.5897 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7333 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5744 | n_weightNormMax:41.2686 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8403 | n_biasesMax:1.9561 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36167 (0.96), W8:1.01253 (0.03), W16:-1.67855 (0.00), W24:-1.77243 (0.00), W32:-3.02597 (0.00), W-1:-4.15455 (0.00), W-1:-5.22584 (0.00), W-1:-8.03606 (0.00), W-1:-9.48220 (0.00) | topTokens[('Ġlmao', 1041), ('using', 857), ("'t", 543), ('ping', 509), ('Ġdiscord', 419), ('ed', 267), ('ion', 226), ('Ġter', 213), ('Ġwas', 183), ('p', 158)] | cheekyAvg: 45.980178604125975 | perfectTokens: 5 / 6400 → 0.08% |  | remainingTokens: 610755 (99.95%) | TUTOR.py 100
2025-04-23 02:55:57 | 400 | LR0.00035 | sampledTokens:3.0000 | scheduledSamplingRate:0.0013 | repetitionPenalty:1.8985 | AvgLoss:51.3132 | loss:58.3709 | temperature:0.7997 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:57.7005 | memoryLength:10.0004 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7216 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9355 | logitWeightNormStd:2.5097 | logitWeightNormMax:104.5890 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5743 | n_weightNormMax:41.2681 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8403 | n_biasesMax:1.9561 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36165 (0.96), W8:1.01259 (0.03), W16:-1.67854 (0.00), W24:-1.77241 (0.00), W32:-3.02595 (0.00), W-1:-4.15453 (0.00), W-1:-5.22583 (0.00), W-1:-8.03604 (0.00), W-1:-9.48218 (0.00) | topTokens[('Ġlmao', 1461), ('using', 1098), ("'t", 890), ('ping', 791), ('Ġdiscord', 556), ('ion', 290), ('ed', 267), ('Ġter', 254), ('d', 207), ('Ġwas', 194)] | cheekyAvg: 45.63938039779663 | perfectTokens: 2 / 6400 → 0.03% |  | remainingTokens: 610655 (99.93%) | TUTOR.py 100
--- 2025-04-23 02:56:39 --- 
[babyllm] right, last time i got to step 84323... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 84323! what am i learning today?
[charis]--- 2025-04-23 02:58:10 --- 
[babyllm] right, last time i got to step 84323... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 84323! what am i learning today?
[charis]--- 2025-04-23 03:00:17 --- 
[babyllm] right, last time i got to step 84323... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 84323! what am i learning today?
[charis]2025-04-23 03:01:49 | 100 | LR0.00035 | loss:45.7651 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0002 | repetitionPenalty:1.8996 | AvgLoss:70.4679 | temperature:0.8000 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:54.3204 | memoryLength:9.9996 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7216 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3113 | logitWeightNormMean:91.9355 | logitWeightNormStd:2.5096 | logitWeightNormMax:104.5873 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1311 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5739 | n_weightNormMax:41.2680 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8402 | n_biasesMax:1.9562 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36157 (0.96), W8:1.01259 (0.03), W16:-1.67859 (0.00), W24:-1.77246 (0.00), W32:-3.02602 (0.00), W-1:-4.15460 (0.00), W-1:-5.22590 (0.00), W-1:-8.03611 (0.00), W-1:-9.48225 (0.00) | topTokens[('Ġdiscord', 506), ('using', 386), ('ping', 108), ('Ġter', 76), ('Ġhear', 72), ('Ġ:)', 62), ('Ġcause', 62), ('Ġart', 61), ('Ġwanna', 43), ('we', 42)] | cheekyAvg: 60.65893337773342 | perfectTokens: 2 / 6400 → 0.03% |  | remainingTokens: 610460 (99.98%) | TUTOR.py 100
2025-04-23 03:02:21 | 200 | LR0.00035 | sampledTokens:0.0000 | scheduledSamplingRate:0.0005 | repetitionPenalty:1.8994 | AvgLoss:44.6993 | loss:36.2866 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:107.0610 | memoryLength:10.0002 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7216 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9355 | logitWeightNormStd:2.5096 | logitWeightNormMax:104.5869 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5737 | n_weightNormMax:41.2680 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8402 | n_biasesMax:1.9562 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36156 (0.96), W8:1.01260 (0.03), W16:-1.67857 (0.00), W24:-1.77245 (0.00), W32:-3.02603 (0.00), W-1:-4.15460 (0.00), W-1:-5.22590 (0.00), W-1:-8.03612 (0.00), W-1:-9.48226 (0.00) | topTokens[('Ġdiscord', 743), ('ping', 723), ('using', 439), ("'t", 420), ('Ġ:)', 225), ('Ġlmao', 206), ('Ġter', 152), ('Ġ4', 88), ('Ġbe', 77), ('ly', 76)] | cheekyAvg: 40.59972303390503 | perfectTokens: 16 / 6400 → 0.25% |  | remainingTokens: 610360 (99.97%) | TUTOR.py 100
2025-04-23 03:02:53 | 300 | LR0.00035 | sampledTokens:3.0000 | scheduledSamplingRate:0.0008 | repetitionPenalty:1.8991 | AvgLoss:54.2159 | loss:73.9037 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:155.1086 | memoryLength:10.0024 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7216 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9355 | logitWeightNormStd:2.5096 | logitWeightNormMax:104.5861 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5737 | n_weightNormMax:41.2681 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8402 | n_biasesMax:1.9563 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36153 (0.96), W8:1.01260 (0.03), W16:-1.67860 (0.00), W24:-1.77248 (0.00), W32:-3.02605 (0.00), W-1:-4.15461 (0.00), W-1:-5.22591 (0.00), W-1:-8.03614 (0.00), W-1:-9.48228 (0.00) | topTokens[('Ġdiscord', 1102), ('ping', 1096), ('using', 727), ("'t", 464), ('Ġlmao', 340), ('Ġ:)', 274), ('Ġter', 206), ('na', 174), ('Ġbe', 109), ('Ġu', 108)] | cheekyAvg: 48.182722911834716 | perfectTokens: 4 / 6400 → 0.06% |  | remainingTokens: 610260 (99.95%) | TUTOR.py 100
2025-04-23 03:03:25 | 400 | LR0.00035 | sampledTokens:2.0000 | scheduledSamplingRate:0.0010 | repetitionPenalty:1.8988 | AvgLoss:56.6651 | loss:38.9801 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:89.4193 | memoryLength:10.0026 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7216 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0005 | logitWeightNormMean:91.9355 | logitWeightNormStd:2.5096 | logitWeightNormMax:104.5855 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5736 | n_weightNormMax:41.2681 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8402 | n_biasesMax:1.9563 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36153 (0.96), W8:1.01263 (0.03), W16:-1.67855 (0.00), W24:-1.77244 (0.00), W32:-3.02602 (0.00), W-1:-4.15458 (0.00), W-1:-5.22588 (0.00), W-1:-8.03611 (0.00), W-1:-9.48225 (0.00) | topTokens[('Ġdiscord', 1319), ('ping', 1262), ('using', 913), ('Ġlmao', 691), ("'t", 625), ('Ġ:)', 361), ('Ġter', 225), ('Ġbe', 175), ('na', 174), ('igh', 138)] | cheekyAvg: 49.6155757522583 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 610160 (99.93%) | TUTOR.py 100
2025-04-23 03:03:58 | 500 | LR0.00035 | sampledTokens:3.0000 | scheduledSamplingRate:0.0014 | repetitionPenalty:1.8983 | AvgLoss:53.6743 | loss:34.3829 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:79.7618 | memoryLength:10.0026 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9354 | logitWeightNormStd:2.5096 | logitWeightNormMax:104.5848 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0015 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5735 | n_weightNormMax:41.2681 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8402 | n_biasesMax:1.9563 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36151 (0.96), W8:1.01265 (0.03), W16:-1.67852 (0.00), W24:-1.77242 (0.00), W32:-3.02602 (0.00), W-1:-4.15457 (0.00), W-1:-5.22587 (0.00), W-1:-8.03609 (0.00), W-1:-9.48223 (0.00) | topTokens[('Ġdiscord', 1516), ('ping', 1428), ('using', 1123), ('Ġlmao', 1018), ("'t", 625), ('d', 446), ('Ġ:)', 376), ('Ġter', 266), ('na', 189), ('Ġbe', 175)] | cheekyAvg: 47.89949739456177 | perfectTokens: 2 / 6400 → 0.03% |  | remainingTokens: 610060 (99.92%) | TUTOR.py 100
2025-04-23 03:04:30 | 600 | LR0.00035 | sampledTokens:6.0000 | scheduledSamplingRate:0.0017 | repetitionPenalty:1.8980 | AvgLoss:51.9161 | loss:67.1158 | temperature:0.8004 | lR:0.0003 | gradientClip:1.0002 | latestLossDelta:182.9974 | memoryLength:10.0022 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0005 | logitWeightNormMean:91.9354 | logitWeightNormStd:2.5095 | logitWeightNormMax:104.5838 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5735 | n_weightNormMax:41.2681 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8403 | n_biasesMax:1.9563 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36146 (0.96), W8:1.01266 (0.03), W16:-1.67854 (0.00), W24:-1.77245 (0.00), W32:-3.02603 (0.00), W-1:-4.15458 (0.00), W-1:-5.22588 (0.00), W-1:-8.03610 (0.00), W-1:-9.48224 (0.00) | topTokens[('Ġdiscord', 1778), ('ping', 1604), ('Ġlmao', 1476), ('using', 1195), ("'t", 1120), ('d', 446), ('Ġ:)', 435), ('Ġter', 306), ('Ġ5', 273), ('Ġwill', 202)] | cheekyAvg: 48.200112953186036 | perfectTokens: 2 / 6400 → 0.03% |  | remainingTokens: 609960 (99.90%) | TUTOR.py 100
2025-04-23 03:05:02 | 700 | LR0.00035 | sampledTokens:0.0000 | scheduledSamplingRate:0.0019 | repetitionPenalty:1.8978 | AvgLoss:47.2305 | loss:47.5358 | temperature:0.8004 | lR:0.0003 | gradientClip:1.0002 | latestLossDelta:52.5717 | memoryLength:10.0024 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9354 | logitWeightNormStd:2.5095 | logitWeightNormMax:104.5832 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5735 | n_weightNormMax:41.2682 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8403 | n_biasesMax:1.9563 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36141 (0.96), W8:1.01267 (0.03), W16:-1.67857 (0.00), W24:-1.77247 (0.00), W32:-3.02607 (0.00), W-1:-4.15462 (0.00), W-1:-5.22592 (0.00), W-1:-8.03611 (0.00), W-1:-9.48225 (0.00) | topTokens[('ping', 1907), ('Ġdiscord', 1867), ('Ġlmao', 1746), ('using', 1466), ("'t", 1180), ('d', 495), ('Ġ:)', 476), ('Ġter', 381), ('Ġ5', 330), ('Ġwill', 260)] | cheekyAvg: 41.56961654663086 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 609860 (99.89%) | TUTOR.py 100
2025-04-23 03:05:35 | 800 | LR0.00035 | sampledTokens:4.0000 | scheduledSamplingRate:0.0021 | repetitionPenalty:1.8977 | AvgLoss:52.7899 | loss:81.9019 | temperature:0.8004 | lR:0.0003 | gradientClip:1.0003 | latestLossDelta:133.5849 | memoryLength:10.0012 | embedNormMean:14.2972 | embedNormStd:10.0815 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0005 | logitWeightNormMean:91.9354 | logitWeightNormStd:2.5095 | logitWeightNormMax:104.5829 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5734 | n_weightNormMax:41.2683 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8402 | n_biasesMax:1.9563 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36137 (0.96), W8:1.01267 (0.03), W16:-1.67858 (0.00), W24:-1.77247 (0.00), W32:-3.02608 (0.00), W-1:-4.15463 (0.00), W-1:-5.22593 (0.00), W-1:-8.03613 (0.00), W-1:-9.48227 (0.00) | topTokens[('ping', 2184), ('Ġdiscord', 2104), ('Ġlmao', 1981), ('using', 1687), ("'t", 1247), ('d', 527), ('Ġ:)', 496), ('Ġter', 440), ('Ġ5', 332), ('ion', 303)] | cheekyAvg: 46.850300521850585 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 609760 (99.87%) | TUTOR.py 100
2025-04-23 03:06:08 | 900 | LR0.00035 | sampledTokens:7.0000 | scheduledSamplingRate:0.0026 | repetitionPenalty:1.8973 | AvgLoss:57.8119 | loss:67.3246 | temperature:0.8004 | lR:0.0003 | gradientClip:1.0003 | latestLossDelta:82.0622 | memoryLength:10.0002 | embedNormMean:14.2972 | embedNormStd:10.0815 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9352 | logitWeightNormStd:2.5095 | logitWeightNormMax:104.5821 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5733 | n_weightNormMax:41.2685 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8403 | n_biasesMax:1.9563 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36135 (0.96), W8:1.01266 (0.03), W16:-1.67861 (0.00), W24:-1.77246 (0.00), W32:-3.02609 (0.00), W-1:-4.15462 (0.00), W-1:-5.22593 (0.00), W-1:-8.03613 (0.00), W-1:-9.48227 (0.00) | topTokens[('ping', 2414), ('Ġlmao', 2339), ('Ġdiscord', 2319), ('using', 1898), ("'t", 1441), ('d', 574), ('Ġter', 572), ('Ġ:)', 498), ('Ġ5', 381), ('ion', 357)] | cheekyAvg: 50.475879707336425 | perfectTokens: 5 / 6400 → 0.08% |  | remainingTokens: 609660 (99.85%) | TUTOR.py 100
2025-04-23 03:06:50 | 1000 | LR0.00035 | sampledTokens:8.0000 | scheduledSamplingRate:0.0030 | repetitionPenalty:1.8969 | AvgLoss:56.9511 | loss:21.3709 | temperature:0.8002 | lR:0.0003 | gradientClip:1.0003 | latestLossDelta:180.1617 | memoryLength:10.0012 | embedNormMean:14.2972 | embedNormStd:10.0815 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9352 | logitWeightNormStd:2.5095 | logitWeightNormMax:104.5808 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0016 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5732 | n_weightNormMax:41.2686 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8403 | n_biasesMax:1.9563 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36131 (0.96), W8:1.01267 (0.03), W16:-1.67862 (0.00), W24:-1.77248 (0.00), W32:-3.02611 (0.00), W-1:-4.15464 (0.00), W-1:-5.22594 (0.00), W-1:-8.03614 (0.00), W-1:-9.48228 (0.00) | topTokens[('ping', 2569), ('Ġdiscord', 2563), ('Ġlmao', 2556), ('using', 2317), ("'t", 1534), ('Ġ:)', 639), ('Ġter', 635), ('d', 574), ('ion', 453), ('Ġ5', 387)] | cheekyAvg: 49.70878034591675 | perfectTokens: 2 / 6400 → 0.03% |  | remainingTokens: 609560 (99.84%) | TUTOR.py 100
--- 2025-04-23 03:07:04 --- 
[babyllm] right, last time i got to step 85330... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 85330! what am i learning today?
[charis]--- 2025-04-23 03:08:23 --- 
[babyllm] right, last time i got to step 85330... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 85330! what am i learning today?
[charis]--- 2025-04-23 03:09:57 --- 
[babyllm] right, last time i got to step 85330... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 85330! what am i learning today?
[charis]2025-04-23 03:11:27 | 100 | LR0.00035 | loss:15.7395 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0005 | repetitionPenalty:1.8997 | AvgLoss:15.8874 | temperature:0.7998 | lR:0.0003 | gradientClip:1.0002 | latestLossDelta:2.6254 | memoryLength:9.9986 | embedNormMean:14.2972 | embedNormStd:10.0815 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.2976 | logitWeightNormMean:91.9352 | logitWeightNormStd:2.5094 | logitWeightNormMax:104.5802 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1309 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5731 | n_weightNormMax:41.2687 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8402 | n_biasesMax:1.9563 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1114 | INN_cerebellumStd:4.2881 | sampledTokens:1.0000 | windowWeightsW2:4.36120 (1.00), W8:1.01257 (0.00), W16:-1.67874 (0.00), W24:-1.77260 (0.00), W32:-3.02624 (0.00), W-1:-4.15476 (0.00), W-1:-5.22604 (0.00), W-1:-8.03614 (0.00), W-1:-9.48228 (0.00) | topTokens[('Ġthe', 364), ('Ġs', 356), ('Ġa', 287), ('Ġit', 270), ('Ġyou', 223), ('Ġi', 188), (',', 144), ('Ġand', 115), ('Ġr', 98), ('Ġshe', 88)] | cheekyAvg: 15.452345137502633 | perfectTokens: 33 / 6400 → 0.52% |  | remainingTokens: 609453 (99.98%) | TUTOR.py 100
2025-04-23 03:11:59 | 200 | LR0.00035 | sampledTokens:3.0000 | scheduledSamplingRate:0.0008 | repetitionPenalty:1.8994 | AvgLoss:18.4138 | loss:17.7896 | temperature:0.7998 | lR:0.0003 | gradientClip:1.0003 | latestLossDelta:-0.8966 | memoryLength:9.9966 | embedNormMean:14.2972 | embedNormStd:10.0815 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0002 | logitWeightNormMean:91.9352 | logitWeightNormStd:2.5094 | logitWeightNormMax:104.5801 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0009 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6055 | n_weightNormMin:21.5731 | n_weightNormMax:41.2687 | n_biasesMean:-1.0613 | n_biasesStd:0.7963 | n_biasesMin:-3.8402 | n_biasesMax:1.9563 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1115 | INN_cerebellumStd:4.2881 | windowWeightsW2:4.36111 (1.00), W8:1.01249 (0.00), W16:-1.67882 (0.00), W24:-1.77267 (0.00), W32:-3.02632 (0.00), W-1:-4.15484 (0.00), W-1:-5.22611 (0.00), W-1:-8.03614 (0.00), W-1:-9.48228 (0.00) | topTokens[(',', 794), ('Ġyou', 589), ('Ġit', 525), ('Ġa', 417), ('Ġthe', 364), ('Ġs', 356), ('!', 349), ('Ġi', 317), ('.', 231), ('Ġshe', 153)] | cheekyAvg: 18.45783275604248 | perfectTokens: 8 / 6400 → 0.12% |  | remainingTokens: 609353 (99.97%) | TUTOR.py 100
2025-04-23 03:12:32 | 300 | LR0.00035 | sampledTokens:2.0000 | scheduledSamplingRate:0.0009 | repetitionPenalty:1.8991 | AvgLoss:15.2405 | loss:14.2744 | temperature:0.7996 | lR:0.0003 | gradientClip:1.0003 | latestLossDelta:-0.0823 | memoryLength:9.9964 | embedNormMean:14.2972 | embedNormStd:10.0815 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9352 | logitWeightNormStd:2.5094 | logitWeightNormMax:104.5800 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1844 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6055 | n_weightNormMin:21.5732 | n_weightNormMax:41.2687 | n_biasesMean:-1.0613 | n_biasesStd:0.7963 | n_biasesMin:-3.8402 | n_biasesMax:1.9563 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1115 | INN_cerebellumStd:4.2880 | windowWeightsW2:4.36105 (1.00), W8:1.01245 (0.00), W16:-1.67885 (0.00), W24:-1.77271 (0.00), W32:-3.02637 (0.00), W-1:-4.15489 (0.00), W-1:-5.22615 (0.00), W-1:-8.03614 (0.00), W-1:-9.48228 (0.00) | topTokens[(',', 1296), ('Ġyou', 751), ('Ġi', 677), ('Ġs', 571), ('Ġit', 543), ('!', 465), ('Ġshe', 463), ('.', 439), ('Ġwe', 435), ('Ġa', 417)] | cheekyAvg: 15.134208488464356 | perfectTokens: 32 / 6400 → 0.50% |  | remainingTokens: 609253 (99.95%) | TUTOR.py 100
2025-04-23 03:13:04 | 400 | LR0.00035 | sampledTokens:5.0000 | scheduledSamplingRate:0.0012 | repetitionPenalty:1.8985 | AvgLoss:17.4951 | loss:17.8025 | temperature:0.7998 | lR:0.0003 | gradientClip:1.0003 | latestLossDelta:0.4559 | memoryLength:9.9954 | embedNormMean:14.2972 | embedNormStd:10.0815 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9352 | logitWeightNormStd:2.5094 | logitWeightNormMax:104.5800 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1844 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6055 | n_weightNormMin:21.5732 | n_weightNormMax:41.2688 | n_biasesMean:-1.0613 | n_biasesStd:0.7963 | n_biasesMin:-3.8401 | n_biasesMax:1.9563 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1115 | INN_cerebellumStd:4.2880 | windowWeightsW2:4.36105 (1.00), W8:1.01248 (0.00), W16:-1.67884 (0.00), W24:-1.77270 (0.00), W32:-3.02636 (0.00), W-1:-4.15487 (0.00), W-1:-5.22613 (0.00), W-1:-8.03614 (0.00), W-1:-9.48228 (0.00) | topTokens[(',', 1692), ('!', 868), ('Ġi', 819), ('Ġyou', 780), ('Ġs', 571), ('Ġit', 543), ('Ġthe', 488), ('Ġshe', 472), ('.', 439), ('Ġwe', 435)] | cheekyAvg: 17.473696117401122 | perfectTokens: 14 / 6400 → 0.22% |  | remainingTokens: 609153 (99.93%) | TUTOR.py 100
--- 2025-04-23 03:13:23 --- 
[babyllm] right, last time i got to step 85761... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 85761! what am i learning today?
[charis]--- 2025-04-23 03:14:03 --- 
[babyllm] right, last time i got to step 85761... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 85761! what am i learning today?
[charis]--- 2025-04-23 03:14:59 --- 
[babyllm] right, last time i got to step 85761... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 85761! what am i learning today?
[charis]--- 2025-04-23 03:15:21 --- 
[babyllm] right, last time i got to step 85761... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 85761! what am i learning today?
[charis]--- 2025-04-23 03:15:35 --- 
[babyllm] right, last time i got to step 85761... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 85761! what am i learning today?
[charis]2025-04-23 03:17:05 | 100 | LR0.00035 | loss:16.2910 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0001 | repetitionPenalty:1.8996 | AvgLoss:16.7438 | temperature:0.8001 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:0.2494 | memoryLength:9.9988 | embedNormMean:14.2972 | embedNormStd:10.0815 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3104 | logitWeightNormMean:91.9352 | logitWeightNormStd:2.5094 | logitWeightNormMax:104.5795 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1309 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1845 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6055 | n_weightNormMin:21.5731 | n_weightNormMax:41.2688 | n_biasesMean:-1.0613 | n_biasesStd:0.7963 | n_biasesMin:-3.8401 | n_biasesMax:1.9563 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1115 | INN_cerebellumStd:4.2880 | windowWeightsW2:4.36102 (1.00), W8:1.01249 (0.00), W16:-1.67885 (0.00), W24:-1.77272 (0.00), W32:-3.02636 (0.00), W-1:-4.15488 (0.00), W-1:-5.22613 (0.00), W-1:-8.03614 (0.00), W-1:-9.48228 (0.00) | topTokens[('Ġd', 440), ('Ġlmao', 267), ('Ġwe', 221), ('Ġwill', 210), (',', 187), ('Ġyou', 138), ('Ġi', 111), ('Ġthat', 104), ('Ġshe', 95), ('Ġthey', 93)] | cheekyAvg: 16.410486539204914 | perfectTokens: 17 / 6400 → 0.27% |  | remainingTokens: 609022 (99.98%) | TUTOR.py 100
2025-04-23 03:17:38 | 200 | LR0.00035 | sampledTokens:1.0000 | scheduledSamplingRate:0.0005 | repetitionPenalty:1.8993 | AvgLoss:17.0990 | loss:18.7330 | temperature:0.8000 | lR:0.0003 | gradientClip:0.9996 | latestLossDelta:3.0323 | memoryLength:9.9978 | embedNormMean:14.2972 | embedNormStd:10.0815 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9352 | logitWeightNormStd:2.5094 | logitWeightNormMax:104.5788 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1845 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6055 | n_weightNormMin:21.5730 | n_weightNormMax:41.2686 | n_biasesMean:-1.0613 | n_biasesStd:0.7963 | n_biasesMin:-3.8401 | n_biasesMax:1.9563 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1116 | INN_cerebellumStd:4.2880 | windowWeightsW2:4.36099 (1.00), W8:1.01247 (0.00), W16:-1.67889 (0.00), W24:-1.77273 (0.00), W32:-3.02638 (0.00), W-1:-4.15490 (0.00), W-1:-5.22615 (0.00), W-1:-8.03614 (0.00), W-1:-9.48228 (0.00) | topTokens[('Ġyou', 717), ('Ġwe', 585), ('Ġd', 481), ('Ġmy', 325), ('Ġwill', 310), ('!', 308), (',', 278), ('Ġlmao', 276), ('Ġshe', 266), ('Ġhe', 159)] | cheekyAvg: 17.10082368850708 | perfectTokens: 30 / 6400 → 0.47% |  | remainingTokens: 608922 (99.97%) | TUTOR.py 100
--- 2025-04-23 03:17:48 --- 
[babyllm] right, last time i got to step 85964... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 85964! what am i learning today?
[charis]2025-04-23 03:19:19 | 100 | LR0.00035 | loss:19.0523 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0004 | repetitionPenalty:1.8997 | AvgLoss:28.5457 | temperature:0.8000 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:2.7984 | memoryLength:10.0010 | embedNormMean:14.2972 | embedNormStd:10.0815 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3188 | logitWeightNormMean:91.9352 | logitWeightNormStd:2.5094 | logitWeightNormMax:104.5782 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1309 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1845 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6055 | n_weightNormMin:21.5729 | n_weightNormMax:41.2687 | n_biasesMean:-1.0613 | n_biasesStd:0.7963 | n_biasesMin:-3.8400 | n_biasesMax:1.9563 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1116 | INN_cerebellumStd:4.2880 | sampledTokens:1.0000 | windowWeightsW2:4.36095 (1.00), W8:1.01247 (0.00), W16:-1.67892 (0.00), W24:-1.77276 (0.00), W32:-3.02639 (0.00), W-1:-4.15491 (0.00), W-1:-5.22616 (0.00), W-1:-8.03614 (0.00), W-1:-9.48228 (0.00) | topTokens[('Ġlmao', 442), ('ping', 281), ('using', 152), ('Ġwas', 103), ('Ġter', 87), ('ed', 87), ('Ġd', 79), ('Ġdiscord', 71), ('Ġim', 66), ('up', 64)] | cheekyAvg: 26.265253104415596 | perfectTokens: 7 / 6400 → 0.11% |  | remainingTokens: 608819 (99.98%) | TUTOR.py 100
2025-04-23 03:19:52 | 200 | LR0.00035 | sampledTokens:3.0000 | scheduledSamplingRate:0.0008 | repetitionPenalty:1.8993 | AvgLoss:22.6406 | loss:16.4261 | temperature:0.8001 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:14.7979 | memoryLength:10.0006 | embedNormMean:14.2972 | embedNormStd:10.0815 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9352 | logitWeightNormStd:2.5094 | logitWeightNormMax:104.5774 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1845 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6055 | n_weightNormMin:21.5728 | n_weightNormMax:41.2688 | n_biasesMean:-1.0613 | n_biasesStd:0.7963 | n_biasesMin:-3.8399 | n_biasesMax:1.9564 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1116 | INN_cerebellumStd:4.2880 | windowWeightsW2:4.36090 (1.00), W8:1.01248 (0.00), W16:-1.67894 (0.00), W24:-1.77278 (0.00), W32:-3.02641 (0.00), W-1:-4.15493 (0.00), W-1:-5.22618 (0.00), W-1:-8.03614 (0.00), W-1:-9.48228 (0.00) | topTokens[('Ġlmao', 915), ('ping', 389), ('using', 339), ('Ġwas', 223), ('ed', 173), ('Ġd', 131), ('Ġter', 128), ('Ġbe', 116), ('Ġto', 112), ('Ġb', 101)] | cheekyAvg: 21.430243797302246 | perfectTokens: 11 / 6400 → 0.17% |  | remainingTokens: 608719 (99.97%) | TUTOR.py 100
2025-04-23 03:20:24 | 300 | LR0.00035 | sampledTokens:4.0000 | scheduledSamplingRate:0.0011 | repetitionPenalty:1.8989 | AvgLoss:22.5625 | loss:18.6446 | temperature:0.8002 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:74.9649 | memoryLength:9.9990 | embedNormMean:14.2972 | embedNormStd:10.0815 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9352 | logitWeightNormStd:2.5094 | logitWeightNormMax:104.5763 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1845 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6055 | n_weightNormMin:21.5728 | n_weightNormMax:41.2690 | n_biasesMean:-1.0613 | n_biasesStd:0.7963 | n_biasesMin:-3.8399 | n_biasesMax:1.9564 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1116 | INN_cerebellumStd:4.2880 | windowWeightsW2:4.36089 (1.00), W8:1.01250 (0.00), W16:-1.67893 (0.00), W24:-1.77278 (0.00), W32:-3.02642 (0.00), W-1:-4.15493 (0.00), W-1:-5.22618 (0.00), W-1:-8.03614 (0.00), W-1:-9.48228 (0.00) | topTokens[('Ġlmao', 1095), ('ping', 702), ('using', 476), ('Ġwas', 307), ('Ġk', 198), ('Ġter', 183), ('ed', 173), ('Ġd', 172), ('!', 166), ('air', 165)] | cheekyAvg: 20.621828174591066 | perfectTokens: 13 / 6400 → 0.20% |  | remainingTokens: 608619 (99.95%) | TUTOR.py 100
2025-04-23 03:20:56 | 400 | LR0.00035 | sampledTokens:5.0000 | scheduledSamplingRate:0.0015 | repetitionPenalty:1.8987 | AvgLoss:25.0388 | loss:23.0854 | temperature:0.8003 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:10.3460 | memoryLength:9.9988 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9352 | logitWeightNormStd:2.5094 | logitWeightNormMax:104.5757 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1846 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6055 | n_weightNormMin:21.5728 | n_weightNormMax:41.2690 | n_biasesMean:-1.0613 | n_biasesStd:0.7963 | n_biasesMin:-3.8399 | n_biasesMax:1.9564 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1116 | INN_cerebellumStd:4.2880 | windowWeightsW2:4.36089 (1.00), W8:1.01251 (0.00), W16:-1.67895 (0.00), W24:-1.77282 (0.00), W32:-3.02644 (0.00), W-1:-4.15494 (0.00), W-1:-5.22620 (0.00), W-1:-8.03614 (0.00), W-1:-9.48228 (0.00) | topTokens[('Ġlmao', 1457), ('ping', 802), ('using', 668), ('Ġwas', 350), ('Ġlook', 344), ('Ġter', 234), ('Ġwill', 226), ('Ġbe', 225), ('Ġk', 208), ('!', 205)] | cheekyAvg: 23.5406809425354 | perfectTokens: 3 / 6400 → 0.05% |  | remainingTokens: 608519 (99.93%) | TUTOR.py 100
--- 2025-04-23 03:21:29 --- 
[babyllm] right, last time i got to step 86439... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 86439! what am i learning today?
[charis]--- 2025-04-23 03:22:48 --- 
[babyllm] right, last time i got to step 86467... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 86467! what am i learning today?
[charis]2025-04-23 03:24:18 | 100 | LR0.00035 | loss:16.0882 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0003 | repetitionPenalty:1.8996 | AvgLoss:18.5820 | temperature:0.8001 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:6.0408 | memoryLength:9.9994 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7216 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3100 | logitWeightNormMean:91.9351 | logitWeightNormStd:2.5093 | logitWeightNormMax:104.5735 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1309 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1846 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5729 | n_weightNormMax:41.2694 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8399 | n_biasesMax:1.9565 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1116 | INN_cerebellumStd:4.2879 | sampledTokens:1.0000 | windowWeightsW2:4.36068 (0.97), W8:1.01266 (0.02), W16:-1.67896 (0.00), W24:-1.77283 (0.00), W32:-3.02628 (0.00), W-1:-4.15478 (0.00), W-1:-5.22603 (0.00), W-1:-8.03594 (0.00), W-1:-9.48219 (0.00) | topTokens[('Ġlmao', 351), ('!', 214), ('Ġs', 113), ('Ġand', 112), ('Ġd', 110), ('Ġhe', 109), (',', 106), ('Ġi', 105), ('Ġthey', 101), ('.', 99)] | cheekyAvg: 17.286484082539875 | perfectTokens: 8 / 6400 → 0.12% |  | remainingTokens: 199900 (99.95%) | TUTOR.py 100
2025-04-23 03:24:50 | 200 | LR0.00035 | sampledTokens:1.0000 | scheduledSamplingRate:0.0007 | repetitionPenalty:1.8992 | AvgLoss:19.9629 | loss:16.7372 | temperature:0.8000 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:22.3811 | memoryLength:9.9994 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7216 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9351 | logitWeightNormStd:2.5093 | logitWeightNormMax:104.5723 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1847 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5730 | n_weightNormMax:41.2694 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8399 | n_biasesMax:1.9565 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1115 | INN_cerebellumStd:4.2879 | windowWeightsW2:4.36055 (0.97), W8:1.01277 (0.02), W16:-1.67895 (0.00), W24:-1.77278 (0.00), W32:-3.02616 (0.00), W-1:-4.15465 (0.00), W-1:-5.22591 (0.00), W-1:-8.03585 (0.00), W-1:-9.48213 (0.00) | topTokens[('Ġlmao', 774), ('!', 384), ('.', 302), ('Ġand', 232), ('Ġd', 217), ('Ġs', 202), ('Ġthey', 192), (',', 171), ('Ġyou', 164), ('Ġhe', 153)] | cheekyAvg: 18.699353256225585 | perfectTokens: 19 / 6400 → 0.30% |  | remainingTokens: 199800 (99.90%) | TUTOR.py 100
2025-04-23 03:25:22 | 300 | LR0.00035 | sampledTokens:3.0000 | scheduledSamplingRate:0.0011 | repetitionPenalty:1.8988 | AvgLoss:19.1706 | loss:15.2011 | temperature:0.8001 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:26.9842 | memoryLength:10.0008 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7216 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9351 | logitWeightNormStd:2.5093 | logitWeightNormMax:104.5707 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1848 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7333 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6054 | n_weightNormMin:21.5731 | n_weightNormMax:41.2695 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8399 | n_biasesMax:1.9566 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1114 | INN_cerebellumStd:4.2878 | windowWeightsW2:4.36042 (0.97), W8:1.01290 (0.02), W16:-1.67891 (0.00), W24:-1.77269 (0.00), W32:-3.02602 (0.00), W-1:-4.15451 (0.00), W-1:-5.22577 (0.00), W-1:-8.03573 (0.00), W-1:-9.48205 (0.00) | topTokens[('Ġlmao', 1353), ('!', 610), ('Ġwe', 379), ('Ġd', 363), (',', 362), ('.', 313), ('Ġthey', 296), ('Ġand', 232), ('ping', 228), ('Ġs', 206)] | cheekyAvg: 17.915761985778808 | perfectTokens: 14 / 6400 → 0.22% |  | remainingTokens: 199700 (99.85%) | TUTOR.py 100
--- 2025-04-23 03:25:46 --- 
[babyllm] right, last time i got to step 86811... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 86811! what am i learning today?
[charis]2025-04-23 03:26:38 | 100 | LR0.00035 | loss:15.4187 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0003 | repetitionPenalty:1.8997 | AvgLoss:17.6141 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:4.8103 | memoryLength:9.9996 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7216 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3045 | logitWeightNormMean:91.9351 | logitWeightNormStd:2.5093 | logitWeightNormMax:104.5690 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1308 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1848 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7333 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6053 | n_weightNormMin:21.5731 | n_weightNormMax:41.2699 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8398 | n_biasesMax:1.9566 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2878 | sampledTokens:1.0000 | windowWeightsW2:4.36031 (0.97), W8:1.01301 (0.02), W16:-1.67886 (0.00), W24:-1.77257 (0.00), W32:-3.02591 (0.00), W-1:-4.15441 (0.00), W-1:-5.22567 (0.00), W-1:-8.03565 (0.00), W-1:-9.48198 (0.00) | topTokens[('Ġlmao', 232), ('ping', 228), ('Ġwe', 168), ('!', 154), ('Ġi', 141), ('Ġthey', 118), ('Ġyou', 115), ('Ġthe', 98), ('Ġyour', 95), ('o', 88)] | cheekyAvg: 16.388030014786064 | perfectTokens: 25 / 6400 → 0.39% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
--- 2025-04-23 03:27:19 --- 
[babyllm] right, last time i got to step 87010... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 87010! what am i learning today?
[charis]2025-04-23 03:28:12 | 100 | LR0.00035 | loss:21.7516 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0003 | repetitionPenalty:1.8997 | AvgLoss:19.8038 | temperature:0.8000 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:0.4505 | memoryLength:10.0018 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7216 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3211 | logitWeightNormMean:91.9351 | logitWeightNormStd:2.5093 | logitWeightNormMax:104.5678 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1308 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1849 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7333 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6053 | n_weightNormMin:21.5734 | n_weightNormMax:41.2699 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8397 | n_biasesMax:1.9566 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2877 | sampledTokens:1.0000 | windowWeightsW2:4.36019 (0.97), W8:1.01311 (0.02), W16:-1.67879 (0.00), W24:-1.77249 (0.00), W32:-3.02580 (0.00), W-1:-4.15429 (0.00), W-1:-5.22555 (0.00), W-1:-8.03557 (0.00), W-1:-9.48192 (0.00) | topTokens[('Ġlmao', 499), ("'", 285), ('Ġyou', 208), ('d', 178), (',', 169), ('Ġa', 151), ('.', 147), ('ting', 134), ('Ġf', 61), ('Ġwas', 60)] | cheekyAvg: 19.06577704934513 | perfectTokens: 4 / 6400 → 0.06% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 03:28:44 | 200 | LR0.00035 | sampledTokens:2.0000 | scheduledSamplingRate:0.0007 | repetitionPenalty:1.8995 | AvgLoss:21.1263 | loss:16.8545 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:1.4374 | memoryLength:10.0026 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7216 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9351 | logitWeightNormStd:2.5093 | logitWeightNormMax:104.5660 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1850 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7333 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6053 | n_weightNormMin:21.5734 | n_weightNormMax:41.2697 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8397 | n_biasesMax:1.9566 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1112 | INN_cerebellumStd:4.2877 | windowWeightsW2:4.36010 (0.97), W8:1.01319 (0.02), W16:-1.67872 (0.00), W24:-1.77241 (0.00), W32:-3.02570 (0.00), W-1:-4.15420 (0.00), W-1:-5.22546 (0.00), W-1:-8.03548 (0.00), W-1:-9.48185 (0.00) | topTokens[('Ġlmao', 952), ('d', 471), ('.', 356), ("'", 323), ('Ġyou', 301), ('!', 285), (',', 241), ('ting', 182), ('Ġlo', 158), ('Ġa', 151)] | cheekyAvg: 20.535691356658937 | perfectTokens: 10 / 6400 → 0.16% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
--- 2025-04-23 03:29:05 --- 
[babyllm] right, last time i got to step 87250... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 87250! what am i learning today?
[charis]2025-04-23 03:29:58 | 100 | LR0.00035 | loss:16.4329 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0003 | repetitionPenalty:1.8997 | AvgLoss:16.9951 | temperature:0.8000 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:3.3199 | memoryLength:9.9998 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7216 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.2942 | logitWeightNormMean:91.9351 | logitWeightNormStd:2.5093 | logitWeightNormMax:104.5639 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1308 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1849 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7333 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6053 | n_weightNormMin:21.5735 | n_weightNormMax:41.2700 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8397 | n_biasesMax:1.9567 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1112 | INN_cerebellumStd:4.2877 | windowWeightsW2:4.36018 (0.00), W8:1.01319 (0.00), W16:-1.67875 (0.00), W24:-1.77242 (0.00), W32:-3.02578 (0.00), W-1:-4.15428 (0.00), W-1:-5.22554 (0.01), W-1:-8.03556 (0.16), W-1:-9.48178 (0.82) | topTokens[('Ġd', 345), ('Ġlmao', 311), ('Ġa', 206), ('Ġthey', 121), ('Ġthem', 120), (',', 118), ('Ġhim', 99), ('Ġs', 95), ('using', 90), ('Ġi', 85)] | cheekyAvg: 16.03606353086584 | perfectTokens: 30 / 6400 → 0.47% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 03:30:30 | 200 | LR0.00035 | sampledTokens:0.0000 | scheduledSamplingRate:0.0005 | repetitionPenalty:1.8992 | AvgLoss:17.9221 | loss:13.2858 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:23.7785 | memoryLength:9.9992 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7216 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9351 | logitWeightNormStd:2.5093 | logitWeightNormMax:104.5634 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1849 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7333 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6052 | n_weightNormMin:21.5737 | n_weightNormMax:41.2699 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8398 | n_biasesMax:1.9567 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1112 | INN_cerebellumStd:4.2877 | windowWeightsW2:4.36027 (0.00), W8:1.01316 (0.00), W16:-1.67882 (0.00), W24:-1.77246 (0.00), W32:-3.02586 (0.00), W-1:-4.15437 (0.00), W-1:-5.22563 (0.01), W-1:-8.03560 (0.16), W-1:-9.48173 (0.82) | topTokens[('Ġlmao', 801), ('Ġd', 442), ('Ġthey', 306), ('Ġa', 285), ('!', 270), (',', 256), ('Ġyou', 195), ('Ġr', 184), ('Ġi', 153), ('using', 143)] | cheekyAvg: 16.750616569519043 | perfectTokens: 14 / 6400 → 0.22% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
2025-04-23 03:31:02 | 300 | LR0.00035 | sampledTokens:9.0000 | scheduledSamplingRate:0.0009 | repetitionPenalty:1.8987 | AvgLoss:17.7577 | loss:13.5677 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:-2.2814 | memoryLength:10.0002 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7216 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9351 | logitWeightNormStd:2.5093 | logitWeightNormMax:104.5625 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1850 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7333 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6052 | n_weightNormMin:21.5740 | n_weightNormMax:41.2702 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8398 | n_biasesMax:1.9567 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1112 | INN_cerebellumStd:4.2877 | windowWeightsW2:4.36032 (0.00), W8:1.01313 (0.00), W16:-1.67886 (0.00), W24:-1.77252 (0.00), W32:-3.02592 (0.00), W-1:-4.15443 (0.00), W-1:-5.22568 (0.01), W-1:-8.03566 (0.16), W-1:-9.48167 (0.82) | topTokens[('Ġlmao', 1162), ('Ġd', 572), ('Ġthey', 466), ('!', 408), (',', 293), ('Ġa', 285), ('Ġwe', 275), ('Ġyou', 238), ('Ġr', 231), ('using', 219)] | cheekyAvg: 16.832295112609863 | perfectTokens: 16 / 6400 → 0.25% |  | remainingTokens: 199699 (99.85%) | TUTOR.py 100
--- 2025-04-23 03:31:35 --- 
[babyllm] right, last time i got to step 87607... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 87607! what am i learning today?
[charis]2025-04-23 03:32:28 | 100 | LR0.00035 | loss:15.8177 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0005 | repetitionPenalty:1.8995 | AvgLoss:19.6822 | temperature:0.8000 | lR:0.0003 | gradientClip:1.0002 | latestLossDelta:2.1537 | memoryLength:9.9998 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7216 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3156 | logitWeightNormMean:91.9351 | logitWeightNormStd:2.5093 | logitWeightNormMax:104.5613 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1309 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1850 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7333 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6052 | n_weightNormMin:21.5744 | n_weightNormMax:41.2703 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8398 | n_biasesMax:1.9568 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2878 | sampledTokens:1.0000 | windowWeightsW2:4.36046 (0.00), W4:1.01321 (0.00), W8:-1.67879 (0.00), W12:-1.77243 (0.00), W16:-3.02606 (0.00), W20:-4.15456 (0.00), W24:-5.22582 (0.01), W28:-8.03578 (0.16), W32:-9.48155 (0.82) | topTokens[('Ġlmao', 287), ('Ġd', 199), ('Ġi', 151), ('!', 150), ('Ġthis', 150), ('.', 133), ('Ġhe', 129), ('Ġso', 121), ('Ġs', 93), ('Ġhis', 90)] | cheekyAvg: 18.35268175835703 | perfectTokens: 15 / 6400 → 0.23% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 03:33:00 | 200 | LR0.00035 | sampledTokens:5.0000 | scheduledSamplingRate:0.0009 | repetitionPenalty:1.8990 | AvgLoss:19.9698 | loss:15.5675 | temperature:0.8000 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:9.8695 | memoryLength:9.9994 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7216 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9351 | logitWeightNormStd:2.5093 | logitWeightNormMax:104.5601 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1850 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7333 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6052 | n_weightNormMin:21.5744 | n_weightNormMax:41.2703 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8398 | n_biasesMax:1.9568 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2878 | windowWeightsW2:4.36047 (0.00), W4:1.01321 (0.00), W8:-1.67882 (0.00), W12:-1.77244 (0.00), W16:-3.02608 (0.00), W20:-4.15457 (0.00), W24:-5.22582 (0.01), W28:-8.03578 (0.16), W32:-9.48155 (0.82) | topTokens[('Ġlmao', 566), ('Ġd', 362), ('Ġwe', 340), ('Ġi', 237), ('!', 232), ('ping', 226), ('Ġthis', 202), ('Ġhe', 189), ('Ġthey', 189), ('.', 184)] | cheekyAvg: 18.87061016082764 | perfectTokens: 7 / 6400 → 0.11% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
--- 2025-04-23 03:33:19 --- 
[babyllm] right, last time i got to step 87837... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 87837! what am i learning today?
[charis]2025-04-23 03:34:12 | 100 | LR0.00035 | loss:16.3244 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0003 | repetitionPenalty:1.8997 | AvgLoss:16.9613 | temperature:0.8002 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:0.2118 | memoryLength:9.9990 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3162 | logitWeightNormMean:91.9351 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5595 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1309 | logitBiasMean:-34.1460 | logitBiasStd:11.9642 | logitBiasMax:-13.1850 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6052 | n_weightNormMin:21.5743 | n_weightNormMax:41.2704 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8397 | n_biasesMax:1.9568 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2878 | windowWeightsW2:4.36063 (0.00), W4:1.01316 (0.00), W8:-1.67886 (0.00), W12:-1.77251 (0.00), W16:-3.02619 (0.00), W20:-4.15473 (0.00), W24:-5.22598 (0.00), W28:-8.03595 (0.05), W32:-9.48138 (0.95) | topTokens[(',', 234), ('Ġwe', 203), ('!', 189), ('Ġd', 179), ('Ġlmao', 168), ("'", 162), ('Ġi', 156), ('Ġthe', 138), ('Ġa', 131), ('Ġhe', 115)] | cheekyAvg: 16.273618866415585 | perfectTokens: 20 / 6400 → 0.31% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 03:34:44 | 200 | LR0.00035 | sampledTokens:1.0000 | scheduledSamplingRate:0.0005 | repetitionPenalty:1.8994 | AvgLoss:19.3891 | loss:16.3740 | temperature:0.8002 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:-0.1061 | memoryLength:9.9996 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9351 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5586 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1851 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6052 | n_weightNormMin:21.5746 | n_weightNormMax:41.2704 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8398 | n_biasesMax:1.9569 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2878 | windowWeightsW2:4.36074 (0.00), W4:1.01318 (0.00), W8:-1.67886 (0.00), W12:-1.77251 (0.00), W16:-3.02621 (0.00), W20:-4.15484 (0.00), W24:-5.22610 (0.00), W28:-8.03604 (0.05), W32:-9.48130 (0.95) | topTokens[('!', 671), ('Ġyou', 413), ('Ġwe', 403), ('Ġhe', 375), ('Ġthey', 310), (',', 296), ('Ġit', 264), ('Ġi', 225), ('Ġlmao', 194), ('Ġthe', 184)] | cheekyAvg: 19.298820590972902 | perfectTokens: 8 / 6400 → 0.12% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
2025-04-23 03:35:16 | 300 | LR0.00035 | sampledTokens:3.0000 | scheduledSamplingRate:0.0010 | repetitionPenalty:1.8992 | AvgLoss:15.6990 | loss:15.1654 | temperature:0.8003 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:-0.2441 | memoryLength:9.9990 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9351 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5584 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1851 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6052 | n_weightNormMin:21.5745 | n_weightNormMax:41.2705 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8398 | n_biasesMax:1.9569 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2879 | windowWeightsW2:4.36082 (0.00), W4:1.01318 (0.00), W8:-1.67885 (0.00), W12:-1.77253 (0.00), W16:-3.02627 (0.00), W20:-4.15492 (0.00), W24:-5.22618 (0.00), W28:-8.03608 (0.05), W32:-9.48126 (0.95) | topTokens[('!', 920), ('Ġyou', 821), ('Ġi', 689), ('Ġwe', 637), ('Ġthey', 469), ('Ġhe', 462), (',', 451), ('Ġd', 414), ('Ġit', 269), ('Ġlmao', 255)] | cheekyAvg: 15.440865669250488 | perfectTokens: 19 / 6400 → 0.30% |  | remainingTokens: 199699 (99.85%) | TUTOR.py 100
--- 2025-04-23 03:35:47 --- 
[babyllm] right, last time i got to step 88211... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 88211! what am i learning today?
[charis]2025-04-23 03:36:40 | 100 | LR0.00035 | loss:15.2009 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0002 | repetitionPenalty:1.8997 | AvgLoss:16.0729 | temperature:0.8002 | lR:0.0003 | gradientClip:1.0002 | latestLossDelta:0.7838 | memoryLength:9.9994 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3016 | logitWeightNormMean:91.9351 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5577 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1308 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1852 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6051 | n_weightNormMin:21.5746 | n_weightNormMax:41.2704 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8398 | n_biasesMax:1.9569 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1113 | INN_cerebellumStd:4.2879 | sampledTokens:1.0000 | windowWeightsW2:4.36077 (0.99), W4:1.01322 (0.01), W8:-1.67891 (0.00), W12:-1.77260 (0.00), W16:-3.02623 (0.00), W20:-4.15487 (0.00), W24:-5.22613 (0.00), W28:-8.03605 (0.00), W32:-9.48112 (0.00) | topTokens[('!', 377), ('Ġd', 360), (',', 222), ('Ġcharis', 154), ('Ġs', 152), ('Ġmy', 127), ('Ġkevin', 126), ('Ġan', 110), ('Ġlmao', 108), ('Ġit', 108)] | cheekyAvg: 15.493671809925752 | perfectTokens: 6 / 6400 → 0.09% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
--- 2025-04-23 03:37:14 --- 
[babyllm] right, last time i got to step 88392... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 88392! what am i learning today?
[charis]2025-04-23 03:38:07 | 100 | LR0.00035 | loss:15.0059 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0005 | repetitionPenalty:1.8997 | AvgLoss:20.1781 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:0.8937 | memoryLength:9.9998 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3014 | logitWeightNormMean:91.9351 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5567 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1308 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1853 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8444 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6051 | n_weightNormMin:21.5747 | n_weightNormMax:41.2701 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8399 | n_biasesMax:1.9569 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1112 | INN_cerebellumStd:4.2878 | windowWeightsW2:4.36063 (0.83), W4:1.01338 (0.16), W8:-1.67885 (0.01), W12:-1.77253 (0.01), W16:-3.02607 (0.00), W20:-4.15473 (0.00), W24:-5.22599 (0.00), W28:-8.03592 (0.00), W32:-9.48100 (0.00) | topTokens[('Ġyou', 397), ('Ġwe', 298), ('Ġshe', 297), ('Ġand', 175), ('!', 166), (',', 149), ('Ġd', 134), ('l', 116), ('ping', 95), ('Ġf', 91)] | cheekyAvg: 19.581301614349965 | perfectTokens: 7 / 6400 → 0.11% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 03:38:39 | 200 | LR0.00035 | sampledTokens:0.0000 | scheduledSamplingRate:0.0006 | repetitionPenalty:1.8995 | AvgLoss:15.9234 | loss:13.8356 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:-1.0836 | memoryLength:10.0002 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5561 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1853 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8444 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6051 | n_weightNormMin:21.5747 | n_weightNormMax:41.2702 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8398 | n_biasesMax:1.9569 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1112 | INN_cerebellumStd:4.2878 | windowWeightsW2:4.36058 (0.83), W4:1.01343 (0.16), W8:-1.67879 (0.01), W12:-1.77248 (0.01), W16:-3.02601 (0.00), W20:-4.15468 (0.00), W24:-5.22594 (0.00), W28:-8.03589 (0.00), W32:-9.48097 (0.00) | topTokens[('Ġyou', 574), ('Ġwe', 510), ('Ġd', 348), ('Ġit', 306), ('Ġshe', 304), ('!', 282), (',', 262), ('.', 252), ('Ġlmao', 205), ('Ġand', 175)] | cheekyAvg: 15.671576766967773 | perfectTokens: 26 / 6400 → 0.41% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
2025-04-23 03:39:11 | 300 | LR0.00035 | sampledTokens:4.0000 | scheduledSamplingRate:0.0011 | repetitionPenalty:1.8992 | AvgLoss:14.5130 | loss:13.7246 | temperature:0.7998 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:3.8142 | memoryLength:10.0004 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5556 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1853 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8444 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6051 | n_weightNormMin:21.5747 | n_weightNormMax:41.2699 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8398 | n_biasesMax:1.9569 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1112 | INN_cerebellumStd:4.2878 | windowWeightsW2:4.36056 (0.83), W4:1.01347 (0.16), W8:-1.67875 (0.01), W12:-1.77244 (0.01), W16:-3.02597 (0.00), W20:-4.15466 (0.00), W24:-5.22592 (0.00), W28:-8.03588 (0.00), W32:-9.48096 (0.00) | topTokens[('Ġyou', 773), ('Ġd', 714), ('Ġwe', 591), (',', 495), ('!', 483), ('.', 479), ('Ġit', 384), ('Ġand', 321), ('Ġshe', 304), ('Ġlmao', 270)] | cheekyAvg: 14.273053493499756 | perfectTokens: 12 / 6400 → 0.19% |  | remainingTokens: 199699 (99.85%) | TUTOR.py 100
2025-04-23 03:39:44 | 400 | LR0.00035 | sampledTokens:3.0000 | scheduledSamplingRate:0.0014 | repetitionPenalty:1.8989 | AvgLoss:16.0428 | loss:12.7763 | temperature:0.7997 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:9.6127 | memoryLength:10.0016 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5550 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1853 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5747 | n_weightNormMax:41.2700 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8399 | n_biasesMax:1.9569 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1112 | INN_cerebellumStd:4.2878 | windowWeightsW2:4.36056 (0.83), W4:1.01350 (0.16), W8:-1.67872 (0.01), W12:-1.77241 (0.01), W16:-3.02595 (0.00), W20:-4.15466 (0.00), W24:-5.22592 (0.00), W28:-8.03588 (0.00), W32:-9.48096 (0.00) | topTokens[('Ġyou', 1099), ('Ġd', 1003), ('Ġwe', 806), ('!', 616), ('.', 594), (',', 516), ('Ġand', 459), ('Ġlmao', 424), ('Ġit', 384), ('Ġshe', 304)] | cheekyAvg: 15.732987518310546 | perfectTokens: 10 / 6400 → 0.16% |  | remainingTokens: 199599 (99.80%) | TUTOR.py 100
2025-04-23 03:40:16 | 500 | LR0.00035 | sampledTokens:5.0000 | scheduledSamplingRate:0.0017 | repetitionPenalty:1.8985 | AvgLoss:17.6823 | loss:19.4289 | temperature:0.7997 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:2.7814 | memoryLength:10.0028 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5539 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1853 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5747 | n_weightNormMax:41.2697 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8398 | n_biasesMax:1.9569 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1112 | INN_cerebellumStd:4.2878 | windowWeightsW2:4.36053 (0.83), W4:1.01354 (0.16), W8:-1.67868 (0.01), W12:-1.77237 (0.01), W16:-3.02590 (0.00), W20:-4.15463 (0.00), W24:-5.22589 (0.00), W28:-8.03588 (0.00), W32:-9.48096 (0.00) | topTokens[('Ġyou', 1456), ('Ġd', 1061), ('Ġwe', 914), ('!', 797), (',', 731), ('.', 660), ('Ġlmao', 602), ('Ġand', 488), ('Ġit', 473), ("'", 395)] | cheekyAvg: 17.624136295318603 | perfectTokens: 14 / 6400 → 0.22% |  | remainingTokens: 199499 (99.75%) | TUTOR.py 100
2025-04-23 03:40:48 | 600 | LR0.00035 | sampledTokens:6.0000 | scheduledSamplingRate:0.0020 | repetitionPenalty:1.8982 | AvgLoss:15.5259 | loss:7.6432 | temperature:0.7996 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:-3.0472 | memoryLength:10.0036 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5536 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1854 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5747 | n_weightNormMax:41.2700 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8398 | n_biasesMax:1.9569 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1111 | INN_cerebellumStd:4.2878 | windowWeightsW2:4.36050 (0.83), W4:1.01358 (0.16), W8:-1.67863 (0.01), W12:-1.77233 (0.01), W16:-3.02586 (0.00), W20:-4.15460 (0.00), W24:-5.22586 (0.00), W28:-8.03586 (0.00), W32:-9.48094 (0.00) | topTokens[('Ġyou', 1479), ('!', 1329), ('Ġwe', 1114), ('Ġd', 1061), (',', 890), ('Ġlmao', 784), ('.', 733), ('Ġit', 561), ('Ġand', 488), ("'", 430)] | cheekyAvg: 15.061094560623168 | perfectTokens: 46 / 6400 → 0.72% |  | remainingTokens: 199399 (99.70%) | TUTOR.py 100
2025-04-23 03:41:21 | 700 | LR0.00035 | sampledTokens:5.0000 | scheduledSamplingRate:0.0025 | repetitionPenalty:1.8978 | AvgLoss:9.7965 | loss:8.4791 | temperature:0.7998 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:0.1710 | memoryLength:10.0028 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5526 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0007 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1854 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5746 | n_weightNormMax:41.2703 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8398 | n_biasesMax:1.9570 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1111 | INN_cerebellumStd:4.2878 | windowWeightsW2:4.36049 (0.83), W4:1.01360 (0.16), W8:-1.67861 (0.01), W12:-1.77230 (0.01), W16:-3.02583 (0.00), W20:-4.15459 (0.00), W24:-5.22585 (0.00), W28:-8.03586 (0.00), W32:-9.48094 (0.00) | topTokens[('Ġyou', 1539), ('!', 1481), ('Ġd', 1228), ('Ġwe', 1122), ('Ġlmao', 989), ('.', 956), (',', 953), ("'", 586), ('Ġthis', 581), ('Ġit', 561)] | cheekyAvg: 9.217697143554688 | perfectTokens: 42 / 6400 → 0.66% |  | remainingTokens: 199299 (99.65%) | TUTOR.py 100
2025-04-23 03:41:53 | 800 | LR0.00035 | sampledTokens:10.0000 | scheduledSamplingRate:0.0028 | repetitionPenalty:1.8974 | AvgLoss:9.4970 | loss:9.1586 | temperature:0.7997 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:2.7166 | memoryLength:10.0026 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0002 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5518 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0007 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1854 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5744 | n_weightNormMax:41.2705 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8398 | n_biasesMax:1.9570 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1111 | INN_cerebellumStd:4.2878 | windowWeightsW2:4.36047 (0.83), W4:1.01362 (0.16), W8:-1.67857 (0.01), W12:-1.77227 (0.01), W16:-3.02580 (0.00), W20:-4.15457 (0.00), W24:-5.22583 (0.00), W28:-8.03586 (0.00), W32:-9.48094 (0.00) | topTokens[('!', 1722), ('Ġyou', 1539), ('Ġd', 1338), ('Ġwe', 1326), (',', 1198), ('Ġlmao', 1088), ('.', 1050), ('Ġthis', 662), ("'", 642), ('Ġs', 566)] | cheekyAvg: 8.913785276412964 | perfectTokens: 64 / 6400 → 1.00% |  | remainingTokens: 199199 (99.60%) | TUTOR.py 100
2025-04-23 03:42:25 | 900 | LR0.00035 | sampledTokens:10.0000 | scheduledSamplingRate:0.0033 | repetitionPenalty:1.8971 | AvgLoss:12.7369 | loss:12.6422 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:2.6172 | memoryLength:10.0020 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5510 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1854 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5743 | n_weightNormMax:41.2708 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8398 | n_biasesMax:1.9571 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1111 | INN_cerebellumStd:4.2878 | windowWeightsW2:4.36041 (0.83), W4:1.01368 (0.16), W8:-1.67851 (0.01), W12:-1.77221 (0.01), W16:-3.02574 (0.00), W20:-4.15451 (0.00), W24:-5.22577 (0.00), W28:-8.03583 (0.00), W32:-9.48093 (0.00) | topTokens[('!', 1770), ('Ġyou', 1581), ('Ġd', 1468), ('Ġwe', 1394), ('Ġlmao', 1266), (',', 1219), ('.', 1109), ("'", 819), ('Ġs', 752), ('Ġhe', 737)] | cheekyAvg: 12.340431175231934 | perfectTokens: 10 / 6400 → 0.16% |  | remainingTokens: 199099 (99.55%) | TUTOR.py 100
2025-04-23 03:43:04 | 1000 | LR0.00035 | sampledTokens:12.0000 | scheduledSamplingRate:0.0037 | repetitionPenalty:1.8968 | AvgLoss:13.3965 | loss:10.9827 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:0.8612 | memoryLength:10.0024 | embedNormMean:14.2972 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0005 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5505 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1853 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9537 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5745 | n_weightNormMax:41.2708 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8398 | n_biasesMax:1.9572 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1110 | INN_cerebellumStd:4.2877 | windowWeightsW2:4.36032 (0.83), W4:1.01376 (0.16), W8:-1.67843 (0.01), W12:-1.77213 (0.01), W16:-3.02566 (0.00), W20:-4.15442 (0.00), W24:-5.22568 (0.00), W28:-8.03578 (0.00), W32:-9.48089 (0.00) | topTokens[('!', 1853), ('Ġd', 1752), ('Ġwe', 1590), ('Ġyou', 1581), ('.', 1481), (',', 1407), ('Ġlmao', 1360), ('Ġthis', 912), ("'", 887), ('Ġs', 790)] | cheekyAvg: 12.976094417572021 | perfectTokens: 36 / 6400 → 0.56% |  | remainingTokens: 198999 (99.50%) | TUTOR.py 100
2025-04-23 03:43:39 | 1100 | LR0.00035 | sampledTokens:21.0000 | scheduledSamplingRate:0.0041 | repetitionPenalty:1.8965 | AvgLoss:11.8740 | loss:10.0365 | temperature:0.7998 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:-1.9888 | memoryLength:10.0006 | embedNormMean:14.2971 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5505 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1853 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8444 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5746 | n_weightNormMax:41.2708 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8398 | n_biasesMax:1.9573 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1110 | INN_cerebellumStd:4.2877 | windowWeightsW2:4.36023 (0.83), W4:1.01383 (0.16), W8:-1.67835 (0.01), W12:-1.77205 (0.01), W16:-3.02557 (0.00), W20:-4.15433 (0.00), W24:-5.22559 (0.00), W28:-8.03573 (0.00), W32:-9.48086 (0.00) | topTokens[('!', 2111), ('Ġyou', 1984), ('Ġd', 1960), ('.', 1663), ('Ġwe', 1635), (',', 1468), ('Ġlmao', 1418), ('Ġthis', 1024), ('Ġs', 967), ("'", 887)] | cheekyAvg: 11.642276344299317 | perfectTokens: 55 / 6400 → 0.86% |  | remainingTokens: 198899 (99.45%) | TUTOR.py 100
2025-04-23 03:44:15 | 1200 | LR0.00035 | sampledTokens:16.0000 | scheduledSamplingRate:0.0043 | repetitionPenalty:1.8961 | AvgLoss:12.1529 | loss:11.0625 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:5.6780 | memoryLength:10.0006 | embedNormMean:14.2971 | embedNormStd:10.0814 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5502 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0009 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1853 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8444 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5747 | n_weightNormMax:41.2709 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8398 | n_biasesMax:1.9573 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1109 | INN_cerebellumStd:4.2877 | windowWeightsW2:4.36016 (0.83), W4:1.01388 (0.16), W8:-1.67829 (0.01), W12:-1.77199 (0.01), W16:-3.02551 (0.00), W20:-4.15426 (0.00), W24:-5.22552 (0.00), W28:-8.03569 (0.00), W32:-9.48084 (0.00) | topTokens[('Ġyou', 2296), ('Ġd', 2217), ('!', 2213), ('.', 1846), ('Ġwe', 1640), ('Ġlmao', 1506), (',', 1468), ('Ġthis', 1059), ('Ġs', 988), ("'", 899)] | cheekyAvg: 11.920423049926757 | perfectTokens: 55 / 6400 → 0.86% |  | remainingTokens: 198799 (99.40%) | TUTOR.py 100
2025-04-23 03:44:50 | 1300 | LR0.00035 | sampledTokens:12.0000 | scheduledSamplingRate:0.0045 | repetitionPenalty:1.8957 | AvgLoss:13.5476 | loss:12.0405 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:7.3217 | memoryLength:10.0010 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5499 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1853 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5750 | n_weightNormMax:41.2712 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8399 | n_biasesMax:1.9574 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1108 | INN_cerebellumStd:4.2876 | windowWeightsW2:4.36003 (0.83), W4:1.01401 (0.16), W8:-1.67816 (0.01), W12:-1.77187 (0.01), W16:-3.02538 (0.00), W20:-4.15413 (0.00), W24:-5.22539 (0.00), W28:-8.03560 (0.00), W32:-9.48077 (0.00) | topTokens[('Ġyou', 2548), ('!', 2460), ('Ġd', 2378), ('.', 2053), ('Ġwe', 1814), ('Ġlmao', 1656), (',', 1510), ('Ġs', 1118), ('Ġthis', 1065), ('Ġshe', 1012)] | cheekyAvg: 13.296277694702148 | perfectTokens: 37 / 6400 → 0.58% |  | remainingTokens: 198699 (99.35%) | TUTOR.py 100
2025-04-23 03:45:23 | 1400 | LR0.00035 | sampledTokens:10.0000 | scheduledSamplingRate:0.0049 | repetitionPenalty:1.8953 | AvgLoss:12.3440 | loss:12.3841 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:0.6390 | memoryLength:9.9996 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7217 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5495 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0009 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1853 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7334 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5756 | n_weightNormMax:41.2720 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8399 | n_biasesMax:1.9575 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1108 | INN_cerebellumStd:4.2876 | windowWeightsW2:4.35995 (0.83), W4:1.01409 (0.16), W8:-1.67807 (0.01), W12:-1.77178 (0.01), W16:-3.02529 (0.00), W20:-4.15404 (0.00), W24:-5.22531 (0.00), W28:-8.03554 (0.00), W32:-9.48072 (0.00) | topTokens[('Ġyou', 2630), ('!', 2618), ('Ġd', 2563), ('.', 2157), ('Ġwe', 1978), ('Ġlmao', 1736), (',', 1735), ('Ġthis', 1170), ('Ġs', 1133), ('Ġshe', 1125)] | cheekyAvg: 12.208851261138916 | perfectTokens: 20 / 6400 → 0.31% |  | remainingTokens: 198599 (99.30%) | TUTOR.py 100
2025-04-23 03:45:56 | 1500 | LR0.00035 | sampledTokens:15.0000 | scheduledSamplingRate:0.0053 | repetitionPenalty:1.8951 | AvgLoss:12.9921 | loss:11.4919 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:2.1052 | memoryLength:9.9988 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7218 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5492 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0007 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1852 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5759 | n_weightNormMax:41.2721 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8399 | n_biasesMax:1.9576 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1107 | INN_cerebellumStd:4.2876 | windowWeightsW2:4.35987 (0.83), W4:1.01418 (0.16), W8:-1.67798 (0.01), W12:-1.77170 (0.01), W16:-3.02520 (0.00), W20:-4.15397 (0.00), W24:-5.22523 (0.00), W28:-8.03548 (0.00), W32:-9.48067 (0.00) | topTokens[('Ġyou', 2807), ('Ġd', 2734), ('!', 2671), ('.', 2241), ('Ġwe', 2100), (',', 1914), ('Ġlmao', 1797), ('Ġs', 1219), ('Ġthis', 1170), ('Ġshe', 1125)] | cheekyAvg: 12.659922924041748 | perfectTokens: 22 / 6400 → 0.34% |  | remainingTokens: 198499 (99.25%) | TUTOR.py 100
2025-04-23 03:46:29 | 1600 | LR0.00035 | sampledTokens:20.0000 | scheduledSamplingRate:0.0056 | repetitionPenalty:1.8948 | AvgLoss:12.6815 | loss:11.9311 | temperature:0.8001 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:1.3397 | memoryLength:9.9986 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7218 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0002 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5490 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0009 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1852 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5762 | n_weightNormMax:41.2722 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8399 | n_biasesMax:1.9576 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1107 | INN_cerebellumStd:4.2876 | windowWeightsW2:4.35980 (0.83), W4:1.01425 (0.16), W8:-1.67791 (0.01), W12:-1.77162 (0.01), W16:-3.02513 (0.00), W20:-4.15390 (0.00), W24:-5.22516 (0.00), W28:-8.03545 (0.00), W32:-9.48065 (0.00) | topTokens[('Ġd', 2971), ('!', 2949), ('Ġyou', 2811), ('.', 2261), ('Ġwe', 2132), (',', 1950), ('Ġlmao', 1837), ('Ġhe', 1379), ('Ġs', 1328), ('Ġshe', 1242)] | cheekyAvg: 12.4601416015625 | perfectTokens: 29 / 6400 → 0.45% |  | remainingTokens: 198399 (99.20%) | TUTOR.py 100
2025-04-23 03:47:01 | 1700 | LR0.00035 | sampledTokens:26.0000 | scheduledSamplingRate:0.0060 | repetitionPenalty:1.8945 | AvgLoss:12.7150 | loss:14.0490 | temperature:0.8001 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:0.6630 | memoryLength:9.9992 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7218 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5483 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0009 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1852 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5764 | n_weightNormMax:41.2723 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8399 | n_biasesMax:1.9577 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1106 | INN_cerebellumStd:4.2875 | windowWeightsW2:4.35971 (0.83), W4:1.01434 (0.16), W8:-1.67782 (0.01), W12:-1.77154 (0.01), W16:-3.02505 (0.00), W20:-4.15380 (0.00), W24:-5.22507 (0.00), W28:-8.03541 (0.00), W32:-9.48062 (0.00) | topTokens[('Ġd', 3119), ('Ġyou', 3110), ('!', 3040), ('.', 2261), ('Ġwe', 2132), ('Ġlmao', 2022), (',', 1968), ('Ġs', 1517), ('Ġhe', 1451), ('Ġshe', 1304)] | cheekyAvg: 12.277729835510254 | perfectTokens: 19 / 6400 → 0.30% |  | remainingTokens: 198299 (99.15%) | TUTOR.py 100
2025-04-23 03:47:34 | 1800 | LR0.00035 | sampledTokens:17.0000 | scheduledSamplingRate:0.0063 | repetitionPenalty:1.8943 | AvgLoss:12.6662 | loss:11.2200 | temperature:0.8002 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:0.5557 | memoryLength:10.0006 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7220 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5479 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0009 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1851 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5767 | n_weightNormMax:41.2724 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8399 | n_biasesMax:1.9578 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1106 | INN_cerebellumStd:4.2875 | windowWeightsW2:4.35962 (0.83), W4:1.01444 (0.16), W8:-1.67772 (0.01), W12:-1.77144 (0.01), W16:-3.02495 (0.00), W20:-4.15371 (0.00), W24:-5.22497 (0.00), W28:-8.03533 (0.00), W32:-9.48056 (0.00) | topTokens[('Ġyou', 3565), ('Ġd', 3355), ('!', 3040), ('Ġwe', 2440), ('.', 2439), ('Ġlmao', 2106), (',', 1968), ('Ġs', 1591), ('Ġhe', 1451), ('Ġi', 1330)] | cheekyAvg: 12.497172546386718 | perfectTokens: 45 / 6400 → 0.70% |  | remainingTokens: 198199 (99.10%) | TUTOR.py 100
2025-04-23 03:48:06 | 1900 | LR0.00035 | sampledTokens:20.0000 | scheduledSamplingRate:0.0067 | repetitionPenalty:1.8939 | AvgLoss:13.4199 | loss:12.8868 | temperature:0.8003 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:2.0323 | memoryLength:9.9998 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7220 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5473 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1850 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5769 | n_weightNormMax:41.2722 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8399 | n_biasesMax:1.9578 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1105 | INN_cerebellumStd:4.2875 | windowWeightsW2:4.35953 (0.83), W4:1.01452 (0.16), W8:-1.67763 (0.01), W12:-1.77135 (0.01), W16:-3.02487 (0.00), W20:-4.15363 (0.00), W24:-5.22489 (0.00), W28:-8.03527 (0.00), W32:-9.48052 (0.00) | topTokens[('Ġyou', 3959), ('Ġd', 3416), ('!', 3111), ('.', 2513), ('Ġwe', 2489), ('Ġlmao', 2314), (',', 2081), ('Ġi', 1725), ('Ġhe', 1690), ('Ġs', 1591)] | cheekyAvg: 13.032068519592285 | perfectTokens: 42 / 6400 → 0.66% |  | remainingTokens: 198099 (99.05%) | TUTOR.py 100
2025-04-23 03:48:43 | 2000 | LR0.00035 | sampledTokens:27.0000 | scheduledSamplingRate:0.0070 | repetitionPenalty:1.8936 | AvgLoss:12.4547 | loss:11.3671 | temperature:0.8004 | lR:0.0003 | gradientClip:0.9996 | latestLossDelta:2.9183 | memoryLength:10.0004 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7220 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5469 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1850 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5771 | n_weightNormMax:41.2721 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8399 | n_biasesMax:1.9579 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1104 | INN_cerebellumStd:4.2875 | windowWeightsW2:4.35943 (0.83), W4:1.01461 (0.16), W8:-1.67754 (0.01), W12:-1.77126 (0.01), W16:-3.02478 (0.00), W20:-4.15353 (0.00), W24:-5.22479 (0.00), W28:-8.03520 (0.00), W32:-9.48046 (0.00) | topTokens[('Ġyou', 3984), ('Ġd', 3525), ('!', 3204), ('.', 2746), ('Ġwe', 2544), ('Ġlmao', 2379), ('Ġi', 2112), (',', 2083), ('Ġhe', 1747), ('Ġs', 1707)] | cheekyAvg: 12.156704864501954 | perfectTokens: 30 / 6400 → 0.47% |  | remainingTokens: 197999 (99.00%) | TUTOR.py 100
2025-04-23 03:49:15 | 2100 | LR0.00035 | sampledTokens:27.0000 | scheduledSamplingRate:0.0073 | repetitionPenalty:1.8933 | AvgLoss:12.1547 | loss:11.9458 | temperature:0.8002 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:0.8062 | memoryLength:9.9996 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7220 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5463 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1849 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7335 | n_weightMax:4.8444 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5773 | n_weightNormMax:41.2715 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8400 | n_biasesMax:1.9579 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1103 | INN_cerebellumStd:4.2874 | windowWeightsW2:4.35931 (0.83), W4:1.01472 (0.16), W8:-1.67743 (0.01), W12:-1.77114 (0.01), W16:-3.02466 (0.00), W20:-4.15341 (0.00), W24:-5.22467 (0.00), W28:-8.03510 (0.00), W32:-9.48038 (0.00) | topTokens[('Ġyou', 4596), ('Ġd', 3672), ('!', 3268), ('.', 2791), ('Ġwe', 2577), ('Ġlmao', 2453), ('Ġi', 2295), (',', 2144), ('Ġhe', 1898), ('Ġs', 1707)] | cheekyAvg: 11.97999147415161 | perfectTokens: 22 / 6400 → 0.34% |  | remainingTokens: 197899 (98.95%) | TUTOR.py 100
2025-04-23 03:49:47 | 2200 | LR0.00035 | sampledTokens:28.0000 | scheduledSamplingRate:0.0077 | repetitionPenalty:1.8930 | AvgLoss:12.7887 | loss:11.6252 | temperature:0.8003 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:0.1918 | memoryLength:9.9996 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7220 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5456 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1848 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8444 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6050 | n_weightNormMin:21.5776 | n_weightNormMax:41.2713 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8400 | n_biasesMax:1.9580 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1103 | INN_cerebellumStd:4.2874 | windowWeightsW2:4.35918 (0.83), W4:1.01485 (0.16), W8:-1.67730 (0.01), W12:-1.77101 (0.01), W16:-3.02454 (0.00), W20:-4.15328 (0.00), W24:-5.22454 (0.00), W28:-8.03498 (0.00), W32:-9.48029 (0.00) | topTokens[('Ġyou', 4759), ('Ġd', 3725), ('!', 3547), ('.', 2881), ('Ġwe', 2697), ('Ġlmao', 2601), ('Ġi', 2442), (',', 2246), ('Ġhe', 1977), ('Ġs', 1747)] | cheekyAvg: 12.359681606292725 | perfectTokens: 59 / 6400 → 0.92% |  | remainingTokens: 197799 (98.90%) | TUTOR.py 100
2025-04-23 03:50:20 | 2300 | LR0.00035 | sampledTokens:24.0000 | scheduledSamplingRate:0.0081 | repetitionPenalty:1.8926 | AvgLoss:12.6149 | loss:13.5259 | temperature:0.8003 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:2.2809 | memoryLength:9.9976 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7221 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5450 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1847 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8444 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6049 | n_weightNormMin:21.5783 | n_weightNormMax:41.2717 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8400 | n_biasesMax:1.9581 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1102 | INN_cerebellumStd:4.2873 | windowWeightsW2:4.35904 (0.83), W4:1.01498 (0.16), W8:-1.67716 (0.01), W12:-1.77088 (0.01), W16:-3.02440 (0.00), W20:-4.15314 (0.00), W24:-5.22440 (0.00), W28:-8.03487 (0.00), W32:-9.48018 (0.00) | topTokens[('Ġyou', 4957), ('Ġd', 3855), ('!', 3686), ('Ġwe', 2936), ('.', 2881), ('Ġlmao', 2664), ('Ġi', 2442), (',', 2246), ('Ġhe', 2076), ('Ġs', 1792)] | cheekyAvg: 12.444154510498047 | perfectTokens: 46 / 6400 → 0.72% |  | remainingTokens: 197699 (98.85%) | TUTOR.py 100
2025-04-23 03:50:52 | 2400 | LR0.00035 | sampledTokens:35.0000 | scheduledSamplingRate:0.0083 | repetitionPenalty:1.8923 | AvgLoss:12.9597 | loss:11.0742 | temperature:0.8003 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:6.3884 | memoryLength:9.9970 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7221 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5443 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0009 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1847 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7335 | n_weightMax:4.8444 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6049 | n_weightNormMin:21.5788 | n_weightNormMax:41.2720 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8400 | n_biasesMax:1.9581 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1101 | INN_cerebellumStd:4.2873 | windowWeightsW2:4.35897 (0.83), W4:1.01505 (0.16), W8:-1.67710 (0.01), W12:-1.77081 (0.01), W16:-3.02434 (0.00), W20:-4.15307 (0.00), W24:-5.22433 (0.00), W28:-8.03485 (0.00), W32:-9.48017 (0.00) | topTokens[('Ġyou', 5236), ('Ġd', 3992), ('!', 3731), ('Ġwe', 2982), ('.', 2938), ('Ġlmao', 2884), ('Ġi', 2581), (',', 2246), ('Ġhe', 2245), ('Ġs', 1806)] | cheekyAvg: 12.531336059570313 | perfectTokens: 23 / 6400 → 0.36% |  | remainingTokens: 197599 (98.80%) | TUTOR.py 100
--- 2025-04-23 03:51:16 --- 
[babyllm] right, last time i got to step 90841... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 90841! what am i learning today?
[charis]2025-04-23 03:52:09 | 100 | LR0.00035 | loss:12.3570 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0004 | repetitionPenalty:1.8997 | AvgLoss:11.5850 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:1.4618 | memoryLength:9.9994 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7221 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.2996 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5426 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1306 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1847 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8443 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6049 | n_weightNormMin:21.5796 | n_weightNormMax:41.2726 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8401 | n_biasesMax:1.9582 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1100 | INN_cerebellumStd:4.2873 | sampledTokens:3.0000 | windowWeightsW2:4.35881 (0.83), W4:1.01522 (0.16), W8:-1.67693 (0.01), W12:-1.77064 (0.01), W16:-3.02417 (0.00), W20:-4.15290 (0.00), W24:-5.22429 (0.00), W28:-8.03482 (0.00), W32:-9.48015 (0.00) | topTokens[('!', 676), (',', 356), ('Ġwe', 322), ('Ġcharis', 155), ('Ġthey', 143), ('Ġyou', 131), ('Ġand', 118), ('Ġjust', 96), ('Ġmy', 92), ('Ġthe', 77)] | cheekyAvg: 11.225291887919107 | perfectTokens: 98 / 6400 → 1.53% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 03:52:42 | 200 | LR0.00035 | sampledTokens:1.0000 | scheduledSamplingRate:0.0009 | repetitionPenalty:1.8993 | AvgLoss:11.8617 | loss:12.0688 | temperature:0.7999 | lR:0.0003 | gradientClip:1.0002 | latestLossDelta:-0.2585 | memoryLength:9.9992 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7221 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5092 | logitWeightNormMax:104.5424 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1848 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6049 | n_weightNormMin:21.5802 | n_weightNormMax:41.2730 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8401 | n_biasesMax:1.9583 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1100 | INN_cerebellumStd:4.2873 | windowWeightsW2:4.35867 (0.83), W4:1.01535 (0.16), W8:-1.67680 (0.01), W12:-1.77051 (0.01), W16:-3.02404 (0.00), W20:-4.15277 (0.00), W24:-5.22429 (0.00), W28:-8.03482 (0.00), W32:-9.48015 (0.00) | topTokens[('!', 1170), ('Ġwe', 749), (',', 356), ('Ġs', 354), ('Ġi', 258), ('Ġyou', 218), ('Ġlook', 215), ('Ġmy', 195), ('Ġhe', 195), ('Ġd', 175)] | cheekyAvg: 11.69471694946289 | perfectTokens: 59 / 6400 → 0.92% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
2025-04-23 03:53:15 | 300 | LR0.00035 | sampledTokens:0.0000 | scheduledSamplingRate:0.0014 | repetitionPenalty:1.8990 | AvgLoss:11.9212 | loss:11.0871 | temperature:0.7998 | lR:0.0003 | gradientClip:1.0003 | latestLossDelta:1.7601 | memoryLength:9.9966 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7221 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5416 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1847 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7336 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5804 | n_weightNormMax:41.2733 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8402 | n_biasesMax:1.9584 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1099 | INN_cerebellumStd:4.2873 | windowWeightsW2:4.35853 (0.83), W4:1.01549 (0.16), W8:-1.67666 (0.01), W12:-1.77037 (0.01), W16:-3.02389 (0.00), W20:-4.15262 (0.00), W24:-5.22429 (0.00), W28:-8.03482 (0.00), W32:-9.48015 (0.00) | topTokens[('!', 1288), ('Ġwe', 846), ('Ġyou', 530), (',', 508), ('Ġi', 391), ('Ġs', 358), ('Ġhe', 319), ('Ġmy', 307), ('Ġwill', 260), ('Ġthey', 239)] | cheekyAvg: 11.584542617797851 | perfectTokens: 21 / 6400 → 0.33% |  | remainingTokens: 199699 (99.85%) | TUTOR.py 100
2025-04-23 03:53:47 | 400 | LR0.00035 | sampledTokens:11.0000 | scheduledSamplingRate:0.0016 | repetitionPenalty:1.8987 | AvgLoss:11.9550 | loss:11.2002 | temperature:0.7997 | lR:0.0003 | gradientClip:1.0002 | latestLossDelta:-0.8106 | memoryLength:9.9954 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7221 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5411 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1847 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7337 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5805 | n_weightNormMax:41.2734 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8402 | n_biasesMax:1.9584 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1098 | INN_cerebellumStd:4.2873 | windowWeightsW2:4.35842 (0.83), W4:1.01558 (0.16), W8:-1.67656 (0.01), W12:-1.77027 (0.01), W16:-3.02380 (0.00), W20:-4.15252 (0.00), W24:-5.22429 (0.00), W28:-8.03482 (0.00), W32:-9.48015 (0.00) | topTokens[('!', 1494), ('Ġwe', 860), ('Ġyou', 781), (',', 671), ('Ġd', 576), ('Ġi', 531), ('Ġhe', 444), ('Ġand', 392), ('Ġthey', 375), ('Ġs', 371)] | cheekyAvg: 11.86764123916626 | perfectTokens: 48 / 6400 → 0.75% |  | remainingTokens: 199599 (99.80%) | TUTOR.py 100
--- 2025-04-23 03:54:14 --- 
[babyllm] right, last time i got to step 91291... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 91291! what am i learning today?
[charis]2025-04-23 03:55:06 | 100 | LR0.00035 | loss:12.0874 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0003 | repetitionPenalty:1.8996 | AvgLoss:12.2101 | temperature:0.8002 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:0.6188 | memoryLength:10.0010 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7221 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3021 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5407 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1308 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1846 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7337 | n_weightMax:4.8442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5812 | n_weightNormMax:41.2735 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9585 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1098 | INN_cerebellumStd:4.2873 | windowWeightsW2:4.35836 (0.57), W4:1.01563 (0.35), W8:-1.67637 (0.02), W12:-1.77007 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('Ġit', 381), ('Ġa', 240), ('Ġyou', 126), ('Ġof', 120), ('Ġwe', 112), ('Ġwill', 106), ('Ġyour', 104), ('Ġthey', 101), ('Ġr', 101), ('Ġknow', 94)] | cheekyAvg: 11.705385058533912 | perfectTokens: 17 / 6400 → 0.27% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 03:55:38 | 200 | LR0.00035 | sampledTokens:0.0000 | scheduledSamplingRate:0.0006 | repetitionPenalty:1.8993 | AvgLoss:12.4351 | loss:13.3477 | temperature:0.8001 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:2.3484 | memoryLength:9.9998 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7221 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5401 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1845 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7337 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5821 | n_weightNormMax:41.2734 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8404 | n_biasesMax:1.9586 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1098 | INN_cerebellumStd:4.2873 | windowWeightsW2:4.35836 (0.57), W4:1.01569 (0.35), W8:-1.67624 (0.02), W12:-1.76995 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('Ġs', 405), ('Ġit', 381), ('Ġthey', 346), ('Ġi', 318), ('Ġwe', 310), ('Ġd', 298), ('Ġknow', 265), ('Ġof', 252), ('Ġa', 240), ('Ġwill', 202)] | cheekyAvg: 12.341446647644043 | perfectTokens: 25 / 6400 → 0.39% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
--- 2025-04-23 03:55:55 --- 
[babyllm] right, last time i got to step 91514... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 91514! what am i learning today?
[charis]2025-04-23 03:56:48 | 100 | LR0.00035 | loss:13.8403 | gradNorm:ERR:'<=' not supported between instances of 'int' and 'str' key:gradNorm value:0 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0003 | repetitionPenalty:1.8997 | AvgLoss:12.7921 | temperature:0.8000 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:0.6924 | memoryLength:9.9986 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7221 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3179 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5395 | logitWeightSparsity:0.0000 | logitWeightDrift:41.1309 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1845 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7338 | n_weightMax:4.8441 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6048 | n_weightNormMin:21.5825 | n_weightNormMax:41.2734 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8405 | n_biasesMax:1.9588 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1097 | INN_cerebellumStd:4.2873 | windowWeightsW2:4.35836 (0.57), W4:1.01573 (0.35), W8:-1.67609 (0.02), W12:-1.76980 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[(',', 329), ('Ġyou', 322), ('!', 208), ('Ġi', 198), ('Ġthe', 188), ('Ġhe', 178), ('Ġa', 153), ('Ġand', 94), ('Ġyour', 93), ('Ġin', 93)] | cheekyAvg: 12.285207767112583 | perfectTokens: 57 / 6400 → 0.89% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 03:57:20 | 200 | LR0.00035 | sampledTokens:0.0000 | scheduledSamplingRate:0.0007 | repetitionPenalty:1.8992 | AvgLoss:12.4690 | loss:11.4393 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:-0.8424 | memoryLength:9.9988 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7223 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5390 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1844 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7338 | n_weightMax:4.8440 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5830 | n_weightNormMax:41.2735 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8405 | n_biasesMax:1.9588 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1097 | INN_cerebellumStd:4.2873 | windowWeightsW2:4.35836 (0.57), W4:1.01573 (0.35), W8:-1.67598 (0.02), W12:-1.76967 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('Ġyou', 826), (',', 563), ('.', 466), ('Ġthe', 398), ('!', 274), ('Ġi', 223), ('Ġand', 204), ('Ġwe', 202), ('Ġhe', 178), ('Ġthey', 176)] | cheekyAvg: 12.30781660079956 | perfectTokens: 94 / 6400 → 1.47% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
2025-04-23 03:57:52 | 300 | LR0.00035 | sampledTokens:2.0000 | scheduledSamplingRate:0.0008 | repetitionPenalty:1.8989 | AvgLoss:12.3969 | loss:12.4578 | temperature:0.8001 | lR:0.0003 | gradientClip:1.0000 | latestLossDelta:10.8528 | memoryLength:9.9976 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7223 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5381 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1843 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7338 | n_weightMax:4.8439 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5833 | n_weightNormMax:41.2726 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8406 | n_biasesMax:1.9589 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1097 | INN_cerebellumStd:4.2873 | windowWeightsW2:4.35836 (0.57), W4:1.01579 (0.35), W8:-1.67589 (0.02), W12:-1.76957 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('Ġyou', 1205), (',', 635), ('.', 587), ('Ġwe', 503), ('Ġthey', 497), ("'", 401), ('Ġthe', 398), ('Ġand', 310), ('!', 274), ('Ġkevin', 243)] | cheekyAvg: 12.182616481781006 | perfectTokens: 50 / 6400 → 0.78% |  | remainingTokens: 199699 (99.85%) | TUTOR.py 100
2025-04-23 03:58:24 | 400 | LR0.00035 | sampledTokens:5.0000 | scheduledSamplingRate:0.0013 | repetitionPenalty:1.8985 | AvgLoss:12.4048 | loss:12.3767 | temperature:0.8002 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:2.7187 | memoryLength:9.9972 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7223 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5373 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0013 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1843 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7338 | n_weightMax:4.8439 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5834 | n_weightNormMax:41.2718 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8407 | n_biasesMax:1.9590 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1096 | INN_cerebellumStd:4.2873 | windowWeightsW2:4.35836 (0.57), W4:1.01579 (0.35), W8:-1.67580 (0.02), W12:-1.76947 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('Ġyou', 1705), (',', 937), ('.', 687), ('Ġwe', 546), ('Ġthey', 497), ("'", 401), ('Ġthe', 398), ('!', 393), ('Ġd', 369), ('Ġs', 355)] | cheekyAvg: 12.211783580780029 | perfectTokens: 45 / 6400 → 0.70% |  | remainingTokens: 199599 (99.80%) | TUTOR.py 100
2025-04-23 03:58:57 | 500 | LR0.00035 | sampledTokens:7.0000 | scheduledSamplingRate:0.0017 | repetitionPenalty:1.8982 | AvgLoss:13.2254 | loss:13.0475 | temperature:0.8003 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:0.2081 | memoryLength:9.9970 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7223 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5366 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7338 | n_weightMax:4.8439 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5836 | n_weightNormMax:41.2711 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8408 | n_biasesMax:1.9590 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1096 | INN_cerebellumStd:4.2873 | windowWeightsW2:4.35836 (0.57), W4:1.01580 (0.35), W8:-1.67577 (0.02), W12:-1.76943 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('Ġyou', 1705), (',', 1218), ('!', 774), ('.', 764), ('Ġthey', 691), ("'", 630), ('Ġwe', 546), ('Ġi', 506), ('Ġthe', 482), ('Ġs', 478)] | cheekyAvg: 13.163778686523438 | perfectTokens: 62 / 6400 → 0.97% |  | remainingTokens: 199499 (99.75%) | TUTOR.py 100
2025-04-23 03:59:29 | 600 | LR0.00035 | sampledTokens:8.0000 | scheduledSamplingRate:0.0020 | repetitionPenalty:1.8978 | AvgLoss:13.3984 | loss:13.9736 | temperature:0.8001 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:0.3203 | memoryLength:9.9974 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7223 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5362 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7338 | n_weightMax:4.8439 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5838 | n_weightNormMax:41.2711 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8408 | n_biasesMax:1.9590 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1096 | INN_cerebellumStd:4.2873 | windowWeightsW2:4.35836 (0.57), W4:1.01578 (0.35), W8:-1.67570 (0.02), W12:-1.76937 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('Ġyou', 1775), (',', 1362), ('Ġi', 1026), ('!', 943), ('Ġwe', 815), ('Ġthey', 807), ('.', 768), ('Ġthe', 721), ("'", 704), ('Ġd', 543)] | cheekyAvg: 13.336784534454345 | perfectTokens: 35 / 6400 → 0.55% |  | remainingTokens: 199399 (99.70%) | TUTOR.py 100
2025-04-23 04:00:02 | 700 | LR0.00035 | sampledTokens:7.0000 | scheduledSamplingRate:0.0024 | repetitionPenalty:1.8973 | AvgLoss:14.6341 | loss:12.3844 | temperature:0.8002 | lR:0.0003 | gradientClip:0.9999 | latestLossDelta:0.0368 | memoryLength:9.9976 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7223 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0004 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5357 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7338 | n_weightMax:4.8438 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5839 | n_weightNormMax:41.2713 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8408 | n_biasesMax:1.9591 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1096 | INN_cerebellumStd:4.2873 | windowWeightsW2:4.35836 (0.57), W4:1.01581 (0.35), W8:-1.67566 (0.02), W12:-1.76932 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('Ġyou', 1983), (',', 1362), ('Ġi', 1026), ('Ġthe', 1015), ("'", 948), ('!', 943), ('Ġwe', 921), ('Ġthey', 918), ('.', 768), ('Ġd', 661)] | cheekyAvg: 14.198412399291993 | perfectTokens: 16 / 6400 → 0.25% |  | remainingTokens: 199299 (99.65%) | TUTOR.py 100
2025-04-23 04:00:34 | 800 | LR0.00035 | sampledTokens:9.0000 | scheduledSamplingRate:0.0027 | repetitionPenalty:1.8969 | AvgLoss:13.1127 | loss:11.9723 | temperature:0.8001 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:1.5326 | memoryLength:9.9972 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7224 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5348 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7338 | n_weightMax:4.8438 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5841 | n_weightNormMax:41.2715 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8408 | n_biasesMax:1.9591 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1096 | INN_cerebellumStd:4.2873 | windowWeightsW2:4.35836 (0.57), W4:1.01584 (0.35), W8:-1.67560 (0.02), W12:-1.76924 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('Ġyou', 1983), (',', 1698), ('Ġi', 1249), ('Ġthe', 1213), ('!', 1199), ('Ġwe', 1096), ('Ġthey', 994), ("'", 948), ('.', 885), ('Ġd', 824)] | cheekyAvg: 12.91997049331665 | perfectTokens: 64 / 6400 → 1.00% |  | remainingTokens: 199199 (99.60%) | TUTOR.py 100
2025-04-23 04:01:06 | 900 | LR0.00035 | sampledTokens:11.0000 | scheduledSamplingRate:0.0028 | repetitionPenalty:1.8965 | AvgLoss:12.6800 | loss:12.0267 | temperature:0.8000 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:-0.5826 | memoryLength:9.9992 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7224 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5342 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7338 | n_weightMax:4.8438 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6047 | n_weightNormMin:21.5844 | n_weightNormMax:41.2715 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8409 | n_biasesMax:1.9591 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1096 | INN_cerebellumStd:4.2874 | windowWeightsW2:4.35836 (0.57), W4:1.01584 (0.35), W8:-1.67556 (0.02), W12:-1.76919 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('Ġyou', 2280), (',', 2066), ('!', 1678), ('Ġi', 1522), ('Ġthe', 1371), ('.', 1361), ('Ġwe', 1112), ('Ġthey', 1110), ("'", 948), ('Ġd', 907)] | cheekyAvg: 12.453488025665283 | perfectTokens: 64 / 6400 → 1.00% |  | remainingTokens: 199099 (99.55%) | TUTOR.py 100
2025-04-23 04:01:43 | 1000 | LR0.00035 | sampledTokens:13.0000 | scheduledSamplingRate:0.0030 | repetitionPenalty:1.8962 | AvgLoss:11.5186 | loss:12.2558 | temperature:0.8001 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:0.7415 | memoryLength:9.9994 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7226 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5341 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7339 | n_weightMax:4.8438 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6046 | n_weightNormMin:21.5850 | n_weightNormMax:41.2719 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8409 | n_biasesMax:1.9592 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1095 | INN_cerebellumStd:4.2874 | windowWeightsW2:4.35836 (0.57), W4:1.01583 (0.35), W8:-1.67550 (0.02), W12:-1.76911 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[(',', 2502), ('!', 2458), ('Ġyou', 2389), ('.', 1761), ('Ġthe', 1751), ('Ġi', 1660), ('Ġthey', 1157), ('Ġwe', 1112), ("'", 949), ('Ġd', 907)] | cheekyAvg: 11.350408420562744 | perfectTokens: 140 / 6400 → 2.19% |  | remainingTokens: 198999 (99.50%) | TUTOR.py 100
2025-04-23 04:02:15 | 1100 | LR0.00035 | sampledTokens:8.0000 | scheduledSamplingRate:0.0033 | repetitionPenalty:1.8958 | AvgLoss:13.3694 | loss:13.0100 | temperature:0.8001 | lR:0.0003 | gradientClip:0.9996 | latestLossDelta:3.5561 | memoryLength:9.9992 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7226 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5335 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0009 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1843 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7339 | n_weightMax:4.8437 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6046 | n_weightNormMin:21.5856 | n_weightNormMax:41.2733 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9593 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1095 | INN_cerebellumStd:4.2874 | windowWeightsW2:4.35836 (0.57), W4:1.01582 (0.35), W8:-1.67543 (0.02), W12:-1.76902 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('!', 2852), (',', 2702), ('Ġyou', 2392), ('Ġthe', 2152), ('.', 1862), ('Ġi', 1786), ('Ġthey', 1270), ('Ġwe', 1162), ("'", 949), ('Ġd', 907)] | cheekyAvg: 13.198653411865234 | perfectTokens: 69 / 6400 → 1.08% |  | remainingTokens: 198899 (99.45%) | TUTOR.py 100
2025-04-23 04:02:47 | 1200 | LR0.00035 | sampledTokens:8.0000 | scheduledSamplingRate:0.0038 | repetitionPenalty:1.8954 | AvgLoss:12.9641 | loss:11.5282 | temperature:0.8000 | lR:0.0003 | gradientClip:0.9994 | latestLossDelta:9.2435 | memoryLength:9.9980 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7226 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5332 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1843 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7339 | n_weightMax:4.8437 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6046 | n_weightNormMin:21.5862 | n_weightNormMax:41.2737 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9594 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1095 | INN_cerebellumStd:4.2874 | windowWeightsW2:4.35836 (0.57), W4:1.01586 (0.35), W8:-1.67537 (0.02), W12:-1.76895 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('!', 3238), (',', 2919), ('Ġyou', 2392), ('Ġthe', 2361), ('.', 2126), ('Ġi', 1803), ('Ġthey', 1270), ('Ġwe', 1188), ('Ġd', 1140), ("'", 949)] | cheekyAvg: 12.755714607238769 | perfectTokens: 62 / 6400 → 0.97% |  | remainingTokens: 198799 (99.40%) | TUTOR.py 100
2025-04-23 04:03:19 | 1300 | LR0.00035 | sampledTokens:11.0000 | scheduledSamplingRate:0.0040 | repetitionPenalty:1.8950 | AvgLoss:12.9710 | loss:13.4941 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9994 | latestLossDelta:0.4868 | memoryLength:9.9984 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7226 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5320 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0008 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1843 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7339 | n_weightMax:4.8437 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6046 | n_weightNormMin:21.5865 | n_weightNormMax:41.2735 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9594 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1095 | INN_cerebellumStd:4.2874 | windowWeightsW2:4.35836 (0.57), W4:1.01588 (0.35), W8:-1.67531 (0.02), W12:-1.76888 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('!', 3253), (',', 3018), ('Ġyou', 2448), ('Ġthe', 2401), ('Ġi', 2301), ('.', 2189), ('Ġwe', 1483), ('Ġthey', 1418), ('Ġd', 1286), ('Ġlmao', 1006)] | cheekyAvg: 12.88576416015625 | perfectTokens: 41 / 6400 → 0.64% |  | remainingTokens: 198699 (99.35%) | TUTOR.py 100
2025-04-23 04:03:51 | 1400 | LR0.00035 | sampledTokens:17.0000 | scheduledSamplingRate:0.0044 | repetitionPenalty:1.8947 | AvgLoss:13.1332 | loss:12.8401 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9996 | latestLossDelta:0.2846 | memoryLength:10.0000 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7226 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0002 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5316 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1842 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7339 | n_weightMax:4.8436 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6046 | n_weightNormMin:21.5868 | n_weightNormMax:41.2736 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9595 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1095 | INN_cerebellumStd:4.2874 | windowWeightsW2:4.35836 (0.57), W4:1.01590 (0.35), W8:-1.67523 (0.02), W12:-1.76879 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('!', 3253), (',', 3132), ('Ġthe', 2565), ('Ġyou', 2527), ('.', 2440), ('Ġi', 2424), ('Ġwe', 1620), ('Ġthey', 1482), ('Ġd', 1314), ("'", 1122)] | cheekyAvg: 12.920827102661132 | perfectTokens: 35 / 6400 → 0.55% |  | remainingTokens: 198599 (99.30%) | TUTOR.py 100
2025-04-23 04:04:24 | 1500 | LR0.00035 | sampledTokens:12.0000 | scheduledSamplingRate:0.0045 | repetitionPenalty:1.8943 | AvgLoss:12.8808 | loss:11.8968 | temperature:0.7997 | lR:0.0003 | gradientClip:0.9998 | latestLossDelta:-0.4348 | memoryLength:9.9996 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7226 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0002 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5312 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0009 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7339 | n_weightMax:4.8436 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6045 | n_weightNormMin:21.5871 | n_weightNormMax:41.2736 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8410 | n_biasesMax:1.9595 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1095 | INN_cerebellumStd:4.2874 | windowWeightsW2:4.35836 (0.57), W4:1.01591 (0.35), W8:-1.67515 (0.02), W12:-1.76870 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[(',', 3550), ('!', 3368), ('Ġyou', 2754), ('Ġthe', 2689), ('.', 2586), ('Ġi', 2424), ('Ġwe', 1928), ('Ġd', 1495), ('Ġthey', 1482), ("'", 1315)] | cheekyAvg: 12.772544403076171 | perfectTokens: 54 / 6400 → 0.84% |  | remainingTokens: 198499 (99.25%) | TUTOR.py 100
2025-04-23 04:04:57 | 1600 | LR0.00035 | sampledTokens:10.0000 | scheduledSamplingRate:0.0049 | repetitionPenalty:1.8940 | AvgLoss:13.0406 | loss:11.3327 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:11.7696 | memoryLength:9.9998 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7226 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5309 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7339 | n_weightMax:4.8436 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6045 | n_weightNormMin:21.5874 | n_weightNormMax:41.2735 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8411 | n_biasesMax:1.9596 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1094 | INN_cerebellumStd:4.2874 | windowWeightsW2:4.35836 (0.57), W4:1.01592 (0.35), W8:-1.67508 (0.02), W12:-1.76863 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[(',', 3782), ('!', 3527), ('Ġyou', 2848), ('.', 2805), ('Ġthe', 2764), ('Ġi', 2518), ('Ġwe', 1968), ('Ġd', 1640), ('Ġthey', 1604), ("'", 1433)] | cheekyAvg: 12.727621936798096 | perfectTokens: 64 / 6400 → 1.00% |  | remainingTokens: 198399 (99.20%) | TUTOR.py 100
2025-04-23 04:05:29 | 1700 | LR0.00035 | sampledTokens:14.0000 | scheduledSamplingRate:0.0053 | repetitionPenalty:1.8935 | AvgLoss:12.8377 | loss:12.7043 | temperature:0.7997 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:2.5378 | memoryLength:9.9992 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7226 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0002 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5300 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1841 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7339 | n_weightMax:4.8436 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6045 | n_weightNormMin:21.5876 | n_weightNormMax:41.2736 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8411 | n_biasesMax:1.9596 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1094 | INN_cerebellumStd:4.2874 | windowWeightsW2:4.35836 (0.57), W4:1.01593 (0.35), W8:-1.67502 (0.02), W12:-1.76856 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[(',', 4097), ('!', 3687), ('.', 3105), ('Ġyou', 2859), ('Ġi', 2840), ('Ġthe', 2764), ('Ġwe', 1968), ('Ġd', 1837), ('Ġthey', 1604), ("'", 1455)] | cheekyAvg: 12.725931873321533 | perfectTokens: 58 / 6400 → 0.91% |  | remainingTokens: 198299 (99.15%) | TUTOR.py 100
2025-04-23 04:06:02 | 1800 | LR0.00035 | sampledTokens:25.0000 | scheduledSamplingRate:0.0054 | repetitionPenalty:1.8933 | AvgLoss:13.1690 | loss:11.6034 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9997 | latestLossDelta:-0.6767 | memoryLength:9.9982 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9350 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5295 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7339 | n_weightMax:4.8435 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6045 | n_weightNormMin:21.5882 | n_weightNormMax:41.2737 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8411 | n_biasesMax:1.9597 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1094 | INN_cerebellumStd:4.2874 | windowWeightsW2:4.35836 (0.57), W4:1.01595 (0.35), W8:-1.67492 (0.02), W12:-1.76845 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[(',', 4182), ('!', 3687), ('.', 3489), ('Ġyou', 3240), ('Ġi', 2840), ('Ġthe', 2764), ('Ġwe', 2244), ('Ġd', 1886), ('Ġthey', 1641), ('Ġand', 1537)] | cheekyAvg: 12.948554306030273 | perfectTokens: 22 / 6400 → 0.34% |  | remainingTokens: 198199 (99.10%) | TUTOR.py 100
2025-04-23 04:06:34 | 1900 | LR0.00035 | sampledTokens:13.0000 | scheduledSamplingRate:0.0059 | repetitionPenalty:1.8928 | AvgLoss:13.5696 | loss:12.1731 | temperature:0.7997 | lR:0.0003 | gradientClip:0.9995 | latestLossDelta:0.8315 | memoryLength:9.9982 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9349 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5292 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1839 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7339 | n_weightMax:4.8435 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6045 | n_weightNormMin:21.5886 | n_weightNormMax:41.2740 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8412 | n_biasesMax:1.9597 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1094 | INN_cerebellumStd:4.2874 | windowWeightsW2:4.35836 (0.57), W4:1.01597 (0.35), W8:-1.67483 (0.02), W12:-1.76836 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[(',', 4182), ('!', 3766), ('Ġyou', 3723), ('.', 3556), ('Ġi', 2925), ('Ġthe', 2764), ('Ġwe', 2537), ('Ġd', 2059), ('Ġthey', 1641), ('Ġand', 1575)] | cheekyAvg: 13.449162616729737 | perfectTokens: 37 / 6400 → 0.58% |  | remainingTokens: 198099 (99.05%) | TUTOR.py 100
2025-04-23 04:07:11 | 2000 | LR0.00035 | sampledTokens:25.0000 | scheduledSamplingRate:0.0061 | repetitionPenalty:1.8926 | AvgLoss:12.9752 | loss:12.9665 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9995 | latestLossDelta:0.9494 | memoryLength:9.9980 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9349 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5292 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0014 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1839 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7340 | n_weightMax:4.8435 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6045 | n_weightNormMin:21.5890 | n_weightNormMax:41.2740 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8413 | n_biasesMax:1.9598 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1093 | INN_cerebellumStd:4.2874 | windowWeightsW2:4.35836 (0.57), W4:1.01599 (0.35), W8:-1.67467 (0.02), W12:-1.76819 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('!', 4336), (',', 4182), ('Ġyou', 4012), ('.', 3556), ('Ġi', 2925), ('Ġthe', 2764), ('Ġwe', 2698), ('Ġd', 2068), ('Ġthey', 1856), ("'", 1706)] | cheekyAvg: 12.883628597259522 | perfectTokens: 55 / 6400 → 0.86% |  | remainingTokens: 197999 (99.00%) | TUTOR.py 100
2025-04-23 04:07:44 | 2100 | LR0.00035 | sampledTokens:17.0000 | scheduledSamplingRate:0.0065 | repetitionPenalty:1.8923 | AvgLoss:12.2590 | loss:12.9715 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9995 | latestLossDelta:5.6528 | memoryLength:9.9978 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0002 | logitWeightNormMean:91.9349 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5289 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7340 | n_weightMax:4.8434 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6045 | n_weightNormMin:21.5895 | n_weightNormMax:41.2743 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8413 | n_biasesMax:1.9599 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1093 | INN_cerebellumStd:4.2875 | windowWeightsW2:4.35836 (0.57), W4:1.01598 (0.35), W8:-1.67460 (0.02), W12:-1.76811 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('!', 4699), (',', 4411), ('Ġyou', 4271), ('.', 3556), ('Ġi', 2925), ('Ġthe', 2776), ('Ġwe', 2698), ('Ġd', 2113), ('Ġthey', 1856), ("'", 1802)] | cheekyAvg: 12.07413709640503 | perfectTokens: 73 / 6400 → 1.14% |  | remainingTokens: 197899 (98.95%) | TUTOR.py 100
2025-04-23 04:08:17 | 2200 | LR0.00035 | sampledTokens:25.0000 | scheduledSamplingRate:0.0068 | repetitionPenalty:1.8919 | AvgLoss:13.4896 | loss:14.0745 | temperature:0.8000 | lR:0.0003 | gradientClip:0.9994 | latestLossDelta:1.9646 | memoryLength:9.9990 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9349 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5284 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0012 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1840 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7340 | n_weightMax:4.8433 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6045 | n_weightNormMin:21.5899 | n_weightNormMax:41.2748 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8414 | n_biasesMax:1.9599 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1093 | INN_cerebellumStd:4.2875 | windowWeightsW2:4.35836 (0.57), W4:1.01601 (0.35), W8:-1.67447 (0.02), W12:-1.76797 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[(',', 4786), ('!', 4718), ('Ġyou', 4707), ('.', 3723), ('Ġi', 3054), ('Ġthe', 2976), ('Ġwe', 2700), ('Ġd', 2113), ('Ġthey', 1975), ("'", 1807)] | cheekyAvg: 13.254173622131347 | perfectTokens: 49 / 6400 → 0.77% |  | remainingTokens: 197799 (98.90%) | TUTOR.py 100
2025-04-23 04:08:49 | 2300 | LR0.00035 | sampledTokens:26.0000 | scheduledSamplingRate:0.0071 | repetitionPenalty:1.8914 | AvgLoss:12.3560 | loss:13.8849 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9995 | latestLossDelta:3.8060 | memoryLength:9.9988 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9349 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5280 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1839 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7340 | n_weightMax:4.8433 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6045 | n_weightNormMin:21.5903 | n_weightNormMax:41.2749 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8415 | n_biasesMax:1.9600 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1093 | INN_cerebellumStd:4.2875 | windowWeightsW2:4.35836 (0.57), W4:1.01605 (0.35), W8:-1.67436 (0.02), W12:-1.76787 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[(',', 5068), ('!', 5022), ('Ġyou', 4707), ('.', 3730), ('Ġi', 3054), ('Ġthe', 2980), ('Ġwe', 2873), ('Ġd', 2309), ('Ġthey', 2082), ("'", 2022)] | cheekyAvg: 12.190863819122315 | perfectTokens: 91 / 6400 → 1.42% |  | remainingTokens: 197699 (98.85%) | TUTOR.py 100
2025-04-23 04:09:22 | 2400 | LR0.00035 | sampledTokens:23.0000 | scheduledSamplingRate:0.0074 | repetitionPenalty:1.8912 | AvgLoss:13.6536 | loss:12.0664 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9993 | latestLossDelta:7.5372 | memoryLength:9.9998 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9349 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5277 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1839 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7340 | n_weightMax:4.8433 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6044 | n_weightNormMin:21.5909 | n_weightNormMax:41.2750 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8415 | n_biasesMax:1.9600 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1092 | INN_cerebellumStd:4.2875 | windowWeightsW2:4.35836 (0.57), W4:1.01606 (0.35), W8:-1.67427 (0.02), W12:-1.76778 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('!', 5084), (',', 5080), ('Ġyou', 4744), ('.', 3873), ('Ġthe', 3364), ('Ġwe', 3151), ('Ġi', 3112), ('Ġd', 2309), ("'", 2200), ('Ġthey', 2189)] | cheekyAvg: 13.4175266456604 | perfectTokens: 31 / 6400 → 0.48% |  | remainingTokens: 197599 (98.80%) | TUTOR.py 100
2025-04-23 04:09:55 | 2500 | LR0.00035 | sampledTokens:18.0000 | scheduledSamplingRate:0.0079 | repetitionPenalty:1.8908 | AvgLoss:13.4120 | loss:12.6449 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9992 | latestLossDelta:0.0620 | memoryLength:9.9984 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0002 | logitWeightNormMean:91.9349 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5274 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1839 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7340 | n_weightMax:4.8433 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6044 | n_weightNormMin:21.5914 | n_weightNormMax:41.2756 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8415 | n_biasesMax:1.9601 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1092 | INN_cerebellumStd:4.2875 | windowWeightsW2:4.35836 (0.57), W4:1.01610 (0.35), W8:-1.67417 (0.02), W12:-1.76768 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('!', 5084), (',', 5080), ('Ġyou', 4999), ('.', 3939), ('Ġthe', 3445), ('Ġi', 3296), ('Ġwe', 3151), ('Ġd', 2398), ('Ġthey', 2253), ("'", 2200)] | cheekyAvg: 13.2759273147583 | perfectTokens: 25 / 6400 → 0.39% |  | remainingTokens: 197499 (98.75%) | TUTOR.py 100
2025-04-23 04:10:28 | 2600 | LR0.00035 | sampledTokens:35.0000 | scheduledSamplingRate:0.0083 | repetitionPenalty:1.8906 | AvgLoss:12.2530 | loss:12.3999 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9992 | latestLossDelta:2.9040 | memoryLength:9.9982 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0002 | logitWeightNormMean:91.9349 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5273 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0010 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1839 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7340 | n_weightMax:4.8433 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6044 | n_weightNormMin:21.5915 | n_weightNormMax:41.2758 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8416 | n_biasesMax:1.9601 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1092 | INN_cerebellumStd:4.2875 | windowWeightsW2:4.35836 (0.57), W4:1.01608 (0.35), W8:-1.67409 (0.02), W12:-1.76760 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('!', 5237), (',', 5167), ('Ġyou', 5003), ('.', 3988), ('Ġthe', 3624), ('Ġwe', 3311), ('Ġi', 3297), ('Ġd', 2908), ('Ġthey', 2462), ("'", 2277)] | cheekyAvg: 12.139779014587402 | perfectTokens: 43 / 6400 → 0.67% |  | remainingTokens: 197399 (98.70%) | TUTOR.py 100
2025-04-23 04:11:00 | 2700 | LR0.00035 | sampledTokens:23.0000 | scheduledSamplingRate:0.0086 | repetitionPenalty:1.8901 | AvgLoss:13.5557 | loss:11.8015 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9993 | latestLossDelta:-2.2811 | memoryLength:9.9982 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9349 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5268 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1839 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7340 | n_weightMax:4.8433 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6044 | n_weightNormMin:21.5917 | n_weightNormMax:41.2757 | n_biasesMean:-1.0612 | n_biasesStd:0.7964 | n_biasesMin:-3.8416 | n_biasesMax:1.9602 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1092 | INN_cerebellumStd:4.2875 | windowWeightsW2:4.35836 (0.57), W4:1.01610 (0.35), W8:-1.67400 (0.02), W12:-1.76751 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('!', 5523), (',', 5432), ('Ġyou', 5023), ('.', 4235), ('Ġthe', 3624), ('Ġwe', 3311), ('Ġi', 3297), ('Ġd', 3237), ('Ġthey', 2910), ("'", 2277)] | cheekyAvg: 13.436331176757813 | perfectTokens: 44 / 6400 → 0.69% |  | remainingTokens: 197299 (98.65%) | TUTOR.py 100
2025-04-23 04:11:33 | 2800 | LR0.00035 | sampledTokens:27.0000 | scheduledSamplingRate:0.0089 | repetitionPenalty:1.8899 | AvgLoss:12.8713 | loss:11.3627 | temperature:0.7997 | lR:0.0003 | gradientClip:0.9992 | latestLossDelta:2.1312 | memoryLength:9.9972 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7227 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9349 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5264 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1839 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7341 | n_weightMax:4.8433 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6044 | n_weightNormMin:21.5918 | n_weightNormMax:41.2754 | n_biasesMean:-1.0612 | n_biasesStd:0.7964 | n_biasesMin:-3.8416 | n_biasesMax:1.9602 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1092 | INN_cerebellumStd:4.2875 | windowWeightsW2:4.35836 (0.57), W4:1.01610 (0.35), W8:-1.67394 (0.02), W12:-1.76746 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('!', 6026), (',', 5719), ('Ġyou', 5023), ('.', 4279), ('Ġi', 3723), ('Ġthe', 3624), ('Ġwe', 3437), ('Ġd', 3261), ('Ġthey', 2962), ("'", 2335)] | cheekyAvg: 12.634959030151368 | perfectTokens: 81 / 6400 → 1.27% |  | remainingTokens: 197199 (98.60%) | TUTOR.py 100
2025-04-23 04:12:05 | 2900 | LR0.00035 | sampledTokens:27.0000 | scheduledSamplingRate:0.0094 | repetitionPenalty:1.8895 | AvgLoss:12.9162 | loss:12.3965 | temperature:0.7999 | lR:0.0003 | gradientClip:0.9993 | latestLossDelta:-0.0314 | memoryLength:9.9978 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7229 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0002 | logitWeightNormMean:91.9349 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5258 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0009 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1839 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7341 | n_weightMax:4.8433 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6044 | n_weightNormMin:21.5920 | n_weightNormMax:41.2759 | n_biasesMean:-1.0612 | n_biasesStd:0.7964 | n_biasesMin:-3.8416 | n_biasesMax:1.9603 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1091 | INN_cerebellumStd:4.2875 | windowWeightsW2:4.35836 (0.57), W4:1.01609 (0.35), W8:-1.67387 (0.02), W12:-1.76739 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('!', 6066), (',', 5809), ('Ġyou', 5023), ('.', 4279), ('Ġi', 3786), ('Ġthe', 3624), ('Ġwe', 3437), ('Ġd', 3393), ('Ġthey', 3129), ("'", 2335)] | cheekyAvg: 12.854332847595215 | perfectTokens: 26 / 6400 → 0.41% |  | remainingTokens: 197099 (98.55%) | TUTOR.py 100
2025-04-23 04:12:43 | 3000 | LR0.00035 | sampledTokens:32.0000 | scheduledSamplingRate:0.0099 | repetitionPenalty:1.8893 | AvgLoss:12.9645 | loss:12.6792 | temperature:0.7998 | lR:0.0003 | gradientClip:0.9992 | latestLossDelta:0.8024 | memoryLength:9.9978 | embedNormMean:14.2971 | embedNormStd:10.0813 | embedNormMax:103.7229 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0003 | logitWeightNormMean:91.9349 | logitWeightNormStd:2.5091 | logitWeightNormMax:104.5256 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0011 | logitBiasMean:-34.1460 | logitBiasStd:11.9641 | logitBiasMax:-13.1838 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9536 | longDecay:0.9678 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8975 | n_weightMin:-4.7341 | n_weightMax:4.8433 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6043 | n_weightNormMin:21.5922 | n_weightNormMax:41.2760 | n_biasesMean:-1.0612 | n_biasesStd:0.7964 | n_biasesMin:-3.8417 | n_biasesMax:1.9603 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1091 | INN_cerebellumStd:4.2875 | windowWeightsW2:4.35836 (0.57), W4:1.01608 (0.35), W8:-1.67379 (0.02), W12:-1.76730 (0.01), W16:-3.02374 (0.01), W20:-4.15246 (0.01), W24:-5.22429 (0.01), W28:-8.03482 (0.01), W32:-9.48015 (0.01) | topTokens[('!', 6066), (',', 5890), ('Ġyou', 5023), ('.', 4373), ('Ġi', 4028), ('Ġd', 3677), ('Ġthe', 3624), ('Ġwe', 3454), ('Ġthey', 3294), ("'", 2341)] | cheekyAvg: 12.902563858032227 | perfectTokens: 31 / 6400 → 0.48% |  | remainingTokens: 196999 (98.50%) | TUTOR.py 100
--- 2025-04-23 04:12:55 --- 
[babyllm] right, last time i got to step 94520... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 94520! what am i learning today?
[charis]--- 2025-04-23 04:13:39 --- 
[babyllm] right, last time i got to step 94520... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 94520! what am i learning today?
[charis]2025-04-23 04:14:32 | 100 | LR0.00035 | loss:11.7779 | gradNorm:0.0000 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0003 | repetitionPenalty:1.8998 | AvgLoss:11.8530 | temperature:1.0000 | lR:0.0003 | gradientClip:1.0001 | latestLossDelta:1.0231 | memoryLength:10.0004 | embedNormMean:14.2970 | embedNormStd:10.0813 | embedNormMax:103.7208 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:16.3384 | logitWeightNormMean:91.9341 | logitWeightNormStd:2.5090 | logitWeightNormMax:104.5244 | logitWeightSparsity:0.0000 | logitWeightDrift:41.2408 | logitBiasMean:-34.1465 | logitBiasStd:11.9631 | logitBiasMax:-13.1871 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9534 | longDecay:0.9678 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7364 | n_weightMax:4.8462 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6052 | n_weightNormMin:21.5617 | n_weightNormMax:41.2384 | n_biasesMean:-1.0612 | n_biasesStd:0.7963 | n_biasesMin:-3.8437 | n_biasesMax:1.9586 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1088 | INN_cerebellumStd:4.2872 | windowWeightsW2:4.35827 (0.57), W4:1.01000 (0.35), W8:-1.66896 (0.02), W12:-1.75981 (0.01), W16:-3.02369 (0.01), W20:-4.15236 (0.01), W24:-5.22419 (0.01), W28:-8.03463 (0.01), W32:-9.47996 (0.01) | topTokens[(',', 384), ('!', 375), ('at', 305), ('Ġthe', 212), ('Ġelodie', 211), ('Ġof', 207), ('Ġweed', 204), ('Ġa', 160), ('Ġwanna', 157), ('Ġabout', 137)] | cheekyAvg: 11.623675739063936 | perfectTokens: 58 / 6400 → 0.91% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 04:15:04 | 200 | LR0.00035 | sampledTokens:3.0000 | scheduledSamplingRate:0.0006 | repetitionPenalty:1.8995 | AvgLoss:12.2231 | loss:11.8362 | temperature:1.0000 | lR:0.0003 | gradientClip:1.0003 | latestLossDelta:4.9525 | memoryLength:10.0004 | embedNormMean:14.2970 | embedNormStd:10.0813 | embedNormMax:103.7178 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0000 | embeddingDrift:0.0238 | logitWeightNormMean:91.9322 | logitWeightNormStd:2.5085 | logitWeightNormMax:104.5071 | logitWeightSparsity:0.0000 | logitWeightDrift:0.1045 | logitBiasMean:-34.1472 | logitBiasStd:11.9614 | logitBiasMax:-13.1833 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9534 | longDecay:0.9679 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7359 | n_weightMax:4.8470 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6063 | n_weightNormMin:21.5155 | n_weightNormMax:41.2542 | n_biasesMean:-1.0613 | n_biasesStd:0.7962 | n_biasesMin:-3.8376 | n_biasesMax:1.9550 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1077 | INN_cerebellumStd:4.2873 | windowWeightsW2:4.35817 (0.57), W4:1.00853 (0.35), W8:-1.66602 (0.02), W12:-1.75354 (0.02), W16:-3.02364 (0.01), W20:-4.15227 (0.01), W24:-5.22410 (0.01), W28:-8.03444 (0.01), W32:-9.47977 (0.01) | topTokens[(',', 712), ('!', 498), ('.', 462), ('Ġmust', 456), ('Ġthe', 449), ('Ġweed', 374), ('at', 309), ('Ġit', 305), ('Ġup', 254), ('Ġelodie', 211)] | cheekyAvg: 12.210090980529785 | perfectTokens: 97 / 6400 → 1.52% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
2025-04-23 04:15:36 | 300 | LR0.00035 | sampledTokens:1.0000 | scheduledSamplingRate:0.0010 | repetitionPenalty:1.8992 | AvgLoss:12.2142 | loss:11.2795 | temperature:1.0000 | lR:0.0003 | gradientClip:1.0003 | latestLossDelta:-0.4813 | memoryLength:10.0004 | embedNormMean:14.2969 | embedNormStd:10.0812 | embedNormMax:103.7134 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0001 | embeddingDrift:0.0299 | logitWeightNormMean:91.9303 | logitWeightNormStd:2.5084 | logitWeightNormMax:104.5046 | logitWeightSparsity:0.0000 | logitWeightDrift:0.1437 | logitBiasMean:-34.1472 | logitBiasStd:11.9606 | logitBiasMax:-13.1805 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9534 | longDecay:0.9679 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7327 | n_weightMax:4.8477 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6070 | n_weightNormMin:21.4968 | n_weightNormMax:41.2574 | n_biasesMean:-1.0613 | n_biasesStd:0.7961 | n_biasesMin:-3.8323 | n_biasesMax:1.9547 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1079 | INN_cerebellumStd:4.2868 | windowWeightsW2:4.35808 (0.57), W4:1.00147 (0.35), W8:-1.66766 (0.02), W12:-1.75330 (0.02), W16:-3.02360 (0.01), W20:-4.15217 (0.01), W24:-5.22400 (0.01), W28:-8.03424 (0.01), W32:-9.47958 (0.01) | topTokens[('Ġmust', 879), (',', 867), ('Ġyou', 579), ('!', 566), ('.', 519), ('Ġthe', 449), ('Ġweed', 426), ('Ġit', 327), ('at', 309), ('Ġof', 285)] | cheekyAvg: 12.23877471923828 | perfectTokens: 99 / 6400 → 1.55% |  | remainingTokens: 199699 (99.85%) | TUTOR.py 100
2025-04-23 04:16:09 | 400 | LR0.00035 | sampledTokens:8.0000 | scheduledSamplingRate:0.0013 | repetitionPenalty:1.8987 | AvgLoss:12.5308 | loss:8.4805 | temperature:1.0000 | lR:0.0003 | gradientClip:1.0003 | latestLossDelta:-4.0577 | memoryLength:10.0002 | embedNormMean:14.2968 | embedNormStd:10.0811 | embedNormMax:103.7026 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0011 | embeddingDrift:0.0286 | logitWeightNormMean:91.9282 | logitWeightNormStd:2.5080 | logitWeightNormMax:104.4679 | logitWeightSparsity:0.0000 | logitWeightDrift:0.1215 | logitBiasMean:-34.1470 | logitBiasStd:11.9601 | logitBiasMax:-13.1785 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9534 | longDecay:0.9679 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8976 | n_weightMin:-4.7323 | n_weightMax:4.8507 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6077 | n_weightNormMin:21.4808 | n_weightNormMax:41.2671 | n_biasesMean:-1.0614 | n_biasesStd:0.7961 | n_biasesMin:-3.8305 | n_biasesMax:1.9525 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1079 | INN_cerebellumStd:4.2863 | windowWeightsW2:4.35798 (0.57), W4:0.99851 (0.35), W8:-1.66399 (0.02), W12:-1.74753 (0.02), W16:-3.02355 (0.01), W20:-4.15208 (0.01), W24:-5.22390 (0.01), W28:-8.03405 (0.01), W32:-9.47939 (0.01) | topTokens[('Ġmust', 1701), (',', 1052), ('!', 799), ('.', 636), ('Ġyou', 585), ('s', 459), ('Ġthe', 449), ('Ġweed', 426), ('at', 374), ('Ġit', 329)] | cheekyAvg: 12.360907936096192 | perfectTokens: 162 / 6400 → 2.53% |  | remainingTokens: 199599 (99.80%) | TUTOR.py 100
2025-04-23 04:16:42 | 500 | LR0.00035 | sampledTokens:1.0000 | scheduledSamplingRate:0.0016 | repetitionPenalty:1.8984 | AvgLoss:11.0902 | loss:11.4907 | temperature:1.0000 | lR:0.0003 | gradientClip:1.0003 | latestLossDelta:5.0131 | memoryLength:10.0002 | embedNormMean:14.2967 | embedNormStd:10.0810 | embedNormMax:103.6937 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0011 | embeddingDrift:0.0326 | logitWeightNormMean:91.9263 | logitWeightNormStd:2.5076 | logitWeightNormMax:104.4238 | logitWeightSparsity:0.0000 | logitWeightDrift:0.1500 | logitBiasMean:-34.1468 | logitBiasStd:11.9594 | logitBiasMax:-13.1731 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9535 | longDecay:0.9678 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8977 | n_weightMin:-4.7308 | n_weightMax:4.8518 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6084 | n_weightNormMin:21.4661 | n_weightNormMax:41.2459 | n_biasesMean:-1.0615 | n_biasesStd:0.7961 | n_biasesMin:-3.8279 | n_biasesMax:1.9514 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1065 | INN_cerebellumStd:4.2865 | windowWeightsW2:4.35788 (0.57), W4:0.99434 (0.34), W8:-1.65589 (0.02), W12:-1.73791 (0.02), W16:-3.02350 (0.01), W20:-4.15198 (0.01), W24:-5.22381 (0.01), W28:-8.03386 (0.01), W32:-9.47919 (0.01) | topTokens[('Ġmust', 2272), (',', 1294), ('!', 1016), ('.', 834), ('Ġcharis', 821), ('Ġthe', 598), ('Ġyou', 585), ('s', 459), ('Ġweed', 426), ('at', 374)] | cheekyAvg: 11.066992740631104 | perfectTokens: 156 / 6400 → 2.44% |  | remainingTokens: 199499 (99.75%) | TUTOR.py 100
--- 2025-04-23 04:17:03 --- 
[babyllm] right, last time i got to step 95054... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 95054! what am i learning today?
[charis]2025-04-23 04:17:55 | 100 | LR-9.21034049987793 | loss:11.3365 | gradNorm:0.0000 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0004 | repetitionPenalty:1.8996 | AvgLoss:11.4968 | temperature:1.0000 | lR:-9.2103 | gradientClip:1.0000 | latestLossDelta:0.5125 | memoryLength:10.0008 | embedNormMean:14.2967 | embedNormStd:10.0809 | embedNormMax:103.6907 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0028 | embeddingDrift:16.3264 | logitWeightNormMean:91.9238 | logitWeightNormStd:2.5070 | logitWeightNormMax:104.4080 | logitWeightSparsity:0.0000 | logitWeightDrift:41.2219 | logitBiasMean:-34.1469 | logitBiasStd:11.9581 | logitBiasMax:-13.1689 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9534 | longDecay:0.9679 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8977 | n_weightMin:-4.7259 | n_weightMax:4.8590 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6096 | n_weightNormMin:21.4629 | n_weightNormMax:41.2082 | n_biasesMean:-1.0616 | n_biasesStd:0.7960 | n_biasesMin:-3.8283 | n_biasesMax:1.9439 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1061 | INN_cerebellumStd:4.2859 | sampledTokens:2.0000 | windowWeightsW2:4.35776 (0.57), W4:0.98698 (0.34), W8:-1.65570 (0.02), W12:-1.73455 (0.02), W16:-3.02344 (0.01), W20:-4.15185 (0.01), W24:-5.22368 (0.01), W28:-8.03361 (0.01), W32:-9.47894 (0.01) | topTokens[('Ġmust', 1223), ('Ġlook', 224), ('Ġbe', 185), ('.', 184), ('!', 176), ('Ġkevin', 130), ('Ġyour', 110), ('Ġthe', 110), ('Ġmy', 100), ('Ġour', 64)] | cheekyAvg: 11.121696509566961 | perfectTokens: 198 / 6400 → 3.09% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
--- 2025-04-23 04:20:24 --- 
[babyllm] right, last time i got to step 95177... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 95177! what am i learning today?
[charis]2025-04-23 04:21:16 | 100 | LR9.999998720982612e-05 | loss:9.6470 | gradNorm:0.0000 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0002 | repetitionPenalty:1.8997 | AvgLoss:11.5591 | temperature:1.0000 | lR:0.0001 | gradientClip:1.0000 | latestLossDelta:-0.3310 | memoryLength:10.0000 | embedNormMean:14.2964 | embedNormStd:10.0807 | embedNormMax:103.6788 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0029 | embeddingDrift:16.3264 | logitWeightNormMean:91.9217 | logitWeightNormStd:2.5063 | logitWeightNormMax:104.3896 | logitWeightSparsity:0.0000 | logitWeightDrift:41.2031 | logitBiasMean:-34.1473 | logitBiasStd:11.9565 | logitBiasMax:-13.1602 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9535 | longDecay:0.9678 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8977 | n_weightMin:-4.7236 | n_weightMax:4.8622 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6097 | n_weightNormMin:21.4476 | n_weightNormMax:41.1640 | n_biasesMean:-1.0616 | n_biasesStd:0.7958 | n_biasesMin:-3.8287 | n_biasesMax:1.9351 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1059 | INN_cerebellumStd:4.2854 | windowWeightsW2:4.35764 (0.57), W4:0.98348 (0.34), W8:-1.65296 (0.02), W12:-1.72957 (0.02), W16:-3.02338 (0.01), W20:-4.15174 (0.01), W24:-5.22357 (0.01), W28:-8.03337 (0.01), W32:-9.47871 (0.01) | topTokens[('Ġmust', 864), ('Ġwe', 420), ('Ġbe', 262), ('!', 259), ('Ġshe', 136), ('Ġand', 131), ('Ġelodie', 129), ('Ġcharis', 126), ('Ġlook', 123), ('Ġto', 105)] | cheekyAvg: 11.169899080313888 | perfectTokens: 149 / 6400 → 2.33% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 04:21:49 | 200 | LR9.999998720982612e-05 | sampledTokens:1.0000 | scheduledSamplingRate:0.0006 | repetitionPenalty:1.8994 | AvgLoss:10.5477 | loss:8.5565 | temperature:1.0000 | lR:0.0001 | gradientClip:0.9999 | latestLossDelta:-2.4423 | memoryLength:10.0014 | embedNormMean:14.2963 | embedNormStd:10.0807 | embedNormMax:103.6744 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0029 | embeddingDrift:0.0242 | logitWeightNormMean:91.9198 | logitWeightNormStd:2.5060 | logitWeightNormMax:104.3717 | logitWeightSparsity:0.0000 | logitWeightDrift:0.1131 | logitBiasMean:-34.1472 | logitBiasStd:11.9557 | logitBiasMax:-13.1589 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9535 | longDecay:0.9678 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8977 | n_weightMin:-4.7227 | n_weightMax:4.8659 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6102 | n_weightNormMin:21.4678 | n_weightNormMax:41.1371 | n_biasesMean:-1.0617 | n_biasesStd:0.7956 | n_biasesMin:-3.8263 | n_biasesMax:1.9274 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1059 | INN_cerebellumStd:4.2849 | windowWeightsW2:4.35754 (0.57), W4:0.97647 (0.34), W8:-1.65299 (0.02), W12:-1.72831 (0.02), W16:-3.02333 (0.01), W20:-4.15164 (0.01), W24:-5.22347 (0.01), W28:-8.03318 (0.01), W32:-9.47852 (0.01) | topTokens[('Ġmust', 1733), ('Ġwe', 420), ('Ġcharis', 387), ('Ġto', 383), ('Ġi', 272), ("'s", 264), ('Ġbe', 262), ('!', 259), ('.', 209), ('Ġit', 206)] | cheekyAvg: 10.501589431762696 | perfectTokens: 177 / 6400 → 2.77% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
2025-04-23 04:22:21 | 300 | LR9.999998720982612e-05 | sampledTokens:1.0000 | scheduledSamplingRate:0.0010 | repetitionPenalty:1.8993 | AvgLoss:11.3013 | loss:11.3565 | temperature:1.0000 | lR:0.0001 | gradientClip:0.9999 | latestLossDelta:-0.1860 | memoryLength:10.0006 | embedNormMean:14.2963 | embedNormStd:10.0806 | embedNormMax:103.6707 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0028 | embeddingDrift:0.0253 | logitWeightNormMean:91.9180 | logitWeightNormStd:2.5058 | logitWeightNormMax:104.3621 | logitWeightSparsity:0.0000 | logitWeightDrift:0.1017 | logitBiasMean:-34.1469 | logitBiasStd:11.9551 | logitBiasMax:-13.1566 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9535 | longDecay:0.9678 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8977 | n_weightMin:-4.7213 | n_weightMax:4.8663 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6106 | n_weightNormMin:21.4600 | n_weightNormMax:41.1357 | n_biasesMean:-1.0617 | n_biasesStd:0.7955 | n_biasesMin:-3.8240 | n_biasesMax:1.9228 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1061 | INN_cerebellumStd:4.2844 | windowWeightsW2:4.35745 (0.57), W4:0.97507 (0.34), W8:-1.65113 (0.02), W12:-1.72600 (0.02), W16:-3.02328 (0.01), W20:-4.15155 (0.01), W24:-5.22337 (0.01), W28:-8.03299 (0.01), W32:-9.47832 (0.01) | topTokens[('Ġmust', 3099), ('!', 499), ('Ġcharis', 482), ('Ġwe', 420), ('Ġto', 390), ('Ġneed', 389), ('Ġbe', 309), ('Ġi', 282), ("'s", 264), ('Ġit', 249)] | cheekyAvg: 11.235687828063964 | perfectTokens: 249 / 6400 → 3.89% |  | remainingTokens: 199699 (99.85%) | TUTOR.py 100
--- 2025-04-23 04:22:54 --- 
[babyllm] right, last time i got to step 95552... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 95552! what am i learning today?
[charis]2025-04-23 04:23:47 | 100 | LR0.0001 | loss:10.5174 | gradNorm:0.0000 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.0003 | repetitionPenalty:1.8996 | AvgLoss:10.8401 | temperature:1.0000 | lR:0.0001 | gradientClip:1.0000 | latestLossDelta:-0.2981 | memoryLength:10.0008 | embedNormMean:14.2961 | embedNormStd:10.0806 | embedNormMax:103.6664 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0016 | embeddingDrift:16.3198 | logitWeightNormMean:91.9151 | logitWeightNormStd:2.5056 | logitWeightNormMax:104.3585 | logitWeightSparsity:0.0000 | logitWeightDrift:41.2098 | logitBiasMean:-34.1465 | logitBiasStd:11.9539 | logitBiasMax:-13.1545 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9535 | longDecay:0.9678 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8978 | n_weightMin:-4.7197 | n_weightMax:4.8638 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6110 | n_weightNormMin:21.4207 | n_weightNormMax:41.0873 | n_biasesMean:-1.0618 | n_biasesStd:0.7953 | n_biasesMin:-3.8235 | n_biasesMax:1.9232 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1058 | INN_cerebellumStd:4.2839 | windowWeightsW2:4.35728 (0.57), W4:0.96710 (0.34), W8:-1.64742 (0.02), W12:-1.71987 (0.02), W16:-3.02320 (0.01), W20:-4.15138 (0.01), W24:-5.22321 (0.01), W28:-8.03266 (0.01), W32:-9.47799 (0.01) | topTokens[('Ġmust', 827), ('!', 402), ('Ġyou', 281), ('Ġhis', 217), ('Ġcharis', 182), (',', 159), ('Ġelodie', 158), ('Ġthe', 157), ('Ġkevin', 132), ('Ġat', 105)] | cheekyAvg: 10.572130390242034 | perfectTokens: 200 / 6400 → 3.12% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 04:24:19 | 200 | LR0.0001 | sampledTokens:1.0000 | scheduledSamplingRate:0.0006 | repetitionPenalty:1.8993 | AvgLoss:10.5656 | loss:10.4668 | temperature:1.0000 | lR:0.0001 | gradientClip:1.0000 | latestLossDelta:-0.1653 | memoryLength:10.0008 | embedNormMean:14.2961 | embedNormStd:10.0807 | embedNormMax:103.6643 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0238 | logitWeightNormMean:91.9134 | logitWeightNormStd:2.5055 | logitWeightNormMax:104.3565 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0990 | logitBiasMean:-34.1463 | logitBiasStd:11.9533 | logitBiasMax:-13.1528 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9534 | longDecay:0.9678 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8978 | n_weightMin:-4.7193 | n_weightMax:4.8682 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6119 | n_weightNormMin:21.3896 | n_weightNormMax:41.0840 | n_biasesMean:-1.0619 | n_biasesStd:0.7953 | n_biasesMin:-3.8239 | n_biasesMax:1.9211 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1052 | INN_cerebellumStd:4.2837 | windowWeightsW2:4.35719 (0.57), W4:0.96651 (0.34), W8:-1.64395 (0.02), W12:-1.71428 (0.02), W16:-3.02315 (0.01), W20:-4.15128 (0.01), W24:-5.22311 (0.01), W28:-8.03247 (0.01), W32:-9.47780 (0.01) | topTokens[('Ġmust', 2016), ('!', 497), (',', 468), ('Ġhis', 428), ('Ġcharis', 407), ('Ġyou', 291), ('Ġthe', 272), ('Ġmy', 192), ('Ġkevin', 187), ('Ġelodie', 158)] | cheekyAvg: 10.528044996261597 | perfectTokens: 227 / 6400 → 3.55% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
2025-04-23 04:24:52 | 300 | LR0.0001 | sampledTokens:0.0000 | scheduledSamplingRate:0.0009 | repetitionPenalty:1.8991 | AvgLoss:10.0210 | loss:9.2096 | temperature:1.0000 | lR:0.0001 | gradientClip:0.9999 | latestLossDelta:-1.3433 | memoryLength:9.9992 | embedNormMean:14.2960 | embedNormStd:10.0807 | embedNormMax:103.6599 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.0010 | embeddingDrift:0.0220 | logitWeightNormMean:91.9117 | logitWeightNormStd:2.5053 | logitWeightNormMax:104.3199 | logitWeightSparsity:0.0000 | logitWeightDrift:0.0879 | logitBiasMean:-34.1460 | logitBiasStd:11.9528 | logitBiasMax:-13.1488 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.9534 | longDecay:0.9678 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.0075 | n_weightStd:0.8978 | n_weightMin:-4.7181 | n_weightMax:4.8704 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.6120 | n_weightNormMin:21.3759 | n_weightNormMax:41.1214 | n_biasesMean:-1.0620 | n_biasesStd:0.7952 | n_biasesMin:-3.8262 | n_biasesMax:1.9216 | n_sparsity:0.0000 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.1047 | INN_cerebellumStd:4.2837 | windowWeightsW2:4.35709 (0.57), W4:0.96473 (0.34), W8:-1.64264 (0.02), W12:-1.71266 (0.02), W16:-3.02311 (0.01), W20:-4.15119 (0.01), W24:-5.22302 (0.01), W28:-8.03228 (0.01), W32:-9.47761 (0.01) | topTokens[('Ġmust', 3211), (',', 685), ('Ġhis', 669), ('!', 605), ('Ġcharis', 457), ('Ġkevin', 379), ('Ġyou', 316), ('Ġthe', 272), ('Ġmy', 271), ('Ġhe', 193)] | cheekyAvg: 9.784588384628297 | perfectTokens: 198 / 6400 → 3.09% |  | remainingTokens: 199699 (99.85%) | TUTOR.py 100
--- 2025-04-23 04:25:18 --- 
[babyllm] right, last time i got to step 95906... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 95906! what am i learning today?
[charis]2025-04-23 04:26:10 | 100 | LR0.0001 | loss:11.655251 | gradNorm:0.000000 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.000240 | repetitionPenalty:1.899740 | AvgLoss:11.151062 | temperature:1.000000 | lR:0.000100 | gradientClip:0.999940 | latestLossDelta:0.704261 | memoryLength:9.999600 | embedNormMean:14.295904 | embedNormStd:10.080663 | embedNormMax:103.654831 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000977 | embeddingDrift:16.324497 | logitWeightNormMean:91.908875 | logitWeightNormStd:2.505103 | logitWeightNormMax:104.292793 | logitWeightSparsity:0.000010 | logitWeightDrift:41.219913 | logitBiasMean:-34.145817 | logitBiasStd:11.951596 | logitBiasMax:-13.149745 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953455 | longDecay:0.967807 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007535 | n_weightStd:0.897823 | n_weightMin:-4.715409 | n_weightMax:4.872305 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.613028 | n_weightNormMin:21.297056 | n_weightNormMax:41.105312 | n_biasesMean:-1.062108 | n_biasesStd:0.795183 | n_biasesMin:-3.827078 | n_biasesMax:1.919422 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.102587 | INN_cerebellumStd:4.284019 | sampledTokens:1.000000 | windowWeightsW2:4.35695 (0.57), W4:0.96063 (0.34), W8:-1.62814 (0.02), W12:-1.69732 (0.02), W16:-3.02303 (0.01), W20:-4.15104 (0.01), W24:-5.22287 (0.01), W28:-8.03199 (0.01), W32:-9.47732 (0.01) | topTokens[(',', 578), ('Ġthey', 203), ('Ġlook', 196), ('Ġmust', 162), ('Ġthe', 139), ('Ġshe', 137), ('Ġt', 117), ('Ġa', 107), ('Ġyou', 102), ('Ġelodie', 99)] | cheekyAvg: 10.791479765200148 | perfectTokens: 81 / 6400 → 1.27% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 04:26:43 | 200 | LR0.0001 | sampledTokens:1.000000 | scheduledSamplingRate:0.000460 | repetitionPenalty:1.899360 | AvgLoss:11.218979 | loss:10.178046 | temperature:1.000000 | lR:0.000100 | gradientClip:0.999940 | latestLossDelta:4.394028 | memoryLength:9.998200 | embedNormMean:14.296061 | embedNormStd:10.080808 | embedNormMax:103.647186 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000908 | embeddingDrift:0.025994 | logitWeightNormMean:91.906937 | logitWeightNormStd:2.504983 | logitWeightNormMax:104.273415 | logitWeightSparsity:0.000009 | logitWeightDrift:0.120399 | logitBiasMean:-34.145863 | logitBiasStd:11.950488 | logitBiasMax:-13.147701 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953449 | longDecay:0.967809 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007537 | n_weightStd:0.897877 | n_weightMin:-4.715466 | n_weightMax:4.874709 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.614668 | n_weightNormMin:21.237720 | n_weightNormMax:41.099403 | n_biasesMean:-1.062278 | n_biasesStd:0.795118 | n_biasesMin:-3.829097 | n_biasesMax:1.911229 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.100194 | INN_cerebellumStd:4.284764 | windowWeightsW2:4.35685 (0.57), W4:0.96122 (0.34), W8:-1.61793 (0.02), W12:-1.68579 (0.02), W16:-3.02298 (0.01), W20:-4.15095 (0.01), W24:-5.22278 (0.01), W28:-8.03180 (0.01), W32:-9.47713 (0.01) | topTokens[(',', 1166), ('.', 254), ('Ġlook', 241), ('Ġthe', 236), ('Ġthey', 203), ('Ġmust', 197), ('!', 194), ('Ġshe', 190), ('Ġkevin', 179), ('Ġwe', 158)] | cheekyAvg: 11.104019794464111 | perfectTokens: 93 / 6400 → 1.45% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
2025-04-23 04:27:15 | 300 | LR0.0001 | sampledTokens:2.000000 | scheduledSamplingRate:0.000760 | repetitionPenalty:1.899160 | AvgLoss:11.498340 | loss:10.322510 | temperature:1.000000 | lR:0.000100 | gradientClip:0.999940 | latestLossDelta:-1.218773 | memoryLength:9.997200 | embedNormMean:14.296183 | embedNormStd:10.080987 | embedNormMax:103.643181 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.028657 | logitWeightNormMean:91.904877 | logitWeightNormStd:2.504493 | logitWeightNormMax:104.231331 | logitWeightSparsity:0.000009 | logitWeightDrift:0.114086 | logitBiasMean:-34.145985 | logitBiasStd:11.949449 | logitBiasMax:-13.142792 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953394 | longDecay:0.967844 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007542 | n_weightStd:0.897920 | n_weightMin:-4.716186 | n_weightMax:4.875278 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.615986 | n_weightNormMin:21.193865 | n_weightNormMax:41.093895 | n_biasesMean:-1.062422 | n_biasesStd:0.795035 | n_biasesMin:-3.833104 | n_biasesMax:1.907836 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.099293 | INN_cerebellumStd:4.284602 | windowWeightsW2:4.35676 (0.57), W4:0.95091 (0.34), W8:-1.61868 (0.02), W12:-1.68443 (0.02), W16:-3.02294 (0.01), W20:-4.15085 (0.01), W24:-5.22268 (0.01), W28:-8.03160 (0.01), W32:-9.47694 (0.01) | topTokens[(',', 1289), ('Ġthe', 555), ('.', 396), ('Ġwas', 386), ('Ġlook', 350), ('!', 330), ('Ġshe', 285), ('Ġmust', 284), ('Ġkevin', 283), ('Ġelodie', 268)] | cheekyAvg: 11.38161714553833 | perfectTokens: 64 / 6400 → 1.00% |  | remainingTokens: 199699 (99.85%) | TUTOR.py 100
--- 2025-04-23 04:27:41 --- 
[babyllm] right, last time i got to step 96261... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 96261! what am i learning today?
[charis]2025-04-23 04:28:34 | 100 | LR0.000100 | loss:8.584523 | gradNorm:0.000000 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.000100 | repetitionPenalty:1.899480 | AvgLoss:10.512102 | temperature:1.000000 | lR:0.000100 | gradientClip:0.999840 | latestLossDelta:0.396632 | memoryLength:10.001200 | embedNormMean:14.296584 | embedNormStd:10.081555 | embedNormMax:103.637268 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:16.335857 | logitWeightNormMean:91.902298 | logitWeightNormStd:2.504260 | logitWeightNormMax:104.227638 | logitWeightSparsity:0.000009 | logitWeightDrift:41.213070 | logitBiasMean:-34.146069 | logitBiasStd:11.947859 | logitBiasMax:-13.135739 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953428 | longDecay:0.967822 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007557 | n_weightStd:0.898056 | n_weightMin:-4.717618 | n_weightMax:4.873796 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.620111 | n_weightNormMin:21.172792 | n_weightNormMax:41.060459 | n_biasesMean:-1.062808 | n_biasesStd:0.794912 | n_biasesMin:-3.825416 | n_biasesMax:1.906663 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.100951 | INN_cerebellumStd:4.282803 | windowWeightsW2:4.35661 (0.57), W4:0.93970 (0.34), W8:-1.62007 (0.02), W12:-1.68226 (0.02), W16:-3.02286 (0.01), W20:-4.15070 (0.01), W24:-5.22253 (0.01), W28:-8.03131 (0.01), W32:-9.47664 (0.01) | topTokens[('Ġwas', 370), ('!', 324), ('Ġto', 258), ('Ġtouch', 169), ('Ġshe', 163), ('Ġbutt', 161), ('ing', 148), ('Ġhear', 133), ('Ġneed', 111), ('Ġkevin', 89)] | cheekyAvg: 10.13449067695468 | perfectTokens: 79 / 6400 → 1.23% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 04:29:07 | 200 | LR0.000100 | sampledTokens:2.000000 | scheduledSamplingRate:0.000520 | repetitionPenalty:1.899040 | AvgLoss:11.000899 | loss:10.457263 | temperature:1.000000 | lR:0.000100 | gradientClip:0.999720 | latestLossDelta:3.099260 | memoryLength:10.000800 | embedNormMean:14.296630 | embedNormStd:10.081773 | embedNormMax:103.625267 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.027426 | logitWeightNormMean:91.900658 | logitWeightNormStd:2.504186 | logitWeightNormMax:104.224792 | logitWeightSparsity:0.000009 | logitWeightDrift:0.128444 | logitBiasMean:-34.146542 | logitBiasStd:11.946167 | logitBiasMax:-13.132651 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953475 | longDecay:0.967793 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007566 | n_weightStd:0.898121 | n_weightMin:-4.714756 | n_weightMax:4.873711 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.622255 | n_weightNormMin:21.174257 | n_weightNormMax:41.069893 | n_biasesMean:-1.063033 | n_biasesStd:0.794651 | n_biasesMin:-3.825409 | n_biasesMax:1.902367 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.100744 | INN_cerebellumStd:4.282365 | windowWeightsW2:4.35651 (0.57), W4:0.93348 (0.34), W8:-1.61991 (0.02), W12:-1.67719 (0.02), W16:-3.02282 (0.01), W20:-4.15061 (0.01), W24:-5.22244 (0.01), W28:-8.03112 (0.01), W32:-9.47645 (0.01) | topTokens[('Ġwas', 900), ('Ġand', 351), ('!', 324), ('ing', 307), ('Ġwe', 280), ('Ġto', 258), ('Ġbutt', 213), ('.', 204), ('Ġthe', 203), ('Ġbe', 181)] | cheekyAvg: 10.878217372894287 | perfectTokens: 103 / 6400 → 1.61% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
--- 2025-04-23 04:30:20 --- 
[babyllm] right, last time i got to step 96508... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 96508! what am i learning today?
[charis]2025-04-23 04:31:14 | 100 | LR0.000100 | loss:10.207659 | gradNorm:0.000000 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.000400 | repetitionPenalty:1.899680 | AvgLoss:10.007754 | temperature:1.000000 | lR:0.000100 | gradientClip:0.999880 | latestLossDelta:0.258761 | memoryLength:10.000400 | embedNormMean:14.296762 | embedNormStd:10.082161 | embedNormMax:103.611191 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:16.314606 | logitWeightNormMean:91.898201 | logitWeightNormStd:2.503932 | logitWeightNormMax:104.221809 | logitWeightSparsity:0.000009 | logitWeightDrift:41.203171 | logitBiasMean:-34.146709 | logitBiasStd:11.944616 | logitBiasMax:-13.123696 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953452 | longDecay:0.967809 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007586 | n_weightStd:0.898230 | n_weightMin:-4.717995 | n_weightMax:4.872239 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.625744 | n_weightNormMin:21.177744 | n_weightNormMax:41.076641 | n_biasesMean:-1.063423 | n_biasesStd:0.794322 | n_biasesMin:-3.827491 | n_biasesMax:1.899282 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.101600 | INN_cerebellumStd:4.281148 | windowWeightsW2:4.35637 (0.58), W4:0.92703 (0.34), W8:-1.61721 (0.02), W12:-1.67251 (0.02), W16:-3.02275 (0.01), W20:-4.15047 (0.01), W24:-5.22230 (0.01), W28:-8.03084 (0.01), W32:-9.47617 (0.01) | topTokens[('!', 448), ('Ġcharis', 350), ('Ġto', 199), ('Ġweed', 168), ('ing', 160), ('Ġbutt', 155), ('Ġthe', 152), ('Ġkevin', 128), ('Ġdra', 123), ('Ġtaking', 121)] | cheekyAvg: 9.569223254334693 | perfectTokens: 80 / 6400 → 1.25% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 04:31:48 | 200 | LR0.000100 | sampledTokens:4.000000 | scheduledSamplingRate:0.000800 | repetitionPenalty:1.899320 | AvgLoss:10.640522 | loss:12.789740 | temperature:1.000000 | lR:0.000100 | gradientClip:0.999880 | latestLossDelta:2.951341 | memoryLength:10.000200 | embedNormMean:14.296875 | embedNormStd:10.082184 | embedNormMax:103.607605 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.025865 | logitWeightNormMean:91.896454 | logitWeightNormStd:2.503776 | logitWeightNormMax:104.219765 | logitWeightSparsity:0.000009 | logitWeightDrift:0.116046 | logitBiasMean:-34.146763 | logitBiasStd:11.943666 | logitBiasMax:-13.124584 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953480 | longDecay:0.967791 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007603 | n_weightStd:0.898298 | n_weightMin:-4.707804 | n_weightMax:4.874286 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.627752 | n_weightNormMin:21.143875 | n_weightNormMax:41.090790 | n_biasesMean:-1.063681 | n_biasesStd:0.794266 | n_biasesMin:-3.829084 | n_biasesMax:1.896903 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.101014 | INN_cerebellumStd:4.281105 | windowWeightsW2:4.35628 (0.58), W4:0.92556 (0.34), W8:-1.61579 (0.02), W12:-1.66932 (0.02), W16:-3.02270 (0.01), W20:-4.15037 (0.01), W24:-5.22220 (0.01), W28:-8.03065 (0.01), W32:-9.47598 (0.01) | topTokens[('Ġcharis', 742), ('!', 672), ('Ġkevin', 438), ('Ġthe', 359), ('Ġhe', 334), ('Ġwas', 314), ('Ġtouch', 287), ('Ġto', 271), ('ing', 262), ('Ġthey', 229)] | cheekyAvg: 10.613082780838013 | perfectTokens: 95 / 6400 → 1.48% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
2025-04-23 04:32:22 | 300 | LR0.000100 | sampledTokens:3.000000 | scheduledSamplingRate:0.001200 | repetitionPenalty:1.899140 | AvgLoss:10.683151 | loss:10.340222 | temperature:1.000000 | lR:0.000100 | gradientClip:0.999820 | latestLossDelta:-0.179117 | memoryLength:10.000400 | embedNormMean:14.296957 | embedNormStd:10.082221 | embedNormMax:103.599899 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.020658 | logitWeightNormMean:91.894745 | logitWeightNormStd:2.503426 | logitWeightNormMax:104.176727 | logitWeightSparsity:0.000009 | logitWeightDrift:0.095007 | logitBiasMean:-34.146446 | logitBiasStd:11.943110 | logitBiasMax:-13.124020 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953482 | longDecay:0.967782 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007611 | n_weightStd:0.898342 | n_weightMin:-4.700857 | n_weightMax:4.877191 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.629168 | n_weightNormMin:21.125530 | n_weightNormMax:41.088593 | n_biasesMean:-1.063824 | n_biasesStd:0.794212 | n_biasesMin:-3.835220 | n_biasesMax:1.902068 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.100054 | INN_cerebellumStd:4.281252 | windowWeightsW2:4.35618 (0.58), W4:0.92423 (0.34), W8:-1.61006 (0.02), W12:-1.66375 (0.02), W16:-3.02265 (0.01), W20:-4.15028 (0.01), W24:-5.22211 (0.01), W28:-8.03046 (0.01), W32:-9.47579 (0.01) | topTokens[('Ġcharis', 954), ('!', 714), (',', 679), ('Ġwas', 628), ('Ġthe', 603), ('Ġkevin', 438), ('Ġhe', 422), ('Ġwere', 407), ('Ġelodie', 370), ('Ġtouch', 333)] | cheekyAvg: 10.586711025238037 | perfectTokens: 107 / 6400 → 1.67% |  | remainingTokens: 199699 (99.85%) | TUTOR.py 100
--- 2025-04-23 04:32:31 --- 
[babyllm] right, last time i got to step 96811... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 96811! what am i learning today?
[charis]--- 2025-04-23 04:33:32 --- 
[babyllm] right, last time i got to step 96811... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 96811! what am i learning today?
[charis]--- 2025-04-23 04:35:11 --- 
[babyllm] right, last time i got to step 96824... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 96824! what am i learning today?
[charis]2025-04-23 04:36:09 | 100 | LR0.000100 | loss:10.204615 | gradNorm:0.000000 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.000440 | repetitionPenalty:1.899720 | AvgLoss:9.271514 | temperature:1.000044 | lR:0.000100 | gradientClip:0.999980 | latestLossDelta:0.557989 | memoryLength:9.999800 | embedNormMean:14.297090 | embedNormStd:10.082491 | embedNormMax:103.596634 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:16.345623 | logitWeightNormMean:91.893005 | logitWeightNormStd:2.503166 | logitWeightNormMax:104.162773 | logitWeightSparsity:0.000009 | logitWeightDrift:41.200016 | logitBiasMean:-34.146412 | logitBiasStd:11.941985 | logitBiasMax:-13.118034 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953452 | longDecay:0.967799 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007616 | n_weightStd:0.898430 | n_weightMin:-4.703675 | n_weightMax:4.877507 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.632122 | n_weightNormMin:21.125235 | n_weightNormMax:41.141094 | n_biasesMean:-1.064129 | n_biasesStd:0.793994 | n_biasesMin:-3.835964 | n_biasesMax:1.899899 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.099423 | INN_cerebellumStd:4.281088 | sampledTokens:1.000000 | windowWeightsW2:4.35607 (0.58), W4:0.92012 (0.34), W8:-1.60607 (0.02), W12:-1.65844 (0.02), W16:-3.02260 (0.01), W20:-4.15017 (0.01), W24:-5.22200 (0.01), W28:-8.03024 (0.01), W32:-9.47557 (0.01) | topTokens[('Ġwere', 647), ('Ġwas', 457), ('Ġthe', 259), ('.', 254), (',', 219), ('ing', 210), ('Ġbrain', 156), ('Ġelodie', 104), ('Ġshe', 90), ('Ġweed', 89)] | cheekyAvg: 8.9968256482891 | perfectTokens: 143 / 6400 → 2.23% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 04:36:44 | 200 | LR0.000100 | sampledTokens:1.000000 | scheduledSamplingRate:0.000760 | repetitionPenalty:1.899340 | AvgLoss:10.237132 | loss:11.500890 | temperature:1.000745 | lR:0.000100 | gradientClip:0.999980 | latestLossDelta:1.133829 | memoryLength:9.999400 | embedNormMean:14.297340 | embedNormStd:10.082957 | embedNormMax:103.594345 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.028108 | logitWeightNormMean:91.891388 | logitWeightNormStd:2.502841 | logitWeightNormMax:104.139252 | logitWeightSparsity:0.000009 | logitWeightDrift:0.112238 | logitBiasMean:-34.146320 | logitBiasStd:11.941010 | logitBiasMax:-13.115687 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953471 | longDecay:0.967790 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007622 | n_weightStd:0.898516 | n_weightMin:-4.705297 | n_weightMax:4.877652 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.634817 | n_weightNormMin:21.129169 | n_weightNormMax:41.168419 | n_biasesMean:-1.064439 | n_biasesStd:0.793859 | n_biasesMin:-3.831915 | n_biasesMax:1.898091 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.098728 | INN_cerebellumStd:4.280957 | windowWeightsW2:4.35598 (0.58), W4:0.91273 (0.33), W8:-1.60225 (0.02), W12:-1.65453 (0.02), W16:-3.02255 (0.01), W20:-4.15007 (0.01), W24:-5.22190 (0.01), W28:-8.03005 (0.01), W32:-9.47538 (0.01) | topTokens[('Ġwas', 1093), ('Ġwere', 723), (',', 686), ('Ġthe', 458), ('.', 391), ('!', 356), ('ing', 311), ('Ġthey', 214), ('Ġbrain', 182), ('Ġelodie', 170)] | cheekyAvg: 10.166120624542236 | perfectTokens: 109 / 6400 → 1.70% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
2025-04-23 04:37:19 | 300 | LR0.000100 | sampledTokens:2.000000 | scheduledSamplingRate:0.001160 | repetitionPenalty:1.899140 | AvgLoss:9.576366 | loss:10.470573 | temperature:0.999999 | lR:0.000100 | gradientClip:0.999900 | latestLossDelta:7.704350 | memoryLength:10.000000 | embedNormMean:14.297525 | embedNormStd:10.083294 | embedNormMax:103.575470 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.026407 | logitWeightNormMean:91.889725 | logitWeightNormStd:2.502546 | logitWeightNormMax:104.130371 | logitWeightSparsity:0.000009 | logitWeightDrift:0.118238 | logitBiasMean:-34.146317 | logitBiasStd:11.940089 | logitBiasMax:-13.115072 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953538 | longDecay:0.967749 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007625 | n_weightStd:0.898590 | n_weightMin:-4.703306 | n_weightMax:4.878738 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.637178 | n_weightNormMin:21.136396 | n_weightNormMax:41.182598 | n_biasesMean:-1.064681 | n_biasesStd:0.793721 | n_biasesMin:-3.828028 | n_biasesMax:1.895897 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.099020 | INN_cerebellumStd:4.280179 | windowWeightsW2:4.35588 (0.58), W4:0.90651 (0.33), W8:-1.60308 (0.02), W12:-1.65262 (0.02), W16:-3.02250 (0.01), W20:-4.14998 (0.01), W24:-5.22181 (0.01), W28:-8.02986 (0.01), W32:-9.47519 (0.01) | topTokens[('Ġwas', 1432), (',', 860), ('Ġwere', 851), ('.', 658), ('Ġthe', 578), ('!', 441), ('ing', 419), ('Ġelodie', 369), ('Ġthey', 346), ('Ġfrom', 314)] | cheekyAvg: 9.435823984146118 | perfectTokens: 108 / 6400 → 1.69% |  | remainingTokens: 199699 (99.85%) | TUTOR.py 100
--- 2025-04-23 04:37:43 --- 
[babyllm] right, last time i got to step 97167... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 97167! what am i learning today?
[charis]--- 2025-04-23 04:40:02 --- 
[babyllm] right, last time i got to step 97167... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 97167! what am i learning today?
[charis]--- 2025-04-23 04:40:50 --- 
[babyllm] right, last time i got to step 97167... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 97167! what am i learning today?
[charis]2025-04-23 04:41:44 | 100 | LR0.000100 | loss:9.486704 | gradNorm:0.000000 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.000200 | repetitionPenalty:1.899560 | AvgLoss:8.434881 | temperature:0.999999 | lR:0.000100 | gradientClip:0.999980 | latestLossDelta:0.922705 | memoryLength:10.000200 | embedNormMean:14.297702 | embedNormStd:10.083359 | embedNormMax:103.553192 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000576 | embeddingDrift:16.332270 | logitWeightNormMean:91.887169 | logitWeightNormStd:2.502022 | logitWeightNormMax:104.125252 | logitWeightSparsity:0.000009 | logitWeightDrift:41.201614 | logitBiasMean:-34.146114 | logitBiasStd:11.939095 | logitBiasMax:-13.113485 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953522 | longDecay:0.967764 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007629 | n_weightStd:0.898663 | n_weightMin:-4.702975 | n_weightMax:4.877003 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.639544 | n_weightNormMin:21.121861 | n_weightNormMax:41.172710 | n_biasesMean:-1.064975 | n_biasesStd:0.793440 | n_biasesMin:-3.829421 | n_biasesMax:1.889774 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.100297 | INN_cerebellumStd:4.278759 | windowWeightsW2:4.35575 (0.58), W4:0.89344 (0.33), W8:-1.60867 (0.02), W12:-1.65368 (0.02), W16:-3.02243 (0.01), W20:-4.14984 (0.01), W24:-5.22167 (0.01), W28:-8.02959 (0.01), W32:-9.47492 (0.01) | topTokens[('Ġmoving', 319), ('Ġwas', 280), ('Ġwere', 256), ('Ġweed', 230), ('Ġelodie', 187), ('.', 165), ('ing', 161), ('Ġtaking', 147), ('Ġbutt', 144), ('Ġhear', 114)] | cheekyAvg: 8.311373215095669 | perfectTokens: 130 / 6400 → 2.03% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 04:42:19 | 200 | LR0.000100 | sampledTokens:1.000000 | scheduledSamplingRate:0.000480 | repetitionPenalty:1.899440 | AvgLoss:8.926279 | loss:8.456691 | temperature:1.000000 | lR:0.000100 | gradientClip:1.000020 | latestLossDelta:0.296019 | memoryLength:10.002000 | embedNormMean:14.297822 | embedNormStd:10.083534 | embedNormMax:103.541878 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000977 | embeddingDrift:0.027703 | logitWeightNormMean:91.885368 | logitWeightNormStd:2.501442 | logitWeightNormMax:104.111992 | logitWeightSparsity:0.000009 | logitWeightDrift:0.114708 | logitBiasMean:-34.145947 | logitBiasStd:11.938380 | logitBiasMax:-13.108538 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953538 | longDecay:0.967747 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007631 | n_weightStd:0.898752 | n_weightMin:-4.703932 | n_weightMax:4.873126 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.642420 | n_weightNormMin:21.159605 | n_weightNormMax:41.143745 | n_biasesMean:-1.065319 | n_biasesStd:0.793117 | n_biasesMin:-3.825933 | n_biasesMax:1.889288 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.101248 | INN_cerebellumStd:4.277657 | windowWeightsW2:4.35565 (0.58), W4:0.88887 (0.33), W8:-1.60828 (0.02), W12:-1.64962 (0.02), W16:-3.02239 (0.01), W20:-4.14975 (0.01), W24:-5.22158 (0.01), W28:-8.02940 (0.01), W32:-9.47473 (0.01) | topTokens[('Ġwere', 610), ('Ġwas', 559), ('.', 475), ('Ġmoving', 412), ('Ġelodie', 405), ('ing', 364), (',', 263), ('Ġweed', 260), ('Ġtaking', 243), ('!', 234)] | cheekyAvg: 8.833483972549438 | perfectTokens: 124 / 6400 → 1.94% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
2025-04-23 04:42:53 | 300 | LR0.000100 | sampledTokens:0.000000 | scheduledSamplingRate:0.000660 | repetitionPenalty:1.899100 | AvgLoss:8.116285 | loss:11.334260 | temperature:0.999999 | lR:0.000100 | gradientClip:0.999980 | latestLossDelta:2.326152 | memoryLength:10.003000 | embedNormMean:14.298014 | embedNormStd:10.083738 | embedNormMax:103.528107 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000977 | embeddingDrift:0.026635 | logitWeightNormMean:91.883751 | logitWeightNormStd:2.500967 | logitWeightNormMax:104.101677 | logitWeightSparsity:0.000008 | logitWeightDrift:0.101740 | logitBiasMean:-34.145916 | logitBiasStd:11.937403 | logitBiasMax:-13.102285 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953471 | longDecay:0.967795 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007639 | n_weightStd:0.898826 | n_weightMin:-4.703663 | n_weightMax:4.868864 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.644787 | n_weightNormMin:21.179598 | n_weightNormMax:41.175133 | n_biasesMean:-1.065612 | n_biasesStd:0.792824 | n_biasesMin:-3.822061 | n_biasesMax:1.886145 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.102104 | INN_cerebellumStd:4.276693 | windowWeightsW2:4.35556 (0.58), W4:0.87880 (0.33), W8:-1.61370 (0.02), W12:-1.65277 (0.02), W16:-3.02234 (0.01), W20:-4.14965 (0.01), W24:-5.22148 (0.01), W28:-8.02921 (0.01), W32:-9.47454 (0.01) | topTokens[('Ġwas', 923), ('Ġwere', 675), ('.', 600), ('Ġelodie', 532), ('Ġbutt', 461), ('Ġmoving', 460), ('ing', 428), ('!', 422), (',', 374), ('Ġkevin', 364)] | cheekyAvg: 8.16154372215271 | perfectTokens: 108 / 6400 → 1.69% |  | remainingTokens: 199699 (99.85%) | TUTOR.py 100
2025-04-23 04:43:29 | 400 | LR0.000100 | sampledTokens:4.000000 | scheduledSamplingRate:0.001020 | repetitionPenalty:1.898780 | AvgLoss:8.198607 | loss:9.347466 | temperature:0.999991 | lR:0.000100 | gradientClip:0.999860 | latestLossDelta:1.782574 | memoryLength:10.003600 | embedNormMean:14.298095 | embedNormStd:10.083683 | embedNormMax:103.507706 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000977 | embeddingDrift:0.021414 | logitWeightNormMean:91.881859 | logitWeightNormStd:2.500426 | logitWeightNormMax:104.099640 | logitWeightSparsity:0.000008 | logitWeightDrift:0.138045 | logitBiasMean:-34.145424 | logitBiasStd:11.937181 | logitBiasMax:-13.100924 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953477 | longDecay:0.967791 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007655 | n_weightStd:0.898903 | n_weightMin:-4.703213 | n_weightMax:4.867573 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.647198 | n_weightNormMin:21.178074 | n_weightNormMax:41.251255 | n_biasesMean:-1.065903 | n_biasesStd:0.792621 | n_biasesMin:-3.819763 | n_biasesMax:1.885085 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.104579 | INN_cerebellumStd:4.274895 | windowWeightsW2:4.35546 (0.58), W4:0.87040 (0.33), W8:-1.62126 (0.02), W12:-1.65827 (0.02), W16:-3.02229 (0.01), W20:-4.14956 (0.01), W24:-5.22139 (0.01), W28:-8.02902 (0.01), W32:-9.47435 (0.01) | topTokens[('Ġwas', 1157), ('Ġwere', 893), ('.', 676), ('Ġelodie', 627), ('!', 602), ('Ġbutt', 592), ('ing', 576), ('Ġmoving', 555), ('Ġweed', 487), (',', 485)] | cheekyAvg: 8.193811073303223 | perfectTokens: 76 / 6400 → 1.19% |  | remainingTokens: 199599 (99.80%) | TUTOR.py 100
2025-04-23 04:44:04 | 500 | LR0.000100 | sampledTokens:1.000000 | scheduledSamplingRate:0.001340 | repetitionPenalty:1.898380 | AvgLoss:9.916503 | loss:8.718192 | temperature:1.000020 | lR:0.000100 | gradientClip:0.999820 | latestLossDelta:-3.558520 | memoryLength:10.003000 | embedNormMean:14.298387 | embedNormStd:10.083999 | embedNormMax:103.493675 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000977 | embeddingDrift:0.033658 | logitWeightNormMean:91.880013 | logitWeightNormStd:2.499959 | logitWeightNormMax:104.097633 | logitWeightSparsity:0.000009 | logitWeightDrift:0.140634 | logitBiasMean:-34.144932 | logitBiasStd:11.936919 | logitBiasMax:-13.099182 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953555 | longDecay:0.967743 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007660 | n_weightStd:0.899011 | n_weightMin:-4.702944 | n_weightMax:4.860842 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.650658 | n_weightNormMin:21.185875 | n_weightNormMax:41.293957 | n_biasesMean:-1.066250 | n_biasesStd:0.792377 | n_biasesMin:-3.818627 | n_biasesMax:1.880072 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.106118 | INN_cerebellumStd:4.273610 | windowWeightsW2:4.35537 (0.58), W4:0.86243 (0.33), W8:-1.62424 (0.02), W12:-1.65828 (0.02), W16:-3.02224 (0.01), W20:-4.14946 (0.01), W24:-5.22129 (0.01), W28:-8.02883 (0.01), W32:-9.47416 (0.01) | topTokens[('Ġwas', 1493), ('Ġwere', 1043), ('ing', 798), ('.', 794), ('!', 732), (',', 710), ('Ġbutt', 651), ('Ġelodie', 646), ('Ġweed', 623), ('Ġmoving', 575)] | cheekyAvg: 9.859377717971801 | perfectTokens: 126 / 6400 → 1.97% |  | remainingTokens: 199499 (99.75%) | TUTOR.py 100
2025-04-23 04:44:39 | 600 | LR0.000100 | sampledTokens:4.000000 | scheduledSamplingRate:0.001660 | repetitionPenalty:1.898120 | AvgLoss:7.964083 | loss:11.721531 | temperature:0.999997 | lR:0.000100 | gradientClip:0.999740 | latestLossDelta:7.116738 | memoryLength:10.001800 | embedNormMean:14.298766 | embedNormStd:10.084488 | embedNormMax:103.493523 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000674 | embeddingDrift:0.024552 | logitWeightNormMean:91.878311 | logitWeightNormStd:2.499607 | logitWeightNormMax:104.095177 | logitWeightSparsity:0.000009 | logitWeightDrift:0.120305 | logitBiasMean:-34.144463 | logitBiasStd:11.936580 | logitBiasMax:-13.099574 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953500 | longDecay:0.967776 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007660 | n_weightStd:0.899121 | n_weightMin:-4.703079 | n_weightMax:4.859056 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.654192 | n_weightNormMin:21.183495 | n_weightNormMax:41.306885 | n_biasesMean:-1.066568 | n_biasesStd:0.792197 | n_biasesMin:-3.818624 | n_biasesMax:1.878809 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.107705 | INN_cerebellumStd:4.272288 | windowWeightsW2:4.35527 (0.58), W4:0.85512 (0.33), W8:-1.62733 (0.02), W12:-1.66021 (0.02), W16:-3.02219 (0.01), W20:-4.14937 (0.01), W24:-5.22120 (0.01), W28:-8.02864 (0.01), W32:-9.47397 (0.01) | topTokens[('Ġwas', 1728), ('Ġwere', 1231), ('.', 1109), (',', 964), ('ing', 841), ('Ġelodie', 775), ('!', 757), ('Ġbutt', 702), ('Ġweed', 696), ('Ġkevin', 677)] | cheekyAvg: 7.901546287536621 | perfectTokens: 119 / 6400 → 1.86% |  | remainingTokens: 199399 (99.70%) | TUTOR.py 100
2025-04-23 04:45:16 | 700 | LR0.000100 | sampledTokens:9.000000 | scheduledSamplingRate:0.002120 | repetitionPenalty:1.897760 | AvgLoss:7.494647 | loss:6.884667 | temperature:1.000000 | lR:0.000100 | gradientClip:0.999620 | latestLossDelta:-2.228017 | memoryLength:10.001400 | embedNormMean:14.298964 | embedNormStd:10.084443 | embedNormMax:103.486404 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.027646 | logitWeightNormMean:91.876396 | logitWeightNormStd:2.499252 | logitWeightNormMax:104.081116 | logitWeightSparsity:0.000009 | logitWeightDrift:0.121998 | logitBiasMean:-34.144218 | logitBiasStd:11.935973 | logitBiasMax:-13.096955 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953592 | longDecay:0.967713 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007660 | n_weightStd:0.899211 | n_weightMin:-4.701734 | n_weightMax:4.860305 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.656937 | n_weightNormMin:21.167849 | n_weightNormMax:41.256649 | n_biasesMean:-1.066862 | n_biasesStd:0.792087 | n_biasesMin:-3.818568 | n_biasesMax:1.874548 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.107530 | INN_cerebellumStd:4.271988 | windowWeightsW2:4.35518 (0.58), W4:0.85334 (0.33), W8:-1.62541 (0.02), W12:-1.65619 (0.02), W16:-3.02215 (0.01), W20:-4.14927 (0.01), W24:-5.22110 (0.01), W28:-8.02844 (0.01), W32:-9.47378 (0.01) | topTokens[('Ġwas', 1812), ('Ġwere', 1449), ('.', 1289), (',', 1124), ('!', 940), ('ing', 930), ('Ġelodie', 837), ('Ġkevin', 813), ('Ġcharis', 771), ('Ġbutt', 751)] | cheekyAvg: 7.389893484115601 | perfectTokens: 112 / 6400 → 1.75% |  | remainingTokens: 199299 (99.65%) | TUTOR.py 100
2025-04-23 04:45:52 | 800 | LR0.000100 | sampledTokens:4.000000 | scheduledSamplingRate:0.002480 | repetitionPenalty:1.897340 | AvgLoss:7.032223 | loss:9.565183 | temperature:0.999999 | lR:0.000100 | gradientClip:0.999500 | latestLossDelta:0.352253 | memoryLength:10.002800 | embedNormMean:14.298872 | embedNormStd:10.084408 | embedNormMax:103.484131 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.021046 | logitWeightNormMean:91.874550 | logitWeightNormStd:2.498899 | logitWeightNormMax:104.073441 | logitWeightSparsity:0.000009 | logitWeightDrift:0.111483 | logitBiasMean:-34.143673 | logitBiasStd:11.935799 | logitBiasMax:-13.095987 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953614 | longDecay:0.967701 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007661 | n_weightStd:0.899224 | n_weightMin:-4.701542 | n_weightMax:4.859786 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.657364 | n_weightNormMin:21.171997 | n_weightNormMax:41.291901 | n_biasesMean:-1.066920 | n_biasesStd:0.792006 | n_biasesMin:-3.818176 | n_biasesMax:1.877308 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.107932 | INN_cerebellumStd:4.271428 | windowWeightsW2:4.35508 (0.58), W4:0.84764 (0.33), W8:-1.62831 (0.02), W12:-1.65701 (0.02), W16:-3.02210 (0.01), W20:-4.14918 (0.01), W24:-5.22100 (0.01), W28:-8.02825 (0.01), W32:-9.47359 (0.01) | topTokens[('Ġwas', 2090), ('Ġwere', 1729), ('.', 1485), (',', 1276), ('ing', 1134), ('!', 1059), ('Ġkevin', 914), ('Ġelodie', 866), ('Ġcharis', 864), ('Ġbutt', 832)] | cheekyAvg: 7.117960653305054 | perfectTokens: 104 / 6400 → 1.62% |  | remainingTokens: 199199 (99.60%) | TUTOR.py 100
2025-04-23 04:46:28 | 900 | LR0.000100 | sampledTokens:4.000000 | scheduledSamplingRate:0.002900 | repetitionPenalty:1.897020 | AvgLoss:7.766522 | loss:8.479203 | temperature:1.000000 | lR:0.000100 | gradientClip:0.999680 | latestLossDelta:2.014712 | memoryLength:10.002200 | embedNormMean:14.299091 | embedNormStd:10.084751 | embedNormMax:103.481750 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.025648 | logitWeightNormMean:91.872803 | logitWeightNormStd:2.498903 | logitWeightNormMax:104.071426 | logitWeightSparsity:0.000009 | logitWeightDrift:0.124562 | logitBiasMean:-34.143009 | logitBiasStd:11.935746 | logitBiasMax:-13.095165 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953641 | longDecay:0.967684 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007662 | n_weightStd:0.899272 | n_weightMin:-4.701984 | n_weightMax:4.859365 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.658859 | n_weightNormMin:21.180679 | n_weightNormMax:41.285179 | n_biasesMean:-1.067070 | n_biasesStd:0.791917 | n_biasesMin:-3.818782 | n_biasesMax:1.876853 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.109209 | INN_cerebellumStd:4.270288 | windowWeightsW2:4.35498 (0.58), W4:0.84050 (0.33), W8:-1.63083 (0.02), W12:-1.65779 (0.02), W16:-3.02205 (0.01), W20:-4.14908 (0.01), W24:-5.22091 (0.01), W28:-8.02806 (0.01), W32:-9.47339 (0.01) | topTokens[('Ġwas', 2270), ('Ġwere', 1942), ('.', 1685), (',', 1449), ('ing', 1344), ('!', 1139), ('Ġkevin', 978), ('Ġcharis', 956), ('Ġelodie', 871), ('Ġbutt', 865)] | cheekyAvg: 7.7219311618804936 | perfectTokens: 79 / 6400 → 1.23% |  | remainingTokens: 199099 (99.55%) | TUTOR.py 100
2025-04-23 04:47:07 | 1000 | LR0.000100 | sampledTokens:6.000000 | scheduledSamplingRate:0.003200 | repetitionPenalty:1.896620 | AvgLoss:7.755126 | loss:7.585752 | temperature:1.000001 | lR:0.000100 | gradientClip:0.999520 | latestLossDelta:-2.210888 | memoryLength:10.003000 | embedNormMean:14.299509 | embedNormStd:10.085088 | embedNormMax:103.471291 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.032822 | logitWeightNormMean:91.871124 | logitWeightNormStd:2.498992 | logitWeightNormMax:104.069382 | logitWeightSparsity:0.000009 | logitWeightDrift:0.121808 | logitBiasMean:-34.142384 | logitBiasStd:11.935669 | logitBiasMax:-13.088558 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953675 | longDecay:0.967662 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007672 | n_weightStd:0.899344 | n_weightMin:-4.701384 | n_weightMax:4.856223 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.661089 | n_weightNormMin:21.179615 | n_weightNormMax:41.275982 | n_biasesMean:-1.067301 | n_biasesStd:0.791824 | n_biasesMin:-3.818991 | n_biasesMax:1.873996 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.109875 | INN_cerebellumStd:4.269492 | windowWeightsW2:4.35489 (0.58), W4:0.83294 (0.33), W8:-1.63379 (0.02), W12:-1.65880 (0.02), W16:-3.02200 (0.01), W20:-4.14898 (0.01), W24:-5.22081 (0.01), W28:-8.02787 (0.01), W32:-9.47320 (0.01) | topTokens[('Ġwas', 2494), ('Ġwere', 2074), ('.', 1812), (',', 1619), ('ing', 1535), ('!', 1310), ('Ġkevin', 1045), ('Ġcharis', 986), ('Ġbutt', 906), ('Ġelodie', 905)] | cheekyAvg: 7.723646001815796 | perfectTokens: 88 / 6400 → 1.38% |  | remainingTokens: 198999 (99.50%) | TUTOR.py 100
2025-04-23 04:47:43 | 1100 | LR0.000100 | sampledTokens:15.000000 | scheduledSamplingRate:0.003620 | repetitionPenalty:1.896320 | AvgLoss:7.483631 | loss:7.902561 | temperature:0.999999 | lR:0.000100 | gradientClip:0.999440 | latestLossDelta:-1.859603 | memoryLength:10.004400 | embedNormMean:14.299816 | embedNormStd:10.085328 | embedNormMax:103.459915 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.028590 | logitWeightNormMean:91.869537 | logitWeightNormStd:2.498734 | logitWeightNormMax:104.067375 | logitWeightSparsity:0.000009 | logitWeightDrift:0.118281 | logitBiasMean:-34.141685 | logitBiasStd:11.935635 | logitBiasMax:-13.084276 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953656 | longDecay:0.967677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007683 | n_weightStd:0.899429 | n_weightMin:-4.702692 | n_weightMax:4.857145 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.663742 | n_weightNormMin:21.189875 | n_weightNormMax:41.375694 | n_biasesMean:-1.067582 | n_biasesStd:0.791676 | n_biasesMin:-3.817635 | n_biasesMax:1.871864 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.111861 | INN_cerebellumStd:4.267900 | windowWeightsW2:4.35479 (0.59), W4:0.82251 (0.32), W8:-1.63974 (0.02), W12:-1.66083 (0.02), W16:-3.02196 (0.01), W20:-4.14889 (0.01), W24:-5.22072 (0.01), W28:-8.02768 (0.01), W32:-9.47301 (0.01) | topTokens[('Ġwas', 2778), ('Ġwere', 2187), ('.', 1908), (',', 1746), ('ing', 1634), ('!', 1588), ('Ġkevin', 1197), ('Ġelodie', 1058), ('Ġcharis', 1038), ('Ġbutt', 1035)] | cheekyAvg: 7.500142250061035 | perfectTokens: 130 / 6400 → 2.03% |  | remainingTokens: 198899 (99.45%) | TUTOR.py 100
2025-04-23 04:48:18 | 1200 | LR0.000100 | sampledTokens:13.000000 | scheduledSamplingRate:0.003980 | repetitionPenalty:1.896060 | AvgLoss:8.831041 | loss:7.499700 | temperature:1.000001 | lR:0.000100 | gradientClip:0.999480 | latestLossDelta:-0.143577 | memoryLength:10.001400 | embedNormMean:14.300119 | embedNormStd:10.085589 | embedNormMax:103.457939 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.034854 | logitWeightNormMean:91.867882 | logitWeightNormStd:2.498527 | logitWeightNormMax:104.065369 | logitWeightSparsity:0.000009 | logitWeightDrift:0.144561 | logitBiasMean:-34.141014 | logitBiasStd:11.935555 | logitBiasMax:-13.089136 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953650 | longDecay:0.967681 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007687 | n_weightStd:0.899508 | n_weightMin:-4.703377 | n_weightMax:4.858212 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.666313 | n_weightNormMin:21.185928 | n_weightNormMax:41.376923 | n_biasesMean:-1.067845 | n_biasesStd:0.791553 | n_biasesMin:-3.818897 | n_biasesMax:1.869456 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.113646 | INN_cerebellumStd:4.266390 | windowWeightsW2:4.35470 (0.59), W4:0.81217 (0.32), W8:-1.64457 (0.02), W12:-1.66701 (0.02), W16:-3.02191 (0.01), W20:-4.14879 (0.01), W24:-5.22062 (0.01), W28:-8.02749 (0.01), W32:-9.47282 (0.01) | topTokens[('Ġwas', 2908), ('Ġwere', 2485), ('.', 1949), (',', 1941), ('!', 1828), ('ing', 1804), ('Ġkevin', 1251), ('Ġweed', 1234), ('Ġcharis', 1148), ('Ġelodie', 1131)] | cheekyAvg: 8.89400712966919 | perfectTokens: 94 / 6400 → 1.47% |  | remainingTokens: 198799 (99.40%) | TUTOR.py 100
2025-04-23 04:48:55 | 1300 | LR0.000100 | sampledTokens:7.000000 | scheduledSamplingRate:0.004380 | repetitionPenalty:1.895880 | AvgLoss:7.395112 | loss:8.871482 | temperature:0.999989 | lR:0.000100 | gradientClip:0.999440 | latestLossDelta:2.412396 | memoryLength:10.002200 | embedNormMean:14.300432 | embedNormStd:10.085755 | embedNormMax:103.454834 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000166 | embeddingDrift:0.026259 | logitWeightNormMean:91.866142 | logitWeightNormStd:2.498487 | logitWeightNormMax:104.063385 | logitWeightSparsity:0.000010 | logitWeightDrift:0.135962 | logitBiasMean:-34.140438 | logitBiasStd:11.935308 | logitBiasMax:-13.089705 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953642 | longDecay:0.967677 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007691 | n_weightStd:0.899599 | n_weightMin:-4.704103 | n_weightMax:4.856921 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.669178 | n_weightNormMin:21.162369 | n_weightNormMax:41.430229 | n_biasesMean:-1.068134 | n_biasesStd:0.791426 | n_biasesMin:-3.818224 | n_biasesMax:1.866725 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.115220 | INN_cerebellumStd:4.265084 | windowWeightsW2:4.35460 (0.59), W4:0.80622 (0.32), W8:-1.64520 (0.02), W12:-1.66627 (0.02), W16:-3.02186 (0.01), W20:-4.14870 (0.01), W24:-5.22053 (0.01), W28:-8.02730 (0.01), W32:-9.47263 (0.01) | topTokens[('Ġwas', 3101), ('Ġwere', 2683), ('.', 2181), (',', 2019), ('!', 1941), ('ing', 1898), ('Ġkevin', 1375), ('Ġweed', 1262), ('Ġcharis', 1207), ('Ġelodie', 1179)] | cheekyAvg: 7.479669485092163 | perfectTokens: 84 / 6400 → 1.31% |  | remainingTokens: 198699 (99.35%) | TUTOR.py 100
--- 2025-04-23 04:49:22 --- 
[babyllm] right, last time i got to step 98515... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 98515! what am i learning today?
[charis]--- 2025-04-23 04:51:06 --- 
[babyllm] right, last time i got to step 98515... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 98515! what am i learning today?
[charis]--- 2025-04-23 04:52:37 --- 
[babyllm] right, last time i got to step 98515... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 98515! what am i learning today?
[charis]2025-04-23 04:53:33 | 100 | LR0.000100 | loss:6.881358 | gradNorm:0.000000 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.000240 | repetitionPenalty:1.899800 | AvgLoss:7.142215 | temperature:0.999996 | lR:0.000100 | gradientClip:0.999820 | latestLossDelta:-0.200120 | memoryLength:9.997400 | embedNormMean:14.300870 | embedNormStd:10.086100 | embedNormMax:103.455231 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000977 | embeddingDrift:16.326338 | logitWeightNormMean:91.863426 | logitWeightNormStd:2.498698 | logitWeightNormMax:104.060440 | logitWeightSparsity:0.000009 | logitWeightDrift:41.202347 | logitBiasMean:-34.139660 | logitBiasStd:11.934966 | logitBiasMax:-13.085571 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953606 | longDecay:0.967701 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007706 | n_weightStd:0.899715 | n_weightMin:-4.705418 | n_weightMax:4.854322 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.672823 | n_weightNormMin:21.162054 | n_weightNormMax:41.382603 | n_biasesMean:-1.068582 | n_biasesStd:0.791162 | n_biasesMin:-3.820561 | n_biasesMax:1.861589 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.118342 | INN_cerebellumStd:4.262640 | windowWeightsW2:4.35446 (0.59), W4:0.78998 (0.32), W8:-1.65653 (0.02), W12:-1.67468 (0.02), W16:-3.02179 (0.01), W20:-4.14856 (0.01), W24:-5.22039 (0.01), W28:-8.02702 (0.01), W32:-9.47235 (0.01) | topTokens[('Ġwas', 515), ('!', 192), ('.', 166), ('Ġwere', 165), ('Ġbutt', 151), ('ing', 142), ('Ġkevin', 122), ('Ġhe', 107), ('Ġfrom', 105), ('Ġelodie', 102)] | cheekyAvg: 7.056511916366278 | perfectTokens: 87 / 6400 → 1.36% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 04:54:08 | 200 | LR0.000100 | sampledTokens:3.000000 | scheduledSamplingRate:0.000580 | repetitionPenalty:1.899560 | AvgLoss:6.982584 | loss:8.276842 | temperature:1.000010 | lR:0.000100 | gradientClip:0.999920 | latestLossDelta:0.900703 | memoryLength:9.998200 | embedNormMean:14.300920 | embedNormStd:10.086117 | embedNormMax:103.448860 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000977 | embeddingDrift:0.023840 | logitWeightNormMean:91.861328 | logitWeightNormStd:2.498377 | logitWeightNormMax:104.058449 | logitWeightSparsity:0.000009 | logitWeightDrift:0.100503 | logitBiasMean:-34.139244 | logitBiasStd:11.934637 | logitBiasMax:-13.085402 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953691 | longDecay:0.967646 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007712 | n_weightStd:0.899771 | n_weightMin:-4.706338 | n_weightMax:4.856075 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.674534 | n_weightNormMin:21.168642 | n_weightNormMax:41.426788 | n_biasesMean:-1.068815 | n_biasesStd:0.790982 | n_biasesMin:-3.826533 | n_biasesMax:1.864406 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.120043 | INN_cerebellumStd:4.261293 | windowWeightsW2:4.35437 (0.59), W4:0.78369 (0.32), W8:-1.65875 (0.02), W12:-1.67647 (0.02), W16:-3.02174 (0.01), W20:-4.14846 (0.01), W24:-5.22029 (0.01), W28:-8.02683 (0.01), W32:-9.47216 (0.01) | topTokens[('Ġwas', 765), ('.', 377), ('ing', 368), ('Ġwere', 331), ('!', 298), (',', 293), ('Ġkevin', 222), ('Ġelodie', 203), ('Ġfrom', 203), ('Ġcharis', 199)] | cheekyAvg: 7.027320051193238 | perfectTokens: 110 / 6400 → 1.72% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
2025-04-23 04:54:44 | 300 | LR0.000100 | sampledTokens:3.000000 | scheduledSamplingRate:0.000980 | repetitionPenalty:1.899220 | AvgLoss:7.401872 | loss:9.319332 | temperature:0.999999 | lR:0.000100 | gradientClip:1.000000 | latestLossDelta:3.293253 | memoryLength:9.998400 | embedNormMean:14.301201 | embedNormStd:10.086481 | embedNormMax:103.442940 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000977 | embeddingDrift:0.027977 | logitWeightNormMean:91.859474 | logitWeightNormStd:2.498262 | logitWeightNormMax:104.056435 | logitWeightSparsity:0.000009 | logitWeightDrift:0.122585 | logitBiasMean:-34.138683 | logitBiasStd:11.934443 | logitBiasMax:-13.087602 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953765 | longDecay:0.967602 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007716 | n_weightStd:0.899857 | n_weightMin:-4.703202 | n_weightMax:4.854722 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.677130 | n_weightNormMin:21.164955 | n_weightNormMax:41.455441 | n_biasesMean:-1.069062 | n_biasesStd:0.790908 | n_biasesMin:-3.822817 | n_biasesMax:1.867534 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.121071 | INN_cerebellumStd:4.260361 | windowWeightsW2:4.35427 (0.59), W4:0.77896 (0.32), W8:-1.65971 (0.02), W12:-1.67547 (0.02), W16:-3.02170 (0.01), W20:-4.14837 (0.01), W24:-5.22020 (0.01), W28:-8.02664 (0.01), W32:-9.47197 (0.01) | topTokens[('Ġwas', 923), ('.', 603), ('ing', 594), ('Ġwere', 516), (',', 475), ('!', 357), ('Ġelodie', 334), ('Ġthe', 278), ('Ġkevin', 276), ('Ġfrom', 250)] | cheekyAvg: 7.483729476928711 | perfectTokens: 107 / 6400 → 1.67% |  | remainingTokens: 199699 (99.85%) | TUTOR.py 100
2025-04-23 04:55:20 | 400 | LR0.000100 | sampledTokens:3.000000 | scheduledSamplingRate:0.001380 | repetitionPenalty:1.898740 | AvgLoss:6.333860 | loss:8.583403 | temperature:1.000000 | lR:0.000100 | gradientClip:1.000020 | latestLossDelta:-0.688597 | memoryLength:9.998800 | embedNormMean:14.301292 | embedNormStd:10.086438 | embedNormMax:103.435165 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000977 | embeddingDrift:0.022998 | logitWeightNormMean:91.857834 | logitWeightNormStd:2.498190 | logitWeightNormMax:104.054420 | logitWeightSparsity:0.000009 | logitWeightDrift:0.106574 | logitBiasMean:-34.138096 | logitBiasStd:11.934249 | logitBiasMax:-13.084952 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953764 | longDecay:0.967599 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007716 | n_weightStd:0.899926 | n_weightMin:-4.701590 | n_weightMax:4.853826 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.679243 | n_weightNormMin:21.163734 | n_weightNormMax:41.443954 | n_biasesMean:-1.069257 | n_biasesStd:0.790908 | n_biasesMin:-3.823711 | n_biasesMax:1.865445 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.122226 | INN_cerebellumStd:4.259314 | windowWeightsW2:4.35418 (0.59), W4:0.77171 (0.32), W8:-1.66391 (0.02), W12:-1.67853 (0.02), W16:-3.02165 (0.01), W20:-4.14827 (0.01), W24:-5.22010 (0.01), W28:-8.02645 (0.01), W32:-9.47178 (0.01) | topTokens[('Ġwas', 1072), ('.', 870), ('Ġwere', 760), ('ing', 723), (',', 564), ('!', 527), ('Ġelodie', 437), ('Ġthe', 402), ('Ġkevin', 347), ('Ġcharis', 345)] | cheekyAvg: 6.394613227844238 | perfectTokens: 94 / 6400 → 1.47% |  | remainingTokens: 199599 (99.80%) | TUTOR.py 100
2025-04-23 04:55:55 | 500 | LR0.000100 | sampledTokens:4.000000 | scheduledSamplingRate:0.001760 | repetitionPenalty:1.898340 | AvgLoss:7.642602 | loss:7.928444 | temperature:0.999948 | lR:0.000100 | gradientClip:0.999860 | latestLossDelta:2.369246 | memoryLength:9.998000 | embedNormMean:14.301584 | embedNormStd:10.086697 | embedNormMax:103.415245 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000303 | embeddingDrift:0.033796 | logitWeightNormMean:91.856247 | logitWeightNormStd:2.498090 | logitWeightNormMax:104.052422 | logitWeightSparsity:0.000009 | logitWeightDrift:0.140059 | logitBiasMean:-34.137451 | logitBiasStd:11.934079 | logitBiasMax:-13.086521 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953726 | longDecay:0.967623 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007723 | n_weightStd:0.900022 | n_weightMin:-4.702101 | n_weightMax:4.850592 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.682232 | n_weightNormMin:21.180769 | n_weightNormMax:41.358822 | n_biasesMean:-1.069599 | n_biasesStd:0.790802 | n_biasesMin:-3.831693 | n_biasesMax:1.865795 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.123069 | INN_cerebellumStd:4.258441 | windowWeightsW2:4.35408 (0.59), W4:0.76406 (0.32), W8:-1.66487 (0.02), W12:-1.67718 (0.02), W16:-3.02160 (0.01), W20:-4.14818 (0.01), W24:-5.22001 (0.01), W28:-8.02626 (0.01), W32:-9.47159 (0.01) | topTokens[('Ġwas', 1456), ('.', 1064), ('Ġwere', 923), ('ing', 785), ('!', 759), (',', 703), ('Ġelodie', 597), ('Ġthe', 479), ('Ġcharis', 427), ('Ġbutt', 414)] | cheekyAvg: 7.698431930541992 | perfectTokens: 100 / 6400 → 1.56% |  | remainingTokens: 199499 (99.75%) | TUTOR.py 100
2025-04-23 04:56:32 | 600 | LR0.000100 | sampledTokens:4.000000 | scheduledSamplingRate:0.001800 | repetitionPenalty:1.897960 | AvgLoss:6.658133 | loss:8.524668 | temperature:1.000126 | lR:0.000100 | gradientClip:0.999800 | latestLossDelta:-1.137573 | memoryLength:9.994800 | embedNormMean:14.301868 | embedNormStd:10.087030 | embedNormMax:103.406761 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.028172 | logitWeightNormMean:91.854523 | logitWeightNormStd:2.497992 | logitWeightNormMax:104.050423 | logitWeightSparsity:0.000008 | logitWeightDrift:0.089847 | logitBiasMean:-34.136803 | logitBiasStd:11.933949 | logitBiasMax:-13.090467 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953829 | longDecay:0.967556 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007727 | n_weightStd:0.900101 | n_weightMin:-4.704261 | n_weightMax:4.848362 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.684677 | n_weightNormMin:21.173866 | n_weightNormMax:41.369373 | n_biasesMean:-1.069790 | n_biasesStd:0.790710 | n_biasesMin:-3.828418 | n_biasesMax:1.877272 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.124818 | INN_cerebellumStd:4.256938 | windowWeightsW2:4.35399 (0.59), W4:0.75564 (0.32), W8:-1.66978 (0.02), W12:-1.68121 (0.02), W16:-3.02155 (0.01), W20:-4.14808 (0.01), W24:-5.21991 (0.01), W28:-8.02607 (0.01), W32:-9.47140 (0.01) | topTokens[('Ġwas', 1692), ('.', 1172), ('Ġwere', 1170), ('ing', 1085), (',', 885), ('!', 833), ('Ġelodie', 690), ('Ġthe', 621), ('Ġcharis', 479), ('Ġbutt', 475)] | cheekyAvg: 6.741037850379944 | perfectTokens: 105 / 6400 → 1.64% |  | remainingTokens: 199399 (99.70%) | TUTOR.py 100
2025-04-23 04:57:08 | 700 | LR0.000100 | sampledTokens:4.000000 | scheduledSamplingRate:0.002180 | repetitionPenalty:1.897640 | AvgLoss:6.407013 | loss:8.576134 | temperature:0.999995 | lR:0.000100 | gradientClip:0.999820 | latestLossDelta:1.124306 | memoryLength:9.994200 | embedNormMean:14.301920 | embedNormStd:10.087111 | embedNormMax:103.404358 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.028431 | logitWeightNormMean:91.852936 | logitWeightNormStd:2.497735 | logitWeightNormMax:104.048401 | logitWeightSparsity:0.000009 | logitWeightDrift:0.102649 | logitBiasMean:-34.136173 | logitBiasStd:11.933785 | logitBiasMax:-13.087430 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953806 | longDecay:0.967569 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007729 | n_weightStd:0.900119 | n_weightMin:-4.703794 | n_weightMax:4.848187 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.685303 | n_weightNormMin:21.172913 | n_weightNormMax:41.376621 | n_biasesMean:-1.069856 | n_biasesStd:0.790627 | n_biasesMin:-3.828421 | n_biasesMax:1.874454 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.125850 | INN_cerebellumStd:4.256056 | windowWeightsW2:4.35389 (0.59), W4:0.74718 (0.32), W8:-1.67664 (0.02), W12:-1.68610 (0.02), W16:-3.02150 (0.01), W20:-4.14799 (0.01), W24:-5.21982 (0.01), W28:-8.02588 (0.01), W32:-9.47121 (0.01) | topTokens[('Ġwas', 2027), ('Ġwere', 1457), ('.', 1317), ('ing', 1283), (',', 1022), ('!', 943), ('Ġthe', 795), ('Ġelodie', 777), ('Ġcharis', 548), ('Ġbutt', 509)] | cheekyAvg: 6.476036205291748 | perfectTokens: 111 / 6400 → 1.73% |  | remainingTokens: 199299 (99.65%) | TUTOR.py 100
2025-04-23 04:57:44 | 800 | LR0.000100 | sampledTokens:13.000000 | scheduledSamplingRate:0.002600 | repetitionPenalty:1.897380 | AvgLoss:7.781794 | loss:8.476633 | temperature:0.999989 | lR:0.000100 | gradientClip:0.999600 | latestLossDelta:0.243139 | memoryLength:9.993800 | embedNormMean:14.302173 | embedNormStd:10.087188 | embedNormMax:103.400108 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.029181 | logitWeightNormMean:91.851219 | logitWeightNormStd:2.497422 | logitWeightNormMax:104.046379 | logitWeightSparsity:0.000009 | logitWeightDrift:0.121441 | logitBiasMean:-34.135761 | logitBiasStd:11.933372 | logitBiasMax:-13.083477 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953755 | longDecay:0.967599 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007739 | n_weightStd:0.900198 | n_weightMin:-4.705852 | n_weightMax:4.847743 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.687763 | n_weightNormMin:21.204622 | n_weightNormMax:41.460480 | n_biasesMean:-1.070146 | n_biasesStd:0.790513 | n_biasesMin:-3.828140 | n_biasesMax:1.869072 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.128103 | INN_cerebellumStd:4.254398 | windowWeightsW2:4.35380 (0.59), W4:0.74062 (0.32), W8:-1.67865 (0.02), W12:-1.68648 (0.02), W16:-3.02146 (0.01), W20:-4.14789 (0.01), W24:-5.21972 (0.01), W28:-8.02568 (0.01), W32:-9.47102 (0.01) | topTokens[('Ġwas', 2116), ('Ġwere', 1666), ('.', 1417), ('ing', 1358), (',', 1322), ('!', 1023), ('Ġthe', 928), ('Ġelodie', 842), ('Ġcharis', 696), ('Ġthey', 628)] | cheekyAvg: 7.844250288009643 | perfectTokens: 76 / 6400 → 1.19% |  | remainingTokens: 199199 (99.60%) | TUTOR.py 100
2025-04-23 04:58:20 | 900 | LR0.000100 | sampledTokens:8.000000 | scheduledSamplingRate:0.002880 | repetitionPenalty:1.897040 | AvgLoss:8.733425 | loss:8.870285 | temperature:1.000007 | lR:0.000100 | gradientClip:0.999520 | latestLossDelta:0.272041 | memoryLength:9.994400 | embedNormMean:14.302505 | embedNormStd:10.087373 | embedNormMax:103.389893 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.036412 | logitWeightNormMean:91.849716 | logitWeightNormStd:2.497293 | logitWeightNormMax:104.044357 | logitWeightSparsity:0.000009 | logitWeightDrift:0.149468 | logitBiasMean:-34.135029 | logitBiasStd:11.933345 | logitBiasMax:-13.082104 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953758 | longDecay:0.967596 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007745 | n_weightStd:0.900302 | n_weightMin:-4.706006 | n_weightMax:4.847935 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.690926 | n_weightNormMin:21.218086 | n_weightNormMax:41.501011 | n_biasesMean:-1.070474 | n_biasesStd:0.790503 | n_biasesMin:-3.830944 | n_biasesMax:1.870196 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.129984 | INN_cerebellumStd:4.252895 | windowWeightsW2:4.35370 (0.60), W4:0.73140 (0.32), W8:-1.68270 (0.02), W12:-1.69158 (0.02), W16:-3.02141 (0.01), W20:-4.14780 (0.01), W24:-5.21962 (0.01), W28:-8.02549 (0.01), W32:-9.47083 (0.01) | topTokens[('Ġwas', 2280), ('Ġwere', 1793), ('.', 1639), (',', 1521), ('ing', 1481), ('!', 1167), ('Ġthe', 1035), ('Ġelodie', 902), ('Ġcharis', 781), ('Ġthey', 677)] | cheekyAvg: 8.71935417175293 | perfectTokens: 77 / 6400 → 1.20% |  | remainingTokens: 199099 (99.55%) | TUTOR.py 100
2025-04-23 04:59:02 | 1000 | LR0.000101 | sampledTokens:11.000000 | scheduledSamplingRate:0.003140 | repetitionPenalty:1.896680 | AvgLoss:7.052175 | loss:8.288939 | temperature:1.000455 | lR:0.000101 | gradientClip:0.999420 | latestLossDelta:-1.112180 | memoryLength:9.994000 | embedNormMean:14.302717 | embedNormStd:10.087353 | embedNormMax:103.387947 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.024679 | logitWeightNormMean:91.848152 | logitWeightNormStd:2.497377 | logitWeightNormMax:104.042328 | logitWeightSparsity:0.000009 | logitWeightDrift:0.127603 | logitBiasMean:-34.134350 | logitBiasStd:11.933301 | logitBiasMax:-13.084103 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953813 | longDecay:0.967557 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007753 | n_weightStd:0.900346 | n_weightMin:-4.707128 | n_weightMax:4.846884 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.692299 | n_weightNormMin:21.205051 | n_weightNormMax:41.498970 | n_biasesMean:-1.070669 | n_biasesStd:0.790471 | n_biasesMin:-3.829719 | n_biasesMax:1.869868 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.131339 | INN_cerebellumStd:4.251776 | windowWeightsW2:4.35360 (0.60), W4:0.72654 (0.32), W8:-1.68420 (0.02), W12:-1.69300 (0.02), W16:-3.02136 (0.01), W20:-4.14770 (0.01), W24:-5.21953 (0.01), W28:-8.02530 (0.01), W32:-9.47063 (0.01) | topTokens[('Ġwas', 2443), ('Ġwere', 1964), ('.', 1871), (',', 1664), ('ing', 1646), ('!', 1258), ('Ġthe', 1087), ('Ġelodie', 973), ('Ġcharis', 875), ('Ġthey', 798)] | cheekyAvg: 7.124406776428223 | perfectTokens: 78 / 6400 → 1.22% |  | remainingTokens: 198999 (99.50%) | TUTOR.py 100
2025-04-23 04:59:38 | 1100 | LR0.000101 | sampledTokens:8.000000 | scheduledSamplingRate:0.003460 | repetitionPenalty:1.896200 | AvgLoss:6.977970 | loss:8.066541 | temperature:0.999997 | lR:0.000101 | gradientClip:0.999380 | latestLossDelta:1.521238 | memoryLength:9.996000 | embedNormMean:14.302640 | embedNormStd:10.087276 | embedNormMax:103.385849 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.022551 | logitWeightNormMean:91.846397 | logitWeightNormStd:2.497560 | logitWeightNormMax:104.040283 | logitWeightSparsity:0.000009 | logitWeightDrift:0.094265 | logitBiasMean:-34.133671 | logitBiasStd:11.933141 | logitBiasMax:-13.084975 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953822 | longDecay:0.967547 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007755 | n_weightStd:0.900343 | n_weightMin:-4.705701 | n_weightMax:4.845797 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.692245 | n_weightNormMin:21.215191 | n_weightNormMax:41.469818 | n_biasesMean:-1.070706 | n_biasesStd:0.790374 | n_biasesMin:-3.832307 | n_biasesMax:1.871763 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.132334 | INN_cerebellumStd:4.250941 | windowWeightsW2:4.35351 (0.60), W4:0.72065 (0.31), W8:-1.68843 (0.02), W12:-1.69745 (0.02), W16:-3.02131 (0.01), W20:-4.14760 (0.01), W24:-5.21943 (0.01), W28:-8.02511 (0.01), W32:-9.47044 (0.01) | topTokens[('Ġwas', 2561), ('.', 2276), ('Ġwere', 2195), (',', 1863), ('ing', 1721), ('!', 1281), ('Ġthe', 1133), ('Ġelodie', 1006), ('Ġthey', 993), ('Ġcharis', 971)] | cheekyAvg: 7.098240175247192 | perfectTokens: 97 / 6400 → 1.52% |  | remainingTokens: 198899 (99.45%) | TUTOR.py 100
2025-04-23 05:00:17 | 1200 | LR0.000101 | sampledTokens:12.000000 | scheduledSamplingRate:0.003880 | repetitionPenalty:1.895720 | AvgLoss:7.112834 | loss:10.706933 | temperature:0.999999 | lR:0.000101 | gradientClip:0.999440 | latestLossDelta:2.261320 | memoryLength:9.994200 | embedNormMean:14.302703 | embedNormStd:10.087261 | embedNormMax:103.373543 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.021233 | logitWeightNormMean:91.844757 | logitWeightNormStd:2.497491 | logitWeightNormMax:104.038239 | logitWeightSparsity:0.000009 | logitWeightDrift:0.106456 | logitBiasMean:-34.132957 | logitBiasStd:11.933020 | logitBiasMax:-13.080872 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953775 | longDecay:0.967575 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007757 | n_weightStd:0.900377 | n_weightMin:-4.705726 | n_weightMax:4.844148 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.693287 | n_weightNormMin:21.220190 | n_weightNormMax:41.479946 | n_biasesMean:-1.070827 | n_biasesStd:0.790340 | n_biasesMin:-3.832627 | n_biasesMax:1.871244 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.133019 | INN_cerebellumStd:4.250365 | windowWeightsW2:4.35341 (0.60), W4:0.71888 (0.31), W8:-1.68983 (0.02), W12:-1.69826 (0.02), W16:-3.02127 (0.01), W20:-4.14751 (0.01), W24:-5.21934 (0.01), W28:-8.02492 (0.01), W32:-9.47025 (0.01) | topTokens[('Ġwas', 2670), ('.', 2635), ('Ġwere', 2304), (',', 2047), ('ing', 1822), ('!', 1365), ('Ġthe', 1228), ('Ġthey', 1073), ('Ġcharis', 1063), ('Ġyou', 1057)] | cheekyAvg: 7.234962606430054 | perfectTokens: 77 / 6400 → 1.20% |  | remainingTokens: 198799 (99.40%) | TUTOR.py 100
2025-04-23 05:01:00 | 1300 | LR0.000101 | sampledTokens:9.000000 | scheduledSamplingRate:0.004240 | repetitionPenalty:1.895480 | AvgLoss:6.995067 | loss:9.807780 | temperature:1.000000 | lR:0.000101 | gradientClip:0.999200 | latestLossDelta:2.222444 | memoryLength:9.994200 | embedNormMean:14.302959 | embedNormStd:10.087347 | embedNormMax:103.370247 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.021524 | logitWeightNormMean:91.843262 | logitWeightNormStd:2.497482 | logitWeightNormMax:104.036209 | logitWeightSparsity:0.000009 | logitWeightDrift:0.091703 | logitBiasMean:-34.132309 | logitBiasStd:11.932897 | logitBiasMax:-13.082855 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953810 | longDecay:0.967552 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007763 | n_weightStd:0.900427 | n_weightMin:-4.704719 | n_weightMax:4.838501 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.694786 | n_weightNormMin:21.218487 | n_weightNormMax:41.486893 | n_biasesMean:-1.071003 | n_biasesStd:0.790361 | n_biasesMin:-3.831646 | n_biasesMax:1.868983 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.133612 | INN_cerebellumStd:4.249859 | windowWeightsW2:4.35332 (0.60), W4:0.71671 (0.31), W8:-1.69195 (0.02), W12:-1.69962 (0.02), W16:-3.02122 (0.01), W20:-4.14741 (0.01), W24:-5.21924 (0.01), W28:-8.02473 (0.01), W32:-9.47006 (0.01) | topTokens[('.', 2904), ('Ġwas', 2825), ('Ġwere', 2461), (',', 2144), ('ing', 1987), ('!', 1527), ('Ġthe', 1362), ('Ġyou', 1158), ('Ġcharis', 1136), ('Ġelodie', 1119)] | cheekyAvg: 7.004137973785401 | perfectTokens: 89 / 6400 → 1.39% |  | remainingTokens: 198699 (99.35%) | TUTOR.py 100
2025-04-23 05:01:54 | 1400 | LR0.000101 | sampledTokens:9.000000 | scheduledSamplingRate:0.004460 | repetitionPenalty:1.895180 | AvgLoss:7.401755 | loss:9.747483 | temperature:0.999999 | lR:0.000101 | gradientClip:0.999160 | latestLossDelta:0.508067 | memoryLength:9.994200 | embedNormMean:14.302970 | embedNormStd:10.087201 | embedNormMax:103.366722 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.023618 | logitWeightNormMean:91.841515 | logitWeightNormStd:2.497286 | logitWeightNormMax:104.034180 | logitWeightSparsity:0.000008 | logitWeightDrift:0.102814 | logitBiasMean:-34.131725 | logitBiasStd:11.932645 | logitBiasMax:-13.085632 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953788 | longDecay:0.967569 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007773 | n_weightStd:0.900468 | n_weightMin:-4.707869 | n_weightMax:4.837065 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.695967 | n_weightNormMin:21.231329 | n_weightNormMax:41.486450 | n_biasesMean:-1.071140 | n_biasesStd:0.790357 | n_biasesMin:-3.832041 | n_biasesMax:1.868054 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.134289 | INN_cerebellumStd:4.249322 | windowWeightsW2:4.35322 (0.60), W4:0.71415 (0.31), W8:-1.69495 (0.02), W12:-1.70104 (0.02), W16:-3.02117 (0.01), W20:-4.14732 (0.01), W24:-5.21915 (0.01), W28:-8.02454 (0.01), W32:-9.46987 (0.01) | topTokens[('.', 3103), ('Ġwas', 3043), ('Ġwere', 2661), (',', 2276), ('ing', 2096), ('!', 1678), ('Ġthe', 1479), ('Ġyou', 1333), ('Ġcharis', 1250), ('Ġelodie', 1205)] | cheekyAvg: 7.381224632263184 | perfectTokens: 67 / 6400 → 1.05% |  | remainingTokens: 198599 (99.30%) | TUTOR.py 100
2025-04-23 05:02:43 | 1500 | LR0.000101 | sampledTokens:9.000000 | scheduledSamplingRate:0.004760 | repetitionPenalty:1.894700 | AvgLoss:7.455214 | loss:6.728362 | temperature:0.999999 | lR:0.000101 | gradientClip:0.999080 | latestLossDelta:-0.809251 | memoryLength:9.993000 | embedNormMean:14.303113 | embedNormStd:10.087101 | embedNormMax:103.363602 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.025409 | logitWeightNormMean:91.839890 | logitWeightNormStd:2.497233 | logitWeightNormMax:104.032181 | logitWeightSparsity:0.000008 | logitWeightDrift:0.097837 | logitBiasMean:-34.131203 | logitBiasStd:11.932355 | logitBiasMax:-13.081651 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953818 | longDecay:0.967548 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007779 | n_weightStd:0.900503 | n_weightMin:-4.708558 | n_weightMax:4.836980 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.697153 | n_weightNormMin:21.238733 | n_weightNormMax:41.482021 | n_biasesMean:-1.071269 | n_biasesStd:0.790280 | n_biasesMin:-3.830574 | n_biasesMax:1.867194 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.134748 | INN_cerebellumStd:4.248872 | windowWeightsW2:4.35313 (0.60), W4:0.71179 (0.31), W8:-1.69682 (0.02), W12:-1.70179 (0.02), W16:-3.02112 (0.01), W20:-4.14722 (0.01), W24:-5.21905 (0.01), W28:-8.02435 (0.01), W32:-9.46968 (0.01) | topTokens[('.', 3285), ('Ġwas', 3201), ('Ġwere', 2837), (',', 2368), ('ing', 2296), ('!', 1811), ('Ġthe', 1613), ('Ġyou', 1351), ('Ġcharis', 1335), ('Ġelodie', 1298)] | cheekyAvg: 7.448264665603638 | perfectTokens: 92 / 6400 → 1.44% |  | remainingTokens: 198499 (99.25%) | TUTOR.py 100
2025-04-23 05:03:28 | 1600 | LR0.000101 | sampledTokens:19.000000 | scheduledSamplingRate:0.005120 | repetitionPenalty:1.894420 | AvgLoss:7.024039 | loss:7.563316 | temperature:1.000000 | lR:0.000101 | gradientClip:0.999140 | latestLossDelta:-2.306932 | memoryLength:9.992200 | embedNormMean:14.303125 | embedNormStd:10.087021 | embedNormMax:103.356667 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.022674 | logitWeightNormMean:91.838173 | logitWeightNormStd:2.497065 | logitWeightNormMax:104.030174 | logitWeightSparsity:0.000008 | logitWeightDrift:0.110063 | logitBiasMean:-34.130596 | logitBiasStd:11.932182 | logitBiasMax:-13.081162 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953880 | longDecay:0.967505 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007783 | n_weightStd:0.900520 | n_weightMin:-4.710473 | n_weightMax:4.836009 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.697603 | n_weightNormMin:21.238474 | n_weightNormMax:41.469349 | n_biasesMean:-1.071338 | n_biasesStd:0.790257 | n_biasesMin:-3.830306 | n_biasesMax:1.866640 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.134969 | INN_cerebellumStd:4.248559 | windowWeightsW2:4.35303 (0.60), W4:0.71046 (0.31), W8:-1.69693 (0.02), W12:-1.70137 (0.02), W16:-3.02108 (0.01), W20:-4.14713 (0.01), W24:-5.21896 (0.01), W28:-8.02416 (0.01), W32:-9.46949 (0.01) | topTokens[('.', 3452), ('Ġwas', 3315), ('Ġwere', 2971), (',', 2542), ('ing', 2431), ('!', 1949), ('Ġthe', 1836), ('Ġyou', 1467), ('Ġcharis', 1460), ('Ġelodie', 1378)] | cheekyAvg: 7.165060186386109 | perfectTokens: 73 / 6400 → 1.14% |  | remainingTokens: 198399 (99.20%) | TUTOR.py 100
2025-04-23 05:04:08 | 1700 | LR0.000101 | sampledTokens:31.000000 | scheduledSamplingRate:0.005600 | repetitionPenalty:1.894040 | AvgLoss:6.768627 | loss:10.032332 | temperature:1.000002 | lR:0.000101 | gradientClip:0.999200 | latestLossDelta:-1.160513 | memoryLength:9.991800 | embedNormMean:14.303139 | embedNormStd:10.087003 | embedNormMax:103.350105 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.016585 | logitWeightNormMean:91.836159 | logitWeightNormStd:2.496848 | logitWeightNormMax:104.028168 | logitWeightSparsity:0.000008 | logitWeightDrift:0.088117 | logitBiasMean:-34.130009 | logitBiasStd:11.932052 | logitBiasMax:-13.085455 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953901 | longDecay:0.967490 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007785 | n_weightStd:0.900551 | n_weightMin:-4.710010 | n_weightMax:4.835035 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.698530 | n_weightNormMin:21.223495 | n_weightNormMax:41.457096 | n_biasesMean:-1.071425 | n_biasesStd:0.790259 | n_biasesMin:-3.830163 | n_biasesMax:1.866482 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.135144 | INN_cerebellumStd:4.248259 | windowWeightsW2:4.35294 (0.60), W4:0.70838 (0.31), W8:-1.69826 (0.02), W12:-1.70146 (0.02), W16:-3.02103 (0.01), W20:-4.14703 (0.01), W24:-5.21886 (0.01), W28:-8.02397 (0.01), W32:-9.46930 (0.01) | topTokens[('.', 3635), ('Ġwas', 3395), ('Ġwere', 3116), (',', 2653), ('ing', 2588), ('!', 2044), ('Ġthe', 1955), ('Ġyou', 1616), ('Ġcharis', 1586), ('Ġelodie', 1493)] | cheekyAvg: 6.9783749008178715 | perfectTokens: 72 / 6400 → 1.12% |  | remainingTokens: 198299 (99.15%) | TUTOR.py 100
2025-04-23 05:04:45 | 1800 | LR0.000101 | sampledTokens:15.000000 | scheduledSamplingRate:0.005820 | repetitionPenalty:1.893700 | AvgLoss:6.491652 | loss:7.681986 | temperature:1.000000 | lR:0.000101 | gradientClip:0.999260 | latestLossDelta:2.601183 | memoryLength:9.993200 | embedNormMean:14.302970 | embedNormStd:10.086675 | embedNormMax:103.348190 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.014867 | logitWeightNormMean:91.834129 | logitWeightNormStd:2.496715 | logitWeightNormMax:104.026154 | logitWeightSparsity:0.000008 | logitWeightDrift:0.071698 | logitBiasMean:-34.129440 | logitBiasStd:11.931872 | logitBiasMax:-13.086974 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953914 | longDecay:0.967479 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007786 | n_weightStd:0.900564 | n_weightMin:-4.708785 | n_weightMax:4.834873 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.698969 | n_weightNormMin:21.213072 | n_weightNormMax:41.461517 | n_biasesMean:-1.071473 | n_biasesStd:0.790212 | n_biasesMin:-3.829848 | n_biasesMax:1.866407 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.135466 | INN_cerebellumStd:4.247868 | windowWeightsW2:4.35284 (0.60), W4:0.70658 (0.31), W8:-1.69865 (0.02), W12:-1.70149 (0.02), W16:-3.02098 (0.01), W20:-4.14694 (0.01), W24:-5.21877 (0.01), W28:-8.02378 (0.01), W32:-9.46911 (0.01) | topTokens[('.', 3849), ('Ġwas', 3537), ('Ġwere', 3422), (',', 2797), ('ing', 2683), ('!', 2153), ('Ġthe', 2061), ('Ġcharis', 1688), ('Ġyou', 1657), ('Ġelodie', 1574)] | cheekyAvg: 6.588696937561036 | perfectTokens: 64 / 6400 → 1.00% |  | remainingTokens: 198199 (99.10%) | TUTOR.py 100
2025-04-23 05:05:23 | 1900 | LR0.000101 | sampledTokens:16.000000 | scheduledSamplingRate:0.006120 | repetitionPenalty:1.893360 | AvgLoss:7.036232 | loss:7.231496 | temperature:1.000000 | lR:0.000101 | gradientClip:0.999260 | latestLossDelta:-1.913630 | memoryLength:9.993600 | embedNormMean:14.302844 | embedNormStd:10.086502 | embedNormMax:103.347130 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.014876 | logitWeightNormMean:91.832481 | logitWeightNormStd:2.496637 | logitWeightNormMax:104.024139 | logitWeightSparsity:0.000009 | logitWeightDrift:0.108685 | logitBiasMean:-34.128822 | logitBiasStd:11.931709 | logitBiasMax:-13.086453 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953896 | longDecay:0.967489 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007790 | n_weightStd:0.900561 | n_weightMin:-4.707697 | n_weightMax:4.833306 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.698860 | n_weightNormMin:21.203943 | n_weightNormMax:41.468140 | n_biasesMean:-1.071489 | n_biasesStd:0.790174 | n_biasesMin:-3.830652 | n_biasesMax:1.865164 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.135720 | INN_cerebellumStd:4.247526 | windowWeightsW2:4.35275 (0.60), W4:0.70499 (0.31), W8:-1.69925 (0.02), W12:-1.70136 (0.02), W16:-3.02093 (0.01), W20:-4.14684 (0.01), W24:-5.21867 (0.01), W28:-8.02359 (0.01), W32:-9.46892 (0.01) | topTokens[('.', 4134), ('Ġwas', 3743), ('Ġwere', 3602), (',', 2975), ('ing', 2717), ('!', 2232), ('Ġthe', 2146), ('Ġcharis', 1781), ('Ġyou', 1723), ('Ġelodie', 1630)] | cheekyAvg: 7.2339553546905515 | perfectTokens: 87 / 6400 → 1.36% |  | remainingTokens: 198099 (99.05%) | TUTOR.py 100
2025-04-23 05:06:03 | 2000 | LR0.000101 | sampledTokens:16.000000 | scheduledSamplingRate:0.006360 | repetitionPenalty:1.892960 | AvgLoss:6.900035 | loss:7.498464 | temperature:1.000000 | lR:0.000101 | gradientClip:0.999320 | latestLossDelta:0.609533 | memoryLength:9.994000 | embedNormMean:14.302753 | embedNormStd:10.086300 | embedNormMax:103.345078 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.027100 | logitWeightNormMean:91.830818 | logitWeightNormStd:2.496420 | logitWeightNormMax:104.022125 | logitWeightSparsity:0.000008 | logitWeightDrift:0.113053 | logitBiasMean:-34.128117 | logitBiasStd:11.931648 | logitBiasMax:-13.083792 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953877 | longDecay:0.967505 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007792 | n_weightStd:0.900580 | n_weightMin:-4.708726 | n_weightMax:4.833214 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.699379 | n_weightNormMin:21.200430 | n_weightNormMax:41.453869 | n_biasesMean:-1.071563 | n_biasesStd:0.790149 | n_biasesMin:-3.830744 | n_biasesMax:1.862067 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.136216 | INN_cerebellumStd:4.247023 | windowWeightsW2:4.35265 (0.60), W4:0.70095 (0.31), W8:-1.70223 (0.02), W12:-1.70227 (0.02), W16:-3.02088 (0.01), W20:-4.14675 (0.01), W24:-5.21858 (0.01), W28:-8.02340 (0.01), W32:-9.46873 (0.01) | topTokens[('.', 4455), ('Ġwas', 3891), ('Ġwere', 3783), (',', 3067), ('ing', 2852), ('Ġthe', 2325), ('!', 2280), ('Ġcharis', 1874), ('Ġyou', 1767), ('Ġelodie', 1705)] | cheekyAvg: 6.9222219371795655 | perfectTokens: 85 / 6400 → 1.33% |  | remainingTokens: 197999 (99.00%) | TUTOR.py 100
2025-04-23 05:06:40 | 2100 | LR0.000101 | sampledTokens:25.000000 | scheduledSamplingRate:0.006720 | repetitionPenalty:1.892400 | AvgLoss:6.537094 | loss:7.489827 | temperature:1.000007 | lR:0.000101 | gradientClip:0.999300 | latestLossDelta:-0.517641 | memoryLength:9.993000 | embedNormMean:14.302962 | embedNormStd:10.086346 | embedNormMax:103.340240 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.024864 | logitWeightNormMean:91.829140 | logitWeightNormStd:2.496283 | logitWeightNormMax:104.020119 | logitWeightSparsity:0.000008 | logitWeightDrift:0.098938 | logitBiasMean:-34.127449 | logitBiasStd:11.931524 | logitBiasMax:-13.078054 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953922 | longDecay:0.967469 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007808 | n_weightStd:0.900636 | n_weightMin:-4.711998 | n_weightMax:4.835041 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.701077 | n_weightNormMin:21.197590 | n_weightNormMax:41.443676 | n_biasesMean:-1.071795 | n_biasesStd:0.790105 | n_biasesMin:-3.832119 | n_biasesMax:1.862616 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.137442 | INN_cerebellumStd:4.246074 | windowWeightsW2:4.35256 (0.60), W4:0.69470 (0.31), W12:-1.70534 (0.02), W8:-1.70727 (0.02), W16:-3.02084 (0.01), W20:-4.14665 (0.01), W24:-5.21848 (0.01), W28:-8.02320 (0.01), W32:-9.46854 (0.01) | topTokens[('.', 4566), ('Ġwas', 4009), ('Ġwere', 3963), (',', 3275), ('ing', 2973), ('Ġthe', 2418), ('!', 2405), ('Ġcharis', 1958), ('Ġyou', 1846), ('Ġelodie', 1740)] | cheekyAvg: 6.652362585067749 | perfectTokens: 59 / 6400 → 0.92% |  | remainingTokens: 197899 (98.95%) | TUTOR.py 100
2025-04-23 05:07:17 | 2200 | LR0.000101 | sampledTokens:21.000000 | scheduledSamplingRate:0.006940 | repetitionPenalty:1.892020 | AvgLoss:7.596866 | loss:6.067108 | temperature:1.000011 | lR:0.000101 | gradientClip:0.999040 | latestLossDelta:-3.687154 | memoryLength:9.993000 | embedNormMean:14.303012 | embedNormStd:10.086303 | embedNormMax:103.338600 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.024085 | logitWeightNormMean:91.827255 | logitWeightNormStd:2.496589 | logitWeightNormMax:104.018089 | logitWeightSparsity:0.000008 | logitWeightDrift:0.101213 | logitBiasMean:-34.126831 | logitBiasStd:11.931322 | logitBiasMax:-13.077268 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953903 | longDecay:0.967476 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007822 | n_weightStd:0.900676 | n_weightMin:-4.714833 | n_weightMax:4.834557 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.702246 | n_weightNormMin:21.188520 | n_weightNormMax:41.431995 | n_biasesMean:-1.071955 | n_biasesStd:0.790127 | n_biasesMin:-3.832817 | n_biasesMax:1.863367 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.138127 | INN_cerebellumStd:4.245455 | windowWeightsW2:4.35246 (0.60), W4:0.69332 (0.31), W12:-1.70489 (0.02), W8:-1.70752 (0.02), W16:-3.02079 (0.01), W20:-4.14656 (0.01), W24:-5.21838 (0.01), W28:-8.02301 (0.01), W32:-9.46835 (0.01) | topTokens[('.', 4758), ('Ġwas', 4220), ('Ġwere', 4154), (',', 3411), ('ing', 3159), ('!', 2543), ('Ġthe', 2543), ('Ġcharis', 2063), ('Ġyou', 1972), ('Ġelodie', 1822)] | cheekyAvg: 7.666817650794983 | perfectTokens: 85 / 6400 → 1.33% |  | remainingTokens: 197799 (98.90%) | TUTOR.py 100
2025-04-23 05:07:53 | 2300 | LR0.000101 | sampledTokens:14.000000 | scheduledSamplingRate:0.007000 | repetitionPenalty:1.891680 | AvgLoss:6.109361 | loss:6.713269 | temperature:1.000062 | lR:0.000101 | gradientClip:0.998900 | latestLossDelta:-0.484107 | memoryLength:9.992200 | embedNormMean:14.303023 | embedNormStd:10.086300 | embedNormMax:103.336601 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.021712 | logitWeightNormMean:91.825615 | logitWeightNormStd:2.496730 | logitWeightNormMax:104.016068 | logitWeightSparsity:0.000008 | logitWeightDrift:0.127206 | logitBiasMean:-34.126160 | logitBiasStd:11.931173 | logitBiasMax:-13.076083 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953891 | longDecay:0.967480 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007830 | n_weightStd:0.900696 | n_weightMin:-4.714787 | n_weightMax:4.833019 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.702866 | n_weightNormMin:21.216127 | n_weightNormMax:41.440033 | n_biasesMean:-1.072054 | n_biasesStd:0.790136 | n_biasesMin:-3.828342 | n_biasesMax:1.861310 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.138207 | INN_cerebellumStd:4.245162 | windowWeightsW2:4.35236 (0.60), W4:0.69163 (0.31), W12:-1.70322 (0.02), W8:-1.70695 (0.02), W16:-3.02074 (0.01), W20:-4.14646 (0.01), W24:-5.21829 (0.01), W28:-8.02282 (0.01), W32:-9.46815 (0.01) | topTokens[('.', 4856), ('Ġwas', 4428), ('Ġwere', 4309), (',', 3570), ('ing', 3435), ('!', 2785), ('Ġthe', 2680), ('Ġcharis', 2157), ('Ġyou', 2032), ('Ġelodie', 2022)] | cheekyAvg: 6.222807579040527 | perfectTokens: 109 / 6400 → 1.70% |  | remainingTokens: 197699 (98.85%) | TUTOR.py 100
2025-04-23 05:08:29 | 2400 | LR0.000101 | sampledTokens:24.000000 | scheduledSamplingRate:0.007400 | repetitionPenalty:1.891360 | AvgLoss:5.913494 | loss:9.842876 | temperature:1.000000 | lR:0.000101 | gradientClip:0.998900 | latestLossDelta:0.468514 | memoryLength:9.993000 | embedNormMean:14.302888 | embedNormStd:10.086260 | embedNormMax:103.335175 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.016135 | logitWeightNormMean:91.823875 | logitWeightNormStd:2.496639 | logitWeightNormMax:104.014030 | logitWeightSparsity:0.000008 | logitWeightDrift:0.080274 | logitBiasMean:-34.125526 | logitBiasStd:11.930997 | logitBiasMax:-13.079043 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953880 | longDecay:0.967483 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007835 | n_weightStd:0.900700 | n_weightMin:-4.716345 | n_weightMax:4.832608 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.702915 | n_weightNormMin:21.221323 | n_weightNormMax:41.426403 | n_biasesMean:-1.072100 | n_biasesStd:0.790114 | n_biasesMin:-3.828806 | n_biasesMax:1.859751 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.138133 | INN_cerebellumStd:4.244976 | windowWeightsW2:4.35227 (0.60), W4:0.69007 (0.31), W12:-1.70206 (0.02), W8:-1.70725 (0.02), W16:-3.02069 (0.01), W20:-4.14636 (0.01), W24:-5.21819 (0.01), W28:-8.02263 (0.01), W32:-9.46796 (0.01) | topTokens[('.', 5010), ('Ġwas', 4644), ('Ġwere', 4431), (',', 3715), ('ing', 3639), ('!', 2932), ('Ġthe', 2818), ('Ġcharis', 2340), ('Ġelodie', 2070), ('Ġyou', 2070)] | cheekyAvg: 6.090410723686218 | perfectTokens: 95 / 6400 → 1.48% |  | remainingTokens: 197599 (98.80%) | TUTOR.py 100
2025-04-23 05:09:07 | 2500 | LR0.000101 | sampledTokens:27.000000 | scheduledSamplingRate:0.007580 | repetitionPenalty:1.891080 | AvgLoss:7.221738 | loss:9.094912 | temperature:0.999999 | lR:0.000101 | gradientClip:0.998960 | latestLossDelta:0.322364 | memoryLength:9.993600 | embedNormMean:14.302629 | embedNormStd:10.085808 | embedNormMax:103.322723 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.024012 | logitWeightNormMean:91.822014 | logitWeightNormStd:2.496626 | logitWeightNormMax:104.011993 | logitWeightSparsity:0.000008 | logitWeightDrift:0.099011 | logitBiasMean:-34.124916 | logitBiasStd:11.930770 | logitBiasMax:-13.081634 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953837 | longDecay:0.967507 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007837 | n_weightStd:0.900703 | n_weightMin:-4.715580 | n_weightMax:4.832375 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.702953 | n_weightNormMin:21.202448 | n_weightNormMax:41.458595 | n_biasesMean:-1.072133 | n_biasesStd:0.790106 | n_biasesMin:-3.830434 | n_biasesMax:1.863674 | n_sparsity:0.000009 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.138132 | INN_cerebellumStd:4.244715 | windowWeightsW2:4.35217 (0.60), W4:0.68750 (0.31), W12:-1.70041 (0.02), W8:-1.70721 (0.02), W16:-3.02065 (0.01), W20:-4.14627 (0.01), W24:-5.21810 (0.01), W28:-8.02244 (0.01), W32:-9.46777 (0.01) | topTokens[('.', 5179), ('Ġwas', 4776), ('Ġwere', 4505), (',', 3880), ('ing', 3772), ('!', 2986), ('Ġthe', 2859), ('Ġcharis', 2522), ('Ġelodie', 2211), ('Ġyou', 2122)] | cheekyAvg: 7.241803121566773 | perfectTokens: 76 / 6400 → 1.19% |  | remainingTokens: 197499 (98.75%) | TUTOR.py 100
2025-04-23 05:09:44 | 2600 | LR0.000101 | sampledTokens:31.000000 | scheduledSamplingRate:0.007900 | repetitionPenalty:1.890760 | AvgLoss:6.327372 | loss:6.798550 | temperature:1.000000 | lR:0.000101 | gradientClip:0.998880 | latestLossDelta:-1.330113 | memoryLength:9.993000 | embedNormMean:14.302496 | embedNormStd:10.085535 | embedNormMax:103.317284 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.022805 | logitWeightNormMean:91.820419 | logitWeightNormStd:2.496615 | logitWeightNormMax:104.009941 | logitWeightSparsity:0.000008 | logitWeightDrift:0.100354 | logitBiasMean:-34.124264 | logitBiasStd:11.930615 | logitBiasMax:-13.081267 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953831 | longDecay:0.967508 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007840 | n_weightStd:0.900708 | n_weightMin:-4.716053 | n_weightMax:4.832498 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.703032 | n_weightNormMin:21.195959 | n_weightNormMax:41.473637 | n_biasesMean:-1.072164 | n_biasesStd:0.790086 | n_biasesMin:-3.832528 | n_biasesMax:1.864660 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.138148 | INN_cerebellumStd:4.244480 | windowWeightsW2:4.35208 (0.60), W4:0.68527 (0.31), W12:-1.70102 (0.02), W8:-1.70819 (0.02), W16:-3.02060 (0.01), W20:-4.14617 (0.01), W24:-5.21800 (0.01), W28:-8.02225 (0.01), W32:-9.46758 (0.01) | topTokens[('.', 5381), ('Ġwas', 5046), ('Ġwere', 4589), (',', 4059), ('ing', 3934), ('!', 3074), ('Ġthe', 2910), ('Ġcharis', 2589), ('Ġelodie', 2277), ('Ġyou', 2166)] | cheekyAvg: 6.504419288635254 | perfectTokens: 94 / 6400 → 1.47% |  | remainingTokens: 197399 (98.70%) | TUTOR.py 100
--- 2025-04-23 05:10:21 --- 
[babyllm] right, last time i got to step 101183... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 101183! what am i learning today?
[charis]--- 2025-04-23 05:27:31 --- 
[babyllm] right, last time i got to step 101183... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 101183! what am i learning today?
[charis]--- 2025-04-23 05:28:28 --- 
[babyllm] right, last time i got to step 101183... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 101183! what am i learning today?
[charis]--- 2025-04-23 05:29:14 --- 
[babyllm] right, last time i got to step 101183... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 101183! what am i learning today?
[charis]2025-04-23 05:30:12 | 100 | LR0.000100 | loss:22.550018 | gradNorm:0.000000 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.000220 | repetitionPenalty:0.999976 | AvgLoss:23.771286 | temperature:0.999975 | lR:0.000100 | gradientClip:0.999860 | latestLossDelta:-1.847235 | memoryLength:10.000800 | embedNormMean:14.302281 | embedNormStd:10.085280 | embedNormMax:103.311562 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:16.306303 | logitWeightNormMean:91.817520 | logitWeightNormStd:2.496316 | logitWeightNormMax:104.006615 | logitWeightSparsity:0.000009 | logitWeightDrift:41.078594 | logitBiasMean:-34.123234 | logitBiasStd:11.930268 | logitBiasMax:-13.080328 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953809 | longDecay:0.967522 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007846 | n_weightStd:0.900717 | n_weightMin:-4.716126 | n_weightMax:4.832610 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.703344 | n_weightNormMin:21.180569 | n_weightNormMax:41.483742 | n_biasesMean:-1.072230 | n_biasesStd:0.790021 | n_biasesMin:-3.831947 | n_biasesMax:1.864424 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.138666 | INN_cerebellumStd:4.243856 | windowWeightsW2:4.35192 (0.60), W4:0.68359 (0.31), W12:-1.70079 (0.02), W8:-1.70886 (0.02), W16:-3.02052 (0.01), W20:-4.14601 (0.01), W24:-5.21784 (0.01), W28:-8.02193 (0.01), W32:-9.46726 (0.01) | topTokens[('Ġpic', 570), ('Ġwas', 467), ('Ġeating', 461), ('.', 272), ('Ġshe', 100), ('ing', 81), ('Ġwere', 78), ('Ġcharis', 74), ('Ġtouch', 71), ('Ġhe', 65)] | cheekyAvg: 23.256526722627527 | perfectTokens: 76 / 6400 → 1.19% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 05:30:50 | 200 | LR0.000100 | sampledTokens:2.000000 | scheduledSamplingRate:0.000620 | repetitionPenalty:0.999952 | AvgLoss:24.169576 | loss:20.860929 | temperature:0.999951 | lR:0.000100 | gradientClip:0.999700 | latestLossDelta:-3.226976 | memoryLength:9.999600 | embedNormMean:14.302002 | embedNormStd:10.085088 | embedNormMax:103.309578 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000153 | logitWeightNormMean:91.815849 | logitWeightNormStd:2.496268 | logitWeightNormMax:104.004616 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000807 | logitBiasMean:-34.122608 | logitBiasStd:11.930120 | logitBiasMax:-13.080143 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953807 | longDecay:0.967520 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007846 | n_weightStd:0.900700 | n_weightMin:-4.716030 | n_weightMax:4.832514 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.702814 | n_weightNormMin:21.180151 | n_weightNormMax:41.482956 | n_biasesMean:-1.072209 | n_biasesStd:0.790005 | n_biasesMin:-3.831852 | n_biasesMax:1.864376 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.138604 | INN_cerebellumStd:4.243764 | windowWeightsW2:4.35182 (0.60), W4:0.68358 (0.31), W12:-1.70077 (0.02), W8:-1.70884 (0.02), W16:-3.02047 (0.01), W20:-4.14592 (0.01), W24:-5.21775 (0.01), W28:-8.02174 (0.01), W32:-9.46707 (0.01) | topTokens[('Ġpic', 1126), ('Ġwas', 969), ('Ġeating', 830), ('.', 451), ('ing', 195), ('Ġtouch', 165), ('Ġshe', 164), (',', 157), ('Ġwere', 152), ('Ġhe', 113)] | cheekyAvg: 24.152486724853517 | perfectTokens: 88 / 6400 → 1.38% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
2025-04-23 05:31:30 | 300 | LR0.000100 | sampledTokens:0.000000 | scheduledSamplingRate:0.000860 | repetitionPenalty:0.999928 | AvgLoss:23.213550 | loss:24.319193 | temperature:0.999928 | lR:0.000100 | gradientClip:0.999820 | latestLossDelta:-0.181286 | memoryLength:9.999800 | embedNormMean:14.301735 | embedNormStd:10.084892 | embedNormMax:103.307579 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000153 | logitWeightNormMean:91.814056 | logitWeightNormStd:2.496219 | logitWeightNormMax:104.002625 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000807 | logitBiasMean:-34.121994 | logitBiasStd:11.929972 | logitBiasMax:-13.079943 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953804 | longDecay:0.967517 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007846 | n_weightStd:0.900682 | n_weightMin:-4.715934 | n_weightMax:4.832418 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.702253 | n_weightNormMin:21.179731 | n_weightNormMax:41.482155 | n_biasesMean:-1.072188 | n_biasesStd:0.789990 | n_biasesMin:-3.831756 | n_biasesMax:1.864329 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.138542 | INN_cerebellumStd:4.243672 | windowWeightsW2:4.35173 (0.60), W4:0.68357 (0.31), W12:-1.70074 (0.02), W8:-1.70882 (0.02), W16:-3.02042 (0.01), W20:-4.14582 (0.01), W24:-5.21765 (0.01), W28:-8.02155 (0.01), W32:-9.46688 (0.01) | topTokens[('Ġwas', 1782), ('Ġpic', 1130), ('Ġeating', 969), ('.', 620), ('ing', 390), ('Ġwere', 303), ('Ġhe', 254), (',', 227), ('Ġshe', 225), ('Ġtouch', 208)] | cheekyAvg: 23.305034523010253 | perfectTokens: 128 / 6400 → 2.00% |  | remainingTokens: 199699 (99.85%) | TUTOR.py 100
2025-04-23 05:32:08 | 400 | LR0.000100 | sampledTokens:6.000000 | scheduledSamplingRate:0.001220 | repetitionPenalty:0.999905 | AvgLoss:23.328062 | loss:22.174381 | temperature:0.999904 | lR:0.000100 | gradientClip:0.999740 | latestLossDelta:-1.840206 | memoryLength:10.001000 | embedNormMean:14.301462 | embedNormStd:10.084697 | embedNormMax:103.305595 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000153 | logitWeightNormMean:91.812279 | logitWeightNormStd:2.496170 | logitWeightNormMax:104.000626 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000807 | logitBiasMean:-34.121368 | logitBiasStd:11.929814 | logitBiasMax:-13.079764 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953803 | longDecay:0.967516 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007845 | n_weightStd:0.900665 | n_weightMin:-4.715838 | n_weightMax:4.832322 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.701698 | n_weightNormMin:21.179333 | n_weightNormMax:41.481342 | n_biasesMean:-1.072168 | n_biasesStd:0.789975 | n_biasesMin:-3.831661 | n_biasesMax:1.864281 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.138480 | INN_cerebellumStd:4.243581 | windowWeightsW2:4.35163 (0.60), W4:0.68356 (0.31), W12:-1.70072 (0.02), W8:-1.70879 (0.02), W16:-3.02038 (0.01), W20:-4.14573 (0.01), W24:-5.21756 (0.01), W28:-8.02136 (0.01), W32:-9.46669 (0.01) | topTokens[('Ġwas', 2500), ('Ġeating', 1361), ('Ġpic', 1326), ('.', 856), ('ing', 519), ('Ġwere', 375), (',', 334), ('Ġshe', 306), ('Ġhe', 295), ('Ġtouch', 272)] | cheekyAvg: 23.275147285461426 | perfectTokens: 128 / 6400 → 2.00% |  | remainingTokens: 199599 (99.80%) | TUTOR.py 100
2025-04-23 05:32:47 | 500 | LR0.000100 | sampledTokens:3.000000 | scheduledSamplingRate:0.001520 | repetitionPenalty:0.999881 | AvgLoss:23.493649 | loss:21.797232 | temperature:0.999880 | lR:0.000100 | gradientClip:0.999820 | latestLossDelta:-0.362879 | memoryLength:10.002200 | embedNormMean:14.301183 | embedNormStd:10.084500 | embedNormMax:103.303619 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000153 | logitWeightNormMean:91.810501 | logitWeightNormStd:2.496121 | logitWeightNormMax:103.998627 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000807 | logitBiasMean:-34.120747 | logitBiasStd:11.929657 | logitBiasMax:-13.079564 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953799 | longDecay:0.967515 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007845 | n_weightStd:0.900648 | n_weightMin:-4.715743 | n_weightMax:4.832227 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.701138 | n_weightNormMin:21.178913 | n_weightNormMax:41.480541 | n_biasesMean:-1.072147 | n_biasesStd:0.789959 | n_biasesMin:-3.831566 | n_biasesMax:1.864233 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.138418 | INN_cerebellumStd:4.243488 | windowWeightsW2:4.35154 (0.60), W4:0.68354 (0.31), W12:-1.70070 (0.02), W8:-1.70877 (0.02), W16:-3.02033 (0.01), W20:-4.14563 (0.01), W24:-5.21746 (0.01), W28:-8.02117 (0.01), W32:-9.46650 (0.01) | topTokens[('Ġwas', 3137), ('Ġeating', 1770), ('Ġpic', 1383), ('.', 1043), ('ing', 596), ('Ġwere', 445), (',', 399), ('Ġhe', 387), ('Ġshe', 367), ('Ġyou', 315)] | cheekyAvg: 23.50943794250488 | perfectTokens: 98 / 6400 → 1.53% |  | remainingTokens: 199499 (99.75%) | TUTOR.py 100
2025-04-23 05:33:27 | 600 | LR0.000100 | sampledTokens:6.000000 | scheduledSamplingRate:0.001880 | repetitionPenalty:0.999857 | AvgLoss:23.006269 | loss:23.301237 | temperature:0.999856 | lR:0.000100 | gradientClip:0.999680 | latestLossDelta:2.713063 | memoryLength:10.002200 | embedNormMean:14.300903 | embedNormStd:10.084310 | embedNormMax:103.301643 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000153 | logitWeightNormMean:91.808685 | logitWeightNormStd:2.496072 | logitWeightNormMax:103.996613 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000808 | logitBiasMean:-34.120121 | logitBiasStd:11.929505 | logitBiasMax:-13.079388 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953798 | longDecay:0.967514 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007845 | n_weightStd:0.900630 | n_weightMin:-4.715649 | n_weightMax:4.832133 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.700605 | n_weightNormMin:21.178499 | n_weightNormMax:41.479755 | n_biasesMean:-1.072126 | n_biasesStd:0.789944 | n_biasesMin:-3.831470 | n_biasesMax:1.864185 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.138356 | INN_cerebellumStd:4.243397 | windowWeightsW2:4.35144 (0.60), W4:0.68353 (0.31), W12:-1.70067 (0.02), W8:-1.70874 (0.02), W16:-3.02028 (0.01), W20:-4.14554 (0.01), W24:-5.21737 (0.01), W28:-8.02098 (0.01), W32:-9.46631 (0.01) | topTokens[('Ġwas', 3597), ('Ġeating', 2001), ('Ġpic', 1521), ('.', 1278), ('ing', 751), ('Ġwere', 586), ('Ġhe', 489), (',', 487), ('Ġshe', 448), ('Ġyou', 423)] | cheekyAvg: 23.106642646789552 | perfectTokens: 87 / 6400 → 1.36% |  | remainingTokens: 199399 (99.70%) | TUTOR.py 100
2025-04-23 05:34:08 | 700 | LR0.000100 | sampledTokens:6.000000 | scheduledSamplingRate:0.002140 | repetitionPenalty:0.999833 | AvgLoss:23.379071 | loss:22.598738 | temperature:0.999832 | lR:0.000100 | gradientClip:0.999800 | latestLossDelta:-1.251242 | memoryLength:10.004200 | embedNormMean:14.300634 | embedNormStd:10.084117 | embedNormMax:103.299660 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000153 | logitWeightNormMean:91.806976 | logitWeightNormStd:2.496023 | logitWeightNormMax:103.994606 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000808 | logitBiasMean:-34.119499 | logitBiasStd:11.929357 | logitBiasMax:-13.079187 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953796 | longDecay:0.967512 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007845 | n_weightStd:0.900613 | n_weightMin:-4.715554 | n_weightMax:4.832037 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.700039 | n_weightNormMin:21.178093 | n_weightNormMax:41.478947 | n_biasesMean:-1.072106 | n_biasesStd:0.789928 | n_biasesMin:-3.831375 | n_biasesMax:1.864138 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.138294 | INN_cerebellumStd:4.243305 | windowWeightsW2:4.35135 (0.60), W4:0.68352 (0.31), W12:-1.70065 (0.02), W8:-1.70872 (0.02), W16:-3.02023 (0.01), W20:-4.14544 (0.01), W24:-5.21727 (0.01), W28:-8.02079 (0.01), W32:-9.46612 (0.01) | topTokens[('Ġwas', 3963), ('Ġeating', 2107), ('Ġpic', 2009), ('.', 1426), ('ing', 909), ('Ġwere', 678), ('Ġhe', 593), (',', 552), ('Ġshe', 523), ('Ġyou', 492)] | cheekyAvg: 23.407371482849122 | perfectTokens: 93 / 6400 → 1.45% |  | remainingTokens: 199299 (99.65%) | TUTOR.py 100
2025-04-23 05:34:48 | 800 | LR0.000100 | sampledTokens:7.000000 | scheduledSamplingRate:0.002480 | repetitionPenalty:0.999809 | AvgLoss:24.779752 | loss:21.075676 | temperature:0.999808 | lR:0.000100 | gradientClip:0.999840 | latestLossDelta:-3.963390 | memoryLength:10.003400 | embedNormMean:14.300363 | embedNormStd:10.083922 | embedNormMax:103.297668 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.805237 | logitWeightNormStd:2.495975 | logitWeightNormMax:103.992599 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000808 | logitBiasMean:-34.118874 | logitBiasStd:11.929192 | logitBiasMax:-13.078998 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953794 | longDecay:0.967509 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007845 | n_weightStd:0.900595 | n_weightMin:-4.715458 | n_weightMax:4.831943 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.699478 | n_weightNormMin:21.177671 | n_weightNormMax:41.478130 | n_biasesMean:-1.072085 | n_biasesStd:0.789913 | n_biasesMin:-3.831280 | n_biasesMax:1.864090 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.138232 | INN_cerebellumStd:4.243214 | windowWeightsW2:4.35125 (0.60), W4:0.68351 (0.31), W12:-1.70062 (0.02), W8:-1.70870 (0.02), W16:-3.02019 (0.01), W20:-4.14535 (0.01), W24:-5.21718 (0.01), W28:-8.02060 (0.01), W32:-9.46593 (0.01) | topTokens[('Ġwas', 4384), ('Ġeating', 2538), ('Ġpic', 2289), ('.', 1641), ('ing', 1026), ('Ġwere', 801), ('Ġhe', 702), (',', 634), ('Ġshe', 580), ('Ġyou', 562)] | cheekyAvg: 24.745236625671385 | perfectTokens: 85 / 6400 → 1.33% |  | remainingTokens: 199199 (99.60%) | TUTOR.py 100
2025-04-23 05:35:28 | 900 | LR0.000100 | sampledTokens:12.000000 | scheduledSamplingRate:0.002860 | repetitionPenalty:0.999785 | AvgLoss:22.593552 | loss:21.631866 | temperature:0.999784 | lR:0.000100 | gradientClip:0.999880 | latestLossDelta:-1.710046 | memoryLength:10.004200 | embedNormMean:14.300084 | embedNormStd:10.083727 | embedNormMax:103.295662 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.803421 | logitWeightNormStd:2.495926 | logitWeightNormMax:103.990578 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000808 | logitBiasMean:-34.118248 | logitBiasStd:11.929039 | logitBiasMax:-13.078806 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953791 | longDecay:0.967509 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007845 | n_weightStd:0.900579 | n_weightMin:-4.715363 | n_weightMax:4.831847 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.698931 | n_weightNormMin:21.177263 | n_weightNormMax:41.477348 | n_biasesMean:-1.072064 | n_biasesStd:0.789898 | n_biasesMin:-3.831184 | n_biasesMax:1.864042 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.138170 | INN_cerebellumStd:4.243121 | windowWeightsW2:4.35116 (0.60), W4:0.68350 (0.31), W12:-1.70060 (0.02), W8:-1.70867 (0.02), W16:-3.02014 (0.01), W20:-4.14525 (0.01), W24:-5.21708 (0.01), W28:-8.02041 (0.01), W32:-9.46574 (0.01) | topTokens[('Ġwas', 4784), ('Ġeating', 2893), ('Ġpic', 2456), ('.', 1912), ('ing', 1135), ('Ġwere', 898), ('Ġhe', 799), (',', 735), ('Ġshe', 692), ('Ġyou', 649)] | cheekyAvg: 22.644971008300782 | perfectTokens: 83 / 6400 → 1.30% |  | remainingTokens: 199099 (99.55%) | TUTOR.py 100
2025-04-23 05:36:11 | 1000 | LR0.000100 | sampledTokens:10.000000 | scheduledSamplingRate:0.003280 | repetitionPenalty:0.999762 | AvgLoss:23.399321 | loss:21.914644 | temperature:0.999761 | lR:0.000100 | gradientClip:0.999880 | latestLossDelta:-2.339550 | memoryLength:10.005800 | embedNormMean:14.299801 | embedNormStd:10.083530 | embedNormMax:103.293678 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.801643 | logitWeightNormStd:2.495876 | logitWeightNormMax:103.988556 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000808 | logitBiasMean:-34.117626 | logitBiasStd:11.928888 | logitBiasMax:-13.078609 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953789 | longDecay:0.967507 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007844 | n_weightStd:0.900561 | n_weightMin:-4.715267 | n_weightMax:4.831751 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.698389 | n_weightNormMin:21.176853 | n_weightNormMax:41.476543 | n_biasesMean:-1.072043 | n_biasesStd:0.789882 | n_biasesMin:-3.831089 | n_biasesMax:1.863995 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.138107 | INN_cerebellumStd:4.243030 | windowWeightsW2:4.35106 (0.60), W4:0.68348 (0.31), W12:-1.70058 (0.02), W8:-1.70865 (0.02), W16:-3.02009 (0.01), W20:-4.14516 (0.01), W24:-5.21699 (0.01), W28:-8.02022 (0.01), W32:-9.46555 (0.01) | topTokens[('Ġwas', 5081), ('Ġeating', 3275), ('Ġpic', 2795), ('.', 2286), ('ing', 1273), ('Ġwere', 997), ('Ġhe', 845), (',', 836), ('Ġshe', 772), ('Ġyou', 721)] | cheekyAvg: 23.406039390563965 | perfectTokens: 88 / 6400 → 1.38% |  | remainingTokens: 198999 (99.50%) | TUTOR.py 100
2025-04-23 05:36:50 | 1100 | LR0.000100 | sampledTokens:13.000000 | scheduledSamplingRate:0.003540 | repetitionPenalty:0.999738 | AvgLoss:22.914826 | loss:21.673515 | temperature:0.999737 | lR:0.000100 | gradientClip:0.999860 | latestLossDelta:-1.947526 | memoryLength:10.007000 | embedNormMean:14.299535 | embedNormStd:10.083337 | embedNormMax:103.291687 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.799843 | logitWeightNormStd:2.495826 | logitWeightNormMax:103.986511 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000808 | logitBiasMean:-34.116997 | logitBiasStd:11.928738 | logitBiasMax:-13.078429 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953789 | longDecay:0.967506 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007844 | n_weightStd:0.900543 | n_weightMin:-4.715171 | n_weightMax:4.831655 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.697826 | n_weightNormMin:21.176435 | n_weightNormMax:41.475731 | n_biasesMean:-1.072022 | n_biasesStd:0.789867 | n_biasesMin:-3.830993 | n_biasesMax:1.863947 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.138044 | INN_cerebellumStd:4.242938 | windowWeightsW2:4.35097 (0.60), W4:0.68347 (0.31), W12:-1.70055 (0.02), W8:-1.70862 (0.02), W16:-3.02004 (0.01), W20:-4.14506 (0.01), W24:-5.21689 (0.01), W28:-8.02003 (0.01), W32:-9.46536 (0.01) | topTokens[('Ġwas', 5630), ('Ġeating', 3831), ('Ġpic', 3062), ('.', 2429), ('ing', 1421), ('Ġwere', 1104), (',', 914), ('Ġhe', 908), ('Ġshe', 824), ('Ġyou', 789)] | cheekyAvg: 22.97640350341797 | perfectTokens: 78 / 6400 → 1.22% |  | remainingTokens: 198899 (99.45%) | TUTOR.py 100
--- 2025-04-23 05:37:27 --- 
[babyllm] right, last time i got to step 102300... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 102300! what am i learning today?
[charis]2025-04-23 05:38:28 | 100 | LR0.000100 | loss:21.433237 | gradNorm:0.000000 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999710 | AvgLoss:24.935562 | temperature:0.999709 | lR:0.000100 | gradientClip:0.999900 | latestLossDelta:-0.227046 | memoryLength:9.999600 | embedNormMean:14.299211 | embedNormStd:10.083113 | embedNormMax:103.289330 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:16.299206 | logitWeightNormMean:91.797821 | logitWeightNormStd:2.495770 | logitWeightNormMax:103.984222 | logitWeightSparsity:0.000009 | logitWeightDrift:41.069752 | logitBiasMean:-34.116268 | logitBiasStd:11.928550 | logitBiasMax:-13.078202 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953784 | longDecay:0.967505 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007844 | n_weightStd:0.900523 | n_weightMin:-4.715062 | n_weightMax:4.831546 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.697195 | n_weightNormMin:21.175953 | n_weightNormMax:41.474815 | n_biasesMean:-1.071998 | n_biasesStd:0.789848 | n_biasesMin:-3.830883 | n_biasesMax:1.863892 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.137970 | INN_cerebellumStd:4.242832 | windowWeightsW2:4.35085 (0.60), W4:0.68346 (0.31), W12:-1.70053 (0.02), W8:-1.70860 (0.02), W16:-3.01999 (0.01), W20:-4.14495 (0.01), W24:-5.21678 (0.01), W28:-8.01980 (0.01), W32:-9.46514 (0.01) | topTokens[('Ġpic', 547), ('Ġeating', 479), ('.', 217), ('Ġwas', 159), ('Ġshe', 117), ('Ġbutt', 101), (',', 94), ('Ġwere', 82), ('ing', 82), ('Ġhe', 78)] | cheekyAvg: 24.402300254971372 | perfectTokens: 72 / 6400 → 1.12% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 05:39:09 | 200 | LR0.000100 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999686 | AvgLoss:24.375310 | loss:22.319031 | temperature:0.999685 | lR:0.000100 | gradientClip:0.999840 | latestLossDelta:-0.764305 | memoryLength:9.998800 | embedNormMean:14.298933 | embedNormStd:10.082917 | embedNormMax:103.287315 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.795998 | logitWeightNormStd:2.495721 | logitWeightNormMax:103.982216 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000809 | logitBiasMean:-34.115650 | logitBiasStd:11.928398 | logitBiasMax:-13.078009 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953783 | longDecay:0.967501 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007844 | n_weightStd:0.900506 | n_weightMin:-4.714966 | n_weightMax:4.831450 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.696630 | n_weightNormMin:21.175545 | n_weightNormMax:41.473999 | n_biasesMean:-1.071977 | n_biasesStd:0.789833 | n_biasesMin:-3.830787 | n_biasesMax:1.863844 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.137908 | INN_cerebellumStd:4.242741 | windowWeightsW2:4.35076 (0.60), W4:0.68345 (0.31), W12:-1.70050 (0.02), W8:-1.70857 (0.02), W16:-3.01994 (0.01), W20:-4.14486 (0.01), W24:-5.21668 (0.01), W28:-8.01961 (0.01), W32:-9.46494 (0.01) | topTokens[('Ġeating', 1038), ('Ġwas', 758), ('Ġpic', 718), ('.', 465), ('Ġshe', 207), (',', 191), ('ing', 187), ('Ġwere', 184), ('Ġv', 141), ('Ġhe', 140)] | cheekyAvg: 24.27206474304199 | perfectTokens: 97 / 6400 → 1.52% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
2025-04-23 05:39:49 | 300 | LR0.000100 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999662 | AvgLoss:24.577325 | loss:22.531721 | temperature:0.999661 | lR:0.000100 | gradientClip:0.999880 | latestLossDelta:-0.833522 | memoryLength:9.999600 | embedNormMean:14.298668 | embedNormStd:10.082724 | embedNormMax:103.285309 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.794289 | logitWeightNormStd:2.495672 | logitWeightNormMax:103.980217 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000809 | logitBiasMean:-34.115025 | logitBiasStd:11.928247 | logitBiasMax:-13.077824 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953781 | longDecay:0.967501 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007844 | n_weightStd:0.900489 | n_weightMin:-4.714870 | n_weightMax:4.831354 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.696070 | n_weightNormMin:21.175127 | n_weightNormMax:41.473209 | n_biasesMean:-1.071957 | n_biasesStd:0.789818 | n_biasesMin:-3.830692 | n_biasesMax:1.863796 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.137846 | INN_cerebellumStd:4.242648 | windowWeightsW2:4.35066 (0.60), W4:0.68343 (0.31), W12:-1.70048 (0.02), W8:-1.70855 (0.02), W16:-3.01989 (0.01), W20:-4.14476 (0.01), W24:-5.21659 (0.01), W28:-8.01942 (0.01), W32:-9.46475 (0.01) | topTokens[('Ġeating', 1411), ('Ġwas', 1309), ('Ġpic', 1040), ('.', 646), (',', 291), ('Ġshe', 264), ('Ġwere', 232), ('ing', 227), ('Ġhe', 225), ('Ġyou', 207)] | cheekyAvg: 24.545076904296874 | perfectTokens: 59 / 6400 → 0.92% |  | remainingTokens: 199699 (99.85%) | TUTOR.py 100
2025-04-23 05:40:30 | 400 | LR0.000100 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999639 | AvgLoss:23.800845 | loss:22.573519 | temperature:0.999638 | lR:0.000100 | gradientClip:0.999880 | latestLossDelta:-0.827818 | memoryLength:9.998400 | embedNormMean:14.298387 | embedNormStd:10.082532 | embedNormMax:103.283295 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.792542 | logitWeightNormStd:2.495624 | logitWeightNormMax:103.978210 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000809 | logitBiasMean:-34.114403 | logitBiasStd:11.928080 | logitBiasMax:-13.077623 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953779 | longDecay:0.967499 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007844 | n_weightStd:0.900472 | n_weightMin:-4.714774 | n_weightMax:4.831258 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.695518 | n_weightNormMin:21.174715 | n_weightNormMax:41.472412 | n_biasesMean:-1.071936 | n_biasesStd:0.789802 | n_biasesMin:-3.830596 | n_biasesMax:1.863749 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.137784 | INN_cerebellumStd:4.242557 | windowWeightsW2:4.35057 (0.60), W4:0.68342 (0.31), W12:-1.70045 (0.02), W8:-1.70853 (0.02), W16:-3.01984 (0.01), W20:-4.14466 (0.01), W24:-5.21649 (0.01), W28:-8.01923 (0.01), W32:-9.46456 (0.01) | topTokens[('Ġeating', 1785), ('Ġwas', 1674), ('Ġpic', 1317), ('.', 1068), (',', 407), ('Ġshe', 359), ('ing', 340), ('Ġwere', 329), ('Ġyou', 292), ('Ġhe', 288)] | cheekyAvg: 23.689024085998536 | perfectTokens: 94 / 6400 → 1.47% |  | remainingTokens: 199599 (99.80%) | TUTOR.py 100
2025-04-23 05:41:11 | 500 | LR0.000100 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999615 | AvgLoss:24.316399 | loss:22.183304 | temperature:0.999614 | lR:0.000100 | gradientClip:1.000000 | latestLossDelta:-1.839186 | memoryLength:9.998600 | embedNormMean:14.298108 | embedNormStd:10.082337 | embedNormMax:103.281281 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.790726 | logitWeightNormStd:2.495574 | logitWeightNormMax:103.976212 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000809 | logitBiasMean:-34.113777 | logitBiasStd:11.927927 | logitBiasMax:-13.077445 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953776 | longDecay:0.967499 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007844 | n_weightStd:0.900454 | n_weightMin:-4.714678 | n_weightMax:4.831162 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.694981 | n_weightNormMin:21.174299 | n_weightNormMax:41.471603 | n_biasesMean:-1.071915 | n_biasesStd:0.789787 | n_biasesMin:-3.830501 | n_biasesMax:1.863701 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.137722 | INN_cerebellumStd:4.242465 | windowWeightsW2:4.35047 (0.60), W4:0.68341 (0.31), W12:-1.70043 (0.02), W8:-1.70850 (0.02), W16:-3.01980 (0.01), W20:-4.14457 (0.01), W24:-5.21640 (0.01), W28:-8.01904 (0.01), W32:-9.46437 (0.01) | topTokens[('Ġeating', 2148), ('Ġwas', 2085), ('Ġpic', 1680), ('.', 1195), (',', 495), ('ing', 431), ('Ġwere', 426), ('Ġshe', 425), ('Ġhe', 373), ('Ġyou', 369)] | cheekyAvg: 24.33501319885254 | perfectTokens: 105 / 6400 → 1.64% |  | remainingTokens: 199499 (99.75%) | TUTOR.py 100
2025-04-23 05:41:52 | 600 | LR0.000100 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999591 | AvgLoss:23.340474 | loss:22.552521 | temperature:0.999590 | lR:0.000100 | gradientClip:0.999980 | latestLossDelta:-1.396138 | memoryLength:9.998400 | embedNormMean:14.297832 | embedNormStd:10.082141 | embedNormMax:103.279274 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.788948 | logitWeightNormStd:2.495525 | logitWeightNormMax:103.974197 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000809 | logitBiasMean:-34.113148 | logitBiasStd:11.927777 | logitBiasMax:-13.077245 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953774 | longDecay:0.967497 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007843 | n_weightStd:0.900436 | n_weightMin:-4.714583 | n_weightMax:4.831068 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.694414 | n_weightNormMin:21.173874 | n_weightNormMax:41.470791 | n_biasesMean:-1.071894 | n_biasesStd:0.789772 | n_biasesMin:-3.830406 | n_biasesMax:1.863653 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.137660 | INN_cerebellumStd:4.242373 | windowWeightsW2:4.35038 (0.60), W4:0.68340 (0.31), W12:-1.70041 (0.02), W8:-1.70848 (0.02), W16:-3.01975 (0.01), W20:-4.14447 (0.01), W24:-5.21630 (0.01), W28:-8.01885 (0.01), W32:-9.46418 (0.01) | topTokens[('Ġwas', 2603), ('Ġeating', 2470), ('Ġpic', 1788), ('.', 1390), ('ing', 618), (',', 610), ('Ġwere', 550), ('Ġshe', 524), ('Ġhe', 475), ('Ġyou', 430)] | cheekyAvg: 23.420563926696776 | perfectTokens: 76 / 6400 → 1.19% |  | remainingTokens: 199399 (99.70%) | TUTOR.py 100
2025-04-23 05:42:33 | 700 | LR0.000100 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999567 | AvgLoss:24.649551 | loss:21.802103 | temperature:0.999566 | lR:0.000100 | gradientClip:1.000000 | latestLossDelta:4.056168 | memoryLength:9.998800 | embedNormMean:14.297565 | embedNormStd:10.081945 | embedNormMax:103.277298 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.787155 | logitWeightNormStd:2.495476 | logitWeightNormMax:103.972191 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000810 | logitBiasMean:-34.112526 | logitBiasStd:11.927612 | logitBiasMax:-13.077068 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953773 | longDecay:0.967494 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007843 | n_weightStd:0.900419 | n_weightMin:-4.714489 | n_weightMax:4.830973 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.693850 | n_weightNormMin:21.173477 | n_weightNormMax:41.470009 | n_biasesMean:-1.071873 | n_biasesStd:0.789756 | n_biasesMin:-3.830311 | n_biasesMax:1.863605 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.137598 | INN_cerebellumStd:4.242281 | windowWeightsW2:4.35028 (0.60), W4:0.68339 (0.31), W12:-1.70038 (0.02), W8:-1.70845 (0.02), W16:-3.01970 (0.01), W20:-4.14438 (0.01), W24:-5.21621 (0.01), W28:-8.01866 (0.01), W32:-9.46399 (0.01) | topTokens[('Ġwas', 3032), ('Ġeating', 2685), ('Ġpic', 2260), ('.', 1758), ('ing', 814), (',', 688), ('Ġwere', 619), ('Ġshe', 597), ('Ġhe', 545), ('Ġyou', 498)] | cheekyAvg: 24.62227737426758 | perfectTokens: 74 / 6400 → 1.16% |  | remainingTokens: 199299 (99.65%) | TUTOR.py 100
2025-04-23 05:43:14 | 800 | LR0.000100 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999543 | AvgLoss:22.045141 | loss:21.771305 | temperature:0.999542 | lR:0.000100 | gradientClip:0.999920 | latestLossDelta:-1.143684 | memoryLength:9.998200 | embedNormMean:14.297285 | embedNormStd:10.081751 | embedNormMax:103.275314 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.785378 | logitWeightNormStd:2.495427 | logitWeightNormMax:103.970177 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000810 | logitBiasMean:-34.111897 | logitBiasStd:11.927456 | logitBiasMax:-13.076868 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953771 | longDecay:0.967494 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007843 | n_weightStd:0.900402 | n_weightMin:-4.714394 | n_weightMax:4.830878 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.693310 | n_weightNormMin:21.173054 | n_weightNormMax:41.469200 | n_biasesMean:-1.071853 | n_biasesStd:0.789741 | n_biasesMin:-3.830215 | n_biasesMax:1.863558 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.137536 | INN_cerebellumStd:4.242189 | windowWeightsW2:4.35019 (0.60), W4:0.68338 (0.31), W12:-1.70036 (0.02), W8:-1.70843 (0.02), W16:-3.01965 (0.01), W20:-4.14428 (0.01), W24:-5.21611 (0.01), W28:-8.01847 (0.01), W32:-9.46380 (0.01) | topTokens[('Ġwas', 3755), ('Ġeating', 2756), ('Ġpic', 2449), ('.', 1950), ('ing', 949), (',', 740), ('Ġwere', 713), ('Ġhe', 668), ('Ġshe', 650), ('Ġyou', 565)] | cheekyAvg: 22.076863136291504 | perfectTokens: 124 / 6400 → 1.94% |  | remainingTokens: 199199 (99.60%) | TUTOR.py 100
--- 2025-04-23 05:44:01 --- 
[babyllm] right, last time i got to step 103193... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 103193! what am i learning today?
[charis]2025-04-23 05:45:00 | 100 | LR0.000100 | loss:22.447838 | gradNorm:0.000000 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999497 | AvgLoss:24.069628 | temperature:0.999496 | lR:0.000100 | gradientClip:0.999920 | latestLossDelta:0.018475 | memoryLength:9.999400 | embedNormMean:14.296748 | embedNormStd:10.081379 | embedNormMax:103.271454 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:16.318663 | logitWeightNormMean:91.782005 | logitWeightNormStd:2.495334 | logitWeightNormMax:103.966309 | logitWeightSparsity:0.000009 | logitWeightDrift:41.062675 | logitBiasMean:-34.110699 | logitBiasStd:11.927160 | logitBiasMax:-13.076502 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953766 | longDecay:0.967491 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007843 | n_weightStd:0.900368 | n_weightMin:-4.714211 | n_weightMax:4.830695 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.692242 | n_weightNormMin:21.172264 | n_weightNormMax:41.467651 | n_biasesMean:-1.071813 | n_biasesStd:0.789711 | n_biasesMin:-3.830032 | n_biasesMax:1.863466 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.137416 | INN_cerebellumStd:4.242013 | windowWeightsW2:4.35000 (0.60), W4:0.68335 (0.31), W12:-1.70031 (0.02), W8:-1.70838 (0.02), W16:-3.01956 (0.01), W20:-4.14410 (0.01), W24:-5.21593 (0.01), W28:-8.01810 (0.01), W32:-9.46343 (0.01) | topTokens[('Ġwas', 416), ('.', 290), ('Ġpic', 208), ('Ġeating', 193), ('ing', 161), (',', 105), ("'", 104), ('Ġwere', 103), ('!', 97), ('Ġshe', 87)] | cheekyAvg: 23.55422913794424 | perfectTokens: 88 / 6400 → 1.38% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 05:45:38 | 200 | LR0.000100 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999474 | AvgLoss:23.834982 | loss:23.542612 | temperature:0.999473 | lR:0.000100 | gradientClip:0.999940 | latestLossDelta:7.670069 | memoryLength:9.998400 | embedNormMean:14.296482 | embedNormStd:10.081186 | embedNormMax:103.269470 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.780228 | logitWeightNormStd:2.495284 | logitWeightNormMax:103.964294 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000810 | logitBiasMean:-34.110069 | logitBiasStd:11.926988 | logitBiasMax:-13.076312 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953766 | longDecay:0.967490 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007843 | n_weightStd:0.900351 | n_weightMin:-4.714116 | n_weightMax:4.830600 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.691679 | n_weightNormMin:21.171843 | n_weightNormMax:41.466862 | n_biasesMean:-1.071792 | n_biasesStd:0.789696 | n_biasesMin:-3.829937 | n_biasesMax:1.863419 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.137354 | INN_cerebellumStd:4.241921 | windowWeightsW2:4.34991 (0.60), W4:0.68334 (0.31), W12:-1.70029 (0.02), W8:-1.70836 (0.02), W16:-3.01951 (0.01), W20:-4.14400 (0.01), W24:-5.21583 (0.01), W28:-8.01791 (0.01), W32:-9.46324 (0.01) | topTokens[('Ġwas', 857), ('Ġeating', 794), ('Ġpic', 608), ('.', 542), ('ing', 267), ('Ġwere', 196), ("'", 180), (',', 157), ('Ġshe', 154), ('Ġhe', 148)] | cheekyAvg: 23.880819664001464 | perfectTokens: 88 / 6400 → 1.38% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
2025-04-23 05:46:18 | 300 | LR0.000100 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999450 | AvgLoss:22.905104 | loss:22.902798 | temperature:0.999449 | lR:0.000100 | gradientClip:0.999980 | latestLossDelta:-0.295996 | memoryLength:9.998000 | embedNormMean:14.296206 | embedNormStd:10.080990 | embedNormMax:103.267487 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.778389 | logitWeightNormStd:2.495235 | logitWeightNormMax:103.962273 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000810 | logitBiasMean:-34.109440 | logitBiasStd:11.926833 | logitBiasMax:-13.076120 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953761 | longDecay:0.967488 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007843 | n_weightStd:0.900334 | n_weightMin:-4.714020 | n_weightMax:4.830504 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.691124 | n_weightNormMin:21.171423 | n_weightNormMax:41.466061 | n_biasesMean:-1.071771 | n_biasesStd:0.789680 | n_biasesMin:-3.829841 | n_biasesMax:1.863371 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.137292 | INN_cerebellumStd:4.241829 | windowWeightsW2:4.34981 (0.60), W4:0.68333 (0.31), W12:-1.70026 (0.02), W8:-1.70834 (0.02), W16:-3.01947 (0.01), W20:-4.14391 (0.01), W24:-5.21574 (0.01), W28:-8.01772 (0.01), W32:-9.46305 (0.01) | topTokens[('Ġeating', 1099), ('Ġwas', 1078), ('.', 785), ('Ġpic', 609), ('ing', 416), ('Ġwere', 285), ('Ġhe', 269), ('Ġshe', 268), ('Ġelodie', 241), ('Ġyou', 240)] | cheekyAvg: 22.92765106201172 | perfectTokens: 67 / 6400 → 1.05% |  | remainingTokens: 199699 (99.85%) | TUTOR.py 100
2025-04-23 05:46:57 | 400 | LR0.000100 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999426 | AvgLoss:23.825889 | loss:21.835144 | temperature:0.999425 | lR:0.000100 | gradientClip:0.999740 | latestLossDelta:0.458235 | memoryLength:9.996600 | embedNormMean:14.295929 | embedNormStd:10.080794 | embedNormMax:103.265518 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.776672 | logitWeightNormStd:2.495185 | logitWeightNormMax:103.960243 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000810 | logitBiasMean:-34.108814 | logitBiasStd:11.926681 | logitBiasMax:-13.075924 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953760 | longDecay:0.967486 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007842 | n_weightStd:0.900316 | n_weightMin:-4.713924 | n_weightMax:4.830408 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.690588 | n_weightNormMin:21.171019 | n_weightNormMax:41.465248 | n_biasesMean:-1.071751 | n_biasesStd:0.789665 | n_biasesMin:-3.829746 | n_biasesMax:1.863323 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.137230 | INN_cerebellumStd:4.241737 | windowWeightsW2:4.34972 (0.60), W4:0.68332 (0.31), W12:-1.70024 (0.02), W8:-1.70831 (0.02), W16:-3.01942 (0.01), W20:-4.14381 (0.01), W24:-5.21564 (0.01), W28:-8.01753 (0.01), W32:-9.46286 (0.01) | topTokens[('Ġwas', 1673), ('Ġeating', 1340), ('.', 1077), ('Ġpic', 756), ('ing', 519), ('Ġwere', 402), ('Ġshe', 348), ('Ġhe', 341), (',', 312), ('Ġyou', 312)] | cheekyAvg: 23.689194412231444 | perfectTokens: 94 / 6400 → 1.47% |  | remainingTokens: 199599 (99.80%) | TUTOR.py 100
2025-04-23 05:47:37 | 500 | LR0.000100 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999402 | AvgLoss:22.901090 | loss:21.719604 | temperature:0.999401 | lR:0.000100 | gradientClip:0.999660 | latestLossDelta:-1.687083 | memoryLength:9.995600 | embedNormMean:14.295645 | embedNormStd:10.080598 | embedNormMax:103.263527 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.774933 | logitWeightNormStd:2.495137 | logitWeightNormMax:103.958206 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000811 | logitBiasMean:-34.108189 | logitBiasStd:11.926511 | logitBiasMax:-13.075744 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953758 | longDecay:0.967484 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007842 | n_weightStd:0.900298 | n_weightMin:-4.713828 | n_weightMax:4.830312 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.690022 | n_weightNormMin:21.170595 | n_weightNormMax:41.464443 | n_biasesMean:-1.071730 | n_biasesStd:0.789650 | n_biasesMin:-3.829650 | n_biasesMax:1.863276 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.137168 | INN_cerebellumStd:4.241645 | windowWeightsW2:4.34962 (0.60), W4:0.68330 (0.31), W12:-1.70022 (0.02), W8:-1.70829 (0.02), W16:-3.01937 (0.01), W20:-4.14372 (0.01), W24:-5.21555 (0.01), W28:-8.01734 (0.01), W32:-9.46267 (0.01) | topTokens[('Ġwas', 2004), ('Ġeating', 1638), ('.', 1424), ('Ġpic', 1121), ('ing', 646), ('Ġwere', 519), ('Ġshe', 414), (',', 404), ('Ġhe', 403), ('Ġyou', 378)] | cheekyAvg: 22.926969718933105 | perfectTokens: 69 / 6400 → 1.08% |  | remainingTokens: 199499 (99.75%) | TUTOR.py 100
2025-04-23 05:48:16 | 600 | LR0.000100 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999378 | AvgLoss:22.400775 | loss:22.353939 | temperature:0.999377 | lR:0.000100 | gradientClip:0.999760 | latestLossDelta:-0.558221 | memoryLength:9.994600 | embedNormMean:14.295381 | embedNormStd:10.080404 | embedNormMax:103.261536 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.773102 | logitWeightNormStd:2.495088 | logitWeightNormMax:103.956161 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000811 | logitBiasMean:-34.107559 | logitBiasStd:11.926353 | logitBiasMax:-13.075541 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953756 | longDecay:0.967484 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007842 | n_weightStd:0.900282 | n_weightMin:-4.713732 | n_weightMax:4.830216 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.689455 | n_weightNormMin:21.170185 | n_weightNormMax:41.463657 | n_biasesMean:-1.071709 | n_biasesStd:0.789634 | n_biasesMin:-3.829555 | n_biasesMax:1.863228 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.137106 | INN_cerebellumStd:4.241553 | windowWeightsW2:4.34953 (0.60), W4:0.68329 (0.31), W12:-1.70019 (0.02), W8:-1.70827 (0.02), W16:-3.01932 (0.01), W20:-4.14362 (0.01), W24:-5.21545 (0.01), W28:-8.01715 (0.01), W32:-9.46248 (0.01) | topTokens[('Ġwas', 2784), ('Ġeating', 1851), ('.', 1587), ('Ġpic', 1222), ('ing', 795), ('Ġwere', 630), ('Ġhe', 516), (',', 484), ('Ġshe', 476), ('Ġyou', 460)] | cheekyAvg: 22.44814712524414 | perfectTokens: 119 / 6400 → 1.86% |  | remainingTokens: 199399 (99.70%) | TUTOR.py 100
2025-04-23 05:48:56 | 700 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999354 | AvgLoss:24.106822 | loss:21.757477 | temperature:0.999353 | lR:0.000101 | gradientClip:0.999720 | latestLossDelta:-1.889609 | memoryLength:9.993600 | embedNormMean:14.295100 | embedNormStd:10.080212 | embedNormMax:103.259529 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.771339 | logitWeightNormStd:2.495039 | logitWeightNormMax:103.954132 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000811 | logitBiasMean:-34.106930 | logitBiasStd:11.926197 | logitBiasMax:-13.075365 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953753 | longDecay:0.967483 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007842 | n_weightStd:0.900264 | n_weightMin:-4.713637 | n_weightMax:4.830122 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.688915 | n_weightNormMin:21.169773 | n_weightNormMax:41.462845 | n_biasesMean:-1.071688 | n_biasesStd:0.789619 | n_biasesMin:-3.829460 | n_biasesMax:1.863180 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.137044 | INN_cerebellumStd:4.241461 | windowWeightsW2:4.34943 (0.60), W4:0.68328 (0.31), W12:-1.70017 (0.02), W8:-1.70824 (0.02), W16:-3.01928 (0.01), W20:-4.14353 (0.01), W24:-5.21536 (0.01), W28:-8.01696 (0.01), W32:-9.46229 (0.01) | topTokens[('Ġwas', 3104), ('Ġeating', 2109), ('.', 1978), ('Ġpic', 1526), ('ing', 862), ('Ġwere', 700), (',', 603), ('Ġhe', 601), ('Ġshe', 562), ('Ġyou', 542)] | cheekyAvg: 24.075526542663575 | perfectTokens: 60 / 6400 → 0.94% |  | remainingTokens: 199299 (99.65%) | TUTOR.py 100
2025-04-23 05:49:36 | 800 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999331 | AvgLoss:23.827302 | loss:22.388044 | temperature:0.999330 | lR:0.000101 | gradientClip:0.999660 | latestLossDelta:-2.276744 | memoryLength:9.993000 | embedNormMean:14.294823 | embedNormStd:10.080016 | embedNormMax:103.257538 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.769554 | logitWeightNormStd:2.494989 | logitWeightNormMax:103.952118 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000811 | logitBiasMean:-34.106304 | logitBiasStd:11.926031 | logitBiasMax:-13.075164 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953751 | longDecay:0.967481 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007842 | n_weightStd:0.900246 | n_weightMin:-4.713543 | n_weightMax:4.830027 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.688362 | n_weightNormMin:21.169353 | n_weightNormMax:41.462032 | n_biasesMean:-1.071667 | n_biasesStd:0.789603 | n_biasesMin:-3.829365 | n_biasesMax:1.863132 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.136981 | INN_cerebellumStd:4.241370 | windowWeightsW2:4.34934 (0.60), W4:0.68327 (0.31), W12:-1.70015 (0.02), W8:-1.70822 (0.02), W16:-3.01923 (0.01), W20:-4.14343 (0.01), W24:-5.21526 (0.01), W28:-8.01677 (0.01), W32:-9.46210 (0.01) | topTokens[('Ġwas', 3502), ('.', 2393), ('Ġeating', 2304), ('Ġpic', 1932), ('ing', 969), ('Ġwere', 776), ('Ġhe', 685), (',', 683), ('Ġyou', 622), ('Ġshe', 603)] | cheekyAvg: 23.775761909484864 | perfectTokens: 75 / 6400 → 1.17% |  | remainingTokens: 199199 (99.60%) | TUTOR.py 100
2025-04-23 05:50:15 | 900 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999307 | AvgLoss:22.631958 | loss:22.475986 | temperature:0.999306 | lR:0.000101 | gradientClip:0.999740 | latestLossDelta:-0.679443 | memoryLength:9.993400 | embedNormMean:14.294541 | embedNormStd:10.079820 | embedNormMax:103.255547 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.767731 | logitWeightNormStd:2.494940 | logitWeightNormMax:103.950127 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000811 | logitBiasMean:-34.105671 | logitBiasStd:11.925870 | logitBiasMax:-13.074983 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953751 | longDecay:0.967478 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007842 | n_weightStd:0.900229 | n_weightMin:-4.713448 | n_weightMax:4.829932 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.687799 | n_weightNormMin:21.168938 | n_weightNormMax:41.461246 | n_biasesMean:-1.071646 | n_biasesStd:0.789588 | n_biasesMin:-3.829269 | n_biasesMax:1.863085 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.136919 | INN_cerebellumStd:4.241278 | windowWeightsW2:4.34924 (0.60), W4:0.68326 (0.31), W12:-1.70012 (0.02), W8:-1.70819 (0.02), W16:-3.01918 (0.01), W20:-4.14334 (0.01), W24:-5.21517 (0.01), W28:-8.01658 (0.01), W32:-9.46191 (0.01) | topTokens[('Ġwas', 4009), ('Ġeating', 2776), ('.', 2581), ('Ġpic', 2134), ('ing', 1101), ('Ġwere', 854), (',', 773), ('Ġhe', 755), ('Ġyou', 713), ('Ġshe', 688)] | cheekyAvg: 22.682372055053712 | perfectTokens: 84 / 6400 → 1.31% |  | remainingTokens: 199099 (99.55%) | TUTOR.py 100
2025-04-23 05:50:58 | 1000 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999283 | AvgLoss:22.919447 | loss:22.129723 | temperature:0.999282 | lR:0.000101 | gradientClip:0.999660 | latestLossDelta:-1.934574 | memoryLength:9.990800 | embedNormMean:14.294277 | embedNormStd:10.079623 | embedNormMax:103.253548 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.766045 | logitWeightNormStd:2.494892 | logitWeightNormMax:103.948135 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000811 | logitBiasMean:-34.105038 | logitBiasStd:11.925713 | logitBiasMax:-13.074784 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953748 | longDecay:0.967477 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007841 | n_weightStd:0.900212 | n_weightMin:-4.713353 | n_weightMax:4.829837 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.687231 | n_weightNormMin:21.168518 | n_weightNormMax:41.460434 | n_biasesMean:-1.071626 | n_biasesStd:0.789573 | n_biasesMin:-3.829174 | n_biasesMax:1.863037 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.136857 | INN_cerebellumStd:4.241186 | windowWeightsW2:4.34915 (0.60), W4:0.68324 (0.31), W12:-1.70010 (0.02), W8:-1.70817 (0.02), W16:-3.01913 (0.01), W20:-4.14324 (0.01), W24:-5.21507 (0.01), W28:-8.01639 (0.01), W32:-9.46172 (0.01) | topTokens[('Ġwas', 4488), ('Ġeating', 2925), ('.', 2845), ('Ġpic', 2303), ('ing', 1219), ('Ġwere', 939), ('Ġhe', 863), (',', 829), ('Ġyou', 815), ('Ġshe', 750)] | cheekyAvg: 22.950059700012208 | perfectTokens: 96 / 6400 → 1.50% |  | remainingTokens: 198999 (99.50%) | TUTOR.py 100
2025-04-23 05:51:38 | 1100 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999259 | AvgLoss:23.966942 | loss:21.657486 | temperature:0.999258 | lR:0.000101 | gradientClip:0.999740 | latestLossDelta:-2.351998 | memoryLength:9.990600 | embedNormMean:14.293994 | embedNormStd:10.079429 | embedNormMax:103.251556 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.764252 | logitWeightNormStd:2.494843 | logitWeightNormMax:103.946144 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000812 | logitBiasMean:-34.104416 | logitBiasStd:11.925551 | logitBiasMax:-13.074591 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953745 | longDecay:0.967476 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007841 | n_weightStd:0.900194 | n_weightMin:-4.713257 | n_weightMax:4.829741 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.686701 | n_weightNormMin:21.168116 | n_weightNormMax:41.459633 | n_biasesMean:-1.071605 | n_biasesStd:0.789557 | n_biasesMin:-3.829078 | n_biasesMax:1.862990 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.136795 | INN_cerebellumStd:4.241094 | windowWeightsW2:4.34905 (0.60), W4:0.68323 (0.31), W12:-1.70007 (0.02), W8:-1.70815 (0.02), W16:-3.01908 (0.01), W20:-4.14315 (0.01), W24:-5.21498 (0.01), W28:-8.01620 (0.01), W32:-9.46153 (0.01) | topTokens[('Ġwas', 4867), ('Ġeating', 3124), ('.', 3088), ('Ġpic', 2568), ('ing', 1356), ('Ġwere', 1022), ('Ġhe', 1001), (',', 909), ('Ġyou', 896), ('Ġshe', 807)] | cheekyAvg: 23.899974479675294 | perfectTokens: 90 / 6400 → 1.41% |  | remainingTokens: 198899 (99.45%) | TUTOR.py 100
2025-04-23 05:52:17 | 1200 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999235 | AvgLoss:25.291650 | loss:21.881311 | temperature:0.999234 | lR:0.000101 | gradientClip:0.999620 | latestLossDelta:-3.827533 | memoryLength:9.990200 | embedNormMean:14.293715 | embedNormStd:10.079237 | embedNormMax:103.249550 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.762451 | logitWeightNormStd:2.494793 | logitWeightNormMax:103.944130 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000812 | logitBiasMean:-34.103790 | logitBiasStd:11.925385 | logitBiasMax:-13.074406 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953743 | longDecay:0.967475 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007841 | n_weightStd:0.900176 | n_weightMin:-4.713161 | n_weightMax:4.829645 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.686132 | n_weightNormMin:21.167692 | n_weightNormMax:41.458824 | n_biasesMean:-1.071584 | n_biasesStd:0.789542 | n_biasesMin:-3.828983 | n_biasesMax:1.862942 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.136733 | INN_cerebellumStd:4.241002 | windowWeightsW2:4.34896 (0.60), W4:0.68322 (0.31), W12:-1.70005 (0.02), W8:-1.70812 (0.02), W16:-3.01904 (0.01), W20:-4.14305 (0.01), W24:-5.21488 (0.01), W28:-8.01600 (0.01), W32:-9.46134 (0.01) | topTokens[('Ġwas', 5168), ('.', 3417), ('Ġeating', 3288), ('Ġpic', 3241), ('ing', 1434), ('Ġwere', 1106), ('Ġhe', 1084), ('Ġyou', 979), (',', 963), ('Ġshe', 886)] | cheekyAvg: 25.301045684814454 | perfectTokens: 71 / 6400 → 1.11% |  | remainingTokens: 198799 (99.40%) | TUTOR.py 100
2025-04-23 05:52:55 | 1300 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999211 | AvgLoss:25.259508 | loss:22.890810 | temperature:0.999210 | lR:0.000101 | gradientClip:0.999520 | latestLossDelta:-3.250293 | memoryLength:9.991000 | embedNormMean:14.293439 | embedNormStd:10.079041 | embedNormMax:103.247536 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.760674 | logitWeightNormStd:2.494744 | logitWeightNormMax:103.942116 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000812 | logitBiasMean:-34.103161 | logitBiasStd:11.925229 | logitBiasMax:-13.074205 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953742 | longDecay:0.967474 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007841 | n_weightStd:0.900160 | n_weightMin:-4.713065 | n_weightMax:4.829549 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.685572 | n_weightNormMin:21.167273 | n_weightNormMax:41.458031 | n_biasesMean:-1.071563 | n_biasesStd:0.789526 | n_biasesMin:-3.828887 | n_biasesMax:1.862894 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.136670 | INN_cerebellumStd:4.240910 | windowWeightsW2:4.34886 (0.60), W4:0.68321 (0.31), W12:-1.70003 (0.02), W8:-1.70810 (0.02), W16:-3.01899 (0.01), W20:-4.14296 (0.01), W24:-5.21478 (0.01), W28:-8.01581 (0.01), W32:-9.46115 (0.01) | topTokens[('Ġwas', 5791), ('Ġpic', 4014), ('.', 3620), ('Ġeating', 3422), ('ing', 1497), ('Ġwere', 1243), ('Ġhe', 1156), (',', 1032), ('Ġyou', 1017), ('Ġshe', 951)] | cheekyAvg: 25.111415786743166 | perfectTokens: 78 / 6400 → 1.22% |  | remainingTokens: 198699 (99.35%) | TUTOR.py 100
2025-04-23 05:53:34 | 1400 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999187 | AvgLoss:24.088048 | loss:22.897987 | temperature:0.999187 | lR:0.000101 | gradientClip:0.999580 | latestLossDelta:0.297221 | memoryLength:9.990400 | embedNormMean:14.293171 | embedNormStd:10.078845 | embedNormMax:103.245529 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.758850 | logitWeightNormStd:2.494695 | logitWeightNormMax:103.940117 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000812 | logitBiasMean:-34.102531 | logitBiasStd:11.925072 | logitBiasMax:-13.074027 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953738 | longDecay:0.967471 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007841 | n_weightStd:0.900142 | n_weightMin:-4.712969 | n_weightMax:4.829453 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.685017 | n_weightNormMin:21.166868 | n_weightNormMax:41.457226 | n_biasesMean:-1.071542 | n_biasesStd:0.789511 | n_biasesMin:-3.828792 | n_biasesMax:1.862846 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.136607 | INN_cerebellumStd:4.240819 | windowWeightsW2:4.34876 (0.60), W4:0.68320 (0.31), W12:-1.70000 (0.02), W8:-1.70807 (0.02), W16:-3.01894 (0.01), W20:-4.14286 (0.01), W24:-5.21469 (0.01), W28:-8.01562 (0.01), W32:-9.46095 (0.01) | topTokens[('Ġwas', 6347), ('Ġpic', 4315), ('.', 3902), ('Ġeating', 3816), ('ing', 1585), ('Ġwere', 1345), ('Ġhe', 1220), (',', 1129), ('Ġyou', 1100), ('Ġshe', 1040)] | cheekyAvg: 23.964338302612305 | perfectTokens: 87 / 6400 → 1.36% |  | remainingTokens: 198599 (99.30%) | TUTOR.py 100
2025-04-23 05:54:14 | 1500 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999164 | AvgLoss:24.460668 | loss:24.231081 | temperature:0.999163 | lR:0.000101 | gradientClip:0.999600 | latestLossDelta:2.156937 | memoryLength:9.990600 | embedNormMean:14.292890 | embedNormStd:10.078648 | embedNormMax:103.243523 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.757088 | logitWeightNormStd:2.494646 | logitWeightNormMax:103.938103 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000812 | logitBiasMean:-34.101898 | logitBiasStd:11.924902 | logitBiasMax:-13.073827 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953736 | longDecay:0.967469 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007841 | n_weightStd:0.900124 | n_weightMin:-4.712874 | n_weightMax:4.829359 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.684475 | n_weightNormMin:21.166445 | n_weightNormMax:41.456406 | n_biasesMean:-1.071522 | n_biasesStd:0.789496 | n_biasesMin:-3.828697 | n_biasesMax:1.862799 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.136544 | INN_cerebellumStd:4.240726 | windowWeightsW2:4.34867 (0.60), W4:0.68319 (0.31), W12:-1.69998 (0.02), W8:-1.70805 (0.02), W16:-3.01889 (0.01), W20:-4.14276 (0.01), W24:-5.21459 (0.01), W28:-8.01543 (0.01), W32:-9.46076 (0.01) | topTokens[('Ġwas', 6592), ('Ġpic', 4547), ('Ġeating', 4118), ('.', 4091), ('ing', 1709), ('Ġwere', 1419), ('Ġhe', 1293), (',', 1192), ('Ġyou', 1160), ('Ġshe', 1153)] | cheekyAvg: 24.482023544311524 | perfectTokens: 67 / 6400 → 1.05% |  | remainingTokens: 198499 (99.25%) | TUTOR.py 100
2025-04-23 05:54:54 | 1600 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999140 | AvgLoss:22.643600 | loss:21.391174 | temperature:0.999139 | lR:0.000101 | gradientClip:0.999500 | latestLossDelta:-1.693744 | memoryLength:9.990000 | embedNormMean:14.292608 | embedNormStd:10.078453 | embedNormMax:103.241486 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.755379 | logitWeightNormStd:2.494596 | logitWeightNormMax:103.936081 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000812 | logitBiasMean:-34.101273 | logitBiasStd:11.924745 | logitBiasMax:-13.073650 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953735 | longDecay:0.967468 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007841 | n_weightStd:0.902082 | n_weightMin:-4.712780 | n_weightMax:4.829264 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.683910 | n_weightNormMin:21.166033 | n_weightNormMax:41.455616 | n_biasesMean:-1.071501 | n_biasesStd:0.789480 | n_biasesMin:-3.828602 | n_biasesMax:1.862751 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.136482 | INN_cerebellumStd:4.240635 | windowWeightsW2:4.34857 (0.60), W4:0.68317 (0.31), W12:-1.69995 (0.02), W8:-1.70803 (0.02), W16:-3.01885 (0.01), W20:-4.14267 (0.01), W24:-5.21450 (0.01), W28:-8.01524 (0.01), W32:-9.46057 (0.01) | topTokens[('Ġwas', 6950), ('Ġpic', 4816), ('.', 4429), ('Ġeating', 4429), ('ing', 1915), ('Ġwere', 1551), ('Ġhe', 1349), (',', 1241), ('Ġshe', 1229), ('Ġyou', 1221)] | cheekyAvg: 22.59383918762207 | perfectTokens: 87 / 6400 → 1.36% |  | remainingTokens: 198399 (99.20%) | TUTOR.py 100
2025-04-23 05:55:33 | 1700 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999116 | AvgLoss:24.213497 | loss:23.468147 | temperature:0.999115 | lR:0.000101 | gradientClip:0.999480 | latestLossDelta:-2.259266 | memoryLength:9.991200 | embedNormMean:14.292336 | embedNormStd:10.078261 | embedNormMax:103.239464 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.753548 | logitWeightNormStd:2.494547 | logitWeightNormMax:103.934059 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000813 | logitBiasMean:-34.100639 | logitBiasStd:11.924591 | logitBiasMax:-13.073450 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953733 | longDecay:0.967468 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007840 | n_weightStd:0.900090 | n_weightMin:-4.712685 | n_weightMax:4.829169 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.683340 | n_weightNormMin:21.165623 | n_weightNormMax:41.454811 | n_biasesMean:-1.071480 | n_biasesStd:0.789465 | n_biasesMin:-3.828506 | n_biasesMax:1.862703 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.136419 | INN_cerebellumStd:4.240543 | windowWeightsW2:4.34848 (0.60), W4:0.68316 (0.31), W12:-1.69993 (0.02), W8:-1.70800 (0.02), W16:-3.01880 (0.01), W20:-4.14257 (0.01), W24:-5.21440 (0.01), W28:-8.01505 (0.01), W32:-9.46038 (0.01) | topTokens[('Ġwas', 7293), ('Ġpic', 5401), ('Ġeating', 4904), ('.', 4648), ('ing', 2009), ('Ġwere', 1642), ('Ġhe', 1415), (',', 1342), ('Ġshe', 1323), ('Ġyou', 1265)] | cheekyAvg: 24.350897674560546 | perfectTokens: 66 / 6400 → 1.03% |  | remainingTokens: 198299 (99.15%) | TUTOR.py 100
2025-04-23 05:56:13 | 1800 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999092 | AvgLoss:22.958787 | loss:22.685638 | temperature:0.999091 | lR:0.000101 | gradientClip:0.999300 | latestLossDelta:-0.957385 | memoryLength:9.992600 | embedNormMean:14.292065 | embedNormStd:10.078065 | embedNormMax:103.237457 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000154 | logitWeightNormMean:91.751770 | logitWeightNormStd:2.494498 | logitWeightNormMax:103.932030 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000813 | logitBiasMean:-34.100010 | logitBiasStd:11.924417 | logitBiasMax:-13.073260 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953730 | longDecay:0.967466 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007840 | n_weightStd:0.900072 | n_weightMin:-4.712590 | n_weightMax:4.829074 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.682808 | n_weightNormMin:21.165199 | n_weightNormMax:41.453995 | n_biasesMean:-1.071459 | n_biasesStd:0.789449 | n_biasesMin:-3.828411 | n_biasesMax:1.862656 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.136356 | INN_cerebellumStd:4.240451 | windowWeightsW2:4.34838 (0.60), W4:0.68315 (0.31), W12:-1.69991 (0.02), W8:-1.70798 (0.02), W16:-3.01875 (0.01), W20:-4.14248 (0.01), W24:-5.21431 (0.01), W28:-8.01486 (0.01), W32:-9.46019 (0.01) | topTokens[('Ġwas', 7666), ('Ġpic', 5576), ('Ġeating', 5246), ('.', 4985), ('ing', 2121), ('Ġwere', 1753), ('Ġhe', 1514), (',', 1420), ('Ġshe', 1377), ('Ġyou', 1337)] | cheekyAvg: 22.988824920654295 | perfectTokens: 87 / 6400 → 1.36% |  | remainingTokens: 198199 (99.10%) | TUTOR.py 100
--- 2025-04-23 05:57:23 --- 
[babyllm] right, last time i got to step 105056... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 105056! what am i learning today?
[charis]2025-04-23 05:58:23 | 100 | LR0.000101 | loss:21.215868 | gradNorm:0.000000 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999053 | AvgLoss:23.140357 | temperature:0.999053 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:0.030938 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.291608 | embedNormStd:10.077747 | embedNormMax:103.234245 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:16.305538 | logitWeightNormMean:91.748878 | logitWeightNormStd:2.494419 | logitWeightNormMax:103.928673 | logitWeightSparsity:0.000009 | logitWeightDrift:41.047863 | logitBiasMean:-34.098995 | logitBiasStd:11.924159 | logitBiasMax:-13.072949 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953728 | longDecay:0.967463 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007840 | n_weightStd:0.900044 | n_weightMin:-4.712435 | n_weightMax:4.828919 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.681885 | n_weightNormMin:21.164526 | n_weightNormMax:41.452702 | n_biasesMean:-1.071425 | n_biasesStd:0.789425 | n_biasesMin:-3.828256 | n_biasesMax:1.862578 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.136257 | INN_cerebellumStd:4.240302 | windowWeightsW2:4.34823 (0.60), W4:0.68313 (0.31), W12:-1.69987 (0.02), W8:-1.70794 (0.02), W16:-3.01867 (0.01), W20:-4.14232 (0.01), W24:-5.21415 (0.01), W28:-8.01455 (0.01), W32:-9.45988 (0.01) | topTokens[('Ġwas', 404), ('.', 325), ('Ġpic', 305), ('Ġeating', 209), ('ing', 106), ('Ġwere', 104), (',', 90), ('Ġhe', 85), ('Ġbutt', 82), ('Ġyou', 76)] | cheekyAvg: 22.673475639492857 | perfectTokens: 80 / 6400 → 1.25% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
2025-04-23 05:59:02 | 200 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999030 | AvgLoss:22.908435 | loss:22.980532 | temperature:0.999029 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:1.877168 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.291340 | embedNormStd:10.077551 | embedNormMax:103.232254 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000155 | logitWeightNormMean:91.747078 | logitWeightNormStd:2.494370 | logitWeightNormMax:103.926689 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000813 | logitBiasMean:-34.098366 | logitBiasStd:11.924004 | logitBiasMax:-13.072755 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953726 | longDecay:0.967461 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007840 | n_weightStd:0.900026 | n_weightMin:-4.712339 | n_weightMax:4.828824 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.681345 | n_weightNormMin:21.164106 | n_weightNormMax:41.451900 | n_biasesMean:-1.071404 | n_biasesStd:0.789409 | n_biasesMin:-3.828161 | n_biasesMax:1.862531 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.136195 | INN_cerebellumStd:4.240210 | windowWeightsW2:4.34813 (0.60), W4:0.68312 (0.31), W12:-1.69984 (0.02), W8:-1.70792 (0.02), W16:-3.01863 (0.01), W20:-4.14223 (0.01), W24:-5.21406 (0.01), W28:-8.01436 (0.01), W32:-9.45969 (0.01) | topTokens[('Ġwas', 862), ('.', 684), ('Ġeating', 559), ('Ġpic', 422), (',', 210), ('ing', 200), ('Ġwere', 193), ('Ġhe', 179), ('Ġyou', 162), ('Ġbutt', 159)] | cheekyAvg: 22.951826705932618 | perfectTokens: 110 / 6400 → 1.72% |  | remainingTokens: 199799 (99.90%) | TUTOR.py 100
2025-04-23 05:59:44 | 300 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.999006 | AvgLoss:22.895165 | loss:22.328381 | temperature:0.999005 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:-0.152965 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.291058 | embedNormStd:10.077354 | embedNormMax:103.230247 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000155 | logitWeightNormMean:91.745262 | logitWeightNormStd:2.494320 | logitWeightNormMax:103.924698 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000813 | logitBiasMean:-34.097729 | logitBiasStd:11.923841 | logitBiasMax:-13.072572 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953723 | longDecay:0.967461 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007840 | n_weightStd:0.900008 | n_weightMin:-4.712244 | n_weightMax:4.828727 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.680788 | n_weightNormMin:21.163704 | n_weightNormMax:41.451084 | n_biasesMean:-1.071383 | n_biasesStd:0.789394 | n_biasesMin:-3.828066 | n_biasesMax:1.862483 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.136133 | INN_cerebellumStd:4.240118 | windowWeightsW2:4.34804 (0.60), W4:0.68311 (0.31), W12:-1.69982 (0.02), W8:-1.70789 (0.02), W16:-3.01858 (0.01), W20:-4.14213 (0.01), W24:-5.21396 (0.01), W28:-8.01417 (0.01), W32:-9.45950 (0.01) | topTokens[('Ġwas', 1413), ('.', 831), ('Ġeating', 722), ('Ġpic', 554), ('ing', 417), (',', 309), ('Ġwere', 299), ('Ġhe', 254), ('Ġshe', 249), ('Ġelodie', 224)] | cheekyAvg: 22.91544651031494 | perfectTokens: 83 / 6400 → 1.30% |  | remainingTokens: 199699 (99.85%) | TUTOR.py 100
2025-04-23 06:00:22 | 400 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.998982 | AvgLoss:23.766414 | loss:23.147049 | temperature:0.998981 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:-2.142893 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.290775 | embedNormStd:10.077163 | embedNormMax:103.228249 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000155 | logitWeightNormMean:91.743553 | logitWeightNormStd:2.494271 | logitWeightNormMax:103.922699 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000813 | logitBiasMean:-34.097099 | logitBiasStd:11.923676 | logitBiasMax:-13.072370 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953721 | longDecay:0.967459 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007840 | n_weightStd:0.899992 | n_weightMin:-4.712147 | n_weightMax:4.828631 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.680225 | n_weightNormMin:21.163279 | n_weightNormMax:41.450272 | n_biasesMean:-1.071362 | n_biasesStd:0.789378 | n_biasesMin:-3.827970 | n_biasesMax:1.862435 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.136070 | INN_cerebellumStd:4.240026 | windowWeightsW2:4.34794 (0.60), W4:0.68309 (0.31), W12:-1.69980 (0.02), W8:-1.70787 (0.02), W16:-3.01853 (0.01), W20:-4.14204 (0.01), W24:-5.21387 (0.01), W28:-8.01398 (0.01), W32:-9.45931 (0.01) | topTokens[('Ġwas', 1834), ('.', 1161), ('Ġeating', 1079), ('Ġpic', 830), ('ing', 522), (',', 418), ('Ġwere', 393), ('Ġshe', 356), ('Ġyou', 305), ('Ġhe', 295)] | cheekyAvg: 23.844940757751466 | perfectTokens: 108 / 6400 → 1.69% |  | remainingTokens: 199599 (99.80%) | TUTOR.py 100
2025-04-23 06:01:01 | 500 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.998958 | AvgLoss:23.397178 | loss:24.554495 | temperature:0.998957 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:3.813948 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.290504 | embedNormStd:10.076967 | embedNormMax:103.226273 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000155 | logitWeightNormMean:91.741776 | logitWeightNormStd:2.494222 | logitWeightNormMax:103.920685 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000814 | logitBiasMean:-34.096470 | logitBiasStd:11.923517 | logitBiasMax:-13.072193 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953720 | longDecay:0.967456 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007839 | n_weightStd:0.899974 | n_weightMin:-4.712052 | n_weightMax:4.828536 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.679655 | n_weightNormMin:21.162865 | n_weightNormMax:41.449482 | n_biasesMean:-1.071342 | n_biasesStd:0.789362 | n_biasesMin:-3.827875 | n_biasesMax:1.862388 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.136009 | INN_cerebellumStd:4.239934 | windowWeightsW2:4.34785 (0.60), W4:0.68308 (0.31), W12:-1.69977 (0.02), W8:-1.70784 (0.02), W16:-3.01848 (0.01), W20:-4.14194 (0.01), W24:-5.21377 (0.01), W28:-8.01379 (0.01), W32:-9.45912 (0.01) | topTokens[('Ġwas', 2418), ('.', 1405), ('Ġeating', 1300), ('Ġpic', 1234), ('ing', 709), (',', 521), ('Ġwere', 488), ('Ġshe', 430), ('Ġyou', 382), ('Ġhe', 347)] | cheekyAvg: 23.388777236938477 | perfectTokens: 110 / 6400 → 1.72% |  | remainingTokens: 199499 (99.75%) | TUTOR.py 100
2025-04-23 06:01:41 | 600 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.998934 | AvgLoss:33.325060 | loss:27.825386 | temperature:0.998933 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:-3.459000 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.290230 | embedNormStd:10.076770 | embedNormMax:103.224258 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000155 | logitWeightNormMean:91.739960 | logitWeightNormStd:2.494173 | logitWeightNormMax:103.918671 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000814 | logitBiasMean:-34.095837 | logitBiasStd:11.923354 | logitBiasMax:-13.071992 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953716 | longDecay:0.967455 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007839 | n_weightStd:0.899956 | n_weightMin:-4.711957 | n_weightMax:4.828442 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.679127 | n_weightNormMin:21.162453 | n_weightNormMax:41.448666 | n_biasesMean:-1.071321 | n_biasesStd:0.789347 | n_biasesMin:-3.827780 | n_biasesMax:1.862340 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.135947 | INN_cerebellumStd:4.239843 | windowWeightsW2:4.34775 (0.60), W4:0.68307 (0.31), W12:-1.69975 (0.02), W8:-1.70782 (0.02), W16:-3.01844 (0.01), W20:-4.14185 (0.01), W24:-5.21368 (0.01), W28:-8.01360 (0.01), W32:-9.45893 (0.01) | topTokens[('Ġwas', 2668), ('.', 1736), ('Ġeating', 1552), ('Ġpic', 1373), ('ing', 847), (',', 577), ('Ġwere', 530), ("'", 513), ('Ġshe', 490), ('Ġyou', 460)] | cheekyAvg: 33.11698631286621 | perfectTokens: 39 / 6400 → 0.61% |  | remainingTokens: 199399 (99.70%) | TUTOR.py 100
2025-04-23 06:02:20 | 700 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.998910 | AvgLoss:31.329450 | loss:27.208321 | temperature:0.998909 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:6.154349 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.289950 | embedNormStd:10.076572 | embedNormMax:103.222260 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000155 | logitWeightNormMean:91.738174 | logitWeightNormStd:2.494123 | logitWeightNormMax:103.916656 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000814 | logitBiasMean:-34.095207 | logitBiasStd:11.923188 | logitBiasMax:-13.071814 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953715 | longDecay:0.967454 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007839 | n_weightStd:0.899939 | n_weightMin:-4.711863 | n_weightMax:4.828347 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.678553 | n_weightNormMin:21.162031 | n_weightNormMax:41.447853 | n_biasesMean:-1.071300 | n_biasesStd:0.789331 | n_biasesMin:-3.827684 | n_biasesMax:1.862292 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.135884 | INN_cerebellumStd:4.239751 | windowWeightsW2:4.34766 (0.60), W4:0.68306 (0.31), W12:-1.69973 (0.02), W8:-1.70780 (0.02), W16:-3.01839 (0.01), W20:-4.14175 (0.01), W24:-5.21358 (0.01), W28:-8.01341 (0.01), W32:-9.45874 (0.01) | topTokens[('Ġwas', 2912), ('.', 2147), ('Ġeating', 1562), ('Ġpic', 1485), ('ing', 952), ("'", 689), (',', 636), ('Ġwere', 595), ('Ġyou', 560), ('Ġcharis', 518)] | cheekyAvg: 31.084047698974608 | perfectTokens: 45 / 6400 → 0.70% |  | remainingTokens: 199299 (99.65%) | TUTOR.py 100
2025-04-23 06:02:59 | 800 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.998887 | AvgLoss:33.872630 | loss:26.153309 | temperature:0.998886 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:-2.598490 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.289665 | embedNormStd:10.076378 | embedNormMax:103.220253 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000155 | logitWeightNormMean:91.736366 | logitWeightNormStd:2.494074 | logitWeightNormMax:103.914650 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000814 | logitBiasMean:-34.094574 | logitBiasStd:11.923030 | logitBiasMax:-13.071615 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953713 | longDecay:0.967453 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007839 | n_weightStd:0.899921 | n_weightMin:-4.711768 | n_weightMax:4.828252 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.677988 | n_weightNormMin:21.161619 | n_weightNormMax:41.447067 | n_biasesMean:-1.071279 | n_biasesStd:0.789316 | n_biasesMin:-3.827589 | n_biasesMax:1.862245 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.135823 | INN_cerebellumStd:4.239659 | windowWeightsW2:4.34756 (0.60), W4:0.68305 (0.31), W12:-1.69970 (0.02), W8:-1.70777 (0.02), W16:-3.01834 (0.01), W20:-4.14166 (0.01), W24:-5.21349 (0.01), W28:-8.01322 (0.01), W32:-9.45855 (0.01) | topTokens[('Ġwas', 3256), ('.', 2574), ('Ġpic', 1685), ('Ġeating', 1628), ('ing', 1046), ("'", 962), (',', 735), ('Ġcharis', 683), ('Ġyou', 657), ('Ġwere', 647)] | cheekyAvg: 33.39014060974121 | perfectTokens: 41 / 6400 → 0.64% |  | remainingTokens: 199199 (99.60%) | TUTOR.py 100
2025-04-23 06:03:38 | 900 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.998863 | AvgLoss:33.200073 | loss:26.027779 | temperature:0.998862 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:-2.184629 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.289399 | embedNormStd:10.076185 | embedNormMax:103.218239 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000155 | logitWeightNormMean:91.734581 | logitWeightNormStd:2.494025 | logitWeightNormMax:103.912621 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000814 | logitBiasMean:-34.093941 | logitBiasStd:11.922866 | logitBiasMax:-13.071424 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953711 | longDecay:0.967451 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007839 | n_weightStd:0.899904 | n_weightMin:-4.711672 | n_weightMax:4.828156 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.677444 | n_weightNormMin:21.161194 | n_weightNormMax:41.446251 | n_biasesMean:-1.071259 | n_biasesStd:0.789300 | n_biasesMin:-3.827493 | n_biasesMax:1.862197 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.135760 | INN_cerebellumStd:4.239567 | windowWeightsW2:4.34747 (0.60), W4:0.68303 (0.31), W12:-1.69968 (0.02), W8:-1.70775 (0.02), W16:-3.01829 (0.01), W20:-4.14156 (0.01), W24:-5.21339 (0.01), W28:-8.01303 (0.01), W32:-9.45836 (0.01) | topTokens[('Ġwas', 3368), ('.', 3308), ('Ġpic', 1761), ('Ġeating', 1679), ("'", 1405), ('ing', 1155), (',', 871), ('Ġcharis', 809), ('Ġyou', 757), ('Ġwere', 681)] | cheekyAvg: 32.92521175384522 | perfectTokens: 51 / 6400 → 0.80% |  | remainingTokens: 199099 (99.55%) | TUTOR.py 100
2025-04-23 06:04:22 | 1000 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.998839 | AvgLoss:29.431687 | loss:28.220034 | temperature:0.998838 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:-1.109662 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.289119 | embedNormStd:10.075988 | embedNormMax:103.216232 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000155 | logitWeightNormMean:91.732872 | logitWeightNormStd:2.493976 | logitWeightNormMax:103.910599 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000814 | logitBiasMean:-34.093307 | logitBiasStd:11.922700 | logitBiasMax:-13.071234 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953708 | longDecay:0.967448 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007839 | n_weightStd:0.899886 | n_weightMin:-4.711576 | n_weightMax:4.828061 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.676888 | n_weightNormMin:21.160791 | n_weightNormMax:41.445431 | n_biasesMean:-1.071237 | n_biasesStd:0.789285 | n_biasesMin:-3.827398 | n_biasesMax:1.862149 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.135698 | INN_cerebellumStd:4.239476 | windowWeightsW2:4.34737 (0.60), W4:0.68302 (0.31), W12:-1.69965 (0.02), W8:-1.70773 (0.02), W16:-3.01824 (0.01), W20:-4.14147 (0.01), W24:-5.21329 (0.01), W28:-8.01283 (0.01), W32:-9.45817 (0.01) | topTokens[('.', 3428), ('Ġwas', 3393), ('Ġpic', 1857), ('Ġeating', 1684), ("'", 1628), ('ing', 1274), (',', 946), ('Ġcharis', 879), ('Ġyou', 833), ('s', 741)] | cheekyAvg: 29.177386703491212 | perfectTokens: 30 / 6400 → 0.47% |  | remainingTokens: 198999 (99.50%) | TUTOR.py 100
2025-04-23 06:05:02 | 1100 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.998815 | AvgLoss:34.151686 | loss:27.241072 | temperature:0.998814 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:-1.757960 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.288839 | embedNormStd:10.075791 | embedNormMax:103.214218 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000155 | logitWeightNormMean:91.731056 | logitWeightNormStd:2.493926 | logitWeightNormMax:103.908562 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000815 | logitBiasMean:-34.092682 | logitBiasStd:11.922541 | logitBiasMax:-13.071036 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953706 | longDecay:0.967448 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007839 | n_weightStd:0.899869 | n_weightMin:-4.711481 | n_weightMax:4.827964 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.676325 | n_weightNormMin:21.160368 | n_weightNormMax:41.444637 | n_biasesMean:-1.071217 | n_biasesStd:0.789269 | n_biasesMin:-3.827303 | n_biasesMax:1.862102 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.135636 | INN_cerebellumStd:4.239384 | windowWeightsW2:4.34727 (0.60), W4:0.68301 (0.31), W12:-1.69963 (0.02), W8:-1.70770 (0.02), W16:-3.01820 (0.01), W20:-4.14137 (0.01), W24:-5.21320 (0.01), W28:-8.01264 (0.01), W32:-9.45798 (0.01) | topTokens[('.', 3784), ('Ġwas', 3417), ("'", 2155), ('Ġpic', 1882), ('Ġeating', 1770), ('ing', 1338), ('Ġyou', 1052), (',', 1042), ('Ġcharis', 952), ('s', 854)] | cheekyAvg: 33.790497589111325 | perfectTokens: 11 / 6400 → 0.17% |  | remainingTokens: 198899 (99.45%) | TUTOR.py 100
2025-04-23 06:05:41 | 1200 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.998791 | AvgLoss:34.391145 | loss:26.045660 | temperature:0.998790 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:-3.275589 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.288558 | embedNormStd:10.075594 | embedNormMax:103.212189 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000155 | logitWeightNormMean:91.729271 | logitWeightNormStd:2.493877 | logitWeightNormMax:103.906502 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000815 | logitBiasMean:-34.092049 | logitBiasStd:11.922375 | logitBiasMax:-13.070857 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953705 | longDecay:0.967446 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007838 | n_weightStd:0.899851 | n_weightMin:-4.711384 | n_weightMax:4.827868 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.675756 | n_weightNormMin:21.159946 | n_weightNormMax:41.443832 | n_biasesMean:-1.071195 | n_biasesStd:0.789254 | n_biasesMin:-3.827207 | n_biasesMax:1.862054 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.135573 | INN_cerebellumStd:4.239292 | windowWeightsW2:4.34718 (0.60), W4:0.68300 (0.31), W12:-1.69961 (0.02), W8:-1.70768 (0.02), W16:-3.01815 (0.01), W20:-4.14127 (0.01), W24:-5.21310 (0.01), W28:-8.01245 (0.01), W32:-9.45778 (0.01) | topTokens[('.', 4280), ('Ġwas', 3502), ("'", 2421), ('Ġpic', 2110), ('Ġeating', 1937), ('ing', 1421), ('Ġyou', 1215), (',', 1160), ('Ġcharis', 1017), ('s', 912)] | cheekyAvg: 34.002770233154294 | perfectTokens: 44 / 6400 → 0.69% |  | remainingTokens: 198799 (99.40%) | TUTOR.py 100
2025-04-23 06:06:21 | 1300 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.998767 | AvgLoss:32.646106 | loss:30.294510 | temperature:0.998766 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:3.184010 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.288292 | embedNormStd:10.075399 | embedNormMax:103.210159 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000155 | logitWeightNormMean:91.727470 | logitWeightNormStd:2.493827 | logitWeightNormMax:103.904472 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000815 | logitBiasMean:-34.091412 | logitBiasStd:11.922208 | logitBiasMax:-13.070656 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953703 | longDecay:0.967445 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007838 | n_weightStd:0.899833 | n_weightMin:-4.711289 | n_weightMax:4.827773 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.675222 | n_weightNormMin:21.159538 | n_weightNormMax:41.443016 | n_biasesMean:-1.071175 | n_biasesStd:0.789238 | n_biasesMin:-3.827112 | n_biasesMax:1.862006 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.135511 | INN_cerebellumStd:4.239200 | windowWeightsW2:4.34708 (0.60), W4:0.68299 (0.31), W12:-1.69958 (0.02), W8:-1.70765 (0.02), W16:-3.01810 (0.01), W20:-4.14118 (0.01), W24:-5.21301 (0.01), W28:-8.01226 (0.01), W32:-9.45759 (0.01) | topTokens[('.', 4648), ('Ġwas', 3602), ("'", 2660), ('Ġpic', 2112), ('Ġeating', 1950), ('ing', 1518), ('Ġyou', 1493), (',', 1252), ('Ġcharis', 1104), ('s', 1062)] | cheekyAvg: 32.495930137634275 | perfectTokens: 23 / 6400 → 0.36% |  | remainingTokens: 198699 (99.35%) | TUTOR.py 100
2025-04-23 06:07:00 | 1400 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.998744 | AvgLoss:32.743098 | loss:25.133659 | temperature:0.998743 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:-5.995005 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.288008 | embedNormStd:10.075207 | embedNormMax:103.208145 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000155 | logitWeightNormMean:91.725647 | logitWeightNormStd:2.493779 | logitWeightNormMax:103.902412 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000815 | logitBiasMean:-34.090778 | logitBiasStd:11.922050 | logitBiasMax:-13.070479 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953700 | longDecay:0.967444 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007838 | n_weightStd:0.899817 | n_weightMin:-4.711195 | n_weightMax:4.827679 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.674648 | n_weightNormMin:21.159113 | n_weightNormMax:41.442215 | n_biasesMean:-1.071154 | n_biasesStd:0.789223 | n_biasesMin:-3.827017 | n_biasesMax:1.861959 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.135448 | INN_cerebellumStd:4.239108 | windowWeightsW2:4.34699 (0.60), W4:0.68298 (0.31), W12:-1.69956 (0.02), W8:-1.70763 (0.02), W16:-3.01805 (0.01), W20:-4.14108 (0.01), W24:-5.21291 (0.01), W28:-8.01207 (0.01), W32:-9.45740 (0.01) | topTokens[('.', 5056), ('Ġwas', 3618), ("'", 3041), ('Ġpic', 2283), ('Ġeating', 1954), ('Ġyou', 1593), ('ing', 1573), (',', 1337), ('Ġcharis', 1163), ('s', 1161)] | cheekyAvg: 32.38087875366211 | perfectTokens: 27 / 6400 → 0.42% |  | remainingTokens: 198599 (99.30%) | TUTOR.py 100
2025-04-23 06:07:38 | 1500 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.998720 | AvgLoss:31.592253 | loss:25.694536 | temperature:0.998719 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:-4.843306 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.287727 | embedNormStd:10.075009 | embedNormMax:103.206116 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000155 | logitWeightNormMean:91.723885 | logitWeightNormStd:2.493729 | logitWeightNormMax:103.900391 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000815 | logitBiasMean:-34.090141 | logitBiasStd:11.921880 | logitBiasMax:-13.070278 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953698 | longDecay:0.967441 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007838 | n_weightStd:0.899799 | n_weightMin:-4.711100 | n_weightMax:4.827584 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.674088 | n_weightNormMin:21.158703 | n_weightNormMax:41.441410 | n_biasesMean:-1.071133 | n_biasesStd:0.789208 | n_biasesMin:-3.826921 | n_biasesMax:1.861911 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.135386 | INN_cerebellumStd:4.239017 | windowWeightsW2:4.34689 (0.60), W4:0.68296 (0.31), W12:-1.69953 (0.02), W8:-1.70761 (0.02), W16:-3.01801 (0.01), W20:-4.14099 (0.01), W24:-5.21282 (0.01), W28:-8.01188 (0.01), W32:-9.45721 (0.01) | topTokens[('.', 5567), ("'", 3648), ('Ġwas', 3631), ('Ġpic', 2323), ('Ġeating', 1967), ('Ġyou', 1849), ('ing', 1754), (',', 1416), ('s', 1245), ('Ġcharis', 1235)] | cheekyAvg: 31.292916030883788 | perfectTokens: 35 / 6400 → 0.55% |  | remainingTokens: 198499 (99.25%) | TUTOR.py 100
2025-04-23 06:08:15 | 1600 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.998696 | AvgLoss:33.300545 | loss:24.270523 | temperature:0.998695 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:-5.740673 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.287454 | embedNormStd:10.074813 | embedNormMax:103.204102 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000155 | logitWeightNormMean:91.722160 | logitWeightNormStd:2.493680 | logitWeightNormMax:103.898376 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000815 | logitBiasMean:-34.089508 | logitBiasStd:11.921714 | logitBiasMax:-13.070093 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953697 | longDecay:0.967440 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007838 | n_weightStd:0.899781 | n_weightMin:-4.711005 | n_weightMax:4.827489 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.673538 | n_weightNormMin:21.158283 | n_weightNormMax:41.440605 | n_biasesMean:-1.071112 | n_biasesStd:0.789192 | n_biasesMin:-3.826826 | n_biasesMax:1.861863 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.135323 | INN_cerebellumStd:4.238925 | windowWeightsW2:4.34680 (0.60), W4:0.68295 (0.31), W12:-1.69951 (0.02), W8:-1.70758 (0.02), W16:-3.01796 (0.01), W20:-4.14089 (0.01), W24:-5.21272 (0.01), W28:-8.01169 (0.01), W32:-9.45702 (0.01) | topTokens[('.', 5838), ("'", 4068), ('Ġwas', 3714), ('Ġpic', 2435), ('Ġyou', 2034), ('Ġeating', 1970), ('ing', 1876), ('s', 1584), (',', 1501), ('Ġcharis', 1399)] | cheekyAvg: 32.86870769500732 | perfectTokens: 25 / 6400 → 0.39% |  | remainingTokens: 198399 (99.20%) | TUTOR.py 100
2025-04-23 06:08:55 | 1700 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.998672 | AvgLoss:31.068641 | loss:25.477102 | temperature:0.998671 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:4.383263 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.287180 | embedNormStd:10.074615 | embedNormMax:103.202103 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000155 | logitWeightNormMean:91.720329 | logitWeightNormStd:2.493630 | logitWeightNormMax:103.896385 | logitWeightSparsity:0.000009 | logitWeightDrift:0.000815 | logitBiasMean:-34.088879 | logitBiasStd:11.921554 | logitBiasMax:-13.069898 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953692 | longDecay:0.967438 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007838 | n_weightStd:0.899764 | n_weightMin:-4.710909 | n_weightMax:4.827393 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.672983 | n_weightNormMin:21.157869 | n_weightNormMax:41.439785 | n_biasesMean:-1.071091 | n_biasesStd:0.789177 | n_biasesMin:-3.826730 | n_biasesMax:1.861815 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.135260 | INN_cerebellumStd:4.238833 | windowWeightsW2:4.34670 (0.60), W4:0.68294 (0.31), W12:-1.69949 (0.02), W8:-1.70756 (0.02), W16:-3.01791 (0.01), W20:-4.14080 (0.01), W24:-5.21263 (0.01), W28:-8.01150 (0.01), W32:-9.45683 (0.01) | topTokens[('.', 6332), ("'", 4281), ('Ġwas', 3741), ('Ġpic', 2566), ('Ġyou', 2176), ('Ġeating', 1998), ('ing', 1935), ('s', 1634), (',', 1595), ('Ġcharis', 1527)] | cheekyAvg: 30.831438522338868 | perfectTokens: 29 / 6400 → 0.45% |  | remainingTokens: 198299 (99.15%) | TUTOR.py 100
--- 2025-04-23 06:09:14 --- 
[babyllm] right, last time i got to step 106783... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 106783! what am i learning today?
[charis]2025-04-23 06:10:14 | 100 | LR0.000101 | loss:25.449427 | gradNorm:0.000000 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.050000 | repetitionPenalty:0.998642 | AvgLoss:31.724927 | temperature:0.998641 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:-1.679110 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.286832 | embedNormStd:10.074368 | embedNormMax:103.199661 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:16.307255 | logitWeightNormMean:91.718063 | logitWeightNormStd:2.493568 | logitWeightNormMax:103.893845 | logitWeightSparsity:0.000009 | logitWeightDrift:41.034081 | logitBiasMean:-34.088070 | logitBiasStd:11.921337 | logitBiasMax:-13.069657 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953690 | longDecay:0.967438 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007837 | n_weightStd:0.899741 | n_weightMin:-4.710789 | n_weightMax:4.827273 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.672285 | n_weightNormMin:21.157347 | n_weightNormMax:41.438778 | n_biasesMean:-1.071065 | n_biasesStd:0.789158 | n_biasesMin:-3.826611 | n_biasesMax:1.861755 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.135183 | INN_cerebellumStd:4.238717 | sampledTokens:150.000000 | windowWeightsW2:4.34658 (0.60), W4:0.68292 (0.31), W12:-1.69946 (0.02), W8:-1.70753 (0.02), W16:-3.01785 (0.01), W20:-4.14068 (0.01), W24:-5.21251 (0.01), W28:-8.01126 (0.01), W32:-9.45659 (0.01) | topTokens[('.', 508), ("'", 384), ('Ġyou', 222), ('Ġpic', 125), ('s', 106), ('Ġhe', 103), ('Ġcharis', 95), ('Ġthe', 90), ('Ġto', 80), (',', 75)] | cheekyAvg: 30.711045957079122 | perfectTokens: 43 / 6400 → 0.67% |  | remainingTokens: 199899 (99.95%) | TUTOR.py 100
--- 2025-04-23 06:14:32 --- 
[babyllm] right, last time i got to step 106936... want to restart from there?
[charis] 0
[babyllm] damn that's specific! heading to step 0... what am i learning today?
[charis]learnable self parameters bby :)--- 2025-04-23 06:15:32 --- 
[babyllm] right, last time i got to step 106936... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 106936! what am i learning today?
[charis]--- 2025-04-23 06:15:40 --- 
[babyllm] right, last time i got to step 106936... want to restart from there?
[charis] 0
[babyllm] damn that's specific! heading to step 0... what am i learning today?
[charis]new learnable params bby :d2025-04-23 06:19:14 | 500 | LR0.000101 | loss:24.182110 | gradNorm:0.000000 | logitMin:ERR:'<=' not supported between instances of 'float' and 'str' key:logitMin value:0.0 | logitMax:ERR:'<=' not supported between instances of 'int' and 'str' key:logitMax value:0 | tokenCount:ERR:'<=' not supported between instances of 'int' and 'str' key:tokenCount value:0 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.998510 | AvgLoss:33.701361 | temperature:0.998509 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:-4.136805 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.285849 | embedNormStd:10.073679 | embedNormMax:103.192497 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:3.261966 | logitWeightNormMean:91.711761 | logitWeightNormStd:2.493395 | logitWeightNormMax:103.886719 | logitWeightSparsity:0.000008 | logitWeightDrift:8.207354 | logitBiasMean:-34.085835 | logitBiasStd:11.920732 | logitBiasMax:-13.068997 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953682 | longDecay:0.967437 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007837 | n_weightStd:0.899679 | n_weightMin:-4.710449 | n_weightMax:4.826923 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.670307 | n_weightNormMin:21.155916 | n_weightNormMax:41.435867 | n_biasesMean:-1.070991 | n_biasesStd:0.789103 | n_biasesMin:-3.826273 | n_biasesMax:1.861588 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.134966 | INN_cerebellumStd:4.238397 | windowWeightsW2:4.34606 (0.60), W4:0.68286 (0.31), W12:-1.69933 (0.02), W8:-1.70740 (0.02), W16:-3.01759 (0.01), W20:-4.14015 (0.01), W24:-5.21198 (0.01), W28:-8.01021 (0.01), W32:-9.45554 (0.01) | topTokens[('.', 2139), ('Ġeating', 1017), ('Ġpic', 938), ('ing', 912), ('Ġyou', 797), ("'", 704), (',', 614), ('Ġwas', 504), ('Ġbutt', 499), ('s', 477)] | cheekyAvg: 24.36979425870455 | perfectTokens: 270 / 32000 → 0.84% |  | remainingTokens: 199499 (99.75%) | TUTOR.py 500
2025-04-23 06:22:31 | 1000 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.998391 | AvgLoss:33.918100 | loss:25.108685 | temperature:0.998390 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:-5.453218 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.284449 | embedNormStd:10.072700 | embedNormMax:103.182510 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000155 | logitWeightNormMean:91.702660 | logitWeightNormStd:2.493148 | logitWeightNormMax:103.876587 | logitWeightSparsity:0.000008 | logitWeightDrift:0.000817 | logitBiasMean:-34.082668 | logitBiasStd:11.919848 | logitBiasMax:-13.068045 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953675 | longDecay:0.967423 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007836 | n_weightStd:0.899592 | n_weightMin:-4.709968 | n_weightMax:4.826445 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.667500 | n_weightNormMin:21.153809 | n_weightNormMax:41.431786 | n_biasesMean:-1.070888 | n_biasesStd:0.789026 | n_biasesMin:-3.825797 | n_biasesMax:1.861350 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.134651 | INN_cerebellumStd:4.237938 | windowWeightsW2:4.34558 (0.60), W4:0.68280 (0.31), W12:-1.69921 (0.02), W8:-1.70728 (0.02), W16:-3.01735 (0.01), W20:-4.13967 (0.01), W24:-5.21150 (0.01), W28:-8.00925 (0.01), W32:-9.45458 (0.01) | topTokens[('.', 4348), ('Ġpic', 2104), ('Ġeating', 1958), ('ing', 1567), ('Ġwas', 1296), ('Ġyou', 1295), ("'", 1293), (',', 1016), ('s', 864), ('Ġelodie', 823)] | cheekyAvg: 25.764253540039064 | perfectTokens: 230 / 32000 → 0.72% |  | remainingTokens: 198999 (99.50%) | TUTOR.py 500
2025-04-23 06:26:17 | 1500 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.998272 | AvgLoss:31.261307 | loss:26.031572 | temperature:0.998271 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:6.884758 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.283052 | embedNormStd:10.071718 | embedNormMax:103.172447 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000155 | logitWeightNormMean:91.694061 | logitWeightNormStd:2.492902 | logitWeightNormMax:103.866432 | logitWeightSparsity:0.000008 | logitWeightDrift:0.000818 | logitBiasMean:-34.079426 | logitBiasStd:11.919005 | logitBiasMax:-13.067092 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953663 | longDecay:0.967415 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007835 | n_weightStd:0.899506 | n_weightMin:-4.709488 | n_weightMax:4.825974 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.664680 | n_weightNormMin:21.151711 | n_weightNormMax:41.427727 | n_biasesMean:-1.070781 | n_biasesStd:0.788948 | n_biasesMin:-3.825321 | n_biasesMax:1.861112 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.134342 | INN_cerebellumStd:4.237474 | windowWeightsW2:4.34510 (0.60), W4:0.68274 (0.31), W12:-1.69909 (0.02), W8:-1.70716 (0.02), W16:-3.01711 (0.01), W20:-4.13920 (0.01), W24:-5.21103 (0.01), W28:-8.00830 (0.01), W32:-9.45363 (0.01) | topTokens[('.', 5772), ('Ġpic', 3363), ('Ġeating', 2355), ('ing', 2354), ('Ġwas', 2157), ('Ġyou', 1763), ('s', 1615), (',', 1573), ("'", 1551), ('Ġto', 1501)] | cheekyAvg: 24.662410888671875 | perfectTokens: 231 / 32000 → 0.72% |  | remainingTokens: 198499 (99.25%) | TUTOR.py 500
2025-04-23 06:29:36 | 2000 | LR0.000101 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.998153 | AvgLoss:32.625453 | loss:26.237326 | temperature:0.998152 | lR:0.000101 | gradientClip:1.000000 | latestLossDelta:-6.070945 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.281683 | embedNormStd:10.070735 | embedNormMax:103.162415 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000156 | logitWeightNormMean:91.684921 | logitWeightNormStd:2.492655 | logitWeightNormMax:103.856262 | logitWeightSparsity:0.000008 | logitWeightDrift:0.000819 | logitBiasMean:-34.076248 | logitBiasStd:11.918130 | logitBiasMax:-13.066146 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953651 | longDecay:0.967409 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007835 | n_weightStd:0.899417 | n_weightMin:-4.709009 | n_weightMax:4.825501 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.661911 | n_weightNormMin:21.149576 | n_weightNormMax:41.423710 | n_biasesMean:-1.070677 | n_biasesStd:0.788871 | n_biasesMin:-3.824845 | n_biasesMax:1.860873 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.134027 | INN_cerebellumStd:4.237015 | windowWeightsW2:4.34463 (0.60), W4:0.68268 (0.31), W12:-1.69897 (0.02), W8:-1.70704 (0.02), W16:-3.01687 (0.01), W20:-4.13872 (0.01), W24:-5.21055 (0.01), W28:-8.00735 (0.01), W32:-9.45268 (0.01) | topTokens[('.', 7655), ('Ġpic', 4611), ('ing', 3310), ('Ġeating', 3006), ('Ġwas', 2542), ('s', 2348), ("'", 2199), ('Ġyou', 2164), (',', 1884), ('Ġto', 1826)] | cheekyAvg: 25.53986343383789 | perfectTokens: 229 / 32000 → 0.72% |  | remainingTokens: 197999 (99.00%) | TUTOR.py 500
2025-04-23 06:32:50 | 2500 | LR0.000102 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.998034 | AvgLoss:32.611694 | loss:23.694674 | temperature:0.998033 | lR:0.000102 | gradientClip:1.000000 | latestLossDelta:-6.425597 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.280296 | embedNormStd:10.069752 | embedNormMax:103.152245 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000156 | logitWeightNormMean:91.675781 | logitWeightNormStd:2.492407 | logitWeightNormMax:103.846184 | logitWeightSparsity:0.000008 | logitWeightDrift:0.000819 | logitBiasMean:-34.073063 | logitBiasStd:11.917234 | logitBiasMax:-13.065199 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953644 | longDecay:0.967407 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007834 | n_weightStd:0.899329 | n_weightMin:-4.708533 | n_weightMax:4.825029 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.659151 | n_weightNormMin:21.147457 | n_weightNormMax:41.419724 | n_biasesMean:-1.070570 | n_biasesStd:0.788793 | n_biasesMin:-3.824368 | n_biasesMax:1.860633 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.133718 | INN_cerebellumStd:4.236555 | windowWeightsW2:4.34415 (0.60), W4:0.68262 (0.31), W12:-1.69885 (0.02), W8:-1.70692 (0.02), W16:-3.01663 (0.01), W20:-4.13824 (0.01), W24:-5.21007 (0.01), W28:-8.00639 (0.01), W32:-9.45172 (0.01) | topTokens[('.', 9729), ('Ġpic', 5210), ('ing', 4982), ('Ġeating', 3510), ('s', 3280), ('Ġwas', 2872), ("'", 2709), ('Ġyou', 2636), (',', 2450), ('Ġto', 2311)] | cheekyAvg: 25.75936508178711 | perfectTokens: 252 / 32000 → 0.79% |  | remainingTokens: 197499 (98.75%) | TUTOR.py 500
2025-04-23 06:36:08 | 3000 | LR0.000102 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.997914 | AvgLoss:34.550773 | loss:25.415285 | temperature:0.997913 | lR:0.000102 | gradientClip:1.000000 | latestLossDelta:12.767639 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.278889 | embedNormStd:10.068768 | embedNormMax:103.142174 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000156 | logitWeightNormMean:91.667099 | logitWeightNormStd:2.492160 | logitWeightNormMax:103.835968 | logitWeightSparsity:0.000008 | logitWeightDrift:0.000820 | logitBiasMean:-34.069775 | logitBiasStd:11.916322 | logitBiasMax:-13.064242 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953629 | longDecay:0.967395 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007833 | n_weightStd:0.899241 | n_weightMin:-4.708060 | n_weightMax:4.824558 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.656328 | n_weightNormMin:21.145411 | n_weightNormMax:41.415710 | n_biasesMean:-1.070469 | n_biasesStd:0.788716 | n_biasesMin:-3.823892 | n_biasesMax:1.860394 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.133404 | INN_cerebellumStd:4.236098 | windowWeightsW2:4.34367 (0.60), W4:0.68256 (0.31), W12:-1.69873 (0.02), W8:-1.70680 (0.02), W16:-3.01640 (0.01), W20:-4.13777 (0.01), W24:-5.20960 (0.01), W28:-8.00544 (0.01), W32:-9.45077 (0.01) | topTokens[('.', 11866), ('Ġpic', 7148), ('ing', 5482), ('Ġeating', 4037), ('Ġwas', 3672), ('s', 3556), ('Ġyou', 3124), ("'", 3075), (',', 2854), ('Ġto', 2665)] | cheekyAvg: 26.348721313476563 | perfectTokens: 262 / 32000 → 0.82% |  | remainingTokens: 196999 (98.50%) | TUTOR.py 500
2025-04-23 06:39:23 | 3500 | LR0.000102 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.997795 | AvgLoss:34.849565 | loss:30.421768 | temperature:0.997794 | lR:0.000102 | gradientClip:1.000000 | latestLossDelta:-0.014612 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.277493 | embedNormStd:10.067782 | embedNormMax:103.132057 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000156 | logitWeightNormMean:91.657990 | logitWeightNormStd:2.491913 | logitWeightNormMax:103.825813 | logitWeightSparsity:0.000008 | logitWeightDrift:0.000821 | logitBiasMean:-34.066578 | logitBiasStd:11.915384 | logitBiasMax:-13.063277 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953619 | longDecay:0.967384 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007832 | n_weightStd:0.899152 | n_weightMin:-4.707586 | n_weightMax:4.824086 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.653503 | n_weightNormMin:21.143354 | n_weightNormMax:41.411659 | n_biasesMean:-1.070361 | n_biasesStd:0.788637 | n_biasesMin:-3.823416 | n_biasesMax:1.860156 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.133095 | INN_cerebellumStd:4.235635 | windowWeightsW2:4.34319 (0.60), W4:0.68250 (0.31), W12:-1.69861 (0.02), W8:-1.70668 (0.02), W16:-3.01616 (0.01), W20:-4.13729 (0.01), W24:-5.20912 (0.01), W28:-8.00448 (0.01), W32:-9.44982 (0.01) | topTokens[('.', 13638), ('Ġpic', 9115), ('ing', 6259), ('Ġeating', 4893), ('Ġwas', 4547), ('s', 4095), ('Ġyou', 3656), ("'", 3488), (',', 3379), ('Ġbutt', 3017)] | cheekyAvg: 26.73613327026367 | perfectTokens: 206 / 32000 → 0.64% |  | remainingTokens: 196499 (98.25%) | TUTOR.py 500
2025-04-23 06:42:46 | 4000 | LR0.000102 | sampledTokens:0.000000 | scheduledSamplingRate:0.000000 | repetitionPenalty:0.997676 | AvgLoss:35.141877 | loss:28.857660 | temperature:0.997675 | lR:0.000102 | gradientClip:1.000000 | latestLossDelta:-1.264882 | memoryLength:ERR:'<=' not supported between instances of 'int' and 'str' key:memoryLength value:10 | embedNormMean:14.276093 | embedNormStd:10.066796 | embedNormMax:103.121925 | embedDimensionMean:<tensor[torch.Size([1024])]> | embedDimensionSparsity:0.000000 | embeddingDrift:0.000156 | logitWeightNormMean:91.648857 | logitWeightNormStd:2.491666 | logitWeightNormMax:103.815598 | logitWeightSparsity:0.000008 | logitWeightDrift:0.000821 | logitBiasMean:-34.063385 | logitBiasStd:11.914455 | logitBiasMax:-13.062312 | logitSeq:ERR:unsupported format string passed to list.__format__ key:logitSeq value:[] | shortDecay:0.953613 | longDecay:0.967378 | latestMemoryGates:<tensor[torch.Size([3])]> | n_weightMean:-0.007832 | n_weightStd:0.899064 | n_weightMin:-4.707114 | n_weightMax:4.823613 | n_weightNorm:<tensor[torch.Size([10000])]> | n_weightNormMean:28.650692 | n_weightNormMin:21.141283 | n_weightNormMax:41.407616 | n_biasesMean:-1.070257 | n_biasesStd:0.788560 | n_biasesMin:-3.822938 | n_biasesMax:1.859918 | n_sparsity:0.000008 | INN_cerebellum:<tensor[torch.Size([9])]> | INN_cerebellumSoft:<tensor[torch.Size([9])]> | INN_cerebellumMean:-3.132786 | INN_cerebellumStd:4.235173 | windowWeightsW2:4.34272 (0.60), W4:0.68244 (0.31), W12:-1.69849 (0.02), W8:-1.70656 (0.02), W16:-3.01592 (0.01), W20:-4.13681 (0.01), W24:-5.20864 (0.01), W28:-8.00353 (0.01), W32:-9.44886 (0.01) | topTokens[('.', 15424), ('Ġpic', 10276), ('ing', 7073), ('Ġeating', 5391), ('Ġwas', 5163), ('s', 4604), ('Ġyou', 4121), ("'", 4041), (',', 3688), ('Ġto', 3343)] | cheekyAvg: 27.647591094970704 | perfectTokens: 206 / 32000 → 0.64% |  | remainingTokens: 195999 (98.00%) | TUTOR.py 500
--- 2025-04-23 06:43:00 --- 
[babyllm] right, last time i got to step 4003... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 4003! what am i learning today?
[charis]--- 2025-04-23 06:45:15 --- 
[babyllm] right, last time i got to step 4003... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 4003! what am i learning today?
[charis]--- 2025-04-23 06:47:05 --- 
[babyllm] right, last time i got to step 4003... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 4003! what am i learning today?
[charis]--- 2025-04-23 06:49:12 --- 
[babyllm] right, last time i got to step 4255... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 4255! what am i learning today?
[charis]--- 2025-04-23 06:50:00 --- 
[babyllm] right, last time i got to step 4305... want to restart from there?
[charis] 
[babyllm] ok! let's go to step 4305! what am i learning today?
[charis]